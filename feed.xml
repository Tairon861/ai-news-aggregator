<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 30 Sep 2025 01:42:53 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Big AI firms pump money into world models as LLM advances slow (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/big-ai-firms-pump-money-into-world-models-as-llm-advances-slow/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        World models aim to navigate the physical world by learning from videos, robotic data.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Montage of AI logos" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aifirms-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Montage of AI logos" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aifirms-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The groups are developing systems to navigate the physical world by learning from videos and robotic data rather than just language.


              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          FT montage/Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The world’s top artificial intelligence groups are stepping up their focus on so-called world models that can better understand human environments, in the search for new ways to achieve machine “superintelligence.”&lt;/p&gt;
&lt;p&gt;Google DeepMind, Meta, and Nvidia are among the companies attempting to gain ground in the AI race by developing systems that aim to navigate the physical world by learning from videos and robotic data rather than just language.&lt;/p&gt;
&lt;p&gt;This push comes as questions rise about whether large language models—the technology that powers popular chatbots such as OpenAI’s ChatGPT—are reaching a ceiling in their progress.&lt;/p&gt;
&lt;p&gt;The leaps in performance between LLMs released by companies across the sector, such as OpenAI, Google, and Elon Musk’s xAI, have been slowing, despite the vast sums invested in their development.&lt;/p&gt;
&lt;p&gt;The potential market for world models could be huge, almost the size of the global economy, according to Rev Lebaredian, vice-president of Omniverse and simulation technology at Nvidia, as it brings the technology into the physical domain, such as the manufacturing and health care sectors.&lt;/p&gt;
&lt;p&gt;“What is the opportunity for world foundation models? Essentially... $100 trillion if we can make an intelligence that can understand the physical world and operate in the physical world,” he said.&lt;/p&gt;
&lt;p&gt;World models are trained using data streams of real or simulated environments. They are viewed as an important step in pushing forward progress in self-driving cars, robotics, and so-called AI agents, but require a huge amount of data and computing power to train and are considered an unsolved technical challenge.&lt;/p&gt;
&lt;p&gt;This focus on an alternative approach to LLMs has become visible as several AI groups have unveiled a series of advancements in world models in recent months.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Last month, Google DeepMind previewed Genie 3, which generates video frame by frame and takes past interactions into account. Previously, video generation models have typically created the entire video at once, rather than step-by-step.&lt;/p&gt;
&lt;p&gt;“AI... remains very much limited to the digital domain,” said Shlomi Fruchter, co-lead of Genie 3 at Google DeepMind. “By building environments that look like or behave like the real world, we can have much more scalable ways to train the AI... without the real implications of making a mistake in the real world.”&lt;/p&gt;
&lt;p&gt;Meta is attempting to replicate how children learn passively by observing the world around them, training its V-JEPA models on raw video content.&lt;/p&gt;
&lt;p&gt;Its Facebook Artificial Intelligence Research (Fair) lab, led by Meta chief AI scientist Yann LeCun and focused on longer-term AI projects, released its second version of the model in June, which it has been testing on robots.&lt;/p&gt;
&lt;p&gt;LeCun, considered one of the “godfathers” of modern AI, has been one of the most vocal proponents of the new architecture, warning that LLMs would never achieve the ability to reason and plan like humans.&lt;/p&gt;
&lt;p&gt;Despite this, Meta’s chief, Mark Zuckerberg, has recently increased investment in top AI talent, with an elite team now pushing to make breakthroughs on its next Llama LLM models. This has included hiring Alexandr Wang, the founder of data labeling group Scale AI, to head all of Meta’s AI work, with LeCun now reporting to Wang.&lt;/p&gt;
&lt;p&gt;One near-term application of world models is in the entertainment industry, where they can create interactive and realistic scenes. World Labs, a startup founded by AI pioneer Fei-Fei Li, is developing a model that generates video game-like 3D environments from a single image.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Runway, a video generation start-up that has deals with Hollywood studios, including Lionsgate, launched a product last month that uses world models to create gaming settings, with personalized stories and characters generated in real time.&lt;/p&gt;
&lt;p&gt;“Traditional video methods [are a] brute-force approach to pixel generation, where you’re trying to squeeze motion in a couple of frames to create the illusion of movement, but the model actually doesn’t really know or reason about what’s going on in that scene,” said Cristóbal Valenzuela, chief executive officer at Runway.&lt;/p&gt;
&lt;p&gt;Previous video-generation models had physics that were unlike the real world, he added, which general-purpose world model systems help to address.&lt;/p&gt;
&lt;p&gt;To build these models, companies need to collect a huge amount of physical data about the world.&lt;/p&gt;
&lt;p&gt;San Francisco-based Niantic has mapped 10 million locations, gathering information through games including Pokémon Go, which has 30 million monthly players interacting with a global map.&lt;/p&gt;
&lt;p&gt;Niantic ran Pokémon Go for nine years and, even after the game was sold to US-based Scopely in June, its players still contribute anonymized data through scans of public landmarks to help build its world model.&lt;/p&gt;
&lt;p&gt;“We have a running start at the problem,” said John Hanke, chief executive of Niantic Spatial, as the company is now called following the Scopely deal.&lt;/p&gt;
&lt;p&gt;Both Niantic and Nvidia are working on filling gaps by getting their world models to generate or predict environments. Nvidia’s Omniverse platform creates and runs such simulations, assisting the $4.3 trillion tech giant’s push toward robotics and building on its long history of simulating real-world environments in video games.&lt;/p&gt;
&lt;p&gt;Nvidia Chief Executive Jensen Huang has asserted that the next major growth phase for the company will come with “physical AI,” with the new models revolutionizing the field of robotics.&lt;/p&gt;
&lt;p&gt;Some such as Meta’s LeCun have said this vision of a new generation of AI systems powering machines with human-level intelligence could take 10 years to achieve.&lt;/p&gt;
&lt;p&gt;But the potential scope of the cutting-edge technology is extensive, according to AI experts. World models “open up the opportunity to service all of these other industries and amplify the same thing that computers did for knowledge work,” said Nvidia’s Lebaredian.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Additional reporting by Melissa Heikkilä in London and Michael Acton in San Francisco.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        World models aim to navigate the physical world by learning from videos, robotic data.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Montage of AI logos" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aifirms-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Montage of AI logos" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aifirms-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The groups are developing systems to navigate the physical world by learning from videos and robotic data rather than just language.


              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          FT montage/Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The world’s top artificial intelligence groups are stepping up their focus on so-called world models that can better understand human environments, in the search for new ways to achieve machine “superintelligence.”&lt;/p&gt;
&lt;p&gt;Google DeepMind, Meta, and Nvidia are among the companies attempting to gain ground in the AI race by developing systems that aim to navigate the physical world by learning from videos and robotic data rather than just language.&lt;/p&gt;
&lt;p&gt;This push comes as questions rise about whether large language models—the technology that powers popular chatbots such as OpenAI’s ChatGPT—are reaching a ceiling in their progress.&lt;/p&gt;
&lt;p&gt;The leaps in performance between LLMs released by companies across the sector, such as OpenAI, Google, and Elon Musk’s xAI, have been slowing, despite the vast sums invested in their development.&lt;/p&gt;
&lt;p&gt;The potential market for world models could be huge, almost the size of the global economy, according to Rev Lebaredian, vice-president of Omniverse and simulation technology at Nvidia, as it brings the technology into the physical domain, such as the manufacturing and health care sectors.&lt;/p&gt;
&lt;p&gt;“What is the opportunity for world foundation models? Essentially... $100 trillion if we can make an intelligence that can understand the physical world and operate in the physical world,” he said.&lt;/p&gt;
&lt;p&gt;World models are trained using data streams of real or simulated environments. They are viewed as an important step in pushing forward progress in self-driving cars, robotics, and so-called AI agents, but require a huge amount of data and computing power to train and are considered an unsolved technical challenge.&lt;/p&gt;
&lt;p&gt;This focus on an alternative approach to LLMs has become visible as several AI groups have unveiled a series of advancements in world models in recent months.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Last month, Google DeepMind previewed Genie 3, which generates video frame by frame and takes past interactions into account. Previously, video generation models have typically created the entire video at once, rather than step-by-step.&lt;/p&gt;
&lt;p&gt;“AI... remains very much limited to the digital domain,” said Shlomi Fruchter, co-lead of Genie 3 at Google DeepMind. “By building environments that look like or behave like the real world, we can have much more scalable ways to train the AI... without the real implications of making a mistake in the real world.”&lt;/p&gt;
&lt;p&gt;Meta is attempting to replicate how children learn passively by observing the world around them, training its V-JEPA models on raw video content.&lt;/p&gt;
&lt;p&gt;Its Facebook Artificial Intelligence Research (Fair) lab, led by Meta chief AI scientist Yann LeCun and focused on longer-term AI projects, released its second version of the model in June, which it has been testing on robots.&lt;/p&gt;
&lt;p&gt;LeCun, considered one of the “godfathers” of modern AI, has been one of the most vocal proponents of the new architecture, warning that LLMs would never achieve the ability to reason and plan like humans.&lt;/p&gt;
&lt;p&gt;Despite this, Meta’s chief, Mark Zuckerberg, has recently increased investment in top AI talent, with an elite team now pushing to make breakthroughs on its next Llama LLM models. This has included hiring Alexandr Wang, the founder of data labeling group Scale AI, to head all of Meta’s AI work, with LeCun now reporting to Wang.&lt;/p&gt;
&lt;p&gt;One near-term application of world models is in the entertainment industry, where they can create interactive and realistic scenes. World Labs, a startup founded by AI pioneer Fei-Fei Li, is developing a model that generates video game-like 3D environments from a single image.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Runway, a video generation start-up that has deals with Hollywood studios, including Lionsgate, launched a product last month that uses world models to create gaming settings, with personalized stories and characters generated in real time.&lt;/p&gt;
&lt;p&gt;“Traditional video methods [are a] brute-force approach to pixel generation, where you’re trying to squeeze motion in a couple of frames to create the illusion of movement, but the model actually doesn’t really know or reason about what’s going on in that scene,” said Cristóbal Valenzuela, chief executive officer at Runway.&lt;/p&gt;
&lt;p&gt;Previous video-generation models had physics that were unlike the real world, he added, which general-purpose world model systems help to address.&lt;/p&gt;
&lt;p&gt;To build these models, companies need to collect a huge amount of physical data about the world.&lt;/p&gt;
&lt;p&gt;San Francisco-based Niantic has mapped 10 million locations, gathering information through games including Pokémon Go, which has 30 million monthly players interacting with a global map.&lt;/p&gt;
&lt;p&gt;Niantic ran Pokémon Go for nine years and, even after the game was sold to US-based Scopely in June, its players still contribute anonymized data through scans of public landmarks to help build its world model.&lt;/p&gt;
&lt;p&gt;“We have a running start at the problem,” said John Hanke, chief executive of Niantic Spatial, as the company is now called following the Scopely deal.&lt;/p&gt;
&lt;p&gt;Both Niantic and Nvidia are working on filling gaps by getting their world models to generate or predict environments. Nvidia’s Omniverse platform creates and runs such simulations, assisting the $4.3 trillion tech giant’s push toward robotics and building on its long history of simulating real-world environments in video games.&lt;/p&gt;
&lt;p&gt;Nvidia Chief Executive Jensen Huang has asserted that the next major growth phase for the company will come with “physical AI,” with the new models revolutionizing the field of robotics.&lt;/p&gt;
&lt;p&gt;Some such as Meta’s LeCun have said this vision of a new generation of AI systems powering machines with human-level intelligence could take 10 years to achieve.&lt;/p&gt;
&lt;p&gt;But the potential scope of the cutting-edge technology is extensive, according to AI experts. World models “open up the opportunity to service all of these other industries and amplify the same thing that computers did for knowledge work,” said Nvidia’s Lebaredian.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Additional reporting by Melissa Heikkilä in London and Michael Acton in San Francisco.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/big-ai-firms-pump-money-into-world-models-as-llm-advances-slow/</guid><pubDate>Mon, 29 Sep 2025 13:56:05 +0000</pubDate></item><item><title>This week’s bundle savings: Founder and Investor Pass deals for TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/29/founder-investor-only-bundle-pass-deal-for-techcrunch-disrupt-2025-this-week/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;You read that right. From &lt;strong&gt;today through October 3&lt;/strong&gt;, we’re offering an exclusive deal just for founders and investors at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Founder Bundle Passes:&lt;/strong&gt; Groups of 4–9 founders save &lt;strong&gt;15%&lt;/strong&gt;.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Investor Bundle Passes:&lt;/strong&gt; Groups of 4–9 investors save &lt;strong&gt;20%&lt;/strong&gt; (up from 15%).&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;Round up your founder community or investor network, spread the news on all channels, and &lt;strong&gt;secure your bundle passes now&lt;/strong&gt; — these group savings are only available for a limited time.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-register-your-group-before-friday-october-3-at-11-59-p-m-pt"&gt;&lt;strong&gt;Register your group before Friday, October 3, at 11:59 p.m. PT.&lt;/strong&gt;&lt;/h4&gt;



&lt;h2 class="wp-block-heading" id="h-what-to-expect-at-disrupt-2025"&gt;What to expect at Disrupt 2025&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Disrupt stage crowd" class="wp-image-2799293" height="340" src="https://techcrunch.com/wp-content/uploads/2024/06/stage_1200x600.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Experience three full days at San Francisco’s Moscone West on October 27–29, with &lt;strong&gt;200+ sessions&lt;/strong&gt; featuring &lt;strong&gt;250+ top tech voices&lt;/strong&gt; across five industry stages, roundtables, and breakouts. Founders and investors alike will have access to unique perks designed to help you grow, scale, and connect.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-for-founders"&gt;For founders:&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;The &lt;strong&gt;Founder Pass&lt;/strong&gt; is built to help founders grow, connect, and gain visibility. For the first time, groups of 4–9 founders can save &lt;strong&gt;15%&lt;/strong&gt;. Once this offer ends after October 3, it’s gone.&lt;/p&gt;







&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Curated VC matchmaking:&lt;/strong&gt; Engage in personalized meetings with investors aligned to your stage and sector.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Exclusive access to the Deal Flow Cafe:&lt;/strong&gt; Connect informally with VCs actively seeking their next big bet.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 networking student" class="wp-image-2896237" height="453" src="https://techcrunch.com/wp-content/uploads/2024/10/Networking_disrupt.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Investor list:&lt;/strong&gt; Gain early access to a list of Disrupt investors who’ve opted in to meet founders.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Growth and IPO playbooks:&lt;/strong&gt; Learn directly from industry leaders on scaling, fundraising, and building sustainable companies.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Sector-focused stages and deep dives:&lt;/strong&gt; Engage in sessions designed for your growth, covering AI, GTM strategies,  the 2026 scaling playbook, and more.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Learn from top VCs:&lt;/strong&gt; Witness compelling pitches from startups competing in the iconic &lt;strong&gt;Startup Battlefield 200&lt;/strong&gt;, and gain insights from seasoned VCs on what it takes to craft a winning pitch and build a viable startup.&lt;/li&gt;
&lt;/ul&gt;



&lt;h3 class="wp-block-heading" id="h-for-investors"&gt;For investors:&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;The &lt;strong&gt;Investor Pass&lt;/strong&gt; gives premium access to startups that align with your portfolio goals. Groups of 4–9 investors can save &lt;strong&gt;20%&lt;/strong&gt;, up from 15%, through October 3.&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Direct access to 200 pitch-ready startups&lt;/strong&gt;: Meet pre–Series A startups handpicked by TechCrunch, competing for $100,000 in equity-free funding.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Exclusive access to the Deal Flow Cafe&lt;/strong&gt;: Connect informally with founders actively seeking investors.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Curated meetings&lt;/strong&gt;: Schedule impactful 1:1 or small-group meetings with founders matching your investment focus.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Founder list&lt;/strong&gt;: Get early access to a list of Disrupt founders who’ve opted in to connect with investors.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 StrictlyVC" class="wp-image-3038996" height="454" src="https://techcrunch.com/wp-content/uploads/2024/12/Disrupt-2024-StrictlyVC-Session.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;StrictlyVC session&lt;/strong&gt;: Participate in a boutique investor-only session featuring LP tracks and insider stories from top VCs, LPs, and founders.&lt;/li&gt;
&lt;/ul&gt;



&lt;h3 class="wp-block-heading" id="h-don-t-miss-out-on-disrupt-group-discounts"&gt;Don’t miss out on Disrupt group discounts&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;This is a &lt;strong&gt;limited-time offer&lt;/strong&gt;. No other bundle deals will be offered after &lt;strong&gt;October 3&lt;/strong&gt;. Bring your &lt;strong&gt;founder community&lt;/strong&gt; or &lt;strong&gt;investor network&lt;/strong&gt;, save on group passes, and secure your spot at one of the most anticipated tech events of the year in October.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Going solo? &lt;strong&gt;Save up to $444&lt;/strong&gt; on your individual pass.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;You read that right. From &lt;strong&gt;today through October 3&lt;/strong&gt;, we’re offering an exclusive deal just for founders and investors at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Founder Bundle Passes:&lt;/strong&gt; Groups of 4–9 founders save &lt;strong&gt;15%&lt;/strong&gt;.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Investor Bundle Passes:&lt;/strong&gt; Groups of 4–9 investors save &lt;strong&gt;20%&lt;/strong&gt; (up from 15%).&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;Round up your founder community or investor network, spread the news on all channels, and &lt;strong&gt;secure your bundle passes now&lt;/strong&gt; — these group savings are only available for a limited time.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-register-your-group-before-friday-october-3-at-11-59-p-m-pt"&gt;&lt;strong&gt;Register your group before Friday, October 3, at 11:59 p.m. PT.&lt;/strong&gt;&lt;/h4&gt;



&lt;h2 class="wp-block-heading" id="h-what-to-expect-at-disrupt-2025"&gt;What to expect at Disrupt 2025&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Disrupt stage crowd" class="wp-image-2799293" height="340" src="https://techcrunch.com/wp-content/uploads/2024/06/stage_1200x600.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Experience three full days at San Francisco’s Moscone West on October 27–29, with &lt;strong&gt;200+ sessions&lt;/strong&gt; featuring &lt;strong&gt;250+ top tech voices&lt;/strong&gt; across five industry stages, roundtables, and breakouts. Founders and investors alike will have access to unique perks designed to help you grow, scale, and connect.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-for-founders"&gt;For founders:&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;The &lt;strong&gt;Founder Pass&lt;/strong&gt; is built to help founders grow, connect, and gain visibility. For the first time, groups of 4–9 founders can save &lt;strong&gt;15%&lt;/strong&gt;. Once this offer ends after October 3, it’s gone.&lt;/p&gt;







&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Curated VC matchmaking:&lt;/strong&gt; Engage in personalized meetings with investors aligned to your stage and sector.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Exclusive access to the Deal Flow Cafe:&lt;/strong&gt; Connect informally with VCs actively seeking their next big bet.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 networking student" class="wp-image-2896237" height="453" src="https://techcrunch.com/wp-content/uploads/2024/10/Networking_disrupt.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Investor list:&lt;/strong&gt; Gain early access to a list of Disrupt investors who’ve opted in to meet founders.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Growth and IPO playbooks:&lt;/strong&gt; Learn directly from industry leaders on scaling, fundraising, and building sustainable companies.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Sector-focused stages and deep dives:&lt;/strong&gt; Engage in sessions designed for your growth, covering AI, GTM strategies,  the 2026 scaling playbook, and more.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Learn from top VCs:&lt;/strong&gt; Witness compelling pitches from startups competing in the iconic &lt;strong&gt;Startup Battlefield 200&lt;/strong&gt;, and gain insights from seasoned VCs on what it takes to craft a winning pitch and build a viable startup.&lt;/li&gt;
&lt;/ul&gt;



&lt;h3 class="wp-block-heading" id="h-for-investors"&gt;For investors:&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;The &lt;strong&gt;Investor Pass&lt;/strong&gt; gives premium access to startups that align with your portfolio goals. Groups of 4–9 investors can save &lt;strong&gt;20%&lt;/strong&gt;, up from 15%, through October 3.&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Direct access to 200 pitch-ready startups&lt;/strong&gt;: Meet pre–Series A startups handpicked by TechCrunch, competing for $100,000 in equity-free funding.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Exclusive access to the Deal Flow Cafe&lt;/strong&gt;: Connect informally with founders actively seeking investors.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Curated meetings&lt;/strong&gt;: Schedule impactful 1:1 or small-group meetings with founders matching your investment focus.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Founder list&lt;/strong&gt;: Get early access to a list of Disrupt founders who’ve opted in to connect with investors.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 StrictlyVC" class="wp-image-3038996" height="454" src="https://techcrunch.com/wp-content/uploads/2024/12/Disrupt-2024-StrictlyVC-Session.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;StrictlyVC session&lt;/strong&gt;: Participate in a boutique investor-only session featuring LP tracks and insider stories from top VCs, LPs, and founders.&lt;/li&gt;
&lt;/ul&gt;



&lt;h3 class="wp-block-heading" id="h-don-t-miss-out-on-disrupt-group-discounts"&gt;Don’t miss out on Disrupt group discounts&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;This is a &lt;strong&gt;limited-time offer&lt;/strong&gt;. No other bundle deals will be offered after &lt;strong&gt;October 3&lt;/strong&gt;. Bring your &lt;strong&gt;founder community&lt;/strong&gt; or &lt;strong&gt;investor network&lt;/strong&gt;, save on group passes, and secure your spot at one of the most anticipated tech events of the year in October.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Going solo? &lt;strong&gt;Save up to $444&lt;/strong&gt; on your individual pass.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 no anniversary" class="wp-image-3040972" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Disrupt_General_Article_No-Anniversary-at-all_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/29/founder-investor-only-bundle-pass-deal-for-techcrunch-disrupt-2025-this-week/</guid><pubDate>Mon, 29 Sep 2025 14:15:00 +0000</pubDate></item><item><title>OpenAI rolls out safety routing system, parental controls on ChatGPT (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/29/openai-rolls-out-safety-routing-system-parental-controls-on-chatgpt/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI began testing a new&amp;nbsp;safety routing&amp;nbsp;system&amp;nbsp;in ChatGPT&amp;nbsp;over the weekend, and&amp;nbsp;on Monday introduced parental controls to the chatbot —&amp;nbsp;drawing mixed reactions from users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The safety features come in response to numerous incidents of certain ChatGPT models validating users’ delusional thinking instead of redirecting harmful conversations.&amp;nbsp;OpenAI is facing a&amp;nbsp;wrongful death lawsuit&amp;nbsp;tied&amp;nbsp;to one such incident,&amp;nbsp;after&amp;nbsp;a teenage boy died by suicide after months of interactions with ChatGPT.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The routing system is designed to&amp;nbsp;detect emotionally sensitive conversations and&amp;nbsp;automatically switch mid-chat to GPT-5-thinking, which the company sees as the best equipped model for high-stakes safety work. In particular, the GPT-5 models were trained with a new safety feature that OpenAI calls “safe completions,” which allows them to answer sensitive questions in a safe way, rather than simply refusing to engage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a contrast from the company’s previous chat models, which are designed to be agreeable and answer questions quickly. GPT-4o has come under particular scrutiny because of its overly sycophantic, agreeable nature, which has both fueled incidents of&amp;nbsp;AI-induced&amp;nbsp;delusions and drawn a large base of devoted users.&amp;nbsp;When OpenAI rolled out&amp;nbsp;GPT-5 as the default&amp;nbsp;in August, many users&amp;nbsp;pushed back&amp;nbsp;and demanded access to GPT-4o.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While many experts and users have welcomed the safety features, others have&amp;nbsp;criticized&amp;nbsp;what they see as an overly cautious implementation, with some users&amp;nbsp;accusing OpenAI of treating adults like children in a way that degrades the quality of the service.&amp;nbsp;OpenAI has suggested that getting it right will take&amp;nbsp;time and&amp;nbsp;has given itself&amp;nbsp;a&amp;nbsp;120-day period of iteration and improvement.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nick Turley, VP and head of the ChatGPT app, acknowledged some of the “strong reactions to 4o responses” due to the implementation of the router&amp;nbsp;with explanations.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Routing happens on a per-message basis; switching from the default model happens on a temporary basis,”&amp;nbsp;Turley posted on X. “ChatGPT will tell you which model is active when asked. This is part of a broader effort to strengthen safeguards and learn from real-world use before a wider rollout.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The implementation of parental controls in ChatGPT received similar levels of praise and scorn, with some commending giving parents a way to keep tabs on their children’s AI use, and others fearful that it opens the door to OpenAI treating adults like children.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The controls let parents customize their teen’s experience by setting quiet hours, turning off voice mode and memory, removing image generation, and opting out of model training. Teen accounts will also get additional&amp;nbsp;content protections&amp;nbsp;— like reduced graphic content and extreme beauty ideals&amp;nbsp;— and a detection system that recognizes potential signs that a teen might be thinking about self-harm.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If our systems detect potential harm, a small team of specially trained people reviews the situation,” per OpenAI’s&amp;nbsp;blog. “If there are signs of acute distress, we will contact parents by email, text&amp;nbsp;message&amp;nbsp;and push alert on&amp;nbsp;their&amp;nbsp;phone, unless they have opted out.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI acknowledged that the system&amp;nbsp;won’t&amp;nbsp;be perfect and may sometimes raise alarms when there&amp;nbsp;isn’t&amp;nbsp;real danger, “but we think it’s better to act and alert a parent so they can step in than to stay silent.” The AI firm said it is also working on ways to reach law enforcement or emergency services if&amp;nbsp;it&amp;nbsp;detects&amp;nbsp;an imminent threat to life and&amp;nbsp;cannot&amp;nbsp;reach a parent.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI began testing a new&amp;nbsp;safety routing&amp;nbsp;system&amp;nbsp;in ChatGPT&amp;nbsp;over the weekend, and&amp;nbsp;on Monday introduced parental controls to the chatbot —&amp;nbsp;drawing mixed reactions from users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The safety features come in response to numerous incidents of certain ChatGPT models validating users’ delusional thinking instead of redirecting harmful conversations.&amp;nbsp;OpenAI is facing a&amp;nbsp;wrongful death lawsuit&amp;nbsp;tied&amp;nbsp;to one such incident,&amp;nbsp;after&amp;nbsp;a teenage boy died by suicide after months of interactions with ChatGPT.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The routing system is designed to&amp;nbsp;detect emotionally sensitive conversations and&amp;nbsp;automatically switch mid-chat to GPT-5-thinking, which the company sees as the best equipped model for high-stakes safety work. In particular, the GPT-5 models were trained with a new safety feature that OpenAI calls “safe completions,” which allows them to answer sensitive questions in a safe way, rather than simply refusing to engage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a contrast from the company’s previous chat models, which are designed to be agreeable and answer questions quickly. GPT-4o has come under particular scrutiny because of its overly sycophantic, agreeable nature, which has both fueled incidents of&amp;nbsp;AI-induced&amp;nbsp;delusions and drawn a large base of devoted users.&amp;nbsp;When OpenAI rolled out&amp;nbsp;GPT-5 as the default&amp;nbsp;in August, many users&amp;nbsp;pushed back&amp;nbsp;and demanded access to GPT-4o.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While many experts and users have welcomed the safety features, others have&amp;nbsp;criticized&amp;nbsp;what they see as an overly cautious implementation, with some users&amp;nbsp;accusing OpenAI of treating adults like children in a way that degrades the quality of the service.&amp;nbsp;OpenAI has suggested that getting it right will take&amp;nbsp;time and&amp;nbsp;has given itself&amp;nbsp;a&amp;nbsp;120-day period of iteration and improvement.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nick Turley, VP and head of the ChatGPT app, acknowledged some of the “strong reactions to 4o responses” due to the implementation of the router&amp;nbsp;with explanations.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Routing happens on a per-message basis; switching from the default model happens on a temporary basis,”&amp;nbsp;Turley posted on X. “ChatGPT will tell you which model is active when asked. This is part of a broader effort to strengthen safeguards and learn from real-world use before a wider rollout.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The implementation of parental controls in ChatGPT received similar levels of praise and scorn, with some commending giving parents a way to keep tabs on their children’s AI use, and others fearful that it opens the door to OpenAI treating adults like children.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The controls let parents customize their teen’s experience by setting quiet hours, turning off voice mode and memory, removing image generation, and opting out of model training. Teen accounts will also get additional&amp;nbsp;content protections&amp;nbsp;— like reduced graphic content and extreme beauty ideals&amp;nbsp;— and a detection system that recognizes potential signs that a teen might be thinking about self-harm.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If our systems detect potential harm, a small team of specially trained people reviews the situation,” per OpenAI’s&amp;nbsp;blog. “If there are signs of acute distress, we will contact parents by email, text&amp;nbsp;message&amp;nbsp;and push alert on&amp;nbsp;their&amp;nbsp;phone, unless they have opted out.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI acknowledged that the system&amp;nbsp;won’t&amp;nbsp;be perfect and may sometimes raise alarms when there&amp;nbsp;isn’t&amp;nbsp;real danger, “but we think it’s better to act and alert a parent so they can step in than to stay silent.” The AI firm said it is also working on ways to reach law enforcement or emergency services if&amp;nbsp;it&amp;nbsp;detects&amp;nbsp;an imminent threat to life and&amp;nbsp;cannot&amp;nbsp;reach a parent.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/29/openai-rolls-out-safety-routing-system-parental-controls-on-chatgpt/</guid><pubDate>Mon, 29 Sep 2025 14:50:42 +0000</pubDate></item><item><title>[NEW] Brave updates its AI-powered search with a detailed answers feature (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/29/brave-updates-its-ai-powered-search-with-a-detailed-answers-feature/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Browser maker and Google Search alternative Brave announced on Monday that it’s adding a new feature to its AI-powered search suite, Ask Brave, to provide detailed answers on a topic based on the query.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The search company said that this new feature will co-exist next to its AI Answers feature, which was introduced last year to give summarized responses to search queries. The company said that people are getting more than 15 million answers every day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;You don’t need to switch to a special mode to use Ask Brave. The search engine will automatically recognize what kind of query you are asking and give a response accordingly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can use the ask button next to the Brave search box to begin a search. You can also turn your normal search query into an AI search query by tapping into the Ask tab on the search page result. If you have the Brave search as your default search engine, you can append a double question mark (“??”) to a query to begin an ask Brave search query.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A screenshot of a Brave search feature that lets you append two question marks to get a detailed answer." class="wp-image-3051465" height="131" src="https://techcrunch.com/wp-content/uploads/2025/09/image-6.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Brave&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“While AI Answers give our users quick summaries, Ask&amp;nbsp;Brave&amp;nbsp;provides longer answers, follow-ups, and a chat mode enhanced with Deep Research, and most importantly, contextually relevant enrichments such as videos, news articles, products, businesses, shopping, and more — in the right place, at the right time,” said the chief of search at Brave, Josep M. Pujol, in a statement. “Search makes it possible, LLMs glue it together.&amp;nbsp;We anticipate that Ask&amp;nbsp;Brave&amp;nbsp;will generate millions more daily AI-powered answers with this powerful combination of search and chat, and look forward to deploying more useful AI-powered search tools for our users.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The format of the answer you get out of Ask Brave is more akin to a report format that you get out of ChatGPT or Perplexity, which includes links, videos, and image carousels. Once you get the answer, you can ask the AI chatbot to convert the answer into a different format or ask follow-up questions.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A screenshot showing the new Ask brave feature from the search company Brave, which gives detailed answers to your queries. " class="wp-image-3051464" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/Ask-Brave.jpeg?w=619" width="619" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Brave&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Brave said that it is using the company’s own API to ground search results for accuracy, along with deep research for certain queries.  &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;AI-powered Q&amp;amp;A is now creeping into various search experiences. Google has expanded its AI mode to multiple languages, including a global rollout for Spanish last week. Brave’s feature is similar but comes with a privacy claim that the company encrypts users’ chats and deletes them after 24 hours of inactivity. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Browser maker and Google Search alternative Brave announced on Monday that it’s adding a new feature to its AI-powered search suite, Ask Brave, to provide detailed answers on a topic based on the query.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The search company said that this new feature will co-exist next to its AI Answers feature, which was introduced last year to give summarized responses to search queries. The company said that people are getting more than 15 million answers every day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;You don’t need to switch to a special mode to use Ask Brave. The search engine will automatically recognize what kind of query you are asking and give a response accordingly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can use the ask button next to the Brave search box to begin a search. You can also turn your normal search query into an AI search query by tapping into the Ask tab on the search page result. If you have the Brave search as your default search engine, you can append a double question mark (“??”) to a query to begin an ask Brave search query.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A screenshot of a Brave search feature that lets you append two question marks to get a detailed answer." class="wp-image-3051465" height="131" src="https://techcrunch.com/wp-content/uploads/2025/09/image-6.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Brave&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“While AI Answers give our users quick summaries, Ask&amp;nbsp;Brave&amp;nbsp;provides longer answers, follow-ups, and a chat mode enhanced with Deep Research, and most importantly, contextually relevant enrichments such as videos, news articles, products, businesses, shopping, and more — in the right place, at the right time,” said the chief of search at Brave, Josep M. Pujol, in a statement. “Search makes it possible, LLMs glue it together.&amp;nbsp;We anticipate that Ask&amp;nbsp;Brave&amp;nbsp;will generate millions more daily AI-powered answers with this powerful combination of search and chat, and look forward to deploying more useful AI-powered search tools for our users.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The format of the answer you get out of Ask Brave is more akin to a report format that you get out of ChatGPT or Perplexity, which includes links, videos, and image carousels. Once you get the answer, you can ask the AI chatbot to convert the answer into a different format or ask follow-up questions.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A screenshot showing the new Ask brave feature from the search company Brave, which gives detailed answers to your queries. " class="wp-image-3051464" height="680" src="https://techcrunch.com/wp-content/uploads/2025/09/Ask-Brave.jpeg?w=619" width="619" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Brave&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Brave said that it is using the company’s own API to ground search results for accuracy, along with deep research for certain queries.  &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;AI-powered Q&amp;amp;A is now creeping into various search experiences. Google has expanded its AI mode to multiple languages, including a global rollout for Spanish last week. Brave’s feature is similar but comes with a privacy claim that the company encrypts users’ chats and deletes them after 24 hours of inactivity. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/29/brave-updates-its-ai-powered-search-with-a-detailed-answers-feature/</guid><pubDate>Mon, 29 Sep 2025 16:00:00 +0000</pubDate></item><item><title>Anthropic launches Claude Sonnet 4.5, its best AI model for coding (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/29/anthropic-launches-claude-sonnet-4-5-its-best-ai-model-for-coding/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Anthropic launched a new frontier model called Claude Sonnet 4.5, which it claims offers state-of-the-art performance on coding benchmarks. The company says Claude Sonnet 4.5 is capable of building “production-ready” applications, rather than just prototypes, representing a leap in reliability from previous AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Claude Sonnet 4.5 will be available via the Claude API and in the Claude chatbot. The pricing for developers is the same as Claude Sonnet 4: $3 per million input tokens (roughly 750,000 words, or more than the entire “Lord of the Rings” series) and $15 per million output tokens.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In the last year, Anthropic’s AI models have emerged as a favorite among developers and enterprises, in large part due to their strong performance on software engineering tasks. Apple and Meta reportedly use Claude AI models internally, and Anthropic has made a significant business selling API access to AI coding applications such as Cursor, Windsurf, and Replit. Recently, OpenAI’s GPT-5 has challenged Anthropic’s dominance in the space, outperforming Claude models on a variety of coding benchmarks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic says Claude Sonnet 4.5 offers industry-leading performance on several coding benchmarks, including SWE-Bench Verified. However, Anthropic AI researcher David Hershey tells TechCrunch that it is hard to capture Claude Sonnet 4.5’s performance on benchmarks alone.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3051688" height="384" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-29-at-10.08.34AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Anthropic&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Hershey says he’s seen Claude Sonnet 4.5 code autonomously for up to 30 hours during early trials with some enterprise customers. In that time, he watched the AI model not only build an application, but also stand up database services, purchase domain names, and perform a SOC 2 audit to make sure the product was secure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement shared with TechCrunch, Cursor CEO Michael Truell said Claude Sonnet 4.5 represents state-of-the-art coding performance, specifically on longer horizon tasks. Windsurf CEO Jeff Wang said in a statement that Claude Sonnet 4.5 represents a “new generation of coding models.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic also claims that Claude Sonnet 4.5 is its most aligned frontier AI model yet, with lower rates of sycophancy and deception than previous models. The company says it has also improved Claude’s susceptibility to prompt injection attacks.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the launch of Claude Sonnet 4.5, Anthropic is also launching the Claude Agent SDK. The company says this is the same infrastructure that powers Claude Code and can be used to help developers build their own agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic is also releasing a temporary research preview called “Imagine with Claude” for Max subscribers, which shows the AI model generating software on the fly. The company says the model will respond to user requests in real time, with no predetermined functionality or prewritten code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tense competition in the AI world has made it common for companies to ship flagship models every few months. Claude Sonnet 4.5 is launching less than two months after Anthropic’s last AI model, Claude Opus 4.1. These rapid production cycles make it difficult for any company to hold a meaningful lead for very long.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Anthropic launched a new frontier model called Claude Sonnet 4.5, which it claims offers state-of-the-art performance on coding benchmarks. The company says Claude Sonnet 4.5 is capable of building “production-ready” applications, rather than just prototypes, representing a leap in reliability from previous AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Claude Sonnet 4.5 will be available via the Claude API and in the Claude chatbot. The pricing for developers is the same as Claude Sonnet 4: $3 per million input tokens (roughly 750,000 words, or more than the entire “Lord of the Rings” series) and $15 per million output tokens.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In the last year, Anthropic’s AI models have emerged as a favorite among developers and enterprises, in large part due to their strong performance on software engineering tasks. Apple and Meta reportedly use Claude AI models internally, and Anthropic has made a significant business selling API access to AI coding applications such as Cursor, Windsurf, and Replit. Recently, OpenAI’s GPT-5 has challenged Anthropic’s dominance in the space, outperforming Claude models on a variety of coding benchmarks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic says Claude Sonnet 4.5 offers industry-leading performance on several coding benchmarks, including SWE-Bench Verified. However, Anthropic AI researcher David Hershey tells TechCrunch that it is hard to capture Claude Sonnet 4.5’s performance on benchmarks alone.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3051688" height="384" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-29-at-10.08.34AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Anthropic&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Hershey says he’s seen Claude Sonnet 4.5 code autonomously for up to 30 hours during early trials with some enterprise customers. In that time, he watched the AI model not only build an application, but also stand up database services, purchase domain names, and perform a SOC 2 audit to make sure the product was secure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement shared with TechCrunch, Cursor CEO Michael Truell said Claude Sonnet 4.5 represents state-of-the-art coding performance, specifically on longer horizon tasks. Windsurf CEO Jeff Wang said in a statement that Claude Sonnet 4.5 represents a “new generation of coding models.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic also claims that Claude Sonnet 4.5 is its most aligned frontier AI model yet, with lower rates of sycophancy and deception than previous models. The company says it has also improved Claude’s susceptibility to prompt injection attacks.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the launch of Claude Sonnet 4.5, Anthropic is also launching the Claude Agent SDK. The company says this is the same infrastructure that powers Claude Code and can be used to help developers build their own agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic is also releasing a temporary research preview called “Imagine with Claude” for Max subscribers, which shows the AI model generating software on the fly. The company says the model will respond to user requests in real time, with no predetermined functionality or prewritten code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tense competition in the AI world has made it common for companies to ship flagship models every few months. Claude Sonnet 4.5 is launching less than two months after Anthropic’s last AI model, Claude Opus 4.1. These rapid production cycles make it difficult for any company to hold a meaningful lead for very long.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/29/anthropic-launches-claude-sonnet-4-5-its-best-ai-model-for-coding/</guid><pubDate>Mon, 29 Sep 2025 17:02:14 +0000</pubDate></item><item><title>[NEW] Vibe-coding startup Anything nabs a $100M valuation after hitting $2M ARR in its first two weeks (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/29/vibe-coding-startup-anything-nabs-a-100m-valuation-after-hitting-2m-arr-in-its-first-two-weeks/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/dhruv_marcus.png?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s no secret that vibe coding — using AI-powered coding tools to build apps and websites via natural language prompts — is exploding in popularity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In July, Swedish vibe-coding startup Lovable hit $100 million in annual recurring revenue (ARR) just eight months after launch. It plans to close the year at $250 million ARR and thinks it will hit $1 billion ARR within the next 12 months. Meanwhile, Replit said earlier this month that its ARR soared from&amp;nbsp;$2.8 million&amp;nbsp;to&amp;nbsp;$150 million&amp;nbsp;in less than a year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These companies’ remarkable growth has fueled a wave of competitors, many of which are also quickly gaining momentum. “This is one of those spaces where every company is growing like a weed,” said Nikhil Basu Trivedi, co-founder and general partner at VC firm Footwork.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, despite their rapid growth, Lovable, Replit, and other vibe-coding startups have a significant shortcoming, argues Basu Trivedi: They excel at developing prototypes but struggle to enable users to launch production-ready software.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem with most vibe-coding companies, Basu Trivedi says, is that they don’t provide all the infrastructure that nontechnical users need to launch a functional product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anything, an AI app launched a month ago, is attempting to solve this problem by offering all the tools — from databases to storage and payment functionality — that users need to run businesses on the web or to send their vibe-coded creations to the App Store. The company’s initial traction was explosive, reaching $2 million annualized run rate in just two weeks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though the vibe-coding market is crowded, the company’s growth rate is so impressive that Basu Trivedi knew he had to fund it.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Anything announced on Monday that it has raised an $11 million financing round at a $100 million valuation, led by Footwork, with additional backing from Uncork, Bessemer, and M13.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Co-founded by former Google colleagues Dhruv Amin and Marcus Lowe, Anything is particularly designed to help nontechnical people generate complete web and mobile applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You haven’t really seen real businesses built on top of any of these tools,” Amin said about other vibe-coding companies. “We want to be the Shopify of the space, where people build apps that make money on top of us.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amin claims that users have already leveraged Anything to build fully functional applications available in the AppStore, including a habit tracker, a CPR training course, and a hairstyle “try-on” app. Some of these apps are even starting to make money.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These users, according to Amin, can finish their app in large part because they don’t have to figure out how to set up and connect other essential tools to the prototype generated by the vibe-coding app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea of developing a soup-to-nuts AI-assisted app builder came to Amin and Lowe a little under a year ago. The duo has been working together since 2021. Their first offering was a bootstrapped development marketplace that used AI coding tools in conjunction with human developers. But this was before the rise of LLMs. That business was generating about $2 million in annualized run rate, but it became clear that generative AI could soon deliver apps faster and at lower costs than their marketplace model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So, in 2023, they shut down that business and started working on developing an AI-powered app-building tool. They even raised some pre-seed and seed funding from Uncork and Bessemer Venture Partners along the way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amin and Lowe noticed that most competitive tools, including Lovable and StackBlitz‘s Bolt, rely on the third-party database Supabase. They believed that they could differentiate Anything AI by building all the infrastructure in-house.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That development took time, but it may turn out to be worth the effort because Anything is not the only startup in this market. It’s not even the only one that’s making a bet that offering all the back-end tools can be a big growth driver. Other startups that are building big chunks of their own infrastructure include Mocha and Rork, the latter of which claims to be on track to hit $10 million in ARR by the end of the year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the intense competition doesn’t faze Basu Trivedi. “It seems there’s enough demand out there for different types of app-building products,” he said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/dhruv_marcus.png?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s no secret that vibe coding — using AI-powered coding tools to build apps and websites via natural language prompts — is exploding in popularity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In July, Swedish vibe-coding startup Lovable hit $100 million in annual recurring revenue (ARR) just eight months after launch. It plans to close the year at $250 million ARR and thinks it will hit $1 billion ARR within the next 12 months. Meanwhile, Replit said earlier this month that its ARR soared from&amp;nbsp;$2.8 million&amp;nbsp;to&amp;nbsp;$150 million&amp;nbsp;in less than a year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These companies’ remarkable growth has fueled a wave of competitors, many of which are also quickly gaining momentum. “This is one of those spaces where every company is growing like a weed,” said Nikhil Basu Trivedi, co-founder and general partner at VC firm Footwork.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, despite their rapid growth, Lovable, Replit, and other vibe-coding startups have a significant shortcoming, argues Basu Trivedi: They excel at developing prototypes but struggle to enable users to launch production-ready software.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem with most vibe-coding companies, Basu Trivedi says, is that they don’t provide all the infrastructure that nontechnical users need to launch a functional product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anything, an AI app launched a month ago, is attempting to solve this problem by offering all the tools — from databases to storage and payment functionality — that users need to run businesses on the web or to send their vibe-coded creations to the App Store. The company’s initial traction was explosive, reaching $2 million annualized run rate in just two weeks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though the vibe-coding market is crowded, the company’s growth rate is so impressive that Basu Trivedi knew he had to fund it.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Anything announced on Monday that it has raised an $11 million financing round at a $100 million valuation, led by Footwork, with additional backing from Uncork, Bessemer, and M13.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Co-founded by former Google colleagues Dhruv Amin and Marcus Lowe, Anything is particularly designed to help nontechnical people generate complete web and mobile applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You haven’t really seen real businesses built on top of any of these tools,” Amin said about other vibe-coding companies. “We want to be the Shopify of the space, where people build apps that make money on top of us.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amin claims that users have already leveraged Anything to build fully functional applications available in the AppStore, including a habit tracker, a CPR training course, and a hairstyle “try-on” app. Some of these apps are even starting to make money.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These users, according to Amin, can finish their app in large part because they don’t have to figure out how to set up and connect other essential tools to the prototype generated by the vibe-coding app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea of developing a soup-to-nuts AI-assisted app builder came to Amin and Lowe a little under a year ago. The duo has been working together since 2021. Their first offering was a bootstrapped development marketplace that used AI coding tools in conjunction with human developers. But this was before the rise of LLMs. That business was generating about $2 million in annualized run rate, but it became clear that generative AI could soon deliver apps faster and at lower costs than their marketplace model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So, in 2023, they shut down that business and started working on developing an AI-powered app-building tool. They even raised some pre-seed and seed funding from Uncork and Bessemer Venture Partners along the way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amin and Lowe noticed that most competitive tools, including Lovable and StackBlitz‘s Bolt, rely on the third-party database Supabase. They believed that they could differentiate Anything AI by building all the infrastructure in-house.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That development took time, but it may turn out to be worth the effort because Anything is not the only startup in this market. It’s not even the only one that’s making a bet that offering all the back-end tools can be a big growth driver. Other startups that are building big chunks of their own infrastructure include Mocha and Rork, the latter of which claims to be on track to hit $10 million in ARR by the end of the year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the intense competition doesn’t faze Basu Trivedi. “It seems there’s enough demand out there for different types of app-building products,” he said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/29/vibe-coding-startup-anything-nabs-a-100m-valuation-after-hitting-2m-arr-in-its-first-two-weeks/</guid><pubDate>Mon, 29 Sep 2025 17:55:29 +0000</pubDate></item><item><title>[NEW] OpenAI takes on Google, Amazon with new agentic shopping system (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/29/openai-takes-on-google-amazon-with-new-agentic-shopping-system/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-29-at-2.55.40PM.png?resize=1200,683" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT users&amp;nbsp;in the U.S. can now make&amp;nbsp;Etsy and Shopify&amp;nbsp;purchases within conversations, marking a next step toward the future of online shopping&amp;nbsp;— both&amp;nbsp;for&amp;nbsp;consumers and&amp;nbsp;the platforms that control&amp;nbsp;product discovery, recommendation, and payments. In other words, OpenAI might be on the path to reshaping who holds power in e-commerce.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s new&amp;nbsp;“Instant Checkout” feature&amp;nbsp;is&amp;nbsp;available to ChatGPT Pro, Plus,&amp;nbsp;and Free logged-in users&amp;nbsp;buying from U.S.-based Etsy sellers,&amp;nbsp;with&amp;nbsp;more than 1 million Shopify merchants like Glossier, Skims, Spanx, and Vuori “coming soon,”&amp;nbsp;per OpenAI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Instant Checkout builds on&amp;nbsp;previous&amp;nbsp;shopping features on ChatGPT&amp;nbsp;that surfaced relevant products, images, reviews, prices, and direct links to merchants in response to shopping questions like “what should I get my friend who loves ceramics?” or “best sneakers to wear to the office.”&amp;nbsp;Now, instead of having to leave the conversation, users can just tap “Buy” to confirm their order, shipping, and payment details&amp;nbsp;(options include Apple Pay, Google Pay, Stripe, or credit card)&amp;nbsp;to complete the purchase.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year,&amp;nbsp;Perplexity introduced&amp;nbsp;a similar in-chat shopping and payments feature. Microsoft also offers merchants the ability to create in-chat storefront capabilities with the Copilot Merchant Program.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This&amp;nbsp;type of frictionless experience has the potential to spark a new movement in how people shop online — one that moves away from search engines like Google and e-commerce platforms like Amazon toward conversational agents with curated recommendations, comparisons, and easy checkout experiences.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s&amp;nbsp;also setting the stage for new power brokers to&amp;nbsp;emerge&amp;nbsp;in e-commerce. Google and Amazon have&amp;nbsp;long&amp;nbsp;been the gatekeepers for retail discovery.&amp;nbsp;If more purchases start inside AI chatbots, the firms behind them will suddenly have more control over what products are surfaced&amp;nbsp;and&amp;nbsp;what&amp;nbsp;commissions or fees they charge.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both&amp;nbsp;Amazon&amp;nbsp;and&amp;nbsp;Google&amp;nbsp;have previously&amp;nbsp;leveraged&amp;nbsp;their dominance to favor their own products or preferred partners, pushing down competitors in search results or charging steep fees to sellers simply to&amp;nbsp;maintain&amp;nbsp;visibility.&amp;nbsp;OpenAI said in a blog post that the product results it surfaces are “organic and unsponsored, ranked purely on relevance to the user,” and that it will charge merchants a “small fee” for completed purchases.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out&amp;nbsp;to OpenAI&amp;nbsp;for more information.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Along with OpenAI’s&amp;nbsp;introduction of in-chat checkout, the AI firm also noted that it will open source its&amp;nbsp;Agentic Commerce Protocol&amp;nbsp;(ACP), the tech that powers Instant Checkout built with Stripe, so that other merchants and developers can integrate agentic checkout.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Stripe is building the economic infrastructure for AI,” Will&amp;nbsp;Gaybrick, president of technology and business at Stripe, said in a statement. “That means re-architecting today’s commerce systems and creating new AI-powered experiences for billions of people.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While some may balk at handing ChatGPT private payment information, the&amp;nbsp;company&amp;nbsp;says orders, payments, and fulfillment are handled by the merchant using their existing systems. ChatGPT merely acts as an agent, an intermediary that can securely pass along information between user and merchant.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Open sourcing ACP makes it easier for merchants to integrate with ChatGPT, widening the&amp;nbsp;adoption&amp;nbsp;of AI chatbots&amp;nbsp;that function as a virtual storefront.&amp;nbsp;It also expands OpenAI’s potential control as a gatekeeper for retail discovery and checkout, and could position the firm to be the de facto architect of the AI commerce ecosystem.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That would put it in tension with Google yet again, as the tech giant has recently launched its own open protocol for purchases initiated by AI agents, dubbed Agent Payments Protocol (AP2).   &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-29-at-2.55.40PM.png?resize=1200,683" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT users&amp;nbsp;in the U.S. can now make&amp;nbsp;Etsy and Shopify&amp;nbsp;purchases within conversations, marking a next step toward the future of online shopping&amp;nbsp;— both&amp;nbsp;for&amp;nbsp;consumers and&amp;nbsp;the platforms that control&amp;nbsp;product discovery, recommendation, and payments. In other words, OpenAI might be on the path to reshaping who holds power in e-commerce.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s new&amp;nbsp;“Instant Checkout” feature&amp;nbsp;is&amp;nbsp;available to ChatGPT Pro, Plus,&amp;nbsp;and Free logged-in users&amp;nbsp;buying from U.S.-based Etsy sellers,&amp;nbsp;with&amp;nbsp;more than 1 million Shopify merchants like Glossier, Skims, Spanx, and Vuori “coming soon,”&amp;nbsp;per OpenAI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Instant Checkout builds on&amp;nbsp;previous&amp;nbsp;shopping features on ChatGPT&amp;nbsp;that surfaced relevant products, images, reviews, prices, and direct links to merchants in response to shopping questions like “what should I get my friend who loves ceramics?” or “best sneakers to wear to the office.”&amp;nbsp;Now, instead of having to leave the conversation, users can just tap “Buy” to confirm their order, shipping, and payment details&amp;nbsp;(options include Apple Pay, Google Pay, Stripe, or credit card)&amp;nbsp;to complete the purchase.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year,&amp;nbsp;Perplexity introduced&amp;nbsp;a similar in-chat shopping and payments feature. Microsoft also offers merchants the ability to create in-chat storefront capabilities with the Copilot Merchant Program.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This&amp;nbsp;type of frictionless experience has the potential to spark a new movement in how people shop online — one that moves away from search engines like Google and e-commerce platforms like Amazon toward conversational agents with curated recommendations, comparisons, and easy checkout experiences.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s&amp;nbsp;also setting the stage for new power brokers to&amp;nbsp;emerge&amp;nbsp;in e-commerce. Google and Amazon have&amp;nbsp;long&amp;nbsp;been the gatekeepers for retail discovery.&amp;nbsp;If more purchases start inside AI chatbots, the firms behind them will suddenly have more control over what products are surfaced&amp;nbsp;and&amp;nbsp;what&amp;nbsp;commissions or fees they charge.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both&amp;nbsp;Amazon&amp;nbsp;and&amp;nbsp;Google&amp;nbsp;have previously&amp;nbsp;leveraged&amp;nbsp;their dominance to favor their own products or preferred partners, pushing down competitors in search results or charging steep fees to sellers simply to&amp;nbsp;maintain&amp;nbsp;visibility.&amp;nbsp;OpenAI said in a blog post that the product results it surfaces are “organic and unsponsored, ranked purely on relevance to the user,” and that it will charge merchants a “small fee” for completed purchases.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out&amp;nbsp;to OpenAI&amp;nbsp;for more information.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Along with OpenAI’s&amp;nbsp;introduction of in-chat checkout, the AI firm also noted that it will open source its&amp;nbsp;Agentic Commerce Protocol&amp;nbsp;(ACP), the tech that powers Instant Checkout built with Stripe, so that other merchants and developers can integrate agentic checkout.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Stripe is building the economic infrastructure for AI,” Will&amp;nbsp;Gaybrick, president of technology and business at Stripe, said in a statement. “That means re-architecting today’s commerce systems and creating new AI-powered experiences for billions of people.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While some may balk at handing ChatGPT private payment information, the&amp;nbsp;company&amp;nbsp;says orders, payments, and fulfillment are handled by the merchant using their existing systems. ChatGPT merely acts as an agent, an intermediary that can securely pass along information between user and merchant.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Open sourcing ACP makes it easier for merchants to integrate with ChatGPT, widening the&amp;nbsp;adoption&amp;nbsp;of AI chatbots&amp;nbsp;that function as a virtual storefront.&amp;nbsp;It also expands OpenAI’s potential control as a gatekeeper for retail discovery and checkout, and could position the firm to be the de facto architect of the AI commerce ecosystem.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That would put it in tension with Google yet again, as the tech giant has recently launched its own open protocol for purchases initiated by AI agents, dubbed Agent Payments Protocol (AP2).   &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/29/openai-takes-on-google-amazon-with-new-agentic-shopping-system/</guid><pubDate>Mon, 29 Sep 2025 19:32:27 +0000</pubDate></item><item><title>[NEW] DeepSeek releases ‘sparse attention’ model that cuts API costs in half (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/29/deepseek-releases-sparse-attention-model-that-cuts-api-costs-in-half/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Researchers at DeepSeek on Monday released a new experimental model called V3.2-exp, designed to have dramatically lower inference costs when used in long-context operations. DeepSeek announced the model with a post on Hugging Face, also posting a linked academic paper on GitHub.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The most important feature of the new model is called DeepSeek Sparse Attention, an intricate system described in detail in the diagram below. In essence, the system uses a module called a “lightning indexer” to prioritize specific excerpts from the context window. After that, a separate system called a “fine-grained token selection system” chooses specific tokens from within those excerpts to load into the module’s limited attention window. Taken together, they allow the Sparse Attention models to operate over long portions of context with comparatively small server loads.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3051825" height="397" src="https://techcrunch.com/wp-content/uploads/2025/09/Screen-Shot-2025-09-29-at-3.35.45-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For long-context operations, the benefits of the system are significant. Preliminary testing by DeepSeek found that the price of a simple API call could be reduced by as much as half in long-context situations. Further testing will be required to build a more robust assessment, but because the model is open-weight and freely available on Hugging Face, it won’t be long before third-party tests can assess the claims made in the paper.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;DeepSeek’s new model is one of a string of recent breakthroughs tackling the problem of inference costs — essentially, the server costs of operating a pre-trained AI model, as distinct from the cost of training it. In DeepSeek’s case, the researchers were looking for ways to make the fundamental transformer architecture operate more efficiently — and finding that there are significant improvements to be made.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Based in China, DeepSeek has been an unusual figure in the AI boom, particularly for those who view AI research as a nationalist struggle between the U.S. and China. The company made waves at the beginning of the year with its R1 model, trained using primarily reinforcement learning at a far lower cost than its American competitors. But the model has not sparked a wholesale revolution in AI training, as some predicted, and the company has receded from the spotlight in the months since.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new “sparse attention” approach is unlikely to produce the same uproar as R1 — but it could still teach U.S. providers some much needed tricks to help keep inference costs low.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Researchers at DeepSeek on Monday released a new experimental model called V3.2-exp, designed to have dramatically lower inference costs when used in long-context operations. DeepSeek announced the model with a post on Hugging Face, also posting a linked academic paper on GitHub.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The most important feature of the new model is called DeepSeek Sparse Attention, an intricate system described in detail in the diagram below. In essence, the system uses a module called a “lightning indexer” to prioritize specific excerpts from the context window. After that, a separate system called a “fine-grained token selection system” chooses specific tokens from within those excerpts to load into the module’s limited attention window. Taken together, they allow the Sparse Attention models to operate over long portions of context with comparatively small server loads.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3051825" height="397" src="https://techcrunch.com/wp-content/uploads/2025/09/Screen-Shot-2025-09-29-at-3.35.45-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For long-context operations, the benefits of the system are significant. Preliminary testing by DeepSeek found that the price of a simple API call could be reduced by as much as half in long-context situations. Further testing will be required to build a more robust assessment, but because the model is open-weight and freely available on Hugging Face, it won’t be long before third-party tests can assess the claims made in the paper.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;DeepSeek’s new model is one of a string of recent breakthroughs tackling the problem of inference costs — essentially, the server costs of operating a pre-trained AI model, as distinct from the cost of training it. In DeepSeek’s case, the researchers were looking for ways to make the fundamental transformer architecture operate more efficiently — and finding that there are significant improvements to be made.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Based in China, DeepSeek has been an unusual figure in the AI boom, particularly for those who view AI research as a nationalist struggle between the U.S. and China. The company made waves at the beginning of the year with its R1 model, trained using primarily reinforcement learning at a far lower cost than its American competitors. But the model has not sparked a wholesale revolution in AI training, as some predicted, and the company has receded from the spotlight in the months since.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new “sparse attention” approach is unlikely to produce the same uproar as R1 — but it could still teach U.S. providers some much needed tricks to help keep inference costs low.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/29/deepseek-releases-sparse-attention-model-that-cuts-api-costs-in-half/</guid><pubDate>Mon, 29 Sep 2025 20:25:08 +0000</pubDate></item><item><title>[NEW] AI recruiter Alex raises $17M to automate initial job interviews (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/29/ai-recruiter-alex-raises-17m-to-automate-initial-job-interviews/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Alex.com-Team.jpg?resize=1200,820" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Job seekers in all fields can expect to soon be doing a lot more initial screening interviews. While that may sound like positive news, it doesn’t mean that there will suddenly be more open positions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead, recruiters, often bogged down with determining which applicants are qualified for the next round, will outsource the routine screening tasks — like checking backgrounds, salary needs, and availability — to (you guessed it) AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Alex, a startup building an AI recruiter, says it’s already helping companies conduct video interviews and phone screens.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aaron Wang (pictured center, bottom row), who co-founded Alex about 18 months ago, told TechCrunch that the startup’s voice AI tool can conduct autonomous interviews with applicants soon after they apply for a job. “Our AI recruiter does thousands of interviews a day and helps people get hired at some of the biggest companies in the world,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although Wang, who previously worked at Facebook and spent time as a quant for a hedge fund, declined to name customers, he said they include Fortune 100 companies, financial institutions, nationwide restaurant chains, and Big 4 accounting firms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors view the rise of AI interviewers as a trend that many companies will inevitably adopt. That conviction led to Alex’s new $17 million Series A round, which was led by Peak XV Partners. The round included participation from Y Combinator and Uncorrelated Ventures, along with several chief human resources officers (CHROs) from unnamed Fortune 500 companies, and others. This Series A follows the company’s $3 million seed funding, which was led by 1984 Ventures last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alex isn’t alone in offering AI recruiting services to companies. The startup’s competitors include other early-stage companies like HeyMilo, ConverzAI, and Ribbon.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Mercor, the rapidly growing AI data labeling startup that we reported is attempting to raise a new round at a $10 billion valuation, also started its life as an AI recruiter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alex’s long-term vision is to interview millions of job applicants to build professional profile data that is richer and deeper than what LinkedIn currently offers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our thesis is that a 10-minute conversation with you tells me a whole lot more about you than your LinkedIn profile does,” Wang said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But for now, Alex is focused on helping recruiters free up their time to build relationships with pre-qualified candidates and advising hiring managers.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Alex.com-Team.jpg?resize=1200,820" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Job seekers in all fields can expect to soon be doing a lot more initial screening interviews. While that may sound like positive news, it doesn’t mean that there will suddenly be more open positions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead, recruiters, often bogged down with determining which applicants are qualified for the next round, will outsource the routine screening tasks — like checking backgrounds, salary needs, and availability — to (you guessed it) AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Alex, a startup building an AI recruiter, says it’s already helping companies conduct video interviews and phone screens.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aaron Wang (pictured center, bottom row), who co-founded Alex about 18 months ago, told TechCrunch that the startup’s voice AI tool can conduct autonomous interviews with applicants soon after they apply for a job. “Our AI recruiter does thousands of interviews a day and helps people get hired at some of the biggest companies in the world,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although Wang, who previously worked at Facebook and spent time as a quant for a hedge fund, declined to name customers, he said they include Fortune 100 companies, financial institutions, nationwide restaurant chains, and Big 4 accounting firms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors view the rise of AI interviewers as a trend that many companies will inevitably adopt. That conviction led to Alex’s new $17 million Series A round, which was led by Peak XV Partners. The round included participation from Y Combinator and Uncorrelated Ventures, along with several chief human resources officers (CHROs) from unnamed Fortune 500 companies, and others. This Series A follows the company’s $3 million seed funding, which was led by 1984 Ventures last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alex isn’t alone in offering AI recruiting services to companies. The startup’s competitors include other early-stage companies like HeyMilo, ConverzAI, and Ribbon.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Mercor, the rapidly growing AI data labeling startup that we reported is attempting to raise a new round at a $10 billion valuation, also started its life as an AI recruiter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alex’s long-term vision is to interview millions of job applicants to build professional profile data that is richer and deeper than what LinkedIn currently offers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our thesis is that a 10-minute conversation with you tells me a whole lot more about you than your LinkedIn profile does,” Wang said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But for now, Alex is focused on helping recruiters free up their time to build relationships with pre-qualified candidates and advising hiring managers.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/29/ai-recruiter-alex-raises-17m-to-automate-initial-job-interviews/</guid><pubDate>Mon, 29 Sep 2025 20:32:35 +0000</pubDate></item><item><title>[NEW] DeepSeek: Everything you need to know about the AI chatbot app (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/29/deepseek-everything-you-need-to-know-about-the-ai-chatbot-app/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/deepseek-2.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;DeepSeek has gone viral.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chinese AI lab DeepSeek broke into the mainstream consciousness this week after&amp;nbsp;its chatbot app rose to the top of the Apple App Store charts (and Google Play, as well). DeepSeek’s AI models, which were trained using compute-efficient techniques,&amp;nbsp;have led Wall Street analysts&amp;nbsp;—&amp;nbsp;and technologists&amp;nbsp;— to question whether the U.S. can maintain its lead in the AI race and whether the demand for AI chips will sustain.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But where did DeepSeek come from, and how did it rise to international fame so quickly?&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-deepseek-s-trader-origins"&gt;DeepSeek’s trader origins&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek is backed by High-Flyer Capital Management, a Chinese quantitative hedge fund that uses AI to inform its trading decisions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI enthusiast Liang Wenfeng co-founded High-Flyer in 2015. Wenfeng, who reportedly began dabbling in trading while a student at Zhejiang University, launched High-Flyer Capital Management as a hedge fund in 2019 focused on developing and deploying AI algorithms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2023, High-Flyer started DeepSeek as a lab dedicated to researching AI tools separate from its financial business. With High-Flyer as one of its investors, the lab spun off into its own company, also called DeepSeek.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;From day one, DeepSeek built its own data center clusters for model training. But like other AI companies in China, DeepSeek has been affected by U.S. export bans on hardware. To train one of its more recent models, the company was forced to use Nvidia H800 chips, a less-powerful version of a chip, the H100, available to U.S. companies.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek’s technical team is said to skew young. The company reportedly aggressively recruits doctorate AI researchers from top Chinese universities. DeepSeek also hires people without any computer science background to help its tech better understand a wide range of subjects, per The New York Times.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-deepseek-s-strong-models"&gt;DeepSeek’s strong models&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek unveiled its first set of models — DeepSeek Coder, DeepSeek LLM, and DeepSeek Chat — in November 2023. But it wasn’t until last spring, when the startup released its next-gen DeepSeek-V2 family of models, that the AI industry started to take notice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek-V2, a general-purpose text- and image-analyzing system, performed well in various AI benchmarks — and was far cheaper to run than comparable models at the time. It forced DeepSeek’s domestic competition, including ByteDance and Alibaba, to cut the usage prices for some of their models, and make others completely free.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;DeepSeek-V3, launched in December 2024, only added to DeepSeek’s notoriety.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to DeepSeek’s internal benchmark testing, DeepSeek V3 outperforms both downloadable, openly available models like Meta’s&amp;nbsp;Llama and “closed” models that can only be accessed through an API, like OpenAI’s GPT-4o. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Equally impressive is DeepSeek’s R1 “reasoning” model. Released in January, DeepSeek claims R1 performs as well as OpenAI’s&amp;nbsp;o1&amp;nbsp;model on key benchmarks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Being a reasoning model, R1 effectively fact-checks itself, which&amp;nbsp;helps it to avoid some of the&amp;nbsp;pitfalls&amp;nbsp;that normally trip up models. Reasoning models take a little longer — usually seconds to minutes longer — to arrive at solutions compared to a typical non-reasoning model. The upside is that they tend to be more reliable in domains such as physics, science, and math.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There is a downside to R1, DeepSeek V3, and DeepSeek’s other models, however. Being Chinese-developed AI, they’re subject to&amp;nbsp;benchmarking&amp;nbsp;by China’s internet regulator to ensure that its responses “embody core socialist values.” In DeepSeek’s chatbot app, for example, R1 won’t answer questions about Tiananmen Square or Taiwan’s autonomy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In March, DeepSeek surpassed 16.5 million visits. “[F]or March, DeepSeek is in second place, despite seeing traffic drop 25% from where it was in February, based on daily visits,” David Carr, editor at Similarweb, told TechCrunch. It still pales in comparison to ChatGPT, which surged past 500 million weekly active users in March.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In May, DeepSeek released an updated version of its&amp;nbsp;R1 reasoning AI model&amp;nbsp;on the&amp;nbsp;developer platform Hugging Face. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek unveiled a new experimental model called V3.2-exp in September, designed to have dramatically lower inference costs when used in long-context operations.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-disruptive-approach"&gt;A disruptive approach&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If DeepSeek has a business model, it’s not clear what that model is, exactly. The company prices its products and services well below market value — and gives others away for free. It’s also not taking investor money, despite a ton of VC interest.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The way DeepSeek tells it, efficiency breakthroughs have enabled it to maintain extreme cost competitiveness. Some experts dispute the figures the company has supplied, however.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whatever the case may be, developers have taken to DeepSeek’s models, which aren’t open source as the phrase is commonly understood but are available under permissive licenses that allow for commercial use. According to Clem Delangue, the CEO of Hugging Face, one of the platforms hosting DeepSeek’s models, developers on Hugging Face have created over 500 “derivative” models of R1 that have racked up 2.5 million downloads combined.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek’s success against larger and more established rivals has been described as “upending AI” and “over-hyped.” The company’s success was at least in part responsible for causing Nvidia’s stock price to drop by 18% in January, and for eliciting a public response from OpenAI CEO Sam Altman. In March, U.S. Commerce department bureaus told staffers that DeepSeek will be banned on their government devices, according to Reuters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft announced that DeepSeek is available on its Azure AI Foundry service, Microsoft’s platform that brings together AI services for enterprises under a single banner. When asked about DeepSeek’s impact on Meta’s AI spending during its first-quarter earnings call, CEO Mark Zuckerberg said spending on AI infrastructure will continue to be a “strategic advantage” for Meta. In March, OpenAI called DeepSeek “state-subsidized” and “state-controlled,” and recommends that the U.S. government consider banning models from DeepSeek.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During Nvidia’s fourth-quarter earnings call, CEO Jensen Huang emphasized DeepSeek’s “excellent innovation,” saying that it and other “reasoning” models are great for Nvidia because they need so much more compute.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, some companies are banning DeepSeek, and so are entire countries and governments, including South Korea. New York state also banned DeepSeek from being used on government devices. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In May, Microsoft vice chairman and president Brad Smith said in a Senate hearing that Microsoft employees aren’t allowed to use DeepSeek due to data security and propaganda concerns.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for what DeepSeek’s future might hold, it’s not clear. Improved models are a given. But the U.S. government appears to be growing wary of what it perceives as harmful foreign influence. In March, The Wall Street Journal reported that the U.S. will likely ban DeepSeek on government devices.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story was originally published January 28, 2025, and will be updated regularly.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/deepseek-2.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;DeepSeek has gone viral.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chinese AI lab DeepSeek broke into the mainstream consciousness this week after&amp;nbsp;its chatbot app rose to the top of the Apple App Store charts (and Google Play, as well). DeepSeek’s AI models, which were trained using compute-efficient techniques,&amp;nbsp;have led Wall Street analysts&amp;nbsp;—&amp;nbsp;and technologists&amp;nbsp;— to question whether the U.S. can maintain its lead in the AI race and whether the demand for AI chips will sustain.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But where did DeepSeek come from, and how did it rise to international fame so quickly?&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-deepseek-s-trader-origins"&gt;DeepSeek’s trader origins&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek is backed by High-Flyer Capital Management, a Chinese quantitative hedge fund that uses AI to inform its trading decisions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI enthusiast Liang Wenfeng co-founded High-Flyer in 2015. Wenfeng, who reportedly began dabbling in trading while a student at Zhejiang University, launched High-Flyer Capital Management as a hedge fund in 2019 focused on developing and deploying AI algorithms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2023, High-Flyer started DeepSeek as a lab dedicated to researching AI tools separate from its financial business. With High-Flyer as one of its investors, the lab spun off into its own company, also called DeepSeek.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;From day one, DeepSeek built its own data center clusters for model training. But like other AI companies in China, DeepSeek has been affected by U.S. export bans on hardware. To train one of its more recent models, the company was forced to use Nvidia H800 chips, a less-powerful version of a chip, the H100, available to U.S. companies.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek’s technical team is said to skew young. The company reportedly aggressively recruits doctorate AI researchers from top Chinese universities. DeepSeek also hires people without any computer science background to help its tech better understand a wide range of subjects, per The New York Times.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-deepseek-s-strong-models"&gt;DeepSeek’s strong models&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek unveiled its first set of models — DeepSeek Coder, DeepSeek LLM, and DeepSeek Chat — in November 2023. But it wasn’t until last spring, when the startup released its next-gen DeepSeek-V2 family of models, that the AI industry started to take notice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek-V2, a general-purpose text- and image-analyzing system, performed well in various AI benchmarks — and was far cheaper to run than comparable models at the time. It forced DeepSeek’s domestic competition, including ByteDance and Alibaba, to cut the usage prices for some of their models, and make others completely free.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;DeepSeek-V3, launched in December 2024, only added to DeepSeek’s notoriety.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to DeepSeek’s internal benchmark testing, DeepSeek V3 outperforms both downloadable, openly available models like Meta’s&amp;nbsp;Llama and “closed” models that can only be accessed through an API, like OpenAI’s GPT-4o. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Equally impressive is DeepSeek’s R1 “reasoning” model. Released in January, DeepSeek claims R1 performs as well as OpenAI’s&amp;nbsp;o1&amp;nbsp;model on key benchmarks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Being a reasoning model, R1 effectively fact-checks itself, which&amp;nbsp;helps it to avoid some of the&amp;nbsp;pitfalls&amp;nbsp;that normally trip up models. Reasoning models take a little longer — usually seconds to minutes longer — to arrive at solutions compared to a typical non-reasoning model. The upside is that they tend to be more reliable in domains such as physics, science, and math.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There is a downside to R1, DeepSeek V3, and DeepSeek’s other models, however. Being Chinese-developed AI, they’re subject to&amp;nbsp;benchmarking&amp;nbsp;by China’s internet regulator to ensure that its responses “embody core socialist values.” In DeepSeek’s chatbot app, for example, R1 won’t answer questions about Tiananmen Square or Taiwan’s autonomy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In March, DeepSeek surpassed 16.5 million visits. “[F]or March, DeepSeek is in second place, despite seeing traffic drop 25% from where it was in February, based on daily visits,” David Carr, editor at Similarweb, told TechCrunch. It still pales in comparison to ChatGPT, which surged past 500 million weekly active users in March.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In May, DeepSeek released an updated version of its&amp;nbsp;R1 reasoning AI model&amp;nbsp;on the&amp;nbsp;developer platform Hugging Face. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek unveiled a new experimental model called V3.2-exp in September, designed to have dramatically lower inference costs when used in long-context operations.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-disruptive-approach"&gt;A disruptive approach&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;If DeepSeek has a business model, it’s not clear what that model is, exactly. The company prices its products and services well below market value — and gives others away for free. It’s also not taking investor money, despite a ton of VC interest.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The way DeepSeek tells it, efficiency breakthroughs have enabled it to maintain extreme cost competitiveness. Some experts dispute the figures the company has supplied, however.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whatever the case may be, developers have taken to DeepSeek’s models, which aren’t open source as the phrase is commonly understood but are available under permissive licenses that allow for commercial use. According to Clem Delangue, the CEO of Hugging Face, one of the platforms hosting DeepSeek’s models, developers on Hugging Face have created over 500 “derivative” models of R1 that have racked up 2.5 million downloads combined.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;DeepSeek’s success against larger and more established rivals has been described as “upending AI” and “over-hyped.” The company’s success was at least in part responsible for causing Nvidia’s stock price to drop by 18% in January, and for eliciting a public response from OpenAI CEO Sam Altman. In March, U.S. Commerce department bureaus told staffers that DeepSeek will be banned on their government devices, according to Reuters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft announced that DeepSeek is available on its Azure AI Foundry service, Microsoft’s platform that brings together AI services for enterprises under a single banner. When asked about DeepSeek’s impact on Meta’s AI spending during its first-quarter earnings call, CEO Mark Zuckerberg said spending on AI infrastructure will continue to be a “strategic advantage” for Meta. In March, OpenAI called DeepSeek “state-subsidized” and “state-controlled,” and recommends that the U.S. government consider banning models from DeepSeek.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During Nvidia’s fourth-quarter earnings call, CEO Jensen Huang emphasized DeepSeek’s “excellent innovation,” saying that it and other “reasoning” models are great for Nvidia because they need so much more compute.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, some companies are banning DeepSeek, and so are entire countries and governments, including South Korea. New York state also banned DeepSeek from being used on government devices. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In May, Microsoft vice chairman and president Brad Smith said in a Senate hearing that Microsoft employees aren’t allowed to use DeepSeek due to data security and propaganda concerns.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for what DeepSeek’s future might hold, it’s not clear. Improved models are a given. But the U.S. government appears to be growing wary of what it perceives as harmful foreign influence. In March, The Wall Street Journal reported that the U.S. will likely ban DeepSeek on government devices.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story was originally published January 28, 2025, and will be updated regularly.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/29/deepseek-everything-you-need-to-know-about-the-ai-chatbot-app/</guid><pubDate>Mon, 29 Sep 2025 20:56:38 +0000</pubDate></item><item><title>[NEW] California Governor Newsom signs landmark AI safety bill SB 53 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/29/california-governor-newsom-signs-landmark-ai-safety-bill-sb-53/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2159615518.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California Gov. Gavin Newsom has&amp;nbsp;signed SB 53, a first-in-the-nation bill that sets new&amp;nbsp;transparency requirements&amp;nbsp;on large AI companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB&amp;nbsp;53, which&amp;nbsp;passed&amp;nbsp;the state legislature two weeks ago,&amp;nbsp;requires large AI labs — including OpenAI, Anthropic, Meta, and Google DeepMind — to be transparent about safety&amp;nbsp;protocols. It also&amp;nbsp;ensures whistleblower protections for employees at those companies.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition,&amp;nbsp;SB 53&amp;nbsp;creates a mechanism for AI companies and the public to report potential critical safety incidents&amp;nbsp;to California’s Office of Emergency Services.&amp;nbsp;Companies&amp;nbsp;also&amp;nbsp;have to report incidents related to crimes committed without human oversight, such as cyberattacks, and deceptive behavior by a model that isn’t required under the EU AI Act.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bill has received mixed reactions from the AI industry. Tech firms have broadly argued that state-level AI policy risks creating a “patchwork of regulation” that would hinder innovation, although Anthropic endorsed the bill. Meta and OpenAI lobbied against it. OpenAI even wrote and published an open letter to Gov. Newsom that discouraged his signing of SB 53.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new bill comes as some of Silicon Valley’s tech elite have poured hundreds of millions into super PACs to back candidates that support a light-touch approach to AI regulation.&amp;nbsp;Leaders at OpenAI and&amp;nbsp;Meta&amp;nbsp;have in recent weeks launched&amp;nbsp;pro-AI super PACs&amp;nbsp;that aim to&amp;nbsp;back candidates&amp;nbsp;and bills that are friendly to AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, other states might look to California for inspiration as they&amp;nbsp;attempt&amp;nbsp;to curb the potential&amp;nbsp;harms&amp;nbsp;caused by the&amp;nbsp;unmitigated advancement of such a powerful emerging technology.&amp;nbsp;In New York, a similar bill was passed by state lawmakers and is awaiting Gov. Kathy Hochul’s signature or veto.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“California has proven that we can establish regulations to protect our communities while also ensuring that the growing AI industry continues to thrive,” Newsom said in a statement.&amp;nbsp;“This legislation strikes that balance. AI is the new frontier in innovation, and California is not only here for it — but stands strong as a national leader by enacting the first-in-the-nation frontier AI safety legislation that builds public trust as this emerging technology rapidly evolves.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The governor is also weighing another bill —&amp;nbsp;SB 243&amp;nbsp;— that passed both the State Assembly and Senate with bipartisan support this month. The bill would regulate AI companion chatbots, requiring operators to implement safety protocols, and hold them legally&amp;nbsp;accountable if their&amp;nbsp;bots&amp;nbsp;fail to&amp;nbsp;meet those standards.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 is&amp;nbsp;Senator&amp;nbsp;Scott Wiener’s second attempt at an AI safety bill&amp;nbsp;after&amp;nbsp;Newsom vetoed&amp;nbsp;his more sweeping SB 1047 last year amid major pushback from AI companies.&amp;nbsp;With this bill, Wiener&amp;nbsp;reached out to major AI companies&amp;nbsp;to attempt to help them understand the changes he made to the bill.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2159615518.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California Gov. Gavin Newsom has&amp;nbsp;signed SB 53, a first-in-the-nation bill that sets new&amp;nbsp;transparency requirements&amp;nbsp;on large AI companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB&amp;nbsp;53, which&amp;nbsp;passed&amp;nbsp;the state legislature two weeks ago,&amp;nbsp;requires large AI labs — including OpenAI, Anthropic, Meta, and Google DeepMind — to be transparent about safety&amp;nbsp;protocols. It also&amp;nbsp;ensures whistleblower protections for employees at those companies.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition,&amp;nbsp;SB 53&amp;nbsp;creates a mechanism for AI companies and the public to report potential critical safety incidents&amp;nbsp;to California’s Office of Emergency Services.&amp;nbsp;Companies&amp;nbsp;also&amp;nbsp;have to report incidents related to crimes committed without human oversight, such as cyberattacks, and deceptive behavior by a model that isn’t required under the EU AI Act.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bill has received mixed reactions from the AI industry. Tech firms have broadly argued that state-level AI policy risks creating a “patchwork of regulation” that would hinder innovation, although Anthropic endorsed the bill. Meta and OpenAI lobbied against it. OpenAI even wrote and published an open letter to Gov. Newsom that discouraged his signing of SB 53.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new bill comes as some of Silicon Valley’s tech elite have poured hundreds of millions into super PACs to back candidates that support a light-touch approach to AI regulation.&amp;nbsp;Leaders at OpenAI and&amp;nbsp;Meta&amp;nbsp;have in recent weeks launched&amp;nbsp;pro-AI super PACs&amp;nbsp;that aim to&amp;nbsp;back candidates&amp;nbsp;and bills that are friendly to AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, other states might look to California for inspiration as they&amp;nbsp;attempt&amp;nbsp;to curb the potential&amp;nbsp;harms&amp;nbsp;caused by the&amp;nbsp;unmitigated advancement of such a powerful emerging technology.&amp;nbsp;In New York, a similar bill was passed by state lawmakers and is awaiting Gov. Kathy Hochul’s signature or veto.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“California has proven that we can establish regulations to protect our communities while also ensuring that the growing AI industry continues to thrive,” Newsom said in a statement.&amp;nbsp;“This legislation strikes that balance. AI is the new frontier in innovation, and California is not only here for it — but stands strong as a national leader by enacting the first-in-the-nation frontier AI safety legislation that builds public trust as this emerging technology rapidly evolves.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The governor is also weighing another bill —&amp;nbsp;SB 243&amp;nbsp;— that passed both the State Assembly and Senate with bipartisan support this month. The bill would regulate AI companion chatbots, requiring operators to implement safety protocols, and hold them legally&amp;nbsp;accountable if their&amp;nbsp;bots&amp;nbsp;fail to&amp;nbsp;meet those standards.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 is&amp;nbsp;Senator&amp;nbsp;Scott Wiener’s second attempt at an AI safety bill&amp;nbsp;after&amp;nbsp;Newsom vetoed&amp;nbsp;his more sweeping SB 1047 last year amid major pushback from AI companies.&amp;nbsp;With this bill, Wiener&amp;nbsp;reached out to major AI companies&amp;nbsp;to attempt to help them understand the changes he made to the bill.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/29/california-governor-newsom-signs-landmark-ai-safety-bill-sb-53/</guid><pubDate>Mon, 29 Sep 2025 21:57:03 +0000</pubDate></item><item><title>[NEW] Anthropic says its new AI model “maintained focus” for 30 hours on multistep tasks (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/anthropic-says-its-new-ai-model-maintained-focus-for-30-hours-on-multistep-tasks/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Latest Claude model beats OpenAI and Google on coding tests.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Claude Sonnet 4.5 logo." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/sonnet45-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Claude Sonnet 4.5 logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/sonnet45-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Claude Sonnet 4.5 logo.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Monday, Anthropic released Claude Sonnet 4.5, a new AI language model the company calls its "most capable model to date," with improved coding and computer use capabilities. The company also revealed Claude Code 2.0, a command-line AI agent for developers, and the Claude Agent SDK, which is a tool developers can use to build their own AI coding agents.&lt;/p&gt;
&lt;p&gt;Anthropic says it has witnessed Sonnet 4.5 working continuously on the same project "for more than 30 hours on complex, multi-step tasks," though the company did not provide specific details about the tasks. In the past, agentic models have been known to typically lose coherence over long periods of time as errors accumulate and context windows (a type of short-term&amp;nbsp;memory for the model) fill up. In the past, Anthropic has mentioned that previous Claude 4.0 models have played &lt;em&gt;Pokémon&lt;/em&gt; for over 24 hours or refactored code for seven hours.&lt;/p&gt;
&lt;p&gt;To understand why Sonnet exists, you need to know a bit about how AI language models work. Traditionally, Anthropic has produced three differently sized AI models in the Claude family: Haiku (the smallest), Sonnet (mid-range), and Opus (the largest). Anthropic last updated Haiku in November 2024 (to 3.5), Sonnet this past May (to 4.0), and Opus in August (to 4.1). Model size in parameters, which are values stored in its neural network, is roughly proportional to overall contextual depth (the number of multidimensional connections between concepts, which you might call "knowledge") and better problem-solving capability, but larger models are also slower and more expensive to run. So AI companies always seek a sweet spot in the middle with reasonable performance-cost trade-offs. Claude Sonnet has filled that role for Anthropic quite well for several years now.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119733 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="The intro card for Sonnet 4.5, seen in the Claude web interface on September 29, 2025." class="center large" height="706" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/sonnet_intro-1024x706.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Claude is popular with some software developers thanks to Claude Code, and Anthropic is confident about the latest version of Sonnet's coding capability: "Claude Sonnet 4.5 is the best coding model in the world," the company boasts on its website. "It's the strongest model for building complex agents. It’s the best model at using computers. And it shows substantial gains in reasoning and math."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Anthropic backs up those claims with strong benchmark performance. Sonnet 4.5 model achieved a reported 77.2 percent score on SWE-bench Verified, a benchmark that attempts to measure real-world software coding abilities, and it currently leads the OSWorld benchmark at 61.4 percent, which tests AI models on real-world computer tasks. That beats OpenAI's GPT-5 Codex (which scored 74.5 percent) and Google's Gemini 2.5 Pro (67.2 percent).&lt;/p&gt;
&lt;p&gt;In other testing, Claude Sonnet 4.5 showed gains across multiple other evaluations such as AIME 2024, a mathematics competition benchmark, and MMMLU, which tests subject knowledge across 14 non-English languages. On finance-specific tasks measured by Vals AI's Finance Agent benchmark, which is a relatively new benchmark that "tests the ability of agents to perform tasks expected of an entry-level financial analyst," Sonnet 4.5 scored 92 percent.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119745 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Claude Sonnet 4.5 benchmark results measured and reported by Anthropic." class="center large" height="901" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/2825bb34cb9b9aa1ef347f816c590b5bbdae2b4d-2600x2288-1-1024x901.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Claude Sonnet 4.5 benchmark results measured and reported by Anthropic.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Sonnet 4.5 also reportedly demonstrated improved computer use capabilities compared to its predecessor in testing. Four months ago, Claude Sonnet 4 scored 42.2 percent on OSWorld. The new version increases that score to 61.4 percent. Anthropic uses these capabilities in its Claude for Chrome extension. Similar to OpenAI's ChatGPT Agent. Claude's extension can navigate websites, fill spreadsheets, and complete other browser-based tasks with various degrees of success.&lt;/p&gt;
&lt;p&gt;As always, it's worth noting that AI benchmarks can be gamed easily, poorly designed, or suffer from dataset contamination (a scenario where the model is inadvertently trained on answers in the benchmark). So always take any benchmarks with a grain of salt until they are independently verified. Even with a skeptical eye on the self-reported numbers, it seems that Sonnet 4.5 represents a solid step up from 4.0, and given Anthropic's history of delivering more capable models over time, we have no particular reason to doubt that.&lt;/p&gt;
&lt;p&gt;Simon Willison, a veteran software developer and frequent source of independent expert perspective on AI models for Ars Technica, wrote about Sonnet 4.5 on his blog today. He seems generally impressed: "Anthropic gave me access to a preview version of a 'new model' over the weekend which turned out to be Sonnet 4.5," he wrote. "My initial impressions were that it felt like a better model for code than GPT-5-Codex, which has been my preferred coding model since it launched a few weeks ago. This space moves so fast—Gemini 3 is rumored to land soon so who knows how long Sonnet 4.5 will continue to hold the 'best coding model' crown."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Claude 4.5 is available everywhere today. Through the API, the model maintains the same pricing as Claude Sonnet 4, at $3 per million input tokens and $15 per million output tokens. Developers can access it through the Claude API using "claude-sonnet-4-5" as the model identifier.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Other new features&lt;/h2&gt;
&lt;p&gt;Some ancillary features of the Claude family got some upgrades today, too. For example, Anthropic added code execution and file creation directly within conversations for users of Claude's web interface and dedicated apps. Along those lines, users can now generate spreadsheets, slides, and documents without leaving the chat interface.&lt;/p&gt;
&lt;p&gt;The company also released a five-day research preview called "Imagine with Claude" for Max subscribers, which demonstrates the model generating software in real time. Anthropic describes it as "a fun demonstration showing what Claude Sonnet 4.5 can do" when combined with appropriate infrastructure.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119732 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of the available Anthropic AI models for Claude Max users seen in the Claude web interface on September 29, 2025." class="center large" height="582" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/anthropic_models_9-29-2025-1024x582.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of the available Anthropic AI models for Claude Max users seen in the Claude web interface on September 29, 2025.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;As mentioned above, the command-line development tool Claude Code also received several updates today, alongside the new model. The company added checkpoints that save progress and allow users to roll back to previous states, refreshed the terminal interface, and shipped a native VS Code extension. The Claude API also gains a new context editing feature and memory tool for handling longer-running agent tasks.&lt;/p&gt;
&lt;p&gt;Right now, AI companies are particularly clinging to software development benchmarks as proof of AI assistant capability because progress in other fields is difficult to objectively measure, and it's a domain where LLMs have arguably shown high utility compared to other fields that might suffer from confabulations. But people still use AI chatbots like Claude as general assistants. And given the recent news about troubles with some users going down fantasy rabbit holes with AI chatbots, it's perhaps more notable than usual that Anthropic claims that Claude Sonnet 4.5 shows reduced "sycophancy, deception, power-seeking, and the tendency to encourage delusional thinking" compared to previous models. Sycophancy, in particular, is the tendency for an AI model to praise the user's ideas, even if they are wrong or potentially dangerous.&lt;/p&gt;
&lt;p&gt;We could quibble with how Anthropic frames some of those AI output behaviors through a decidedly anthropomorphic lens, as we have in the past, but overall, attempts to reduce sycophancy are welcome news in a world that has been increasingly turning to chatbots for far more than just coding assistance.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Latest Claude model beats OpenAI and Google on coding tests.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Claude Sonnet 4.5 logo." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/sonnet45-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Claude Sonnet 4.5 logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/sonnet45-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Claude Sonnet 4.5 logo.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Monday, Anthropic released Claude Sonnet 4.5, a new AI language model the company calls its "most capable model to date," with improved coding and computer use capabilities. The company also revealed Claude Code 2.0, a command-line AI agent for developers, and the Claude Agent SDK, which is a tool developers can use to build their own AI coding agents.&lt;/p&gt;
&lt;p&gt;Anthropic says it has witnessed Sonnet 4.5 working continuously on the same project "for more than 30 hours on complex, multi-step tasks," though the company did not provide specific details about the tasks. In the past, agentic models have been known to typically lose coherence over long periods of time as errors accumulate and context windows (a type of short-term&amp;nbsp;memory for the model) fill up. In the past, Anthropic has mentioned that previous Claude 4.0 models have played &lt;em&gt;Pokémon&lt;/em&gt; for over 24 hours or refactored code for seven hours.&lt;/p&gt;
&lt;p&gt;To understand why Sonnet exists, you need to know a bit about how AI language models work. Traditionally, Anthropic has produced three differently sized AI models in the Claude family: Haiku (the smallest), Sonnet (mid-range), and Opus (the largest). Anthropic last updated Haiku in November 2024 (to 3.5), Sonnet this past May (to 4.0), and Opus in August (to 4.1). Model size in parameters, which are values stored in its neural network, is roughly proportional to overall contextual depth (the number of multidimensional connections between concepts, which you might call "knowledge") and better problem-solving capability, but larger models are also slower and more expensive to run. So AI companies always seek a sweet spot in the middle with reasonable performance-cost trade-offs. Claude Sonnet has filled that role for Anthropic quite well for several years now.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119733 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="The intro card for Sonnet 4.5, seen in the Claude web interface on September 29, 2025." class="center large" height="706" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/sonnet_intro-1024x706.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Claude is popular with some software developers thanks to Claude Code, and Anthropic is confident about the latest version of Sonnet's coding capability: "Claude Sonnet 4.5 is the best coding model in the world," the company boasts on its website. "It's the strongest model for building complex agents. It’s the best model at using computers. And it shows substantial gains in reasoning and math."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Anthropic backs up those claims with strong benchmark performance. Sonnet 4.5 model achieved a reported 77.2 percent score on SWE-bench Verified, a benchmark that attempts to measure real-world software coding abilities, and it currently leads the OSWorld benchmark at 61.4 percent, which tests AI models on real-world computer tasks. That beats OpenAI's GPT-5 Codex (which scored 74.5 percent) and Google's Gemini 2.5 Pro (67.2 percent).&lt;/p&gt;
&lt;p&gt;In other testing, Claude Sonnet 4.5 showed gains across multiple other evaluations such as AIME 2024, a mathematics competition benchmark, and MMMLU, which tests subject knowledge across 14 non-English languages. On finance-specific tasks measured by Vals AI's Finance Agent benchmark, which is a relatively new benchmark that "tests the ability of agents to perform tasks expected of an entry-level financial analyst," Sonnet 4.5 scored 92 percent.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119745 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Claude Sonnet 4.5 benchmark results measured and reported by Anthropic." class="center large" height="901" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/2825bb34cb9b9aa1ef347f816c590b5bbdae2b4d-2600x2288-1-1024x901.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Claude Sonnet 4.5 benchmark results measured and reported by Anthropic.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Sonnet 4.5 also reportedly demonstrated improved computer use capabilities compared to its predecessor in testing. Four months ago, Claude Sonnet 4 scored 42.2 percent on OSWorld. The new version increases that score to 61.4 percent. Anthropic uses these capabilities in its Claude for Chrome extension. Similar to OpenAI's ChatGPT Agent. Claude's extension can navigate websites, fill spreadsheets, and complete other browser-based tasks with various degrees of success.&lt;/p&gt;
&lt;p&gt;As always, it's worth noting that AI benchmarks can be gamed easily, poorly designed, or suffer from dataset contamination (a scenario where the model is inadvertently trained on answers in the benchmark). So always take any benchmarks with a grain of salt until they are independently verified. Even with a skeptical eye on the self-reported numbers, it seems that Sonnet 4.5 represents a solid step up from 4.0, and given Anthropic's history of delivering more capable models over time, we have no particular reason to doubt that.&lt;/p&gt;
&lt;p&gt;Simon Willison, a veteran software developer and frequent source of independent expert perspective on AI models for Ars Technica, wrote about Sonnet 4.5 on his blog today. He seems generally impressed: "Anthropic gave me access to a preview version of a 'new model' over the weekend which turned out to be Sonnet 4.5," he wrote. "My initial impressions were that it felt like a better model for code than GPT-5-Codex, which has been my preferred coding model since it launched a few weeks ago. This space moves so fast—Gemini 3 is rumored to land soon so who knows how long Sonnet 4.5 will continue to hold the 'best coding model' crown."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Claude 4.5 is available everywhere today. Through the API, the model maintains the same pricing as Claude Sonnet 4, at $3 per million input tokens and $15 per million output tokens. Developers can access it through the Claude API using "claude-sonnet-4-5" as the model identifier.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Other new features&lt;/h2&gt;
&lt;p&gt;Some ancillary features of the Claude family got some upgrades today, too. For example, Anthropic added code execution and file creation directly within conversations for users of Claude's web interface and dedicated apps. Along those lines, users can now generate spreadsheets, slides, and documents without leaving the chat interface.&lt;/p&gt;
&lt;p&gt;The company also released a five-day research preview called "Imagine with Claude" for Max subscribers, which demonstrates the model generating software in real time. Anthropic describes it as "a fun demonstration showing what Claude Sonnet 4.5 can do" when combined with appropriate infrastructure.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119732 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of the available Anthropic AI models for Claude Max users seen in the Claude web interface on September 29, 2025." class="center large" height="582" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/anthropic_models_9-29-2025-1024x582.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of the available Anthropic AI models for Claude Max users seen in the Claude web interface on September 29, 2025.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;As mentioned above, the command-line development tool Claude Code also received several updates today, alongside the new model. The company added checkpoints that save progress and allow users to roll back to previous states, refreshed the terminal interface, and shipped a native VS Code extension. The Claude API also gains a new context editing feature and memory tool for handling longer-running agent tasks.&lt;/p&gt;
&lt;p&gt;Right now, AI companies are particularly clinging to software development benchmarks as proof of AI assistant capability because progress in other fields is difficult to objectively measure, and it's a domain where LLMs have arguably shown high utility compared to other fields that might suffer from confabulations. But people still use AI chatbots like Claude as general assistants. And given the recent news about troubles with some users going down fantasy rabbit holes with AI chatbots, it's perhaps more notable than usual that Anthropic claims that Claude Sonnet 4.5 shows reduced "sycophancy, deception, power-seeking, and the tendency to encourage delusional thinking" compared to previous models. Sycophancy, in particular, is the tendency for an AI model to praise the user's ideas, even if they are wrong or potentially dangerous.&lt;/p&gt;
&lt;p&gt;We could quibble with how Anthropic frames some of those AI output behaviors through a decidedly anthropomorphic lens, as we have in the past, but overall, attempts to reduce sycophancy are welcome news in a world that has been increasingly turning to chatbots for far more than just coding assistance.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/anthropic-says-its-new-ai-model-maintained-focus-for-30-hours-on-multistep-tasks/</guid><pubDate>Mon, 29 Sep 2025 22:10:27 +0000</pubDate></item></channel></rss>