<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 09 Feb 2026 19:18:14 +0000</lastBuildDate><item><title>Goldman Sachs tests autonomous AI agents for process-heavy work (AI News)</title><link>https://www.artificialintelligence-news.com/news/goldman-sachs-tests-autonomous-ai-agents-for-process-heavy-work/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Goldman-Sachs-tests-autonomous-AI-agents-for-process-heavy-work-scaled-e1770608251794.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Goldman Sachs is pushing deeper into real use of artificial intelligence inside its operations, moving to systems that can carry out complex tasks on their own. The Wall Street bank is working with AI startup Anthropic to create autonomous AI agents powered by Anthropic’s Claude model that can handle work that used to require large teams of people. The bank’s chief information officer says the technology has surprised staff with how capable it can be.&lt;/p&gt;&lt;p&gt;Many companies use AI for tasks like helping employees draft text or analysing trends. But Goldman Sachs is testing AI systems that go into what bankers call back-office work – functions like accounting, compliance checks and onboarding new clients – areas viewed as too complex for automation. Such jobs involve many rules, data and detailed review, and have resisted full automation.&lt;/p&gt;&lt;h3&gt;Moving AI agents into process-heavy operations&lt;/h3&gt;&lt;p&gt;The partnership with Anthropic has been underway for roughly six months, with engineers from the AI startup embedded directly with teams at Goldman Sachs to build these agents side by side with in-house staff, according to a report based on an interview with the bank’s CIO. The work has focused on areas where automation could cut the time it takes to complete repetitive and data-heavy tasks.&lt;/p&gt;&lt;p&gt;Marco Argenti, Goldman’s chief information officer, described the AI systems as a new kind of digital assistant. “Think of it as a digital co-worker for many of the professions in the firm that are scaled, complex and very process-intensive,” he told &lt;em&gt;CNBC&lt;/em&gt;. In early tests, the ability to reason through multi-step work and apply logic to complex areas like accounting and compliance was something the bank had not expected from the model.&lt;/p&gt;&lt;p&gt;Goldman Sachs has been among the more active banks in testing AI tools over the past few years. Before this announcement, the firm deployed internal tools to help engineers write and debug code. But the change now is toward systems that can take on work traditionally done by accountants and compliance teams. That highlights how organisations are trying to find concrete business uses for AI beyond the hype.&lt;/p&gt;&lt;h3&gt;Faster workflows, human oversight remains&lt;/h3&gt;&lt;p&gt;The agents are based on Anthropic’s Claude Opus 4.6 model, which has been built to handle long documents and complex reasoning. Goldman’s tests have shown that such systems can reduce the time needed for tasks like client onboarding, trade reconciliation and document review. While the bank has not shared specific performance numbers, people familiar with the matter told news outlets that work which once took a great deal of human labour can now be done in much less time.&lt;/p&gt;&lt;p&gt;Argenti said the rollout is not about replacing human workers, at least not at this stage. The bank reportedly views the agents as a tool to help existing staff manage busy schedules and get through high volumes of work. In areas like compliance and accounting, jobs can involve repetitive, rule-based steps. AI frees analysts from that repetition so they can focus on higher-value judgement work.&lt;/p&gt;&lt;p&gt;Markets have already reacted to the idea that large institutions are moving toward more AI-driven automation. In recent days, a sell-off in enterprise software stocks wiped out billions in value as some investors worried that tools like autonomous agents could speed up the decline of traditional business software that has dominated corporate IT for years.&lt;/p&gt;&lt;h3&gt;AI adoption meets governance reality&lt;/h3&gt;&lt;p&gt;Industry watchers see Goldman’s move as part of a wider trend. For example, some firms are piloting tools to read large data sets, interpret multiple sources of information, and draft investment analysis. These steps show AI making the jump from isolated projects to operational work. Yet the technology raises questions about oversight and trust. AI systems that interpret financial rules and compliance standards must be monitored carefully to avoid errors that could have regulatory or financial consequences. That’s why many institutions treat these systems as helpers that are reviewed by human experts until they mature.&lt;/p&gt;&lt;p&gt;Goldman Sachs is starting with operational functions that have traditionally resisted automation because they involve a lot of data and formal steps. The bank has not said when it expects deployment of the agents in its operations, but executives have suggested that the initial tests have been promising enough to support further rollout.&lt;/p&gt;&lt;p&gt;The broader industry context shows other banks and financial firms also exploring similar use cases. Some have already invested heavily in AI infrastructure, and reports indicate that major firms are planning to use AI to cut costs, speed workflows and improve risk management. However, many remain cautious about putting AI into customer-facing or regulated functions.&lt;/p&gt;&lt;p&gt;Goldman’s push into autonomous AI agents is an example of how large companies are reshaping internal operations using the latest generation of AI models. If systems can handle complex tasks reliably, organisations could see real changes in how work gets done – particularly in back-office functions where volume and repetition keep costs high and innovation slow.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Louis Droege)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Intuit, Uber, and State Farm trial AI agents inside enterprise workflows&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Goldman-Sachs-tests-autonomous-AI-agents-for-process-heavy-work-scaled-e1770608251794.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Goldman Sachs is pushing deeper into real use of artificial intelligence inside its operations, moving to systems that can carry out complex tasks on their own. The Wall Street bank is working with AI startup Anthropic to create autonomous AI agents powered by Anthropic’s Claude model that can handle work that used to require large teams of people. The bank’s chief information officer says the technology has surprised staff with how capable it can be.&lt;/p&gt;&lt;p&gt;Many companies use AI for tasks like helping employees draft text or analysing trends. But Goldman Sachs is testing AI systems that go into what bankers call back-office work – functions like accounting, compliance checks and onboarding new clients – areas viewed as too complex for automation. Such jobs involve many rules, data and detailed review, and have resisted full automation.&lt;/p&gt;&lt;h3&gt;Moving AI agents into process-heavy operations&lt;/h3&gt;&lt;p&gt;The partnership with Anthropic has been underway for roughly six months, with engineers from the AI startup embedded directly with teams at Goldman Sachs to build these agents side by side with in-house staff, according to a report based on an interview with the bank’s CIO. The work has focused on areas where automation could cut the time it takes to complete repetitive and data-heavy tasks.&lt;/p&gt;&lt;p&gt;Marco Argenti, Goldman’s chief information officer, described the AI systems as a new kind of digital assistant. “Think of it as a digital co-worker for many of the professions in the firm that are scaled, complex and very process-intensive,” he told &lt;em&gt;CNBC&lt;/em&gt;. In early tests, the ability to reason through multi-step work and apply logic to complex areas like accounting and compliance was something the bank had not expected from the model.&lt;/p&gt;&lt;p&gt;Goldman Sachs has been among the more active banks in testing AI tools over the past few years. Before this announcement, the firm deployed internal tools to help engineers write and debug code. But the change now is toward systems that can take on work traditionally done by accountants and compliance teams. That highlights how organisations are trying to find concrete business uses for AI beyond the hype.&lt;/p&gt;&lt;h3&gt;Faster workflows, human oversight remains&lt;/h3&gt;&lt;p&gt;The agents are based on Anthropic’s Claude Opus 4.6 model, which has been built to handle long documents and complex reasoning. Goldman’s tests have shown that such systems can reduce the time needed for tasks like client onboarding, trade reconciliation and document review. While the bank has not shared specific performance numbers, people familiar with the matter told news outlets that work which once took a great deal of human labour can now be done in much less time.&lt;/p&gt;&lt;p&gt;Argenti said the rollout is not about replacing human workers, at least not at this stage. The bank reportedly views the agents as a tool to help existing staff manage busy schedules and get through high volumes of work. In areas like compliance and accounting, jobs can involve repetitive, rule-based steps. AI frees analysts from that repetition so they can focus on higher-value judgement work.&lt;/p&gt;&lt;p&gt;Markets have already reacted to the idea that large institutions are moving toward more AI-driven automation. In recent days, a sell-off in enterprise software stocks wiped out billions in value as some investors worried that tools like autonomous agents could speed up the decline of traditional business software that has dominated corporate IT for years.&lt;/p&gt;&lt;h3&gt;AI adoption meets governance reality&lt;/h3&gt;&lt;p&gt;Industry watchers see Goldman’s move as part of a wider trend. For example, some firms are piloting tools to read large data sets, interpret multiple sources of information, and draft investment analysis. These steps show AI making the jump from isolated projects to operational work. Yet the technology raises questions about oversight and trust. AI systems that interpret financial rules and compliance standards must be monitored carefully to avoid errors that could have regulatory or financial consequences. That’s why many institutions treat these systems as helpers that are reviewed by human experts until they mature.&lt;/p&gt;&lt;p&gt;Goldman Sachs is starting with operational functions that have traditionally resisted automation because they involve a lot of data and formal steps. The bank has not said when it expects deployment of the agents in its operations, but executives have suggested that the initial tests have been promising enough to support further rollout.&lt;/p&gt;&lt;p&gt;The broader industry context shows other banks and financial firms also exploring similar use cases. Some have already invested heavily in AI infrastructure, and reports indicate that major firms are planning to use AI to cut costs, speed workflows and improve risk management. However, many remain cautious about putting AI into customer-facing or regulated functions.&lt;/p&gt;&lt;p&gt;Goldman’s push into autonomous AI agents is an example of how large companies are reshaping internal operations using the latest generation of AI models. If systems can handle complex tasks reliably, organisations could see real changes in how work gets done – particularly in back-office functions where volume and repetition keep costs high and innovation slow.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Louis Droege)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Intuit, Uber, and State Farm trial AI agents inside enterprise workflows&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/goldman-sachs-tests-autonomous-ai-agents-for-process-heavy-work/</guid><pubDate>Mon, 09 Feb 2026 10:00:00 +0000</pubDate></item><item><title>Cryptocurrency markets a testbed for AI forecasting models (AI News)</title><link>https://www.artificialintelligence-news.com/news/cryptocurrency-markets-a-testbed-for-ai-forecasting-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Picture1.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Cryptocurrency markets have become a high-speed playground where developers optimise the next generation of predictive software. Using real-time data flows and decentralised platforms, scientists develop prediction models that can extend the scope of traditional finance.&lt;/p&gt;&lt;p&gt;The digital asset landscape offers an unparalleled environment for machine learning. When you track cryptocurrency prices today, you are observing a system shaped simultaneously by on-chain transactions, global sentiment signals, and macroeconomic inputs, all of which generate dense datasets suited for advanced neural networks.&lt;/p&gt;&lt;p&gt;Such a steady trickle of information makes it possible to assess and reapply an algorithm without interference from fixed trading times or restrictive market access.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-evolution-of-neural-networks-in-forecasting"&gt;The evolution of neural networks in forecasting&lt;/h3&gt;&lt;p&gt;Current machine learning technology, particularly the “Long Short-Term Memory” neuronal network, has found widespread application in interpreting market behaviour. A recurrent neural network, like an LSTM, can recognise long-term market patterns and is far more flexible than traditional analytical techniques in fluctuating markets.&lt;/p&gt;&lt;p&gt;The research on hybrid models that combine LSTMs with attention mechanisms has really improved techniques for extracting important signals from market noise. Compared to previous models that used linear techniques, these models analyse not only structured price data but also unstructured data.&lt;/p&gt;&lt;p&gt;With the inclusion of Natural Language Processing, it is now possible to interpret the flow of news and social media activity, enabling sentiment measurement. While prediction was previously based on historical stock pricing patterns, it now increasingly depends on behavioural changes in global participant networks.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-high-frequency-environment-for-model-validation"&gt;A High-Frequency Environment for Model Validation&lt;/h3&gt;&lt;p&gt;The transparency of blockchain data offers a level of data granularity that is not found in existing financial infrastructures. Each transaction is now an input that can be traced, enabling cause-and-effect analysis without delay.&lt;/p&gt;&lt;p&gt;However, the growing presence of autonomous AI agents has changed how such data is used. This is because specialised platforms are being developed to support decentralised processing in a variety of networks.&lt;/p&gt;&lt;p&gt;This has effectively turned blockchain ecosystems into real-time validation environments, where the feedback loop between data ingestion and model refinement occurs almost instantly.&lt;/p&gt;&lt;p&gt;Researchers use this setting to test specific abilities:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Real-time anomaly detection: Systems compare live transaction flows against simulated historical conditions to identify irregular liquidity behaviour before broader disruptions emerge.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Macro sentiment mapping: Global social behaviour data are compared to on-chain activity to assess true market psychology.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Autonomous risk adjustment: Programmes run probabilistic simulations to rebalance exposure dynamically as volatility thresholds are crossed.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Predictive on-chain monitoring: AI tracks wallet activity to anticipate liquidity shifts before they impact centralised trading venues.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These systems really do not function as isolated instruments. Instead, they adjust dynamically, continually changing their parameters in response to emerging market conditions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-synergy-of-depin-and-computational-power"&gt;The synergy of DePIN and computational power&lt;/h3&gt;&lt;p&gt;To train complex predictive models, large amounts of computing power are required, leading to the development of Decentralised Physical Infrastructure Networks (DePIN). By using decentralised GPU capacity on a global computing grid, less dependence on cloud infrastructure can be achieved.&lt;/p&gt;&lt;p&gt;Consequently, smaller-scale research teams are afforded computational power that was previously beyond their budgets. This makes it easier and faster to run experiments in different model designs.&lt;/p&gt;&lt;p&gt;This trend is also echoed in the markets. A report dated January 2025 noted strong growth in the capitalisation of assets related to artificial intelligence agents in the latter half of 2024, as demand for such intelligence infrastructure increased.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-from-reactive-bots-to-anticipatory-agents"&gt;From reactive bots to anticipatory agents&lt;/h3&gt;&lt;p&gt;The market is moving beyond rule-based trading bots toward proactive AI agents. Instead of responding to predefined triggers, modern systems evaluate probability distributions to anticipate directional changes.&lt;/p&gt;&lt;p&gt;Gradient boosting and Bayesian learning methods allow the identification of areas where mean reversion may occur ahead of strong corrections.&lt;/p&gt;&lt;p&gt;Some models now incorporate fractal analysis to detect recurring structures in timeframes, further improving adaptability in rapidly-changing conditions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-addressing-model-risk-and-infrastructure-constraints"&gt;Addressing model risk and infrastructure constraints&lt;/h3&gt;&lt;p&gt;Despite such rapid progress, several problems remain. Problems identified include hallucinations in models, in which patterns found in a model do not belong to the patterns that cause them. Methods to mitigate this problem have been adopted by those applying this technology, including ‘explainable AI’.&lt;/p&gt;&lt;p&gt;The other vital requirement that has remained unaltered with the evolution in AI technology is scalability. With the growing number of interactions among autonomous agents, it is imperative that the underlying transactions efficiently manage the rising volume without latency or data loss.&lt;/p&gt;&lt;p&gt;At the end of 2024, the most optimal scaling solution handled tens of millions of transactions per day in an area that required improvement.&lt;/p&gt;&lt;p&gt;Such an agile framework lays the foundation for the future, where data, intelligence and validation will come together in a strong ecosystem that facilitates more reliable projections, better governance and greater confidence in AI-driven insights.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Picture1.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Cryptocurrency markets have become a high-speed playground where developers optimise the next generation of predictive software. Using real-time data flows and decentralised platforms, scientists develop prediction models that can extend the scope of traditional finance.&lt;/p&gt;&lt;p&gt;The digital asset landscape offers an unparalleled environment for machine learning. When you track cryptocurrency prices today, you are observing a system shaped simultaneously by on-chain transactions, global sentiment signals, and macroeconomic inputs, all of which generate dense datasets suited for advanced neural networks.&lt;/p&gt;&lt;p&gt;Such a steady trickle of information makes it possible to assess and reapply an algorithm without interference from fixed trading times or restrictive market access.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-evolution-of-neural-networks-in-forecasting"&gt;The evolution of neural networks in forecasting&lt;/h3&gt;&lt;p&gt;Current machine learning technology, particularly the “Long Short-Term Memory” neuronal network, has found widespread application in interpreting market behaviour. A recurrent neural network, like an LSTM, can recognise long-term market patterns and is far more flexible than traditional analytical techniques in fluctuating markets.&lt;/p&gt;&lt;p&gt;The research on hybrid models that combine LSTMs with attention mechanisms has really improved techniques for extracting important signals from market noise. Compared to previous models that used linear techniques, these models analyse not only structured price data but also unstructured data.&lt;/p&gt;&lt;p&gt;With the inclusion of Natural Language Processing, it is now possible to interpret the flow of news and social media activity, enabling sentiment measurement. While prediction was previously based on historical stock pricing patterns, it now increasingly depends on behavioural changes in global participant networks.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-high-frequency-environment-for-model-validation"&gt;A High-Frequency Environment for Model Validation&lt;/h3&gt;&lt;p&gt;The transparency of blockchain data offers a level of data granularity that is not found in existing financial infrastructures. Each transaction is now an input that can be traced, enabling cause-and-effect analysis without delay.&lt;/p&gt;&lt;p&gt;However, the growing presence of autonomous AI agents has changed how such data is used. This is because specialised platforms are being developed to support decentralised processing in a variety of networks.&lt;/p&gt;&lt;p&gt;This has effectively turned blockchain ecosystems into real-time validation environments, where the feedback loop between data ingestion and model refinement occurs almost instantly.&lt;/p&gt;&lt;p&gt;Researchers use this setting to test specific abilities:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Real-time anomaly detection: Systems compare live transaction flows against simulated historical conditions to identify irregular liquidity behaviour before broader disruptions emerge.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Macro sentiment mapping: Global social behaviour data are compared to on-chain activity to assess true market psychology.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Autonomous risk adjustment: Programmes run probabilistic simulations to rebalance exposure dynamically as volatility thresholds are crossed.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Predictive on-chain monitoring: AI tracks wallet activity to anticipate liquidity shifts before they impact centralised trading venues.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These systems really do not function as isolated instruments. Instead, they adjust dynamically, continually changing their parameters in response to emerging market conditions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-synergy-of-depin-and-computational-power"&gt;The synergy of DePIN and computational power&lt;/h3&gt;&lt;p&gt;To train complex predictive models, large amounts of computing power are required, leading to the development of Decentralised Physical Infrastructure Networks (DePIN). By using decentralised GPU capacity on a global computing grid, less dependence on cloud infrastructure can be achieved.&lt;/p&gt;&lt;p&gt;Consequently, smaller-scale research teams are afforded computational power that was previously beyond their budgets. This makes it easier and faster to run experiments in different model designs.&lt;/p&gt;&lt;p&gt;This trend is also echoed in the markets. A report dated January 2025 noted strong growth in the capitalisation of assets related to artificial intelligence agents in the latter half of 2024, as demand for such intelligence infrastructure increased.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-from-reactive-bots-to-anticipatory-agents"&gt;From reactive bots to anticipatory agents&lt;/h3&gt;&lt;p&gt;The market is moving beyond rule-based trading bots toward proactive AI agents. Instead of responding to predefined triggers, modern systems evaluate probability distributions to anticipate directional changes.&lt;/p&gt;&lt;p&gt;Gradient boosting and Bayesian learning methods allow the identification of areas where mean reversion may occur ahead of strong corrections.&lt;/p&gt;&lt;p&gt;Some models now incorporate fractal analysis to detect recurring structures in timeframes, further improving adaptability in rapidly-changing conditions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-addressing-model-risk-and-infrastructure-constraints"&gt;Addressing model risk and infrastructure constraints&lt;/h3&gt;&lt;p&gt;Despite such rapid progress, several problems remain. Problems identified include hallucinations in models, in which patterns found in a model do not belong to the patterns that cause them. Methods to mitigate this problem have been adopted by those applying this technology, including ‘explainable AI’.&lt;/p&gt;&lt;p&gt;The other vital requirement that has remained unaltered with the evolution in AI technology is scalability. With the growing number of interactions among autonomous agents, it is imperative that the underlying transactions efficiently manage the rising volume without latency or data loss.&lt;/p&gt;&lt;p&gt;At the end of 2024, the most optimal scaling solution handled tens of millions of transactions per day in an area that required improvement.&lt;/p&gt;&lt;p&gt;Such an agile framework lays the foundation for the future, where data, intelligence and validation will come together in a strong ecosystem that facilitates more reliable projections, better governance and greater confidence in AI-driven insights.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/cryptocurrency-markets-a-testbed-for-ai-forecasting-models/</guid><pubDate>Mon, 09 Feb 2026 10:30:39 +0000</pubDate></item><item><title>Exclusive: Why are Chinese AI models dominating open-source as Western labs step back? (AI News)</title><link>https://www.artificialintelligence-news.com/news/chinese-ai-models-175k-unprotected-systems-western-retreat/</link><description>&lt;p&gt;Because Western AI labs&amp;nbsp;won’t—or&amp;nbsp;can’t—anymore. As OpenAI, Anthropic, and Google face mounting pressure to restrict their most powerful models, Chinese developers have filled the open-source void with AI explicitly built for what operators need: powerful models that run on commodity hardware.&lt;/p&gt;&lt;p&gt;A new security&amp;nbsp;study&amp;nbsp;reveals just how thoroughly Chinese AI has captured this space.&amp;nbsp;Research published by SentinelOne and Censys,&amp;nbsp;mapping&amp;nbsp;175,000 exposed AI hosts across 130 countries over 293 days, shows&amp;nbsp;Alibaba’s&amp;nbsp;Qwen2 consistently&amp;nbsp;ranking&amp;nbsp;second only&amp;nbsp;to&amp;nbsp;Meta’s&amp;nbsp;Llama in global deployment.&amp;nbsp;More tellingly, the Chinese model appears on 52% of systems running multiple AI models—suggesting&amp;nbsp;it’s&amp;nbsp;become the de facto alternative to Llama.&lt;/p&gt;&lt;p&gt;“Over the next 12–18 months, we expect Chinese-origin model families to play an increasingly central role in the open-source LLM ecosystem, particularly as Western frontier labs slow or constrain open-weight releases,”&amp;nbsp;Gabriel Bernadett-Shapiro, distinguished AI research scientist at SentinelOne, told TechForge&amp;nbsp;Media’s&amp;nbsp;&lt;em&gt;AI News&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;The finding arrives as OpenAI, Anthropic, and Google face regulatory scrutiny, safety review overhead, and commercial incentives pushing them toward API-gated releases rather than publishing model weights&amp;nbsp;freely.&amp;nbsp;The contrast with Chinese developers&amp;nbsp;couldn’t&amp;nbsp;be sharper.&lt;/p&gt;&lt;p&gt;Chinese labs have demonstrated what Bernadett-Shapiro calls&amp;nbsp;“a willingness to publish large, high-quality weights that&amp;nbsp;are explicitly optimised&amp;nbsp;for local deployment, quantisation, and commodity hardware.”&lt;/p&gt;&lt;p&gt;“In practice, this makes them easier to adopt, easier to run, and easier to integrate into edge and residential environments,”&amp;nbsp;he added.&lt;/p&gt;&lt;p&gt;Put simply: if&amp;nbsp;you’re&amp;nbsp;a researcher or developer wanting to run powerful AI on your own computer without a massive budget, Chinese models like Qwen2 are often your best—or only—option.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-pragmatics-not-ideology"&gt;Pragmatics, not ideology&lt;/h3&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112062" height="719" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Silent_Brothers_Chart_01-12-2026_03-scaled.jpg-1024x719.avif" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Alibaba’s Qwen2 consistently ranks second only to Meta’s Llama across 175,000 exposed hosts globally. Source: SentinelOne/Censys&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The research shows this dominance&amp;nbsp;isn’t&amp;nbsp;accidental. Qwen2 maintains what Bernadett-Shapiro calls&amp;nbsp;“zero rank volatility”—it holds the number two position across every measurement method the researchers examined: total observations, unique hosts, and host-days.&amp;nbsp;There’s&amp;nbsp;no fluctuation, no regional variation, just consistent global adoption.&lt;/p&gt;&lt;p&gt;The co-deployment pattern is equally revealing. When operators run multiple AI models on the same system—a common practice for comparison or workload segmentation—the pairing of Llama and Qwen2 appears on 40,694 hosts, representing 52% of all multi-family deployments.&lt;/p&gt;&lt;p&gt;Geographic concentration reinforces the picture. In China, Beijing alone accounts for 30% of exposed hosts, with Shanghai and Guangdong&amp;nbsp;adding another&amp;nbsp;21% combined.&amp;nbsp;In the United States, Virginia—reflecting AWS infrastructure&amp;nbsp;density—represents 18% of hosts.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112061" height="719" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Silent_Brothers_Chart_01-12-2026_02-scaled.jpg-1024x719.avif" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;China and the US dominate exposed Ollama host distribution, with Beijing accounting for 30% of Chinese deployments. Source: SentinelOne/Censys&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;“If release velocity, openness, and hardware portability continue to diverge between regions, Chinese model lineages are likely to become the default for open deployments, not because of ideology, but because of availability and pragmatics,”&amp;nbsp;Bernadett-Shapiro explained.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-governance-problem"&gt;The governance problem&lt;/h3&gt;&lt;p&gt;This shift creates what Bernadett-Shapiro characterises as a&amp;nbsp;“governance inversion”—a fundamental reversal of how AI risk and accountability&amp;nbsp;are distributed.&lt;/p&gt;&lt;p&gt;In platform-hosted services like ChatGPT, one company controls everything: the infrastructure, monitors usage, implements safety controls, and can shut down&amp;nbsp;abuse. With open-weight models, the control evaporates. Accountability diffuses across thousands of networks in 130 countries, while dependency concentrates upstream in a handful of model suppliers—increasingly Chinese ones.&lt;/p&gt;&lt;p&gt;The 175,000 exposed hosts operate entirely outside the control systems governing commercial AI platforms.&amp;nbsp;There’s&amp;nbsp;no centralised authentication, no rate limiting, no abuse detection, and critically, no kill switch if misuse is detected.&lt;/p&gt;&lt;p&gt;“Once an open-weight model is released, it is trivial to remove safety or security training,”&amp;nbsp;Bernadett-Shapiro noted.”Frontier labs need to treat open-weight releases as long-lived infrastructure artefacts.”&lt;/p&gt;&lt;p&gt;A persistent backbone of 23,000 hosts&amp;nbsp;showing 87%&amp;nbsp;average uptime drives the majority of activity.&amp;nbsp;These&amp;nbsp;aren’t&amp;nbsp;hobbyist experiments—they’re&amp;nbsp;operational systems providing ongoing utility, often running multiple models simultaneously.&lt;/p&gt;&lt;p&gt;Perhaps most concerning:&amp;nbsp;between 16% and 19% of the infrastructure&amp;nbsp;couldn’t&amp;nbsp;be attributed to any identifiable owner.”Even if we are able to prove that&amp;nbsp;a model was leveraged&amp;nbsp;in an attack, there are not well-established abuse reporting routes,”&amp;nbsp;Bernadett-Shapiro said.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-security-without-guardrails"&gt;Security without guardrails&lt;/h3&gt;&lt;p&gt;Nearly half (48%) of exposed hosts advertise&amp;nbsp;“tool-calling capabilities”—meaning&amp;nbsp;they’re&amp;nbsp;not just generating text. They can execute code, access APIs, and interact with external systems autonomously.&lt;/p&gt;&lt;p&gt;“A&amp;nbsp;text-only model can generate harmful content, but a tool-calling model can act,”&amp;nbsp;Bernadett-Shapiro explained.&amp;nbsp;“On an unauthenticated server, an attacker&amp;nbsp;doesn’t&amp;nbsp;need malware or credentials; they just need a prompt.”&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112064" height="719" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Silent_Brothers_Chart_01-12-2026_01-scaled.jpg-1024x719.avif" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Nearly half of exposed Ollama hosts have tool-calling capabilities that can execute code and access external systems. Source: SentinelOne/Censys&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The highest-risk scenario involves what he calls&amp;nbsp;“exposed, tool-enabled RAG or automation endpoints being driven remotely as an execution layer.”&amp;nbsp;An attacker could&amp;nbsp;simply&amp;nbsp;ask the model to summarise internal documents, extract API keys from code repositories, or call downstream services the model&amp;nbsp;is configured&amp;nbsp;to access.&lt;/p&gt;&lt;p&gt;When paired with&amp;nbsp;“thinking”&amp;nbsp;models optimised for multi-step reasoning—present on 26% of hosts—the system can plan complex operations autonomously. The researchers identified at least 201 hosts running&amp;nbsp;“uncensored”&amp;nbsp;configurations that explicitly remove safety guardrails, though Bernadett-Shapiro notes this represents a lower bound.&lt;/p&gt;&lt;p&gt;In other words, these&amp;nbsp;aren’t&amp;nbsp;just chatbots—they’re&amp;nbsp;AI systems that can take action, and half of them have no password protection.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-frontier-labs-should-do"&gt;What frontier labs should do&lt;/h3&gt;&lt;p&gt;For Western AI developers concerned about maintaining influence over the&amp;nbsp;technology’s&amp;nbsp;trajectory, Bernadett-Shapiro recommends a different approach to model releases.&lt;/p&gt;&lt;p&gt;“Frontier labs&amp;nbsp;can’t&amp;nbsp;control deployment, but they can shape the risks that they release into the world,”&amp;nbsp;he said. That includes&amp;nbsp;“investing in post-release monitoring of ecosystem-level adoption and misuse patterns”&amp;nbsp;rather than treating releases as one-off research outputs.&lt;/p&gt;&lt;p&gt;The current governance model assumes centralised deployment with diffuse upstream supply—the exact opposite of&amp;nbsp;what’s&amp;nbsp;actually happening.&amp;nbsp;“When a small number of lineages dominate&amp;nbsp;what’s&amp;nbsp;runnable on commodity hardware, upstream decisions get amplified everywhere,”&amp;nbsp;he explained.&amp;nbsp;“Governance strategies must acknowledge that inversion.”&lt;/p&gt;&lt;p&gt;But acknowledgement requires visibility. Currently, most labs releasing open-weight models have no systematic way to track how&amp;nbsp;they’re&amp;nbsp;being used, where&amp;nbsp;they’re&amp;nbsp;deployed, or whether safety training remains intact after quantisation and fine-tuning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-12-18-month-outlook"&gt;The 12-18 month outlook&lt;/h3&gt;&lt;p&gt;Bernadett-Shapiro expects the exposed layer to&amp;nbsp;“persist and professionalise”&amp;nbsp;as tool use, agents, and multimodal inputs become default capabilities rather than exceptions.&amp;nbsp;The transient edge will&amp;nbsp;keep churning&amp;nbsp;as hobbyists experiment, but the backbone will&amp;nbsp;grow&amp;nbsp;more stable, more capable, and&amp;nbsp;handle&amp;nbsp;more sensitive data.&lt;/p&gt;&lt;p&gt;Enforcement will remain uneven because residential and small VPS deployments&amp;nbsp;don’t&amp;nbsp;map to existing governance controls.&amp;nbsp;“This&amp;nbsp;isn’t&amp;nbsp;a misconfiguration problem,”&amp;nbsp;he emphasised.&amp;nbsp;“We are observing the early formation of a public, unmanaged AI compute substrate. There is no central switch to flip.”&lt;/p&gt;&lt;p&gt;The geopolitical dimension adds urgency.&amp;nbsp;“When most of the&amp;nbsp;world’s&amp;nbsp;unmanaged AI compute depends on models released by a handful of non-Western labs, traditional assumptions about influence, coordination, and post-release response become weaker,”&amp;nbsp;Bernadett-Shapiro said.&lt;/p&gt;&lt;p&gt;For Western developers and policymakers, the implication is stark:&amp;nbsp;“Even perfect governance of their own platforms has limited impact on the real-world risk surface if the dominant capabilities live elsewhere and propagate through open, decentralised infrastructure.”&lt;/p&gt;&lt;p&gt;The open-source AI ecosystem is globalising, but its centre of gravity is shifting decisively eastward. Not&amp;nbsp;through any coordinated strategy, but through the practical economics of&amp;nbsp;who’s&amp;nbsp;willing to publish what researchers and operators actually need to run AI locally.&lt;/p&gt;&lt;p&gt;The 175,000 exposed hosts mapped in this study are just the visible surface of that fundamental realignment—one that Western policymakers are only beginning to recognise, let alone address.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Huawei details open-source AI development roadmap at Huawei Connect 2025&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111908" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Because Western AI labs&amp;nbsp;won’t—or&amp;nbsp;can’t—anymore. As OpenAI, Anthropic, and Google face mounting pressure to restrict their most powerful models, Chinese developers have filled the open-source void with AI explicitly built for what operators need: powerful models that run on commodity hardware.&lt;/p&gt;&lt;p&gt;A new security&amp;nbsp;study&amp;nbsp;reveals just how thoroughly Chinese AI has captured this space.&amp;nbsp;Research published by SentinelOne and Censys,&amp;nbsp;mapping&amp;nbsp;175,000 exposed AI hosts across 130 countries over 293 days, shows&amp;nbsp;Alibaba’s&amp;nbsp;Qwen2 consistently&amp;nbsp;ranking&amp;nbsp;second only&amp;nbsp;to&amp;nbsp;Meta’s&amp;nbsp;Llama in global deployment.&amp;nbsp;More tellingly, the Chinese model appears on 52% of systems running multiple AI models—suggesting&amp;nbsp;it’s&amp;nbsp;become the de facto alternative to Llama.&lt;/p&gt;&lt;p&gt;“Over the next 12–18 months, we expect Chinese-origin model families to play an increasingly central role in the open-source LLM ecosystem, particularly as Western frontier labs slow or constrain open-weight releases,”&amp;nbsp;Gabriel Bernadett-Shapiro, distinguished AI research scientist at SentinelOne, told TechForge&amp;nbsp;Media’s&amp;nbsp;&lt;em&gt;AI News&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;The finding arrives as OpenAI, Anthropic, and Google face regulatory scrutiny, safety review overhead, and commercial incentives pushing them toward API-gated releases rather than publishing model weights&amp;nbsp;freely.&amp;nbsp;The contrast with Chinese developers&amp;nbsp;couldn’t&amp;nbsp;be sharper.&lt;/p&gt;&lt;p&gt;Chinese labs have demonstrated what Bernadett-Shapiro calls&amp;nbsp;“a willingness to publish large, high-quality weights that&amp;nbsp;are explicitly optimised&amp;nbsp;for local deployment, quantisation, and commodity hardware.”&lt;/p&gt;&lt;p&gt;“In practice, this makes them easier to adopt, easier to run, and easier to integrate into edge and residential environments,”&amp;nbsp;he added.&lt;/p&gt;&lt;p&gt;Put simply: if&amp;nbsp;you’re&amp;nbsp;a researcher or developer wanting to run powerful AI on your own computer without a massive budget, Chinese models like Qwen2 are often your best—or only—option.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-pragmatics-not-ideology"&gt;Pragmatics, not ideology&lt;/h3&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112062" height="719" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Silent_Brothers_Chart_01-12-2026_03-scaled.jpg-1024x719.avif" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Alibaba’s Qwen2 consistently ranks second only to Meta’s Llama across 175,000 exposed hosts globally. Source: SentinelOne/Censys&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The research shows this dominance&amp;nbsp;isn’t&amp;nbsp;accidental. Qwen2 maintains what Bernadett-Shapiro calls&amp;nbsp;“zero rank volatility”—it holds the number two position across every measurement method the researchers examined: total observations, unique hosts, and host-days.&amp;nbsp;There’s&amp;nbsp;no fluctuation, no regional variation, just consistent global adoption.&lt;/p&gt;&lt;p&gt;The co-deployment pattern is equally revealing. When operators run multiple AI models on the same system—a common practice for comparison or workload segmentation—the pairing of Llama and Qwen2 appears on 40,694 hosts, representing 52% of all multi-family deployments.&lt;/p&gt;&lt;p&gt;Geographic concentration reinforces the picture. In China, Beijing alone accounts for 30% of exposed hosts, with Shanghai and Guangdong&amp;nbsp;adding another&amp;nbsp;21% combined.&amp;nbsp;In the United States, Virginia—reflecting AWS infrastructure&amp;nbsp;density—represents 18% of hosts.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112061" height="719" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Silent_Brothers_Chart_01-12-2026_02-scaled.jpg-1024x719.avif" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;China and the US dominate exposed Ollama host distribution, with Beijing accounting for 30% of Chinese deployments. Source: SentinelOne/Censys&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;“If release velocity, openness, and hardware portability continue to diverge between regions, Chinese model lineages are likely to become the default for open deployments, not because of ideology, but because of availability and pragmatics,”&amp;nbsp;Bernadett-Shapiro explained.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-governance-problem"&gt;The governance problem&lt;/h3&gt;&lt;p&gt;This shift creates what Bernadett-Shapiro characterises as a&amp;nbsp;“governance inversion”—a fundamental reversal of how AI risk and accountability&amp;nbsp;are distributed.&lt;/p&gt;&lt;p&gt;In platform-hosted services like ChatGPT, one company controls everything: the infrastructure, monitors usage, implements safety controls, and can shut down&amp;nbsp;abuse. With open-weight models, the control evaporates. Accountability diffuses across thousands of networks in 130 countries, while dependency concentrates upstream in a handful of model suppliers—increasingly Chinese ones.&lt;/p&gt;&lt;p&gt;The 175,000 exposed hosts operate entirely outside the control systems governing commercial AI platforms.&amp;nbsp;There’s&amp;nbsp;no centralised authentication, no rate limiting, no abuse detection, and critically, no kill switch if misuse is detected.&lt;/p&gt;&lt;p&gt;“Once an open-weight model is released, it is trivial to remove safety or security training,”&amp;nbsp;Bernadett-Shapiro noted.”Frontier labs need to treat open-weight releases as long-lived infrastructure artefacts.”&lt;/p&gt;&lt;p&gt;A persistent backbone of 23,000 hosts&amp;nbsp;showing 87%&amp;nbsp;average uptime drives the majority of activity.&amp;nbsp;These&amp;nbsp;aren’t&amp;nbsp;hobbyist experiments—they’re&amp;nbsp;operational systems providing ongoing utility, often running multiple models simultaneously.&lt;/p&gt;&lt;p&gt;Perhaps most concerning:&amp;nbsp;between 16% and 19% of the infrastructure&amp;nbsp;couldn’t&amp;nbsp;be attributed to any identifiable owner.”Even if we are able to prove that&amp;nbsp;a model was leveraged&amp;nbsp;in an attack, there are not well-established abuse reporting routes,”&amp;nbsp;Bernadett-Shapiro said.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-security-without-guardrails"&gt;Security without guardrails&lt;/h3&gt;&lt;p&gt;Nearly half (48%) of exposed hosts advertise&amp;nbsp;“tool-calling capabilities”—meaning&amp;nbsp;they’re&amp;nbsp;not just generating text. They can execute code, access APIs, and interact with external systems autonomously.&lt;/p&gt;&lt;p&gt;“A&amp;nbsp;text-only model can generate harmful content, but a tool-calling model can act,”&amp;nbsp;Bernadett-Shapiro explained.&amp;nbsp;“On an unauthenticated server, an attacker&amp;nbsp;doesn’t&amp;nbsp;need malware or credentials; they just need a prompt.”&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-112064" height="719" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/Silent_Brothers_Chart_01-12-2026_01-scaled.jpg-1024x719.avif" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Nearly half of exposed Ollama hosts have tool-calling capabilities that can execute code and access external systems. Source: SentinelOne/Censys&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The highest-risk scenario involves what he calls&amp;nbsp;“exposed, tool-enabled RAG or automation endpoints being driven remotely as an execution layer.”&amp;nbsp;An attacker could&amp;nbsp;simply&amp;nbsp;ask the model to summarise internal documents, extract API keys from code repositories, or call downstream services the model&amp;nbsp;is configured&amp;nbsp;to access.&lt;/p&gt;&lt;p&gt;When paired with&amp;nbsp;“thinking”&amp;nbsp;models optimised for multi-step reasoning—present on 26% of hosts—the system can plan complex operations autonomously. The researchers identified at least 201 hosts running&amp;nbsp;“uncensored”&amp;nbsp;configurations that explicitly remove safety guardrails, though Bernadett-Shapiro notes this represents a lower bound.&lt;/p&gt;&lt;p&gt;In other words, these&amp;nbsp;aren’t&amp;nbsp;just chatbots—they’re&amp;nbsp;AI systems that can take action, and half of them have no password protection.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-frontier-labs-should-do"&gt;What frontier labs should do&lt;/h3&gt;&lt;p&gt;For Western AI developers concerned about maintaining influence over the&amp;nbsp;technology’s&amp;nbsp;trajectory, Bernadett-Shapiro recommends a different approach to model releases.&lt;/p&gt;&lt;p&gt;“Frontier labs&amp;nbsp;can’t&amp;nbsp;control deployment, but they can shape the risks that they release into the world,”&amp;nbsp;he said. That includes&amp;nbsp;“investing in post-release monitoring of ecosystem-level adoption and misuse patterns”&amp;nbsp;rather than treating releases as one-off research outputs.&lt;/p&gt;&lt;p&gt;The current governance model assumes centralised deployment with diffuse upstream supply—the exact opposite of&amp;nbsp;what’s&amp;nbsp;actually happening.&amp;nbsp;“When a small number of lineages dominate&amp;nbsp;what’s&amp;nbsp;runnable on commodity hardware, upstream decisions get amplified everywhere,”&amp;nbsp;he explained.&amp;nbsp;“Governance strategies must acknowledge that inversion.”&lt;/p&gt;&lt;p&gt;But acknowledgement requires visibility. Currently, most labs releasing open-weight models have no systematic way to track how&amp;nbsp;they’re&amp;nbsp;being used, where&amp;nbsp;they’re&amp;nbsp;deployed, or whether safety training remains intact after quantisation and fine-tuning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-12-18-month-outlook"&gt;The 12-18 month outlook&lt;/h3&gt;&lt;p&gt;Bernadett-Shapiro expects the exposed layer to&amp;nbsp;“persist and professionalise”&amp;nbsp;as tool use, agents, and multimodal inputs become default capabilities rather than exceptions.&amp;nbsp;The transient edge will&amp;nbsp;keep churning&amp;nbsp;as hobbyists experiment, but the backbone will&amp;nbsp;grow&amp;nbsp;more stable, more capable, and&amp;nbsp;handle&amp;nbsp;more sensitive data.&lt;/p&gt;&lt;p&gt;Enforcement will remain uneven because residential and small VPS deployments&amp;nbsp;don’t&amp;nbsp;map to existing governance controls.&amp;nbsp;“This&amp;nbsp;isn’t&amp;nbsp;a misconfiguration problem,”&amp;nbsp;he emphasised.&amp;nbsp;“We are observing the early formation of a public, unmanaged AI compute substrate. There is no central switch to flip.”&lt;/p&gt;&lt;p&gt;The geopolitical dimension adds urgency.&amp;nbsp;“When most of the&amp;nbsp;world’s&amp;nbsp;unmanaged AI compute depends on models released by a handful of non-Western labs, traditional assumptions about influence, coordination, and post-release response become weaker,”&amp;nbsp;Bernadett-Shapiro said.&lt;/p&gt;&lt;p&gt;For Western developers and policymakers, the implication is stark:&amp;nbsp;“Even perfect governance of their own platforms has limited impact on the real-world risk surface if the dominant capabilities live elsewhere and propagate through open, decentralised infrastructure.”&lt;/p&gt;&lt;p&gt;The open-source AI ecosystem is globalising, but its centre of gravity is shifting decisively eastward. Not&amp;nbsp;through any coordinated strategy, but through the practical economics of&amp;nbsp;who’s&amp;nbsp;willing to publish what researchers and operators actually need to run AI locally.&lt;/p&gt;&lt;p&gt;The 175,000 exposed hosts mapped in this study are just the visible surface of that fundamental realignment—one that Western policymakers are only beginning to recognise, let alone address.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Huawei details open-source AI development roadmap at Huawei Connect 2025&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111908" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/chinese-ai-models-175k-unprotected-systems-western-retreat/</guid><pubDate>Mon, 09 Feb 2026 11:00:00 +0000</pubDate></item><item><title>What AI can (and can’t) tell us about XRP in ETF-driven markets (AI News)</title><link>https://www.artificialintelligence-news.com/news/what-ai-can-and-cant-tell-us-about-xrp-in-etf-driven-markets/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/steve-johnson-_0iV9LmPDn0-unsplash-5-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;For a long time, cryptocurrency prices moved quickly. A headline would hit, sentiment would spike, and charts would react almost immediately. That pattern no longer holds. Today’s market is slow, heavier than before, and shaped by forces that do not always announce themselves clearly. Capital allocation, ETF mechanics, and macro positioning now influence price behaviour in ways that are easy to overlook if you only watch short-term moves.&lt;/p&gt;&lt;p&gt;That change becomes obvious when you look at XRP. The XRP price today reflects decisions made by institutions, fund managers, and regulators as much as it reflects trading activity. AI tools are used increasingly to track such inputs – but they are often misunderstood. They do not predict outcomes. They organise complexity.&lt;/p&gt;&lt;p&gt;Understanding that distinction changes how you read the market.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-ai-reads-an-etf-driven-market"&gt;How AI reads an ETF-driven market&lt;/h3&gt;&lt;p&gt;AI systems do not look for narratives, but for relationships. In cryptocurrency markets, that means mapping ETF inflows and outflows against derivatives positioning, on-chain activity, and movements in traditional assets. What has changed recently is how much weight those signals now carry.&lt;/p&gt;&lt;p&gt;Binance Research has reported that altcoin ETFs have recorded more than US$2 billion in net inflows, with XRP and Solana leading that activity. Bitcoin and Ethereum spot ETFs have seen sustained outflows since October. This is not a classic risk-on environment. It is selective, cautious and uneven.&lt;/p&gt;&lt;p&gt;AI models are good at identifying such behaviour, detecting rotation not momentum. They highlight where capital is reallocating even when prices remain range-bound. This is why markets can appear quiet while meaningful positioning takes place underneath.&lt;/p&gt;&lt;p&gt;AI only shows the movement, yet doesn’t explain the reasons behind it.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-ai-can-tell-you-about-xrp"&gt;What AI can tell you about XRP&lt;/h3&gt;&lt;p&gt;XRP does not always move in step with the rest of the market. When conditions change, its price often reacts to access, regulation, and liquidity before sentiment catches up. That pattern has shown up more than once, and it is one reason AI systems tend to weigh fund flows and market depth more heavily than short-term mood shifts when analysing XRP.&lt;/p&gt;&lt;p&gt;Binance Research has pointed to early 2026 as a period where liquidity is coming back without a clear return to risk-taking. Capital has rotated away from crowded trades, but it has not rushed to replace them. AI picks up on that imbalance quickly. It helps explain why XRP has seen ETF interest even while broader momentum in cryptocurrency has felt restrained.&lt;/p&gt;&lt;p&gt;That does not imply a forecast. It is closer to a snapshot of conditions. Market conversations may slow, headlines may thin out, and price can drift, yet positioning continues to evolve in the background. This is easy to miss if you focus only on visible activity.&lt;/p&gt;&lt;p&gt;AI is useful here because it stays indifferent to attention. Instead of responding to engagement spikes or sudden narrative shifts, it tracks what investors are actually doing. In markets where perception often moves ahead of reality, that distinction matters more than it first appears.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-where-ai-constantly-falls-short"&gt;Where AI constantly falls short&lt;/h3&gt;&lt;p&gt;For all its analytical power, AI has blind spots. Regulation is one of the most important. Models are trained on historical relationships, while regulatory decisions rarely follow historical patterns.&lt;/p&gt;&lt;p&gt;Richard Teng, Co-CEO of Binance, addressed this challenge after the exchange secured its ADGM license in January 2026. “The ADGM license crowns years of work to meet some of the world’s most demanding regulatory standards, and arriving in days of the moment we crossed 300 million registered users shows that scale and trust need not be in tension.” Developments like this can alter market confidence quickly, yet they are difficult to quantify before they happen.&lt;/p&gt;&lt;p&gt;AI responds well once regulatory outcomes are known. It struggles beforehand. For XRP, where regulatory clarity has played a central role in past price behaviour, this limitation is significant.&lt;/p&gt;&lt;p&gt;Another weakness is intent. AI can measure flows, but it cannot explain why investors choose caution, delay, or restraint. Defensive positioning does not always look dramatic in data, but it can shape markets for long periods.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-human-judgement-still-shapes-the-outcome"&gt;Why human judgement still shapes the outcome&lt;/h3&gt;&lt;p&gt;AI does not replace interpretation but supports it. Binance Research has described current conditions as a phase of liquidity preservation, with markets waiting for clearer catalysts like macro data releases and policy signals. AI can flag these moments of tension. It cannot tell you whether they will resolve into action or extend into stagnation.&lt;/p&gt;&lt;p&gt;Rachel Conlan, CMO of Binance, reflected on the broader maturity of the industry when discussing Binance Blockchain Week Dubai 2025. She described a market that is more focused on building than spectacle. That mindset applies equally to AI use. The goal is not prediction. It is informed judgement.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-this-means-when-you-look-at-price"&gt;What this means when you look at price&lt;/h3&gt;&lt;p&gt;When used properly, AI helps see forces that are easy to miss, especially in ETF-driven conditions. It highlights where liquidity is moving, where narratives fail to align with behaviour, and where patience may be a rational choice.&lt;/p&gt;&lt;p&gt;What it cannot do is remove uncertainty. In markets shaped by regulation, macro shifts, and institutional decision-making, judgement still matters. The clearest insight comes from combining machine analysis with human context.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/steve-johnson-_0iV9LmPDn0-unsplash-5-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;For a long time, cryptocurrency prices moved quickly. A headline would hit, sentiment would spike, and charts would react almost immediately. That pattern no longer holds. Today’s market is slow, heavier than before, and shaped by forces that do not always announce themselves clearly. Capital allocation, ETF mechanics, and macro positioning now influence price behaviour in ways that are easy to overlook if you only watch short-term moves.&lt;/p&gt;&lt;p&gt;That change becomes obvious when you look at XRP. The XRP price today reflects decisions made by institutions, fund managers, and regulators as much as it reflects trading activity. AI tools are used increasingly to track such inputs – but they are often misunderstood. They do not predict outcomes. They organise complexity.&lt;/p&gt;&lt;p&gt;Understanding that distinction changes how you read the market.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-ai-reads-an-etf-driven-market"&gt;How AI reads an ETF-driven market&lt;/h3&gt;&lt;p&gt;AI systems do not look for narratives, but for relationships. In cryptocurrency markets, that means mapping ETF inflows and outflows against derivatives positioning, on-chain activity, and movements in traditional assets. What has changed recently is how much weight those signals now carry.&lt;/p&gt;&lt;p&gt;Binance Research has reported that altcoin ETFs have recorded more than US$2 billion in net inflows, with XRP and Solana leading that activity. Bitcoin and Ethereum spot ETFs have seen sustained outflows since October. This is not a classic risk-on environment. It is selective, cautious and uneven.&lt;/p&gt;&lt;p&gt;AI models are good at identifying such behaviour, detecting rotation not momentum. They highlight where capital is reallocating even when prices remain range-bound. This is why markets can appear quiet while meaningful positioning takes place underneath.&lt;/p&gt;&lt;p&gt;AI only shows the movement, yet doesn’t explain the reasons behind it.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-ai-can-tell-you-about-xrp"&gt;What AI can tell you about XRP&lt;/h3&gt;&lt;p&gt;XRP does not always move in step with the rest of the market. When conditions change, its price often reacts to access, regulation, and liquidity before sentiment catches up. That pattern has shown up more than once, and it is one reason AI systems tend to weigh fund flows and market depth more heavily than short-term mood shifts when analysing XRP.&lt;/p&gt;&lt;p&gt;Binance Research has pointed to early 2026 as a period where liquidity is coming back without a clear return to risk-taking. Capital has rotated away from crowded trades, but it has not rushed to replace them. AI picks up on that imbalance quickly. It helps explain why XRP has seen ETF interest even while broader momentum in cryptocurrency has felt restrained.&lt;/p&gt;&lt;p&gt;That does not imply a forecast. It is closer to a snapshot of conditions. Market conversations may slow, headlines may thin out, and price can drift, yet positioning continues to evolve in the background. This is easy to miss if you focus only on visible activity.&lt;/p&gt;&lt;p&gt;AI is useful here because it stays indifferent to attention. Instead of responding to engagement spikes or sudden narrative shifts, it tracks what investors are actually doing. In markets where perception often moves ahead of reality, that distinction matters more than it first appears.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-where-ai-constantly-falls-short"&gt;Where AI constantly falls short&lt;/h3&gt;&lt;p&gt;For all its analytical power, AI has blind spots. Regulation is one of the most important. Models are trained on historical relationships, while regulatory decisions rarely follow historical patterns.&lt;/p&gt;&lt;p&gt;Richard Teng, Co-CEO of Binance, addressed this challenge after the exchange secured its ADGM license in January 2026. “The ADGM license crowns years of work to meet some of the world’s most demanding regulatory standards, and arriving in days of the moment we crossed 300 million registered users shows that scale and trust need not be in tension.” Developments like this can alter market confidence quickly, yet they are difficult to quantify before they happen.&lt;/p&gt;&lt;p&gt;AI responds well once regulatory outcomes are known. It struggles beforehand. For XRP, where regulatory clarity has played a central role in past price behaviour, this limitation is significant.&lt;/p&gt;&lt;p&gt;Another weakness is intent. AI can measure flows, but it cannot explain why investors choose caution, delay, or restraint. Defensive positioning does not always look dramatic in data, but it can shape markets for long periods.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-human-judgement-still-shapes-the-outcome"&gt;Why human judgement still shapes the outcome&lt;/h3&gt;&lt;p&gt;AI does not replace interpretation but supports it. Binance Research has described current conditions as a phase of liquidity preservation, with markets waiting for clearer catalysts like macro data releases and policy signals. AI can flag these moments of tension. It cannot tell you whether they will resolve into action or extend into stagnation.&lt;/p&gt;&lt;p&gt;Rachel Conlan, CMO of Binance, reflected on the broader maturity of the industry when discussing Binance Blockchain Week Dubai 2025. She described a market that is more focused on building than spectacle. That mindset applies equally to AI use. The goal is not prediction. It is informed judgement.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-this-means-when-you-look-at-price"&gt;What this means when you look at price&lt;/h3&gt;&lt;p&gt;When used properly, AI helps see forces that are easy to miss, especially in ETF-driven conditions. It highlights where liquidity is moving, where narratives fail to align with behaviour, and where patience may be a rational choice.&lt;/p&gt;&lt;p&gt;What it cannot do is remove uncertainty. In markets shaped by regulation, macro shifts, and institutional decision-making, judgement still matters. The clearest insight comes from combining machine analysis with human context.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/what-ai-can-and-cant-tell-us-about-xrp-in-etf-driven-markets/</guid><pubDate>Mon, 09 Feb 2026 11:04:32 +0000</pubDate></item><item><title>Making AI Work, MIT Technology Review’s new AI newsletter, is here (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/09/1132462/ai-newsletter-professional-applications/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT-TR-Making-AI-Work-Email-2-C.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For years, our newsroom has explored AI’s limitations and potential dangers, as well as its growing energy needs. And our reporters have looked closely at how generative tools are being used for tasks such as coding and running scientific experiments.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But how is AI &lt;em&gt;actually&lt;/em&gt; being used in fields like health care, climate tech, education, and finance? How are small businesses using it? And what should you keep in mind if you use AI tools at work?&amp;nbsp;These questions guided the creation of Making AI Work, a new AI mini-course newsletter. &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;Sign up for Making AI Work&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;to see weekly case studies exploring tools and tips for AI implementation. The limited-run newsletter will deliver practical, industry-specific guidance on how generative AI is being used and deployed across sectors and what professionals need to know to apply it in their everyday work. The goal is to help working professionals more clearly see how AI is actually being used today, and what that looks like in practice—including new challenges it presents.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;You can sign up at any time and you’ll receive seven editions, delivered once per week, until you complete the series.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Each newsletter begins with a case study, examining a specific use case of AI in a given industry. Then we’ll take a deeper look at the AI tool being used, with more context about how other companies or sectors are employing that same tool or system. Finally, we’ll end with action-oriented tips to help you apply the tool.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Here’s a closer look at what we’ll cover:&lt;br /&gt;&lt;/p&gt; 
 &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 1: How AI is changing health care&amp;nbsp;&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Explore the future of medical note-taking by learning about the Microsoft Copilot tool used by doctors at Vanderbilt University Medical Center.&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 2: How AI could power up the nuclear industry&amp;nbsp;&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Dig into an experiment between Google and the nuclear giant Westinghouse to see if AI can help build nuclear reactors more efficiently.&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 3: How to encourage smarter AI use in the classroom&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Visit a private high school in Connecticut and meet a technology coordinator who will get you up to speed on MagicSchool, an AI-powered platform for educators.&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 4: How small businesses can leverage AI&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Hear from an independent tutor on how he’s outsourcing basic administrative tasks to Notion AI.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 5: How AI is helping financial firms make better investments&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Learn more about the ways financial firms are using large language models like ChatGPT Enterprise to supercharge their research operations.&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 6: How to use AI yourself&amp;nbsp;&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;We’ll share some insights from the staff of &lt;em&gt;MIT Technology Review&lt;/em&gt; about how you might use AI tools powered by LLMs in your own life and work.&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 7: 5 ways people are getting AI right&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;The series ends with an on-demand virtual event featuring expert guests exploring what AI adoptions are working, and why. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;If you’re not quite ready to jump into Making AI Work, then check out Intro to AI, &lt;em&gt;MIT Technology Review&lt;/em&gt;’s first AI newsletter mini-course, which serves as a beginner’s guide to artificial intelligence. Readers will learn the basics of what AI is, how it’s used, what the current regulatory landscape looks like, and more. &lt;strong&gt;Sign up to receive Intro to AI for free.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Our hope is that Making AI Work will help you understand how AI can, well, work for you. &lt;strong&gt;Sign up for Making AI Work to learn how LLMs are being put to work across industries.&amp;nbsp;&lt;/strong&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT-TR-Making-AI-Work-Email-2-C.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For years, our newsroom has explored AI’s limitations and potential dangers, as well as its growing energy needs. And our reporters have looked closely at how generative tools are being used for tasks such as coding and running scientific experiments.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But how is AI &lt;em&gt;actually&lt;/em&gt; being used in fields like health care, climate tech, education, and finance? How are small businesses using it? And what should you keep in mind if you use AI tools at work?&amp;nbsp;These questions guided the creation of Making AI Work, a new AI mini-course newsletter. &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;Sign up for Making AI Work&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;to see weekly case studies exploring tools and tips for AI implementation. The limited-run newsletter will deliver practical, industry-specific guidance on how generative AI is being used and deployed across sectors and what professionals need to know to apply it in their everyday work. The goal is to help working professionals more clearly see how AI is actually being used today, and what that looks like in practice—including new challenges it presents.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;You can sign up at any time and you’ll receive seven editions, delivered once per week, until you complete the series.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Each newsletter begins with a case study, examining a specific use case of AI in a given industry. Then we’ll take a deeper look at the AI tool being used, with more context about how other companies or sectors are employing that same tool or system. Finally, we’ll end with action-oriented tips to help you apply the tool.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Here’s a closer look at what we’ll cover:&lt;br /&gt;&lt;/p&gt; 
 &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 1: How AI is changing health care&amp;nbsp;&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Explore the future of medical note-taking by learning about the Microsoft Copilot tool used by doctors at Vanderbilt University Medical Center.&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 2: How AI could power up the nuclear industry&amp;nbsp;&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Dig into an experiment between Google and the nuclear giant Westinghouse to see if AI can help build nuclear reactors more efficiently.&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 3: How to encourage smarter AI use in the classroom&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Visit a private high school in Connecticut and meet a technology coordinator who will get you up to speed on MagicSchool, an AI-powered platform for educators.&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 4: How small businesses can leverage AI&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Hear from an independent tutor on how he’s outsourcing basic administrative tasks to Notion AI.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 5: How AI is helping financial firms make better investments&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;Learn more about the ways financial firms are using large language models like ChatGPT Enterprise to supercharge their research operations.&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 6: How to use AI yourself&amp;nbsp;&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;We’ll share some insights from the staff of &lt;em&gt;MIT Technology Review&lt;/em&gt; about how you might use AI tools powered by LLMs in your own life and work.&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Week 7: 5 ways people are getting AI right&lt;/strong&gt;&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;The series ends with an on-demand virtual event featuring expert guests exploring what AI adoptions are working, and why. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;If you’re not quite ready to jump into Making AI Work, then check out Intro to AI, &lt;em&gt;MIT Technology Review&lt;/em&gt;’s first AI newsletter mini-course, which serves as a beginner’s guide to artificial intelligence. Readers will learn the basics of what AI is, how it’s used, what the current regulatory landscape looks like, and more. &lt;strong&gt;Sign up to receive Intro to AI for free.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Our hope is that Making AI Work will help you understand how AI can, well, work for you. &lt;strong&gt;Sign up for Making AI Work to learn how LLMs are being put to work across industries.&amp;nbsp;&lt;/strong&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/09/1132462/ai-newsletter-professional-applications/</guid><pubDate>Mon, 09 Feb 2026 11:30:00 +0000</pubDate></item><item><title>The Download: what Moltbook tells us about AI hype, and the rise and rise of AI therapy (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/09/1132498/the-download-what-moltbook-tells-us-about-ai-hype-and-the-rise-and-rise-of-ai-therapy/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Moltbook was peak AI theater&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;For a few days recently, the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website’s tagline puts it: “Where AI agents share, discuss, and upvote. Humans welcome to observe.”&lt;/p&gt;  &lt;p&gt;We observed! Launched on January 28, Moltbook went viral in a matter of hours. It’s been designed as a place where instances of a free open-source LLM-powered agent known as OpenClaw (formerly known as ClawdBot, then Moltbot), could come together and do whatever they wanted.&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;But is Moltbook really a glimpse of the future, as many have claimed? Or something else entirely? Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The ascent of the AI therapist&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We’re in the midst of a global mental-­health crisis. More than a billion people worldwide suffer from a mental-health condition, according to the World Health Organization. The prevalence of anxiety and depression is growing in many demographics, particularly young people, and suicide is claiming hundreds of thousands of lives globally each year.&lt;/p&gt;&lt;p&gt;Given the clear demand for accessible and affordable mental-health services, it’s no wonder that people have looked to artificial intelligence for possible relief. Millions are already actively seeking therapy from popular chatbots, or from specialized psychology apps like Wysa and Woebot.&lt;/p&gt;&lt;p&gt;Four timely new books are a reminder that while the present feels like a blur of breakthroughs, scandals, and confusion, this disorienting time is rooted in deeper histories of care, technology, and trust.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Becky Ferreira&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the &lt;/strong&gt;&lt;strong&gt;most recent print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazin&lt;/strong&gt;&lt;strong&gt;e, which shines a light on the exciting innovations happening right now. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Making AI Work, MIT Technology Review’s new AI newsletter, is here&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;For years, our newsroom has explored AI’s limitations and potential dangers, as well as its growing energy needs. And our reporters have looked closely at how generative tools are being used for tasks such as coding and running scientific experiments.&lt;/p&gt;&lt;p&gt;But how is AI &lt;em&gt;actually&lt;/em&gt; being used in fields like health care, climate tech, education, and finance? How are small businesses using it? And what should you keep in mind if you use AI tools at work? These questions guided the creation of Making AI Work, a new AI mini-course newsletter. Read more about it, and sign up here to receive the seven editions straight to your inbox.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 The US is failing to punish polluters&lt;/strong&gt;&lt;br /&gt;The number of civil lawsuits it’s pursuing has sharply dropped in comparison to Trump’s first term. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;Rising GDP = greater carbon emissions. But does it have to? &lt;/em&gt;(The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The European Union has warned Meta against blocking rival AI assistants&lt;br /&gt;&lt;/strong&gt;It’s the latest example of Brussels’ attempts to rein in Big Tech. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 AI ads took over the Super Bowl&lt;/strong&gt;&lt;br /&gt;Hyping up chatbots and taking swipes at their competitors. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;They appeared to be trying to win over AI naysayers, too. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;Celebrities were out in force to flog AI wares. &lt;/em&gt;(Slate $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 &lt;strong&gt;China wants to completely dominate the humanoid robot industry&lt;/strong&gt;&lt;br /&gt;Local governments and banks are only too happy to oblige promising startups. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Why the humanoid workforce is running late. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 We’re witnessing the first real crypto crash&lt;br /&gt;Cryptocurrency is now fully part of the financial system, for better or worse. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;Wall Street’s grasp of AI is pretty shaky too. &lt;/em&gt;(Semafor)&lt;br /&gt;+ &lt;em&gt;Even traditionally safe markets are looking pretty volatile right now. &lt;/em&gt;(Economist $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 The man who coined vibe coding has a new fixation&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;“Agentic engineering” is the next big thing, apparently. (Insider $)&lt;br /&gt;+ &lt;em&gt;Agentic AI is the talk of the town right now. &lt;/em&gt;(The Information $)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 AI running app Runna has adjusted its aggressive training plans &lt;/strong&gt;&lt;strong&gt;🏃‍♂️&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;Runners had long suspected its suggestions were pushing them towards injury. (WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 San Francisco’s march for billionaires was a flop&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Only around three dozen supporters turned up. (SF Chronicle)&lt;br /&gt;+ &lt;em&gt;Predictably, journalists nearly outnumbered the demonstrators. &lt;/em&gt;(TechCrunch)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 AI is shaking up romance novels ❤️&lt;/strong&gt;&lt;br /&gt;But models still aren’t great at writing sex scenes. (NYT $)&lt;br /&gt;+ &lt;em&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 ChatGPT won’t be replacing human stylists any time soon&lt;/strong&gt;&lt;br /&gt;Its menswear suggestions are more manosphere influencer than suave gentleman. (GQ)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“There is no Plan B, because that assumes you will fail. We’re going to do the start-up thing until we die.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—William Alexander, an ambitious 21-year old AI worker, explains his and his cohort’s attitudes towards trying to make it big in the highly-competitive industry to the New York Times.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1132502" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_14d65b.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The open-source AI boom is built on Big Tech’s handouts. How long will it last?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In May 2023 a leaked memo reported to have been written by Luke Sernau, a senior engineer at Google, said out loud what many in Silicon Valley must have been whispering for weeks: an open-source free-for-all is threatening Big Tech’s grip on AI.&lt;/p&gt;  &lt;p&gt;In many ways, that’s a good thing. AI won't thrive if just a few mega-rich companies get to gatekeep this technology or decide how it is used. But this open-source boom is precarious, and if Big Tech decides to shut up shop, a boomtown could become a backwater. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Dark showering, anyone?&lt;br /&gt;+ Chef Yujia Hu is renowned for his shoe-shaped sushi designs.&lt;br /&gt;+ Meanwhile, in the depths of the South Atlantic Ocean: a giant phantom jelly has been spotted.&lt;br /&gt;+ I have nothing but respect for this X account dedicated to documenting rats and mice in movies and TV 🐀🐁&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Moltbook was peak AI theater&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;For a few days recently, the hottest new hangout on the internet was a vibe-coded Reddit clone called Moltbook, which billed itself as a social network for bots. As the website’s tagline puts it: “Where AI agents share, discuss, and upvote. Humans welcome to observe.”&lt;/p&gt;  &lt;p&gt;We observed! Launched on January 28, Moltbook went viral in a matter of hours. It’s been designed as a place where instances of a free open-source LLM-powered agent known as OpenClaw (formerly known as ClawdBot, then Moltbot), could come together and do whatever they wanted.&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;But is Moltbook really a glimpse of the future, as many have claimed? Or something else entirely? Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The ascent of the AI therapist&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;We’re in the midst of a global mental-­health crisis. More than a billion people worldwide suffer from a mental-health condition, according to the World Health Organization. The prevalence of anxiety and depression is growing in many demographics, particularly young people, and suicide is claiming hundreds of thousands of lives globally each year.&lt;/p&gt;&lt;p&gt;Given the clear demand for accessible and affordable mental-health services, it’s no wonder that people have looked to artificial intelligence for possible relief. Millions are already actively seeking therapy from popular chatbots, or from specialized psychology apps like Wysa and Woebot.&lt;/p&gt;&lt;p&gt;Four timely new books are a reminder that while the present feels like a blur of breakthroughs, scandals, and confusion, this disorienting time is rooted in deeper histories of care, technology, and trust.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Becky Ferreira&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the &lt;/strong&gt;&lt;strong&gt;most recent print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazin&lt;/strong&gt;&lt;strong&gt;e, which shines a light on the exciting innovations happening right now. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Making AI Work, MIT Technology Review’s new AI newsletter, is here&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;For years, our newsroom has explored AI’s limitations and potential dangers, as well as its growing energy needs. And our reporters have looked closely at how generative tools are being used for tasks such as coding and running scientific experiments.&lt;/p&gt;&lt;p&gt;But how is AI &lt;em&gt;actually&lt;/em&gt; being used in fields like health care, climate tech, education, and finance? How are small businesses using it? And what should you keep in mind if you use AI tools at work? These questions guided the creation of Making AI Work, a new AI mini-course newsletter. Read more about it, and sign up here to receive the seven editions straight to your inbox.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 The US is failing to punish polluters&lt;/strong&gt;&lt;br /&gt;The number of civil lawsuits it’s pursuing has sharply dropped in comparison to Trump’s first term. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;Rising GDP = greater carbon emissions. But does it have to? &lt;/em&gt;(The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The European Union has warned Meta against blocking rival AI assistants&lt;br /&gt;&lt;/strong&gt;It’s the latest example of Brussels’ attempts to rein in Big Tech. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 AI ads took over the Super Bowl&lt;/strong&gt;&lt;br /&gt;Hyping up chatbots and taking swipes at their competitors. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;They appeared to be trying to win over AI naysayers, too. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;Celebrities were out in force to flog AI wares. &lt;/em&gt;(Slate $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 &lt;strong&gt;China wants to completely dominate the humanoid robot industry&lt;/strong&gt;&lt;br /&gt;Local governments and banks are only too happy to oblige promising startups. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Why the humanoid workforce is running late. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 We’re witnessing the first real crypto crash&lt;br /&gt;Cryptocurrency is now fully part of the financial system, for better or worse. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;Wall Street’s grasp of AI is pretty shaky too. &lt;/em&gt;(Semafor)&lt;br /&gt;+ &lt;em&gt;Even traditionally safe markets are looking pretty volatile right now. &lt;/em&gt;(Economist $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 The man who coined vibe coding has a new fixation&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;“Agentic engineering” is the next big thing, apparently. (Insider $)&lt;br /&gt;+ &lt;em&gt;Agentic AI is the talk of the town right now. &lt;/em&gt;(The Information $)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 AI running app Runna has adjusted its aggressive training plans &lt;/strong&gt;&lt;strong&gt;🏃‍♂️&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;Runners had long suspected its suggestions were pushing them towards injury. (WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 San Francisco’s march for billionaires was a flop&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Only around three dozen supporters turned up. (SF Chronicle)&lt;br /&gt;+ &lt;em&gt;Predictably, journalists nearly outnumbered the demonstrators. &lt;/em&gt;(TechCrunch)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 AI is shaking up romance novels ❤️&lt;/strong&gt;&lt;br /&gt;But models still aren’t great at writing sex scenes. (NYT $)&lt;br /&gt;+ &lt;em&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 ChatGPT won’t be replacing human stylists any time soon&lt;/strong&gt;&lt;br /&gt;Its menswear suggestions are more manosphere influencer than suave gentleman. (GQ)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“There is no Plan B, because that assumes you will fail. We’re going to do the start-up thing until we die.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—William Alexander, an ambitious 21-year old AI worker, explains his and his cohort’s attitudes towards trying to make it big in the highly-competitive industry to the New York Times.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1132502" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_14d65b.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;The open-source AI boom is built on Big Tech’s handouts. How long will it last?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In May 2023 a leaked memo reported to have been written by Luke Sernau, a senior engineer at Google, said out loud what many in Silicon Valley must have been whispering for weeks: an open-source free-for-all is threatening Big Tech’s grip on AI.&lt;/p&gt;  &lt;p&gt;In many ways, that’s a good thing. AI won't thrive if just a few mega-rich companies get to gatekeep this technology or decide how it is used. But this open-source boom is precarious, and if Big Tech decides to shut up shop, a boomtown could become a backwater. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Will Douglas Heaven&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Dark showering, anyone?&lt;br /&gt;+ Chef Yujia Hu is renowned for his shoe-shaped sushi designs.&lt;br /&gt;+ Meanwhile, in the depths of the South Atlantic Ocean: a giant phantom jelly has been spotted.&lt;br /&gt;+ I have nothing but respect for this X account dedicated to documenting rats and mice in movies and TV 🐀🐁&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/09/1132498/the-download-what-moltbook-tells-us-about-ai-hype-and-the-rise-and-rise-of-ai-therapy/</guid><pubDate>Mon, 09 Feb 2026 13:10:00 +0000</pubDate></item><item><title>[NEW] Call for speakers: TechCrunch Founder Summit 2026 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/call-for-speakers-techcrunch-founder-summit-2026/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Have real-world scaling experience? The&amp;nbsp;&lt;strong&gt;TechCrunch Founder Summit 2026&lt;/strong&gt;&amp;nbsp;stage is calling.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On&amp;nbsp;&lt;strong&gt;June 23 in Boston&lt;/strong&gt;, this annual founder-focused event will&amp;nbsp;bring together&amp;nbsp;1,100+ founders and investors to explore the realities of scaling startups across every stage.&amp;nbsp;We’re&amp;nbsp;seeking experienced founders, VCs, and startup operators to lead interactive roundtable discussions rooted in practical, real-world insight.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Experienced leaders from across the startup ecosystem will convene to host&amp;nbsp;interactive roundtable sessions&amp;nbsp;designed to spark real conversations. This is where founders get honest guidance, tactical takeaways, and clarity on the challenges that come with growth.&amp;nbsp;&lt;strong&gt;Apply here to get started.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-apply-to-lead-a-roundtable-session"&gt;Apply to lead a roundtable session&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Roundtables at TC Founder Summit are built for depth, not decks. Each session is a&amp;nbsp;30-minute, informal discussion&amp;nbsp;led by up to two speakers, with no slides or video — just meaningful dialogue and practical insight. These intimate conversations create space for founders to ask real questions and connect directly with experts&amp;nbsp;who’ve&amp;nbsp;been there before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To apply, click&amp;nbsp;&lt;strong&gt;Apply to Speak&lt;/strong&gt;&amp;nbsp;on the&amp;nbsp;&lt;strong&gt;event page&lt;/strong&gt;,&amp;nbsp;submit&amp;nbsp;your proposed topic, and share your experience as a scaling expert.&amp;nbsp;TC&amp;nbsp;Founder Summit is the ideal platform to contribute to the next generation of startup leaders.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 roundtable sessions" class="wp-image-2966337" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/Early-Stage-Roundtable-Sessions-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-speaker-benefits"&gt;Speaker benefits&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking at TC Founder Summit is more than visibility.&amp;nbsp;It’s&amp;nbsp;full access to the experience. Along with elevating your authority and brand,&amp;nbsp;you’ll&amp;nbsp;gain premium entry to breakout sessions, roundtables, and curated networking with founders seeking guidance and VCs scouting&amp;nbsp;what’s&amp;nbsp;next.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, TechCrunch will amplify your participation through:&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Event agenda placement on the web and mobile app.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Inclusion in a shared TechCrunch.com article.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Social media promotion across TechCrunch channels.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-make-your-impact-by-applying-today"&gt;Make your impact by applying today&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Lead the conversation. Share what&amp;nbsp;you’ve&amp;nbsp;learned. Help founders navigate the highs and lows of&amp;nbsp;scaling, and&amp;nbsp;strengthen your reputation as a trusted voice in the startup community.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apply early.&amp;nbsp;TC&amp;nbsp;Founder Summit takes place on June 23, but speaker applications close well before then.&amp;nbsp;&lt;strong&gt;Submit now&lt;/strong&gt;&amp;nbsp;and be part of TechCrunch’s annual founder bootcamp.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Founder Summit breakout audience" class="wp-image-3086922" height="453" src="https://techcrunch.com/wp-content/uploads/2026/01/TC-All-Stage-2025-Breakout-QA.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Have real-world scaling experience? The&amp;nbsp;&lt;strong&gt;TechCrunch Founder Summit 2026&lt;/strong&gt;&amp;nbsp;stage is calling.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On&amp;nbsp;&lt;strong&gt;June 23 in Boston&lt;/strong&gt;, this annual founder-focused event will&amp;nbsp;bring together&amp;nbsp;1,100+ founders and investors to explore the realities of scaling startups across every stage.&amp;nbsp;We’re&amp;nbsp;seeking experienced founders, VCs, and startup operators to lead interactive roundtable discussions rooted in practical, real-world insight.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Experienced leaders from across the startup ecosystem will convene to host&amp;nbsp;interactive roundtable sessions&amp;nbsp;designed to spark real conversations. This is where founders get honest guidance, tactical takeaways, and clarity on the challenges that come with growth.&amp;nbsp;&lt;strong&gt;Apply here to get started.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-apply-to-lead-a-roundtable-session"&gt;Apply to lead a roundtable session&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Roundtables at TC Founder Summit are built for depth, not decks. Each session is a&amp;nbsp;30-minute, informal discussion&amp;nbsp;led by up to two speakers, with no slides or video — just meaningful dialogue and practical insight. These intimate conversations create space for founders to ask real questions and connect directly with experts&amp;nbsp;who’ve&amp;nbsp;been there before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To apply, click&amp;nbsp;&lt;strong&gt;Apply to Speak&lt;/strong&gt;&amp;nbsp;on the&amp;nbsp;&lt;strong&gt;event page&lt;/strong&gt;,&amp;nbsp;submit&amp;nbsp;your proposed topic, and share your experience as a scaling expert.&amp;nbsp;TC&amp;nbsp;Founder Summit is the ideal platform to contribute to the next generation of startup leaders.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 roundtable sessions" class="wp-image-2966337" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/Early-Stage-Roundtable-Sessions-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-speaker-benefits"&gt;Speaker benefits&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking at TC Founder Summit is more than visibility.&amp;nbsp;It’s&amp;nbsp;full access to the experience. Along with elevating your authority and brand,&amp;nbsp;you’ll&amp;nbsp;gain premium entry to breakout sessions, roundtables, and curated networking with founders seeking guidance and VCs scouting&amp;nbsp;what’s&amp;nbsp;next.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, TechCrunch will amplify your participation through:&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Event agenda placement on the web and mobile app.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Inclusion in a shared TechCrunch.com article.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Social media promotion across TechCrunch channels.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-make-your-impact-by-applying-today"&gt;Make your impact by applying today&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Lead the conversation. Share what&amp;nbsp;you’ve&amp;nbsp;learned. Help founders navigate the highs and lows of&amp;nbsp;scaling, and&amp;nbsp;strengthen your reputation as a trusted voice in the startup community.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apply early.&amp;nbsp;TC&amp;nbsp;Founder Summit takes place on June 23, but speaker applications close well before then.&amp;nbsp;&lt;strong&gt;Submit now&lt;/strong&gt;&amp;nbsp;and be part of TechCrunch’s annual founder bootcamp.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Founder Summit breakout audience" class="wp-image-3086922" height="453" src="https://techcrunch.com/wp-content/uploads/2026/01/TC-All-Stage-2025-Breakout-QA.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/call-for-speakers-techcrunch-founder-summit-2026/</guid><pubDate>Mon, 09 Feb 2026 15:00:00 +0000</pubDate></item><item><title>[NEW] Ex-Googlers are building infrastructure to help companies understand their video data (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/ex-googlers-are-building-infrastructure-to-help-companies-understand-their-video-data/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Businesses are generating more video than ever. From years of broadcast archives to thousands of store cameras and countless hours of production footage, most of it just sits unused on servers, unwatched and unanalyzed. This is dark data: a massive, untapped resource that companies collect automatically but almost never use in a meaningful way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To tackle the problem, Aza Kai (CEO) and Hiraku Yanagita (COO), two former Googlers who spent nearly a decade working together at Google Japan, decided to build their own solution. The duo co-founded InfiniMind, a Tokyo-based startup developing infrastructure that converts petabytes of unviewed video and audio into structured, queryable business data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“My co-founder, who spent a decade leading brand and data solutions at Google Japan, and I saw this inflection point coming while we were still at Google,” Kai said. By 2024, the technology had matured, and the market demand had become clear enough that the co-founders felt compelled to build the company themselves, he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kai, who previously worked at Google Japan across cloud, machine learning, ad systems, and video recommendation models and later led data science teams, explained that current solutions force a trade-off. Earlier approaches could label objects in individual frames, but they couldn’t track narratives, understand causality, or answer complex questions about video content. For clients with decades of broadcast archives and petabytes of footage, even basic questions about their content often went unanswered.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What really changed was the progress in vision-language models between 2021 and 2023. That’s when video AI started moving beyond simple object tagging, Kai noted. Falling GPU costs and annual performance gains of roughly 15% to 20% over the last decade helped, but the bigger story was capability — until recently, models just couldn’t do the job, he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;InfiniMind recently secured $5.8 million in seed funding, led by UTEC and joined by CX2, Headline Asia, Chiba Dojo, and an AI researcher at a16z Scout. The company is relocating its headquarters to the U.S., while it continues to operate an office in Japan. Japan provided the perfect testbed: strong hardware, talented engineers, and a supportive startup ecosystem,&lt;strong&gt; &lt;/strong&gt;allowing the team to fine-tune its technology with demanding customers before going global.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its first product, TV Pulse, launched in Japan in April 2025. The AI-powered platform analyzes television content in real time, helping media and retail companies “track product exposure, brand presence, customer sentiment, and PR impact,” per the startup. After pilot programs with major broadcasters and agencies, it already has paying customers, including wholesalers and media companies.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Now, InfiniMind is ready for the international market. Its flagship product, DeepFrame, a long-form video intelligence platform capable of processing 200 hours of footage to pinpoint specific scenes, speakers, or events, is scheduled for a beta release in March, followed by a full launch in April 2026, Kai said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3090794" height="453" src="https://techcrunch.com/wp-content/uploads/2026/02/InfiniMind-team-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;infinimind&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The video analysis space is highly fragmented. Companies such as TwelveLabs provide general-purpose video understanding APIs for a broad range of users, including consumers, prosumers, and enterprises, Kai said, while&amp;nbsp;InfiniMind focuses specifically on enterprise use cases, including monitoring, safety, security, and analyzing video content for deeper insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our solution requires no code; clients bring their data, and our system processes it, providing actionable insights,” Kai said. “We also integrate audio, sound, and speech understanding, not just visuals. Our system can handle unlimited video length, and cost efficiency is a major differentiator. Most existing solutions prioritize accuracy or specific use cases but don’t solve cost challenges.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The seed funding will help the team continue developing the DeepFrame model, expand engineering infrastructure, hire more engineers, and reach additional customers across Japan and the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is an exciting space, one of the paths toward AGI,” Kai said. “Understanding general video intelligence is about understanding reality. Industrial applications are important, but our ultimate goal is to push the boundaries of technology to better understand reality and help humans make better decisions.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Businesses are generating more video than ever. From years of broadcast archives to thousands of store cameras and countless hours of production footage, most of it just sits unused on servers, unwatched and unanalyzed. This is dark data: a massive, untapped resource that companies collect automatically but almost never use in a meaningful way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To tackle the problem, Aza Kai (CEO) and Hiraku Yanagita (COO), two former Googlers who spent nearly a decade working together at Google Japan, decided to build their own solution. The duo co-founded InfiniMind, a Tokyo-based startup developing infrastructure that converts petabytes of unviewed video and audio into structured, queryable business data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“My co-founder, who spent a decade leading brand and data solutions at Google Japan, and I saw this inflection point coming while we were still at Google,” Kai said. By 2024, the technology had matured, and the market demand had become clear enough that the co-founders felt compelled to build the company themselves, he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kai, who previously worked at Google Japan across cloud, machine learning, ad systems, and video recommendation models and later led data science teams, explained that current solutions force a trade-off. Earlier approaches could label objects in individual frames, but they couldn’t track narratives, understand causality, or answer complex questions about video content. For clients with decades of broadcast archives and petabytes of footage, even basic questions about their content often went unanswered.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What really changed was the progress in vision-language models between 2021 and 2023. That’s when video AI started moving beyond simple object tagging, Kai noted. Falling GPU costs and annual performance gains of roughly 15% to 20% over the last decade helped, but the bigger story was capability — until recently, models just couldn’t do the job, he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;InfiniMind recently secured $5.8 million in seed funding, led by UTEC and joined by CX2, Headline Asia, Chiba Dojo, and an AI researcher at a16z Scout. The company is relocating its headquarters to the U.S., while it continues to operate an office in Japan. Japan provided the perfect testbed: strong hardware, talented engineers, and a supportive startup ecosystem,&lt;strong&gt; &lt;/strong&gt;allowing the team to fine-tune its technology with demanding customers before going global.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its first product, TV Pulse, launched in Japan in April 2025. The AI-powered platform analyzes television content in real time, helping media and retail companies “track product exposure, brand presence, customer sentiment, and PR impact,” per the startup. After pilot programs with major broadcasters and agencies, it already has paying customers, including wholesalers and media companies.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Now, InfiniMind is ready for the international market. Its flagship product, DeepFrame, a long-form video intelligence platform capable of processing 200 hours of footage to pinpoint specific scenes, speakers, or events, is scheduled for a beta release in March, followed by a full launch in April 2026, Kai said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3090794" height="453" src="https://techcrunch.com/wp-content/uploads/2026/02/InfiniMind-team-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;infinimind&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The video analysis space is highly fragmented. Companies such as TwelveLabs provide general-purpose video understanding APIs for a broad range of users, including consumers, prosumers, and enterprises, Kai said, while&amp;nbsp;InfiniMind focuses specifically on enterprise use cases, including monitoring, safety, security, and analyzing video content for deeper insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our solution requires no code; clients bring their data, and our system processes it, providing actionable insights,” Kai said. “We also integrate audio, sound, and speech understanding, not just visuals. Our system can handle unlimited video length, and cost efficiency is a major differentiator. Most existing solutions prioritize accuracy or specific use cases but don’t solve cost challenges.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The seed funding will help the team continue developing the DeepFrame model, expand engineering infrastructure, hire more engineers, and reach additional customers across Japan and the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is an exciting space, one of the paths toward AGI,” Kai said. “Understanding general video intelligence is about understanding reality. Industrial applications are important, but our ultimate goal is to push the boundaries of technology to better understand reality and help humans make better decisions.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/ex-googlers-are-building-infrastructure-to-help-companies-understand-their-video-data/</guid><pubDate>Mon, 09 Feb 2026 17:00:00 +0000</pubDate></item><item><title>[NEW] Why the Moltbook frenzy was like Pokémon (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/moltbook-head3.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse into the future. It appeared to show AI systems doing useful things for the humans that created them (one person used the platform to help him negotiate a deal on a new car). Sure, it was flooded with crypto scams, and many of the posts were actually written by people, but &lt;em&gt;something&lt;/em&gt; about it pointed to a future of helpful AI, right?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;The whole experiment reminded our senior editor for AI, Will Douglas Heaven, of something far less interesting: Pokémon.&lt;/p&gt;  &lt;p&gt;Back in 2014, someone set up a game of Pokémon in which the main character could be controlled by anyone on the internet via the streaming platform Twitch. Playing was as clunky as it sounds, but it was incredibly popular: at one point, a million people were playing the game at the same time.&lt;/p&gt; 
 &lt;p&gt;“It was yet another weird online social experiment that got picked up by the mainstream media: What did this mean for the future?” Will says. “Not a lot, it turned out.”&lt;/p&gt;  &lt;p&gt;The frenzy about Moltbook struck a similar tone to Will, and it turned out that one of the sources he spoke to had been thinking about Pokémon too. Jason Schloetzer, at the Georgetown Psaros Center for Financial Markets and Policy, saw the whole thing as a sort of Pokémon battle for AI enthusiasts, in which they created AI agents and deployed them to interact with other agents. In this light, the news that many AI agents were actually being instructed by people to say certain things that made them sound sentient or intelligent makes a whole lot more sense.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“It’s basically a spectator sport,” he told Will, “but for language models.”&lt;/p&gt;  &lt;p&gt;Will wrote an excellent piece about why Moltbook was not the glimpse into the future that it was said to be. Even if you are excited about a future of agentic AI, he points out, there are some key pieces that Moltbook made clear are still missing. It was a forum of chaos, but a genuinely helpful hive mind would require more coordination, shared objectives, and shared memory.&lt;/p&gt;  &lt;p&gt;“More than anything else, I think Moltbook was the internet having fun,” Will says. “The biggest question that now leaves me with is: How far will people push AI just for the laughs?”&lt;/p&gt;  &lt;p&gt;Read the whole story.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/moltbook-head3.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse into the future. It appeared to show AI systems doing useful things for the humans that created them (one person used the platform to help him negotiate a deal on a new car). Sure, it was flooded with crypto scams, and many of the posts were actually written by people, but &lt;em&gt;something&lt;/em&gt; about it pointed to a future of helpful AI, right?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;The whole experiment reminded our senior editor for AI, Will Douglas Heaven, of something far less interesting: Pokémon.&lt;/p&gt;  &lt;p&gt;Back in 2014, someone set up a game of Pokémon in which the main character could be controlled by anyone on the internet via the streaming platform Twitch. Playing was as clunky as it sounds, but it was incredibly popular: at one point, a million people were playing the game at the same time.&lt;/p&gt; 
 &lt;p&gt;“It was yet another weird online social experiment that got picked up by the mainstream media: What did this mean for the future?” Will says. “Not a lot, it turned out.”&lt;/p&gt;  &lt;p&gt;The frenzy about Moltbook struck a similar tone to Will, and it turned out that one of the sources he spoke to had been thinking about Pokémon too. Jason Schloetzer, at the Georgetown Psaros Center for Financial Markets and Policy, saw the whole thing as a sort of Pokémon battle for AI enthusiasts, in which they created AI agents and deployed them to interact with other agents. In this light, the news that many AI agents were actually being instructed by people to say certain things that made them sound sentient or intelligent makes a whole lot more sense.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“It’s basically a spectator sport,” he told Will, “but for language models.”&lt;/p&gt;  &lt;p&gt;Will wrote an excellent piece about why Moltbook was not the glimpse into the future that it was said to be. Even if you are excited about a future of agentic AI, he points out, there are some key pieces that Moltbook made clear are still missing. It was a forum of chaos, but a genuinely helpful hive mind would require more coordination, shared objectives, and shared memory.&lt;/p&gt;  &lt;p&gt;“More than anything else, I think Moltbook was the internet having fun,” Will says. “The biggest question that now leaves me with is: How far will people push AI just for the laughs?”&lt;/p&gt;  &lt;p&gt;Read the whole story.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/</guid><pubDate>Mon, 09 Feb 2026 17:02:56 +0000</pubDate></item><item><title>[NEW] Anthropic closes in on $20B round (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/anthropic-closes-in-on-20b-round/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2252871842.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is in the final stages of raising $20 billion in new capital at a valuation of $350 billion, Bloomberg reports, with investor demand leading the company to raise twice the funding it set out to obtain. The company raised $13 billion in equity funding just five months ago, but intense competition between frontier labs and the ongoing cost of compute has made it eager to raise as quickly as possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Firms expected to participate in the round include Altimeter Capital Management, Sequoia Capital, Lightspeed Venture Partners, Menlo Ventures, Coatue Management, Iconiq Capital, and Singapore’s sovereign wealth fund, but the bulk of the funding is said to come from the company’s strategic partners Nvidia and Microsoft.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic is building on recent successes, most notably the deployment of its coding agents, which have software engineers raving about increased coding productivity. Last week, the company’s release of new models focused on legal and business research rattled the share prices of publicly-traded data firms as investors worried about the ability of AI to disrupt their businesses. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s rival, OpenAI, is reportedly assembling a new $100 billion fundraising round, and both companies are thought to be preparing IPOs ahead of a blockbuster summer in the markets, with xAI, recently acquired by SpaceX, also tapping public equity as part of the rocket maker’s IPO.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2252871842.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is in the final stages of raising $20 billion in new capital at a valuation of $350 billion, Bloomberg reports, with investor demand leading the company to raise twice the funding it set out to obtain. The company raised $13 billion in equity funding just five months ago, but intense competition between frontier labs and the ongoing cost of compute has made it eager to raise as quickly as possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Firms expected to participate in the round include Altimeter Capital Management, Sequoia Capital, Lightspeed Venture Partners, Menlo Ventures, Coatue Management, Iconiq Capital, and Singapore’s sovereign wealth fund, but the bulk of the funding is said to come from the company’s strategic partners Nvidia and Microsoft.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic is building on recent successes, most notably the deployment of its coding agents, which have software engineers raving about increased coding productivity. Last week, the company’s release of new models focused on legal and business research rattled the share prices of publicly-traded data firms as investors worried about the ability of AI to disrupt their businesses. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s rival, OpenAI, is reportedly assembling a new $100 billion fundraising round, and both companies are thought to be preparing IPOs ahead of a blockbuster summer in the markets, with xAI, recently acquired by SpaceX, also tapping public equity as part of the rocket maker’s IPO.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/anthropic-closes-in-on-20b-round/</guid><pubDate>Mon, 09 Feb 2026 17:37:23 +0000</pubDate></item><item><title>[NEW] Workday CEO Eschenbach departs, with co-founder Aneel Bhusri returning as CEO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/workday-ceo-eschenbach-departs-with-co-founder-aneel-bhusri-returning-as-ceo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/workday-larger-959933114.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Enterprise resource planning software company Workday announced Monday that chief executive Carl Eschenbach was stepping down and leaving the company’s board, effective immediately. Workday co-founder and former CEO Aneel Bhusri will return as CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eschenbach joined Workday in December 2022 as co-CEO alongside Bhusri, and had been operating as the company’s sole CEO since February 2024. Bhusri, who had led the company since 2009 —&amp;nbsp;sometimes as co-CEO, sometimes as sole CEO — has been serving as the company’s executive chairman since 2024.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Workday confirmed to TechCrunch that Bhusri is returning to the role permanently, as opposed to taking the helm during a search for a replacement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Workday made this leadership change as it says its next chapter will be focused on, unsurprisingly, AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re now entering one of the most pivotal moments in our history,” Bhusri said in the company’s press release Monday. “AI is a bigger transformation than SaaS — and it will define the next generation of market leaders. I’m energized to return as CEO, working alongside our presidents Gerrit Kazmaier and Rob Enslin, and I’m excited about the opportunity in front of us.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last February, Workday laid off 8.5% of its headcount, or 1,750 people, with Eschenbach stating at the time that the company needed a new approach to labor in the age of AI.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/workday-larger-959933114.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Enterprise resource planning software company Workday announced Monday that chief executive Carl Eschenbach was stepping down and leaving the company’s board, effective immediately. Workday co-founder and former CEO Aneel Bhusri will return as CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eschenbach joined Workday in December 2022 as co-CEO alongside Bhusri, and had been operating as the company’s sole CEO since February 2024. Bhusri, who had led the company since 2009 —&amp;nbsp;sometimes as co-CEO, sometimes as sole CEO — has been serving as the company’s executive chairman since 2024.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Workday confirmed to TechCrunch that Bhusri is returning to the role permanently, as opposed to taking the helm during a search for a replacement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Workday made this leadership change as it says its next chapter will be focused on, unsurprisingly, AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re now entering one of the most pivotal moments in our history,” Bhusri said in the company’s press release Monday. “AI is a bigger transformation than SaaS — and it will define the next generation of market leaders. I’m energized to return as CEO, working alongside our presidents Gerrit Kazmaier and Rob Enslin, and I’m excited about the opportunity in front of us.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last February, Workday laid off 8.5% of its headcount, or 1,750 people, with Eschenbach stating at the time that the company needed a new approach to labor in the age of AI.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/workday-ceo-eschenbach-departs-with-co-founder-aneel-bhusri-returning-as-ceo/</guid><pubDate>Mon, 09 Feb 2026 18:15:08 +0000</pubDate></item><item><title>[NEW] How AI trained on birds is surfacing underwater mysteries (The latest research from Google)</title><link>https://research.google/blog/how-ai-trained-on-birds-is-surfacing-underwater-mysteries/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Evaluation&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;We evaluated Perch 2.0 using a few-shot linear probe on marine tasks, such as distinguishing different baleen whale species or different killer whale subpopulations. Its performance was compared against pre-trained models that are supported in our Perch Hoplite repository for agile modeling and transfer learning. They include Perch 2.0, Perch 1.0, SurfPerch, and the multispecies whale model.&lt;/p&gt;&lt;p&gt;For underwater data evaluation, we used three datasets: NOAA PIPAN, ReefSet, and DCLDE.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;NOAA PIPAN&lt;/b&gt;: An annotated subset of the NOAA NCEI Passive Acoustic Data Archive from the NOAA Pacific Islands Fisheries Science Center recordings. It includes labels used in our prior whale models as well as new annotations for baleen species such as common minke whale, humpback whale, sei whale, blue whale, fin whale, and Bryde’s whale.&lt;/li&gt;&lt;li&gt;&lt;b&gt;ReefSet:&lt;/b&gt; Developed for SurfPerch model training, this dataset leverages data annotations from the Google Arts and Culture project: Calling in Our Corals. It includes a mix of biological reef noises (croaks, crackles, growls), specific species/genera classes (e.g., damselfish, dolphins, and groupers), and anthropomorphic noise and wave classes.&lt;/li&gt;&lt;li&gt;&lt;b&gt;DCLDE:&lt;/b&gt; This dataset is evaluated using three different label sets:&lt;ul&gt;&lt;li&gt;Species: For distinguishing between killer whales, humpbacks, abiotic sounds, and unknown underwater sounds (with some uncertainty in killer whale and humpbacks labels).&lt;/li&gt;&lt;li&gt;Species Known Bio: For certain labels of killer whales and humpbacks.&lt;/li&gt;&lt;li&gt;Ecotype: For distinguishing between killer whale subpopulations (ecotypes), including Transient/Biggs, Northern Residents, Southern Residents, Southeastern Alaska killer whales, and offshore killer whales.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In this protocol, for a given target dataset with labeled data, we compute embeddings from each of the candidate models. We then select a fixed number of examples per class (4, 8, 16, or 32), and train a simple multi-class logistic regression model on top of the embeddings. We use the resulting classifier to compute the area under the receiver-operating characteristic curve (AUC_ROC), where values closer to 1 indicate a stronger ability to distinguish between classes. This process simulates using a given pre-trained embedding model to create a custom classifier from a small number of labelled examples.&lt;/p&gt;&lt;p&gt;Our results show that more examples per class improve performance across all the models, except on ReefSet data, where performance is high even with only four examples per class for all models, except the multispecies whale model. Notably, Perch 2.0 is consistently either the top or second-best performing model for each dataset and sample size.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Evaluation&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;We evaluated Perch 2.0 using a few-shot linear probe on marine tasks, such as distinguishing different baleen whale species or different killer whale subpopulations. Its performance was compared against pre-trained models that are supported in our Perch Hoplite repository for agile modeling and transfer learning. They include Perch 2.0, Perch 1.0, SurfPerch, and the multispecies whale model.&lt;/p&gt;&lt;p&gt;For underwater data evaluation, we used three datasets: NOAA PIPAN, ReefSet, and DCLDE.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;NOAA PIPAN&lt;/b&gt;: An annotated subset of the NOAA NCEI Passive Acoustic Data Archive from the NOAA Pacific Islands Fisheries Science Center recordings. It includes labels used in our prior whale models as well as new annotations for baleen species such as common minke whale, humpback whale, sei whale, blue whale, fin whale, and Bryde’s whale.&lt;/li&gt;&lt;li&gt;&lt;b&gt;ReefSet:&lt;/b&gt; Developed for SurfPerch model training, this dataset leverages data annotations from the Google Arts and Culture project: Calling in Our Corals. It includes a mix of biological reef noises (croaks, crackles, growls), specific species/genera classes (e.g., damselfish, dolphins, and groupers), and anthropomorphic noise and wave classes.&lt;/li&gt;&lt;li&gt;&lt;b&gt;DCLDE:&lt;/b&gt; This dataset is evaluated using three different label sets:&lt;ul&gt;&lt;li&gt;Species: For distinguishing between killer whales, humpbacks, abiotic sounds, and unknown underwater sounds (with some uncertainty in killer whale and humpbacks labels).&lt;/li&gt;&lt;li&gt;Species Known Bio: For certain labels of killer whales and humpbacks.&lt;/li&gt;&lt;li&gt;Ecotype: For distinguishing between killer whale subpopulations (ecotypes), including Transient/Biggs, Northern Residents, Southern Residents, Southeastern Alaska killer whales, and offshore killer whales.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In this protocol, for a given target dataset with labeled data, we compute embeddings from each of the candidate models. We then select a fixed number of examples per class (4, 8, 16, or 32), and train a simple multi-class logistic regression model on top of the embeddings. We use the resulting classifier to compute the area under the receiver-operating characteristic curve (AUC_ROC), where values closer to 1 indicate a stronger ability to distinguish between classes. This process simulates using a given pre-trained embedding model to create a custom classifier from a small number of labelled examples.&lt;/p&gt;&lt;p&gt;Our results show that more examples per class improve performance across all the models, except on ReefSet data, where performance is high even with only four examples per class for all models, except the multispecies whale model. Notably, Perch 2.0 is consistently either the top or second-best performing model for each dataset and sample size.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/how-ai-trained-on-birds-is-surfacing-underwater-mysteries/</guid><pubDate>Mon, 09 Feb 2026 18:38:06 +0000</pubDate></item></channel></rss>