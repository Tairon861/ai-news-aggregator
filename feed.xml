<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 22 Jan 2026 12:56:13 +0000</lastBuildDate><item><title>[NEW] Yann LeCun’s new venture is a contrarian bet against large language models (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/22/1131661/yann-lecuns-new-venture-ami-labs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AP23165452788339.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Yann LeCun is a Turing Award recipient and a top AI researcher, but he has long been a contrarian figure in the tech world. He believes that the industry’s current obsession with large language models is wrong-headed and will ultimately fail to solve many pressing problems.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Instead, he thinks we should be betting on world models—a different type of AI that accurately reflects the dynamics of the real world. He is also a staunch advocate for open-source AI and criticizes the closed approach of frontier labs like OpenAI and Anthropic.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Perhaps it’s no surprise, then, that he recently left Meta, where he had served as chief scientist for FAIR (Fundamental AI Research), the company's influential research lab that he founded. Meta has struggled to gain much traction with its open-source AI model Llama and has seen internal shake-ups, including the controversial acquisition of ScaleAI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;LeCun sat down with &lt;em&gt;MIT Technology Review&lt;/em&gt; in an exclusive online interview from his Paris apartment to discuss his new venture, life after Meta, the future of artificial intelligence, and why he thinks the industry is chasing the wrong ideas.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Both the questions and answers below have been edited for clarity and brevity.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;You’ve just announced a new company, Advanced Machine Intelligence (AMI).&amp;nbsp; Tell me about the big ideas behind it.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;It is going to be a global company, but headquartered in Paris. You pronounce it “ami”—it means “friend” in French. I am excited. There is a very high concentration of talent in Europe, but it is not always given a proper environment to flourish. And there is certainly a huge demand from the industry and governments for a credible frontier AI company that is neither Chinese nor American. I think that is going to be to our advantage.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;So an ambitious alternative to the US-China binary we currently have. What made you want to pursue that third path?&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Well, there are sovereignty issues for a lot of countries, and they want some control over AI. What I’m advocating is that AI is going to become a platform, and most platforms tend to become open-source. Unfortunately, that’s not really the direction the American industry is taking. Right? As the competition increases, they feel like they have to be secretive. I think that is a strategic mistake.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;It’s certainly true for OpenAI, which went from very open to very closed, and Anthropic has always been closed. Google was sort of a little open. And then Meta, we’ll see. My sense is that it’s not going in a positive direction at this moment.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Simultaneously, China has completely embraced this open approach. So all leading open-source AI platforms are Chinese, and the result is that academia and startups, outside of the US, have basically embraced Chinese models. There’s nothing wrong with that—you know, Chinese models are good. Chinese engineers and scientists are great. But you know, if there is a future in which all of our information diet is being mediated by AI assistance, and the choice is either English-speaking models produced by proprietary companies always close to the US or Chinese models which may be open-source but need to be fine-tuned so that they answer questions about Tiananmen Square in 1989—you know, it’s not a very pleasant and engaging future.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;They [the future models] should be able to be fine-tuned by anyone and produce a very high diversity of AI assistance, with different linguistic abilities and value systems and political biases and centers of interests. You need high diversity of assistance for the same reason that you need high diversity of press.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;That is certainly a compelling pitch. How are investors buying that idea so far?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;They really like it. A lot of venture capitalists are very much in favor of this idea of open-source, because they know for a lot of small startups, they really rely on open-source models. They don’t have the means to train their own model, and it’s kind of dangerous for them strategically to embrace a proprietary model.&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;You recently left Meta. What’s your view on the company and Mark Zuckerberg’s leadership? There’s a perception that Meta has fumbled its AI advantage.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I think FAIR [LeCun’s lab at Meta] was extremely successful in the research part. Where Meta was less successful is in picking up on that research and pushing it into practical technology and products. Mark made some choices that he thought were the best for the company. I may not have agreed with all of them. For example, the robotics group at FAIR was let go, which I think was a strategic mistake. But I’m not the director of FAIR. People make decisions rationally, and there’s no reason to be upset.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;So, no bad blood? Could Meta be a future client for AMI?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Meta might be our first client! We’ll see. The work we are doing is not in direct competition. Our focus on world models for the physical world is very different from their focus on generative AI and LLMs.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;You were working on AI long before LLMs became a mainstream approach. But since ChatGPT broke out, LLMs have become almost synonymous with AI.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yes, and we are going to change that. The public face of AI, perhaps, is mostly LLMs and chatbots of various types. But the latest ones of those are not pure LLMs. They are LLM plus a lot of things, like perception systems and code that solves particular problems. So we are going to see LLMs as kind of the orchestrator in systems, a little bit.&lt;/p&gt;  &lt;p&gt;Beyond LLMs, there is a lot of AI that is behind the scenes that runs a big chunk of our society. There are assistance driving programs in a car, quick-turn MRI images, algorithms that drive social media—that’s all AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;You have been vocal in arguing that LLMs can only get us so far. Do you think LLMs are overhyped these days? Can you summarize to our readers why you believe that LLMs are not enough?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;There is a sense in which they have not been overhyped, which is that they are extremely useful to a lot of people, particularly if you write text, do research, or write code. LLMs manipulate language really well. But people have had this illusion, or delusion, that it is a matter of time until we can scale them up to having human-level intelligence, and that is simply false.&lt;/p&gt;  &lt;p&gt;The truly difficult part is understanding the real world. This is the Moravec Paradox (a phenomenon observed by the computer scientist Hans Moravec in 1988): What’s easy for us, like perception and navigation, is hard for computers, and vice versa. LLMs are limited to the discrete world of text. They can’t truly reason or plan, because they lack a model of the world. They can’t predict the consequences of their actions. This is why we don’t have a domestic robot that is as agile as a house cat, or a truly autonomous car.&lt;/p&gt; 
 &lt;p&gt;We are going to have AI systems that have humanlike and human-level intelligence, but they’re&amp;nbsp; not going to be built on LLMs, and it’s not going to happen next year or two years from now. It’s going to take a while. There are major conceptual breakthroughs that have to happen before we have AI systems that have human-level intelligence. And that is what I’ve been working on. And this company, AMI Labs, is focusing on the next generation.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And your solution is world models and JEPA architecture (JEPA, or “joint embedding predictive architecture,” is a learning framework that trains AI models to understand the world, created by LeCun while he was at Meta). What’s the elevator pitch?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;The world is unpredictable. If you try to build a generative model that predicts every detail of the future, it will fail.&amp;nbsp; JEPA is not generative AI. It is a system that learns to represent videos really well. The key is to learn an abstract representation of the world and make predictions in that abstract space, ignoring the details you can’t predict. That’s what JEPA does. It learns the underlying rules of the world from observation, like a baby learning about gravity. This is the foundation for common sense, and it’s the key to building truly intelligent systems that can reason and plan in the real world. The most exciting work so far on this is coming from academia, not the big industrial labs stuck in the LLM world.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The lack of non-text data has been a problem in taking AI systems further in understanding the physical world. JEPA is trained on videos. What other kinds of data will you be using?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Our systems will be trained on video, audio, and sensor data of all kinds—not just text. We are working with various modalities, from the position of a robot arm to lidar data to audio. I’m also involved in a project using JEPA to model complex physical and clinical phenomena.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What are some of the concrete, real-world applications you envision for world models?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The applications are vast. Think about complex industrial processes where you have thousands of sensors, like in a jet engine, a steel mill, or a chemical factory. There is no technique right now to build a complete, holistic model of these systems. A world model could learn this from the sensor data and predict how the system will behave. Or think of smart glasses that can watch what you’re doing, identify your actions, and then predict what you’re going to do next to assist you. This is what will finally make agentic systems reliable. An agentic system that is supposed to take actions in the world cannot work reliably unless it has a world model to predict the consequences of its actions. Without it, the system will inevitably make mistakes. This is the key to unlocking everything from truly useful domestic robots to Level 5 autonomous driving.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Humanoid robots are all the rage recently, especially ones built by companies from China. What’s your take?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;There are all these brute-force ways to get around the limitations of learning systems, which require inordinate amounts of training data to do anything. So the secret of all the companies getting robots to do kung fu or dance is they are all planned in advance. But frankly, nobody—absolutely nobody—knows how to make those robots smart enough to be useful. Take my word for it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;You need an enormous amount of tele-operation training data for every single task, and when the environment changes a little bit, it doesn’t generalize very well. What this tells us is we are missing something very big. The reason why a 17-year-old can learn to drive in 20 hours is because they already know a lot about how the world behaves. If we want a generally useful domestic robot, we need systems to have a kind of good understanding of the physical world. That’s not going to happen until we have good world models and planning.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;&lt;strong&gt;There’s a growing sentiment that it’s becoming harder to do foundational AI research in academia because of the massive computing resources required. Do you think the most important innovations will now come from industry?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;No. LLMs are now technology development, not research. It’s true that it’s very difficult for academics to play an important role there because of the requirements for computation, data access, and engineering support. But it’s a product now. It’s not something academia should even be interested in. It’s like speech recognition in the early 2010s—it was a solved problem, and the progress was in the hands of industry.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;What academia should be working on is long-term objectives that go beyond the capabilities of current systems. That’s why I tell people in universities: Don’t work on LLMs. There is no point. You’re not going to be able to rival what’s going on in industry. Work on something else. Invent new techniques. The breakthroughs are not going to come from scaling up LLMs. The most exciting work on world models is coming from academia, not the big industrial labs. The whole idea of using attention circuits in neural nets came out of the University of Montreal. That research paper started the whole revolution. Now that the big companies are closing up, the breakthroughs are going to slow down. Academia needs access to computing resources, but they should be focused on the next big thing, not on refining the last one.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;You wear many hats: professor, researcher, educator, public thinker … Now you just took on a new one. What is that going to look like for you?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I am going to be the executive chairman of the company, and Alex LeBrun [a former colleague from Meta AI] will be the CEO. It’s going to be LeCun and LeBrun—it’s nice if you pronounce it the French way.&lt;/p&gt;  &lt;p&gt;I am going to keep my position at NYU. I teach one class per year, I have PhD students and postdocs, so I am going to be kept based in New York. But I go to Paris pretty often because of my lab.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Does that mean that you won’t be very hands-on?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Well, there's two ways to be hands-on. One is to manage people day to day, and another is to actually get your hands dirty in research projects, right?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;I can do management, but I don't like doing it. This is not my mission in life. It’s really to make science and technology progress as far as we can, inspire other people to work on things that are interesting, and then contribute to those things. So that has been my role at Meta for the last seven years. I founded FAIR and led it for four to five years. I kind of hated being a director. I am not good at this career management thing. I'm much more visionary and a scientist.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What makes Alex LeBrun the right fit?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Alex is a serial entrepreneur; he’s built three successful AI companies. The first he sold to Microsoft; the second to Facebook, where he was head of the engineering division of FAIR in Paris. He then left to create Nabla, a very successful company in the health-care space. When I offered him the chance to join me in this effort, he accepted almost immediately. He has the experience to build the company, allowing me to focus on science and technology.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;You’re headquartered in Paris. Where else do you plan to have offices?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;We are a global company. There’s going to be an office in North America.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;New York, hopefully?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;New York is great. That’s where I am, right? And it’s not Silicon Valley. Silicon Valley is a bit of a monoculture.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What about Asia? I’m guessing Singapore, too?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt;&lt;p&gt;Probably, yeah. I’ll let you guess.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And how are you attracting talent?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;We don’t have any issue recruiting. There are a lot of people in the AI research community who think the future of AI is in world models. Those people, regardless of pay package, will be motivated to come work for us because they believe in the technological future we are building. We’ve already recruited people from places like OpenAI, Google DeepMind, and xAI.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;I heard that Saining Xie, a prominent researcher from NYU and Google DeepMind, might be joining you as chief scientist. Any comments?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Saining is a brilliant researcher. I have a lot of admiration for him. I hired him twice already. I hired him at FAIR, and I convinced my colleagues at NYU that we should hire him there. Let’s just say I have a lot of respect for him.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;When will you be ready to share more details about AMI Labs, like financial backing or other core members?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Soon—in February, maybe. I’ll let you know.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AP23165452788339.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Yann LeCun is a Turing Award recipient and a top AI researcher, but he has long been a contrarian figure in the tech world. He believes that the industry’s current obsession with large language models is wrong-headed and will ultimately fail to solve many pressing problems.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Instead, he thinks we should be betting on world models—a different type of AI that accurately reflects the dynamics of the real world. He is also a staunch advocate for open-source AI and criticizes the closed approach of frontier labs like OpenAI and Anthropic.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Perhaps it’s no surprise, then, that he recently left Meta, where he had served as chief scientist for FAIR (Fundamental AI Research), the company's influential research lab that he founded. Meta has struggled to gain much traction with its open-source AI model Llama and has seen internal shake-ups, including the controversial acquisition of ScaleAI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;LeCun sat down with &lt;em&gt;MIT Technology Review&lt;/em&gt; in an exclusive online interview from his Paris apartment to discuss his new venture, life after Meta, the future of artificial intelligence, and why he thinks the industry is chasing the wrong ideas.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Both the questions and answers below have been edited for clarity and brevity.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;You’ve just announced a new company, Advanced Machine Intelligence (AMI).&amp;nbsp; Tell me about the big ideas behind it.&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;It is going to be a global company, but headquartered in Paris. You pronounce it “ami”—it means “friend” in French. I am excited. There is a very high concentration of talent in Europe, but it is not always given a proper environment to flourish. And there is certainly a huge demand from the industry and governments for a credible frontier AI company that is neither Chinese nor American. I think that is going to be to our advantage.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;So an ambitious alternative to the US-China binary we currently have. What made you want to pursue that third path?&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Well, there are sovereignty issues for a lot of countries, and they want some control over AI. What I’m advocating is that AI is going to become a platform, and most platforms tend to become open-source. Unfortunately, that’s not really the direction the American industry is taking. Right? As the competition increases, they feel like they have to be secretive. I think that is a strategic mistake.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;It’s certainly true for OpenAI, which went from very open to very closed, and Anthropic has always been closed. Google was sort of a little open. And then Meta, we’ll see. My sense is that it’s not going in a positive direction at this moment.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Simultaneously, China has completely embraced this open approach. So all leading open-source AI platforms are Chinese, and the result is that academia and startups, outside of the US, have basically embraced Chinese models. There’s nothing wrong with that—you know, Chinese models are good. Chinese engineers and scientists are great. But you know, if there is a future in which all of our information diet is being mediated by AI assistance, and the choice is either English-speaking models produced by proprietary companies always close to the US or Chinese models which may be open-source but need to be fine-tuned so that they answer questions about Tiananmen Square in 1989—you know, it’s not a very pleasant and engaging future.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;They [the future models] should be able to be fine-tuned by anyone and produce a very high diversity of AI assistance, with different linguistic abilities and value systems and political biases and centers of interests. You need high diversity of assistance for the same reason that you need high diversity of press.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;That is certainly a compelling pitch. How are investors buying that idea so far?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;They really like it. A lot of venture capitalists are very much in favor of this idea of open-source, because they know for a lot of small startups, they really rely on open-source models. They don’t have the means to train their own model, and it’s kind of dangerous for them strategically to embrace a proprietary model.&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;You recently left Meta. What’s your view on the company and Mark Zuckerberg’s leadership? There’s a perception that Meta has fumbled its AI advantage.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I think FAIR [LeCun’s lab at Meta] was extremely successful in the research part. Where Meta was less successful is in picking up on that research and pushing it into practical technology and products. Mark made some choices that he thought were the best for the company. I may not have agreed with all of them. For example, the robotics group at FAIR was let go, which I think was a strategic mistake. But I’m not the director of FAIR. People make decisions rationally, and there’s no reason to be upset.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;So, no bad blood? Could Meta be a future client for AMI?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Meta might be our first client! We’ll see. The work we are doing is not in direct competition. Our focus on world models for the physical world is very different from their focus on generative AI and LLMs.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;You were working on AI long before LLMs became a mainstream approach. But since ChatGPT broke out, LLMs have become almost synonymous with AI.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Yes, and we are going to change that. The public face of AI, perhaps, is mostly LLMs and chatbots of various types. But the latest ones of those are not pure LLMs. They are LLM plus a lot of things, like perception systems and code that solves particular problems. So we are going to see LLMs as kind of the orchestrator in systems, a little bit.&lt;/p&gt;  &lt;p&gt;Beyond LLMs, there is a lot of AI that is behind the scenes that runs a big chunk of our society. There are assistance driving programs in a car, quick-turn MRI images, algorithms that drive social media—that’s all AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;You have been vocal in arguing that LLMs can only get us so far. Do you think LLMs are overhyped these days? Can you summarize to our readers why you believe that LLMs are not enough?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;There is a sense in which they have not been overhyped, which is that they are extremely useful to a lot of people, particularly if you write text, do research, or write code. LLMs manipulate language really well. But people have had this illusion, or delusion, that it is a matter of time until we can scale them up to having human-level intelligence, and that is simply false.&lt;/p&gt;  &lt;p&gt;The truly difficult part is understanding the real world. This is the Moravec Paradox (a phenomenon observed by the computer scientist Hans Moravec in 1988): What’s easy for us, like perception and navigation, is hard for computers, and vice versa. LLMs are limited to the discrete world of text. They can’t truly reason or plan, because they lack a model of the world. They can’t predict the consequences of their actions. This is why we don’t have a domestic robot that is as agile as a house cat, or a truly autonomous car.&lt;/p&gt; 
 &lt;p&gt;We are going to have AI systems that have humanlike and human-level intelligence, but they’re&amp;nbsp; not going to be built on LLMs, and it’s not going to happen next year or two years from now. It’s going to take a while. There are major conceptual breakthroughs that have to happen before we have AI systems that have human-level intelligence. And that is what I’ve been working on. And this company, AMI Labs, is focusing on the next generation.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And your solution is world models and JEPA architecture (JEPA, or “joint embedding predictive architecture,” is a learning framework that trains AI models to understand the world, created by LeCun while he was at Meta). What’s the elevator pitch?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;The world is unpredictable. If you try to build a generative model that predicts every detail of the future, it will fail.&amp;nbsp; JEPA is not generative AI. It is a system that learns to represent videos really well. The key is to learn an abstract representation of the world and make predictions in that abstract space, ignoring the details you can’t predict. That’s what JEPA does. It learns the underlying rules of the world from observation, like a baby learning about gravity. This is the foundation for common sense, and it’s the key to building truly intelligent systems that can reason and plan in the real world. The most exciting work so far on this is coming from academia, not the big industrial labs stuck in the LLM world.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The lack of non-text data has been a problem in taking AI systems further in understanding the physical world. JEPA is trained on videos. What other kinds of data will you be using?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Our systems will be trained on video, audio, and sensor data of all kinds—not just text. We are working with various modalities, from the position of a robot arm to lidar data to audio. I’m also involved in a project using JEPA to model complex physical and clinical phenomena.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What are some of the concrete, real-world applications you envision for world models?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;The applications are vast. Think about complex industrial processes where you have thousands of sensors, like in a jet engine, a steel mill, or a chemical factory. There is no technique right now to build a complete, holistic model of these systems. A world model could learn this from the sensor data and predict how the system will behave. Or think of smart glasses that can watch what you’re doing, identify your actions, and then predict what you’re going to do next to assist you. This is what will finally make agentic systems reliable. An agentic system that is supposed to take actions in the world cannot work reliably unless it has a world model to predict the consequences of its actions. Without it, the system will inevitably make mistakes. This is the key to unlocking everything from truly useful domestic robots to Level 5 autonomous driving.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Humanoid robots are all the rage recently, especially ones built by companies from China. What’s your take?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;There are all these brute-force ways to get around the limitations of learning systems, which require inordinate amounts of training data to do anything. So the secret of all the companies getting robots to do kung fu or dance is they are all planned in advance. But frankly, nobody—absolutely nobody—knows how to make those robots smart enough to be useful. Take my word for it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;You need an enormous amount of tele-operation training data for every single task, and when the environment changes a little bit, it doesn’t generalize very well. What this tells us is we are missing something very big. The reason why a 17-year-old can learn to drive in 20 hours is because they already know a lot about how the world behaves. If we want a generally useful domestic robot, we need systems to have a kind of good understanding of the physical world. That’s not going to happen until we have good world models and planning.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;&lt;strong&gt;There’s a growing sentiment that it’s becoming harder to do foundational AI research in academia because of the massive computing resources required. Do you think the most important innovations will now come from industry?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;No. LLMs are now technology development, not research. It’s true that it’s very difficult for academics to play an important role there because of the requirements for computation, data access, and engineering support. But it’s a product now. It’s not something academia should even be interested in. It’s like speech recognition in the early 2010s—it was a solved problem, and the progress was in the hands of industry.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;What academia should be working on is long-term objectives that go beyond the capabilities of current systems. That’s why I tell people in universities: Don’t work on LLMs. There is no point. You’re not going to be able to rival what’s going on in industry. Work on something else. Invent new techniques. The breakthroughs are not going to come from scaling up LLMs. The most exciting work on world models is coming from academia, not the big industrial labs. The whole idea of using attention circuits in neural nets came out of the University of Montreal. That research paper started the whole revolution. Now that the big companies are closing up, the breakthroughs are going to slow down. Academia needs access to computing resources, but they should be focused on the next big thing, not on refining the last one.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;You wear many hats: professor, researcher, educator, public thinker … Now you just took on a new one. What is that going to look like for you?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;I am going to be the executive chairman of the company, and Alex LeBrun [a former colleague from Meta AI] will be the CEO. It’s going to be LeCun and LeBrun—it’s nice if you pronounce it the French way.&lt;/p&gt;  &lt;p&gt;I am going to keep my position at NYU. I teach one class per year, I have PhD students and postdocs, so I am going to be kept based in New York. But I go to Paris pretty often because of my lab.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Does that mean that you won’t be very hands-on?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Well, there's two ways to be hands-on. One is to manage people day to day, and another is to actually get your hands dirty in research projects, right?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;I can do management, but I don't like doing it. This is not my mission in life. It’s really to make science and technology progress as far as we can, inspire other people to work on things that are interesting, and then contribute to those things. So that has been my role at Meta for the last seven years. I founded FAIR and led it for four to five years. I kind of hated being a director. I am not good at this career management thing. I'm much more visionary and a scientist.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What makes Alex LeBrun the right fit?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Alex is a serial entrepreneur; he’s built three successful AI companies. The first he sold to Microsoft; the second to Facebook, where he was head of the engineering division of FAIR in Paris. He then left to create Nabla, a very successful company in the health-care space. When I offered him the chance to join me in this effort, he accepted almost immediately. He has the experience to build the company, allowing me to focus on science and technology.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;You’re headquartered in Paris. Where else do you plan to have offices?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;We are a global company. There’s going to be an office in North America.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;New York, hopefully?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;New York is great. That’s where I am, right? And it’s not Silicon Valley. Silicon Valley is a bit of a monoculture.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;What about Asia? I’m guessing Singapore, too?&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt;&lt;p&gt;Probably, yeah. I’ll let you guess.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And how are you attracting talent?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;We don’t have any issue recruiting. There are a lot of people in the AI research community who think the future of AI is in world models. Those people, regardless of pay package, will be motivated to come work for us because they believe in the technological future we are building. We’ve already recruited people from places like OpenAI, Google DeepMind, and xAI.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;I heard that Saining Xie, a prominent researcher from NYU and Google DeepMind, might be joining you as chief scientist. Any comments?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Saining is a brilliant researcher. I have a lot of admiration for him. I hired him twice already. I hired him at FAIR, and I convinced my colleagues at NYU that we should hire him there. Let’s just say I have a lot of respect for him.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;When will you be ready to share more details about AMI Labs, like financial backing or other core members?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Soon—in February, maybe. I’ll let you know.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/22/1131661/yann-lecuns-new-venture-ami-labs/</guid><pubDate>Thu, 22 Jan 2026 10:00:00 +0000</pubDate></item><item><title>[NEW] Gates Foundation and OpenAI test AI in African healthcare (AI News)</title><link>https://www.artificialintelligence-news.com/news/gates-foundation-and-openai-test-ai-in-african-healthcare/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/Gates-Foundation-and-OpenAI-test-AI-in-African-healthcare-scaled-e1769053673751.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Primary healthcare systems across parts of Africa are under growing strain, caught between rising demand, chronic staff shortages, and shrinking international aid budgets. In that context, AI is being tested in healthcare less as a breakthrough technology and more as a way to keep basic services running.&lt;/p&gt;&lt;p&gt;According to reporting by &lt;em&gt;Reuters&lt;/em&gt;, the Gates Foundation and OpenAI are backing a new initiative, Horizon1000, that aims to introduce AI tools into primary healthcare clinics across several African countries. The project will begin in Rwanda and is intended to reach 1,000 clinics and surrounding communities by 2028, supported by a combined $50 million investment.&lt;/p&gt;&lt;p&gt;The timing is not accidental as global development assistance for health fell by just under 27% last year compared to 2024, the Gates Foundation estimates, following cuts that began in the United States and spread to other major donors such as Britain and Germany. Those reductions have coincided with the first rise in preventable child deaths this century, adding pressure to health systems already stretched thin.&lt;/p&gt;&lt;p&gt;Rather than focusing on advanced diagnostics or research, Horizon1000 is framed around everyday tasks that consume time in under-resourced clinics. AI tools under the programme are expected to assist with patient intake, triage, record keeping, appointment scheduling, and access to medical guidance, particularly in settings where one doctor may serve tens of thousands of people.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-gates-foundation-and-openai-focus-on-ai-support-in-healthcare"&gt;Gates Foundation and OpenAI focus on AI support in healthcare&lt;/h3&gt;&lt;p&gt;“In poorer countries with enormous health worker shortages and lack of health systems infrastructure, AI can be a gamechanger in expanding access to quality care,” Bill Gates wrote in a blog post announcing the initiative. Speaking to &lt;em&gt;Reuters&lt;/em&gt; at the World Economic Forum in Davos, Gates said the technology could help health systems recover after aid cuts slowed progress.&lt;/p&gt;&lt;p&gt;“Our commitment is that that revolution will at least happen in the poor countries as quickly as it happens in the rich countries,” he said.&lt;/p&gt;&lt;p&gt;The focus, according to both partners, is on supporting healthcare workers rather than replacing them. OpenAI is expected to provide technical expertise and AI systems, while the Gates Foundation will work with African governments and health authorities to oversee deployment and alignment with national guidelines.&lt;/p&gt;&lt;p&gt;Rwanda was chosen as the first pilot country in part because of its existing digital health efforts. The country established an AI health hub in Kigali last year and has positioned itself as a testbed for health technology projects. Paula Ingabire, Rwanda’s minister of information and communications technology and innovation, said the goal is to reduce administrative burdens while expanding access.&lt;/p&gt;&lt;p&gt;“It is about using AI responsibly to reduce the burden on healthcare workers, to improve the quality of care, and to reach more patients,” Ingabire said in a video statement released alongside the launch.&lt;/p&gt;&lt;p&gt;Under Horizon1000, AI tools may also be used before patients reach clinics. Gates told &lt;em&gt;Reuters&lt;/em&gt; the systems could support pregnant women and HIV patients with guidance ahead of visits, especially when language barriers exist between patients and providers.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-the-ai-tools-are-expected-to-handle"&gt;What the AI tools are expected to handle&lt;/h3&gt;&lt;p&gt;Once patients arrive, AI could help link records, reduce paperwork, and speed up routine processes.&lt;/p&gt;&lt;p&gt;“A typical visit, we think, can be about twice as fast and much better quality,” Gates said.&lt;/p&gt;&lt;p&gt;Those expectations highlight both the promise and the limits of the approach. While AI may help streamline workflows, its impact depends on reliable data, stable power and connectivity, trained staff, and clear oversight. Many previous digital health pilots in low-income settings have struggled to scale beyond initial trials once funding or external support tapered off.&lt;/p&gt;&lt;p&gt;Horizon1000’s designers say they are trying to avoid that pattern by working closely with local governments and health leaders rather than deploying one-size-fits-all systems. Tools are meant to be adapted to local clinical rules, languages, and care models. Even so, questions remain about long-term maintenance, data governance, and who bears responsibility if systems fail or produce errors.&lt;/p&gt;&lt;p&gt;The initiative also reflects a broader shift in how AI is being positioned in global health. Instead of headline-grabbing claims about medical breakthroughs, the emphasis here is on narrow, operational use cases that address staffing gaps and administrative overload. In that sense, AI is being treated less as a cure for weak health systems and more as a temporary support amid declining resources.&lt;/p&gt;&lt;p&gt;OpenAI’s involvement comes as the company expands its presence in healthcare, following earlier work on health-related applications. At the same time, it faces growing scrutiny over how its systems are trained, deployed, and governed, especially in sensitive sectors like medicine.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-test-of-ai-s-limits-in-healthcare-systems"&gt;A test of AI’s limits in healthcare systems&lt;/h3&gt;&lt;p&gt;For African health systems, the stakes are practical rather than symbolic. Sub-Saharan Africa faces an estimated shortage of nearly six million healthcare workers, a gap that training alone cannot close in the near term. If AI tools can help clinicians see more patients, reduce errors, or manage workloads more effectively, they may offer some relief. If they add complexity or require constant outside support, they risk becoming another layer of dependency.&lt;/p&gt;&lt;p&gt;Horizon1000 sits at that intersection. As aid budgets tighten and healthcare demands rise, the project offers a test of whether AI can play a useful, limited role in primary care without overstating its reach. The outcome will depend less on the technology itself than on how well it fits into the systems meant to use it.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: SAP and Fresenius to build sovereign AI backbone for healthcare&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/Gates-Foundation-and-OpenAI-test-AI-in-African-healthcare-scaled-e1769053673751.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Primary healthcare systems across parts of Africa are under growing strain, caught between rising demand, chronic staff shortages, and shrinking international aid budgets. In that context, AI is being tested in healthcare less as a breakthrough technology and more as a way to keep basic services running.&lt;/p&gt;&lt;p&gt;According to reporting by &lt;em&gt;Reuters&lt;/em&gt;, the Gates Foundation and OpenAI are backing a new initiative, Horizon1000, that aims to introduce AI tools into primary healthcare clinics across several African countries. The project will begin in Rwanda and is intended to reach 1,000 clinics and surrounding communities by 2028, supported by a combined $50 million investment.&lt;/p&gt;&lt;p&gt;The timing is not accidental as global development assistance for health fell by just under 27% last year compared to 2024, the Gates Foundation estimates, following cuts that began in the United States and spread to other major donors such as Britain and Germany. Those reductions have coincided with the first rise in preventable child deaths this century, adding pressure to health systems already stretched thin.&lt;/p&gt;&lt;p&gt;Rather than focusing on advanced diagnostics or research, Horizon1000 is framed around everyday tasks that consume time in under-resourced clinics. AI tools under the programme are expected to assist with patient intake, triage, record keeping, appointment scheduling, and access to medical guidance, particularly in settings where one doctor may serve tens of thousands of people.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-gates-foundation-and-openai-focus-on-ai-support-in-healthcare"&gt;Gates Foundation and OpenAI focus on AI support in healthcare&lt;/h3&gt;&lt;p&gt;“In poorer countries with enormous health worker shortages and lack of health systems infrastructure, AI can be a gamechanger in expanding access to quality care,” Bill Gates wrote in a blog post announcing the initiative. Speaking to &lt;em&gt;Reuters&lt;/em&gt; at the World Economic Forum in Davos, Gates said the technology could help health systems recover after aid cuts slowed progress.&lt;/p&gt;&lt;p&gt;“Our commitment is that that revolution will at least happen in the poor countries as quickly as it happens in the rich countries,” he said.&lt;/p&gt;&lt;p&gt;The focus, according to both partners, is on supporting healthcare workers rather than replacing them. OpenAI is expected to provide technical expertise and AI systems, while the Gates Foundation will work with African governments and health authorities to oversee deployment and alignment with national guidelines.&lt;/p&gt;&lt;p&gt;Rwanda was chosen as the first pilot country in part because of its existing digital health efforts. The country established an AI health hub in Kigali last year and has positioned itself as a testbed for health technology projects. Paula Ingabire, Rwanda’s minister of information and communications technology and innovation, said the goal is to reduce administrative burdens while expanding access.&lt;/p&gt;&lt;p&gt;“It is about using AI responsibly to reduce the burden on healthcare workers, to improve the quality of care, and to reach more patients,” Ingabire said in a video statement released alongside the launch.&lt;/p&gt;&lt;p&gt;Under Horizon1000, AI tools may also be used before patients reach clinics. Gates told &lt;em&gt;Reuters&lt;/em&gt; the systems could support pregnant women and HIV patients with guidance ahead of visits, especially when language barriers exist between patients and providers.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-the-ai-tools-are-expected-to-handle"&gt;What the AI tools are expected to handle&lt;/h3&gt;&lt;p&gt;Once patients arrive, AI could help link records, reduce paperwork, and speed up routine processes.&lt;/p&gt;&lt;p&gt;“A typical visit, we think, can be about twice as fast and much better quality,” Gates said.&lt;/p&gt;&lt;p&gt;Those expectations highlight both the promise and the limits of the approach. While AI may help streamline workflows, its impact depends on reliable data, stable power and connectivity, trained staff, and clear oversight. Many previous digital health pilots in low-income settings have struggled to scale beyond initial trials once funding or external support tapered off.&lt;/p&gt;&lt;p&gt;Horizon1000’s designers say they are trying to avoid that pattern by working closely with local governments and health leaders rather than deploying one-size-fits-all systems. Tools are meant to be adapted to local clinical rules, languages, and care models. Even so, questions remain about long-term maintenance, data governance, and who bears responsibility if systems fail or produce errors.&lt;/p&gt;&lt;p&gt;The initiative also reflects a broader shift in how AI is being positioned in global health. Instead of headline-grabbing claims about medical breakthroughs, the emphasis here is on narrow, operational use cases that address staffing gaps and administrative overload. In that sense, AI is being treated less as a cure for weak health systems and more as a temporary support amid declining resources.&lt;/p&gt;&lt;p&gt;OpenAI’s involvement comes as the company expands its presence in healthcare, following earlier work on health-related applications. At the same time, it faces growing scrutiny over how its systems are trained, deployed, and governed, especially in sensitive sectors like medicine.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-test-of-ai-s-limits-in-healthcare-systems"&gt;A test of AI’s limits in healthcare systems&lt;/h3&gt;&lt;p&gt;For African health systems, the stakes are practical rather than symbolic. Sub-Saharan Africa faces an estimated shortage of nearly six million healthcare workers, a gap that training alone cannot close in the near term. If AI tools can help clinicians see more patients, reduce errors, or manage workloads more effectively, they may offer some relief. If they add complexity or require constant outside support, they risk becoming another layer of dependency.&lt;/p&gt;&lt;p&gt;Horizon1000 sits at that intersection. As aid budgets tighten and healthcare demands rise, the project offers a test of whether AI can play a useful, limited role in primary care without overstating its reach. The outcome will depend less on the technology itself than on how well it fits into the systems meant to use it.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: SAP and Fresenius to build sovereign AI backbone for healthcare&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/gates-foundation-and-openai-test-ai-in-african-healthcare/</guid><pubDate>Thu, 22 Jan 2026 10:00:00 +0000</pubDate></item><item><title>[NEW] Why 2026 is a hot year for lithium (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/22/1131563/lithium-2026/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/GettyImages-872586396.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;In 2026, I’m going to be closely watching the price of lithium.&lt;/p&gt;  &lt;p&gt;If you’re not in the habit of obsessively tracking commodity markets, I certainly don’t blame you. (Though the news lately definitely makes the case that minerals can have major implications for global politics and the economy.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But lithium is worthy of a close look right now.&lt;/p&gt;  &lt;p&gt;The metal is crucial for lithium-ion batteries used in phones and laptops, electric vehicles, and large-scale energy storage arrays on the grid. Prices have been on quite the roller coaster over the last few years, and they’re ticking up again after a low period. What happens next could have big implications for mining and battery technology.&lt;/p&gt; 
 &lt;p&gt;Before we look ahead, let’s take a quick trip down memory lane. In 2020, global EV sales started to really take off, driving up demand for the lithium used in their batteries. Because of that growing demand and a limited supply, prices shot up dramatically, with lithium carbonate going from under $10 per kilogram to a high of roughly $70 per kilogram in just two years.&lt;/p&gt;  &lt;p&gt;And the tech world took notice. During those high points, there was a ton of interest in developing alternative batteries that didn’t rely on lithium. I was writing about sodium-based batteries, iron-air batteries, and even experimental ones that were made with plastic.&lt;/p&gt; 
 &lt;p&gt;Researchers and startups were also hunting for alternative ways to get lithium, including battery recycling and processing methods like direct lithium extraction (more on this in a moment).&lt;/p&gt;  &lt;p&gt;But soon, prices crashed back down to earth. We saw lower-than-expected demand for EVs in the US, and developers ramped up mining and processing to meet demand. Through late 2024 and 2025, lithium carbonate was back around $10 a kilogram again. Avoiding lithium or finding new ways to get it suddenly looked a lot less crucial.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;That brings us to today: lithium prices are ticking up again. So far, it’s nowhere close to the dramatic rise we saw a few years ago, but analysts are watching closely. Strong EV growth in China is playing a major role—EVs still make up about 75% of battery demand today. But growth in stationary storage, batteries for the grid, is also contributing to rising demand for lithium in both China and the US.&lt;/p&gt;  &lt;p&gt;Higher prices could create new opportunities. The possibilities include alternative battery chemistries, specifically sodium-ion batteries, says Evelina Stoikou, head of battery technologies and supply chains at BloombergNEF. (I’ll note here that we recently named sodium-ion batteries to our 2026 list of 10 Breakthrough Technologies.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;It’s not just batteries, though. Another industry that could see big changes from a lithium price swing: extraction.&lt;/p&gt;  &lt;p&gt;Today, most lithium is mined from rocks, largely in Australia, before being shipped to China for processing. There’s a growing effort to process the mineral in other places, though, as countries try to create their own lithium supply chains. Tesla recently confirmed that it’s started production at its lithium refinery in Texas, which broke ground in 2023. We could see more investment in processing plants outside China if prices continue to climb.&lt;/p&gt;  &lt;p&gt;This could also be a key year for direct lithium extraction, as Katie Brigham wrote in a recent story for &lt;em&gt;Heatmap&lt;/em&gt;. That technology uses chemical or electrochemical processes to extract lithium from brine (salty water that’s usually sourced from salt lakes or underground reservoirs), quickly and cheaply. Companies including Lilac Solutions, Standard Lithium, and Rio Tinto are all making plans or starting construction on commercial facilities this year in the US and Argentina.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;If there’s anything I’ve learned about following batteries and minerals over the past few years, it’s that predicting the future is impossible. But if you’re looking for tea leaves to read, lithium prices deserve a look.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/GettyImages-872586396.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;In 2026, I’m going to be closely watching the price of lithium.&lt;/p&gt;  &lt;p&gt;If you’re not in the habit of obsessively tracking commodity markets, I certainly don’t blame you. (Though the news lately definitely makes the case that minerals can have major implications for global politics and the economy.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But lithium is worthy of a close look right now.&lt;/p&gt;  &lt;p&gt;The metal is crucial for lithium-ion batteries used in phones and laptops, electric vehicles, and large-scale energy storage arrays on the grid. Prices have been on quite the roller coaster over the last few years, and they’re ticking up again after a low period. What happens next could have big implications for mining and battery technology.&lt;/p&gt; 
 &lt;p&gt;Before we look ahead, let’s take a quick trip down memory lane. In 2020, global EV sales started to really take off, driving up demand for the lithium used in their batteries. Because of that growing demand and a limited supply, prices shot up dramatically, with lithium carbonate going from under $10 per kilogram to a high of roughly $70 per kilogram in just two years.&lt;/p&gt;  &lt;p&gt;And the tech world took notice. During those high points, there was a ton of interest in developing alternative batteries that didn’t rely on lithium. I was writing about sodium-based batteries, iron-air batteries, and even experimental ones that were made with plastic.&lt;/p&gt; 
 &lt;p&gt;Researchers and startups were also hunting for alternative ways to get lithium, including battery recycling and processing methods like direct lithium extraction (more on this in a moment).&lt;/p&gt;  &lt;p&gt;But soon, prices crashed back down to earth. We saw lower-than-expected demand for EVs in the US, and developers ramped up mining and processing to meet demand. Through late 2024 and 2025, lithium carbonate was back around $10 a kilogram again. Avoiding lithium or finding new ways to get it suddenly looked a lot less crucial.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;That brings us to today: lithium prices are ticking up again. So far, it’s nowhere close to the dramatic rise we saw a few years ago, but analysts are watching closely. Strong EV growth in China is playing a major role—EVs still make up about 75% of battery demand today. But growth in stationary storage, batteries for the grid, is also contributing to rising demand for lithium in both China and the US.&lt;/p&gt;  &lt;p&gt;Higher prices could create new opportunities. The possibilities include alternative battery chemistries, specifically sodium-ion batteries, says Evelina Stoikou, head of battery technologies and supply chains at BloombergNEF. (I’ll note here that we recently named sodium-ion batteries to our 2026 list of 10 Breakthrough Technologies.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;It’s not just batteries, though. Another industry that could see big changes from a lithium price swing: extraction.&lt;/p&gt;  &lt;p&gt;Today, most lithium is mined from rocks, largely in Australia, before being shipped to China for processing. There’s a growing effort to process the mineral in other places, though, as countries try to create their own lithium supply chains. Tesla recently confirmed that it’s started production at its lithium refinery in Texas, which broke ground in 2023. We could see more investment in processing plants outside China if prices continue to climb.&lt;/p&gt;  &lt;p&gt;This could also be a key year for direct lithium extraction, as Katie Brigham wrote in a recent story for &lt;em&gt;Heatmap&lt;/em&gt;. That technology uses chemical or electrochemical processes to extract lithium from brine (salty water that’s usually sourced from salt lakes or underground reservoirs), quickly and cheaply. Companies including Lilac Solutions, Standard Lithium, and Rio Tinto are all making plans or starting construction on commercial facilities this year in the US and Argentina.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;If there’s anything I’ve learned about following batteries and minerals over the past few years, it’s that predicting the future is impossible. But if you’re looking for tea leaves to read, lithium prices deserve a look.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/22/1131563/lithium-2026/</guid><pubDate>Thu, 22 Jan 2026 11:00:00 +0000</pubDate></item><item><title>[NEW] Former Google trio is building an interactive AI-powered learning app for kids (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/former-google-trio-is-building-an-interactive-ai-powered-learning-app-for-kids/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Big tech companies and upcoming startups want to use generative AI to build software and hardware for kids. A lot of those experiences are limited to text or voice, and kids might not find that captivating. Three former Google employees want to get over that hurdle with their generative AI-powered interactive app, Sparkli.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sparkli was founded last year by Lax Poojary, Lucie Marchand, and Myn Kang. As parents, Poojary and Kang were not able to satisfy their children’s curiosity or give engaging answers to their questions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Kids, by definition, are very curious, and my son would ask me questions about how cars work or how it rains. My approach was to use ChatGPT or Gemini to explain these concepts to a six-year-old, but that is still a wall of text. What kids want is an interactive experience. This was our core process behind founding Sparkli,” Poojary told TechCrunch over a call.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084423" height="486" src="https://techcrunch.com/wp-content/uploads/2026/01/Home-Screen.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Sparkli&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Prior to launching Sparkli, Poojary and Kang co-founded a travel aggregator called Touring Bird and a video-focused social commerce app, Shoploop, at Google’s Area 120, the company’s internal startup incubator. Poojary later went on to work at Google and YouTube on shopping. Marchand, who is the CTO of Sparkli, was also one of the co-founders of Shoploop and later worked at Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When a kid asked what Mars looks like fifty years ago, we might have shown them a picture,” said Poojary. “Ten years ago, we might have shown them a video. With Sparkli, we want kids to interact and experience what Mars is like.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup said that education systems often fall behind in teaching modern concepts. Sparkli wants to teach kids about topics like skills design, financial literacy, and entrepreneurship by creating an AI-powered learning “expedition.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app lets users explore some predefined topics in different categories or ask their own questions to create a learning path. The app also highlights one new topic every day to let kids learn something new. Kids can either listen to the generated voice or read the text. Chapters under one topic include a mix of audio, video, images, quizzes, and games. The app also creates choose-as-you-go adventures that don’t create the pressure of getting questions right or wrong.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084427" height="486" src="https://techcrunch.com/wp-content/uploads/2026/01/Simulator.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Sparkli&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Poojary mentioned that the startup uses generative AI to create all of its media assets on the fly. The company can create a learning experience within two minutes of a user asking a question, and it is trying to reduce this time further. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup mentioned that while AI assistants can help children learn certain topics, their focus is not on education. It said that to make its product effective, the first two hires were a PhD holder in educational science and AI, and a teacher. This was a conscious decision to ensure its content better serves children, keeping principals of pedagogy in mind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the key concerns around kids using AI is safety. Companies like OpenAI and Character.ai are facing lawsuits from parents who allege that these tools encouraged their children to self-harm. Sparkli said that while certain topics like sexual content are completely banned on the app, when a child asks about topics like self-harm, the app tries to teach them about emotional intelligence and encourages them to talk to their parents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is piloting its app with an institute that has a network of schools with over 100,000 students. Currently, its target audience is children aged 5-12, and it has tested its product in over 20 schools last year.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Sparkli has also built a teacher module that allows teachers to track progress and assign homework to kids. The company said that it was inspired by Duolingo to make the app engaging enough that kids can learn concepts and also feel like coming back to the app frequently. The app has streaks and rewards for kids for completing lessons regularly. It also gives kids quest cards, based on the initial avatar they have set up, for learning different topics.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have seen a very positive response from our school pilots. Teachers often use Sparkli to create expeditions that kids can explore at the start of the class and lead them into a more discussion-based format. Some teachers also used it to create [homework] after they explain a topic to let kids explore further and get a measure of their understanding,” Poojary said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the startup wants to primarily work with schools globally for the next few months, it wants to open up consumer access and let parents download the app by mid-2026. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has raised $5 million in pre-seed funding led by Swiss venture firm Founderful. Sparkli is Founderful’s first pure-play edtech investment. The firm’s founding partner, Lukas Wender, said that the team’s technical skill and market opportunity nudged him to invest in the startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As a father of two kids who are in school now, I see them learning interesting stuff, but they don’t learn topics like financial literacy or innovation in technology. I thought from a product point of view, Sparkli gets them away from video games and lets them learn stuff in an immersive way,” Wender said.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Big tech companies and upcoming startups want to use generative AI to build software and hardware for kids. A lot of those experiences are limited to text or voice, and kids might not find that captivating. Three former Google employees want to get over that hurdle with their generative AI-powered interactive app, Sparkli.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sparkli was founded last year by Lax Poojary, Lucie Marchand, and Myn Kang. As parents, Poojary and Kang were not able to satisfy their children’s curiosity or give engaging answers to their questions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Kids, by definition, are very curious, and my son would ask me questions about how cars work or how it rains. My approach was to use ChatGPT or Gemini to explain these concepts to a six-year-old, but that is still a wall of text. What kids want is an interactive experience. This was our core process behind founding Sparkli,” Poojary told TechCrunch over a call.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084423" height="486" src="https://techcrunch.com/wp-content/uploads/2026/01/Home-Screen.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Sparkli&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Prior to launching Sparkli, Poojary and Kang co-founded a travel aggregator called Touring Bird and a video-focused social commerce app, Shoploop, at Google’s Area 120, the company’s internal startup incubator. Poojary later went on to work at Google and YouTube on shopping. Marchand, who is the CTO of Sparkli, was also one of the co-founders of Shoploop and later worked at Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When a kid asked what Mars looks like fifty years ago, we might have shown them a picture,” said Poojary. “Ten years ago, we might have shown them a video. With Sparkli, we want kids to interact and experience what Mars is like.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup said that education systems often fall behind in teaching modern concepts. Sparkli wants to teach kids about topics like skills design, financial literacy, and entrepreneurship by creating an AI-powered learning “expedition.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app lets users explore some predefined topics in different categories or ask their own questions to create a learning path. The app also highlights one new topic every day to let kids learn something new. Kids can either listen to the generated voice or read the text. Chapters under one topic include a mix of audio, video, images, quizzes, and games. The app also creates choose-as-you-go adventures that don’t create the pressure of getting questions right or wrong.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084427" height="486" src="https://techcrunch.com/wp-content/uploads/2026/01/Simulator.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Sparkli&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Poojary mentioned that the startup uses generative AI to create all of its media assets on the fly. The company can create a learning experience within two minutes of a user asking a question, and it is trying to reduce this time further. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup mentioned that while AI assistants can help children learn certain topics, their focus is not on education. It said that to make its product effective, the first two hires were a PhD holder in educational science and AI, and a teacher. This was a conscious decision to ensure its content better serves children, keeping principals of pedagogy in mind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the key concerns around kids using AI is safety. Companies like OpenAI and Character.ai are facing lawsuits from parents who allege that these tools encouraged their children to self-harm. Sparkli said that while certain topics like sexual content are completely banned on the app, when a child asks about topics like self-harm, the app tries to teach them about emotional intelligence and encourages them to talk to their parents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is piloting its app with an institute that has a network of schools with over 100,000 students. Currently, its target audience is children aged 5-12, and it has tested its product in over 20 schools last year.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Sparkli has also built a teacher module that allows teachers to track progress and assign homework to kids. The company said that it was inspired by Duolingo to make the app engaging enough that kids can learn concepts and also feel like coming back to the app frequently. The app has streaks and rewards for kids for completing lessons regularly. It also gives kids quest cards, based on the initial avatar they have set up, for learning different topics.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have seen a very positive response from our school pilots. Teachers often use Sparkli to create expeditions that kids can explore at the start of the class and lead them into a more discussion-based format. Some teachers also used it to create [homework] after they explain a topic to let kids explore further and get a measure of their understanding,” Poojary said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the startup wants to primarily work with schools globally for the next few months, it wants to open up consumer access and let parents download the app by mid-2026. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has raised $5 million in pre-seed funding led by Swiss venture firm Founderful. Sparkli is Founderful’s first pure-play edtech investment. The firm’s founding partner, Lukas Wender, said that the team’s technical skill and market opportunity nudged him to invest in the startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As a father of two kids who are in school now, I see them learning interesting stuff, but they don’t learn topics like financial literacy or innovation in technology. I thought from a product point of view, Sparkli gets them away from video games and lets them learn stuff in an immersive way,” Wender said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/former-google-trio-is-building-an-interactive-ai-powered-learning-app-for-kids/</guid><pubDate>Thu, 22 Jan 2026 11:00:00 +0000</pubDate></item></channel></rss>