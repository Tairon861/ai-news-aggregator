<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 26 Feb 2026 07:03:59 +0000</lastBuildDate><item><title>Wearable startup CUDIS launches a new health ring line with an AI-fueled ‘coach’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/25/wearable-startup-cudis-launches-a-new-health-ring-line-with-an-ai-fueled-coach/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/CUDIS-002-Sporty-05.png?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Wearables startup CUDIS is launching its newest series of health rings this week. The updated ring comes equipped with a number of features, including an AI “agent coach” designed to keep users on track to attain their fitness goals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CUDIS says it differentiates itself from other wearables by not just delivering health metrics but also incentivizing healthy behavior through a points system. Users garner digital “health points” for healthy behaviors — things like daily sleep, 10,000 steps every&amp;nbsp;day, sports activities, and conversations with the ring’s AI coach — which can then be redeemed through an integrated marketplace for discounts on health supplements and other products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The ring’s AI Agent Coach, meanwhile, is designed to leverage generative AI to aid with healthy programs for exercise and daily health. The company says that its agent&amp;nbsp;generates tailored programs including “daily tasks, recovery protocols, supplement recommendations, and direct referrals to licensed medical professionals.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ring also tracks a host of body metrics and daily behaviors, such as sleep quality, stress management, movement, and recovery. This helps them see how these metrics affect their Pace of Aging (PoA), showing whether their body is aging faster or slower than their chronological age, the company explains.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CUDIS CEO and co-founder Edison Chen told TechCrunch that since his company’s first wearable was launched in 2024, the company has sold over 30,000 units across its first two models. The app’s user base has also grown to 250,000 users across 103 countries, he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our strongest markets so far have been North America, Europe, and Asia,” Chen said. “What we’re good at is pattern recognition for healthy people trying to optimize,” Chen told TechCrunch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The AI spots when you’re trending in the wrong direction, such as chronic poor sleep, declining HRV, elevated resting heart rate, and either suggests lifestyle changes or connects you to a professional.&amp;nbsp;The control is in the escalation pathway to the right care&amp;nbsp;access,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company claims that it keeps user data encrypted and secure via the Solana blockchain. It has previously been described as a “web3 AI wellness company.” (TechCrunch was not able to test the smart ring directly to verify its security claims.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CUDIS announced $5 million of seed funding in 2024. The round was led by Draper Associates and included a number of other investors, including a number of blockchain-associated investor groups like Skybridge, DraperDragon, Monke Ventures, and Foresight Ventures, among others. The company also plans to launch a Kickstarter soon.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/CUDIS-002-Sporty-05.png?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Wearables startup CUDIS is launching its newest series of health rings this week. The updated ring comes equipped with a number of features, including an AI “agent coach” designed to keep users on track to attain their fitness goals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CUDIS says it differentiates itself from other wearables by not just delivering health metrics but also incentivizing healthy behavior through a points system. Users garner digital “health points” for healthy behaviors — things like daily sleep, 10,000 steps every&amp;nbsp;day, sports activities, and conversations with the ring’s AI coach — which can then be redeemed through an integrated marketplace for discounts on health supplements and other products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The ring’s AI Agent Coach, meanwhile, is designed to leverage generative AI to aid with healthy programs for exercise and daily health. The company says that its agent&amp;nbsp;generates tailored programs including “daily tasks, recovery protocols, supplement recommendations, and direct referrals to licensed medical professionals.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ring also tracks a host of body metrics and daily behaviors, such as sleep quality, stress management, movement, and recovery. This helps them see how these metrics affect their Pace of Aging (PoA), showing whether their body is aging faster or slower than their chronological age, the company explains.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CUDIS CEO and co-founder Edison Chen told TechCrunch that since his company’s first wearable was launched in 2024, the company has sold over 30,000 units across its first two models. The app’s user base has also grown to 250,000 users across 103 countries, he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our strongest markets so far have been North America, Europe, and Asia,” Chen said. “What we’re good at is pattern recognition for healthy people trying to optimize,” Chen told TechCrunch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The AI spots when you’re trending in the wrong direction, such as chronic poor sleep, declining HRV, elevated resting heart rate, and either suggests lifestyle changes or connects you to a professional.&amp;nbsp;The control is in the escalation pathway to the right care&amp;nbsp;access,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company claims that it keeps user data encrypted and secure via the Solana blockchain. It has previously been described as a “web3 AI wellness company.” (TechCrunch was not able to test the smart ring directly to verify its security claims.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CUDIS announced $5 million of seed funding in 2024. The round was led by Draper Associates and included a number of other investors, including a number of blockchain-associated investor groups like Skybridge, DraperDragon, Monke Ventures, and Foresight Ventures, among others. The company also plans to launch a Kickstarter soon.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/25/wearable-startup-cudis-launches-a-new-health-ring-line-with-an-ai-fueled-coach/</guid><pubDate>Wed, 25 Feb 2026 19:10:04 +0000</pubDate></item><item><title>Mixing generative AI with physics to create personal items that work in the real world (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/mixing-ai-with-physics-to-create-personal-items-0225</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/PhysiOpt%20%281%29_0.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-9038cddb-7fff-ba3f-8738-0c541d247fad"&gt;Have you ever had an idea for something that looked cool, but wouldn’t work well in practice? When it comes to designing things like decor and personal accessories, generative artificial intelligence (genAI) models can relate. They can produce creative and elaborate 3D designs, but when you try to fabricate such blueprints into real-world objects, they usually don’t sustain everyday use.&lt;/p&gt;&lt;p&gt;The underlying problem is that genAI models often lack an understanding of physics. While tools like Microsoft’s&amp;nbsp;TRELLIS system can create a 3D model from a text prompt or image, its design for a chair, for example, may be unstable, or have disconnected parts. The model doesn’t fully understand what your intended object is designed to do, so even if your seat can be 3D printed, it would likely fall apart under the force of someone sitting down.&lt;/p&gt;&lt;p dir="ltr"&gt;In an attempt to make these designs work in the real world, researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) are giving generative AI models a reality check. Their “PhysiOpt” system augments these tools with physics simulations, making blueprints for personal items such as cups, keyholders, and bookends work as intended when they’re 3D printed. It rapidly tests if the structure of your 3D model is viable, gently modifying smaller shapes while ensuring the overall appearance and function of the design is preserved.&lt;/p&gt;&lt;p dir="ltr"&gt;You can simply type what you want to create and what it’ll be used for into PhysiOpt, or upload an image to the system’s user interface, and in roughly half a minute, you’ll get a realistic 3D object to fabricate. For example, CSAIL researchers prompted it to generate a “flamingo-shaped glass for drinking,” which they 3D printed into a drinking glass with a handle and base resembling the tropical bird’s leg. As the design was generated, PhysiOpt made tiny refinements to ensure the design was structurally sound.&lt;/p&gt;&lt;p&gt;“PhysiOpt combines GenAI and physically-based shape optimization, helping virtually anyone generate the designs they want for unique accessories and decorations,” says MIT electrical engineering and computer science (EECS) PhD student and CSAIL researcher Xiao Sean Zhan SM ’25, who is a co-lead author on a&amp;nbsp;paper presenting the work. “It’s an automatic system that allows you to make the shape physically manufacturable, given some constraints. PhysiOpt can iterate on its creations as often as you’d like, without any extra training.”&lt;/p&gt;&lt;p dir="ltr"&gt;This approach enables you to create a “smart design,” where the AI generator crafts your item based on users’ specifications, while considering functionality. You can plug in your favorite 3D generative AI model, and after typing out what you want to generate, you specify how much force or weight the object should handle. It’s a neat way to simulate real-world use, such as predicting whether a hook will be strong enough to hold up your coat. Users also specify what materials they’ll fabricate the item with (such as plastics or wood), and how it’s supported — for instance, a cup stands on the ground, whereas a bookend leans against a collection of books.&lt;/p&gt;&lt;p dir="ltr"&gt;Given the specifics, PhysiOpt begins to iteratively optimize the object. Under the hood, it runs a physics simulation called a “finite element analysis” to stress test the design. This comprehensive scan provides a heat map over your 3D model, which indicates where your blueprint isn’t well-supported. If you were generating, say, a birdhouse, you may find that the support beams under the house were colored bright red, meaning the house will crumble if it’s not reinforced.&lt;/p&gt;&lt;p dir="ltr"&gt;PhysiOpt can create even bolder pieces. Researchers saw this versatility firsthand when they fabricated a steampunk (a style that blends Victorian and futuristic aesthetics) keyholder featuring intricate, robotic-looking hooks, and a “giraffe table” with a flat back that you can place items on. But how did it know what “steampunk” is, or even how such a unique piece of furniture should look?&lt;/p&gt;&lt;p&gt;Remarkably, the answer isn’t extensive training — at least, not from the researchers. Instead, PhysiOpt uses a pre-trained model that’s already seen thousands of shapes and objects. “Existing systems often need lots of additional training to have a semantic understanding of what you want to see,” adds co-lead author Clément Jambon, who is also an MIT EECS PhD student and CSAIL researcher. “But we use a model with that feel for what you want to create already baked in, so PhysiOpt is training-free.”&lt;/p&gt;&lt;p dir="ltr"&gt;By working with a pre-trained model, PhysiOpt can use “shape priors,” or knowledge of how shapes should look based on earlier training, to generate what users want to see. It’s sort of like an artist recreating the style of a famous painter. Their expertise is rooted in closely studying a variety of artistic approaches, so they’ll likely be able to mirror that particular aesthetic. Likewise, a pre-trained model’s familiarity with shapes helps it generate 3D models.&lt;/p&gt;&lt;p dir="ltr"&gt;CSAIL researchers observed that PhysiOpt’s visual know-how helped it create 3D models more efficiently than&amp;nbsp;“DiffIPC,” a comparable method that simulates and optimizes shapes. When both approaches were tasked with generating 3D designs for items like chairs, CSAIL’s system was nearly 10 times faster per iteration, while creating more realistic objects.&lt;/p&gt;&lt;p dir="ltr"&gt;PhysiOpt presents a potential bridge between ideas and real-world personal items. What you may think is a great idea for a coffee mug, for instance, could soon make the jump from your computer screen to your desk. And while PhysiOpt already does the stress-testing for designers, it may soon be able to predict constraints such as loads and boundaries, instead of users needing to provide those details. This more autonomous, common-sense approach could be made possible by incorporating vision language models, which combine an understanding of human language with computer vision.&lt;/p&gt;&lt;p dir="ltr"&gt;What’s more, Zhan and Jambon intend to remove the artifacts, or random fragments that occasionally appear in PhysiOpt’s 3D models, by making the system even more physics-aware. The MIT scientists are also considering how they can model more complex constraints for various fabrication techniques, such as minimizing overhanging components for 3D printing.&lt;/p&gt;&lt;p&gt;Zhan and Jambon wrote their paper with MIT-IBM Watson AI Lab Principal Research Scientist Kenney Ng ’89, SM ’90, PhD ’00 and two CSAIL colleagues: undergraduate researcher Evan Thompson and Assistant Professor Mina Konaković Luković, who is a principal investigator at the lab.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The researchers’ work was supported, in part, by the MIT-IBM Watson AI Laboratory and the Wistron Corp. They presented it in December at the Association for Computing Machinery’s SIGGRAPH Conference and Exhibition on Computer Graphics and Interactive Techniques in Asia.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/PhysiOpt%20%281%29_0.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-9038cddb-7fff-ba3f-8738-0c541d247fad"&gt;Have you ever had an idea for something that looked cool, but wouldn’t work well in practice? When it comes to designing things like decor and personal accessories, generative artificial intelligence (genAI) models can relate. They can produce creative and elaborate 3D designs, but when you try to fabricate such blueprints into real-world objects, they usually don’t sustain everyday use.&lt;/p&gt;&lt;p&gt;The underlying problem is that genAI models often lack an understanding of physics. While tools like Microsoft’s&amp;nbsp;TRELLIS system can create a 3D model from a text prompt or image, its design for a chair, for example, may be unstable, or have disconnected parts. The model doesn’t fully understand what your intended object is designed to do, so even if your seat can be 3D printed, it would likely fall apart under the force of someone sitting down.&lt;/p&gt;&lt;p dir="ltr"&gt;In an attempt to make these designs work in the real world, researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) are giving generative AI models a reality check. Their “PhysiOpt” system augments these tools with physics simulations, making blueprints for personal items such as cups, keyholders, and bookends work as intended when they’re 3D printed. It rapidly tests if the structure of your 3D model is viable, gently modifying smaller shapes while ensuring the overall appearance and function of the design is preserved.&lt;/p&gt;&lt;p dir="ltr"&gt;You can simply type what you want to create and what it’ll be used for into PhysiOpt, or upload an image to the system’s user interface, and in roughly half a minute, you’ll get a realistic 3D object to fabricate. For example, CSAIL researchers prompted it to generate a “flamingo-shaped glass for drinking,” which they 3D printed into a drinking glass with a handle and base resembling the tropical bird’s leg. As the design was generated, PhysiOpt made tiny refinements to ensure the design was structurally sound.&lt;/p&gt;&lt;p&gt;“PhysiOpt combines GenAI and physically-based shape optimization, helping virtually anyone generate the designs they want for unique accessories and decorations,” says MIT electrical engineering and computer science (EECS) PhD student and CSAIL researcher Xiao Sean Zhan SM ’25, who is a co-lead author on a&amp;nbsp;paper presenting the work. “It’s an automatic system that allows you to make the shape physically manufacturable, given some constraints. PhysiOpt can iterate on its creations as often as you’d like, without any extra training.”&lt;/p&gt;&lt;p dir="ltr"&gt;This approach enables you to create a “smart design,” where the AI generator crafts your item based on users’ specifications, while considering functionality. You can plug in your favorite 3D generative AI model, and after typing out what you want to generate, you specify how much force or weight the object should handle. It’s a neat way to simulate real-world use, such as predicting whether a hook will be strong enough to hold up your coat. Users also specify what materials they’ll fabricate the item with (such as plastics or wood), and how it’s supported — for instance, a cup stands on the ground, whereas a bookend leans against a collection of books.&lt;/p&gt;&lt;p dir="ltr"&gt;Given the specifics, PhysiOpt begins to iteratively optimize the object. Under the hood, it runs a physics simulation called a “finite element analysis” to stress test the design. This comprehensive scan provides a heat map over your 3D model, which indicates where your blueprint isn’t well-supported. If you were generating, say, a birdhouse, you may find that the support beams under the house were colored bright red, meaning the house will crumble if it’s not reinforced.&lt;/p&gt;&lt;p dir="ltr"&gt;PhysiOpt can create even bolder pieces. Researchers saw this versatility firsthand when they fabricated a steampunk (a style that blends Victorian and futuristic aesthetics) keyholder featuring intricate, robotic-looking hooks, and a “giraffe table” with a flat back that you can place items on. But how did it know what “steampunk” is, or even how such a unique piece of furniture should look?&lt;/p&gt;&lt;p&gt;Remarkably, the answer isn’t extensive training — at least, not from the researchers. Instead, PhysiOpt uses a pre-trained model that’s already seen thousands of shapes and objects. “Existing systems often need lots of additional training to have a semantic understanding of what you want to see,” adds co-lead author Clément Jambon, who is also an MIT EECS PhD student and CSAIL researcher. “But we use a model with that feel for what you want to create already baked in, so PhysiOpt is training-free.”&lt;/p&gt;&lt;p dir="ltr"&gt;By working with a pre-trained model, PhysiOpt can use “shape priors,” or knowledge of how shapes should look based on earlier training, to generate what users want to see. It’s sort of like an artist recreating the style of a famous painter. Their expertise is rooted in closely studying a variety of artistic approaches, so they’ll likely be able to mirror that particular aesthetic. Likewise, a pre-trained model’s familiarity with shapes helps it generate 3D models.&lt;/p&gt;&lt;p dir="ltr"&gt;CSAIL researchers observed that PhysiOpt’s visual know-how helped it create 3D models more efficiently than&amp;nbsp;“DiffIPC,” a comparable method that simulates and optimizes shapes. When both approaches were tasked with generating 3D designs for items like chairs, CSAIL’s system was nearly 10 times faster per iteration, while creating more realistic objects.&lt;/p&gt;&lt;p dir="ltr"&gt;PhysiOpt presents a potential bridge between ideas and real-world personal items. What you may think is a great idea for a coffee mug, for instance, could soon make the jump from your computer screen to your desk. And while PhysiOpt already does the stress-testing for designers, it may soon be able to predict constraints such as loads and boundaries, instead of users needing to provide those details. This more autonomous, common-sense approach could be made possible by incorporating vision language models, which combine an understanding of human language with computer vision.&lt;/p&gt;&lt;p dir="ltr"&gt;What’s more, Zhan and Jambon intend to remove the artifacts, or random fragments that occasionally appear in PhysiOpt’s 3D models, by making the system even more physics-aware. The MIT scientists are also considering how they can model more complex constraints for various fabrication techniques, such as minimizing overhanging components for 3D printing.&lt;/p&gt;&lt;p&gt;Zhan and Jambon wrote their paper with MIT-IBM Watson AI Lab Principal Research Scientist Kenney Ng ’89, SM ’90, PhD ’00 and two CSAIL colleagues: undergraduate researcher Evan Thompson and Assistant Professor Mina Konaković Luković, who is a principal investigator at the lab.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The researchers’ work was supported, in part, by the MIT-IBM Watson AI Laboratory and the Wistron Corp. They presented it in December at the Association for Computing Machinery’s SIGGRAPH Conference and Exhibition on Computer Graphics and Interactive Techniques in Asia.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/mixing-ai-with-physics-to-create-personal-items-0225</guid><pubDate>Wed, 25 Feb 2026 19:40:00 +0000</pubDate></item><item><title>Alphabet-owned robotics software company Intrinsic joins Google (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/25/alphabet-owned-robotics-software-company-intrinsic-joins-google/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Intrinsic.jpg?resize=1200,1108" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is moving further into physical AI by bringing a familiar robotics software platform under its wing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alphabet-owned Intrinsic, which builds AI models and software designed to make industrial robots more accessible, is joining Google, the companies announced on Wednesday. Intrinsic will remain a distinct entity within Google but will work closely with Google DeepMind and will tap into Google’s Gemini AI models and cloud services.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Alphabet declined to share information regarding funding or purchase price.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intrinsic “graduated” into an independent Alphabet-owned company in 2021 after five years of development within Alphabet’s X, the company’s moonshot research division. Other companies that have graduated from X include robotaxi company Waymo and drone delivery company Wing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wendy Tan White has served as Intrinsic’s CEO since its spinout in 2021.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company hit the ground running. A few months after announcing its independence, Intrinsic acquired Vicarious, a fellow robotics software company, in April 2022. While the purchase price wasn’t disclosed, Vicarious had raised about $250 million from VCs and tech bigwigs like Jeff Bezos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A few months later, Intrinsic acquired several for-profit divisions of Open Robotics, a nonprofit organization that builds hardware and software platforms for the robotics industry.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Despite this rapid expansion, Intrinsic laid off 20% of its workforce in January 2023.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company announced its first product, Flowstate, just a few months later. Flowstate is a software platform for developing robotics workflows aimed at developers that don’t have deep robotics experience — aligning with the company’s mission to make robotics more accessible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since then, the company has fine-tuned the technology, improved its simulation capabilities, and released its Intrinsic Vision AI model in late 2025.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Intrinsic announced a joint venture with electronics manufacturer Foxconn in October 2025 that entails the two companies working together on general-purpose intelligent robots to transform how electronics are manufactured, with the goal of full factory automation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, the company is working toward those goals with closer collaboration with Google’s AI prowess.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Combined with Google’s incredible AI and infrastructure, we’re going to unlock the promise of physical AI for a much broader set of manufacturing businesses and developers. This will fundamentally shift production, from its economics to operations, and enable truly advanced manufacturing,” Tan White wrote in the company’s blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This move makes a lot of sense for Google, as many tech leaders, including Nvidia’s Jensen Huang and Qualcomm’s Cristiano Amon, see physical AI as the next natural step in the monetization and advancement of AI models and technology.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Intrinsic.jpg?resize=1200,1108" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is moving further into physical AI by bringing a familiar robotics software platform under its wing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alphabet-owned Intrinsic, which builds AI models and software designed to make industrial robots more accessible, is joining Google, the companies announced on Wednesday. Intrinsic will remain a distinct entity within Google but will work closely with Google DeepMind and will tap into Google’s Gemini AI models and cloud services.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Alphabet declined to share information regarding funding or purchase price.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intrinsic “graduated” into an independent Alphabet-owned company in 2021 after five years of development within Alphabet’s X, the company’s moonshot research division. Other companies that have graduated from X include robotaxi company Waymo and drone delivery company Wing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wendy Tan White has served as Intrinsic’s CEO since its spinout in 2021.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company hit the ground running. A few months after announcing its independence, Intrinsic acquired Vicarious, a fellow robotics software company, in April 2022. While the purchase price wasn’t disclosed, Vicarious had raised about $250 million from VCs and tech bigwigs like Jeff Bezos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A few months later, Intrinsic acquired several for-profit divisions of Open Robotics, a nonprofit organization that builds hardware and software platforms for the robotics industry.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Despite this rapid expansion, Intrinsic laid off 20% of its workforce in January 2023.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company announced its first product, Flowstate, just a few months later. Flowstate is a software platform for developing robotics workflows aimed at developers that don’t have deep robotics experience — aligning with the company’s mission to make robotics more accessible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since then, the company has fine-tuned the technology, improved its simulation capabilities, and released its Intrinsic Vision AI model in late 2025.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Intrinsic announced a joint venture with electronics manufacturer Foxconn in October 2025 that entails the two companies working together on general-purpose intelligent robots to transform how electronics are manufactured, with the goal of full factory automation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, the company is working toward those goals with closer collaboration with Google’s AI prowess.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Combined with Google’s incredible AI and infrastructure, we’re going to unlock the promise of physical AI for a much broader set of manufacturing businesses and developers. This will fundamentally shift production, from its economics to operations, and enable truly advanced manufacturing,” Tan White wrote in the company’s blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This move makes a lot of sense for Google, as many tech leaders, including Nvidia’s Jensen Huang and Qualcomm’s Cristiano Amon, see physical AI as the next natural step in the monetization and advancement of AI models and technology.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/25/alphabet-owned-robotics-software-company-intrinsic-joins-google/</guid><pubDate>Wed, 25 Feb 2026 20:00:00 +0000</pubDate></item><item><title>The White House wants AI companies to cover rate hikes. Most have already said they would. (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/25/the-white-house-wants-ai-companies-to-cover-rate-hikes-most-have-already-said-they-would/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-692150220.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The proliferation of AI data centers plugging into the national electrical grid has helped increase consumer electricity prices, driving up the average national electricity price by more than 6% in the last year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s not a good look for the incumbents ahead of this fall’s elections, and President Donald Trump addressed the challenge in his State of the Union speech last night. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’re telling the major tech companies that they have the obligation to provide for their own power needs,” Trump said. “They can build their own power plants as part of their factory, so that no one’s prices will go up.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The  hyperscalers in question don’t need to be told. They have already made public commitments in recent weeks to cover electricity costs by building their own power sources, paying higher rates, or both, part of a broader effort to solve PR problems around data center expansion and win over skeptical communities. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On January 11, Microsoft announced its policy “to ensure that the electricity cost of serving our datacenters is not passed on to residential customers.” On January 26, OpenAI committed to “paying its own way on energy, so that our operations don’t increase your energy prices.” On February 11, Anthropic made the same pledge to “cover electricity price increases that consumers face from our data centers.” Yesterday, Google announced the largest battery project in the world to support a data center in Minnesota.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What these commitments mean in practice, and who will determine which data centers are responsible for which price increases, remains unknown. The White House has not released the text of the proposed pledge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A handshake agreement with Big Tech over data center costs isn’t good enough,” Arizona Democratic Senator Mark Kelly said on social media. “Americans need a guarantee that energy prices won’t soar and communities have a say.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;White House spokesperson Taylor Rodgers said that next week, companies will send representatives to formally sign the pledge at the White House. Amazon, Google, Meta, Microsoft, xAI, Oracle, and OpenAI are reportedly among those set to attend. However, none of the companies have confirmed their attendance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even if tech companies commit to taking on electricity costs, on-site power plants may not be a panacea — they can still have adverse impacts on the surrounding environment, and will stress supply chains for natural gas, turbines, photovoltaics, and batteries, depending on how companies aim to power their compute.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-692150220.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The proliferation of AI data centers plugging into the national electrical grid has helped increase consumer electricity prices, driving up the average national electricity price by more than 6% in the last year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s not a good look for the incumbents ahead of this fall’s elections, and President Donald Trump addressed the challenge in his State of the Union speech last night. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’re telling the major tech companies that they have the obligation to provide for their own power needs,” Trump said. “They can build their own power plants as part of their factory, so that no one’s prices will go up.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The  hyperscalers in question don’t need to be told. They have already made public commitments in recent weeks to cover electricity costs by building their own power sources, paying higher rates, or both, part of a broader effort to solve PR problems around data center expansion and win over skeptical communities. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On January 11, Microsoft announced its policy “to ensure that the electricity cost of serving our datacenters is not passed on to residential customers.” On January 26, OpenAI committed to “paying its own way on energy, so that our operations don’t increase your energy prices.” On February 11, Anthropic made the same pledge to “cover electricity price increases that consumers face from our data centers.” Yesterday, Google announced the largest battery project in the world to support a data center in Minnesota.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What these commitments mean in practice, and who will determine which data centers are responsible for which price increases, remains unknown. The White House has not released the text of the proposed pledge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A handshake agreement with Big Tech over data center costs isn’t good enough,” Arizona Democratic Senator Mark Kelly said on social media. “Americans need a guarantee that energy prices won’t soar and communities have a say.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;White House spokesperson Taylor Rodgers said that next week, companies will send representatives to formally sign the pledge at the White House. Amazon, Google, Meta, Microsoft, xAI, Oracle, and OpenAI are reportedly among those set to attend. However, none of the companies have confirmed their attendance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even if tech companies commit to taking on electricity costs, on-site power plants may not be a panacea — they can still have adverse impacts on the surrounding environment, and will stress supply chains for natural gas, turbines, photovoltaics, and batteries, depending on how companies aim to power their compute.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/25/the-white-house-wants-ai-companies-to-cover-rate-hikes-most-have-already-said-they-would/</guid><pubDate>Wed, 25 Feb 2026 20:42:14 +0000</pubDate></item><item><title>Roundtables: Why 2026 Is the Year for Sodium-Ion Batteries (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/25/1132873/roundtables-why-2026-is-the-year-for-sodium-ion-batteries/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MITTR-Roundtables-Zoom-Opening-Overlay.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;p&gt;Available only for MIT Alumni and subscribers.&lt;/p&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;strong&gt;Listen to the session or watch below&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-audio"&gt;&lt;audio controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/GMT20260225-180003_Recording.cutfile.20260225202106540.m4a"&gt;&lt;/audio&gt;&lt;/figure&gt;  &lt;p&gt;Sodium-based batteries could be a cheaper, safer alternative to lithium-ion, and the technology is finally making its way into cars—and energy storage arrays on the grid. Sodium-ion batteries are one of MIT Technology Review's &lt;em&gt;10 Breakthrough Technologies of 2026&lt;/em&gt; list, and this subscriber-only discussion explains why. &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Watch a discussion exploring the present moment for sodium-ion batteries—and what’s coming next.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Speakers:&lt;/strong&gt; &lt;strong&gt;Mary Beth Griggs&lt;/strong&gt;, Science Editor;&amp;nbsp;&lt;strong&gt;Casey Crownhart&lt;/strong&gt;, Senior Climate Reporter; and &lt;strong&gt;Caiwei Chen&lt;/strong&gt;, China Reporter&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_3"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;Recorded on February 25, 2026&lt;br /&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Related Stories:&lt;/strong&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MITTR-Roundtables-Zoom-Opening-Overlay.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;p&gt;Available only for MIT Alumni and subscribers.&lt;/p&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;strong&gt;Listen to the session or watch below&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-audio"&gt;&lt;audio controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/GMT20260225-180003_Recording.cutfile.20260225202106540.m4a"&gt;&lt;/audio&gt;&lt;/figure&gt;  &lt;p&gt;Sodium-based batteries could be a cheaper, safer alternative to lithium-ion, and the technology is finally making its way into cars—and energy storage arrays on the grid. Sodium-ion batteries are one of MIT Technology Review's &lt;em&gt;10 Breakthrough Technologies of 2026&lt;/em&gt; list, and this subscriber-only discussion explains why. &lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Watch a discussion exploring the present moment for sodium-ion batteries—and what’s coming next.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Speakers:&lt;/strong&gt; &lt;strong&gt;Mary Beth Griggs&lt;/strong&gt;, Science Editor;&amp;nbsp;&lt;strong&gt;Casey Crownhart&lt;/strong&gt;, Senior Climate Reporter; and &lt;strong&gt;Caiwei Chen&lt;/strong&gt;, China Reporter&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_3"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;Recorded on February 25, 2026&lt;br /&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Related Stories:&lt;/strong&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/25/1132873/roundtables-why-2026-is-the-year-for-sodium-ion-batteries/</guid><pubDate>Wed, 25 Feb 2026 21:15:27 +0000</pubDate></item><item><title>The Galaxy S26 is faster, more expensive, and even more chock-full of AI (AI - Ars Technica)</title><link>https://arstechnica.com/gadgets/2026/02/samsung-reveals-galaxy-s26-lineup-with-privacy-display-and-exclusive-gemini-smarts/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Samsung’s Galaxy S26 series is available for preorder today and ships on March 11.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="S26 lineup" class="absolute inset-0 w-full h-full object-cover hidden" height="356" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_dl2-640x356.jpg" width="640" /&gt;
                  &lt;img alt="S26 lineup" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_dl2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Galaxy S26 lineup doesn't change much on the outside.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samsung

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;There used to be countless companies making flagship Android phones, but a combination of factors has narrowed the field over time. Today, Samsung is the undisputed king of the Android device ecosystem with its Galaxy S line. So we can safely assume today’s Unpacked has revealed the most popular Android phones for the next year—the Galaxy S26 Ultra, Galaxy S26+, and Galaxy S26.&lt;/p&gt;
&lt;p&gt;Samsung didn’t swing for the fences this time around, producing phones with a few cosmetic tweaks and upgraded internals. Meanwhile, Samsung is investing even more in AI, saying the S26 series includes the first “Agentic AI phones.” Despite limited hardware upgrades, the realities of component prices in the age of AI mean the prices of the two cheaper models have gone up by $100 this year. The Ultra remains at an already eye-watering $1,300.&lt;/p&gt;
&lt;h2&gt;Faster and more private&lt;/h2&gt;
&lt;p&gt;Looking at the Galaxy S26 family, you’d be hard-pressed to tell them apart from last year’s phones. The camera surround is different, and the measurements of the smallest and largest phone are ever so slightly different. You probably won’t be able to tell just by looking, but the S26 Ultra has regressed from titanium to aluminum, a reversion Apple also made with its latest high-end phones. This phone also retains its S Pen stylus.&lt;/p&gt;
&lt;div class="table-wrapper"&gt;&lt;table class="specifications right" width="400"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th colspan="4" style="text-align: left;"&gt;Specs at a glance: Samsung Galaxy S26 series&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Galaxy S26 ($900)&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Galaxy S26+ ($1,100)&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Galaxy S26 Ultra ($1,300)&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;SoC&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Snapdragon 8 Elite Gen 5 (3 nm)&lt;/td&gt;
&lt;td&gt;Snapdragon 8 Elite Gen 5 (3 nm)&lt;/td&gt;
&lt;td&gt;Snapdragon 8 Elite Gen 5 (3 nm)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Memory&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;12GB&lt;/td&gt;
&lt;td&gt;12GB&lt;/td&gt;
&lt;td&gt;12GB, 16GB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;256GB, 512GB&lt;/td&gt;
&lt;td&gt;256GB, 512GB&lt;/td&gt;
&lt;td&gt;256GB, 512GB, 1TB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Display&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;6.3-inch OLED, 10-bit color, 2340×1080, 1-120Hz&lt;/td&gt;
&lt;td&gt;6.7-inch OLED, 10-bit color, 3120×1440, 1-120Hz&lt;/td&gt;
&lt;td&gt;6.9-inch OLED, 10-bit color, 3120×1440, 1-120Hz, S Pen support&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Cameras&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;50MP primary, f/1.8, 1.0 μm; 12MP ultrawide, f/2.2, 1.4 μm, 10MP 3x telephoto, f/2.4, 1.0 μm; 12MP selfie, f/2.2, 1.12 μm&lt;/td&gt;
&lt;td&gt;50MP primary, f/1.8, 1.0 μm; 12MP ultrawide, f/2.2, 1.4 μm, 10MP 3x telephoto, f/2.4, 1.0 μm; 12MP selfie, f/2.2, 1.12 μm&lt;/td&gt;
&lt;td&gt;200MP primary, f/1.4, 0.6 μm; 50MP ultrawide, f/1.9, 0.7 μm; 10MP 3x telephoto, f/2.4, 1.12 μm; 50MP 5x telephoto, f/2.9, 0.7 μm; 12MP selfie, f/2.2, 1.12 μm&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Software&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Android 16&lt;/td&gt;
&lt;td&gt;Android 16&lt;/td&gt;
&lt;td&gt;Android 16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Battery&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;4,300 mAh&lt;/td&gt;
&lt;td&gt;4,900 mAh&lt;/td&gt;
&lt;td&gt;5,000 mAh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Connectivity&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Wi-Fi 7, Bluetooth 5.4, USB-C 3.2, Sub6 5G&lt;/td&gt;
&lt;td&gt;Wi-Fi 7, Bluetooth 5.4, USB-C 3.2, Sub6 and mmWave 5G&lt;/td&gt;
&lt;td&gt;Wi-Fi 7, Bluetooth 5.4, USB-C 3.2, Sub6 and mmWave 5G&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Measurements&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;71.7×149.6×7.2 mm, 167g&lt;/td&gt;
&lt;td&gt;75.8×158.4×7.3 mm, 190g&lt;/td&gt;
&lt;td&gt;78.1×163.6×7.9 mm, 214 g&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;These phones will again have the latest Snapdragon flagship processor (in North America, Japan, and China) with customizations exclusive to Samsung. The Snapdragon 8 Elite Gen 5 for Galaxy is a 3 nm chip with third-gen Oryon CPU cores, an Adreno 840 GPU, and a powerful Hexagon NPU for on-device AI processing. Samsung promises double-digit performance gains across the board, which is what we hear every year.&lt;/p&gt;
&lt;p&gt;Samsung flagship phones have extremely fast hardware, so they benchmark well. However, they also tend to heat up and throttle quickly during sustained use. Perhaps that won’t be as much of a problem with the S26 series. Samsung says it has implemented its largest vapor chamber ever to better control temperatures.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The batteries have also been redesigned for greater efficiency and charging speed, but the base model is the only one that saw a capacity boost (4,000 to 4,300 mAh). Charging speeds have gotten a much-needed increase at the Ultra level. Samsung has only said you can now get a 75 percent charge in 30 minutes using its most expensive phone—it peaks at 60 W, up from 45 W for the last Ultra.&lt;/p&gt;
&lt;p&gt;Samsung has been using the same camera sensors for a few cycles now, and it’s not changing anything major this time around. The Ultra still has four cameras (including two telephotos) that top out with the 200 MP primary, and the S26+ and base model still have three cameras with a 50 MP primary. The apertures on the Ultra sensors are a bit wider to allow for brighter photos in challenging conditions. More interesting, though, is the option to record high-quality 8K video directly to an external drive. The S26 also brings support for the Advanced Professional Video (APV) codec.&lt;/p&gt;
&lt;p&gt;While the display specs haven’t changed much, they are home to the phone’s most notable new feature: Privacy Display. As smartphone screens have improved, they have emphasized high brightness and wide viewing angles, which is what you want most of the time. However, that also makes it easy for people nearby to see what’s on your screen. With one tap, the S26 can make it harder for shoulder surfers to see what you’re doing.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-2142568 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="2750" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_dl4-1.jpg" width="4000" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Privacy Display prevents shoulder surfers from peeking at your screen.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samsung

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Privacy Display uses a technology called Black Matrix, which activates “narrow pixels.” These pixels focus light more directly on the user to limit the viewing angle. Privacy Display can be activated system-wide as you like, but it can also be activated on a per-app basis or even just in the part of the screen where notifications appear.&lt;/p&gt;
&lt;h2&gt;What is an Agentic AI phone anyway?&lt;/h2&gt;
&lt;p&gt;Unsurprisingly, AI takes the lead with the S26 launch. Part of that is just Samsung following the zeitgeist, but companies can also add new AI capabilities to fill out spec sheets without a bunch of increasingly expensive hardware upgrades. In Samsung’s words, it has sought to have “AI integrated into every layer” of the Galaxy S26 experience.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That starts with expanded awareness of screen context. The company’s Now Brief feature, which is supposed to pull together useful information from across your apps, has not been very impressive so far. With the S26, Samsung is piping notification content into Now Brief, allowing it to remind you about things even if you never added them to your calendar or to-do list. Like many of Samsung’s Galaxy AI features, this data is processed on-device and won’t go to the cloud.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2142496-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_main6.mp4?_=1" type="video/mp4" /&gt;A Galaxy AI Nudge that helps you select photos.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A Galaxy AI Nudge that helps you select photos.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In a similar vein, Galaxy AI is also getting “Nudges,” which look similar to Google’s Magic Cue on the Pixel 10 series. The Galaxy S26 will be able to suggest content and apps based on what’s happening on the screen. For example, Galaxy AI might see you want to share images and suggest the right ones, or perhaps it will check your calendar for openings to save you from switching apps. Of course, that assumes the AI will correctly recognize the context and call the right action.&lt;/p&gt;
&lt;p&gt;AI features will also be expanding in Samsung’s stock apps. In the Browser, Samsung has partnered with Perplexity for a new “Ask AI” feature. Rather than juggling tabs to read original sources yourself, you can have the AI do it. It basically gives you a research report like you could get from Perplexity itself (or Gemini Deep Research), but it’s integrated with the browser. Samsung’s gallery app also gets expanded AI editing tools with the S26. These capabilities will really allow you to change the substance of photos, so Samsung has added a visible watermark to label them. We’ve asked if there are AI labels in the image metadata, like you get with some other editing systems.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2142569 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="2800" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_dl6.jpg" width="4500" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      AI-edited photos have a visible watermark.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samsung

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;A major component of Samsung’s “Agentic AI phone” pitch comes from a partnership with Google. For starters, Google’s AI-powered scam detection features in the Messaging app, previously exclusive to Pixels, will launch on the S26 in preview before expanding to more devices later. Circle to Search is getting an upgrade that lets it identify multiple objects in a single image—this is in testing on both the Pixel 10 series and the Galaxy S26.&lt;/p&gt;
&lt;p&gt;The other Google tie-in is more in keeping with the goal of agentic AI. For the first time, Gemini will be able to handle multistep tasks for you. You can watch it work if you prefer, but this can also happen entirely in the background while you do other things. It’s a bit like the recently launched Chrome Auto Browse but for apps.&lt;/p&gt;
&lt;p&gt;The selection of apps is pretty slim during this testing period. Samsung and Google say you’ll be able to order food and groceries in apps like DoorDash and Grubhub, and there will be a tie-in with Uber for both rides and food. Google currently says you should “supervise closely” when the agent is working on your behalf. So we’ll see how that goes.&lt;/p&gt;
&lt;h2&gt;When you can get it&lt;/h2&gt;
&lt;p&gt;Samsung is accepting preorders for its new phones starting today. You can get them at every mobile carrier or directly from Samsung’s website. Carriers will offer a variety of deals with monthly credits to reduce the sting of the new, higher prices. Samsung has enhanced trade-in values right now, which is a more straightforward way to get a discount if you have an old phone to unload. It’s offering up to $900 off instantly with an S25 Ultra or Z Fold 6 trade-in. Even a phone from a couple of years ago can cut the price of a Galaxy S26 way down.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2142570 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="S26 colors" class="fullwidth full" height="3375" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-Launch_dl3.jpg" width="4500" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Galaxy S26 comes in a variety of understated colors.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samsung

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The phones are available in violet cobalt, sky blue, white, and black at all retailers. Samsung’s exclusive colors this time are silver shadow and pink gold. Devices will be on shelves and the doorsteps of preorderers on or around March 11.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Samsung’s Galaxy S26 series is available for preorder today and ships on March 11.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="S26 lineup" class="absolute inset-0 w-full h-full object-cover hidden" height="356" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_dl2-640x356.jpg" width="640" /&gt;
                  &lt;img alt="S26 lineup" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_dl2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Galaxy S26 lineup doesn't change much on the outside.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samsung

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;There used to be countless companies making flagship Android phones, but a combination of factors has narrowed the field over time. Today, Samsung is the undisputed king of the Android device ecosystem with its Galaxy S line. So we can safely assume today’s Unpacked has revealed the most popular Android phones for the next year—the Galaxy S26 Ultra, Galaxy S26+, and Galaxy S26.&lt;/p&gt;
&lt;p&gt;Samsung didn’t swing for the fences this time around, producing phones with a few cosmetic tweaks and upgraded internals. Meanwhile, Samsung is investing even more in AI, saying the S26 series includes the first “Agentic AI phones.” Despite limited hardware upgrades, the realities of component prices in the age of AI mean the prices of the two cheaper models have gone up by $100 this year. The Ultra remains at an already eye-watering $1,300.&lt;/p&gt;
&lt;h2&gt;Faster and more private&lt;/h2&gt;
&lt;p&gt;Looking at the Galaxy S26 family, you’d be hard-pressed to tell them apart from last year’s phones. The camera surround is different, and the measurements of the smallest and largest phone are ever so slightly different. You probably won’t be able to tell just by looking, but the S26 Ultra has regressed from titanium to aluminum, a reversion Apple also made with its latest high-end phones. This phone also retains its S Pen stylus.&lt;/p&gt;
&lt;div class="table-wrapper"&gt;&lt;table class="specifications right" width="400"&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th colspan="4" style="text-align: left;"&gt;Specs at a glance: Samsung Galaxy S26 series&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Galaxy S26 ($900)&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Galaxy S26+ ($1,100)&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Galaxy S26 Ultra ($1,300)&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;SoC&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Snapdragon 8 Elite Gen 5 (3 nm)&lt;/td&gt;
&lt;td&gt;Snapdragon 8 Elite Gen 5 (3 nm)&lt;/td&gt;
&lt;td&gt;Snapdragon 8 Elite Gen 5 (3 nm)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Memory&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;12GB&lt;/td&gt;
&lt;td&gt;12GB&lt;/td&gt;
&lt;td&gt;12GB, 16GB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;256GB, 512GB&lt;/td&gt;
&lt;td&gt;256GB, 512GB&lt;/td&gt;
&lt;td&gt;256GB, 512GB, 1TB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Display&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;6.3-inch OLED, 10-bit color, 2340×1080, 1-120Hz&lt;/td&gt;
&lt;td&gt;6.7-inch OLED, 10-bit color, 3120×1440, 1-120Hz&lt;/td&gt;
&lt;td&gt;6.9-inch OLED, 10-bit color, 3120×1440, 1-120Hz, S Pen support&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Cameras&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;50MP primary, f/1.8, 1.0 μm; 12MP ultrawide, f/2.2, 1.4 μm, 10MP 3x telephoto, f/2.4, 1.0 μm; 12MP selfie, f/2.2, 1.12 μm&lt;/td&gt;
&lt;td&gt;50MP primary, f/1.8, 1.0 μm; 12MP ultrawide, f/2.2, 1.4 μm, 10MP 3x telephoto, f/2.4, 1.0 μm; 12MP selfie, f/2.2, 1.12 μm&lt;/td&gt;
&lt;td&gt;200MP primary, f/1.4, 0.6 μm; 50MP ultrawide, f/1.9, 0.7 μm; 10MP 3x telephoto, f/2.4, 1.12 μm; 50MP 5x telephoto, f/2.9, 0.7 μm; 12MP selfie, f/2.2, 1.12 μm&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Software&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Android 16&lt;/td&gt;
&lt;td&gt;Android 16&lt;/td&gt;
&lt;td&gt;Android 16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Battery&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;4,300 mAh&lt;/td&gt;
&lt;td&gt;4,900 mAh&lt;/td&gt;
&lt;td&gt;5,000 mAh&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Connectivity&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Wi-Fi 7, Bluetooth 5.4, USB-C 3.2, Sub6 5G&lt;/td&gt;
&lt;td&gt;Wi-Fi 7, Bluetooth 5.4, USB-C 3.2, Sub6 and mmWave 5G&lt;/td&gt;
&lt;td&gt;Wi-Fi 7, Bluetooth 5.4, USB-C 3.2, Sub6 and mmWave 5G&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Measurements&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;71.7×149.6×7.2 mm, 167g&lt;/td&gt;
&lt;td&gt;75.8×158.4×7.3 mm, 190g&lt;/td&gt;
&lt;td&gt;78.1×163.6×7.9 mm, 214 g&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;&lt;/div&gt;
&lt;p&gt;These phones will again have the latest Snapdragon flagship processor (in North America, Japan, and China) with customizations exclusive to Samsung. The Snapdragon 8 Elite Gen 5 for Galaxy is a 3 nm chip with third-gen Oryon CPU cores, an Adreno 840 GPU, and a powerful Hexagon NPU for on-device AI processing. Samsung promises double-digit performance gains across the board, which is what we hear every year.&lt;/p&gt;
&lt;p&gt;Samsung flagship phones have extremely fast hardware, so they benchmark well. However, they also tend to heat up and throttle quickly during sustained use. Perhaps that won’t be as much of a problem with the S26 series. Samsung says it has implemented its largest vapor chamber ever to better control temperatures.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The batteries have also been redesigned for greater efficiency and charging speed, but the base model is the only one that saw a capacity boost (4,000 to 4,300 mAh). Charging speeds have gotten a much-needed increase at the Ultra level. Samsung has only said you can now get a 75 percent charge in 30 minutes using its most expensive phone—it peaks at 60 W, up from 45 W for the last Ultra.&lt;/p&gt;
&lt;p&gt;Samsung has been using the same camera sensors for a few cycles now, and it’s not changing anything major this time around. The Ultra still has four cameras (including two telephotos) that top out with the 200 MP primary, and the S26+ and base model still have three cameras with a 50 MP primary. The apertures on the Ultra sensors are a bit wider to allow for brighter photos in challenging conditions. More interesting, though, is the option to record high-quality 8K video directly to an external drive. The S26 also brings support for the Advanced Professional Video (APV) codec.&lt;/p&gt;
&lt;p&gt;While the display specs haven’t changed much, they are home to the phone’s most notable new feature: Privacy Display. As smartphone screens have improved, they have emphasized high brightness and wide viewing angles, which is what you want most of the time. However, that also makes it easy for people nearby to see what’s on your screen. With one tap, the S26 can make it harder for shoulder surfers to see what you’re doing.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-2142568 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="2750" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_dl4-1.jpg" width="4000" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Privacy Display prevents shoulder surfers from peeking at your screen.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samsung

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Privacy Display uses a technology called Black Matrix, which activates “narrow pixels.” These pixels focus light more directly on the user to limit the viewing angle. Privacy Display can be activated system-wide as you like, but it can also be activated on a per-app basis or even just in the part of the screen where notifications appear.&lt;/p&gt;
&lt;h2&gt;What is an Agentic AI phone anyway?&lt;/h2&gt;
&lt;p&gt;Unsurprisingly, AI takes the lead with the S26 launch. Part of that is just Samsung following the zeitgeist, but companies can also add new AI capabilities to fill out spec sheets without a bunch of increasingly expensive hardware upgrades. In Samsung’s words, it has sought to have “AI integrated into every layer” of the Galaxy S26 experience.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That starts with expanded awareness of screen context. The company’s Now Brief feature, which is supposed to pull together useful information from across your apps, has not been very impressive so far. With the S26, Samsung is piping notification content into Now Brief, allowing it to remind you about things even if you never added them to your calendar or to-do list. Like many of Samsung’s Galaxy AI features, this data is processed on-device and won’t go to the cloud.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2142496-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_main6.mp4?_=1" type="video/mp4" /&gt;A Galaxy AI Nudge that helps you select photos.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A Galaxy AI Nudge that helps you select photos.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;In a similar vein, Galaxy AI is also getting “Nudges,” which look similar to Google’s Magic Cue on the Pixel 10 series. The Galaxy S26 will be able to suggest content and apps based on what’s happening on the screen. For example, Galaxy AI might see you want to share images and suggest the right ones, or perhaps it will check your calendar for openings to save you from switching apps. Of course, that assumes the AI will correctly recognize the context and call the right action.&lt;/p&gt;
&lt;p&gt;AI features will also be expanding in Samsung’s stock apps. In the Browser, Samsung has partnered with Perplexity for a new “Ask AI” feature. Rather than juggling tabs to read original sources yourself, you can have the AI do it. It basically gives you a research report like you could get from Perplexity itself (or Gemini Deep Research), but it’s integrated with the browser. Samsung’s gallery app also gets expanded AI editing tools with the S26. These capabilities will really allow you to change the substance of photos, so Samsung has added a visible watermark to label them. We’ve asked if there are AI labels in the image metadata, like you get with some other editing systems.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2142569 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="2800" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-A-First-Look_dl6.jpg" width="4500" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      AI-edited photos have a visible watermark.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samsung

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;A major component of Samsung’s “Agentic AI phone” pitch comes from a partnership with Google. For starters, Google’s AI-powered scam detection features in the Messaging app, previously exclusive to Pixels, will launch on the S26 in preview before expanding to more devices later. Circle to Search is getting an upgrade that lets it identify multiple objects in a single image—this is in testing on both the Pixel 10 series and the Galaxy S26.&lt;/p&gt;
&lt;p&gt;The other Google tie-in is more in keeping with the goal of agentic AI. For the first time, Gemini will be able to handle multistep tasks for you. You can watch it work if you prefer, but this can also happen entirely in the background while you do other things. It’s a bit like the recently launched Chrome Auto Browse but for apps.&lt;/p&gt;
&lt;p&gt;The selection of apps is pretty slim during this testing period. Samsung and Google say you’ll be able to order food and groceries in apps like DoorDash and Grubhub, and there will be a tie-in with Uber for both rides and food. Google currently says you should “supervise closely” when the agent is working on your behalf. So we’ll see how that goes.&lt;/p&gt;
&lt;h2&gt;When you can get it&lt;/h2&gt;
&lt;p&gt;Samsung is accepting preorders for its new phones starting today. You can get them at every mobile carrier or directly from Samsung’s website. Carriers will offer a variety of deals with monthly credits to reduce the sting of the new, higher prices. Samsung has enhanced trade-in values right now, which is a more straightforward way to get a discount if you have an old phone to unload. It’s offering up to $900 off instantly with an S25 Ultra or Z Fold 6 trade-in. Even a phone from a couple of years ago can cut the price of a Galaxy S26 way down.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2142570 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="S26 colors" class="fullwidth full" height="3375" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Samsung-Mobile-Galaxy-Unpacked-2026-Galaxy-S26-Series-Launch_dl3.jpg" width="4500" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Galaxy S26 comes in a variety of understated colors.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samsung

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The phones are available in violet cobalt, sky blue, white, and black at all retailers. Samsung’s exclusive colors this time are silver shadow and pink gold. Devices will be on shelves and the doorsteps of preorderers on or around March 11.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2026/02/samsung-reveals-galaxy-s26-lineup-with-privacy-display-and-exclusive-gemini-smarts/</guid><pubDate>Wed, 25 Feb 2026 21:41:27 +0000</pubDate></item><item><title>Musk has no proof OpenAI stole xAI trade secrets, judge rules, tossing lawsuit (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/02/judge-xai-cant-claim-openai-stole-trade-secrets-just-by-hiring-ex-staffers/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Even twisting an ex-employee’s text to favor xAI’s reading fails to sway judge.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="428" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2259422080-640x428.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2259422080-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anadolu / Contributor | Anadolu

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Elon Musk appears to be grasping at straws in a lawsuit accusing OpenAI of poaching eight xAI employees in an allegedly unlawful bid to access xAI trade secrets connected to its data centers and chatbot, Grok.&lt;/p&gt;
&lt;p&gt;In a Tuesday order granting OpenAI’s motion to dismiss, US District Judge Rita F. Lin said that xAI failed to provide evidence of any misconduct from OpenAI.&lt;/p&gt;
&lt;p&gt;Instead, xAI seemed fixated on a range of alleged conduct of former employees. But in assessing xAI’s claims, Lin said that xAI failed to show proof that OpenAI induced any of these employees to steal trade secrets “or that these former xAI employees used any stolen trade secrets once employed by OpenAI.”&lt;/p&gt;
&lt;p&gt;Two employees admitted to stealing confidential information, with both downloading xAI’s source code and one improperly grabbing a supposedly sensitive recording from a Musk “All Hands” meeting. But the rest were either accused of retaining seemingly less consequential data, like retaining work chats on their devices, or didn’t seem to hold any confidential information at all. Lin called out particularly weak arguments that xAI’s complaint acknowledged that one employee who OpenAI poached never received access to confidential information allegedly sought after exiting xAI, and two employees were lumped into the complaint who “simply left xAI for OpenAI,” Lin noted.&lt;/p&gt;
&lt;p&gt;From the limited evidence, Lin concluded that “while xAI may state misappropriation claims against a couple of its former employees, it does not state a plausible misappropriation claim against OpenAI.”&lt;/p&gt;
&lt;p&gt;Lin’s order will likely not be the end of the litigation, as she is allowing xAI to amend its complaint to address the current deficiencies.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Ars could not immediately reach xAI for comment, so it’s unclear what steps xAI may take next.&lt;/p&gt;
&lt;p&gt;However, xAI seems unlikely to give up the fight, which OpenAI has alleged is part of a “harassment campaign” that Musk is waging through multiple lawsuits attacking his biggest competitor’s business practices.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, OpenAI celebrated the order on X, alleging that “this baseless lawsuit was never anything more than yet another front in Mr. Musk’s ongoing campaign of harassment.”&lt;/p&gt;
&lt;p&gt;Other tech companies poaching talent for AI projects will likely be relieved while reading Lin’s order. Commercial litigator Sarah Tishler told Ars that the order “boils down to a fundamental concept in trade secret law: hiring from a competitor is not the same as stealing trade secrets from one.”&lt;/p&gt;
&lt;p&gt;“Under the Defend Trade Secrets Act, xAI has to show that OpenAI actually received and used the alleged trade secrets, not just that it hired employees who may have taken them,” Tishler said. “Suspicious timing, aggressive recruiting, and even downloaded files are not enough on their own.”&lt;/p&gt;
&lt;p&gt;Tishler suggested that the ruling will likely be welcomed by AI firms eager to secure the best talent without incurring legal risks from their hiring practices.&lt;/p&gt;
&lt;p&gt;“In the AI industry, where talent moves fast and the competitive stakes are enormous, this ruling reaffirms that suspicion is not enough,” Tishler said. “You have to show the stolen information actually made it into the competitor’s hands and was put to use.”&lt;/p&gt;
&lt;h2&gt;OpenAI not liable for engineers swiping source code&lt;/h2&gt;
&lt;p&gt;Through the lawsuit, Musk has alleged that OpenAI is violating California’s unfair competition law. He claims that OpenAI is attempting “to destroy legitimate competition in the AI industry by neutralizing xAI’s innovations” and forcing xAI “to unfairly compete against its own trade secrets.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But this claim hinges entirely upon xAI proving that OpenAI poached its employees to steal its trade secrets. So, for xAI’s lawsuit to proceed, xAI will need to beef up the evidence base for its other claim, that OpenAI has violated the federal Defend Trade Secrets Act, Lin said. To succeed on that, xAI must prove that OpenAI unlawfully acquired, disclosed, or used a trade secret with xAI’s consent.&lt;/p&gt;
&lt;p&gt;That will likely be challenging because xAI, at this point, has not offered “any nonconclusory allegations that OpenAI itself acquired, disclosed, or used xAI’s trade secrets,” Lin wrote.&lt;/p&gt;
&lt;p&gt;All xAI has claimed is that OpenAI induced former employees to share secrets, and so far, nothing backs that claim, Lin said. Tishler noted that the court also rejected an xAI theory that “OpenAI should be responsible for what its new hires did before they arrived” for “the same reason: without evidence that OpenAI directed the theft or actually put the stolen information to use, you cannot hold the company liable.”&lt;/p&gt;
&lt;p&gt;The strongest evidence that xAI had of employee misconduct, allegedly allowing OpenAI to misappropriate xAI trade secrets, revolves around the departure of one of xAI’s earliest engineers, Xuechen Li.&lt;/p&gt;
&lt;p&gt;That evidence wasn’t enough, Lin said. xAI alleged that Li gave a presentation to OpenAI that supposedly included confidential information. Li also uploaded “the entire xAI source code base to a personal cloud account,” which he had connected to ChatGPT, Lin noted, after a recruiter sent a message on Signal sharing a link with Li to another unrelated cloud storage location.&lt;/p&gt;
&lt;p&gt;xAI hoped the Signal messages would shock the court, expecting it to read through the lines the way xAI did. As proof that OpenAI allegedly got access to xAI’s source code, xAI pointed to a Signal message that an OpenAI recruiter sent to Li “four hours after” Li downloaded the source code, saying “nw!” xAI has alleged this message is short-hand for “no way!”—suggesting the OpenAI recruiter was geeked to get access to xAI’s source code. But in a footnote, Lin said that “OpenAI insists that ‘nw’ means ‘no worries,’” and thus is unconnected to Li’s decision to upload the source code to a ChatGPT-linked cloud account.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Even interpreting the text using xAI’s reading, however, xAI did not show enough to prove the recruiter or OpenAI accessed or requested the files, Lin said.&lt;/p&gt;
&lt;p&gt;It also didn’t help xAI’s case that a temporary injunction that xAI secured in a separate lawsuit targeting the engineer blocked Li from accepting a job at OpenAI.&lt;/p&gt;
&lt;p&gt;That injunction led OpenAI to withdraw its job offer to Li. And that’s a problem for xAI, because since Li never worked at OpenAI, it’s clear that he never used xAI’s trade secrets while working for OpenAI.&lt;/p&gt;
&lt;p&gt;Further weakening xAI’s arguments, if Li indeed shared confidential information during his presentation while interviewing for OpenAI, xAI has alleged no facts suggesting that OpenAI was aware Li was sharing xAI trade secrets, Lin wrote.&lt;/p&gt;
&lt;p&gt;This “makes it very hard to argue OpenAI ever used anything he allegedly took,” Tishler told Ars.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Another former xAI engineer, Jimmy Fraiture, was accused of copying xAI trade secrets, but Fraiture has said he deleted the information he improperly downloaded before starting his job at OpenAI. Importantly, Lin said, since he joined OpenAI, there’s no evidence that he used xAI trade secrets to benefit xAI’s rival.&lt;/p&gt;
&lt;p&gt;“Other than the bare fact that Fraiture had been recruited” by the same OpenAI employee “who had also recruited Li, xAI does not allege any facts indicating that OpenAI had encouraged Fraiture to take xAI’s confidential information in the first place,” Lin wrote.&lt;/p&gt;
&lt;p&gt;Since “none of the other former employees allegedly shared with or disclosed to OpenAI any xAI trade secrets,” xAI could not advance its claim that OpenAI misappropriated trade secrets based only on allegations tied to Li and Fraiture’s supposed misconduct, Lin said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;xAI may be able to amend its complaint to maintain these arguments, but the company has thus far presented scant, purely circumstantial evidence.&lt;/p&gt;
&lt;p&gt;It’s possible that xAI will secure more evidence to support its misappropriation claims against OpenAI in its ongoing lawsuit against Li. Ars could not immediately reach Li’s lawyer to find out if today’s ruling may impact that case.&lt;/p&gt;
&lt;h2&gt;Ex-executive’s “hostility” is not proof of theft&lt;/h2&gt;
&lt;p&gt;Among the least convincing arguments that xAI raised was a claim that an unnamed finance executive left xAI to take a “lesser role” at OpenAI after learning everything he knew about data centers from xAI.&lt;/p&gt;
&lt;p&gt;That executive slighted xAI when Musk’s company later attempted to inquire about “confidentiality concerns.”&lt;/p&gt;
&lt;p&gt;“Suck my dick,” the former xAI executive allegedly said, refusing to explain how his OpenAI work might overlap with his xAI position. “Leave me the fuck alone.”&lt;/p&gt;
&lt;p&gt;xAI tried to argue that the executive’s hostility was proof of misconduct. But Lin wrote that xAI only alleged that the executive “merely possessed xAI trade secrets about data centers” and did not allege that he ever used trade secrets to benefit OpenAI.&lt;/p&gt;
&lt;p&gt;Had xAI found evidence that OpenAI’s data center strategy suddenly mirrored xAI’s after the executive joined xAI’s rival, that may have helped xAI’s case. But there are plenty of reasons a former employee might reject an ex-employer’s outreach following an exit, Lin suggested.&lt;/p&gt;
&lt;p&gt;“His hostility when xAI reached out about its confidentiality concerns also does not support a plausible inference of use,” Lin wrote. “Hostility toward one’s former employer during departure does not, without more, indicate use of trade secrets in a subsequent job. Nor does the executive’s lack of experience with AI data centers before his time at xAI, without more, support a plausible inference that he used xAI’s trade secrets at OpenAI.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;xAI has until March 17 to amend its complaint to keep up this particular fight against OpenAI. But the company won’t be able to add any new claims or parties, Lin noted, “or otherwise change the allegations except to correct the identified deficiencies.”&lt;/p&gt;
&lt;h2&gt;Criminal probe likely leaves OpenAI on pins&lt;/h2&gt;
&lt;p&gt;For Li, the engineer accused of disclosing xAI trade secrets with OpenAI, the litigation could eliminate one front of discovery as he navigates two other legal fights over xAI’s trade secrets claims.&lt;/p&gt;
&lt;p&gt;Tishler has been closely monitoring xAI’s trade secret legal battles. In October, she noted that Li is in a particularly prickly position, facing pressure in civil litigation from Musk to turn over data that could be used against him in the Federal Bureau of Investigation’s criminal investigation into Musk’s allegations. As Tishler explained:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“The practical reality is stark: Li faces a choice between protecting himself in the criminal action with his silence, and the civil consequences of doing so. Refuse to answer, and xAI could argue adverse inferences; answer, and the responses could feed the criminal case.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ultimately, the FBI is trying to prove that Li stole information that qualified as a trade secret and intended to use it for OpenAI’s benefit, while knowing that it would harm xAI. If they succeed, “xAI would suddenly have a government-backed record that its trade secrets were stolen,” Tishler wrote.&lt;/p&gt;
&lt;p&gt;If xAI were so armed and able to keep the OpenAI lawsuit alive, the central question in the lawsuit that Lin dismissed today would shift, Tishler suggested, from “was there a theft?” to “what did OpenAI know, and when did it know it?”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Even twisting an ex-employee’s text to favor xAI’s reading fails to sway judge.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="428" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2259422080-640x428.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2259422080-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anadolu / Contributor | Anadolu

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Elon Musk appears to be grasping at straws in a lawsuit accusing OpenAI of poaching eight xAI employees in an allegedly unlawful bid to access xAI trade secrets connected to its data centers and chatbot, Grok.&lt;/p&gt;
&lt;p&gt;In a Tuesday order granting OpenAI’s motion to dismiss, US District Judge Rita F. Lin said that xAI failed to provide evidence of any misconduct from OpenAI.&lt;/p&gt;
&lt;p&gt;Instead, xAI seemed fixated on a range of alleged conduct of former employees. But in assessing xAI’s claims, Lin said that xAI failed to show proof that OpenAI induced any of these employees to steal trade secrets “or that these former xAI employees used any stolen trade secrets once employed by OpenAI.”&lt;/p&gt;
&lt;p&gt;Two employees admitted to stealing confidential information, with both downloading xAI’s source code and one improperly grabbing a supposedly sensitive recording from a Musk “All Hands” meeting. But the rest were either accused of retaining seemingly less consequential data, like retaining work chats on their devices, or didn’t seem to hold any confidential information at all. Lin called out particularly weak arguments that xAI’s complaint acknowledged that one employee who OpenAI poached never received access to confidential information allegedly sought after exiting xAI, and two employees were lumped into the complaint who “simply left xAI for OpenAI,” Lin noted.&lt;/p&gt;
&lt;p&gt;From the limited evidence, Lin concluded that “while xAI may state misappropriation claims against a couple of its former employees, it does not state a plausible misappropriation claim against OpenAI.”&lt;/p&gt;
&lt;p&gt;Lin’s order will likely not be the end of the litigation, as she is allowing xAI to amend its complaint to address the current deficiencies.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Ars could not immediately reach xAI for comment, so it’s unclear what steps xAI may take next.&lt;/p&gt;
&lt;p&gt;However, xAI seems unlikely to give up the fight, which OpenAI has alleged is part of a “harassment campaign” that Musk is waging through multiple lawsuits attacking his biggest competitor’s business practices.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, OpenAI celebrated the order on X, alleging that “this baseless lawsuit was never anything more than yet another front in Mr. Musk’s ongoing campaign of harassment.”&lt;/p&gt;
&lt;p&gt;Other tech companies poaching talent for AI projects will likely be relieved while reading Lin’s order. Commercial litigator Sarah Tishler told Ars that the order “boils down to a fundamental concept in trade secret law: hiring from a competitor is not the same as stealing trade secrets from one.”&lt;/p&gt;
&lt;p&gt;“Under the Defend Trade Secrets Act, xAI has to show that OpenAI actually received and used the alleged trade secrets, not just that it hired employees who may have taken them,” Tishler said. “Suspicious timing, aggressive recruiting, and even downloaded files are not enough on their own.”&lt;/p&gt;
&lt;p&gt;Tishler suggested that the ruling will likely be welcomed by AI firms eager to secure the best talent without incurring legal risks from their hiring practices.&lt;/p&gt;
&lt;p&gt;“In the AI industry, where talent moves fast and the competitive stakes are enormous, this ruling reaffirms that suspicion is not enough,” Tishler said. “You have to show the stolen information actually made it into the competitor’s hands and was put to use.”&lt;/p&gt;
&lt;h2&gt;OpenAI not liable for engineers swiping source code&lt;/h2&gt;
&lt;p&gt;Through the lawsuit, Musk has alleged that OpenAI is violating California’s unfair competition law. He claims that OpenAI is attempting “to destroy legitimate competition in the AI industry by neutralizing xAI’s innovations” and forcing xAI “to unfairly compete against its own trade secrets.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But this claim hinges entirely upon xAI proving that OpenAI poached its employees to steal its trade secrets. So, for xAI’s lawsuit to proceed, xAI will need to beef up the evidence base for its other claim, that OpenAI has violated the federal Defend Trade Secrets Act, Lin said. To succeed on that, xAI must prove that OpenAI unlawfully acquired, disclosed, or used a trade secret with xAI’s consent.&lt;/p&gt;
&lt;p&gt;That will likely be challenging because xAI, at this point, has not offered “any nonconclusory allegations that OpenAI itself acquired, disclosed, or used xAI’s trade secrets,” Lin wrote.&lt;/p&gt;
&lt;p&gt;All xAI has claimed is that OpenAI induced former employees to share secrets, and so far, nothing backs that claim, Lin said. Tishler noted that the court also rejected an xAI theory that “OpenAI should be responsible for what its new hires did before they arrived” for “the same reason: without evidence that OpenAI directed the theft or actually put the stolen information to use, you cannot hold the company liable.”&lt;/p&gt;
&lt;p&gt;The strongest evidence that xAI had of employee misconduct, allegedly allowing OpenAI to misappropriate xAI trade secrets, revolves around the departure of one of xAI’s earliest engineers, Xuechen Li.&lt;/p&gt;
&lt;p&gt;That evidence wasn’t enough, Lin said. xAI alleged that Li gave a presentation to OpenAI that supposedly included confidential information. Li also uploaded “the entire xAI source code base to a personal cloud account,” which he had connected to ChatGPT, Lin noted, after a recruiter sent a message on Signal sharing a link with Li to another unrelated cloud storage location.&lt;/p&gt;
&lt;p&gt;xAI hoped the Signal messages would shock the court, expecting it to read through the lines the way xAI did. As proof that OpenAI allegedly got access to xAI’s source code, xAI pointed to a Signal message that an OpenAI recruiter sent to Li “four hours after” Li downloaded the source code, saying “nw!” xAI has alleged this message is short-hand for “no way!”—suggesting the OpenAI recruiter was geeked to get access to xAI’s source code. But in a footnote, Lin said that “OpenAI insists that ‘nw’ means ‘no worries,’” and thus is unconnected to Li’s decision to upload the source code to a ChatGPT-linked cloud account.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Even interpreting the text using xAI’s reading, however, xAI did not show enough to prove the recruiter or OpenAI accessed or requested the files, Lin said.&lt;/p&gt;
&lt;p&gt;It also didn’t help xAI’s case that a temporary injunction that xAI secured in a separate lawsuit targeting the engineer blocked Li from accepting a job at OpenAI.&lt;/p&gt;
&lt;p&gt;That injunction led OpenAI to withdraw its job offer to Li. And that’s a problem for xAI, because since Li never worked at OpenAI, it’s clear that he never used xAI’s trade secrets while working for OpenAI.&lt;/p&gt;
&lt;p&gt;Further weakening xAI’s arguments, if Li indeed shared confidential information during his presentation while interviewing for OpenAI, xAI has alleged no facts suggesting that OpenAI was aware Li was sharing xAI trade secrets, Lin wrote.&lt;/p&gt;
&lt;p&gt;This “makes it very hard to argue OpenAI ever used anything he allegedly took,” Tishler told Ars.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Another former xAI engineer, Jimmy Fraiture, was accused of copying xAI trade secrets, but Fraiture has said he deleted the information he improperly downloaded before starting his job at OpenAI. Importantly, Lin said, since he joined OpenAI, there’s no evidence that he used xAI trade secrets to benefit xAI’s rival.&lt;/p&gt;
&lt;p&gt;“Other than the bare fact that Fraiture had been recruited” by the same OpenAI employee “who had also recruited Li, xAI does not allege any facts indicating that OpenAI had encouraged Fraiture to take xAI’s confidential information in the first place,” Lin wrote.&lt;/p&gt;
&lt;p&gt;Since “none of the other former employees allegedly shared with or disclosed to OpenAI any xAI trade secrets,” xAI could not advance its claim that OpenAI misappropriated trade secrets based only on allegations tied to Li and Fraiture’s supposed misconduct, Lin said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;xAI may be able to amend its complaint to maintain these arguments, but the company has thus far presented scant, purely circumstantial evidence.&lt;/p&gt;
&lt;p&gt;It’s possible that xAI will secure more evidence to support its misappropriation claims against OpenAI in its ongoing lawsuit against Li. Ars could not immediately reach Li’s lawyer to find out if today’s ruling may impact that case.&lt;/p&gt;
&lt;h2&gt;Ex-executive’s “hostility” is not proof of theft&lt;/h2&gt;
&lt;p&gt;Among the least convincing arguments that xAI raised was a claim that an unnamed finance executive left xAI to take a “lesser role” at OpenAI after learning everything he knew about data centers from xAI.&lt;/p&gt;
&lt;p&gt;That executive slighted xAI when Musk’s company later attempted to inquire about “confidentiality concerns.”&lt;/p&gt;
&lt;p&gt;“Suck my dick,” the former xAI executive allegedly said, refusing to explain how his OpenAI work might overlap with his xAI position. “Leave me the fuck alone.”&lt;/p&gt;
&lt;p&gt;xAI tried to argue that the executive’s hostility was proof of misconduct. But Lin wrote that xAI only alleged that the executive “merely possessed xAI trade secrets about data centers” and did not allege that he ever used trade secrets to benefit OpenAI.&lt;/p&gt;
&lt;p&gt;Had xAI found evidence that OpenAI’s data center strategy suddenly mirrored xAI’s after the executive joined xAI’s rival, that may have helped xAI’s case. But there are plenty of reasons a former employee might reject an ex-employer’s outreach following an exit, Lin suggested.&lt;/p&gt;
&lt;p&gt;“His hostility when xAI reached out about its confidentiality concerns also does not support a plausible inference of use,” Lin wrote. “Hostility toward one’s former employer during departure does not, without more, indicate use of trade secrets in a subsequent job. Nor does the executive’s lack of experience with AI data centers before his time at xAI, without more, support a plausible inference that he used xAI’s trade secrets at OpenAI.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;xAI has until March 17 to amend its complaint to keep up this particular fight against OpenAI. But the company won’t be able to add any new claims or parties, Lin noted, “or otherwise change the allegations except to correct the identified deficiencies.”&lt;/p&gt;
&lt;h2&gt;Criminal probe likely leaves OpenAI on pins&lt;/h2&gt;
&lt;p&gt;For Li, the engineer accused of disclosing xAI trade secrets with OpenAI, the litigation could eliminate one front of discovery as he navigates two other legal fights over xAI’s trade secrets claims.&lt;/p&gt;
&lt;p&gt;Tishler has been closely monitoring xAI’s trade secret legal battles. In October, she noted that Li is in a particularly prickly position, facing pressure in civil litigation from Musk to turn over data that could be used against him in the Federal Bureau of Investigation’s criminal investigation into Musk’s allegations. As Tishler explained:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;“The practical reality is stark: Li faces a choice between protecting himself in the criminal action with his silence, and the civil consequences of doing so. Refuse to answer, and xAI could argue adverse inferences; answer, and the responses could feed the criminal case.”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Ultimately, the FBI is trying to prove that Li stole information that qualified as a trade secret and intended to use it for OpenAI’s benefit, while knowing that it would harm xAI. If they succeed, “xAI would suddenly have a government-backed record that its trade secrets were stolen,” Tishler wrote.&lt;/p&gt;
&lt;p&gt;If xAI were so armed and able to keep the OpenAI lawsuit alive, the central question in the lawsuit that Lin dismissed today would shift, Tishler suggested, from “was there a theft?” to “what did OpenAI know, and when did it know it?”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/02/judge-xai-cant-claim-openai-stole-trade-secrets-just-by-hiring-ex-staffers/</guid><pubDate>Wed, 25 Feb 2026 22:09:21 +0000</pubDate></item><item><title>Nvidia has another record quarter amid record capex spends (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/25/nvidia-earnings-record-capex-spend-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2219673294.jpg?resize=1200,750" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Chip giant and world’s most valuable company Nvidia reported record profits in its most recent quarter on Wednesday, as demand for AI compute continues to skyrocket.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The demand for tokens in the world has gone completely exponential,” CEO Jensen Huang said on a call with analysts following the results. “I think we’re all seeing that, to the point where even our six-year-old GPUs in the cloud are completely consumed and the pricing is going up.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company reported $68 billion in revenue in the most recent quarter, up 73% from the prior year, with $62 billion of that revenue coming from the company’s data center business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, Nvidia divided the data center revenue into $51 billion in compute revenue (largely GPUs) and $11 billion in networking products like NVLink. The company reported $215 billion in revenue for the full year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As in previous quarters, the company did not report any revenue from chip exports to China, despite the recent lifting of export restrictions by the U.S. government. “While small amounts of H200 products for China-based customers were approved by the U.S. government, they have yet to generate any revenue, and we do not know whether any imports will be allowed into China,” Colette Kress, the company’s chief financial officer, said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our competitors in China, bolstered by recent IPOs, are making progress,” she continued, in an apparent reference to Moore Threads’ IPO in December, “and have the potential to disrupt the structure of the global AI industry over the long term.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During the investor call, Huang also addressed the company’s pending investment in OpenAI, which has been reported at $30 billion.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We continue to work with OpenAI toward a partnership agreement. We believe we are close,” Huang said. He also referenced partnerships with Anthropic, Meta, and Elon Musk’s xAI. However, statements Nvidia filed with the U.S. Securities and Exchange Commission on Wednesday emphasized that there was “no assurance” an investment would take place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Huang also addressed concerns about the sustainability of tech companies’ capex commitments, saying he believed the compute investments would soon bring revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In this new world of AI, compute &lt;em&gt;is&lt;/em&gt; revenue. Without compute, there’s no way to generate tokens. Without tokens, there’s no way to grow revenues,” Huang said. “We’ve reached the inflection point and we’re generating profitable tokens that are productive for customers and profitable for the cloud service providers”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2219673294.jpg?resize=1200,750" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Chip giant and world’s most valuable company Nvidia reported record profits in its most recent quarter on Wednesday, as demand for AI compute continues to skyrocket.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The demand for tokens in the world has gone completely exponential,” CEO Jensen Huang said on a call with analysts following the results. “I think we’re all seeing that, to the point where even our six-year-old GPUs in the cloud are completely consumed and the pricing is going up.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company reported $68 billion in revenue in the most recent quarter, up 73% from the prior year, with $62 billion of that revenue coming from the company’s data center business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, Nvidia divided the data center revenue into $51 billion in compute revenue (largely GPUs) and $11 billion in networking products like NVLink. The company reported $215 billion in revenue for the full year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As in previous quarters, the company did not report any revenue from chip exports to China, despite the recent lifting of export restrictions by the U.S. government. “While small amounts of H200 products for China-based customers were approved by the U.S. government, they have yet to generate any revenue, and we do not know whether any imports will be allowed into China,” Colette Kress, the company’s chief financial officer, said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our competitors in China, bolstered by recent IPOs, are making progress,” she continued, in an apparent reference to Moore Threads’ IPO in December, “and have the potential to disrupt the structure of the global AI industry over the long term.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During the investor call, Huang also addressed the company’s pending investment in OpenAI, which has been reported at $30 billion.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We continue to work with OpenAI toward a partnership agreement. We believe we are close,” Huang said. He also referenced partnerships with Anthropic, Meta, and Elon Musk’s xAI. However, statements Nvidia filed with the U.S. Securities and Exchange Commission on Wednesday emphasized that there was “no assurance” an investment would take place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Huang also addressed concerns about the sustainability of tech companies’ capex commitments, saying he believed the compute investments would soon bring revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In this new world of AI, compute &lt;em&gt;is&lt;/em&gt; revenue. Without compute, there’s no way to generate tokens. Without tokens, there’s no way to grow revenues,” Huang said. “We’ve reached the inflection point and we’re generating profitable tokens that are productive for customers and profitable for the cloud service providers”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/25/nvidia-earnings-record-capex-spend-ai/</guid><pubDate>Wed, 25 Feb 2026 23:04:42 +0000</pubDate></item><item><title>Anthropic acquires computer-use AI startup Vercept after Meta poached one of its founders (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/25/anthropic-acquires-vercept-ai-startup-agents-computer-use-founders-investors/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/anthropic-image-jagmeet-singh-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic on Wednesday announced that it has acquired Vercept, an AI startup with deep roots to some of the biggest names in Seattle’s tech scene. The acquisition marks the latest after Anthropic acquired coding agent engine Bun in December to help scale Claude Code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vercept had created tools for more complex agentic tasks, including its product Vy, a computer-use agent in the cloud that could operate a remote Apple MacBook. Vercept is one of the many startups working on re-imagining the personal computer for the age of AI agents. As part of the deal, Anthropic is shuttering Vercept’s product on March 25.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup was a grad of Seattle’s AI-focused incubator A12, which spawned from the longstanding Allen Institute for AI. Vercept’s co-founders had roots with the Allen Institute, as well, and were previously researchers there. One co-founder, Matt Deitke, made news last year as one of the AI researchers who negotiated a monster $250 million salary from Meta to join its Superintelligence Lab. On Wednesday, Deitke congratulated his former colleagues in a post on X.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Vercept was a relatively high-profile AI startup in the region. In a LinkedIn post announcing the acquisition by Anthropic, Vercept CEO Kiana Ehsani said the startup had raised a total of $50 million. She called out A12’s Seth Bannon, a board member, as the lead investor. Vercept previously announced it had raised a $16 million seed round last January.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The list of angel investors was impressive, too, and included former Google CEO Eric Schmidt, Google DeepMind chief scientist Jeff Dean, Cruise founder Kyle Vogt, and Dropbox co-founder Arash Ferdowsi, GeekWire reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Anthropic’s announcement of the acquisition, the company named co-founders Ehsani, Luca Weihs, and Ross Girshick as some of the team brought on to join Anthropic in the acquisition. However, not all of Vercept’s co-founders are joining the Claude maker.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Oren Etzioni, who has previously been named as a co-founder of Vercept and investor in the startup, is well known in Seattle as the founding leader of the Allen Institute for AI. Along with Deitke, he is also not joining Anthropic, and was vocally less pleased about the acqui-hire. He posted on LinkedIn: “After a little bit more than a year, Vercept is throwing in the towel and giving their customers 30 days to get off the platform. Sad. A fantastic team is joining Anthropic. I wish them the very best!”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Etzioni is also a professor at the University of Washington and known for other startups he’s founded and backed as a VC. He did not respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Etzioni’s LinkedIn post, he accused Bannon, the Vercept lead investor, of being “partly responsible” for Vercept not hiring the correct business people. A back and forth ensued between the investors, with Bannon condemning Etzioni’s remarks: “… you disparaged the heroic work of the founders for achieving an outcome most could only dream of,” Bannon replied in the LinkedIn string. They also accused each other of other less savory things like lying and legal threats.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While public spats between investors are entertaining, and essentially meaningless, the underlying motivation is notable. The stakes are high to build the next big AI winner, and now a promising startup that raised a decently sized war chest will be tucked into Anthropic.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While the terms of the deal were not disclosed, Etzioni says he got a return on his money. Anthropic clearly wanted these researchers (perhaps — especially — with another of them at Meta).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Etzioni told GeekWire that he remains bummed. “I’m pleased to have gotten a positive return but obviously disappointed that after just a little over a year with so much traction, and such a fantastic team, we’re basically throwing in the towel,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders joining Anthropic, however, appear happy, according to CEO’s Ehsani’s LinkedIn post. “The choices were clear: we could build independently and work toward the same vision as two separate versions of it, or join forces with an incredible team and accelerate that vision into reality. The decision became an easy choice,” she said of joining Anthropic.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/anthropic-image-jagmeet-singh-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic on Wednesday announced that it has acquired Vercept, an AI startup with deep roots to some of the biggest names in Seattle’s tech scene. The acquisition marks the latest after Anthropic acquired coding agent engine Bun in December to help scale Claude Code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vercept had created tools for more complex agentic tasks, including its product Vy, a computer-use agent in the cloud that could operate a remote Apple MacBook. Vercept is one of the many startups working on re-imagining the personal computer for the age of AI agents. As part of the deal, Anthropic is shuttering Vercept’s product on March 25.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup was a grad of Seattle’s AI-focused incubator A12, which spawned from the longstanding Allen Institute for AI. Vercept’s co-founders had roots with the Allen Institute, as well, and were previously researchers there. One co-founder, Matt Deitke, made news last year as one of the AI researchers who negotiated a monster $250 million salary from Meta to join its Superintelligence Lab. On Wednesday, Deitke congratulated his former colleagues in a post on X.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Vercept was a relatively high-profile AI startup in the region. In a LinkedIn post announcing the acquisition by Anthropic, Vercept CEO Kiana Ehsani said the startup had raised a total of $50 million. She called out A12’s Seth Bannon, a board member, as the lead investor. Vercept previously announced it had raised a $16 million seed round last January.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The list of angel investors was impressive, too, and included former Google CEO Eric Schmidt, Google DeepMind chief scientist Jeff Dean, Cruise founder Kyle Vogt, and Dropbox co-founder Arash Ferdowsi, GeekWire reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Anthropic’s announcement of the acquisition, the company named co-founders Ehsani, Luca Weihs, and Ross Girshick as some of the team brought on to join Anthropic in the acquisition. However, not all of Vercept’s co-founders are joining the Claude maker.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Oren Etzioni, who has previously been named as a co-founder of Vercept and investor in the startup, is well known in Seattle as the founding leader of the Allen Institute for AI. Along with Deitke, he is also not joining Anthropic, and was vocally less pleased about the acqui-hire. He posted on LinkedIn: “After a little bit more than a year, Vercept is throwing in the towel and giving their customers 30 days to get off the platform. Sad. A fantastic team is joining Anthropic. I wish them the very best!”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Etzioni is also a professor at the University of Washington and known for other startups he’s founded and backed as a VC. He did not respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Etzioni’s LinkedIn post, he accused Bannon, the Vercept lead investor, of being “partly responsible” for Vercept not hiring the correct business people. A back and forth ensued between the investors, with Bannon condemning Etzioni’s remarks: “… you disparaged the heroic work of the founders for achieving an outcome most could only dream of,” Bannon replied in the LinkedIn string. They also accused each other of other less savory things like lying and legal threats.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While public spats between investors are entertaining, and essentially meaningless, the underlying motivation is notable. The stakes are high to build the next big AI winner, and now a promising startup that raised a decently sized war chest will be tucked into Anthropic.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While the terms of the deal were not disclosed, Etzioni says he got a return on his money. Anthropic clearly wanted these researchers (perhaps — especially — with another of them at Meta).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Etzioni told GeekWire that he remains bummed. “I’m pleased to have gotten a positive return but obviously disappointed that after just a little over a year with so much traction, and such a fantastic team, we’re basically throwing in the towel,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders joining Anthropic, however, appear happy, according to CEO’s Ehsani’s LinkedIn post. “The choices were clear: we could build independently and work toward the same vision as two separate versions of it, or join forces with an incredible team and accelerate that vision into reality. The decision became an easy choice,” she said of joining Anthropic.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/25/anthropic-acquires-vercept-ai-startup-agents-computer-use-founders-investors/</guid><pubDate>Wed, 25 Feb 2026 23:49:19 +0000</pubDate></item><item><title>Gushwork bets on AI search for customer leads — and early results are emerging (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/25/gushwork-bets-on-ai-search-for-customer-leads-and-early-results-are-emerging/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/gushwork-co-founders.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI-powered search tools reshape how businesses are discovered online, India-founded startup Gushwork is helping companies capture customers from platforms such as ChatGPT, Gemini, and Perplexity — with early traction that is beginning to draw investor support.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The two-year-old startup said Thursday it had raised $9 million in a seed round led by Susquehanna International Group (SIG) and Lightspeed, with participation from B Capital, Seaborne Capital, Beenext, Sparrow Capital, and 2.2 Capital. The round values Gushwork at $33 million post-money, up from about $7.5 million following its Lightspeed-led $2.1 million pre-seed in July 2023, a person familiar with the matter told TechCrunch. The latest financing brings Gushwork’s total funding to $11 million, the startup said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The funding comes as AI companies, including OpenAI and Perplexity, begin to chip away at traditional web search, prompting incumbents like Google to roll out AI-generated overviews and other conversational features across their search products. Gushwork is betting this shift will create a new opportunity to help businesses surface in AI-driven discovery channels using its automated marketing agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2023 by Nayrhit Bhattacharya (pictured above, right) and Adithya Venkatesh (pictured above, left), Gushwork initially focused on helping small and medium businesses outsource workflows using a mix of AI and human expertise. The startup began narrowing its focus toward search-led marketing after seeing strong customer demand for help with improving online visibility.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we started, we were focused on helping businesses outsource faster and outsource better,” Bhattacharya told TechCrunch in an interview, adding that the pull around search from customers became increasingly hard to ignore.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gushwork’s platform uses a network of AI agents to automatically generate and update search-optimized content; build backlinks — typically 10 to 20 per customer — through a network of roughly 200 to 300 partner websites; and track inbound leads through an integrated content management system. The goal, Bhattacharya said, is to help businesses surface in both traditional search results and AI-generated answers without relying on large in-house marketing teams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup says it has signed up more than 300 paying customers — roughly 95% of them in the U.S. — with subscriptions starting at $800 per month. Gushwork is currently running at about $1.5 million in annualized recurring revenue after rolling out its AI search-focused product around three months ago and is targeting $3 million to $3.5 million ARR in the next three months, Bhattacharya said, adding that the startup is growing about 50% to 80% month over month.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Across Gushwork’s customer base, about 20% of website traffic now comes from AI-driven search and chat platforms, but those sources account for around 40% of inbound leads, Bhattacharya said, citing the startup’s internal data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The higher-intent leads, Bhattacharya said, are already translating into business outcomes for some customers. In one case, a professional services client has closed between $200,000 and $350,000 worth of contracts after adopting the platform, he said, declining to disclose the customer’s name. He added that many users are seeing meaningful pipeline growth as AI-driven discovery gains traction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gushwork’s customer base today is concentrated among high-ticket B2B service providers, industrial distributors, and contract manufacturers, primarily in the U.S., Bhattacharya said. The startup’s average subscription runs about $800 to $900 per month, or roughly $9,000 to $10,000 in annual contract value, he added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The shift toward AI-driven discovery is still in its early stages but is gaining momentum. Tools such as generative AI chatbots and AI web browsers are increasingly being used by buyers to research vendors and products. OpenAI said in July 2025 that ChatGPT received about 2.5 billion prompts a day globally, including roughly 330 million from U.S. users. Bhattacharya said the trend is beginning to reshape how some businesses approach online visibility.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gushwork plans to use the new funding to expand its engineering team, improve model accuracy, and scale its go-to-market efforts, Bhattacharya said. He added that the startup has more than 800 businesses on its waitlist that it plans to begin onboarding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup, headquartered in Delaware with an office in Bengaluru, has about 70 employees in India, along with several contractors.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/gushwork-co-founders.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI-powered search tools reshape how businesses are discovered online, India-founded startup Gushwork is helping companies capture customers from platforms such as ChatGPT, Gemini, and Perplexity — with early traction that is beginning to draw investor support.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The two-year-old startup said Thursday it had raised $9 million in a seed round led by Susquehanna International Group (SIG) and Lightspeed, with participation from B Capital, Seaborne Capital, Beenext, Sparrow Capital, and 2.2 Capital. The round values Gushwork at $33 million post-money, up from about $7.5 million following its Lightspeed-led $2.1 million pre-seed in July 2023, a person familiar with the matter told TechCrunch. The latest financing brings Gushwork’s total funding to $11 million, the startup said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The funding comes as AI companies, including OpenAI and Perplexity, begin to chip away at traditional web search, prompting incumbents like Google to roll out AI-generated overviews and other conversational features across their search products. Gushwork is betting this shift will create a new opportunity to help businesses surface in AI-driven discovery channels using its automated marketing agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2023 by Nayrhit Bhattacharya (pictured above, right) and Adithya Venkatesh (pictured above, left), Gushwork initially focused on helping small and medium businesses outsource workflows using a mix of AI and human expertise. The startup began narrowing its focus toward search-led marketing after seeing strong customer demand for help with improving online visibility.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we started, we were focused on helping businesses outsource faster and outsource better,” Bhattacharya told TechCrunch in an interview, adding that the pull around search from customers became increasingly hard to ignore.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gushwork’s platform uses a network of AI agents to automatically generate and update search-optimized content; build backlinks — typically 10 to 20 per customer — through a network of roughly 200 to 300 partner websites; and track inbound leads through an integrated content management system. The goal, Bhattacharya said, is to help businesses surface in both traditional search results and AI-generated answers without relying on large in-house marketing teams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup says it has signed up more than 300 paying customers — roughly 95% of them in the U.S. — with subscriptions starting at $800 per month. Gushwork is currently running at about $1.5 million in annualized recurring revenue after rolling out its AI search-focused product around three months ago and is targeting $3 million to $3.5 million ARR in the next three months, Bhattacharya said, adding that the startup is growing about 50% to 80% month over month.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Across Gushwork’s customer base, about 20% of website traffic now comes from AI-driven search and chat platforms, but those sources account for around 40% of inbound leads, Bhattacharya said, citing the startup’s internal data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The higher-intent leads, Bhattacharya said, are already translating into business outcomes for some customers. In one case, a professional services client has closed between $200,000 and $350,000 worth of contracts after adopting the platform, he said, declining to disclose the customer’s name. He added that many users are seeing meaningful pipeline growth as AI-driven discovery gains traction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gushwork’s customer base today is concentrated among high-ticket B2B service providers, industrial distributors, and contract manufacturers, primarily in the U.S., Bhattacharya said. The startup’s average subscription runs about $800 to $900 per month, or roughly $9,000 to $10,000 in annual contract value, he added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The shift toward AI-driven discovery is still in its early stages but is gaining momentum. Tools such as generative AI chatbots and AI web browsers are increasingly being used by buyers to research vendors and products. OpenAI said in July 2025 that ChatGPT received about 2.5 billion prompts a day globally, including roughly 330 million from U.S. users. Bhattacharya said the trend is beginning to reshape how some businesses approach online visibility.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gushwork plans to use the new funding to expand its engineering team, improve model accuracy, and scale its go-to-market efforts, Bhattacharya said. He added that the startup has more than 800 businesses on its waitlist that it plans to begin onboarding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup, headquartered in Delaware with an office in Bengaluru, has about 70 employees in India, along with several contractors.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/25/gushwork-bets-on-ai-search-for-customer-leads-and-early-results-are-emerging/</guid><pubDate>Thu, 26 Feb 2026 00:00:00 +0000</pubDate></item><item><title>Salesforce CEO Marc Benioff: This isn’t our first SaaSpocalypse (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/25/salesforce-ceo-marc-benioff-this-isnt-our-first-saaspocalypse/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Marc-Benioff.png?resize=1200,658" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Salesforce pulled out all the stops to convince investors that the AI revolution won’t be its death when it announced fourth-quarter earnings on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Salesforce reported a solid quarter of $10.7 billion in revenue, up 13% year-over-year. For the year, it reported $41.5 billion in revenue, up 10% over the previous year, with both results boosted by its $8 billion acquisition of data management company Informatica last May.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Net income landed at $7.46 billion, and the company offered strong guidance for the year ahead, projecting revenue of $45.8 billion to $46.2 billion — a 10% to 11% increase. It also said its “remaining performance obligation,” or RPO, is over $72 billion. That’s a figure that shows revenue under contact that has not yet been delivered or recognized as earned revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The numbers, though, could only do so much. Software-as-a-service stocks, with Salesforce as their poster child, have been getting hammered lately. Investors fear the rise of AI agents will undermine these companies, making their per-employee-seat business models obsolete. The situation has been dubbed the “SaaSpocalypse.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The concept hung so heavily in the air during the earnings call that CEO Marc Benioff mentioned the term at least six times.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You’ve heard about the SaaSpocalypse? And it isn’t our first. We’ve had a few of them,” he said, later adding, “If there is a SaaSpocalypse, it may be eaten by the Sasquatch because there are a lot of companies using a lot of SaaS because it just got better with agents.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an attempt to convince the world of its continued health, Salesforce threw everything and the kitchen sink into this earnings report. The company increased its dividend by nearly 6% to $0.44 per share. It launched a new $50 billion share buyback program. That’s always a favorite with shareholders because it both creates a sturdy buyer of shares and reduces the number of shares in circulation (which can boost the stock price).&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company also revamped the earnings call itself. It was part podcast, part infomercial, and part normal Q&amp;amp;A with a few questions from Wall Street analysts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead of running through the numbers, Benioff interviewed three Salesforce customers on camera to testify to their love of its new agentic options: the CEO of home appliance company SharkNinja; the CEO of Wyndham Hotels and Resorts; and, just to hammer the point, the CEO of SaaStr, the software industry conference and media company. We’ll truncate the interviews to the shortest summary: They all love Salesforce’s AI agent products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Salesforce also introduced a new metric for its agentic products: agentic work units (“AWU”). The idea here is that instead of simply counting “tokens” — the standard unit of AI processing volume — AWU attempts to measure something more meaningful: whether an agent actually completed a task. (Salesforce logged 19 trillion tokens last quarter, which sounds like a lot but really is not in the AI world.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“You can ask it a question and it can write you a poem, but that’s not really all that valuable in the enterprise world,” Salesforce president and CMO Patrick Stokes said on the call. So AWU is intended to measure when the agent writes to a record or does some other verifiable piece of work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On top of that, Salesforce also presented its own architectural vision of the coming world of agents. It shows SaaS software like itself owning most of the tech stack, with the AI model makers on the bottom as unseen, interchangeable, and commoditized work engines.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This was a direct counter to one of the causes of a SaaSpocalypse sell-off earlier this month, after OpenAI released its enterprise agent, Frontier. OpenAI’s architectural vision shows OpenAI owning most of the stack, with systems-of-record SaaS providers (the databases and business-software platforms where companies store their core data) on the bottom as the unseen engines.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And if all that wasn’t enough to influence investors: Benioff was dressed in a black leather jacket, echoing the signature look of the CEO clearly crushing it in the AI world: Nvidia’s Jensen Huang.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Marc-Benioff.png?resize=1200,658" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Salesforce pulled out all the stops to convince investors that the AI revolution won’t be its death when it announced fourth-quarter earnings on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Salesforce reported a solid quarter of $10.7 billion in revenue, up 13% year-over-year. For the year, it reported $41.5 billion in revenue, up 10% over the previous year, with both results boosted by its $8 billion acquisition of data management company Informatica last May.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Net income landed at $7.46 billion, and the company offered strong guidance for the year ahead, projecting revenue of $45.8 billion to $46.2 billion — a 10% to 11% increase. It also said its “remaining performance obligation,” or RPO, is over $72 billion. That’s a figure that shows revenue under contact that has not yet been delivered or recognized as earned revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The numbers, though, could only do so much. Software-as-a-service stocks, with Salesforce as their poster child, have been getting hammered lately. Investors fear the rise of AI agents will undermine these companies, making their per-employee-seat business models obsolete. The situation has been dubbed the “SaaSpocalypse.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The concept hung so heavily in the air during the earnings call that CEO Marc Benioff mentioned the term at least six times.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You’ve heard about the SaaSpocalypse? And it isn’t our first. We’ve had a few of them,” he said, later adding, “If there is a SaaSpocalypse, it may be eaten by the Sasquatch because there are a lot of companies using a lot of SaaS because it just got better with agents.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an attempt to convince the world of its continued health, Salesforce threw everything and the kitchen sink into this earnings report. The company increased its dividend by nearly 6% to $0.44 per share. It launched a new $50 billion share buyback program. That’s always a favorite with shareholders because it both creates a sturdy buyer of shares and reduces the number of shares in circulation (which can boost the stock price).&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company also revamped the earnings call itself. It was part podcast, part infomercial, and part normal Q&amp;amp;A with a few questions from Wall Street analysts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead of running through the numbers, Benioff interviewed three Salesforce customers on camera to testify to their love of its new agentic options: the CEO of home appliance company SharkNinja; the CEO of Wyndham Hotels and Resorts; and, just to hammer the point, the CEO of SaaStr, the software industry conference and media company. We’ll truncate the interviews to the shortest summary: They all love Salesforce’s AI agent products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Salesforce also introduced a new metric for its agentic products: agentic work units (“AWU”). The idea here is that instead of simply counting “tokens” — the standard unit of AI processing volume — AWU attempts to measure something more meaningful: whether an agent actually completed a task. (Salesforce logged 19 trillion tokens last quarter, which sounds like a lot but really is not in the AI world.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“You can ask it a question and it can write you a poem, but that’s not really all that valuable in the enterprise world,” Salesforce president and CMO Patrick Stokes said on the call. So AWU is intended to measure when the agent writes to a record or does some other verifiable piece of work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On top of that, Salesforce also presented its own architectural vision of the coming world of agents. It shows SaaS software like itself owning most of the tech stack, with the AI model makers on the bottom as unseen, interchangeable, and commoditized work engines.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This was a direct counter to one of the causes of a SaaSpocalypse sell-off earlier this month, after OpenAI released its enterprise agent, Frontier. OpenAI’s architectural vision shows OpenAI owning most of the stack, with systems-of-record SaaS providers (the databases and business-software platforms where companies store their core data) on the bottom as the unseen engines.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And if all that wasn’t enough to influence investors: Benioff was dressed in a black leather jacket, echoing the signature look of the CEO clearly crushing it in the AI world: Nvidia’s Jensen Huang.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/25/salesforce-ceo-marc-benioff-this-isnt-our-first-saaspocalypse/</guid><pubDate>Thu, 26 Feb 2026 01:59:12 +0000</pubDate></item><item><title>[NEW] New method could increase LLM training efficiency (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/new-method-could-increase-llm-training-efficiency-0226</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/MIT-LongTail-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Reasoning large language models (LLMs) are designed to solve complex problems by breaking them down into a series of smaller steps. These powerful models are particularly good at challenging tasks like advanced programming and multistep planning.&lt;/p&gt;&lt;p&gt;But developing reasoning models demands an enormous amount of computation and energy due to inefficiencies in the training process. While a few of the high-power processors continuously work through complicated queries, others in the group sit idle.&lt;/p&gt;&lt;p&gt;Researchers from MIT and elsewhere found a way to use this computational downtime to efficiently accelerate reasoning-model training.&lt;/p&gt;&lt;p&gt;Their new method automatically trains a smaller, faster model to predict the outputs of the larger reasoning LLM, which the larger model verifies. This reduces the amount of work the reasoning model must do, accelerating the training process.&lt;/p&gt;&lt;p&gt;The key to this system is its ability to train and deploy the smaller model adaptively, so it kicks in only when some processors are idle. By leveraging computational resources that would otherwise have been wasted, it accelerates training without&amp;nbsp;incurring additional&amp;nbsp;overhead.&lt;/p&gt;&lt;p&gt;When tested on multiple reasoning LLMs, the method doubled the training speed while preserving accuracy. This could reduce the cost and increase the energy efficiency of developing advanced LLMs for applications such as forecasting financial trends or detecting risks in power grids.&lt;/p&gt;&lt;p&gt;“People want models that can handle more complex tasks. But if that is the goal of model development, then we need to prioritize efficiency. We found a lossless solution to this problem and then developed a full-stack system that can deliver quite dramatic speedups in practice,” says Qinghao Hu, an MIT postdoc and co-lead author of a paper on this technique.&lt;/p&gt;&lt;p&gt;He is joined on the paper by co-lead author Shang Yang, an electrical engineering and computer science (EECS) graduate student; Junxian Guo, an EECS graduate student; senior author Song Han, an associate professor in EECS, member of the Research Laboratory of Electronics and a distinguished scientist of NVIDIA; as well as others at NVIDIA, ETH Zurich, the MIT-IBM Watson AI Lab, and the University of Massachusetts at Amherst. The research will be presented at the ACM International Conference on Architectural Support for Programming Languages and Operating Systems.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Training bottleneck&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Developers want reasoning LLMs to identify and correct mistakes in their critical thinking process. This capability allows them to ace complicated queries that would trip up a standard LLM.&lt;/p&gt;&lt;p&gt;To teach them this skill, developers train reasoning LLMs using a technique called reinforcement learning (RL). The model generates multiple potential answers to a query, receives a reward for the best candidate, and is updated based on the top answer. These steps repeat thousands of times as the model learns.&lt;/p&gt;&lt;p&gt;But the researchers found that the process of generating multiple answers, called rollout, can consume as much as 85 percent of the&amp;nbsp;execution time needed for RL training.&lt;/p&gt;&lt;p&gt;“Updating the model — which is the actual ‘training’ part — consumes very little time by comparison,” Hu says.&lt;/p&gt;&lt;p&gt;This bottleneck occurs&amp;nbsp;in standard RL algorithms because all processors in the training group must finish their responses before they can move on to the next step. Because some processors might be working on very long responses, others that generated shorter responses wait for them to finish.&lt;/p&gt;&lt;p&gt;“Our goal was to turn this idle time into speedup without any wasted costs,” Hu adds.&lt;/p&gt;&lt;p&gt;They sought to use an existing technique, called speculative decoding, to speed things up. Speculative decoding involves training a smaller model called a drafter to rapidly guess the future outputs of the larger model.&lt;/p&gt;&lt;p&gt;The larger model verifies the drafter’s guesses, and the responses it accepts are used for training.&lt;/p&gt;&lt;p&gt;Because the larger model can verify all the drafter’s guesses at once, rather than generating each output sequentially, it accelerates the process.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;An adaptive solution&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;But in speculative decoding, the drafter model is typically trained only once and remains static. This makes the technique infeasible for reinforcement learning, since the reasoning model is updated thousands of times during training.&lt;/p&gt;&lt;p&gt;A static drafter would quickly become stale and useless after a few steps.&lt;/p&gt;&lt;p&gt;To overcome this problem, the researchers created a flexible system known as “Taming the Long Tail,” or TLT.&lt;/p&gt;&lt;p&gt;The first part of TLT is an adaptive drafter trainer, which uses free time on idle processors to train the drafter model on the fly, keeping it well-aligned with the target model without using extra computational resources.&lt;/p&gt;&lt;p&gt;The second component, an adaptive rollout engine, manages speculative decoding to automatically select the optimal strategy for each new batch of inputs. This mechanism changes the speculative decoding configuration based on the training workload features, such as the number of inputs processed by the draft model and the number of inputs accepted by the target model during verification.&lt;/p&gt;&lt;p&gt;In addition, the researchers designed the draft model to be lightweight so it can be trained quickly. TLT reuses some components of the reasoning model training process to train the drafter, leading to extra gains in acceleration.&lt;/p&gt;&lt;p&gt;“As soon as some processors finish their short queries and become idle, we immediately switch them to do draft model training using the same data they are using for the rollout process. The key mechanism is our adaptive speculative decoding — these gains wouldn’t be possible without it,” Hu says.&lt;/p&gt;&lt;p&gt;They tested TLT across multiple reasoning LLMs that were trained using real-world datasets. The system accelerated training between 70 and 210 percent while preserving the accuracy of each model.&lt;/p&gt;&lt;p&gt;As an added bonus, the small drafter model could readily be&amp;nbsp;utilized for efficient deployment as a free byproduct.&lt;/p&gt;&lt;p&gt;In the future, the researchers want to integrate TLT into more types of training and inference frameworks and find new reinforcement learning applications that could be accelerated using this approach.&lt;/p&gt;&lt;p&gt;“As reasoning continues to become the major workload driving the demand for inference, Qinghao’s TLT is great work to cope with the computation bottleneck of training these reasoning models. I think this method will be very helpful in the context of efficient AI computing,” Han says.&lt;/p&gt;&lt;p&gt;This work is funded by the MIT-IBM Watson AI Lab, the MIT AI Hardware Program, the MIT Amazon Science Hub, Hyundai Motor Company, and the National Science Foundation.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/MIT-LongTail-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Reasoning large language models (LLMs) are designed to solve complex problems by breaking them down into a series of smaller steps. These powerful models are particularly good at challenging tasks like advanced programming and multistep planning.&lt;/p&gt;&lt;p&gt;But developing reasoning models demands an enormous amount of computation and energy due to inefficiencies in the training process. While a few of the high-power processors continuously work through complicated queries, others in the group sit idle.&lt;/p&gt;&lt;p&gt;Researchers from MIT and elsewhere found a way to use this computational downtime to efficiently accelerate reasoning-model training.&lt;/p&gt;&lt;p&gt;Their new method automatically trains a smaller, faster model to predict the outputs of the larger reasoning LLM, which the larger model verifies. This reduces the amount of work the reasoning model must do, accelerating the training process.&lt;/p&gt;&lt;p&gt;The key to this system is its ability to train and deploy the smaller model adaptively, so it kicks in only when some processors are idle. By leveraging computational resources that would otherwise have been wasted, it accelerates training without&amp;nbsp;incurring additional&amp;nbsp;overhead.&lt;/p&gt;&lt;p&gt;When tested on multiple reasoning LLMs, the method doubled the training speed while preserving accuracy. This could reduce the cost and increase the energy efficiency of developing advanced LLMs for applications such as forecasting financial trends or detecting risks in power grids.&lt;/p&gt;&lt;p&gt;“People want models that can handle more complex tasks. But if that is the goal of model development, then we need to prioritize efficiency. We found a lossless solution to this problem and then developed a full-stack system that can deliver quite dramatic speedups in practice,” says Qinghao Hu, an MIT postdoc and co-lead author of a paper on this technique.&lt;/p&gt;&lt;p&gt;He is joined on the paper by co-lead author Shang Yang, an electrical engineering and computer science (EECS) graduate student; Junxian Guo, an EECS graduate student; senior author Song Han, an associate professor in EECS, member of the Research Laboratory of Electronics and a distinguished scientist of NVIDIA; as well as others at NVIDIA, ETH Zurich, the MIT-IBM Watson AI Lab, and the University of Massachusetts at Amherst. The research will be presented at the ACM International Conference on Architectural Support for Programming Languages and Operating Systems.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Training bottleneck&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Developers want reasoning LLMs to identify and correct mistakes in their critical thinking process. This capability allows them to ace complicated queries that would trip up a standard LLM.&lt;/p&gt;&lt;p&gt;To teach them this skill, developers train reasoning LLMs using a technique called reinforcement learning (RL). The model generates multiple potential answers to a query, receives a reward for the best candidate, and is updated based on the top answer. These steps repeat thousands of times as the model learns.&lt;/p&gt;&lt;p&gt;But the researchers found that the process of generating multiple answers, called rollout, can consume as much as 85 percent of the&amp;nbsp;execution time needed for RL training.&lt;/p&gt;&lt;p&gt;“Updating the model — which is the actual ‘training’ part — consumes very little time by comparison,” Hu says.&lt;/p&gt;&lt;p&gt;This bottleneck occurs&amp;nbsp;in standard RL algorithms because all processors in the training group must finish their responses before they can move on to the next step. Because some processors might be working on very long responses, others that generated shorter responses wait for them to finish.&lt;/p&gt;&lt;p&gt;“Our goal was to turn this idle time into speedup without any wasted costs,” Hu adds.&lt;/p&gt;&lt;p&gt;They sought to use an existing technique, called speculative decoding, to speed things up. Speculative decoding involves training a smaller model called a drafter to rapidly guess the future outputs of the larger model.&lt;/p&gt;&lt;p&gt;The larger model verifies the drafter’s guesses, and the responses it accepts are used for training.&lt;/p&gt;&lt;p&gt;Because the larger model can verify all the drafter’s guesses at once, rather than generating each output sequentially, it accelerates the process.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;An adaptive solution&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;But in speculative decoding, the drafter model is typically trained only once and remains static. This makes the technique infeasible for reinforcement learning, since the reasoning model is updated thousands of times during training.&lt;/p&gt;&lt;p&gt;A static drafter would quickly become stale and useless after a few steps.&lt;/p&gt;&lt;p&gt;To overcome this problem, the researchers created a flexible system known as “Taming the Long Tail,” or TLT.&lt;/p&gt;&lt;p&gt;The first part of TLT is an adaptive drafter trainer, which uses free time on idle processors to train the drafter model on the fly, keeping it well-aligned with the target model without using extra computational resources.&lt;/p&gt;&lt;p&gt;The second component, an adaptive rollout engine, manages speculative decoding to automatically select the optimal strategy for each new batch of inputs. This mechanism changes the speculative decoding configuration based on the training workload features, such as the number of inputs processed by the draft model and the number of inputs accepted by the target model during verification.&lt;/p&gt;&lt;p&gt;In addition, the researchers designed the draft model to be lightweight so it can be trained quickly. TLT reuses some components of the reasoning model training process to train the drafter, leading to extra gains in acceleration.&lt;/p&gt;&lt;p&gt;“As soon as some processors finish their short queries and become idle, we immediately switch them to do draft model training using the same data they are using for the rollout process. The key mechanism is our adaptive speculative decoding — these gains wouldn’t be possible without it,” Hu says.&lt;/p&gt;&lt;p&gt;They tested TLT across multiple reasoning LLMs that were trained using real-world datasets. The system accelerated training between 70 and 210 percent while preserving the accuracy of each model.&lt;/p&gt;&lt;p&gt;As an added bonus, the small drafter model could readily be&amp;nbsp;utilized for efficient deployment as a free byproduct.&lt;/p&gt;&lt;p&gt;In the future, the researchers want to integrate TLT into more types of training and inference frameworks and find new reinforcement learning applications that could be accelerated using this approach.&lt;/p&gt;&lt;p&gt;“As reasoning continues to become the major workload driving the demand for inference, Qinghao’s TLT is great work to cope with the computation bottleneck of training these reasoning models. I think this method will be very helpful in the context of efficient AI computing,” Han says.&lt;/p&gt;&lt;p&gt;This work is funded by the MIT-IBM Watson AI Lab, the MIT AI Hardware Program, the MIT Amazon Science Hub, Hyundai Motor Company, and the National Science Foundation.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/new-method-could-increase-llm-training-efficiency-0226</guid><pubDate>Thu, 26 Feb 2026 05:00:00 +0000</pubDate></item></channel></rss>