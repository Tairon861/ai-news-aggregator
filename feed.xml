<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 20 Oct 2025 12:45:03 +0000</lastBuildDate><item><title>[NEW] The man betting everything on AI and Bill Belichick (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/20/the-man-betting-everything-on-ai-and-bill-belichick/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-20-at-1.13.38AM.png?resize=1200,807" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Lee Roberts meets me at the University Club of San Francisco on a Friday morning, hours before his football team will lose to Cal in heartbreaking fashion – a fumble at the goal line, because little about the University of North Carolina at Chapel Hill’s expensive experiment with Bill Belichick has gone according to script.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Roberts, the Chancellor of UNC, doesn’t know this yet. Right now, he’s in California to talk about artificial intelligence, which is both forward thinking and also – I’d hazard a guess – a welcome distraction from a lot else happening at the 235-year-old school.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“No one’s going to say to [students after they graduate from college], ‘Do the best job you can, but if you use AI, you’ll be in trouble,’” Roberts tells me, leaning into his central thesis about preparing students for the real world. “Yet we have some faculty members who are effectively saying that to students right now.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Roberts has joined me in between other meetings in the city with AI companies because UNC has decided to make AI its north star. It’s a business bet, really. Roberts spent three decades in finance, most recently as managing partner of a private investment firm, and served as state budget director under a Republican governor. He taught budgeting as an adjunct at Duke but never worked in academic administration before becoming UNC’s interim chancellor in January of last year, a post made permanent eight months later.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Never mind that the university just lost 118 federal grants totaling $38 million as part of a sweeping effort by the federal government to terminate more than 4,000 grants across 600 institutions. Never mind that more than 900 people last year signed a statement saying they wouldn’t recognize Roberts as chancellor when he was appointed, calling the process a political “coronation” rather than a search. Never mind that Belichick’s much-touted return to football is currently a 2-4 trainwreck, with write-ups about the team’s dysfunction becoming routine fodder for sports writers. Roberts is focused on the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At UNC, Roberts explains, there’s a spectrum between faculty who are “leaning forward” with AI and those who have “their heads in the sand.” It’s diplomatic phrasing for what is clearly a culture war playing out in faculty lounges across UNC and – it’s probably safe to assume – at other schools across the world. While one UNC professor is assigning more research than students could complete without AI (“much closer to a real world scenario,” says Roberts), others are treating chatbots like anabolic steroids. If you use them, you’re cheating.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have 4,000 faculty members,” Roberts says, as a cable car clatters past the open window beside our table. “And they pride themselves, as they should, on their independence and autonomy in how they teach their classes.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It sounds a little like code for: tenured professors can’t be forced to do anything. So Roberts is creating “incentive-based programs” to move the ball forward, like promoting one of the school’s deans into the role of Vice Provost for AI at the university. That individual, Jeffrey Bardzell, has been a professor for more than 20 years and has “experience both in technology and as a humanist,” says Roberts, adding that Bardzell is “exceptionally well-placed to help the faculty as a whole come further up to speed.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;UNC is barreling ahead on other fronts in the meantime. In its biggest development to date, the university announced this month that it is merging two schools – the School of Data Science and Society and the School of Information and Library Science – into one yet-to-be-named entity with AI studies at the center of the Venn diagram.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;UNC isn’t alone in betting big on AI. At least 14 colleges now offer bachelor’s degrees in AI, and universities like Arizona State University have made headlines for integrating AI tools across all disciplines.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Still, creating this new school has worried some of the school’s library science students, who wonder what will happen to their degrees, according to a report in The Daily Tar Heel, the school’s independent student newspaper. At least one faculty member also complained anonymously in a statement to the paper, saying Roberts pushed for the school without a “cogent idea” of what it will entail, adding that the “careers of faculty, staff and students at both of these schools are being sacrificed to Roberts’ ego.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Roberts tells me the implementation will be collaborative, not top-down. He’s also clear that the move is proactive, not reactive. “This is not about shutting anything down,” he says. “It’s not predominantly a cost-savings move,” he continues, a possible nod to those lost federal research dollars, which amount to 3.5% of UNC’s overall research funding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Roberts doesn’t minimize the devastation of losing grants – “in many cases, [people] lose their life’s work,” he acknowledges – but he’s also quick to note that 3.5% is “well within our average annual variance.” He adds that he has been spending “a lot of time talking with policymakers and legislators in Washington about the tremendous good that federal research funding represents. We need to be especially vigilant right now, when there’s so much uncertainty around [these dollars] that it’s really changing the basic structure of how large research universities have been funded.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, it raises questions about resources in the aggregate. Though UNC’s AI push is the topic du jour, I ask about the $10 million the school is paying Bill Belichick annually as part of a five-year deal signed back in January. I’m from Cleveland, I tell Roberts. I remember when Belichick cut Browns quarterback Bernie Kosar, a hometown hero. The city never forgave him.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Roberts is ready for this. College sports are changing rapidly, he says. Every peer institution spends at least as much on football; many spend more. Football drives revenue for 28 other sports. UNC just won its fourth national championship in women’s lacrosse, its 23rd in women’s soccer. None of that happens without football money.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If we had hired somebody else and we were [down some games], everybody would be saying, ‘Hey, man, you could have had Bill Belichick,’” Roberts offers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In reality, the prevailing narrative about Belichick isn’t just about wins and losses. Even if, ultimately, that’s exactly what it’s about, numerous outlets have published stories describing chaos inside the program, with players, parents, coaches, and administrators all painting a picture of a legendary NFL coach whose style doesn’t translate to college kids.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Roberts isn’t making decisions based on “a couple of news stories,” he says. “Coach Belichick, in my view, has done a really good job integrating with our campus,” Roberts says. He shows up at other teams’ games. He sends pizzas to fraternities on Saturday nights. He grew up on a college campus – his father was the coach at Navy.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Hours after our conversation, UNC will lose to Cal when wide receiver Nathan Leacock loses control of the ball just as he’s crossing into the end zone for what would have been the game-winning touchdown. I can only imagine what the immediate reaction is like back in Chapel Hill.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;My sense is that Roberts will brush it off. He may never be forgiven for not having a traditional academic background, but he also can’t afford to care that this bothers some people. I note that the 900-person petition took issue with the fact that, among the top 50 universities, Roberts is the only leader without higher education administration experience. The petition ran in The Daily Tar Heel, which has been critical of Roberts’ chancellorship throughout.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I don’t think it was 900 students,” Roberts corrects me. “I think it was 900 people, regardless of whether they were students, faculty, staff, or just people in the world who signed an online petition.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I ask how he felt about the whole episode. “No matter what your background was before you came into a job like this, you would have a lot to learn,” Roberts says. If you were a provost, you’d know nothing about “the business or finance or budgetary or political or operational or real estate sides of the university.” If you came from business, you’d need to learn the academic side.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a reasonable point. The modern university chancellor is part CEO, part diplomat, part fundraiser, part sports executive. Presumably, no one arrives with all the skills required. “I think almost no matter what you did previously before coming into a job like this, there would be a learning curve,” Roberts says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What strikes me about Roberts is that he seems relatively unbothered. The federal funding cuts are within the normal range. The Belichick hire is a wait-and-see situation. As for some of the faculty’s resistance to AI, it’s a puzzle to be solved.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He’s also making big bets just as higher education is being squeezed every which way. Federal funding is uncertain. Birth rate declines threaten future enrollment. The value of a college degree is in question, with more students graduating to find the only jobs available to them are low-wage gigs they could have landed without spending staggering amounts on college. Now AI threatens to upend the whole model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Roberts sees opportunity where others might see a crisis. He also thinks the window of opportunity is shorter than some might imagine. “The challenge of AI is that we have to work relatively quickly, and we also have to cooperate across academic disciplines,” he says. “And those are two things that universities, historically, are not especially good at.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Whether Roberts’ game plan works remains to be seen. What’s clear is that he’s betting moving fast and shaking things up is better than moving slowly and preserving tradition at highly ranked UNC. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re going to try to make Carolina the number one public university in America,” he tells me.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s an ambitious vision, and as he delivers it, for better or worse, he sounds very much like a Silicon Valley CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;To hear this interview with Roberts, listen to TechCrunch’s StrictlyVC Download podcast; new episodes drop every Tuesday&lt;/em&gt;.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-20-at-1.13.38AM.png?resize=1200,807" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Lee Roberts meets me at the University Club of San Francisco on a Friday morning, hours before his football team will lose to Cal in heartbreaking fashion – a fumble at the goal line, because little about the University of North Carolina at Chapel Hill’s expensive experiment with Bill Belichick has gone according to script.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Roberts, the Chancellor of UNC, doesn’t know this yet. Right now, he’s in California to talk about artificial intelligence, which is both forward thinking and also – I’d hazard a guess – a welcome distraction from a lot else happening at the 235-year-old school.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“No one’s going to say to [students after they graduate from college], ‘Do the best job you can, but if you use AI, you’ll be in trouble,’” Roberts tells me, leaning into his central thesis about preparing students for the real world. “Yet we have some faculty members who are effectively saying that to students right now.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Roberts has joined me in between other meetings in the city with AI companies because UNC has decided to make AI its north star. It’s a business bet, really. Roberts spent three decades in finance, most recently as managing partner of a private investment firm, and served as state budget director under a Republican governor. He taught budgeting as an adjunct at Duke but never worked in academic administration before becoming UNC’s interim chancellor in January of last year, a post made permanent eight months later.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Never mind that the university just lost 118 federal grants totaling $38 million as part of a sweeping effort by the federal government to terminate more than 4,000 grants across 600 institutions. Never mind that more than 900 people last year signed a statement saying they wouldn’t recognize Roberts as chancellor when he was appointed, calling the process a political “coronation” rather than a search. Never mind that Belichick’s much-touted return to football is currently a 2-4 trainwreck, with write-ups about the team’s dysfunction becoming routine fodder for sports writers. Roberts is focused on the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At UNC, Roberts explains, there’s a spectrum between faculty who are “leaning forward” with AI and those who have “their heads in the sand.” It’s diplomatic phrasing for what is clearly a culture war playing out in faculty lounges across UNC and – it’s probably safe to assume – at other schools across the world. While one UNC professor is assigning more research than students could complete without AI (“much closer to a real world scenario,” says Roberts), others are treating chatbots like anabolic steroids. If you use them, you’re cheating.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have 4,000 faculty members,” Roberts says, as a cable car clatters past the open window beside our table. “And they pride themselves, as they should, on their independence and autonomy in how they teach their classes.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It sounds a little like code for: tenured professors can’t be forced to do anything. So Roberts is creating “incentive-based programs” to move the ball forward, like promoting one of the school’s deans into the role of Vice Provost for AI at the university. That individual, Jeffrey Bardzell, has been a professor for more than 20 years and has “experience both in technology and as a humanist,” says Roberts, adding that Bardzell is “exceptionally well-placed to help the faculty as a whole come further up to speed.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;UNC is barreling ahead on other fronts in the meantime. In its biggest development to date, the university announced this month that it is merging two schools – the School of Data Science and Society and the School of Information and Library Science – into one yet-to-be-named entity with AI studies at the center of the Venn diagram.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;UNC isn’t alone in betting big on AI. At least 14 colleges now offer bachelor’s degrees in AI, and universities like Arizona State University have made headlines for integrating AI tools across all disciplines.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Still, creating this new school has worried some of the school’s library science students, who wonder what will happen to their degrees, according to a report in The Daily Tar Heel, the school’s independent student newspaper. At least one faculty member also complained anonymously in a statement to the paper, saying Roberts pushed for the school without a “cogent idea” of what it will entail, adding that the “careers of faculty, staff and students at both of these schools are being sacrificed to Roberts’ ego.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Roberts tells me the implementation will be collaborative, not top-down. He’s also clear that the move is proactive, not reactive. “This is not about shutting anything down,” he says. “It’s not predominantly a cost-savings move,” he continues, a possible nod to those lost federal research dollars, which amount to 3.5% of UNC’s overall research funding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Roberts doesn’t minimize the devastation of losing grants – “in many cases, [people] lose their life’s work,” he acknowledges – but he’s also quick to note that 3.5% is “well within our average annual variance.” He adds that he has been spending “a lot of time talking with policymakers and legislators in Washington about the tremendous good that federal research funding represents. We need to be especially vigilant right now, when there’s so much uncertainty around [these dollars] that it’s really changing the basic structure of how large research universities have been funded.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, it raises questions about resources in the aggregate. Though UNC’s AI push is the topic du jour, I ask about the $10 million the school is paying Bill Belichick annually as part of a five-year deal signed back in January. I’m from Cleveland, I tell Roberts. I remember when Belichick cut Browns quarterback Bernie Kosar, a hometown hero. The city never forgave him.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Roberts is ready for this. College sports are changing rapidly, he says. Every peer institution spends at least as much on football; many spend more. Football drives revenue for 28 other sports. UNC just won its fourth national championship in women’s lacrosse, its 23rd in women’s soccer. None of that happens without football money.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If we had hired somebody else and we were [down some games], everybody would be saying, ‘Hey, man, you could have had Bill Belichick,’” Roberts offers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In reality, the prevailing narrative about Belichick isn’t just about wins and losses. Even if, ultimately, that’s exactly what it’s about, numerous outlets have published stories describing chaos inside the program, with players, parents, coaches, and administrators all painting a picture of a legendary NFL coach whose style doesn’t translate to college kids.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Roberts isn’t making decisions based on “a couple of news stories,” he says. “Coach Belichick, in my view, has done a really good job integrating with our campus,” Roberts says. He shows up at other teams’ games. He sends pizzas to fraternities on Saturday nights. He grew up on a college campus – his father was the coach at Navy.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Hours after our conversation, UNC will lose to Cal when wide receiver Nathan Leacock loses control of the ball just as he’s crossing into the end zone for what would have been the game-winning touchdown. I can only imagine what the immediate reaction is like back in Chapel Hill.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;My sense is that Roberts will brush it off. He may never be forgiven for not having a traditional academic background, but he also can’t afford to care that this bothers some people. I note that the 900-person petition took issue with the fact that, among the top 50 universities, Roberts is the only leader without higher education administration experience. The petition ran in The Daily Tar Heel, which has been critical of Roberts’ chancellorship throughout.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I don’t think it was 900 students,” Roberts corrects me. “I think it was 900 people, regardless of whether they were students, faculty, staff, or just people in the world who signed an online petition.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I ask how he felt about the whole episode. “No matter what your background was before you came into a job like this, you would have a lot to learn,” Roberts says. If you were a provost, you’d know nothing about “the business or finance or budgetary or political or operational or real estate sides of the university.” If you came from business, you’d need to learn the academic side.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a reasonable point. The modern university chancellor is part CEO, part diplomat, part fundraiser, part sports executive. Presumably, no one arrives with all the skills required. “I think almost no matter what you did previously before coming into a job like this, there would be a learning curve,” Roberts says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What strikes me about Roberts is that he seems relatively unbothered. The federal funding cuts are within the normal range. The Belichick hire is a wait-and-see situation. As for some of the faculty’s resistance to AI, it’s a puzzle to be solved.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He’s also making big bets just as higher education is being squeezed every which way. Federal funding is uncertain. Birth rate declines threaten future enrollment. The value of a college degree is in question, with more students graduating to find the only jobs available to them are low-wage gigs they could have landed without spending staggering amounts on college. Now AI threatens to upend the whole model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Roberts sees opportunity where others might see a crisis. He also thinks the window of opportunity is shorter than some might imagine. “The challenge of AI is that we have to work relatively quickly, and we also have to cooperate across academic disciplines,” he says. “And those are two things that universities, historically, are not especially good at.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Whether Roberts’ game plan works remains to be seen. What’s clear is that he’s betting moving fast and shaking things up is better than moving slowly and preserving tradition at highly ranked UNC. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re going to try to make Carolina the number one public university in America,” he tells me.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s an ambitious vision, and as he delivers it, for better or worse, he sounds very much like a Silicon Valley CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;To hear this interview with Roberts, listen to TechCrunch’s StrictlyVC Download podcast; new episodes drop every Tuesday&lt;/em&gt;.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/20/the-man-betting-everything-on-ai-and-bill-belichick/</guid><pubDate>Mon, 20 Oct 2025 08:10:52 +0000</pubDate></item><item><title>[NEW] Scale AI alum raises $9M for AI serving critical industries in MENA (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/20/scale-ai-alum-raises-9m-for-ai-serving-critical-industries-in-mena/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/IMG_2363.jpeg?resize=1200,896" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Bilal Abu-Ghazaleh had just moved to London few days before our call, splitting his time between there and Dubai.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After nearly a decade in the U.S., including a stint at Scale AI, he’s bringing that experience to his next venture: 1001 AI , a company creating AI infrastructure for critical industries across the Middle East and North Africa (MENA).&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup recently raised a $9 million seed round led by CIV, General Catalyst, and Lux Capital. Other backers include global and regional angels such as Chris Ré, Amjad Masad (Replit), Amira Sajwani (DAMAC), Khalid Bin Bader Al Saud (RAED Ventures), and Hisham Alfalih (Lean Technologies).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Abu-Ghazaleh said his two-month-old company promises to cut inefficiencies in high-stakes sectors like aviation, logistics, and oil and gas through an AI-native operating system for decision-making.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Just looking at the top three or four industries like airports, ports, construction, and oil and gas, we see more than $10 billion in inefficiencies across the Gulf alone,” the founder and CEO said in an interview with TechCrunch. “That’s just in markets like the UAE, Saudi Arabia, and Qatar. Even without counting other sectors, these industries represent a massive opportunity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, any efficiencies found in airport operations can compound the savings, impacting both the airport and its airlines. Meanwhile, he said nine out of ten of the regions mega-projects fall behind schedule or go over budget, meaning even small increases in efficiencies can save these projects serious money. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;1001 AI hopes to sell its decision-making AI to new projects after it launches its first product, which is scheduled by year’s end. The startup is in talks with some of the Gulf’s largest construction firms and airports, said Abu-Ghazaleh.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Born and raised in Jordan, Abu-Ghazaleh moved to the U.S. for college and later joined the Bay Area’s startup scene. After an early product role at computer vision startup Hive AI, he joined Scale AI in 2020 during its rapid expansion. There, he rose through the ranks from operations associate to director of the company’s GenAI operations, scaling its contributor network responsible for annotating and labeling training data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He was later set to join Scale’s international public sector unit, which builds AI solutions for foreign governments. But when Meta invested in Scale, the company shifted direction, and Abu-Ghazaleh left to found 1001 AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Gulf, particularly the UAE and Saudi Arabia, has become one of the world’s most aggressive adopters of AI. From sovereign-backed ventures like G42 in Abu Dhabi to Saudi Arabia’s National Center for AI, governments are investing billions to build local AI infrastructure and attract global talent.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For Abu-Ghazaleh, that mix of appetite, budget, and urgency makes the region a perfect testing ground. But unlike most AI startups focused on software or enterprise tools, 1001 targets real-world physical operations, an area where the company’s investors believe the potential is even greater in the Middle East.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re extremely bullish on AI that solves physical-world problems at scale i.e, optimizing how airports turn around flights, how ports move cargo, how construction sites operate,” said Deena Shakir, partner at&amp;nbsp;Lux&amp;nbsp;Capital. “The MENA region offers significant potential in this space with mission-critical infrastructure that’s under-digitized and ripe for transformation.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the product is still under development, Abu-Ghazaleh offered a glimpse into how it works. The system pulls in data from a client’s existing software, models operational workflows, and issues real-time directives to improve efficiency.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Today, an operations manager might manually call someone to reroute a fuel truck or send a cleaning crew to another gate,” said Abu-Ghazaleh. “With our system, that orchestration happens automatically. The AI orchestrator uses real-time data to reroute vehicles, reassign crews, and adjust operations without human intervention.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike most early-stage AI startups that target specific industries, Abu-Ghazaleh says 1001 can be accessible by many because operational flows across industries often look the same.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That model borrows from the rigor of consulting and contract work. The team spends weeks embedded with clients, running co-development sprints to tailor its systems to each operation’s realities, the CEO said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Bilal&amp;nbsp;is building the decision engine to automate that complexity with Scale-proven execution and the regional gravity to make 1001 the platform this market builds on,” commented Neeraj Arora, managing director at General Catalyst.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new funding will accelerate early deployments across aviation, logistics, and infrastructure, while fueling recruitment in engineering, operations, and go-to-market role as it grows its team across Dubai and London. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;1001 AI plans to launch its first customer deployment by the end of the year, starting with construction. Over the next five years, Abu-Ghazaleh wants the company to become the Gulf’s go-to orchestration layer for these industries before expanding globally.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/IMG_2363.jpeg?resize=1200,896" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Bilal Abu-Ghazaleh had just moved to London few days before our call, splitting his time between there and Dubai.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After nearly a decade in the U.S., including a stint at Scale AI, he’s bringing that experience to his next venture: 1001 AI , a company creating AI infrastructure for critical industries across the Middle East and North Africa (MENA).&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup recently raised a $9 million seed round led by CIV, General Catalyst, and Lux Capital. Other backers include global and regional angels such as Chris Ré, Amjad Masad (Replit), Amira Sajwani (DAMAC), Khalid Bin Bader Al Saud (RAED Ventures), and Hisham Alfalih (Lean Technologies).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Abu-Ghazaleh said his two-month-old company promises to cut inefficiencies in high-stakes sectors like aviation, logistics, and oil and gas through an AI-native operating system for decision-making.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Just looking at the top three or four industries like airports, ports, construction, and oil and gas, we see more than $10 billion in inefficiencies across the Gulf alone,” the founder and CEO said in an interview with TechCrunch. “That’s just in markets like the UAE, Saudi Arabia, and Qatar. Even without counting other sectors, these industries represent a massive opportunity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, any efficiencies found in airport operations can compound the savings, impacting both the airport and its airlines. Meanwhile, he said nine out of ten of the regions mega-projects fall behind schedule or go over budget, meaning even small increases in efficiencies can save these projects serious money. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;1001 AI hopes to sell its decision-making AI to new projects after it launches its first product, which is scheduled by year’s end. The startup is in talks with some of the Gulf’s largest construction firms and airports, said Abu-Ghazaleh.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Born and raised in Jordan, Abu-Ghazaleh moved to the U.S. for college and later joined the Bay Area’s startup scene. After an early product role at computer vision startup Hive AI, he joined Scale AI in 2020 during its rapid expansion. There, he rose through the ranks from operations associate to director of the company’s GenAI operations, scaling its contributor network responsible for annotating and labeling training data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He was later set to join Scale’s international public sector unit, which builds AI solutions for foreign governments. But when Meta invested in Scale, the company shifted direction, and Abu-Ghazaleh left to found 1001 AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Gulf, particularly the UAE and Saudi Arabia, has become one of the world’s most aggressive adopters of AI. From sovereign-backed ventures like G42 in Abu Dhabi to Saudi Arabia’s National Center for AI, governments are investing billions to build local AI infrastructure and attract global talent.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For Abu-Ghazaleh, that mix of appetite, budget, and urgency makes the region a perfect testing ground. But unlike most AI startups focused on software or enterprise tools, 1001 targets real-world physical operations, an area where the company’s investors believe the potential is even greater in the Middle East.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re extremely bullish on AI that solves physical-world problems at scale i.e, optimizing how airports turn around flights, how ports move cargo, how construction sites operate,” said Deena Shakir, partner at&amp;nbsp;Lux&amp;nbsp;Capital. “The MENA region offers significant potential in this space with mission-critical infrastructure that’s under-digitized and ripe for transformation.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the product is still under development, Abu-Ghazaleh offered a glimpse into how it works. The system pulls in data from a client’s existing software, models operational workflows, and issues real-time directives to improve efficiency.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Today, an operations manager might manually call someone to reroute a fuel truck or send a cleaning crew to another gate,” said Abu-Ghazaleh. “With our system, that orchestration happens automatically. The AI orchestrator uses real-time data to reroute vehicles, reassign crews, and adjust operations without human intervention.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike most early-stage AI startups that target specific industries, Abu-Ghazaleh says 1001 can be accessible by many because operational flows across industries often look the same.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That model borrows from the rigor of consulting and contract work. The team spends weeks embedded with clients, running co-development sprints to tailor its systems to each operation’s realities, the CEO said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Bilal&amp;nbsp;is building the decision engine to automate that complexity with Scale-proven execution and the regional gravity to make 1001 the platform this market builds on,” commented Neeraj Arora, managing director at General Catalyst.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new funding will accelerate early deployments across aviation, logistics, and infrastructure, while fueling recruitment in engineering, operations, and go-to-market role as it grows its team across Dubai and London. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;1001 AI plans to launch its first customer deployment by the end of the year, starting with construction. Over the next five years, Abu-Ghazaleh wants the company to become the Gulf’s go-to orchestration layer for these industries before expanding globally.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/20/scale-ai-alum-raises-9m-for-ai-serving-critical-industries-in-mena/</guid><pubDate>Mon, 20 Oct 2025 08:15:50 +0000</pubDate></item><item><title>[NEW] Flowers of the future (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/20/1125345/plant-future-climate-change-research-project/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Flowers play a key role in most landscapes, from urban to rural areas. There might be dandelions poking through the cracks in the pavement, wildflowers on the highway median, or poppies covering a hillside. We might notice the time of year they bloom and connect that to our changing climate. Perhaps we are familiar with their cycles: bud, bloom, wilt, seed. Yet flowers have much more to tell in their bright blooms: The very shape they take is formed by local and global climate conditions.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The form of a flower is a visual display of its climate, if you know what to look for. In a dry year, its petals’ pigmentation may change. In a warm year, the flower might grow bigger. The flower’s ultraviolet-absorbing pigment increases with higher ozone levels. As the climate changes in the future, how might flowers change?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="white flower and a purple flower" class="wp-image-1125929" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/antho.jpg?w=275" /&gt;&lt;figcaption class="wp-element-caption"&gt;Anthocyanins are red or indigo pigments that supply antioxidants and photoprotectants, which help a plant tolerate climate-related stresses such as droughts.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;© 2021 SULLIVAN CN, KOSKI MH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;An artistic research project called Plant Futures imagines how a single species of flower might evolve in response to climate change between 2023 and 2100—and invites us to reflect on the complex, long-term impacts of our warming world. The project has created one flower for every year from 2023 to 2100. The form of each one is data-driven, based on climate projections and research into how climate influences flowers’ visual attributes.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="two rows of flowers that are both yellow and purple" class="wp-image-1125930" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-3-d.png?w=1280" /&gt;&lt;figcaption class="wp-element-caption"&gt;More ultraviolet pigment protects flowers’ pollen against increasing ozone levels.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO TODESCO&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a white flower with a yellow center" class="wp-image-1125931" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-3-e-Rosa__Kent__d.j.b_01.jpg?w=640" /&gt;&lt;figcaption class="wp-element-caption"&gt;Under unpredictable weather conditions, the speculative flowers grow a second layer of petals. In botany, a second layer is called a “double bloom” and arises from random mutations.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF ANNELIE BERNER&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Plant Futures began during an artist residency in Helsinki, where I worked closely with the biologist Aku Korhonen to understand how climate change affected the local ecosystem. While exploring the primeval Haltiala forest, I learned of the &lt;em&gt;Circaea alpina&lt;/em&gt;, a tiny flower that was once rare in that area but has become more common as temperatures have risen in recent years. Yet its habitat is delicate: The plant requires shade and a moist environment, and the spruce population that provides those conditions is declining in the face of new forest pathogens. I wondered: What if the &lt;em&gt;Circaea alpina &lt;/em&gt;could survive in spite of climate uncertainty? If the dark, shaded bogs turn into bright meadows and the wet ground dries out, how might the flower adapt in order to survive? This flower’s potential became the project’s grounding point.&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1125926" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-2_herbarium.jpg?w=2221" width="2221" /&gt;&lt;figcaption class="wp-element-caption"&gt;The author studying historical &lt;em&gt;Circaea&lt;/em&gt; samples in the Luomus Botanical Collections.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF ANNELIE BERNER&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Outside the forest, I worked with botanical experts in the Luomus Botanical Collections. I studied samples of &lt;em&gt;Circaea &lt;/em&gt;flowers from as far back as 1906, and I researched historical climate conditions in an attempt to understand how flower size and color related to a year’s temperature and precipitation patterns.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I researched how other flowering plants respond to changes to their climate conditions and wondered how the &lt;em&gt;Circaea&lt;/em&gt; would need to adapt to thrive in a future world. If such changes happened, what would the &lt;em&gt;Circaea&lt;/em&gt; look like in 2100?&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1125939" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-4_technical-interface.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;We designed the future flowers through a combination of data-driven algorithmic mapping and artistic control. I worked with the data artist Marcin Ignac from Variable Studio to create 3D flowers whose appearance was connected to climate data. Using Nodes.io, we made a 3D model of the &lt;em&gt;Circaea alpina&lt;/em&gt; based on its current morphology and then mapped how those physical parameters might shift as the climate changes. For example, as the temperature rises and precipitation decreases in the data set, the petal color shifts toward red, reflecting how flowers protect themselves with an increase in anthocyanins. Changes in temperature, carbon dioxide levels, and precipitation rates combine to affect the flowers’ size, density of veins, UV pigments, color, and tendency toward double bloom.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1125943" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-6_2025.png?w=2914" /&gt;&lt;figcaption class="wp-element-caption"&gt;2025: &lt;em&gt;Circaea alpina&lt;/em&gt; is ever so slightly larger than usual owing to a warmer summer, but it is otherwise close to the typical &lt;em&gt;Circaea&lt;/em&gt; flower in size, color, and other attributes.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1125944" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-7_2064.png?w=2915" /&gt;&lt;figcaption class="wp-element-caption"&gt;2064: We see a bigger flower with more petals, given an increase in carbon dioxide levels and temperature. The bull’s-eye pattern, composed of UV pigment, is bigger and messier because of an increase in ozone and solar radiation. A second tier of petals reflects uncertainty in the climate model.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1125945" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-8_2074.png?w=2915" /&gt;&lt;figcaption class="wp-element-caption"&gt;2074: The flower becomes pinker, an antioxidative response to the stress of consecutive dry days and higher temperatures. Its size increases, primarily because of higher levels of carbon dioxide. The double bloom of petals persists as the climate model’s projections increase in uncertainty.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1125946" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-9_2100.png?w=2915" /&gt;&lt;figcaption class="wp-element-caption"&gt;2100: The flower’s veins are densely packed, which could signal appropriation of a technique leaves use to improve water transport during droughts. It could also be part of a strategy to attract pollinators in the face of worsening air quality that degrades the transmission of scents.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1125949" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-10_variable-flowers.png?w=1639" width="1639" /&gt;&lt;figcaption class="wp-element-caption"&gt;2023—2100: Each year, the speculative flower changes. Size, color, and form shift in accordance with the increased temperature and carbon dioxide levels and the changes in precipitation patterns.&lt;/figcaption&gt;&lt;/figure&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1125952" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-11_alternative-sculpture.jpg?w=2116" width="2116" /&gt;&lt;figcaption class="wp-element-caption"&gt;In this 10-centimeter cube of plexiglass, the future flowers are “preserved,” allowing the viewer to see them in a comparative, layered view.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF ANNELIE BERNER&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;em&gt;Based in Copenhagen, Annelie Berner is a designer, researcher, teacher, and artist specializing in data visualization.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Flowers play a key role in most landscapes, from urban to rural areas. There might be dandelions poking through the cracks in the pavement, wildflowers on the highway median, or poppies covering a hillside. We might notice the time of year they bloom and connect that to our changing climate. Perhaps we are familiar with their cycles: bud, bloom, wilt, seed. Yet flowers have much more to tell in their bright blooms: The very shape they take is formed by local and global climate conditions.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The form of a flower is a visual display of its climate, if you know what to look for. In a dry year, its petals’ pigmentation may change. In a warm year, the flower might grow bigger. The flower’s ultraviolet-absorbing pigment increases with higher ozone levels. As the climate changes in the future, how might flowers change?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="white flower and a purple flower" class="wp-image-1125929" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/antho.jpg?w=275" /&gt;&lt;figcaption class="wp-element-caption"&gt;Anthocyanins are red or indigo pigments that supply antioxidants and photoprotectants, which help a plant tolerate climate-related stresses such as droughts.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;© 2021 SULLIVAN CN, KOSKI MH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;An artistic research project called Plant Futures imagines how a single species of flower might evolve in response to climate change between 2023 and 2100—and invites us to reflect on the complex, long-term impacts of our warming world. The project has created one flower for every year from 2023 to 2100. The form of each one is data-driven, based on climate projections and research into how climate influences flowers’ visual attributes.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="two rows of flowers that are both yellow and purple" class="wp-image-1125930" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-3-d.png?w=1280" /&gt;&lt;figcaption class="wp-element-caption"&gt;More ultraviolet pigment protects flowers’ pollen against increasing ozone levels.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;MARCO TODESCO&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a white flower with a yellow center" class="wp-image-1125931" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-3-e-Rosa__Kent__d.j.b_01.jpg?w=640" /&gt;&lt;figcaption class="wp-element-caption"&gt;Under unpredictable weather conditions, the speculative flowers grow a second layer of petals. In botany, a second layer is called a “double bloom” and arises from random mutations.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF ANNELIE BERNER&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Plant Futures began during an artist residency in Helsinki, where I worked closely with the biologist Aku Korhonen to understand how climate change affected the local ecosystem. While exploring the primeval Haltiala forest, I learned of the &lt;em&gt;Circaea alpina&lt;/em&gt;, a tiny flower that was once rare in that area but has become more common as temperatures have risen in recent years. Yet its habitat is delicate: The plant requires shade and a moist environment, and the spruce population that provides those conditions is declining in the face of new forest pathogens. I wondered: What if the &lt;em&gt;Circaea alpina &lt;/em&gt;could survive in spite of climate uncertainty? If the dark, shaded bogs turn into bright meadows and the wet ground dries out, how might the flower adapt in order to survive? This flower’s potential became the project’s grounding point.&amp;nbsp;&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1125926" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-2_herbarium.jpg?w=2221" width="2221" /&gt;&lt;figcaption class="wp-element-caption"&gt;The author studying historical &lt;em&gt;Circaea&lt;/em&gt; samples in the Luomus Botanical Collections.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF ANNELIE BERNER&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Outside the forest, I worked with botanical experts in the Luomus Botanical Collections. I studied samples of &lt;em&gt;Circaea &lt;/em&gt;flowers from as far back as 1906, and I researched historical climate conditions in an attempt to understand how flower size and color related to a year’s temperature and precipitation patterns.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I researched how other flowering plants respond to changes to their climate conditions and wondered how the &lt;em&gt;Circaea&lt;/em&gt; would need to adapt to thrive in a future world. If such changes happened, what would the &lt;em&gt;Circaea&lt;/em&gt; look like in 2100?&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1125939" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-4_technical-interface.jpg" /&gt;&lt;figcaption class="wp-element-caption"&gt;We designed the future flowers through a combination of data-driven algorithmic mapping and artistic control. I worked with the data artist Marcin Ignac from Variable Studio to create 3D flowers whose appearance was connected to climate data. Using Nodes.io, we made a 3D model of the &lt;em&gt;Circaea alpina&lt;/em&gt; based on its current morphology and then mapped how those physical parameters might shift as the climate changes. For example, as the temperature rises and precipitation decreases in the data set, the petal color shifts toward red, reflecting how flowers protect themselves with an increase in anthocyanins. Changes in temperature, carbon dioxide levels, and precipitation rates combine to affect the flowers’ size, density of veins, UV pigments, color, and tendency toward double bloom.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1125943" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-6_2025.png?w=2914" /&gt;&lt;figcaption class="wp-element-caption"&gt;2025: &lt;em&gt;Circaea alpina&lt;/em&gt; is ever so slightly larger than usual owing to a warmer summer, but it is otherwise close to the typical &lt;em&gt;Circaea&lt;/em&gt; flower in size, color, and other attributes.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1125944" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-7_2064.png?w=2915" /&gt;&lt;figcaption class="wp-element-caption"&gt;2064: We see a bigger flower with more petals, given an increase in carbon dioxide levels and temperature. The bull’s-eye pattern, composed of UV pigment, is bigger and messier because of an increase in ozone and solar radiation. A second tier of petals reflects uncertainty in the climate model.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1125945" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-8_2074.png?w=2915" /&gt;&lt;figcaption class="wp-element-caption"&gt;2074: The flower becomes pinker, an antioxidative response to the stress of consecutive dry days and higher temperatures. Its size increases, primarily because of higher levels of carbon dioxide. The double bloom of petals persists as the climate model’s projections increase in uncertainty.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1125946" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-9_2100.png?w=2915" /&gt;&lt;figcaption class="wp-element-caption"&gt;2100: The flower’s veins are densely packed, which could signal appropriation of a technique leaves use to improve water transport during droughts. It could also be part of a strategy to attract pollinators in the face of worsening air quality that degrades the transmission of scents.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1125949" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-10_variable-flowers.png?w=1639" width="1639" /&gt;&lt;figcaption class="wp-element-caption"&gt;2023—2100: Each year, the speculative flower changes. Size, color, and form shift in accordance with the increased temperature and carbon dioxide levels and the changes in precipitation patterns.&lt;/figcaption&gt;&lt;/figure&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1125952" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image-11_alternative-sculpture.jpg?w=2116" width="2116" /&gt;&lt;figcaption class="wp-element-caption"&gt;In this 10-centimeter cube of plexiglass, the future flowers are “preserved,” allowing the viewer to see them in a comparative, layered view.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF ANNELIE BERNER&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;em&gt;Based in Copenhagen, Annelie Berner is a designer, researcher, teacher, and artist specializing in data visualization.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/20/1125345/plant-future-climate-change-research-project/</guid><pubDate>Mon, 20 Oct 2025 10:00:00 +0000</pubDate></item><item><title>[NEW] AI could predict who will have a heart attack (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/20/1125336/ai-heart-attack-prediction/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AdobeStock_632825639.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;For all the modern marvels of cardiology, we struggle to predict who will have a heart attack. Many people never get screened at all. Now, startups like Bunkerhill Health, Nanox.AI, and HeartLung Technologies are applying AI algorithms to screen millions of CT scans for early signs of heart disease. This technology could be a breakthrough for public health, applying an old tool to uncover patients whose high risk for a heart attack is hiding in plain sight. But it remains unproven at scale while raising thorny questions about implementation and even how we define disease.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last year, an estimated 20 million Americans had chest CT scans done, after an event like a car accident or to screen for lung cancer. Frequently, they show evidence of coronary artery calcium (CAC), a marker for heart attack risk, that is buried or not mentioned in a radiology report focusing on ruling out bony injuries, life-threatening internal trauma, or cancer.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Dedicated testing for CAC remains an underutilized method of predicting heart attack risk. Over decades, plaque in heart arteries moves through its own life cycle, hardening from lipid-rich residue into calcium. Heart attacks themselves typically occur when younger, lipid-rich plaque unpredictably ruptures, kicking off a clotting cascade of inflammation that ultimately blocks the heart’s blood supply. Calcified plaque is generally stable, but finding CAC suggests that younger, more rupture-prone plaque is likely present too.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Coronary artery calcium can often be spotted on chest CTs, and its concentration can be subjectively described. Normally, quantifying a person’s CAC score involves obtaining a heart-specific CT scan. Algorithms that calculate CAC scores from routine chest CTs, however, could massively expand access to this metric. In practice, these algorithms could then be deployed to alert patients and their doctors about abnormally high scores, encouraging them to seek further care. Today, the footprint of the startups offering AI-derived CAC scores is not large, but it is growing quickly. As their use grows, these algorithms may identify high-risk patients who are traditionally missed or who are on the margins of care.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Historically, CAC scans were believed to have marginal benefit and were marketed to the worried well. Even today, most insurers won’t cover them. Attitudes, though, may be shifting. More expert groups are endorsing CAC scores as a way to refine cardiovascular risk estimates and persuade skeptical patients to start taking statins.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The promise of AI-derived CAC scores is part of a broader trend toward mining troves of medical data to spot otherwise undetected disease. But while it seems promising, the practice raises plenty of questions. For example, CAC scores ­haven’t proved useful as a blunt instrument for universal screening. A 2022 Danish study evaluating a population-based program, for example, showed no benefit in mortality rates for patients who had undergone CAC screening tests. If AI delivered this information automatically, would the calculus really shift?&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;And with widespread adoption, abnormal CAC scores will become common. Who follows up on these findings? “Many health systems aren’t yet set up to act on incidental calcium findings at scale,” says Nishith Khandwala, the cofounder of Bunkerhill Health. Without a standard procedure for doing so, he says, “you risk creating more work than value.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;There’s also the question of whether these AI-generated scores would actually improve patient care. For a symptomatic patient, a CAC score of zero may offer false reassurance. For the asymptomatic patient with a high CAC score, the next steps remain uncertain. Beyond statins, it isn’t clear if these patients would benefit from starting costly cholesterol-lowering drugs such as Repatha or other PCSK9-inhibitors. It may encourage some to pursue unnecessary but costly downstream procedures that could even end up doing harm. Currently, AI-derived CAC scoring is not reimbursed as a separate service by Medicare or most insurers. The business case for this technology today, effectively, lies in these potentially perverse incentives.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At a fundamental level, this approach could actually change how we define disease. Adam Rodman, a hospitalist and AI expert at Beth Israel Deaconess Medical Center in Boston, has observed that AI-derived CAC scores share similarities with the “incidentaloma,” a term coined in the 1980s to describe unexpected findings on CT scans. In both cases, the normal pattern of diagnosis—in which doctors and patients deliberately embark on testing to figure out what’s causing a specific problem—were fundamentally disrupted. But, as Rodman notes, incidentalomas were still found by humans reviewing the scans.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Now, he says, we are entering an era of “machine-based nosology,” where algorithms define diseases on their own terms. As machines make more diagnoses, they may catch things we miss. But Rodman and I began to wonder if a two-tiered diagnostic future may emerge, where “haves” pay for brand-name algorithms while “have-nots” settle for lesser alternatives.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For patients who have no risk factors or are detached from regular medical care, an AI-derived CAC score could potentially catch problems earlier and rewrite the script. But how these scores reach people, what is done about them, and whether they can ultimately improve patient outcomes at scale remain open questions. For now—holding the pen as they toggle between patients and algorithmic outputs—clinicians still matter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Vishal Khetpal is a fellow in cardiovascular disease. The views expressed in this article do not represent those of his employers.&amp;nbsp;&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AdobeStock_632825639.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;For all the modern marvels of cardiology, we struggle to predict who will have a heart attack. Many people never get screened at all. Now, startups like Bunkerhill Health, Nanox.AI, and HeartLung Technologies are applying AI algorithms to screen millions of CT scans for early signs of heart disease. This technology could be a breakthrough for public health, applying an old tool to uncover patients whose high risk for a heart attack is hiding in plain sight. But it remains unproven at scale while raising thorny questions about implementation and even how we define disease.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last year, an estimated 20 million Americans had chest CT scans done, after an event like a car accident or to screen for lung cancer. Frequently, they show evidence of coronary artery calcium (CAC), a marker for heart attack risk, that is buried or not mentioned in a radiology report focusing on ruling out bony injuries, life-threatening internal trauma, or cancer.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Dedicated testing for CAC remains an underutilized method of predicting heart attack risk. Over decades, plaque in heart arteries moves through its own life cycle, hardening from lipid-rich residue into calcium. Heart attacks themselves typically occur when younger, lipid-rich plaque unpredictably ruptures, kicking off a clotting cascade of inflammation that ultimately blocks the heart’s blood supply. Calcified plaque is generally stable, but finding CAC suggests that younger, more rupture-prone plaque is likely present too.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Coronary artery calcium can often be spotted on chest CTs, and its concentration can be subjectively described. Normally, quantifying a person’s CAC score involves obtaining a heart-specific CT scan. Algorithms that calculate CAC scores from routine chest CTs, however, could massively expand access to this metric. In practice, these algorithms could then be deployed to alert patients and their doctors about abnormally high scores, encouraging them to seek further care. Today, the footprint of the startups offering AI-derived CAC scores is not large, but it is growing quickly. As their use grows, these algorithms may identify high-risk patients who are traditionally missed or who are on the margins of care.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Historically, CAC scans were believed to have marginal benefit and were marketed to the worried well. Even today, most insurers won’t cover them. Attitudes, though, may be shifting. More expert groups are endorsing CAC scores as a way to refine cardiovascular risk estimates and persuade skeptical patients to start taking statins.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The promise of AI-derived CAC scores is part of a broader trend toward mining troves of medical data to spot otherwise undetected disease. But while it seems promising, the practice raises plenty of questions. For example, CAC scores ­haven’t proved useful as a blunt instrument for universal screening. A 2022 Danish study evaluating a population-based program, for example, showed no benefit in mortality rates for patients who had undergone CAC screening tests. If AI delivered this information automatically, would the calculus really shift?&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;And with widespread adoption, abnormal CAC scores will become common. Who follows up on these findings? “Many health systems aren’t yet set up to act on incidental calcium findings at scale,” says Nishith Khandwala, the cofounder of Bunkerhill Health. Without a standard procedure for doing so, he says, “you risk creating more work than value.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;There’s also the question of whether these AI-generated scores would actually improve patient care. For a symptomatic patient, a CAC score of zero may offer false reassurance. For the asymptomatic patient with a high CAC score, the next steps remain uncertain. Beyond statins, it isn’t clear if these patients would benefit from starting costly cholesterol-lowering drugs such as Repatha or other PCSK9-inhibitors. It may encourage some to pursue unnecessary but costly downstream procedures that could even end up doing harm. Currently, AI-derived CAC scoring is not reimbursed as a separate service by Medicare or most insurers. The business case for this technology today, effectively, lies in these potentially perverse incentives.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At a fundamental level, this approach could actually change how we define disease. Adam Rodman, a hospitalist and AI expert at Beth Israel Deaconess Medical Center in Boston, has observed that AI-derived CAC scores share similarities with the “incidentaloma,” a term coined in the 1980s to describe unexpected findings on CT scans. In both cases, the normal pattern of diagnosis—in which doctors and patients deliberately embark on testing to figure out what’s causing a specific problem—were fundamentally disrupted. But, as Rodman notes, incidentalomas were still found by humans reviewing the scans.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Now, he says, we are entering an era of “machine-based nosology,” where algorithms define diseases on their own terms. As machines make more diagnoses, they may catch things we miss. But Rodman and I began to wonder if a two-tiered diagnostic future may emerge, where “haves” pay for brand-name algorithms while “have-nots” settle for lesser alternatives.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For patients who have no risk factors or are detached from regular medical care, an AI-derived CAC score could potentially catch problems earlier and rewrite the script. But how these scores reach people, what is done about them, and whether they can ultimately improve patient outcomes at scale remain open questions. For now—holding the pen as they toggle between patients and algorithmic outputs—clinicians still matter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Vishal Khetpal is a fellow in cardiovascular disease. The views expressed in this article do not represent those of his employers.&amp;nbsp;&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/20/1125336/ai-heart-attack-prediction/</guid><pubDate>Mon, 20 Oct 2025 10:00:00 +0000</pubDate></item><item><title>[NEW] Should an AI copy of you help decide if you live or die? (AI – Ars Technica)</title><link>https://arstechnica.com/features/2025/10/should-an-ai-copy-of-you-help-decide-if-you-live-or-die/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 dark:bg-gray-700 md:my-10 md:py-8"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      Doctors share top concerns of AI surrogates aiding life-or-death decisions.
    &lt;/p&gt;

    

    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/pull-the-plug.jpg" width="2560" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;For more than a decade, researchers have wondered whether artificial intelligence could help predict what incapacitated patients might want when doctors must make life-or-death decisions on their behalf.&lt;/p&gt;
&lt;p&gt;It remains one of the most high-stakes questions in health care AI today. But as AI improves, some experts increasingly see it as inevitable that digital “clones” of patients could one day aid family members, doctors, and ethics boards in making end-of-life decisions that are aligned with a patient’s values and goals.&lt;/p&gt;
&lt;p&gt;Ars spoke with experts conducting or closely monitoring this research who confirmed that no hospital has yet deployed so-called “AI surrogates.” But AI researcher Muhammad Aurangzeb Ahmad is aiming to change that, taking the first steps toward piloting AI surrogates at a US medical facility.&lt;/p&gt;
&lt;p&gt;“This is very brand new, so very few people are working on it,” Ahmad told Ars.&lt;/p&gt;
&lt;p&gt;Ahmad is a resident fellow working with trauma department faculty at the University of Washington’s UW Medicine. His research is based at Harborview Medical Center in Seattle, a public hospital in the UW Medicine health system. UW Medicine is integrated with “one of the world’s largest medical research programs” to pursue its mission of improving public health outcomes, UW’s website says.&lt;/p&gt;
&lt;p&gt;UW wasn’t specifically seeking a fellow to experiment with AI surrogates, Ahmad told Ars. But since his project proposal was accepted, he has spent most of this year “in the conceptual phase,” working toward testing the accuracy of AI models based on Harborview patient data.&lt;/p&gt;
&lt;p&gt;The main limitation of this testing, Ahmad said, is that he can only verify the accuracy of his models if patients survive and can later confirm that the model made the right choice. But this is just the first step, he said. The accuracy testing could then expand to other facilities in the network, with the aim of developing AI surrogates that can accurately predict patient preferences about “two-thirds” of the time.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Currently, Ahmad’s models are focused on analyzing data that Harborview already collects, such as injury severity, medical history, prior medical choices, and demographic information.&lt;/p&gt;
&lt;p&gt;“We use that information, feed it to a machine learning predictive model, and then in the retrospective data, we observe how well the model is doing,” Ahmad said.&lt;/p&gt;
&lt;p&gt;No patient has yet interacted with Ahmad’s models, he confirmed. UW Medicine spokesperson Susan Gregg told Ars there’s “considerable work to complete prior to launch,” and the system “would be approved only after a multiple-stage review process.”&lt;/p&gt;
&lt;p&gt;“We have not enrolled any patients at Harborview,” Ahmad said. “We are still at the phase of defining the scope and what theoretical considerations to take into account. It will be some time before it gets off the ground, given the challenges involved.”&lt;/p&gt;
&lt;p&gt;In the future, though, Ahmad envisions models that would also analyze textual data, perhaps from patient-approved recorded conversations with their doctors, to inform their AI copy’s predictions. In that world, trusted human surrogates, such as family members, could provide other textual data from chats or texts with the patient. In the technology’s most “ideal” form, Ahmad sees patients interacting with AI systems throughout their lives, providing feedback to refine models as the patients age through the health system.&lt;/p&gt;
&lt;p&gt;“It takes time to get the relevant data,” Ahmad said.&lt;/p&gt;
&lt;p&gt;Before patients could begin interacting with AI surrogates, any human subject testing would need to be approved by an institutional review board (IRB), Ahmad said.&lt;/p&gt;
&lt;p&gt;Ultimately, he expects that AI surrogates won’t be a perfect model but rather a set of rigorously tested systems that doctors and loved ones can consult when assessing all the known information about what a patient would want in critical moments.&lt;/p&gt;
&lt;p&gt;Whether hospitals would ever adopt such a system is unclear. “Within this space, practitioners are more conservative, and I would even argue that’s rightfully so,” Ahmad said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Gregg told Ars that UW Medicine supports the “thoughtful exploration of innovative ideas, such as the potential responsible and transparent use of AI surrogates in end-of-life care,” as they reflect “our commitment to advancing both science and compassion in medicine.”&lt;/p&gt;
&lt;p&gt;“While end-of-life decision-making represents a particularly complex area, we view these decisions as essential to addressing important questions, such as how to best honor patient wishes when they may be unable to communicate them directly or have no next of kin to do so on their behalf,” Gregg said.&lt;/p&gt;
&lt;h2&gt;Is AI a bad fit for patients with no human surrogates?&lt;/h2&gt;
&lt;p&gt;It has always been hard for doctors to determine what patients want when they can’t speak for themselves. A patient may refuse to be put on a ventilator or receive dialysis or cardiopulmonary resuscitation (CPR) if, for example, they’ve expressed that they want to avoid discomfort at the end of their life. Others may fear complications like infections or have no desire to rely on a machine for life support. Some patients, like young people involved in accidents, may have never expressed preferences.&lt;/p&gt;
&lt;p&gt;Emily Moin, a physician in an intensive care unit in Pennsylvania, told Ars that time is a factor in these decisions, but it’s imperative that a human surrogate who may better understand the patient’s wishes be involved.&lt;/p&gt;
&lt;p&gt;“When we’re in one of these fast-paced situations where we don’t know, but we have a patient in front of us who has died, we will err on the side of providing [CPR] until we are able to arrive at the clinical judgment that that effort is no longer indicated or until we’re able to engage with a surrogate decision maker,” Moin explained.&lt;/p&gt;
&lt;p&gt;Reaching the surrogate, she said, is “an important part of taking care of someone.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Ahmad hopes that AI could help alleviate stress in uncertain moments. For doctors and surrogates, these decisions can be “very emotionally taxing,” Ahmad told Ars, leading many people to second-guess what the patient would choose. Some studies have shown that surrogates often get it wrong, he said, and he believes AI could help improve the odds of success.&lt;/p&gt;
&lt;p&gt;Seeking to nip this problem in the bud, health systems have historically pushed patients to complete “advanced directives” to log their preferences. Over time, though, it has become clear that patients’ preferences tend to be unstable, sometimes changing within days.&lt;/p&gt;
&lt;p&gt;Doctors must also consider that some patients have no stated preferences. Others, Moin said, have reported that their preferences changed after receiving lifesaving treatments because they now know what to expect. These are likely other limitations of Ahmad’s planned testing, which would determine accuracy by checking whether the AI’s decision matches what a patient says they would have wanted after recovery, Moin said.&lt;/p&gt;
&lt;p&gt;“These decisions are dynamically constructed and context-dependent,” Moin said. “And if you’re assessing the performance of the model based on asking someone after they’ve recovered what they would have said before they recovered, that’s not going to provide you with an accurate representation.”&lt;/p&gt;
&lt;p&gt;Moin said one of the big problems with medical AI is that people expect it to “provide better predictions than what we’re currently able to generate.” But the models are being trained on “convenient ground truths,” she said, that don’t “provide meaningful examples for models to learn about the situations” where the models would be employed.&lt;/p&gt;
&lt;p&gt;“I imagine that they would actually want to deploy this model to help to make decisions for unrepresented patients, patients who can’t communicate, patients who don’t have a surrogate,” Moin said, “but those are exactly the patients where you’ll never be able to know what the so-called ground truth is, and then you’ll never be able to assess your bias, and you’ll never be able to assess your model’s performance.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Family members may default to agreeing with AI&lt;/h2&gt;
&lt;p&gt;Culturally, the US has shifted from being “very focused on patient autonomy” to “more of a shared decision-making and, at times, family- and community-focused lens” as the standard for making these difficult decisions, Moin said.&lt;/p&gt;
&lt;p&gt;The longer a doctor knows a patient, and the more conversations a patient’s health team has with family members, the more likely it is for health systems to be able to adapt to respect the patient’s wishes over time, Moin suggested.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;That idea echoes Ahmad’s “ideal” AI surrogate model. But Moin said that if patients talk to an AI, it could actually discourage them from having important conversations with family members. Studies have found that if a patient fills out advanced directives, it can become harder to determine their preferences, Moin said, because patients may be less likely to discuss their preferences with loved ones.&lt;/p&gt;
&lt;p&gt;Earlier this year, Moin urged human surrogates to remain closely involved in do-not-resuscitate orders, writing that doctors who unilaterally make these decisions have an ethical obligation to “ensure that patients and surrogate decision-makers are aware that the decision has been made” and face “the lowest of barriers” to expressing disagreement.&lt;/p&gt;
&lt;p&gt;“Forgoing CPR is one of the most consequential treatment decisions a patient or surrogate can make because, if invoked, it will necessarily lead to death,” Moin wrote.&lt;/p&gt;
&lt;p&gt;Moin told Ars she hopes an AI surrogate’s outputs would never be weighted more than a human surrogate’s opinion, which is based on lived experience with a patient. “But I do worry that there could be culture shifts and other pressures that would encourage clinicians and family members, for that matter, to lean on products like these more heavily,” she said.&lt;/p&gt;
&lt;p&gt;“I can imagine a scenario where, say, a doctor is expected to round on 24 critically ill patients in one day, and the family member is resistant to sitting down for a conversation,” Moin said. “So yeah, maybe all parties involved would default to the shortcut of incorporating the information from this model.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Moin called for more public awareness and debate on AI surrogates, noting that “people really hate” the use of algorithms to determine who gets care.&lt;/p&gt;
&lt;p&gt;“I don’t think that it would be good for patients or clinicians or society for that matter,” Moin said.&lt;/p&gt;
&lt;p&gt;She’s particularly worried that “patients who can’t speak for themselves and who don’t have a clear loved one” would be “the ones who would be most vulnerable to suffering harms” of AI surrogates making wrong calls. Too many such mistakes could further erode trust in health systems, Moin said.&lt;/p&gt;
&lt;h2&gt;AI surrogates may be redundant&lt;/h2&gt;
&lt;p&gt;These decisions are “psychosocially fraught” for everyone involved, Teva Brender, a hospitalist at a medical center for veterans in San Francisco, told Ars. That’s why testing like Ahmad’s is important, he said.&lt;/p&gt;
&lt;p&gt;Last year, Brender co-authored an opinion piece&amp;nbsp;noting “how difficult it can be for families to make decisions for incapacitated patients,” particularly in geriatrics, palliative, and critical care settings.&lt;/p&gt;
&lt;p&gt;“For many, the notion of incorporating AI into goals-of-care conversations will conjure nightmarish visions of a dystopian future wherein we entrust deeply human decisions to algorithms,” Brender’s team wrote. “We share these apprehensions.”&lt;/p&gt;
&lt;p&gt;But with doctors’ and surrogates’ predictions facing significant limitations, “it behooves us to consider how AI could be safely, ethically, and equitably deployed to help surrogates for individuals who are seriously ill,” Brender’s team concluded.&lt;/p&gt;
&lt;p&gt;And it’s “equally important,” Brender told Ars, to help patients choose surrogates and prepare them to substitute their judgments.&lt;/p&gt;
&lt;p&gt;Brender believes Ahmad’s research is worthwhile since there are “lots of questions” requiring scientific research. But he’s “glad to hear” that AI surrogates are “not actually being used among patients” at Harborview yet. “I can’t imagine that an IRB would approve such a thing this early,” he told Ars.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;And AI surrogates may end up playing a redundant role, leading this potential use for AI to fall out of favor, Brender said.&lt;/p&gt;
&lt;p&gt;“The devil’s advocate perspective,” Brender said, is that AI surrogates would just be doing “what a good clinician does anyway,” which is to ask surrogates, “Hey, who was this person? What did they enjoy doing? What brought meaning to their life?”&lt;/p&gt;
&lt;p&gt;“Do you need an AI to do that?” Brender asked. “I’m not so sure.”&lt;/p&gt;
&lt;h2&gt;AI can’t replace human surrogates, doctors warn&lt;/h2&gt;
&lt;p&gt;Last month, bioethics expert Robert Truog joined R. Sean Morrison, a doctor dedicated to advancing palliative care aimed at improving the quality of life for people suffering life-threatening illnesses, in emphasizing that AI should never replace human surrogates in resuscitation decisions.&lt;/p&gt;
&lt;p&gt;“Decisions about hypothetical scenarios do not correlate with decisions that need to be made in real time,” Morrison told Ars. “AI cannot fix this fundamental issue—it is not a matter of better prediction. Patients’ preferences often represent a snapshot in time that are simply not predictive of the future.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The warning came after Georg Starke, a doctor and senior research associate at the Chair for Ethics of AI and Neuroscience at the Technical University of Munich, co-authored a proof-of-concept showing that three AI models, on average, performed better than human surrogates in predicting patient preferences.&lt;/p&gt;
&lt;p&gt;Starke’s study relied on existing data from Swiss respondents of a European survey that tracked population health trends of individuals over 50 years old. The dataset offered “comprehensive information on participants’ end-of-life preferences, including questions concerning” CPR. That allowed the team to build three models: a simple model, a model based on commonly available electronic health records, and a more “personalized” model. Each model successfully predicted whether a patient experiencing cardiac arrest would want CPR, with an accuracy of up to 70 percent.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;His team’s research was intended to “ground a long-standing ethical debate in empirical data,” Starke told Ars.&lt;/p&gt;
&lt;p&gt;“For over a decade, people have speculated about using algorithms to improve clinical decision-making for incapacitated patients, but no one had shown whether such a program could actually be designed,” Starke said. “Our study was meant to test if it’s feasible, explore how well it performs, identify which factors influence the models’ decisions, and spark a broader debate about the technology.”&lt;/p&gt;
&lt;p&gt;A key limitation of AI models depending on “‘accuracy’ alone”—especially if that “accuracy” is “achieved by chance or by pattern-matching purely demographic data outside an individual’s control”—is that the outputs don’t “necessarily reflect an autonomous choice,” Starke said.&lt;/p&gt;
&lt;p&gt;Like Truog and Morrison, Starke’s team emphasized that “human surrogates will remain essential sources for the contextual aspects of specific situations,” particularly with patients with dementia, and agreed that AI models “should not replace surrogate decision-making.”&lt;/p&gt;
&lt;h2&gt;Chatbot surrogates could be bad&lt;/h2&gt;
&lt;p&gt;Human surrogates may grow to trust AI systems in the future, but “it’s all about how the information is presented,” Brender, the hospitalist, told Ars.&lt;/p&gt;
&lt;p&gt;He thinks that AI systems could best serve as a “launchpad” for discussions, giving surrogates a way to consider what data may be significant to the patient.&lt;/p&gt;
&lt;p&gt;But he agreed with Moin that without transparency about how AI surrogates arrive at decisions, AI could sow distrust.&lt;/p&gt;
&lt;p&gt;Imagine, for example, if an AI system didn’t know about a new treatment for cancer that could completely change a patient’s prognosis. Patients might be better served, Brender suggested, if hospitals invested in AI to improve prognosis instead of “literally predicting what a patient would want.” Truog and Morrison also suggested that AI research like Ahmad’s could help hospitals determine what kinds of patients tend to have more stable preferences over time.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Brender suggested that a nightmare scenario could arise if an AI surrogate, presented in a chatbot interface, leads doctors and family members to put “too much trust” in an algorithm. That’s why transparency and rigorous testing will be critical if this technology is ever deployed, he said.&lt;/p&gt;
&lt;p&gt;“If a black-box algorithm says that grandmother would not want resuscitation, I don’t know that that’s helpful,” Brender said. “You need it to be explainable.”&lt;/p&gt;
&lt;h2&gt;Research on bias of AI surrogates doesn’t exist&lt;/h2&gt;
&lt;p&gt;Ahmad agreed that a human should always be in the loop. He emphasized that he’s not rushing to deploy his AI models, which remain in the conceptual phase. Complicating his work, there’s currently little research exploring bias and fairness in the use of AI surrogates.&lt;/p&gt;
&lt;p&gt;Ahmad aims to begin to fill in that gap with a pre-print paper set for release this week that maps out various notions of fairness and then examines fairness across moral traditions. Ultimately, Ahmad suggests, fairness in using AI surrogates “extends beyond parity of outcomes to encompass moral representation, fidelity to the patient’s values, relationships, and worldview.”&lt;/p&gt;
&lt;p class="p1"&gt;“The central question becomes not only, ‘Is the model unbiased?’ but ‘&lt;span class="s1"&gt;Whose moral universe does the model inhabit?'” Ahmad wrote, providing an example:&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p class="p1"&gt;Consider the following: Two patients of &lt;span class="s1"&gt;similar clinical profiles may differ in moral reasoning, one guided by autonomy, another by family or religious duty. &lt;/span&gt;Treating them “similarly” in algorithmic terms would constitute moral erasure. Individual fairness requires incorporating value-sensitive features, such as recorded spiritual preferences or statements about comfort, without violating privacy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It could be more than a decade before the technology is deployed to patients, if it ever happens, Ahmad suggested, because of how challenging it is for AI models to be trained to calculate something as complex as a person’s values and beliefs.&lt;/p&gt;
&lt;p&gt;“That’s where things become really complicated,” Ahmad told Ars, noting “there’s societal norms, and then there’s norms within a particular religious group.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Consider an “extreme example,” Ahmad said. Imagine the puzzle doctors might face if they’re trying to decide if a pregnant woman involved in an accident should be taken off a ventilator because outdated records show she once marked that as her preference. A human surrogate, like her partner or a family member, might be able to advocate on her behalf to stay on the ventilator, particularly if the woman holds pro-life views, he said.&lt;/p&gt;
&lt;p&gt;Without a human surrogate, doctors could turn to AI to help them make a decision, but only if the AI system is able to capture the patient’s values and beliefs based on “patterns learned from data, clinical variables, demographic information, linguistic markers in clinical notes, and possibly the patient’s digital footprint,” Ahmad’s paper explains.&lt;/p&gt;
&lt;p&gt;Then there’s the issue of AI models being “somewhat brittle,” Ahmad said, perhaps giving “a very different answer” if a question is worded slightly differently or in a “clever” way the model doesn’t understand.&lt;/p&gt;
&lt;p&gt;Ahmad is not shying away from what he calls “the problem of engineering values.” To better understand how other researchers are approaching the issue and what expectations patients may have for AI surrogates, Ahmad recently attended an evangelical Christian conference on AI in Dallas, Texas. There, it seemed clear that in a future where AI surrogates are integrated into hospitals, some patients may have high expectations about how well large language models (LLMs) can replicate their inner truths.&lt;/p&gt;
&lt;p&gt;“One thing that really stood out was that people—especially when it comes to LLMs—there was a lot of discussions around having versions of LLMs which reflected their values,” Ahmad said.&lt;/p&gt;
&lt;p&gt;Starke told Ars he thinks it would be ideal to build models based on the most accessible electronic health records, at least from a clinical perspective. To best serve patients, though, he agreed with Ahmad and thinks that “an ideal dataset would be large, diverse, longitudinal, and purpose-built.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“It would combine demographic and clinical variables, documented advance-care-planning data, patient-recorded values and goals, and contextual information about specific decisions,” he said.&lt;/p&gt;
&lt;p&gt;“Including textual and conversational data could further increase a model’s ability to learn &lt;em&gt;why&lt;/em&gt; preferences arise and change, not just &lt;em&gt;what&lt;/em&gt; a patient’s preference was at a single point in time,” Starke said.&lt;/p&gt;
&lt;p&gt;Ahmad suggested that future research could focus on validating fairness frameworks in clinical trials, evaluating moral trade-offs through simulations, and exploring how cross-cultural bioethics can be combined with AI designs.&lt;/p&gt;
&lt;p&gt;Only then might AI surrogates be ready to be deployed, but only as “decision aids,” Ahmad wrote. Any “contested outputs” should automatically “trigger [an] ethics review,” Ahmad wrote, concluding that “the fairest AI surrogate is one that invites conversation, admits doubt, and leaves room for care.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;“AI will not absolve us”&lt;/h2&gt;
&lt;p&gt;Ahmad is hoping to test his conceptual models at various UW sites over the next five years, which would offer “some way to quantify how good this technology is,” he said.&lt;/p&gt;
&lt;p&gt;“After that, I think there’s a collective decision regarding how as a society we decide to integrate or not integrate something like this,” Ahmad said.&lt;/p&gt;
&lt;p&gt;In his paper, he warned against chatbot AI surrogates that could be interpreted as a simulation of the patient, predicting that future models may even speak in patients’ voices and suggesting that the “comfort and familiarity” of such tools might blur “the boundary between assistance and emotional manipulation.”&lt;/p&gt;
&lt;p&gt;Starke agreed that more research and “richer conversations” between patients and doctors are needed.&lt;/p&gt;
&lt;p&gt;“We should be cautious not to apply AI indiscriminately as a solution in search of a problem,” Starke said. “AI will not absolve us from making difficult ethical decisions, especially decisions concerning life and death.”&lt;/p&gt;
&lt;p&gt;Truog, the bioethics expert, told Ars he “could imagine that AI could” one day “provide a surrogate decision maker with some interesting information, and it would be helpful.”&lt;/p&gt;
&lt;p&gt;But a “problem with all of these pathways… is that they frame the decision of whether to perform CPR as a binary choice, regardless of context or the circumstances of the cardiac arrest,” Truog’s editorial said. “In the real world, the answer to the question of whether the patient would want to have CPR” when they’ve lost consciousness, “in almost all cases,” is “it depends.”&lt;/p&gt;
&lt;p&gt;When Truog thinks about the kinds of situations he could end up in, he knows he wouldn’t just be considering his own values, health, and quality of life. His choice “might depend on what my children thought” or “what the financial consequences would be on the details of what my prognosis would be,” he told Ars.&lt;/p&gt;
&lt;p&gt;“I would want my wife or another person that knew me well to be making those decisions,” Truog said. “I wouldn’t want somebody to say, ‘Well, here’s what AI told us about it.'”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 dark:bg-gray-700 md:my-10 md:py-8"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      Doctors share top concerns of AI surrogates aiding life-or-death decisions.
    &lt;/p&gt;

    

    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/pull-the-plug.jpg" width="2560" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;For more than a decade, researchers have wondered whether artificial intelligence could help predict what incapacitated patients might want when doctors must make life-or-death decisions on their behalf.&lt;/p&gt;
&lt;p&gt;It remains one of the most high-stakes questions in health care AI today. But as AI improves, some experts increasingly see it as inevitable that digital “clones” of patients could one day aid family members, doctors, and ethics boards in making end-of-life decisions that are aligned with a patient’s values and goals.&lt;/p&gt;
&lt;p&gt;Ars spoke with experts conducting or closely monitoring this research who confirmed that no hospital has yet deployed so-called “AI surrogates.” But AI researcher Muhammad Aurangzeb Ahmad is aiming to change that, taking the first steps toward piloting AI surrogates at a US medical facility.&lt;/p&gt;
&lt;p&gt;“This is very brand new, so very few people are working on it,” Ahmad told Ars.&lt;/p&gt;
&lt;p&gt;Ahmad is a resident fellow working with trauma department faculty at the University of Washington’s UW Medicine. His research is based at Harborview Medical Center in Seattle, a public hospital in the UW Medicine health system. UW Medicine is integrated with “one of the world’s largest medical research programs” to pursue its mission of improving public health outcomes, UW’s website says.&lt;/p&gt;
&lt;p&gt;UW wasn’t specifically seeking a fellow to experiment with AI surrogates, Ahmad told Ars. But since his project proposal was accepted, he has spent most of this year “in the conceptual phase,” working toward testing the accuracy of AI models based on Harborview patient data.&lt;/p&gt;
&lt;p&gt;The main limitation of this testing, Ahmad said, is that he can only verify the accuracy of his models if patients survive and can later confirm that the model made the right choice. But this is just the first step, he said. The accuracy testing could then expand to other facilities in the network, with the aim of developing AI surrogates that can accurately predict patient preferences about “two-thirds” of the time.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Currently, Ahmad’s models are focused on analyzing data that Harborview already collects, such as injury severity, medical history, prior medical choices, and demographic information.&lt;/p&gt;
&lt;p&gt;“We use that information, feed it to a machine learning predictive model, and then in the retrospective data, we observe how well the model is doing,” Ahmad said.&lt;/p&gt;
&lt;p&gt;No patient has yet interacted with Ahmad’s models, he confirmed. UW Medicine spokesperson Susan Gregg told Ars there’s “considerable work to complete prior to launch,” and the system “would be approved only after a multiple-stage review process.”&lt;/p&gt;
&lt;p&gt;“We have not enrolled any patients at Harborview,” Ahmad said. “We are still at the phase of defining the scope and what theoretical considerations to take into account. It will be some time before it gets off the ground, given the challenges involved.”&lt;/p&gt;
&lt;p&gt;In the future, though, Ahmad envisions models that would also analyze textual data, perhaps from patient-approved recorded conversations with their doctors, to inform their AI copy’s predictions. In that world, trusted human surrogates, such as family members, could provide other textual data from chats or texts with the patient. In the technology’s most “ideal” form, Ahmad sees patients interacting with AI systems throughout their lives, providing feedback to refine models as the patients age through the health system.&lt;/p&gt;
&lt;p&gt;“It takes time to get the relevant data,” Ahmad said.&lt;/p&gt;
&lt;p&gt;Before patients could begin interacting with AI surrogates, any human subject testing would need to be approved by an institutional review board (IRB), Ahmad said.&lt;/p&gt;
&lt;p&gt;Ultimately, he expects that AI surrogates won’t be a perfect model but rather a set of rigorously tested systems that doctors and loved ones can consult when assessing all the known information about what a patient would want in critical moments.&lt;/p&gt;
&lt;p&gt;Whether hospitals would ever adopt such a system is unclear. “Within this space, practitioners are more conservative, and I would even argue that’s rightfully so,” Ahmad said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Gregg told Ars that UW Medicine supports the “thoughtful exploration of innovative ideas, such as the potential responsible and transparent use of AI surrogates in end-of-life care,” as they reflect “our commitment to advancing both science and compassion in medicine.”&lt;/p&gt;
&lt;p&gt;“While end-of-life decision-making represents a particularly complex area, we view these decisions as essential to addressing important questions, such as how to best honor patient wishes when they may be unable to communicate them directly or have no next of kin to do so on their behalf,” Gregg said.&lt;/p&gt;
&lt;h2&gt;Is AI a bad fit for patients with no human surrogates?&lt;/h2&gt;
&lt;p&gt;It has always been hard for doctors to determine what patients want when they can’t speak for themselves. A patient may refuse to be put on a ventilator or receive dialysis or cardiopulmonary resuscitation (CPR) if, for example, they’ve expressed that they want to avoid discomfort at the end of their life. Others may fear complications like infections or have no desire to rely on a machine for life support. Some patients, like young people involved in accidents, may have never expressed preferences.&lt;/p&gt;
&lt;p&gt;Emily Moin, a physician in an intensive care unit in Pennsylvania, told Ars that time is a factor in these decisions, but it’s imperative that a human surrogate who may better understand the patient’s wishes be involved.&lt;/p&gt;
&lt;p&gt;“When we’re in one of these fast-paced situations where we don’t know, but we have a patient in front of us who has died, we will err on the side of providing [CPR] until we are able to arrive at the clinical judgment that that effort is no longer indicated or until we’re able to engage with a surrogate decision maker,” Moin explained.&lt;/p&gt;
&lt;p&gt;Reaching the surrogate, she said, is “an important part of taking care of someone.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Ahmad hopes that AI could help alleviate stress in uncertain moments. For doctors and surrogates, these decisions can be “very emotionally taxing,” Ahmad told Ars, leading many people to second-guess what the patient would choose. Some studies have shown that surrogates often get it wrong, he said, and he believes AI could help improve the odds of success.&lt;/p&gt;
&lt;p&gt;Seeking to nip this problem in the bud, health systems have historically pushed patients to complete “advanced directives” to log their preferences. Over time, though, it has become clear that patients’ preferences tend to be unstable, sometimes changing within days.&lt;/p&gt;
&lt;p&gt;Doctors must also consider that some patients have no stated preferences. Others, Moin said, have reported that their preferences changed after receiving lifesaving treatments because they now know what to expect. These are likely other limitations of Ahmad’s planned testing, which would determine accuracy by checking whether the AI’s decision matches what a patient says they would have wanted after recovery, Moin said.&lt;/p&gt;
&lt;p&gt;“These decisions are dynamically constructed and context-dependent,” Moin said. “And if you’re assessing the performance of the model based on asking someone after they’ve recovered what they would have said before they recovered, that’s not going to provide you with an accurate representation.”&lt;/p&gt;
&lt;p&gt;Moin said one of the big problems with medical AI is that people expect it to “provide better predictions than what we’re currently able to generate.” But the models are being trained on “convenient ground truths,” she said, that don’t “provide meaningful examples for models to learn about the situations” where the models would be employed.&lt;/p&gt;
&lt;p&gt;“I imagine that they would actually want to deploy this model to help to make decisions for unrepresented patients, patients who can’t communicate, patients who don’t have a surrogate,” Moin said, “but those are exactly the patients where you’ll never be able to know what the so-called ground truth is, and then you’ll never be able to assess your bias, and you’ll never be able to assess your model’s performance.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Family members may default to agreeing with AI&lt;/h2&gt;
&lt;p&gt;Culturally, the US has shifted from being “very focused on patient autonomy” to “more of a shared decision-making and, at times, family- and community-focused lens” as the standard for making these difficult decisions, Moin said.&lt;/p&gt;
&lt;p&gt;The longer a doctor knows a patient, and the more conversations a patient’s health team has with family members, the more likely it is for health systems to be able to adapt to respect the patient’s wishes over time, Moin suggested.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;That idea echoes Ahmad’s “ideal” AI surrogate model. But Moin said that if patients talk to an AI, it could actually discourage them from having important conversations with family members. Studies have found that if a patient fills out advanced directives, it can become harder to determine their preferences, Moin said, because patients may be less likely to discuss their preferences with loved ones.&lt;/p&gt;
&lt;p&gt;Earlier this year, Moin urged human surrogates to remain closely involved in do-not-resuscitate orders, writing that doctors who unilaterally make these decisions have an ethical obligation to “ensure that patients and surrogate decision-makers are aware that the decision has been made” and face “the lowest of barriers” to expressing disagreement.&lt;/p&gt;
&lt;p&gt;“Forgoing CPR is one of the most consequential treatment decisions a patient or surrogate can make because, if invoked, it will necessarily lead to death,” Moin wrote.&lt;/p&gt;
&lt;p&gt;Moin told Ars she hopes an AI surrogate’s outputs would never be weighted more than a human surrogate’s opinion, which is based on lived experience with a patient. “But I do worry that there could be culture shifts and other pressures that would encourage clinicians and family members, for that matter, to lean on products like these more heavily,” she said.&lt;/p&gt;
&lt;p&gt;“I can imagine a scenario where, say, a doctor is expected to round on 24 critically ill patients in one day, and the family member is resistant to sitting down for a conversation,” Moin said. “So yeah, maybe all parties involved would default to the shortcut of incorporating the information from this model.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Moin called for more public awareness and debate on AI surrogates, noting that “people really hate” the use of algorithms to determine who gets care.&lt;/p&gt;
&lt;p&gt;“I don’t think that it would be good for patients or clinicians or society for that matter,” Moin said.&lt;/p&gt;
&lt;p&gt;She’s particularly worried that “patients who can’t speak for themselves and who don’t have a clear loved one” would be “the ones who would be most vulnerable to suffering harms” of AI surrogates making wrong calls. Too many such mistakes could further erode trust in health systems, Moin said.&lt;/p&gt;
&lt;h2&gt;AI surrogates may be redundant&lt;/h2&gt;
&lt;p&gt;These decisions are “psychosocially fraught” for everyone involved, Teva Brender, a hospitalist at a medical center for veterans in San Francisco, told Ars. That’s why testing like Ahmad’s is important, he said.&lt;/p&gt;
&lt;p&gt;Last year, Brender co-authored an opinion piece&amp;nbsp;noting “how difficult it can be for families to make decisions for incapacitated patients,” particularly in geriatrics, palliative, and critical care settings.&lt;/p&gt;
&lt;p&gt;“For many, the notion of incorporating AI into goals-of-care conversations will conjure nightmarish visions of a dystopian future wherein we entrust deeply human decisions to algorithms,” Brender’s team wrote. “We share these apprehensions.”&lt;/p&gt;
&lt;p&gt;But with doctors’ and surrogates’ predictions facing significant limitations, “it behooves us to consider how AI could be safely, ethically, and equitably deployed to help surrogates for individuals who are seriously ill,” Brender’s team concluded.&lt;/p&gt;
&lt;p&gt;And it’s “equally important,” Brender told Ars, to help patients choose surrogates and prepare them to substitute their judgments.&lt;/p&gt;
&lt;p&gt;Brender believes Ahmad’s research is worthwhile since there are “lots of questions” requiring scientific research. But he’s “glad to hear” that AI surrogates are “not actually being used among patients” at Harborview yet. “I can’t imagine that an IRB would approve such a thing this early,” he told Ars.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;And AI surrogates may end up playing a redundant role, leading this potential use for AI to fall out of favor, Brender said.&lt;/p&gt;
&lt;p&gt;“The devil’s advocate perspective,” Brender said, is that AI surrogates would just be doing “what a good clinician does anyway,” which is to ask surrogates, “Hey, who was this person? What did they enjoy doing? What brought meaning to their life?”&lt;/p&gt;
&lt;p&gt;“Do you need an AI to do that?” Brender asked. “I’m not so sure.”&lt;/p&gt;
&lt;h2&gt;AI can’t replace human surrogates, doctors warn&lt;/h2&gt;
&lt;p&gt;Last month, bioethics expert Robert Truog joined R. Sean Morrison, a doctor dedicated to advancing palliative care aimed at improving the quality of life for people suffering life-threatening illnesses, in emphasizing that AI should never replace human surrogates in resuscitation decisions.&lt;/p&gt;
&lt;p&gt;“Decisions about hypothetical scenarios do not correlate with decisions that need to be made in real time,” Morrison told Ars. “AI cannot fix this fundamental issue—it is not a matter of better prediction. Patients’ preferences often represent a snapshot in time that are simply not predictive of the future.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The warning came after Georg Starke, a doctor and senior research associate at the Chair for Ethics of AI and Neuroscience at the Technical University of Munich, co-authored a proof-of-concept showing that three AI models, on average, performed better than human surrogates in predicting patient preferences.&lt;/p&gt;
&lt;p&gt;Starke’s study relied on existing data from Swiss respondents of a European survey that tracked population health trends of individuals over 50 years old. The dataset offered “comprehensive information on participants’ end-of-life preferences, including questions concerning” CPR. That allowed the team to build three models: a simple model, a model based on commonly available electronic health records, and a more “personalized” model. Each model successfully predicted whether a patient experiencing cardiac arrest would want CPR, with an accuracy of up to 70 percent.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;His team’s research was intended to “ground a long-standing ethical debate in empirical data,” Starke told Ars.&lt;/p&gt;
&lt;p&gt;“For over a decade, people have speculated about using algorithms to improve clinical decision-making for incapacitated patients, but no one had shown whether such a program could actually be designed,” Starke said. “Our study was meant to test if it’s feasible, explore how well it performs, identify which factors influence the models’ decisions, and spark a broader debate about the technology.”&lt;/p&gt;
&lt;p&gt;A key limitation of AI models depending on “‘accuracy’ alone”—especially if that “accuracy” is “achieved by chance or by pattern-matching purely demographic data outside an individual’s control”—is that the outputs don’t “necessarily reflect an autonomous choice,” Starke said.&lt;/p&gt;
&lt;p&gt;Like Truog and Morrison, Starke’s team emphasized that “human surrogates will remain essential sources for the contextual aspects of specific situations,” particularly with patients with dementia, and agreed that AI models “should not replace surrogate decision-making.”&lt;/p&gt;
&lt;h2&gt;Chatbot surrogates could be bad&lt;/h2&gt;
&lt;p&gt;Human surrogates may grow to trust AI systems in the future, but “it’s all about how the information is presented,” Brender, the hospitalist, told Ars.&lt;/p&gt;
&lt;p&gt;He thinks that AI systems could best serve as a “launchpad” for discussions, giving surrogates a way to consider what data may be significant to the patient.&lt;/p&gt;
&lt;p&gt;But he agreed with Moin that without transparency about how AI surrogates arrive at decisions, AI could sow distrust.&lt;/p&gt;
&lt;p&gt;Imagine, for example, if an AI system didn’t know about a new treatment for cancer that could completely change a patient’s prognosis. Patients might be better served, Brender suggested, if hospitals invested in AI to improve prognosis instead of “literally predicting what a patient would want.” Truog and Morrison also suggested that AI research like Ahmad’s could help hospitals determine what kinds of patients tend to have more stable preferences over time.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Brender suggested that a nightmare scenario could arise if an AI surrogate, presented in a chatbot interface, leads doctors and family members to put “too much trust” in an algorithm. That’s why transparency and rigorous testing will be critical if this technology is ever deployed, he said.&lt;/p&gt;
&lt;p&gt;“If a black-box algorithm says that grandmother would not want resuscitation, I don’t know that that’s helpful,” Brender said. “You need it to be explainable.”&lt;/p&gt;
&lt;h2&gt;Research on bias of AI surrogates doesn’t exist&lt;/h2&gt;
&lt;p&gt;Ahmad agreed that a human should always be in the loop. He emphasized that he’s not rushing to deploy his AI models, which remain in the conceptual phase. Complicating his work, there’s currently little research exploring bias and fairness in the use of AI surrogates.&lt;/p&gt;
&lt;p&gt;Ahmad aims to begin to fill in that gap with a pre-print paper set for release this week that maps out various notions of fairness and then examines fairness across moral traditions. Ultimately, Ahmad suggests, fairness in using AI surrogates “extends beyond parity of outcomes to encompass moral representation, fidelity to the patient’s values, relationships, and worldview.”&lt;/p&gt;
&lt;p class="p1"&gt;“The central question becomes not only, ‘Is the model unbiased?’ but ‘&lt;span class="s1"&gt;Whose moral universe does the model inhabit?'” Ahmad wrote, providing an example:&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p class="p1"&gt;Consider the following: Two patients of &lt;span class="s1"&gt;similar clinical profiles may differ in moral reasoning, one guided by autonomy, another by family or religious duty. &lt;/span&gt;Treating them “similarly” in algorithmic terms would constitute moral erasure. Individual fairness requires incorporating value-sensitive features, such as recorded spiritual preferences or statements about comfort, without violating privacy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It could be more than a decade before the technology is deployed to patients, if it ever happens, Ahmad suggested, because of how challenging it is for AI models to be trained to calculate something as complex as a person’s values and beliefs.&lt;/p&gt;
&lt;p&gt;“That’s where things become really complicated,” Ahmad told Ars, noting “there’s societal norms, and then there’s norms within a particular religious group.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Consider an “extreme example,” Ahmad said. Imagine the puzzle doctors might face if they’re trying to decide if a pregnant woman involved in an accident should be taken off a ventilator because outdated records show she once marked that as her preference. A human surrogate, like her partner or a family member, might be able to advocate on her behalf to stay on the ventilator, particularly if the woman holds pro-life views, he said.&lt;/p&gt;
&lt;p&gt;Without a human surrogate, doctors could turn to AI to help them make a decision, but only if the AI system is able to capture the patient’s values and beliefs based on “patterns learned from data, clinical variables, demographic information, linguistic markers in clinical notes, and possibly the patient’s digital footprint,” Ahmad’s paper explains.&lt;/p&gt;
&lt;p&gt;Then there’s the issue of AI models being “somewhat brittle,” Ahmad said, perhaps giving “a very different answer” if a question is worded slightly differently or in a “clever” way the model doesn’t understand.&lt;/p&gt;
&lt;p&gt;Ahmad is not shying away from what he calls “the problem of engineering values.” To better understand how other researchers are approaching the issue and what expectations patients may have for AI surrogates, Ahmad recently attended an evangelical Christian conference on AI in Dallas, Texas. There, it seemed clear that in a future where AI surrogates are integrated into hospitals, some patients may have high expectations about how well large language models (LLMs) can replicate their inner truths.&lt;/p&gt;
&lt;p&gt;“One thing that really stood out was that people—especially when it comes to LLMs—there was a lot of discussions around having versions of LLMs which reflected their values,” Ahmad said.&lt;/p&gt;
&lt;p&gt;Starke told Ars he thinks it would be ideal to build models based on the most accessible electronic health records, at least from a clinical perspective. To best serve patients, though, he agreed with Ahmad and thinks that “an ideal dataset would be large, diverse, longitudinal, and purpose-built.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“It would combine demographic and clinical variables, documented advance-care-planning data, patient-recorded values and goals, and contextual information about specific decisions,” he said.&lt;/p&gt;
&lt;p&gt;“Including textual and conversational data could further increase a model’s ability to learn &lt;em&gt;why&lt;/em&gt; preferences arise and change, not just &lt;em&gt;what&lt;/em&gt; a patient’s preference was at a single point in time,” Starke said.&lt;/p&gt;
&lt;p&gt;Ahmad suggested that future research could focus on validating fairness frameworks in clinical trials, evaluating moral trade-offs through simulations, and exploring how cross-cultural bioethics can be combined with AI designs.&lt;/p&gt;
&lt;p&gt;Only then might AI surrogates be ready to be deployed, but only as “decision aids,” Ahmad wrote. Any “contested outputs” should automatically “trigger [an] ethics review,” Ahmad wrote, concluding that “the fairest AI surrogate is one that invites conversation, admits doubt, and leaves room for care.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;“AI will not absolve us”&lt;/h2&gt;
&lt;p&gt;Ahmad is hoping to test his conceptual models at various UW sites over the next five years, which would offer “some way to quantify how good this technology is,” he said.&lt;/p&gt;
&lt;p&gt;“After that, I think there’s a collective decision regarding how as a society we decide to integrate or not integrate something like this,” Ahmad said.&lt;/p&gt;
&lt;p&gt;In his paper, he warned against chatbot AI surrogates that could be interpreted as a simulation of the patient, predicting that future models may even speak in patients’ voices and suggesting that the “comfort and familiarity” of such tools might blur “the boundary between assistance and emotional manipulation.”&lt;/p&gt;
&lt;p&gt;Starke agreed that more research and “richer conversations” between patients and doctors are needed.&lt;/p&gt;
&lt;p&gt;“We should be cautious not to apply AI indiscriminately as a solution in search of a problem,” Starke said. “AI will not absolve us from making difficult ethical decisions, especially decisions concerning life and death.”&lt;/p&gt;
&lt;p&gt;Truog, the bioethics expert, told Ars he “could imagine that AI could” one day “provide a surrogate decision maker with some interesting information, and it would be helpful.”&lt;/p&gt;
&lt;p&gt;But a “problem with all of these pathways… is that they frame the decision of whether to perform CPR as a binary choice, regardless of context or the circumstances of the cardiac arrest,” Truog’s editorial said. “In the real world, the answer to the question of whether the patient would want to have CPR” when they’ve lost consciousness, “in almost all cases,” is “it depends.”&lt;/p&gt;
&lt;p&gt;When Truog thinks about the kinds of situations he could end up in, he knows he wouldn’t just be considering his own values, health, and quality of life. His choice “might depend on what my children thought” or “what the financial consequences would be on the details of what my prognosis would be,” he told Ars.&lt;/p&gt;
&lt;p&gt;“I would want my wife or another person that knew me well to be making those decisions,” Truog said. “I wouldn’t want somebody to say, ‘Well, here’s what AI told us about it.'”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/features/2025/10/should-an-ai-copy-of-you-help-decide-if-you-live-or-die/</guid><pubDate>Mon, 20 Oct 2025 11:00:09 +0000</pubDate></item><item><title>[NEW] This retina implant lets people with vision loss do a crossword puzzle (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/20/1126065/this-retina-implant-lets-people-with-vision-loss-do-a-crossword-puzzle/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Science Corporation—a competitor to Neuralink founded by the former president of Elon Musk's brain-interface venture—has leapfrogged its rival after acquiring a vision implant that's in advanced testing, for a fire-sale price.&lt;/p&gt;  &lt;p&gt;The implant produces a form of “artificial vision” that lets some patients read text and do crosswords, according to a report published in &lt;em&gt;The&lt;/em&gt; &lt;em&gt;New England Journal of Medicine&lt;/em&gt; today.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The implant is a microelectronic chip placed under the retina. Using signals from a camera mounted on a pair of glasses, the chip emits bursts of electricity in order to bypass photoreceptor cells damaged by macular degeneration, the leading cause of vision loss in the elderly.&lt;/p&gt;  &lt;p&gt;“The magnitude of the effect is what’s notable,” says José-Alain Sahel, a University of Pittsburgh vision scientist who led testing of the system, which is called PRIMA. “There’s a patient in the UK and she is reading the pages of a regular book, which is unprecedented.”&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Until last year, the device was being developed by Pixium Vision, a French startup co-founded by Sahel, which faced bankruptcy after it couldn’t raise more cash.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That’s when Science Corporation swept in to purchase the company’s assets for about 4 million euros ($4.7 million), according to court filings.&lt;/p&gt; 
 &lt;p&gt;“Science was able to buy it for very cheap just when the study was coming out, so it was good timing for them,” says Sahel. “They could quickly access very advanced technology that’s closer to the market, which is good for a company to have.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Science was founded in 2021 by Max Hodak, the first president of Neuralink, after his sudden departure from that company. Since its founding, Science has raised around $290 million, according to the venture capital database Pitchbook, and used the money to launch broad-ranging exploratory research on brain interfaces and new types of vision treatments.&lt;/p&gt;  &lt;p&gt;“The ambition here is to build a big, standalone medical technology company that would fit in with an Apple, Samsung or an Alphabet,” Hodak said in an interview at Science’s labs in Alameda, California in September. “The goal is to change the world in important ways…but we need to make money in order to invest in these programs.”&lt;/p&gt;  &lt;p&gt;By acquiring the PRIMA implant program, Science effectively vaulted past years of development and testing. The company has requested approval to sell the eye chip in Europe and is in discussions with regulators in the US.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Unlike Neuralink’s implant, which records brain signals so paralyzed recipients can use their thoughts to move a computer mouse, the retina chip sends information into the brain to produce vision. Because the retina is an outgrowth of the brain, the chip qualifies as a type of brain-computer interface.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Artificial vision systems have been studied for years and one, called the Argus II, even reached the market and was installed in the eyes of about 400 people. But that product was later withdrawn after it proved to be a money-loser, according to Cortigent, the company which now owns that technology.&lt;/p&gt;  &lt;p&gt;38 patients in Europe received a PRIMA implant in one eye. On average, the study found, they were able to read five additional lines on a vision chart—the kind with rows of letters, each smaller than the last. Some of that improvement came due to what Sahel calls “various tricks” like using a zoom function, which allows patients to zero in on text they want to read.&lt;/p&gt;  &lt;p&gt;The type of vision loss being treated with the new implant is called geographic atrophy, in which patients have peripheral vision, but can’t make out objects directly in front of them, like words or faces. According to Prevent Blindness, an advocacy organization, this type of central vision loss affects around one in 10 people over 80. &amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;The implant was originally designed starting 20 years ago by Daniel Palanker, a laser expert who is now a professor at Stanford University, who says his breakthrough was realizing that light beams could supply both energy and information to a chip placed under the retina.&amp;nbsp;Other implants, like Argus II, use a wire, which adds complexity.&lt;/p&gt;  &lt;p&gt;“The chip has no brains at all. It just turns light into electrical current that flows into the tissue,” says Palanker. “Patients describe the color they see as yellowish blue or sun color.”&lt;/p&gt;  &lt;p&gt;The system works using a wearable camera that records a scene, then blasts bright infrared light into the eye, using a wavelength humans can’t see. That light hits the chip, which is covered by “what are basically tiny solar panels,” says Palanker. “We just try to replace the photoreceptors with a photo-array.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1126085" height="1688" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Cooking-and-reading-recipe-with-PRIMA-5.png?w=3000" width="3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;A diagram of how a visual scene could be represented by a retinal implant.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY SCIENCE CORPORATION&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The current system produces about 400 spots of vision, which lets users make out the outlines of words and objects. Palanaker says a next-generation device will have five times as many “pixels” and should let people see more. “What we discovered in the trial is that even though you stimulate individual pixels, patients perceive it as continuous. The patient says ‘I see a line’, “I see a letter.’”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;Palanker says it will be important to keep improving the system because “the market size depends on the quality of the vision produced.”&lt;/p&gt;  &lt;p&gt;When Pixium teetered on insolvency, Palanker says he helped search for a buyer, meeting with Hodak. “It was a fire sale, not a celebration. But for me it’s a very lucky outcome, because it means the product is going forward. And the purchase price doesn’t really matter, because there’s a big investment needed to bring it to market. It’s going to cost money,” he says.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Photo of the PRIMA Glasses and Pocket Processor." class="wp-image-1126012" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/251017_prima_embed1.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;The PRIMA artificial vision system has a battery pack/controller and an eye-mounted camera.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY SCIENCE CORPORATION&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;During a visit to Science’s headquarters, Hodak described the company’s effort to re-design the system into something sleeker and more user-friendly. In the original design, in addition to the wearable camera, the patient has to carry around a bulky controller containing a battery and laser, as well as buttons to zoom in and out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But Science has already prototyped a version in which those electronics are squeezed into what look like an extra-large pair of sunglasses.&lt;/p&gt;  &lt;p&gt;“The implant is great, but we'll have new glasses on patients fairly shortly,” Hodak says. “This will substantially improve their ability to have it with them all day.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Other companies also want to treat blindness with brain-computer interfaces, but some think it might be better to send signals directly into the brain. This year, Neuralink has been touting plans for “Blindsight,” a project to send electrical signals directly into the brain’s visual cortex, bypassing the retina entirely. It has yet to test the approach in a person.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Science Corporation—a competitor to Neuralink founded by the former president of Elon Musk's brain-interface venture—has leapfrogged its rival after acquiring a vision implant that's in advanced testing, for a fire-sale price.&lt;/p&gt;  &lt;p&gt;The implant produces a form of “artificial vision” that lets some patients read text and do crosswords, according to a report published in &lt;em&gt;The&lt;/em&gt; &lt;em&gt;New England Journal of Medicine&lt;/em&gt; today.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The implant is a microelectronic chip placed under the retina. Using signals from a camera mounted on a pair of glasses, the chip emits bursts of electricity in order to bypass photoreceptor cells damaged by macular degeneration, the leading cause of vision loss in the elderly.&lt;/p&gt;  &lt;p&gt;“The magnitude of the effect is what’s notable,” says José-Alain Sahel, a University of Pittsburgh vision scientist who led testing of the system, which is called PRIMA. “There’s a patient in the UK and she is reading the pages of a regular book, which is unprecedented.”&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Until last year, the device was being developed by Pixium Vision, a French startup co-founded by Sahel, which faced bankruptcy after it couldn’t raise more cash.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That’s when Science Corporation swept in to purchase the company’s assets for about 4 million euros ($4.7 million), according to court filings.&lt;/p&gt; 
 &lt;p&gt;“Science was able to buy it for very cheap just when the study was coming out, so it was good timing for them,” says Sahel. “They could quickly access very advanced technology that’s closer to the market, which is good for a company to have.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Science was founded in 2021 by Max Hodak, the first president of Neuralink, after his sudden departure from that company. Since its founding, Science has raised around $290 million, according to the venture capital database Pitchbook, and used the money to launch broad-ranging exploratory research on brain interfaces and new types of vision treatments.&lt;/p&gt;  &lt;p&gt;“The ambition here is to build a big, standalone medical technology company that would fit in with an Apple, Samsung or an Alphabet,” Hodak said in an interview at Science’s labs in Alameda, California in September. “The goal is to change the world in important ways…but we need to make money in order to invest in these programs.”&lt;/p&gt;  &lt;p&gt;By acquiring the PRIMA implant program, Science effectively vaulted past years of development and testing. The company has requested approval to sell the eye chip in Europe and is in discussions with regulators in the US.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Unlike Neuralink’s implant, which records brain signals so paralyzed recipients can use their thoughts to move a computer mouse, the retina chip sends information into the brain to produce vision. Because the retina is an outgrowth of the brain, the chip qualifies as a type of brain-computer interface.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Artificial vision systems have been studied for years and one, called the Argus II, even reached the market and was installed in the eyes of about 400 people. But that product was later withdrawn after it proved to be a money-loser, according to Cortigent, the company which now owns that technology.&lt;/p&gt;  &lt;p&gt;38 patients in Europe received a PRIMA implant in one eye. On average, the study found, they were able to read five additional lines on a vision chart—the kind with rows of letters, each smaller than the last. Some of that improvement came due to what Sahel calls “various tricks” like using a zoom function, which allows patients to zero in on text they want to read.&lt;/p&gt;  &lt;p&gt;The type of vision loss being treated with the new implant is called geographic atrophy, in which patients have peripheral vision, but can’t make out objects directly in front of them, like words or faces. According to Prevent Blindness, an advocacy organization, this type of central vision loss affects around one in 10 people over 80. &amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;The implant was originally designed starting 20 years ago by Daniel Palanker, a laser expert who is now a professor at Stanford University, who says his breakthrough was realizing that light beams could supply both energy and information to a chip placed under the retina.&amp;nbsp;Other implants, like Argus II, use a wire, which adds complexity.&lt;/p&gt;  &lt;p&gt;“The chip has no brains at all. It just turns light into electrical current that flows into the tissue,” says Palanker. “Patients describe the color they see as yellowish blue or sun color.”&lt;/p&gt;  &lt;p&gt;The system works using a wearable camera that records a scene, then blasts bright infrared light into the eye, using a wavelength humans can’t see. That light hits the chip, which is covered by “what are basically tiny solar panels,” says Palanker. “We just try to replace the photoreceptors with a photo-array.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1126085" height="1688" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Cooking-and-reading-recipe-with-PRIMA-5.png?w=3000" width="3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;A diagram of how a visual scene could be represented by a retinal implant.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY SCIENCE CORPORATION&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The current system produces about 400 spots of vision, which lets users make out the outlines of words and objects. Palanaker says a next-generation device will have five times as many “pixels” and should let people see more. “What we discovered in the trial is that even though you stimulate individual pixels, patients perceive it as continuous. The patient says ‘I see a line’, “I see a letter.’”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;Palanker says it will be important to keep improving the system because “the market size depends on the quality of the vision produced.”&lt;/p&gt;  &lt;p&gt;When Pixium teetered on insolvency, Palanker says he helped search for a buyer, meeting with Hodak. “It was a fire sale, not a celebration. But for me it’s a very lucky outcome, because it means the product is going forward. And the purchase price doesn’t really matter, because there’s a big investment needed to bring it to market. It’s going to cost money,” he says.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Photo of the PRIMA Glasses and Pocket Processor." class="wp-image-1126012" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/251017_prima_embed1.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;The PRIMA artificial vision system has a battery pack/controller and an eye-mounted camera.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY SCIENCE CORPORATION&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;During a visit to Science’s headquarters, Hodak described the company’s effort to re-design the system into something sleeker and more user-friendly. In the original design, in addition to the wearable camera, the patient has to carry around a bulky controller containing a battery and laser, as well as buttons to zoom in and out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But Science has already prototyped a version in which those electronics are squeezed into what look like an extra-large pair of sunglasses.&lt;/p&gt;  &lt;p&gt;“The implant is great, but we'll have new glasses on patients fairly shortly,” Hodak says. “This will substantially improve their ability to have it with them all day.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Other companies also want to treat blindness with brain-computer interfaces, but some think it might be better to send signals directly into the brain. This year, Neuralink has been touting plans for “Blindsight,” a project to send electrical signals directly into the brain’s visual cortex, bypassing the retina entirely. It has yet to test the approach in a person.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/20/1126065/this-retina-implant-lets-people-with-vision-loss-do-a-crossword-puzzle/</guid><pubDate>Mon, 20 Oct 2025 12:00:00 +0000</pubDate></item><item><title>[NEW] The Download: a promising retina implant, and how climate change affects flowers (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/20/1126099/the-download-a-promising-retina-implant-and-how-climate-change-affects-flowers/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This retina implant lets people with vision loss do a crossword puzzle&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;Science Corporation—a competitor to Neuralink founded by the former president of Elon Musk's brain-interface venture—has leapfrogged its rival after acquiring a vision implant in advanced testing for a fire-sale price. The implant produces a form of “artificial vision” that lets some patients read text and do crosswords, according to a report published in &lt;em&gt;The&lt;/em&gt; &lt;em&gt;New England Journal of Medicine &lt;/em&gt;today.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How it works: &lt;/strong&gt;The implant is a microelectronic chip placed under the retina. Using signals from a camera mounted on a pair of glasses, the chip emits bursts of electricity in order to bypass photoreceptor cells damaged by macular degeneration, the leading cause of vision loss in the elderly. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Antonio Regalado&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How will flowers respond to climate change?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Flowers play a key role in most landscapes, from urban to rural areas. Yet flowers have much more to tell in their bright blooms: The very shape they take is formed by local and global climate conditions.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The form of a flower is a visual display of its climate, if you know what to look for. In a dry year, its petals’ pigmentation may change. In a warm year, the flower might grow bigger. The flower’s ultraviolet-absorbing pigment increases with higher ozone levels.&lt;/p&gt;  &lt;p&gt;Now, a new artistic project sets out to answer the question: As the climate changes in the future, how might flowers change? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Annelie Berner&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;This story is from our forthcoming print issue, which is all about the body. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;2025 climate tech companies to watch: Redwood Materials and its new AI microgrids&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Over the past few years, Redwood Materials has become one of the top US battery recyclers, joining forces with the likes of Volkswagen, BMW, and Toyota to process old electric-vehicle batteries and recover materials that can be used to make new ones.&lt;/p&gt;&lt;p&gt;Now it's moving into reuse as well. Redwood Energy, a new branch of the company, incorporates used EV batteries into microgrids to power energy-hungry AI data centers. Read the full story.&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;—Peter Hall&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Redwood Materials is one of our 10 climate tech companies to watch—our annual list of some of the most promising climate tech firms on the planet. &lt;/strong&gt;&lt;strong&gt;Check out the rest of the list here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 AWS is recovering from a major outage&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s racing to get hundreds of apps and services back online. (The Verge)&lt;br /&gt;+ &lt;em&gt;Snapchat, Roblox and banking services are among those affected. &lt;/em&gt;(The Guardian)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 OpenAI made—then retracted—a claim it had made a major math breakthrough&lt;/strong&gt;&lt;br /&gt;After math experts and rival AI firms ridiculed its poorly-worded declaration. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;What’s next for AI and math. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 The grave costs of Trump’s war on climate science&lt;/strong&gt;&lt;br /&gt;It’s affecting the accuracy of forecasting systems globally, not just in the US. (FT $)&lt;br /&gt;+ &lt;em&gt;Trump himself led an effort to derail plans to tax shipping pollution. &lt;/em&gt;(Politico $)&lt;br /&gt;+ &lt;em&gt;How to make clean energy progress under Trump in the states. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 China claims the US is behind a cyberattack on its national time center&lt;br /&gt;&lt;/strong&gt;It says it has years’ worth of irrefutable evidence of data stealing. (Reuters)&lt;br /&gt;+ &lt;em&gt;US experts allegedly exploited vulnerabilities in mobile phones belonging to National Time Service Center workers. &lt;/em&gt;(Bloomberg $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 Is AI-generated art real art?&lt;br /&gt;It’s a question gallery and museum curators across the world are debating. (NYT $)&lt;br /&gt;+ &lt;em&gt;Artisan craftmakers are happy to resist the pull of AI. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;This tool claims to trace how much of an AI image has been drawn from existing material.&lt;/em&gt; (The Guardian)&lt;br /&gt;+ &lt;em&gt;From slop to Sotheby’s? AI art enters a new phase. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;6 Chipmaker Nexperia has accused its ousted CEO of spreading falsehoods&lt;/strong&gt;&lt;br /&gt;Zhang Xuezheng reportedly claimed it was operating independently in China. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 This whistleblower raised concerns about the safety of US data under DOGE&lt;/strong&gt;&lt;br /&gt;And says the hostile reception to his complaint led to him leaving his dream job. (WP $)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 Aid agencies have been criticized for using AI “poverty porn”&lt;br /&gt;&lt;/strong&gt;But the NGOs say its use protects the identities of real people in social media campaigns. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9&lt;/strong&gt; &lt;strong&gt;EVs lose their value much faster than gas-powered cars&lt;br /&gt;&lt;/strong&gt;Which isn’t exactly an incentive for prospective first-time buyers. (Rest of World)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;10 What happens to our brains when we dream 🧠&lt;/strong&gt;&lt;br /&gt;We’re learning more about the many liminal states they can slip through. (Quanta Magazine)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“Hoisted by their own GPTards.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Meta’s chief AI scientist Yann LeCun pokes fun at OpenAI after the company walked back its claim it had made a major math breakthrough in a post on X.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2025/02/250214_evbatteryfire.gif?fit=1456,818" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;One option for electric vehicle fires? Let them burn.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Although there isn’t solid data on the frequency of EV battery fires, it’s no secret that these fires are happening.&lt;/p&gt;&lt;p&gt;Despite that, manufacturers offer no standardized steps on how to fight them or avoid them in the first place. What’s more, with EVs, it’s never entirely clear whether the fire is truly out.&lt;/p&gt;&lt;p&gt;Patrick Durham, the owner of one of a growing number of private companies helping first responders learn how to deal with lithium-ion battery safety, has a solution. He believes that the best way to manage EV fires right now is to let them burn. But such an approach not only goes against firefighters’ instincts—it’d require a significant cultural shift. Read the full story.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This retina implant lets people with vision loss do a crossword puzzle&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;Science Corporation—a competitor to Neuralink founded by the former president of Elon Musk's brain-interface venture—has leapfrogged its rival after acquiring a vision implant in advanced testing for a fire-sale price. The implant produces a form of “artificial vision” that lets some patients read text and do crosswords, according to a report published in &lt;em&gt;The&lt;/em&gt; &lt;em&gt;New England Journal of Medicine &lt;/em&gt;today.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How it works: &lt;/strong&gt;The implant is a microelectronic chip placed under the retina. Using signals from a camera mounted on a pair of glasses, the chip emits bursts of electricity in order to bypass photoreceptor cells damaged by macular degeneration, the leading cause of vision loss in the elderly. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Antonio Regalado&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How will flowers respond to climate change?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Flowers play a key role in most landscapes, from urban to rural areas. Yet flowers have much more to tell in their bright blooms: The very shape they take is formed by local and global climate conditions.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The form of a flower is a visual display of its climate, if you know what to look for. In a dry year, its petals’ pigmentation may change. In a warm year, the flower might grow bigger. The flower’s ultraviolet-absorbing pigment increases with higher ozone levels.&lt;/p&gt;  &lt;p&gt;Now, a new artistic project sets out to answer the question: As the climate changes in the future, how might flowers change? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Annelie Berner&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;This story is from our forthcoming print issue, which is all about the body. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;2025 climate tech companies to watch: Redwood Materials and its new AI microgrids&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Over the past few years, Redwood Materials has become one of the top US battery recyclers, joining forces with the likes of Volkswagen, BMW, and Toyota to process old electric-vehicle batteries and recover materials that can be used to make new ones.&lt;/p&gt;&lt;p&gt;Now it's moving into reuse as well. Redwood Energy, a new branch of the company, incorporates used EV batteries into microgrids to power energy-hungry AI data centers. Read the full story.&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;—Peter Hall&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Redwood Materials is one of our 10 climate tech companies to watch—our annual list of some of the most promising climate tech firms on the planet. &lt;/strong&gt;&lt;strong&gt;Check out the rest of the list here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 AWS is recovering from a major outage&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s racing to get hundreds of apps and services back online. (The Verge)&lt;br /&gt;+ &lt;em&gt;Snapchat, Roblox and banking services are among those affected. &lt;/em&gt;(The Guardian)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 OpenAI made—then retracted—a claim it had made a major math breakthrough&lt;/strong&gt;&lt;br /&gt;After math experts and rival AI firms ridiculed its poorly-worded declaration. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;What’s next for AI and math. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 The grave costs of Trump’s war on climate science&lt;/strong&gt;&lt;br /&gt;It’s affecting the accuracy of forecasting systems globally, not just in the US. (FT $)&lt;br /&gt;+ &lt;em&gt;Trump himself led an effort to derail plans to tax shipping pollution. &lt;/em&gt;(Politico $)&lt;br /&gt;+ &lt;em&gt;How to make clean energy progress under Trump in the states. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 China claims the US is behind a cyberattack on its national time center&lt;br /&gt;&lt;/strong&gt;It says it has years’ worth of irrefutable evidence of data stealing. (Reuters)&lt;br /&gt;+ &lt;em&gt;US experts allegedly exploited vulnerabilities in mobile phones belonging to National Time Service Center workers. &lt;/em&gt;(Bloomberg $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 Is AI-generated art real art?&lt;br /&gt;It’s a question gallery and museum curators across the world are debating. (NYT $)&lt;br /&gt;+ &lt;em&gt;Artisan craftmakers are happy to resist the pull of AI. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;This tool claims to trace how much of an AI image has been drawn from existing material.&lt;/em&gt; (The Guardian)&lt;br /&gt;+ &lt;em&gt;From slop to Sotheby’s? AI art enters a new phase. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;6 Chipmaker Nexperia has accused its ousted CEO of spreading falsehoods&lt;/strong&gt;&lt;br /&gt;Zhang Xuezheng reportedly claimed it was operating independently in China. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 This whistleblower raised concerns about the safety of US data under DOGE&lt;/strong&gt;&lt;br /&gt;And says the hostile reception to his complaint led to him leaving his dream job. (WP $)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 Aid agencies have been criticized for using AI “poverty porn”&lt;br /&gt;&lt;/strong&gt;But the NGOs say its use protects the identities of real people in social media campaigns. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9&lt;/strong&gt; &lt;strong&gt;EVs lose their value much faster than gas-powered cars&lt;br /&gt;&lt;/strong&gt;Which isn’t exactly an incentive for prospective first-time buyers. (Rest of World)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;10 What happens to our brains when we dream 🧠&lt;/strong&gt;&lt;br /&gt;We’re learning more about the many liminal states they can slip through. (Quanta Magazine)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“Hoisted by their own GPTards.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Meta’s chief AI scientist Yann LeCun pokes fun at OpenAI after the company walked back its claim it had made a major math breakthrough in a post on X.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2025/02/250214_evbatteryfire.gif?fit=1456,818" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;One option for electric vehicle fires? Let them burn.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Although there isn’t solid data on the frequency of EV battery fires, it’s no secret that these fires are happening.&lt;/p&gt;&lt;p&gt;Despite that, manufacturers offer no standardized steps on how to fight them or avoid them in the first place. What’s more, with EVs, it’s never entirely clear whether the fire is truly out.&lt;/p&gt;&lt;p&gt;Patrick Durham, the owner of one of a growing number of private companies helping first responders learn how to deal with lithium-ion battery safety, has a solution. He believes that the best way to manage EV fires right now is to let them burn. But such an approach not only goes against firefighters’ instincts—it’d require a significant cultural shift. Read the full story.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/20/1126099/the-download-a-promising-retina-implant-and-how-climate-change-affects-flowers/</guid><pubDate>Mon, 20 Oct 2025 12:10:00 +0000</pubDate></item></channel></rss>