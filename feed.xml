<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 17 Jul 2025 01:56:19 +0000</lastBuildDate><item><title>These four charts show where AI companies could go next in the US (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/16/1120233/these-four-charts-show-where-ai-companies-could-go-next-in-the-us/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/city-ai.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;No one knows exactly how AI will transform our communities, workplaces, and society as a whole. Because it’s hard to predict the impact AI will have on jobs, many workers and local governments are left trying to read the tea leaves to understand how to prepare and adapt.&lt;/p&gt;  &lt;p&gt;A new interactive report released today by the Brookings Institution attempts to map how embedded AI companies and jobs are in different regions of the United States in order to prescribe policy treatments to those struggling to keep up.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;While the impact of AI on tech hubs like San Francisco and Boston is already being felt, AI proponents believe it will transform work everywhere, and in every industry. The report uses various proxies for what the researchers call “AI readiness” to document how unevenly this supposed transformation is taking place.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Here are four charts to help understand where that could matter.&amp;nbsp;&lt;/p&gt; 
   &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;1. AI development is still highly focused in tech hubs.&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Brookings divides US cities into five categories based on how ready they are to adopt AI-related industries and job offerings. To do so, it looked at local talent pool development, innovations in local institutions, and adoption potential among local companies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The “AI Superstars” above represent, unsurprisingly, parts of the San Francisco Bay Area, such outliers that they are given their own category. The “Star AI Hubs,” on the other hand, include large metropolitan areas known for tech work, including Boston, Seattle, and Miami.&lt;/p&gt; 
   &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;2. &lt;strong&gt;Concentration of workers and startups is highly centralized, too.&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The data shows that the vast majority of people working with AI and startups focused on AI are clustered in the tech hubs above. The report found that almost two-thirds of workers advertising their AI skills work there, and well over 75% of AI startups were founded there. The so-called “Star AI Hubs,” from the likes of New York City and Seattle down to Columbus, Ohio, and Boulder, Colorado, take up another significant portion of the pie.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s clear that most of the developments in AI are concentrated in certain large cities, and this pattern can end up perpetuating itself. According to the report, though, “AI activity has spread into most regional economies across the country,” highlighting the need for policy that encourages growth through AI without sacrificing other areas of the country.&lt;/p&gt;    &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;3. &lt;strong&gt;&lt;strong&gt;Emerging centers of AI show promise but are lacking in one way or another.&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Beyond the big, obvious tech-hub cities, Brookings claims, there are 14 regions that show promise in AI development and worker engagement with AI. Among these are cities surrounding academic institutions like the University of Wisconsin in Madison or Texas A&amp;amp;M University in College Station, and regional cultural centers like Pittsburgh, Detroit, and Nashville.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, according to Brookings, these places are lacking in some respect or another that limits their development. Take Columbia, South Carolina, for example. Despite a sizable regional population of about 860,000 people and the University of South Carolina right there, the report says the area has struggled with talent development; relatively few students graduate with science and engineering degrees, and few showcase AI skills in their job profiles.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;On the other hand, the Tampa, Florida, metropolitan area struggles with innovation, owing in large part to lagging productivity of local universities. The majority of the regions Brookings examined struggle with adoption, which in the report is measured largely by company engagement with AI-related tools like enterprise data and cloud services.&lt;/p&gt;    &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;4. &lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Emerging centers are generally leaning toward industry or government contracts, not both.&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Still, these emerging centers show plenty of promise, and funders are taking note. To measure innovation and adoption of AI, the report tallies federal contracts for AI research and development as well as venture capital funding deals.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;If you examine how these emerging centers are collecting each, it appears that many of them are specializing as centers for federal research, like Huntsville, Alabama, or places for VC firms to scout, like the Sacramento area in California.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;While VC interest can beget VC interest, and likewise for government, this may give some indication of where these places have room to grow. “University presence is a tremendous influence on success here,” says Mark Muro, one of the authors of the report. Fostering the relationship between academia and industry could be key to improving the local AI ecosystem.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/city-ai.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;No one knows exactly how AI will transform our communities, workplaces, and society as a whole. Because it’s hard to predict the impact AI will have on jobs, many workers and local governments are left trying to read the tea leaves to understand how to prepare and adapt.&lt;/p&gt;  &lt;p&gt;A new interactive report released today by the Brookings Institution attempts to map how embedded AI companies and jobs are in different regions of the United States in order to prescribe policy treatments to those struggling to keep up.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;While the impact of AI on tech hubs like San Francisco and Boston is already being felt, AI proponents believe it will transform work everywhere, and in every industry. The report uses various proxies for what the researchers call “AI readiness” to document how unevenly this supposed transformation is taking place.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Here are four charts to help understand where that could matter.&amp;nbsp;&lt;/p&gt; 
   &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;1. AI development is still highly focused in tech hubs.&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Brookings divides US cities into five categories based on how ready they are to adopt AI-related industries and job offerings. To do so, it looked at local talent pool development, innovations in local institutions, and adoption potential among local companies.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The “AI Superstars” above represent, unsurprisingly, parts of the San Francisco Bay Area, such outliers that they are given their own category. The “Star AI Hubs,” on the other hand, include large metropolitan areas known for tech work, including Boston, Seattle, and Miami.&lt;/p&gt; 
   &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;2. &lt;strong&gt;Concentration of workers and startups is highly centralized, too.&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The data shows that the vast majority of people working with AI and startups focused on AI are clustered in the tech hubs above. The report found that almost two-thirds of workers advertising their AI skills work there, and well over 75% of AI startups were founded there. The so-called “Star AI Hubs,” from the likes of New York City and Seattle down to Columbus, Ohio, and Boulder, Colorado, take up another significant portion of the pie.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s clear that most of the developments in AI are concentrated in certain large cities, and this pattern can end up perpetuating itself. According to the report, though, “AI activity has spread into most regional economies across the country,” highlighting the need for policy that encourages growth through AI without sacrificing other areas of the country.&lt;/p&gt;    &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;3. &lt;strong&gt;&lt;strong&gt;Emerging centers of AI show promise but are lacking in one way or another.&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Beyond the big, obvious tech-hub cities, Brookings claims, there are 14 regions that show promise in AI development and worker engagement with AI. Among these are cities surrounding academic institutions like the University of Wisconsin in Madison or Texas A&amp;amp;M University in College Station, and regional cultural centers like Pittsburgh, Detroit, and Nashville.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, according to Brookings, these places are lacking in some respect or another that limits their development. Take Columbia, South Carolina, for example. Despite a sizable regional population of about 860,000 people and the University of South Carolina right there, the report says the area has struggled with talent development; relatively few students graduate with science and engineering degrees, and few showcase AI skills in their job profiles.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;On the other hand, the Tampa, Florida, metropolitan area struggles with innovation, owing in large part to lagging productivity of local universities. The majority of the regions Brookings examined struggle with adoption, which in the report is measured largely by company engagement with AI-related tools like enterprise data and cloud services.&lt;/p&gt;    &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;4. &lt;strong&gt;&lt;strong&gt;&lt;strong&gt;Emerging centers are generally leaning toward industry or government contracts, not both.&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Still, these emerging centers show plenty of promise, and funders are taking note. To measure innovation and adoption of AI, the report tallies federal contracts for AI research and development as well as venture capital funding deals.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;If you examine how these emerging centers are collecting each, it appears that many of them are specializing as centers for federal research, like Huntsville, Alabama, or places for VC firms to scout, like the Sacramento area in California.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;While VC interest can beget VC interest, and likewise for government, this may give some indication of where these places have room to grow. “University presence is a tremendous influence on success here,” says Mark Muro, one of the authors of the report. Fostering the relationship between academia and industry could be key to improving the local AI ecosystem.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/16/1120233/these-four-charts-show-where-ai-companies-could-go-next-in-the-us/</guid><pubDate>Wed, 16 Jul 2025 14:00:44 +0000</pubDate></item><item><title>Hugging Face bets on cute robots to bring open source AI to life (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/hugging-face-bets-on-cute-robots-to-bring-open-source-ai-to-life/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/reachy-mini.jpg?w=770" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Just five days after opening up orders on its Reachy Mini robots, AI developer platform Hugging Face says it has logged $1 million worth of sales. That’s not a bad start for a company that’s just recently expanded into robotics, and is largely known for letting developers download open source AI models off the internet.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On this episode of Equity, Hugging Face co-founder and chief scientist Thomas Wolf breaks down where he sees the company’s robotics going. While other startups tackling robots for the home — such as Figure and 1X — want their robots to offload some of your chores, Hugging Face sees the Reachy Mini as more of a hackable, entertainment device.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;The device is small enough to fit on your desk, and has two misshapen eyes with cameras behind them, as well as microphones, speakers, a head that bobs around, and a pair of antennas for robot ears. It’s designed to come with some preset apps, but also lets people build their own apps that can run locally through open source software.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Eventually, Hugging Face would like to build out a network of apps for Reachy Mini. Wolf even described the Reachy Mini as “a bit like an empty iPhone,” hinting at how massive he thinks this market is.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;The Reachy Mini has gone somewhat viral since launch, largely thanks to its friendly and open design, but also its relatively accessible price point that lets consumers try out an AI-powered robot this year. Wolf says that’s a key part to this launch — making something people want to see on their desk everyday, and can actually afford. Wolf describes the Reachy Mini as an entry point for getting consumers to be comfortable with robots in their home, and earning their trust. We got into more of that on the show.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;I was initially skeptical of the Reachy Mini, but I’ve started to come around to it. I think Wolf and Hugging Face’s vision for the AI device seems fun, and seems like a great way for kids or people new to open source software to learn about the space. Wolf also says he’s interested to see if people will vibe code apps for their robots, an idea I’m fascinated by and slightly scared of.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;At other points on the show, Wolf takes listeners inside Hugging Face’s acquisition of the French robotics startup Pollen, and his insistence on developing a robot at a low price point. Wolf also believes that open source AI will play a similar role in robotics as it has in software, and he’s trying to position Hugging Face to capture that interest.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Later in the episode, we also get into:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How Hugging Face plans to leap from software to hardware.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Hugging Face’s ambitions to one day sell a full-sized humanoid robot.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;The role of privacy in consumer robotics, and how open source can address it.&lt;/li&gt;
&lt;/ul&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt;&amp;nbsp;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt;&amp;nbsp;Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt;&amp;nbsp;Spotify&lt;/em&gt;&lt;em&gt;&amp;nbsp;and all the casts. You also can follow Equity on&lt;/em&gt; &lt;em&gt;X and &lt;/em&gt;&lt;em&gt;Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/reachy-mini.jpg?w=770" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Just five days after opening up orders on its Reachy Mini robots, AI developer platform Hugging Face says it has logged $1 million worth of sales. That’s not a bad start for a company that’s just recently expanded into robotics, and is largely known for letting developers download open source AI models off the internet.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On this episode of Equity, Hugging Face co-founder and chief scientist Thomas Wolf breaks down where he sees the company’s robotics going. While other startups tackling robots for the home — such as Figure and 1X — want their robots to offload some of your chores, Hugging Face sees the Reachy Mini as more of a hackable, entertainment device.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;The device is small enough to fit on your desk, and has two misshapen eyes with cameras behind them, as well as microphones, speakers, a head that bobs around, and a pair of antennas for robot ears. It’s designed to come with some preset apps, but also lets people build their own apps that can run locally through open source software.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Eventually, Hugging Face would like to build out a network of apps for Reachy Mini. Wolf even described the Reachy Mini as “a bit like an empty iPhone,” hinting at how massive he thinks this market is.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;The Reachy Mini has gone somewhat viral since launch, largely thanks to its friendly and open design, but also its relatively accessible price point that lets consumers try out an AI-powered robot this year. Wolf says that’s a key part to this launch — making something people want to see on their desk everyday, and can actually afford. Wolf describes the Reachy Mini as an entry point for getting consumers to be comfortable with robots in their home, and earning their trust. We got into more of that on the show.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;I was initially skeptical of the Reachy Mini, but I’ve started to come around to it. I think Wolf and Hugging Face’s vision for the AI device seems fun, and seems like a great way for kids or people new to open source software to learn about the space. Wolf also says he’s interested to see if people will vibe code apps for their robots, an idea I’m fascinated by and slightly scared of.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;At other points on the show, Wolf takes listeners inside Hugging Face’s acquisition of the French robotics startup Pollen, and his insistence on developing a robot at a low price point. Wolf also believes that open source AI will play a similar role in robotics as it has in software, and he’s trying to position Hugging Face to capture that interest.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Later in the episode, we also get into:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How Hugging Face plans to leap from software to hardware.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Hugging Face’s ambitions to one day sell a full-sized humanoid robot.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;The role of privacy in consumer robotics, and how open source can address it.&lt;/li&gt;
&lt;/ul&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt;&amp;nbsp;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt;&amp;nbsp;Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt;&amp;nbsp;Spotify&lt;/em&gt;&lt;em&gt;&amp;nbsp;and all the casts. You also can follow Equity on&lt;/em&gt; &lt;em&gt;X and &lt;/em&gt;&lt;em&gt;Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/hugging-face-bets-on-cute-robots-to-bring-open-source-ai-to-life/</guid><pubDate>Wed, 16 Jul 2025 14:32:22 +0000</pubDate></item><item><title>ChatGPT: Everything you need to know about the AI-powered chatbot (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/16/chatgpt-everything-to-know-about-the-ai-chatbot/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1462188043-e1686340799615.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-july-2025"&gt;July 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-study-warns-of-major-risks-with-ai-therapy-chatbots"&gt;Study warns of major risks with AI therapy chatbots&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-delays-releasing-its-open-model-again"&gt;OpenAI delays releasing its open model again&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;we planned to launch our open-weight model next week.&lt;/p&gt;&lt;p&gt;we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.&lt;/p&gt;&lt;p&gt;while we trust the community will build great things with this model, once weights are…&lt;/p&gt;— Sam Altman (@sama) July 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks"&gt;&lt;strong&gt;OpenAI is reportedly releasing an AI browser in the coming weeks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-is-testing-a-mysterious-new-feature-called-study-together"&gt;ChatGPT is testing a mysterious new feature called ‘study together’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-referrals-from-chatgpt-to-news-sites-are-rising-but-not-enough-to-offset-search-declines"&gt;Referrals from ChatGPT to news sites are rising but not enough to offset search declines&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Referrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="june2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-uses-google-s-ai-chips-to-power-its-products"&gt;&lt;strong&gt;OpenAI uses Google’s AI chips to power its products&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using &lt;em&gt;non&lt;/em&gt;-Nvidia chips in an important way.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-a-new-mit-study-suggests-that-chatgpt-might-be-harming-critical-thinking-skills"&gt;&lt;strong&gt;A new MIT study suggests that ChatGPT might be harming critical thinking skills&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-was-downloaded-30-million-times-last-month"&gt;ChatGPT was downloaded 30 million times last month&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1462188043-e1686340799615.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-july-2025"&gt;July 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-study-warns-of-major-risks-with-ai-therapy-chatbots"&gt;Study warns of major risks with AI therapy chatbots&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-delays-releasing-its-open-model-again"&gt;OpenAI delays releasing its open model again&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;we planned to launch our open-weight model next week.&lt;/p&gt;&lt;p&gt;we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.&lt;/p&gt;&lt;p&gt;while we trust the community will build great things with this model, once weights are…&lt;/p&gt;— Sam Altman (@sama) July 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks"&gt;&lt;strong&gt;OpenAI is reportedly releasing an AI browser in the coming weeks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-is-testing-a-mysterious-new-feature-called-study-together"&gt;ChatGPT is testing a mysterious new feature called ‘study together’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-referrals-from-chatgpt-to-news-sites-are-rising-but-not-enough-to-offset-search-declines"&gt;Referrals from ChatGPT to news sites are rising but not enough to offset search declines&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Referrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="june2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-uses-google-s-ai-chips-to-power-its-products"&gt;&lt;strong&gt;OpenAI uses Google’s AI chips to power its products&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using &lt;em&gt;non&lt;/em&gt;-Nvidia chips in an important way.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-a-new-mit-study-suggests-that-chatgpt-might-be-harming-critical-thinking-skills"&gt;&lt;strong&gt;A new MIT study suggests that ChatGPT might be harming critical thinking skills&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-was-downloaded-30-million-times-last-month"&gt;ChatGPT was downloaded 30 million times last month&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/16/chatgpt-everything-to-know-about-the-ai-chatbot/</guid><pubDate>Wed, 16 Jul 2025 15:22:21 +0000</pubDate></item><item><title>Google rolls out AI-powered business-calling feature, brings Gemini 2.5 Pro to AI Mode (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/16/google-rolls-out-ai-powered-business-calling-feature-brings-gemini-2-5-pro-to-ai-mode/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is rolling out an agentic AI-powered business-calling feature to all users in the United States, the company announced on Wednesday. The tech giant is also enhancing Google Search’s AI Mode by bringing its Gemini 2.5 Pro model to the search experience and introducing deep research capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new business-calling feature uses AI to call local businesses on your behalf to collect information about availability and pricing. The idea behind the feature is to help you access information without having to actually pick up the phone and talk to someone.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google began testing the feature back in January with users who opted into the company’s&amp;nbsp;Search Labs&amp;nbsp;experiments.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3028357" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/AI-powered-calling-Static-8.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;To get started, you need to search for something like “pet groomers near me,” and you’ll see a new option in the results to “Have AI check pricing.” From there, you answer a couple of questions to receive&amp;nbsp;information about appointments and services from different local businesses. For example, you will be asked which type of pet you have, which services you need, and when you need the service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Google spokesperson told TechCrunch in an email that every call to a business begins by announcing that it’s an automated system calling from Google on behalf of a user. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth noting that Google faced backlash a few years ago for a similar business-calling feature that simulated human speech, as some users were concerned that the company was misleading people into thinking they were speaking with another human. Following the backlash, Google said its AI would identify itself as a robot when placing these calls. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new business-calling feature is starting to roll out to all Search users in the United States, with higher limits for Google AI Pro and AI Ultra subscribers.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Google is also supercharging AI Mode, the Google Search feature that lets you ask complex and multi-part questions via an AI interface, with Gemini 2.5 Pro for Google AI Pro and AI Ultra subscribers. The tech giant says the model excels at advanced reasoning, math, and coding questions. Subscribers will be able to select the 2.5 Pro model from a drop-down menu in AI Mode.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3028358" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/Deep-Search-_-Real-Estate-Query-Static.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As for the new “Deep Search” feature in AI Mode, Google says it will save subscribers hours by conducting hundreds of searches and issuing reasoning across differing pieces of information to create a comprehensive and fully cited report in minutes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that Deep Search is useful for in-depth research related to jobs, hobbies, or studies. The company says it’s also useful in instances where you’re making big life decisions, like buying a new house or seeking assistance with a financial analysis.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Since its launch earlier this year, Google has been building out AI Mode with additional capabilities as it continues to take on popular services like Perplexity AI and OpenAI’s ChatGPT Search. For example, Google last month rolled out the ability to have a back-and-forth voice conversation with AI Mode. In May, Google introduced a shopping experience in AI Mode to allow you to view product visuals and other AI-powered guidance that leverages product data.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is rolling out an agentic AI-powered business-calling feature to all users in the United States, the company announced on Wednesday. The tech giant is also enhancing Google Search’s AI Mode by bringing its Gemini 2.5 Pro model to the search experience and introducing deep research capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new business-calling feature uses AI to call local businesses on your behalf to collect information about availability and pricing. The idea behind the feature is to help you access information without having to actually pick up the phone and talk to someone.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google began testing the feature back in January with users who opted into the company’s&amp;nbsp;Search Labs&amp;nbsp;experiments.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3028357" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/AI-powered-calling-Static-8.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;To get started, you need to search for something like “pet groomers near me,” and you’ll see a new option in the results to “Have AI check pricing.” From there, you answer a couple of questions to receive&amp;nbsp;information about appointments and services from different local businesses. For example, you will be asked which type of pet you have, which services you need, and when you need the service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Google spokesperson told TechCrunch in an email that every call to a business begins by announcing that it’s an automated system calling from Google on behalf of a user. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth noting that Google faced backlash a few years ago for a similar business-calling feature that simulated human speech, as some users were concerned that the company was misleading people into thinking they were speaking with another human. Following the backlash, Google said its AI would identify itself as a robot when placing these calls. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new business-calling feature is starting to roll out to all Search users in the United States, with higher limits for Google AI Pro and AI Ultra subscribers.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Google is also supercharging AI Mode, the Google Search feature that lets you ask complex and multi-part questions via an AI interface, with Gemini 2.5 Pro for Google AI Pro and AI Ultra subscribers. The tech giant says the model excels at advanced reasoning, math, and coding questions. Subscribers will be able to select the 2.5 Pro model from a drop-down menu in AI Mode.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3028358" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/Deep-Search-_-Real-Estate-Query-Static.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As for the new “Deep Search” feature in AI Mode, Google says it will save subscribers hours by conducting hundreds of searches and issuing reasoning across differing pieces of information to create a comprehensive and fully cited report in minutes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that Deep Search is useful for in-depth research related to jobs, hobbies, or studies. The company says it’s also useful in instances where you’re making big life decisions, like buying a new house or seeking assistance with a financial analysis.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Since its launch earlier this year, Google has been building out AI Mode with additional capabilities as it continues to take on popular services like Perplexity AI and OpenAI’s ChatGPT Search. For example, Google last month rolled out the ability to have a back-and-forth voice conversation with AI Mode. In May, Google introduced a shopping experience in AI Mode to allow you to view product visuals and other AI-powered guidance that leverages product data.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/16/google-rolls-out-ai-powered-business-calling-feature-brings-gemini-2-5-pro-to-ai-mode/</guid><pubDate>Wed, 16 Jul 2025 16:00:00 +0000</pubDate></item><item><title>xAI is hiring an engineer to make anime girls (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/16/xai-is-hiring-an-engineer-to-make-anime-girls/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/ani-grok.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk’s xAI just released its AI companions, which include the goth waifu Ani and the homicidal red panda Bad Rudy. If you want to get in on that, you’re in luck: The company is hiring for the role of “Fullstack Engineer – Waifus,” or, creating AI-powered anime girls for people to fall in love with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This job is, to quote the listing, part of xAI’s mission to “create AI systems that can accurately understand the universe and aid humanity in the pursuit of knowledge.” &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, that accurate understanding of the universe includes understanding how to create a submissive, pocket-sized girlfriend that will capture users’ hearts and wallets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI has dozens of roles open at the moment, so we can’t say that the company is putting all of its eggs in the waifu basket. But we can probably expect Ani to get some friends in the future.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/ani-grok.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk’s xAI just released its AI companions, which include the goth waifu Ani and the homicidal red panda Bad Rudy. If you want to get in on that, you’re in luck: The company is hiring for the role of “Fullstack Engineer – Waifus,” or, creating AI-powered anime girls for people to fall in love with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This job is, to quote the listing, part of xAI’s mission to “create AI systems that can accurately understand the universe and aid humanity in the pursuit of knowledge.” &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, that accurate understanding of the universe includes understanding how to create a submissive, pocket-sized girlfriend that will capture users’ hearts and wallets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI has dozens of roles open at the moment, so we can’t say that the company is putting all of its eggs in the waifu basket. But we can probably expect Ani to get some friends in the future.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/16/xai-is-hiring-an-engineer-to-make-anime-girls/</guid><pubDate>Wed, 16 Jul 2025 16:09:02 +0000</pubDate></item><item><title>[NEW] AWS unveils Bedrock AgentCore, a new platform for building enterprise AI agents with open source frameworks and tools (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/aws-unveils-bedrock-agentcore-a-new-platform-for-building-enterprise-ai-agents-with-open-source-frameworks-and-tools/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Cloud giant Amazon Web Services (AWS) believes AI agents will change how we all work and interact with information, and that enterprises need a platform that allows them to build and deploy agents at scale — all in one place.&lt;/p&gt;&lt;p&gt;Today at its New York Summit, AWS unveiled Amazon Bedrock AgentCore, &lt;strong&gt;a new enterprise-grade platform designed to build, deploy, and operate AI agents securely and at scale.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Swami Sivasubramanian, AWS Vice President of Agentic AI, said during the keynote that AgentCore “helps organizations move beyond experiments to production-ready agent systems that can be trusted with your most critical business processes.”&lt;/p&gt;&lt;p&gt;AgentCore is a modular stack of services—available in preview—that gives developers the core infrastructure needed to move AI agents from prototype to production, including runtime, memory, identity, observability, API integration, and tools for web browsing and code execution.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;“We believe that agents are going to fundamentally change how we use tools and the internet,” said Deepak Singh, AWS Vice President of Databases and AI. &lt;/strong&gt;“The line between an agent and an application is getting blurrier.”&lt;/p&gt;



&lt;p&gt;AgentCore builds on the existing Bedrock Agents framework, launched in late 2024, but dramatically expands capabilities by supporting any agent framework or foundation model—not just those hosted within Bedrock. &lt;/p&gt;



&lt;p&gt;That includes &lt;strong&gt;compatibility with open-source toolkits like CrewAI, LangChain, LlamaIndex, LangGraph, and AWS’s own Strands Agents SDK.&lt;/strong&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-aws-bedrock-agentcore-includes"&gt;What AWS Bedrock AgentCore includes&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;AgentCore Runtime:&lt;/strong&gt; A serverless, low-latency execution environment that supports multimodal workloads and long-running sessions with session isolation.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Memory:&lt;/strong&gt; Long- and short-term memory services that let agents learn from past interactions and persist contextual knowledge across sessions.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Identity:&lt;/strong&gt; OAuth-based identity and access management, allowing agents to act on behalf of users across systems like GitHub, Slack, or Salesforce.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Observability:&lt;/strong&gt; Built-in dashboards, debugging, and telemetry tools with support for OpenTelemetry, LangSmith, and Datadog.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Gateway:&lt;/strong&gt; Converts internal APIs, Lambda functions, and third-party services into agent-compatible tools using the Model Context Protocol (MCP).&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Browser:&lt;/strong&gt; Provides headless browser access for agents to autonomously interact with websites.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Code Interpreter:&lt;/strong&gt; A secure environment for executing code generated by agents for analysis and visualization.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;AgentCore also integrates with the AWS Marketplace, enabling teams to discover and deploy pre-built agents and tools.&lt;/p&gt;



&lt;p&gt;According to Singh, AgentCore has been designed with interoperability in mind. It supports emerging industry standards like MCP and Google’s Agent-2-Agent (A2A) protocol. Features such as AgentCore Identity and Gateway ensure agents have clear permissioning and can interact securely with internal systems and third-party APIs.&lt;/p&gt;



&lt;p&gt;AWS’s launch puts it squarely into the center of what’s quickly becoming one of the most competitive segments in enterprise AI.&lt;/p&gt;



&lt;p&gt;OpenAI’s Agents SDK and Google’s Gemini-based Agents SDK are both pushing similar visions of end-to-end agent development platforms. &lt;/p&gt;



&lt;p&gt;Writer’s AI HQ and startups like Cognition (maker of Devin) are also building tools for managing autonomous software agents.&lt;/p&gt;



&lt;p&gt;“Agents are the most impactful change we’ve seen in ages,” Sivasubramanian said. “With agents comes a shift to service as a software. This is a tectonic change in how software is built, deployed and operated.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-customer-adoption-and-early-use-cases"&gt;Customer adoption and early use cases&lt;/h2&gt;



&lt;p&gt;Several companies granted early access to AgentCore are already building production-grade agentic applications across industries including finance, healthcare, marketing, and content management.&lt;/p&gt;



&lt;p&gt;Cloud document and file storage company Box is exploring ways to extend its content management tools using Strands Agents and Bedrock AgentCore Runtime. &lt;/p&gt;



&lt;p&gt;CTO Ben Kus said the integration gives Box customers “top tier security and compliance” while scaling AI capabilities across enterprise environments.&lt;/p&gt;



&lt;p&gt;Brazil’s Itaú Unibanco is using AgentCore to support its development of hyper-personalized, secure digital banking experiences. Chief Technology Officer Carlos Eduardo Mazzei said the new platform “will help us deliver an intuitive banking experience with the efficiency of automation and personalization customers expect.”&lt;/p&gt;



&lt;p&gt;In the healthcare space, Innovaccer has built a new protocol—HMCP (Healthcare Model Context Protocol)—on top of AgentCore Gateway. CEO and co-founder Abhinav Shashank called Gateway a “game-changer” that allows the company to convert existing APIs into agent-compatible tools at scale while maintaining trust, compliance, and operational efficiency.&lt;/p&gt;



&lt;p&gt;Marketing firm Epsilon is leveraging AgentCore to accelerate campaign build times and improve engagement. Prashanth Athota, SVP of Software Engineering, said the company expects to reduce build times by up to 30% and enhance customer journey personalization.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-availability-and-pricing"&gt;Availability and pricing&lt;/h2&gt;



&lt;p&gt;AgentCore is now available in preview in select AWS regions including US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Frankfurt). It’s free to try until September 16, 2025, with pricing to begin thereafter.&lt;/p&gt;



&lt;p&gt;Pricing for AgentCore is entirely consumption-based, with no upfront commitments or minimum fees. Each module—Runtime, Memory, Identity, Observability, Gateway, Browser, and Code Interpreter—is billed independently and can be used a la carte or together.&lt;/p&gt;



&lt;p&gt;Runtime, Browser, and Code Interpreter services are priced per second, based on CPU and memory usage, with rates set at $0.0895 per vCPU-hour and $0.00945 per GB-hour.&lt;/p&gt;



&lt;p&gt;Gateway charges $0.005 per 1,000 tool API invocations, $0.025 per 1,000 search queries, and $0.02 per 100 tools indexed per month.&lt;/p&gt;



&lt;p&gt;Memory costs are based on data volume: $0.25 per 1,000 short-term memory events, $0.75 per 1,000 long-term memories stored (or $0.25 with custom strategies), and $0.50 per 1,000 retrievals.&lt;/p&gt;



&lt;p&gt;AgentCore Identity costs $0.010 per 1,000 token or API key requests, though it’s included at no extra charge when used via Runtime or Gateway.&lt;/p&gt;



&lt;p&gt;Observability is billed via Amazon CloudWatch rates.&lt;/p&gt;



&lt;p&gt;To learn more or get started, AWS directs developers to its AgentCore documentation, GitHub samples, and a dedicated Discord server.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Cloud giant Amazon Web Services (AWS) believes AI agents will change how we all work and interact with information, and that enterprises need a platform that allows them to build and deploy agents at scale — all in one place.&lt;/p&gt;&lt;p&gt;Today at its New York Summit, AWS unveiled Amazon Bedrock AgentCore, &lt;strong&gt;a new enterprise-grade platform designed to build, deploy, and operate AI agents securely and at scale.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Swami Sivasubramanian, AWS Vice President of Agentic AI, said during the keynote that AgentCore “helps organizations move beyond experiments to production-ready agent systems that can be trusted with your most critical business processes.”&lt;/p&gt;&lt;p&gt;AgentCore is a modular stack of services—available in preview—that gives developers the core infrastructure needed to move AI agents from prototype to production, including runtime, memory, identity, observability, API integration, and tools for web browsing and code execution.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;“We believe that agents are going to fundamentally change how we use tools and the internet,” said Deepak Singh, AWS Vice President of Databases and AI. &lt;/strong&gt;“The line between an agent and an application is getting blurrier.”&lt;/p&gt;



&lt;p&gt;AgentCore builds on the existing Bedrock Agents framework, launched in late 2024, but dramatically expands capabilities by supporting any agent framework or foundation model—not just those hosted within Bedrock. &lt;/p&gt;



&lt;p&gt;That includes &lt;strong&gt;compatibility with open-source toolkits like CrewAI, LangChain, LlamaIndex, LangGraph, and AWS’s own Strands Agents SDK.&lt;/strong&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-aws-bedrock-agentcore-includes"&gt;What AWS Bedrock AgentCore includes&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;AgentCore Runtime:&lt;/strong&gt; A serverless, low-latency execution environment that supports multimodal workloads and long-running sessions with session isolation.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Memory:&lt;/strong&gt; Long- and short-term memory services that let agents learn from past interactions and persist contextual knowledge across sessions.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Identity:&lt;/strong&gt; OAuth-based identity and access management, allowing agents to act on behalf of users across systems like GitHub, Slack, or Salesforce.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Observability:&lt;/strong&gt; Built-in dashboards, debugging, and telemetry tools with support for OpenTelemetry, LangSmith, and Datadog.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Gateway:&lt;/strong&gt; Converts internal APIs, Lambda functions, and third-party services into agent-compatible tools using the Model Context Protocol (MCP).&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Browser:&lt;/strong&gt; Provides headless browser access for agents to autonomously interact with websites.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;AgentCore Code Interpreter:&lt;/strong&gt; A secure environment for executing code generated by agents for analysis and visualization.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;AgentCore also integrates with the AWS Marketplace, enabling teams to discover and deploy pre-built agents and tools.&lt;/p&gt;



&lt;p&gt;According to Singh, AgentCore has been designed with interoperability in mind. It supports emerging industry standards like MCP and Google’s Agent-2-Agent (A2A) protocol. Features such as AgentCore Identity and Gateway ensure agents have clear permissioning and can interact securely with internal systems and third-party APIs.&lt;/p&gt;



&lt;p&gt;AWS’s launch puts it squarely into the center of what’s quickly becoming one of the most competitive segments in enterprise AI.&lt;/p&gt;



&lt;p&gt;OpenAI’s Agents SDK and Google’s Gemini-based Agents SDK are both pushing similar visions of end-to-end agent development platforms. &lt;/p&gt;



&lt;p&gt;Writer’s AI HQ and startups like Cognition (maker of Devin) are also building tools for managing autonomous software agents.&lt;/p&gt;



&lt;p&gt;“Agents are the most impactful change we’ve seen in ages,” Sivasubramanian said. “With agents comes a shift to service as a software. This is a tectonic change in how software is built, deployed and operated.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-customer-adoption-and-early-use-cases"&gt;Customer adoption and early use cases&lt;/h2&gt;



&lt;p&gt;Several companies granted early access to AgentCore are already building production-grade agentic applications across industries including finance, healthcare, marketing, and content management.&lt;/p&gt;



&lt;p&gt;Cloud document and file storage company Box is exploring ways to extend its content management tools using Strands Agents and Bedrock AgentCore Runtime. &lt;/p&gt;



&lt;p&gt;CTO Ben Kus said the integration gives Box customers “top tier security and compliance” while scaling AI capabilities across enterprise environments.&lt;/p&gt;



&lt;p&gt;Brazil’s Itaú Unibanco is using AgentCore to support its development of hyper-personalized, secure digital banking experiences. Chief Technology Officer Carlos Eduardo Mazzei said the new platform “will help us deliver an intuitive banking experience with the efficiency of automation and personalization customers expect.”&lt;/p&gt;



&lt;p&gt;In the healthcare space, Innovaccer has built a new protocol—HMCP (Healthcare Model Context Protocol)—on top of AgentCore Gateway. CEO and co-founder Abhinav Shashank called Gateway a “game-changer” that allows the company to convert existing APIs into agent-compatible tools at scale while maintaining trust, compliance, and operational efficiency.&lt;/p&gt;



&lt;p&gt;Marketing firm Epsilon is leveraging AgentCore to accelerate campaign build times and improve engagement. Prashanth Athota, SVP of Software Engineering, said the company expects to reduce build times by up to 30% and enhance customer journey personalization.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-availability-and-pricing"&gt;Availability and pricing&lt;/h2&gt;



&lt;p&gt;AgentCore is now available in preview in select AWS regions including US East (N. Virginia), US West (Oregon), Asia Pacific (Sydney), and Europe (Frankfurt). It’s free to try until September 16, 2025, with pricing to begin thereafter.&lt;/p&gt;



&lt;p&gt;Pricing for AgentCore is entirely consumption-based, with no upfront commitments or minimum fees. Each module—Runtime, Memory, Identity, Observability, Gateway, Browser, and Code Interpreter—is billed independently and can be used a la carte or together.&lt;/p&gt;



&lt;p&gt;Runtime, Browser, and Code Interpreter services are priced per second, based on CPU and memory usage, with rates set at $0.0895 per vCPU-hour and $0.00945 per GB-hour.&lt;/p&gt;



&lt;p&gt;Gateway charges $0.005 per 1,000 tool API invocations, $0.025 per 1,000 search queries, and $0.02 per 100 tools indexed per month.&lt;/p&gt;



&lt;p&gt;Memory costs are based on data volume: $0.25 per 1,000 short-term memory events, $0.75 per 1,000 long-term memories stored (or $0.25 with custom strategies), and $0.50 per 1,000 retrievals.&lt;/p&gt;



&lt;p&gt;AgentCore Identity costs $0.010 per 1,000 token or API key requests, though it’s included at no extra charge when used via Runtime or Gateway.&lt;/p&gt;



&lt;p&gt;Observability is billed via Amazon CloudWatch rates.&lt;/p&gt;



&lt;p&gt;To learn more or get started, AWS directs developers to its AgentCore documentation, GitHub samples, and a dedicated Discord server.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/aws-unveils-bedrock-agentcore-a-new-platform-for-building-enterprise-ai-agents-with-open-source-frameworks-and-tools/</guid><pubDate>Wed, 16 Jul 2025 16:31:56 +0000</pubDate></item><item><title>Nvidia’s resumption of H20 chip sales related to rare-earth element trade talks (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/16/nvidias-resumption-of-h20-chip-sales-related-to-rare-earth-element-trade-talks/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;br /&gt;Rare-earth elements appear to be behind Nvidia’s stance on China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After announcing in June plans to essentially withdraw from the Chinese market, the semiconductor chip and AI giant reversed course and said it was filing an application to&amp;nbsp;restart sales of its H20 AI chip to China.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;U.S. Commerce Secretary Howard Lutnick said Tuesday that Nvidia’s plans to start selling its H20 AI chips are tied to ongoing trade discussions with China regarding rare-earth elements, according to reporting from Reuters.&amp;nbsp;AMD plans to restart sales of its MI308 AI chip in China too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rare-earth elements (REE) like lanthanum and cerium, which are largely mined in China, are necessary components in technology, including rechargeable batteries for electric vehicles. These REEs have become a critical point in the current trade debates between the U.S. and China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Not everyone is happy with this trade development though.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The decision “would not only hand our foreign adversaries our most advanced technologies, but is also dangerously inconsistent with this administration’s previously-stated position on export controls for China,” Congressman Raja Krishnamoorthi said in a statement, according to Reuters.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Lutnick isn’t concerned and told CNBC on Tuesday that China is only getting Nvidia’s “fourth best” chip.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t sell them our best stuff, not our second best stuff, not even our third best,” Lutnick said in the interview.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This news comes less than a week after it was rumored that Nvidia would be designing and releasing a new AI chip specifically for the Chinese market to resume business in the country without violating U.S. chip export rules.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The U.S. is still trying to figure out what its AI chip export rules are going to look like. The Trump administration formally rescinded the Biden administration’s AI Diffusion Rule in May and there hasn’t been a formal update since.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Trump administration was rumored to be considering further restrictions on AI chip exports to countries like Thailand and Malaysia, to prevent smuggling, Bloomberg reported last week. Malaysia implemented trade permits on U.S.-made AI chips on Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to Nvidia for comment. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;br /&gt;Rare-earth elements appear to be behind Nvidia’s stance on China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After announcing in June plans to essentially withdraw from the Chinese market, the semiconductor chip and AI giant reversed course and said it was filing an application to&amp;nbsp;restart sales of its H20 AI chip to China.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;U.S. Commerce Secretary Howard Lutnick said Tuesday that Nvidia’s plans to start selling its H20 AI chips are tied to ongoing trade discussions with China regarding rare-earth elements, according to reporting from Reuters.&amp;nbsp;AMD plans to restart sales of its MI308 AI chip in China too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rare-earth elements (REE) like lanthanum and cerium, which are largely mined in China, are necessary components in technology, including rechargeable batteries for electric vehicles. These REEs have become a critical point in the current trade debates between the U.S. and China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Not everyone is happy with this trade development though.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The decision “would not only hand our foreign adversaries our most advanced technologies, but is also dangerously inconsistent with this administration’s previously-stated position on export controls for China,” Congressman Raja Krishnamoorthi said in a statement, according to Reuters.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Lutnick isn’t concerned and told CNBC on Tuesday that China is only getting Nvidia’s “fourth best” chip.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t sell them our best stuff, not our second best stuff, not even our third best,” Lutnick said in the interview.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This news comes less than a week after it was rumored that Nvidia would be designing and releasing a new AI chip specifically for the Chinese market to resume business in the country without violating U.S. chip export rules.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The U.S. is still trying to figure out what its AI chip export rules are going to look like. The Trump administration formally rescinded the Biden administration’s AI Diffusion Rule in May and there hasn’t been a formal update since.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Trump administration was rumored to be considering further restrictions on AI chip exports to countries like Thailand and Malaysia, to prevent smuggling, Bloomberg reported last week. Malaysia implemented trade permits on U.S.-made AI chips on Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to Nvidia for comment. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/16/nvidias-resumption-of-h20-chip-sales-related-to-rare-earth-element-trade-talks/</guid><pubDate>Wed, 16 Jul 2025 16:57:25 +0000</pubDate></item><item><title>[NEW] Claude Code revenue jumps 5.5x as Anthropic launches analytics dashboard (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/anthropic-adds-usage-tracking-to-claude-code-as-enterprise-ai-spending-surges/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Anthropic announced today it is rolling out a comprehensive analytics dashboard for its Claude Code AI programming assistant, addressing one of the most pressing concerns for enterprise technology leaders: understanding whether their investments in AI coding tools are actually paying off.&lt;/p&gt;&lt;p&gt;The new dashboard will provide engineering managers with detailed metrics on how their teams use Claude Code, including lines of code accepted, suggestion accept rates, total user activity over time, total spend over time, average daily spend for each user, and average daily lines of code accepted for each user. The feature comes as companies increasingly demand concrete data to justify their AI spending amid a broader enterprise push to measure artificial intelligence’s return on investment.&lt;/p&gt;&lt;p&gt;“When you’re overseeing a big engineering team, you want to know what everyone’s doing, and that can be very difficult,” said Adam Wolff, who manages Anthropic’s Claude Code team and previously served as head of engineering at Robinhood. “It’s hard to measure, and we’ve seen some startups in this space trying to address this, but it’s valuable to gain insights into how people are using the tools that you give them.”&lt;/p&gt;&lt;p&gt;The dashboard addresses a fundamental challenge facing technology executives: As AI-powered development tools become standard in software engineering, managers lack visibility into which teams and individuals are benefiting most from these expensive premium tools. Claude Code pricing starts at $17 per month for individual developers, with enterprise plans reaching significantly higher price points.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014350" height="544" src="https://venturebeat.com/wp-content/uploads/2025/07/NEW-Claude-Code-Metrics.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;A screenshot of Anthropic’s new analytics dashboard for Claude Code shows usage metrics, spending data and individual developer activity for a team of engineers over a one-month period. (Credit: Anthropic)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-companies-demand-proof-their-ai-coding-investments-are-working"&gt;Companies demand proof their AI coding investments are working&lt;/h2&gt;



&lt;p&gt;This marks one of Anthropic’s most requested features from enterprise customers, signaling broader enterprise appetite for AI accountability tools. The dashboard will track commits, pull requests, and provide detailed breakdowns of activity by user and cost — data that engineering leaders say is crucial for understanding how AI is changing development workflows.&lt;/p&gt;



&lt;p&gt;“Different customers actually want to do different things with that cost,” Wolff explained. “Some were like, hey, I want to spend as much as I can on these AI enablement tools because they see it as a multiplier. Some obviously are sensibly looking to make sure that they don’t blow out their spend.”&lt;/p&gt;



&lt;p&gt;The feature includes role-based access controls, allowing organizations to configure who can view usage data. Wolff emphasized that the system focuses on metadata rather than actual code content, addressing potential privacy concerns about employee surveillance.&lt;/p&gt;



&lt;p&gt;“This does not contain any of the information about what people are actually doing,” he said. “It’s more the meta of, like, how much are they using it, you know, like, which tools are working? What kind of tool acceptance rate do you see — things that you would use to tweak your overall deployment.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-claude-code-revenue-jumps-5-5x-as-developer-adoption-surges"&gt;Claude Code revenue jumps 5.5x as developer adoption surges&lt;/h2&gt;



&lt;p&gt;The dashboard launch comes amid extraordinary growth for Claude Code since Anthropic introduced its Claude 4 models in May. The platform has seen active user base growth of 300% and run-rate revenue expansion of more than 5.5 times, according to company data.&lt;/p&gt;



&lt;p&gt;“Claude Code is on a roll,” Wolff told VentureBeat. “We’ve seen five and a half times revenue growth since we launched the Claude 4 models in May. That gives you a sense of the deluge in demand we’re seeing.”&lt;/p&gt;



&lt;p&gt;The customer roster includes prominent technology companies like Figma, Rakuten, and Intercom, representing a mix of design tools, e-commerce platforms, and customer service technology providers. Wolff noted that many additional enterprise customers are using Claude Code but haven’t yet granted permission for public disclosure.&lt;/p&gt;



&lt;p&gt;The growth trajectory reflects broader industry momentum around AI coding assistants. GitHub’s Copilot, Microsoft’s AI-powered programming tool, has amassed millions of users, while newer entrants like Cursor and recently acquired Windsurf have gained traction among developers seeking more powerful AI assistance.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-premium-pricing-strategy-targets-enterprise-customers-willing-to-pay-more"&gt;Premium pricing strategy targets enterprise customers willing to pay more&lt;/h2&gt;



&lt;p&gt;Claude Code positions itself as a premium enterprise solution in an increasingly crowded market of AI coding tools. Unlike some competitors that focus primarily on code completion, Claude Code offers what Anthropic calls “agentic” capabilities — the ability to understand entire codebases, make coordinated changes across multiple files, and work directly within existing development workflows.&lt;/p&gt;



&lt;p&gt;“This is not cheap. This is a premium tool,” Wolff said. “The buyer has to understand what they’re getting for it. When you see these metrics, it’s pretty clear that developers are using these tools, and they’re making them more productive.”&lt;/p&gt;



&lt;p&gt;The company targets organizations with dedicated AI enablement teams and substantial development operations. Wolff said the most tech-forward companies are leading adoption, particularly those with internal teams focused on AI integration.&lt;/p&gt;



&lt;p&gt;“Certainly companies that have their own AI enablement teams, they love Claude Code because it’s so customizable, it can be deployed with the right set of tools and prompts and permissions that work really well for their organization,” he explained.&lt;/p&gt;



&lt;p&gt;Traditional industries with large developer teams are showing increasing interest, though adoption timelines remain longer as these organizations navigate procurement processes and deployment strategies.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ai-coding-assistant-market-heats-up-as-tech-giants-battle-for-developers"&gt;AI coding assistant market heats up as tech giants battle for developers&lt;/h2&gt;



&lt;p&gt;The analytics dashboard puts Anthropic in direct competition with enterprise feedback about measuring AI tool effectiveness—a challenge facing the entire AI coding assistant market. While competitors like GitHub Copilot and newer entrants focus primarily on individual developer productivity, Anthropic is betting that enterprise customers need comprehensive organizational insights.&lt;/p&gt;



&lt;p&gt;Amazon recently launched Kiro, its own Claude-powered coding environment, highlighting the growing competition in AI development tools. Microsoft continues expanding GitHub Copilot’s capabilities, while Google just acquire-hired Windsurf CEO Varun Mohan and key team members in a $2.4 billion deal to bolster its agentic coding efforts.&lt;/p&gt;



&lt;p&gt;Wolff believes the market has room for multiple solutions, noting that many developers use several AI coding tools depending on specific tasks. “The people who are doing best right now are the ones who are trying everything and using the exactly the right tool for the job,” he said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-autonomous-ai-agents-could-reshape-how-software-gets-built"&gt;Autonomous AI agents could reshape how software gets built&lt;/h2&gt;



&lt;p&gt;Beyond immediate productivity metrics, Wolff sees Claude Code as part of a broader shift toward “agentic” software development, where AI systems can handle complex, multi-step tasks with minimal human supervision.&lt;/p&gt;



&lt;p&gt;“One trend that we’re starting to see is that the agent is becoming the dominant mode, the way that you want to interact with an LLM,” he said. Customers are increasingly building on Claude Code’s software development kit to create custom workflows that handle everything from conversation history to tool integration and security settings.&lt;/p&gt;



&lt;p&gt;The analytics dashboard provides the foundation for organizations to measure this transition. As AI agents become more capable of autonomous software engineering tasks, enterprise leaders will need comprehensive data to understand how these systems impact their development processes.&lt;/p&gt;



&lt;p&gt;The launch is part of a broader enterprise AI trend, where organizations are moving beyond pilot projects to demand detailed analytics and ROI measurements for their AI investments. As AI coding tools mature from experimental features to core development infrastructure, visibility into their usage and effectiveness becomes increasingly critical for technology leaders.&lt;/p&gt;



&lt;p&gt;For an industry built on measuring everything from server uptime to code commits, the ability to finally measure AI’s impact on developer productivity may prove just as valuable as the AI tools themselves.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Anthropic announced today it is rolling out a comprehensive analytics dashboard for its Claude Code AI programming assistant, addressing one of the most pressing concerns for enterprise technology leaders: understanding whether their investments in AI coding tools are actually paying off.&lt;/p&gt;&lt;p&gt;The new dashboard will provide engineering managers with detailed metrics on how their teams use Claude Code, including lines of code accepted, suggestion accept rates, total user activity over time, total spend over time, average daily spend for each user, and average daily lines of code accepted for each user. The feature comes as companies increasingly demand concrete data to justify their AI spending amid a broader enterprise push to measure artificial intelligence’s return on investment.&lt;/p&gt;&lt;p&gt;“When you’re overseeing a big engineering team, you want to know what everyone’s doing, and that can be very difficult,” said Adam Wolff, who manages Anthropic’s Claude Code team and previously served as head of engineering at Robinhood. “It’s hard to measure, and we’ve seen some startups in this space trying to address this, but it’s valuable to gain insights into how people are using the tools that you give them.”&lt;/p&gt;&lt;p&gt;The dashboard addresses a fundamental challenge facing technology executives: As AI-powered development tools become standard in software engineering, managers lack visibility into which teams and individuals are benefiting most from these expensive premium tools. Claude Code pricing starts at $17 per month for individual developers, with enterprise plans reaching significantly higher price points.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014350" height="544" src="https://venturebeat.com/wp-content/uploads/2025/07/NEW-Claude-Code-Metrics.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;A screenshot of Anthropic’s new analytics dashboard for Claude Code shows usage metrics, spending data and individual developer activity for a team of engineers over a one-month period. (Credit: Anthropic)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-companies-demand-proof-their-ai-coding-investments-are-working"&gt;Companies demand proof their AI coding investments are working&lt;/h2&gt;



&lt;p&gt;This marks one of Anthropic’s most requested features from enterprise customers, signaling broader enterprise appetite for AI accountability tools. The dashboard will track commits, pull requests, and provide detailed breakdowns of activity by user and cost — data that engineering leaders say is crucial for understanding how AI is changing development workflows.&lt;/p&gt;



&lt;p&gt;“Different customers actually want to do different things with that cost,” Wolff explained. “Some were like, hey, I want to spend as much as I can on these AI enablement tools because they see it as a multiplier. Some obviously are sensibly looking to make sure that they don’t blow out their spend.”&lt;/p&gt;



&lt;p&gt;The feature includes role-based access controls, allowing organizations to configure who can view usage data. Wolff emphasized that the system focuses on metadata rather than actual code content, addressing potential privacy concerns about employee surveillance.&lt;/p&gt;



&lt;p&gt;“This does not contain any of the information about what people are actually doing,” he said. “It’s more the meta of, like, how much are they using it, you know, like, which tools are working? What kind of tool acceptance rate do you see — things that you would use to tweak your overall deployment.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-claude-code-revenue-jumps-5-5x-as-developer-adoption-surges"&gt;Claude Code revenue jumps 5.5x as developer adoption surges&lt;/h2&gt;



&lt;p&gt;The dashboard launch comes amid extraordinary growth for Claude Code since Anthropic introduced its Claude 4 models in May. The platform has seen active user base growth of 300% and run-rate revenue expansion of more than 5.5 times, according to company data.&lt;/p&gt;



&lt;p&gt;“Claude Code is on a roll,” Wolff told VentureBeat. “We’ve seen five and a half times revenue growth since we launched the Claude 4 models in May. That gives you a sense of the deluge in demand we’re seeing.”&lt;/p&gt;



&lt;p&gt;The customer roster includes prominent technology companies like Figma, Rakuten, and Intercom, representing a mix of design tools, e-commerce platforms, and customer service technology providers. Wolff noted that many additional enterprise customers are using Claude Code but haven’t yet granted permission for public disclosure.&lt;/p&gt;



&lt;p&gt;The growth trajectory reflects broader industry momentum around AI coding assistants. GitHub’s Copilot, Microsoft’s AI-powered programming tool, has amassed millions of users, while newer entrants like Cursor and recently acquired Windsurf have gained traction among developers seeking more powerful AI assistance.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-premium-pricing-strategy-targets-enterprise-customers-willing-to-pay-more"&gt;Premium pricing strategy targets enterprise customers willing to pay more&lt;/h2&gt;



&lt;p&gt;Claude Code positions itself as a premium enterprise solution in an increasingly crowded market of AI coding tools. Unlike some competitors that focus primarily on code completion, Claude Code offers what Anthropic calls “agentic” capabilities — the ability to understand entire codebases, make coordinated changes across multiple files, and work directly within existing development workflows.&lt;/p&gt;



&lt;p&gt;“This is not cheap. This is a premium tool,” Wolff said. “The buyer has to understand what they’re getting for it. When you see these metrics, it’s pretty clear that developers are using these tools, and they’re making them more productive.”&lt;/p&gt;



&lt;p&gt;The company targets organizations with dedicated AI enablement teams and substantial development operations. Wolff said the most tech-forward companies are leading adoption, particularly those with internal teams focused on AI integration.&lt;/p&gt;



&lt;p&gt;“Certainly companies that have their own AI enablement teams, they love Claude Code because it’s so customizable, it can be deployed with the right set of tools and prompts and permissions that work really well for their organization,” he explained.&lt;/p&gt;



&lt;p&gt;Traditional industries with large developer teams are showing increasing interest, though adoption timelines remain longer as these organizations navigate procurement processes and deployment strategies.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ai-coding-assistant-market-heats-up-as-tech-giants-battle-for-developers"&gt;AI coding assistant market heats up as tech giants battle for developers&lt;/h2&gt;



&lt;p&gt;The analytics dashboard puts Anthropic in direct competition with enterprise feedback about measuring AI tool effectiveness—a challenge facing the entire AI coding assistant market. While competitors like GitHub Copilot and newer entrants focus primarily on individual developer productivity, Anthropic is betting that enterprise customers need comprehensive organizational insights.&lt;/p&gt;



&lt;p&gt;Amazon recently launched Kiro, its own Claude-powered coding environment, highlighting the growing competition in AI development tools. Microsoft continues expanding GitHub Copilot’s capabilities, while Google just acquire-hired Windsurf CEO Varun Mohan and key team members in a $2.4 billion deal to bolster its agentic coding efforts.&lt;/p&gt;



&lt;p&gt;Wolff believes the market has room for multiple solutions, noting that many developers use several AI coding tools depending on specific tasks. “The people who are doing best right now are the ones who are trying everything and using the exactly the right tool for the job,” he said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-autonomous-ai-agents-could-reshape-how-software-gets-built"&gt;Autonomous AI agents could reshape how software gets built&lt;/h2&gt;



&lt;p&gt;Beyond immediate productivity metrics, Wolff sees Claude Code as part of a broader shift toward “agentic” software development, where AI systems can handle complex, multi-step tasks with minimal human supervision.&lt;/p&gt;



&lt;p&gt;“One trend that we’re starting to see is that the agent is becoming the dominant mode, the way that you want to interact with an LLM,” he said. Customers are increasingly building on Claude Code’s software development kit to create custom workflows that handle everything from conversation history to tool integration and security settings.&lt;/p&gt;



&lt;p&gt;The analytics dashboard provides the foundation for organizations to measure this transition. As AI agents become more capable of autonomous software engineering tasks, enterprise leaders will need comprehensive data to understand how these systems impact their development processes.&lt;/p&gt;



&lt;p&gt;The launch is part of a broader enterprise AI trend, where organizations are moving beyond pilot projects to demand detailed analytics and ROI measurements for their AI investments. As AI coding tools mature from experimental features to core development infrastructure, visibility into their usage and effectiveness becomes increasingly critical for technology leaders.&lt;/p&gt;



&lt;p&gt;For an industry built on measuring everything from server uptime to code commits, the ability to finally measure AI’s impact on developer productivity may prove just as valuable as the AI tools themselves.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/anthropic-adds-usage-tracking-to-claude-code-as-enterprise-ai-spending-surges/</guid><pubDate>Wed, 16 Jul 2025 17:00:00 +0000</pubDate></item><item><title>OpenAI and Anthropic researchers decry ‘reckless’ safety culture at Elon Musk’s xAI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/16/openai-and-anthropic-researchers-decry-reckless-safety-culture-at-elon-musks-xai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2198970101.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI safety researchers from OpenAI, Anthropic, and other organizations are speaking out publicly against the “reckless” and “completely irresponsible” safety culture at xAI, the billion-dollar AI startup owned by Elon Musk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The criticisms follow weeks of scandals at xAI that have overshadowed the company’s technological advances.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last week, the company’s AI chatbot, Grok, spouted antisemitic comments and repeatedly called itself “MechaHitler.” Shortly after xAI took its chatbot offline to address the problem, it launched an increasingly capable frontier AI model, Grok 4, which TechCrunch and others found to consult Elon Musk’s personal politics for help answering hot-button issues. In the latest development, xAI launched AI companions that take the form of a hyper-sexualized anime girl and an overly aggressive panda.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Friendly joshing among employees of competing AI labs is fairly normal, but these researchers seem to be calling for increased attention to xAI’s safety practices, which they claim to be at odds with industry norms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I didn’t want to post on Grok safety since I work at a competitor, but it’s not about competition,” said Boaz Barak, a computer science professor currently on leave from Harvard to work on safety research at OpenAI, in a Tuesday post on X. “I appreciate the scientists and engineers @xai but the way safety was handled is completely irresponsible.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;I didn't want to post on Grok safety since I work at a competitor, but it's not about competition.&lt;/p&gt;&lt;p&gt;I appreciate the scientists and engineers at @xai but the way safety was handled is completely irresponsible. Thread below.&lt;/p&gt;— Boaz Barak (@boazbaraktcs) July 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Barak particularly takes issue with xAI’s decision to not publish system cards — industry standard reports that detail training methods and safety evaluations in a good faith effort to share information with the research community. As a result, Barak says it’s unclear what safety training was done on Grok 4.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Google have a spotty reputation themselves when it comes to promptly sharing system cards when unveiling new AI models. OpenAI decided not to publish a system card for GPT-4.1, claiming it was not a frontier model. Meanwhile, Google waited months after unveiling Gemini 2.5 Pro to publish a safety report. However, these companies historically publish safety reports for all frontier AI models before they enter full production.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Barak also notes that Grok’s AI companions “take the worst issues we currently have for emotional dependencies and tries to amplify them.” In recent years, we’ve seen countless stories of unstable people developing concerning relationship with chatbots, and how AI’s over-agreeable answers can tip them over the edge of sanity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Samuel Marks, an AI safety researcher with Anthropic, also took issue with xAI’s decision not to publish a safety report, calling the move “reckless.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anthropic, OpenAI, and Google’s release practices have issues,” Marks wrote in a post on X. “But they at least do something, anything to assess safety pre-deployment and document findings. xAI does not.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;xAI launched Grok 4 without any documentation of their safety testing. This is reckless and breaks with industry best practices followed by other major AI labs.&lt;/p&gt;&lt;p&gt;If xAI is going to be a frontier AI developer, they should act like one. 🧵&lt;/p&gt;— Samuel Marks (@saprmarks) July 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The reality is that we don’t really know what xAI did to test Grok 4. In a widely shared post in the online forum LessWrong, one anonymous researcher claims that Grok 4 has no meaningful safety guardrails based on their testing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Whether that’s true or not, the world seems to be finding out about Grok’s shortcomings in real time. Several of xAI’s safety issues have since gone viral, and the company claims to have addressed them with tweaks to Grok’s system prompt.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI, Anthropic, and xAI did not respond to TechCrunch’s request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dan Hendrycks, a safety adviser for xAI and director of the Center for AI Safety, posted on X that the company did “dangerous capability evaluations” on Grok 4. However, the results to those evaluations have not been publicly shared.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It concerns me when standard safety practices aren’t upheld across the AI industry, like publishing the results of dangerous capability evaluations,” said Steven Adler, an independent AI researcher who previously led safety teams at OpenAI, in a statement to TechCrunch. “Governments and the public deserve to know how AI companies are handling the risks of the very powerful systems they say they’re building.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s interesting about xAI’s questionable safety practices is that Musk has long been one of the AI safety industry’s most notable advocates. The billionaire leader of xAI, Tesla, and SpaceX has warned many times about the potential for advanced AI systems to cause catastrophic outcomes for humans, and he’s praised an open approach to developing AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And yet, AI researchers at competing labs claim xAI is veering from industry norms around safely releasing AI models. In doing so, Musk’s startup may be inadvertently making a strong case for state and federal lawmakers to set rules around publishing AI safety reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are several attempts at the state level to do so. California state Sen. Scott Wiener is pushing a bill that would require leading AI labs — likely including xAI — to publish safety reports, while New York Gov. Kathy Hochul is currently considering a similar bill. Advocates of these bills note that most AI labs publish this type of information anyway — but evidently, not all of them do it consistently.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI models today have yet to exhibit real-world scenarios in which they create truly catastrophic harms, such as the death of people or billions of dollars in damages. However, many AI researchers say that this could be a problem in the near future given the rapid progress of AI models, and the billions of dollars Silicon Valley is investing to further improve AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But even for skeptics of such catastrophic scenarios, there’s a strong case to suggest that Grok’s misbehavior makes the products it powers today significantly worse. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Grok spread antisemitism around the X platform this week, just a few weeks after the chatbot repeatedly brought up “white genocide” in conversations with users. Musk has indicated that Grok will be more ingrained in Tesla vehicles, and xAI is trying to sell its AI models to The Pentagon and other enterprises. It’s hard to imagine that people driving Musk’s cars, federal workers protecting the U.S., or enterprise employees automating tasks will be any more receptive to these misbehaviors than users on X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several researchers argue that AI safety and alignment testing not only ensures that the worst outcomes don’t happen, but they also protect against near-term behavioral issues.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the very least, Grok’s incidents tend to overshadow xAI’s rapid progress in developing frontier AI models that best OpenAI and Google’s technology, just a couple years after the startup was founded. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2198970101.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI safety researchers from OpenAI, Anthropic, and other organizations are speaking out publicly against the “reckless” and “completely irresponsible” safety culture at xAI, the billion-dollar AI startup owned by Elon Musk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The criticisms follow weeks of scandals at xAI that have overshadowed the company’s technological advances.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last week, the company’s AI chatbot, Grok, spouted antisemitic comments and repeatedly called itself “MechaHitler.” Shortly after xAI took its chatbot offline to address the problem, it launched an increasingly capable frontier AI model, Grok 4, which TechCrunch and others found to consult Elon Musk’s personal politics for help answering hot-button issues. In the latest development, xAI launched AI companions that take the form of a hyper-sexualized anime girl and an overly aggressive panda.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Friendly joshing among employees of competing AI labs is fairly normal, but these researchers seem to be calling for increased attention to xAI’s safety practices, which they claim to be at odds with industry norms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I didn’t want to post on Grok safety since I work at a competitor, but it’s not about competition,” said Boaz Barak, a computer science professor currently on leave from Harvard to work on safety research at OpenAI, in a Tuesday post on X. “I appreciate the scientists and engineers @xai but the way safety was handled is completely irresponsible.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;I didn't want to post on Grok safety since I work at a competitor, but it's not about competition.&lt;/p&gt;&lt;p&gt;I appreciate the scientists and engineers at @xai but the way safety was handled is completely irresponsible. Thread below.&lt;/p&gt;— Boaz Barak (@boazbaraktcs) July 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Barak particularly takes issue with xAI’s decision to not publish system cards — industry standard reports that detail training methods and safety evaluations in a good faith effort to share information with the research community. As a result, Barak says it’s unclear what safety training was done on Grok 4.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Google have a spotty reputation themselves when it comes to promptly sharing system cards when unveiling new AI models. OpenAI decided not to publish a system card for GPT-4.1, claiming it was not a frontier model. Meanwhile, Google waited months after unveiling Gemini 2.5 Pro to publish a safety report. However, these companies historically publish safety reports for all frontier AI models before they enter full production.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Barak also notes that Grok’s AI companions “take the worst issues we currently have for emotional dependencies and tries to amplify them.” In recent years, we’ve seen countless stories of unstable people developing concerning relationship with chatbots, and how AI’s over-agreeable answers can tip them over the edge of sanity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Samuel Marks, an AI safety researcher with Anthropic, also took issue with xAI’s decision not to publish a safety report, calling the move “reckless.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Anthropic, OpenAI, and Google’s release practices have issues,” Marks wrote in a post on X. “But they at least do something, anything to assess safety pre-deployment and document findings. xAI does not.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;xAI launched Grok 4 without any documentation of their safety testing. This is reckless and breaks with industry best practices followed by other major AI labs.&lt;/p&gt;&lt;p&gt;If xAI is going to be a frontier AI developer, they should act like one. 🧵&lt;/p&gt;— Samuel Marks (@saprmarks) July 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The reality is that we don’t really know what xAI did to test Grok 4. In a widely shared post in the online forum LessWrong, one anonymous researcher claims that Grok 4 has no meaningful safety guardrails based on their testing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Whether that’s true or not, the world seems to be finding out about Grok’s shortcomings in real time. Several of xAI’s safety issues have since gone viral, and the company claims to have addressed them with tweaks to Grok’s system prompt.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI, Anthropic, and xAI did not respond to TechCrunch’s request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dan Hendrycks, a safety adviser for xAI and director of the Center for AI Safety, posted on X that the company did “dangerous capability evaluations” on Grok 4. However, the results to those evaluations have not been publicly shared.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It concerns me when standard safety practices aren’t upheld across the AI industry, like publishing the results of dangerous capability evaluations,” said Steven Adler, an independent AI researcher who previously led safety teams at OpenAI, in a statement to TechCrunch. “Governments and the public deserve to know how AI companies are handling the risks of the very powerful systems they say they’re building.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s interesting about xAI’s questionable safety practices is that Musk has long been one of the AI safety industry’s most notable advocates. The billionaire leader of xAI, Tesla, and SpaceX has warned many times about the potential for advanced AI systems to cause catastrophic outcomes for humans, and he’s praised an open approach to developing AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And yet, AI researchers at competing labs claim xAI is veering from industry norms around safely releasing AI models. In doing so, Musk’s startup may be inadvertently making a strong case for state and federal lawmakers to set rules around publishing AI safety reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are several attempts at the state level to do so. California state Sen. Scott Wiener is pushing a bill that would require leading AI labs — likely including xAI — to publish safety reports, while New York Gov. Kathy Hochul is currently considering a similar bill. Advocates of these bills note that most AI labs publish this type of information anyway — but evidently, not all of them do it consistently.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI models today have yet to exhibit real-world scenarios in which they create truly catastrophic harms, such as the death of people or billions of dollars in damages. However, many AI researchers say that this could be a problem in the near future given the rapid progress of AI models, and the billions of dollars Silicon Valley is investing to further improve AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But even for skeptics of such catastrophic scenarios, there’s a strong case to suggest that Grok’s misbehavior makes the products it powers today significantly worse. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Grok spread antisemitism around the X platform this week, just a few weeks after the chatbot repeatedly brought up “white genocide” in conversations with users. Musk has indicated that Grok will be more ingrained in Tesla vehicles, and xAI is trying to sell its AI models to The Pentagon and other enterprises. It’s hard to imagine that people driving Musk’s cars, federal workers protecting the U.S., or enterprise employees automating tasks will be any more receptive to these misbehaviors than users on X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several researchers argue that AI safety and alignment testing not only ensures that the worst outcomes don’t happen, but they also protect against near-term behavioral issues.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the very least, Grok’s incidents tend to overshadow xAI’s rapid progress in developing frontier AI models that best OpenAI and Google’s technology, just a couple years after the startup was founded. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/16/openai-and-anthropic-researchers-decry-reckless-safety-culture-at-elon-musks-xai/</guid><pubDate>Wed, 16 Jul 2025 18:11:20 +0000</pubDate></item><item><title>[NEW] Permit for xAI’s data center blatantly violates Clean Air Act, NAACP says (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/permit-for-xais-data-center-blatantly-violates-clean-air-act-naacp-says/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Evidence suggests health department gave preferential treatment to xAI, NAACP says.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2217034105-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2217034105-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Local students speak in opposition to a proposal by Elon Musk's xAI to run gas turbines at its data center during a public comment meeting hosted by the Shelby County Health Department at Fairley High School on xAI's permit application to use gas turbines for a new data center in Memphis, TN on April 25, 2025. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          The Washington Post / Contributor | The Washington Post

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;xAI continues to face backlash over its Memphis data center, as the NAACP joined groups today appealing the issuance of a recently granted permit that the groups say will allow xAI to introduce major new sources of pollutants without warning at any time.&lt;/p&gt;
&lt;p&gt;The battle over the gas turbines powering xAI's data center began last April when thermal imaging seemed to show that the firm was lying about dozens of seemingly operational turbines that could be a major source of smog-causing pollution. By June, the NAACP got involved, notifying the Shelby County Health Department (SCHD) of its intent to sue xAI to force Elon Musk's AI company to engage with community members in historically Black neighborhoods who are believed to be most affected by the pollution risks.&lt;/p&gt;
&lt;p&gt;But the NAACP's letter seemingly did nothing to stop the SCHD from granting the permits two weeks later on July 2, as well as exemptions that xAI does not appear to qualify for, the appeal noted. Now, the NAACP—alongside environmental justice groups; the Southern Environmental Law Center (SELC); and Young, Gifted and Green—is appealing. The groups are hoping the Memphis and Shelby County Air Pollution Control Board will revoke the permit and block the exemptions, agreeing that the SCHD's decisions were fatally flawed, violating the Clean Air Act and local laws.&lt;/p&gt;
&lt;p&gt;SCHD's permit granted xAI permission to operate 15 gas turbines at the Memphis data center, while the SELC's imaging showed that xAI was potentially operating as many as 24. Prior to the permitting, xAI was accused of operating at least 35 turbines without the best-available pollution controls.&lt;/p&gt;
&lt;p&gt;In their appeal, the NAACP and other groups argued that the SCHD put xAI profits over Black people's health, granting unlawful exemptions while turning a blind eye to xAI's operations, which allegedly started in 2024 but were treated as brand new in 2025.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Significantly, the groups claimed that the health department "improperly ignored" the prior turbine activity and the additional turbines still believed to be on site, unlawfully deeming some of the turbines as "temporary" and designating xAI's facility a new project with no prior emissions sources. Had xAI's data center been categorized as a modification to an existing major source of pollutants, the appeal said, xAI would've faced stricter emissions controls and "robust ambient air quality impacts assessments."&lt;/p&gt;
&lt;p&gt;And perhaps more concerningly, the exemptions granted could allow xAI—or any other emerging major sources of pollutants in the area—to "install and operate any number of new polluting turbines at any time without any written approval from the Health Department, without any public notice or public participation, and without pollution controls," the appeal said.&lt;/p&gt;
&lt;p&gt;The SCHD and xAI did not respond to Ars' request to comment.&lt;/p&gt;
&lt;h2&gt;Officials accused of cherry-picking Clean Air Act&lt;/h2&gt;
&lt;p&gt;The appeal called out the SCHD for "tellingly" omitting key provisions of the Clean Air Act that allegedly undermined the department's "position" when explaining why xAI qualified for exemptions. Groups also suggested that xAI was getting preferential treatment, providing as evidence a side-by-side comparison of a permit with stricter emissions requirements granted to a natural gas power plant, issued within months of granting xAI's permit with only generalized emissions requirements.&lt;/p&gt;
&lt;p&gt;"The Department cannot cherry pick which parts of the federal Clean Air Act it believes are relevant," the appeal said, calling the SCHD's decisions a "blatant" misrepresentation of the federal law while pointing to statements from the Environmental Protection Agency (EPA) that allegedly "directly" contradict the health department's position.&lt;/p&gt;
&lt;p&gt;For some Memphians protesting xAI's facility, it seems "indisputable" that xAI's turbines fall outside of the Clean Air Act requirements, whether they're temporary or permanent, and if that's true, it is "undeniable" that the activity violates the law. They're afraid the health department is prioritizing xAI's corporate gains over their health by "failing to establish enforceable emission limits" on the data center, which powers what xAI hypes as the world's largest AI supercomputer, Colossus, the engine behind its controversial Grok models.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Rather than a minor source, as the SCHD designated the facility, Memphians think the data center is already a major source of pollutants, with its permitted turbines releasing, at minimum, 900 tons of nitrogen oxides (NOx) per year. That's more than three times the threshold that the Clean Air Act uses to define a major source: "one that 'emits, or has the potential to emit,' at least 250 tons of NOx per year," the appeal noted. Further, the allegedly overlooked additional turbines that were on site at xAI when permitting was granted "have the potential to emit at least 560 tons of NOx per year."&lt;/p&gt;
&lt;p&gt;But so far, Memphians appear stuck with the SCHD's generalized emissions requirements and xAI's voluntary emission limits, which the appeal alleged "fall short" of the stringent limits imposed if xAI were forced to use best-available control technologies. Fixing that is "especially critical given the ongoing and worsening smog problem in Memphis," environmental groups alleged, which is an area that has "failed to meet EPA’s air quality standard for ozone for years."&lt;/p&gt;
&lt;p&gt;xAI also apparently conducted some "air dispersion modeling" to appease critics. But, again, that process was not comparable to the more rigorous analysis that would've been required to get what the EPA calls a Prevention of Significant Deterioration permit, the appeal said.&lt;/p&gt;
&lt;h2&gt;Groups want xAI’s permit revoked&lt;/h2&gt;
&lt;p&gt;To shield Memphians from ongoing health risks, the NAACP and environmental justice groups have urged the Memphis and Shelby County Air Pollution Control Board to act now.&lt;/p&gt;
&lt;p&gt;Memphis is a city already grappling with high rates of emergency room visits and deaths from asthma, with cancer rates four times the national average. Residents have already begun wearing masks, avoiding the outdoors, and keeping their windows closed since xAI's data center moved in, the appeal noted. Residents remain "deeply concerned" about feared exposure to alleged pollutants that can "cause a variety of adverse health effects," including "increased risk of lung infection, aggravated respiratory diseases such as emphysema and chronic bronchitis, and increased frequency of asthma attack," as well as certain types of cancer.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In an SELC press release, LaTricea Adams, CEO and President of Young, Gifted and Green, called the SCHD's decisions on xAI's permit "reckless."&lt;/p&gt;
&lt;p&gt;"As a Black woman born and raised in Memphis, I know firsthand how industry harms Black communities while those in power cower away from justice," Adams said. "The Shelby County Health Department needs to do their job to protect the health of ALL Memphians, especially those in frontline communities… that are burdened with a history of environmental racism, legacy pollution, and redlining."&lt;/p&gt;
&lt;p&gt;Groups also suspect xAI is stockpiling dozens of gas turbines to potentially power a second facility nearby—which could lead to over 90 turbines in operation. To get that facility up and running, Musk claimed that he will be "copying and pasting" the process for launching the first data center, SELC's press release said.&lt;/p&gt;
&lt;p&gt;Groups appealing have asked the board to revoke xAI's permits and declare that xAI's turbines do not qualify for exemptions from the Clean Air Act or other laws and that all permits for gas turbines must meet strict EPA standards. If successful, groups could force xAI to redo the permitting process "pursuant to the major source requirements of the Clean Air Act" and local law. At the very least, they've asked the board to remand the permit to the health department to "reconsider its determinations."&lt;/p&gt;
&lt;p&gt;Unless the pollution control board intervenes, Memphians worry xAI's "unlawful conduct risks being repeated and evading review," with any turbines removed easily brought back with "no notice" to residents if xAI's exemptions remain in place.&lt;/p&gt;
&lt;p&gt;"Nothing is stopping xAI from installing additional unpermitted turbines at any time to meet its widely-publicized demand for additional power," the appeal said.&lt;/p&gt;
&lt;p&gt;NAACP's director of environmental justice, Abre' Conner, confirmed in the SELC's press release that his group and community members "have repeatedly shared concerns that xAI is causing a significant increase in the pollution of the air Memphians breathe."&lt;/p&gt;
&lt;p&gt;"The health department should focus on people’s health—not on maximizing corporate gain," Conner said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Evidence suggests health department gave preferential treatment to xAI, NAACP says.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2217034105-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2217034105-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Local students speak in opposition to a proposal by Elon Musk's xAI to run gas turbines at its data center during a public comment meeting hosted by the Shelby County Health Department at Fairley High School on xAI's permit application to use gas turbines for a new data center in Memphis, TN on April 25, 2025. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          The Washington Post / Contributor | The Washington Post

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;xAI continues to face backlash over its Memphis data center, as the NAACP joined groups today appealing the issuance of a recently granted permit that the groups say will allow xAI to introduce major new sources of pollutants without warning at any time.&lt;/p&gt;
&lt;p&gt;The battle over the gas turbines powering xAI's data center began last April when thermal imaging seemed to show that the firm was lying about dozens of seemingly operational turbines that could be a major source of smog-causing pollution. By June, the NAACP got involved, notifying the Shelby County Health Department (SCHD) of its intent to sue xAI to force Elon Musk's AI company to engage with community members in historically Black neighborhoods who are believed to be most affected by the pollution risks.&lt;/p&gt;
&lt;p&gt;But the NAACP's letter seemingly did nothing to stop the SCHD from granting the permits two weeks later on July 2, as well as exemptions that xAI does not appear to qualify for, the appeal noted. Now, the NAACP—alongside environmental justice groups; the Southern Environmental Law Center (SELC); and Young, Gifted and Green—is appealing. The groups are hoping the Memphis and Shelby County Air Pollution Control Board will revoke the permit and block the exemptions, agreeing that the SCHD's decisions were fatally flawed, violating the Clean Air Act and local laws.&lt;/p&gt;
&lt;p&gt;SCHD's permit granted xAI permission to operate 15 gas turbines at the Memphis data center, while the SELC's imaging showed that xAI was potentially operating as many as 24. Prior to the permitting, xAI was accused of operating at least 35 turbines without the best-available pollution controls.&lt;/p&gt;
&lt;p&gt;In their appeal, the NAACP and other groups argued that the SCHD put xAI profits over Black people's health, granting unlawful exemptions while turning a blind eye to xAI's operations, which allegedly started in 2024 but were treated as brand new in 2025.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Significantly, the groups claimed that the health department "improperly ignored" the prior turbine activity and the additional turbines still believed to be on site, unlawfully deeming some of the turbines as "temporary" and designating xAI's facility a new project with no prior emissions sources. Had xAI's data center been categorized as a modification to an existing major source of pollutants, the appeal said, xAI would've faced stricter emissions controls and "robust ambient air quality impacts assessments."&lt;/p&gt;
&lt;p&gt;And perhaps more concerningly, the exemptions granted could allow xAI—or any other emerging major sources of pollutants in the area—to "install and operate any number of new polluting turbines at any time without any written approval from the Health Department, without any public notice or public participation, and without pollution controls," the appeal said.&lt;/p&gt;
&lt;p&gt;The SCHD and xAI did not respond to Ars' request to comment.&lt;/p&gt;
&lt;h2&gt;Officials accused of cherry-picking Clean Air Act&lt;/h2&gt;
&lt;p&gt;The appeal called out the SCHD for "tellingly" omitting key provisions of the Clean Air Act that allegedly undermined the department's "position" when explaining why xAI qualified for exemptions. Groups also suggested that xAI was getting preferential treatment, providing as evidence a side-by-side comparison of a permit with stricter emissions requirements granted to a natural gas power plant, issued within months of granting xAI's permit with only generalized emissions requirements.&lt;/p&gt;
&lt;p&gt;"The Department cannot cherry pick which parts of the federal Clean Air Act it believes are relevant," the appeal said, calling the SCHD's decisions a "blatant" misrepresentation of the federal law while pointing to statements from the Environmental Protection Agency (EPA) that allegedly "directly" contradict the health department's position.&lt;/p&gt;
&lt;p&gt;For some Memphians protesting xAI's facility, it seems "indisputable" that xAI's turbines fall outside of the Clean Air Act requirements, whether they're temporary or permanent, and if that's true, it is "undeniable" that the activity violates the law. They're afraid the health department is prioritizing xAI's corporate gains over their health by "failing to establish enforceable emission limits" on the data center, which powers what xAI hypes as the world's largest AI supercomputer, Colossus, the engine behind its controversial Grok models.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Rather than a minor source, as the SCHD designated the facility, Memphians think the data center is already a major source of pollutants, with its permitted turbines releasing, at minimum, 900 tons of nitrogen oxides (NOx) per year. That's more than three times the threshold that the Clean Air Act uses to define a major source: "one that 'emits, or has the potential to emit,' at least 250 tons of NOx per year," the appeal noted. Further, the allegedly overlooked additional turbines that were on site at xAI when permitting was granted "have the potential to emit at least 560 tons of NOx per year."&lt;/p&gt;
&lt;p&gt;But so far, Memphians appear stuck with the SCHD's generalized emissions requirements and xAI's voluntary emission limits, which the appeal alleged "fall short" of the stringent limits imposed if xAI were forced to use best-available control technologies. Fixing that is "especially critical given the ongoing and worsening smog problem in Memphis," environmental groups alleged, which is an area that has "failed to meet EPA’s air quality standard for ozone for years."&lt;/p&gt;
&lt;p&gt;xAI also apparently conducted some "air dispersion modeling" to appease critics. But, again, that process was not comparable to the more rigorous analysis that would've been required to get what the EPA calls a Prevention of Significant Deterioration permit, the appeal said.&lt;/p&gt;
&lt;h2&gt;Groups want xAI’s permit revoked&lt;/h2&gt;
&lt;p&gt;To shield Memphians from ongoing health risks, the NAACP and environmental justice groups have urged the Memphis and Shelby County Air Pollution Control Board to act now.&lt;/p&gt;
&lt;p&gt;Memphis is a city already grappling with high rates of emergency room visits and deaths from asthma, with cancer rates four times the national average. Residents have already begun wearing masks, avoiding the outdoors, and keeping their windows closed since xAI's data center moved in, the appeal noted. Residents remain "deeply concerned" about feared exposure to alleged pollutants that can "cause a variety of adverse health effects," including "increased risk of lung infection, aggravated respiratory diseases such as emphysema and chronic bronchitis, and increased frequency of asthma attack," as well as certain types of cancer.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In an SELC press release, LaTricea Adams, CEO and President of Young, Gifted and Green, called the SCHD's decisions on xAI's permit "reckless."&lt;/p&gt;
&lt;p&gt;"As a Black woman born and raised in Memphis, I know firsthand how industry harms Black communities while those in power cower away from justice," Adams said. "The Shelby County Health Department needs to do their job to protect the health of ALL Memphians, especially those in frontline communities… that are burdened with a history of environmental racism, legacy pollution, and redlining."&lt;/p&gt;
&lt;p&gt;Groups also suspect xAI is stockpiling dozens of gas turbines to potentially power a second facility nearby—which could lead to over 90 turbines in operation. To get that facility up and running, Musk claimed that he will be "copying and pasting" the process for launching the first data center, SELC's press release said.&lt;/p&gt;
&lt;p&gt;Groups appealing have asked the board to revoke xAI's permits and declare that xAI's turbines do not qualify for exemptions from the Clean Air Act or other laws and that all permits for gas turbines must meet strict EPA standards. If successful, groups could force xAI to redo the permitting process "pursuant to the major source requirements of the Clean Air Act" and local law. At the very least, they've asked the board to remand the permit to the health department to "reconsider its determinations."&lt;/p&gt;
&lt;p&gt;Unless the pollution control board intervenes, Memphians worry xAI's "unlawful conduct risks being repeated and evading review," with any turbines removed easily brought back with "no notice" to residents if xAI's exemptions remain in place.&lt;/p&gt;
&lt;p&gt;"Nothing is stopping xAI from installing additional unpermitted turbines at any time to meet its widely-publicized demand for additional power," the appeal said.&lt;/p&gt;
&lt;p&gt;NAACP's director of environmental justice, Abre' Conner, confirmed in the SELC's press release that his group and community members "have repeatedly shared concerns that xAI is causing a significant increase in the pollution of the air Memphians breathe."&lt;/p&gt;
&lt;p&gt;"The health department should focus on people’s health—not on maximizing corporate gain," Conner said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/permit-for-xais-data-center-blatantly-violates-clean-air-act-naacp-says/</guid><pubDate>Wed, 16 Jul 2025 19:20:18 +0000</pubDate></item><item><title>[NEW] Scale AI lays off 14% of staff, largely in data-labeling business (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/16/scale-ai-lays-off-14-of-staff-largely-in-data-labeling-business/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2187408947.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Data-labeling startup Scale AI is laying off 200 employees, roughly 14% of its staff, and cutting ties with 500 of its global contractors, Bloomberg reported on Wednesday. The cuts come just a month after Meta hired Scale AI’s CEO in a $14.3 billion deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a memo obtained by Bloomberg, interim CEO Jason Droege told staff that Scale AI had too quickly scaled its core data-labeling business — in which the startup supplied AI labs with labeled, structured data to train AI models. Droege said in the memo that Scale AI would staff up around its enterprise and government sales units.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Like other AI startups that have been reverse acqui-hired, such as Inflection, it seems that Scale AI now has to pivot from the business that put it on the map. In light of Meta’s investment, several of Scale AI’s largest data customers cut ties with the startup.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2187408947.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Data-labeling startup Scale AI is laying off 200 employees, roughly 14% of its staff, and cutting ties with 500 of its global contractors, Bloomberg reported on Wednesday. The cuts come just a month after Meta hired Scale AI’s CEO in a $14.3 billion deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a memo obtained by Bloomberg, interim CEO Jason Droege told staff that Scale AI had too quickly scaled its core data-labeling business — in which the startup supplied AI labs with labeled, structured data to train AI models. Droege said in the memo that Scale AI would staff up around its enterprise and government sales units.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Like other AI startups that have been reverse acqui-hired, such as Inflection, it seems that Scale AI now has to pivot from the business that put it on the map. In light of Meta’s investment, several of Scale AI’s largest data customers cut ties with the startup.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/16/scale-ai-lays-off-14-of-staff-largely-in-data-labeling-business/</guid><pubDate>Wed, 16 Jul 2025 19:26:47 +0000</pubDate></item><item><title>[NEW] India eyes global quantum computer push — and QpiAI is its chosen vehicle (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/16/india-eyes-global-quantum-computer-push-and-qpiai-is-its-chosen-vehicle/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;QpiAI, an Indian startup that claims to integrate AI and quantum computing for enterprise use cases, has raised $32 million in a new funding round co-led by the Indian government as the company aims to expand its presence and develop utility-scale quantum computers for markets around the world.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Indian government’s $750 million National Quantum Mission has co-led QpiAI’s all-equity Series A round, alongside Avataar Ventures, at a post-money valuation of $162 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The funding reflects India’s broader push to establish itself as a quantum computing power. Launched in 2023, the National Quantum Mission is an Indian government initiative that views quantum computing as both an economic opportunity and a national security imperative. The program aims to help develop intermediate-scale quantum computers with 50-1,000 physical qubits within eight years across platforms including superconducting and photonics. It also targets the development of satellite-based quantum communications, inter-city quantum distribution, multi-node quantum networks, magnetometers, and the design and synthesis of quantum materials, including superconductors, semiconductor structures, and topological materials for quantum device fabrication.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;QpiAI is one of eight startups selected by the National Quantum Mission, each receiving an initial grant of up to $3.5 million. Among these companies, the Bengaluru-headquartered startup, which has subsidiaries in the U.S. and Finland, says it has built India’s first full-stack quantum computer, called QpiAI-Indus, which it launched in April with 25 superconducting qubits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2019, QpiAI says it integrates quantum computing and AI to provide optimization capabilities in areas such as manufacturing, industrial, transportation, finance, pharma, and materials. The startup says it has developed specialized software, along with its proprietary hardware, to support real-world quantum applications in fields such as materials science and drug discovery.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Quantum can really make sure AI is robust,” said QpiAI founder and CEO Nagendra Nagaraja in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup views simulation, drug synthesis, and material discovery as some of the key use cases where the combination of AI and quantum could provide a competitive edge.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3028585" height="870" src="https://techcrunch.com/wp-content/uploads/2025/07/qpiai-full-stack-system.jpg" width="2590" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;QpiAI’s full-Stack system aims at industries such as life sciences, automotive, and finance&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;QpiAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Because the design space of a quantum chip is very, very big, and to actually get optimal qubits, which is important when we integrate thousands of qubits to get logical qubits for error correction, AI plays a bigger role there,” Nagaraja told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;QpiAI plans to launch its 64-qubit quantum computer in November, with availability to customers expected by the second or third quarter of next year, Nagaraja said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also working to start manufacturing its quantum hardware locally in 2026. Currently, it assembles 80% of its machines in-house.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;QpiAI employs a 100-person team, comprising 25 PhDs from international institutions or from Indian institutes. About 50 of its employees are based in India. The company says it has around 20 customers in India and the U.S., including the Indian government, which uses its infrastructure to test algorithms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to the company, QpiAI has been profitable at EBITDA level for the past three years, with approximately 60% gross margins and 20% to 30% net margins, Nagaraja told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the fresh funding, QpiAI plans to enter new markets including Singapore and the Middle East. It also aims to allocate funds for its local manufacturing plans and scale its operations to develop a 100-logical qubit system by 2030.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June of last year, QpiAI raised $6.5 million in a pre-Series A round led by YourNest and SVCL at a post-money valuation of around $30 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nagaraja told TechCrunch that QpiAI has a three- to four-year runway, even without accounting for its profitability. He also said the startup is considering an initial public offering in either 2026 or 2027.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The National Quantum Mission’s support extends beyond QpiAI. The Indian government’s program is also backing startups such as QNu Labs (working on quantum-safe networks), Dimira Technologies (cryogenic cables), PrenishQ (diode-laser systems), and QuPrayog (optical atomic clocks). It has also supported Quanastra (cryogenic systems and superconducting detectors), Pristine Diamonds (diamond-based sensing materials), and Quan2D Technologies (single-photon detectors for quantum communication).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We plan to continue to support home-grown product companies like QpiAI to help them expand into large enterprises and position India as global leaders in quantum technologies,” said Ajai Chowdhry, chairman of India’s National Quantum Mission, in a prepared statement.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;QpiAI, an Indian startup that claims to integrate AI and quantum computing for enterprise use cases, has raised $32 million in a new funding round co-led by the Indian government as the company aims to expand its presence and develop utility-scale quantum computers for markets around the world.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Indian government’s $750 million National Quantum Mission has co-led QpiAI’s all-equity Series A round, alongside Avataar Ventures, at a post-money valuation of $162 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The funding reflects India’s broader push to establish itself as a quantum computing power. Launched in 2023, the National Quantum Mission is an Indian government initiative that views quantum computing as both an economic opportunity and a national security imperative. The program aims to help develop intermediate-scale quantum computers with 50-1,000 physical qubits within eight years across platforms including superconducting and photonics. It also targets the development of satellite-based quantum communications, inter-city quantum distribution, multi-node quantum networks, magnetometers, and the design and synthesis of quantum materials, including superconductors, semiconductor structures, and topological materials for quantum device fabrication.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;QpiAI is one of eight startups selected by the National Quantum Mission, each receiving an initial grant of up to $3.5 million. Among these companies, the Bengaluru-headquartered startup, which has subsidiaries in the U.S. and Finland, says it has built India’s first full-stack quantum computer, called QpiAI-Indus, which it launched in April with 25 superconducting qubits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2019, QpiAI says it integrates quantum computing and AI to provide optimization capabilities in areas such as manufacturing, industrial, transportation, finance, pharma, and materials. The startup says it has developed specialized software, along with its proprietary hardware, to support real-world quantum applications in fields such as materials science and drug discovery.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Quantum can really make sure AI is robust,” said QpiAI founder and CEO Nagendra Nagaraja in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup views simulation, drug synthesis, and material discovery as some of the key use cases where the combination of AI and quantum could provide a competitive edge.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3028585" height="870" src="https://techcrunch.com/wp-content/uploads/2025/07/qpiai-full-stack-system.jpg" width="2590" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;QpiAI’s full-Stack system aims at industries such as life sciences, automotive, and finance&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;QpiAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Because the design space of a quantum chip is very, very big, and to actually get optimal qubits, which is important when we integrate thousands of qubits to get logical qubits for error correction, AI plays a bigger role there,” Nagaraja told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;QpiAI plans to launch its 64-qubit quantum computer in November, with availability to customers expected by the second or third quarter of next year, Nagaraja said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also working to start manufacturing its quantum hardware locally in 2026. Currently, it assembles 80% of its machines in-house.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;QpiAI employs a 100-person team, comprising 25 PhDs from international institutions or from Indian institutes. About 50 of its employees are based in India. The company says it has around 20 customers in India and the U.S., including the Indian government, which uses its infrastructure to test algorithms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to the company, QpiAI has been profitable at EBITDA level for the past three years, with approximately 60% gross margins and 20% to 30% net margins, Nagaraja told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the fresh funding, QpiAI plans to enter new markets including Singapore and the Middle East. It also aims to allocate funds for its local manufacturing plans and scale its operations to develop a 100-logical qubit system by 2030.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June of last year, QpiAI raised $6.5 million in a pre-Series A round led by YourNest and SVCL at a post-money valuation of around $30 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nagaraja told TechCrunch that QpiAI has a three- to four-year runway, even without accounting for its profitability. He also said the startup is considering an initial public offering in either 2026 or 2027.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The National Quantum Mission’s support extends beyond QpiAI. The Indian government’s program is also backing startups such as QNu Labs (working on quantum-safe networks), Dimira Technologies (cryogenic cables), PrenishQ (diode-laser systems), and QuPrayog (optical atomic clocks). It has also supported Quanastra (cryogenic systems and superconducting detectors), Pristine Diamonds (diamond-based sensing materials), and Quan2D Technologies (single-photon detectors for quantum communication).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We plan to continue to support home-grown product companies like QpiAI to help them expand into large enterprises and position India as global leaders in quantum technologies,” said Ajai Chowdhry, chairman of India’s National Quantum Mission, in a prepared statement.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/16/india-eyes-global-quantum-computer-push-and-qpiai-is-its-chosen-vehicle/</guid><pubDate>Wed, 16 Jul 2025 20:54:01 +0000</pubDate></item><item><title>[NEW] Can AI really code? Study maps the roadblocks to autonomous software engineering (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/can-ai-really-code-study-maps-roadblocks-to-autonomous-software-engineering-0716</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/mit-csail-%20AI-coding.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-3c70286d-7fff-a737-d9dc-ea0a5bb6f3af"&gt;Imagine a future where artificial intelligence quietly shoulders the drudgery of software development: refactoring tangled code, migrating legacy systems, and hunting down race conditions, so that human engineers can devote themselves to architecture, design, and the genuinely novel problems still beyond a machine’s reach. Recent advances appear to have nudged that future tantalizingly close, but a new paper by researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and several collaborating institutions argues that this potential future reality demands a hard look at present-day challenges.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Titled “Challenges and Paths Towards AI for Software Engineering,” the work maps the many software-engineering tasks beyond code generation, identifies current bottlenecks, and highlights research directions to overcome them, aiming to let humans focus on high-level design while routine work is automated.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“Everyone is talking about how we don’t need programmers anymore, and there’s all this automation now available,” says Armando Solar‑Lezama, MIT professor of electrical engineering and computer science, CSAIL principal investigator, and senior author of the study. “On the one hand, the field has made tremendous progress. We have tools that are way more powerful than any we’ve seen before. But there’s also a long way to go toward really getting the full promise of automation that we would expect.”&lt;/p&gt;&lt;p dir="ltr"&gt;Solar-Lezama argues that popular narratives often shrink software engineering to “the undergrad programming part: someone hands you a spec for a little function and you implement it, or solving LeetCode-style programming interviews.” Real practice is far broader. It includes everyday refactors that polish design, plus sweeping migrations that move millions of lines from COBOL to Java and reshape entire businesses. It requires nonstop testing and analysis — fuzzing, property-based testing, and other methods — to catch concurrency bugs, or patch zero-day flaws. And it involves the maintenance grind: documenting decade-old code, summarizing change histories for new teammates, and reviewing pull requests for style, performance, and security.&lt;/p&gt;&lt;p dir="ltr"&gt;Industry-scale code optimization — think re-tuning GPU kernels or the relentless, multi-layered refinements behind Chrome’s V8 engine — remains stubbornly hard to evaluate. Today’s headline metrics were designed for short, self-contained problems, and while multiple-choice tests still dominate natural-language research, they were never the norm in AI-for-code. The field’s de facto yardstick, SWE-Bench, simply asks a model to patch a GitHub issue: useful, but still akin to the “undergrad programming exercise” paradigm. It touches only a few hundred lines of code, risks data leakage from public repositories, and ignores other real-world contexts — AI-assisted refactors, human–AI pair programming, or performance-critical rewrites that span millions of lines. Until benchmarks expand to capture those higher-stakes scenarios, measuring progress — and thus accelerating it — will remain an open challenge.&lt;/p&gt;&lt;p dir="ltr"&gt;If measurement is one obstacle, human‑machine communication is another. First author Alex  Gu, an MIT graduate student in electrical engineering and computer science, sees today’s interaction as “a thin line of communication.” When he asks a system to generate code, he often receives a large, unstructured file and even a set of unit tests, yet those tests tend to be superficial. This gap extends to the AI’s ability to effectively use the wider suite of software engineering tools, from debuggers to static analyzers, that humans rely on for precise control and deeper understanding. “I don’t really have much control over what the model writes,” he says. “Without a channel for the AI to expose its own confidence — ‘this part’s correct … this part, maybe double‑check’ — developers risk blindly trusting hallucinated logic that compiles, but collapses in production. Another critical aspect is having the AI know when to defer to the user for clarification.”&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Scale compounds these difficulties. Current AI models struggle profoundly with large code bases, often spanning millions of lines. Foundation models learn from public GitHub, but “every company’s code base is kind of different and unique,” Gu says, making proprietary coding conventions and specification requirements fundamentally out of distribution. The result is code that looks plausible yet calls non‑existent functions, violates internal style rules, or fails continuous‑integration pipelines. This often leads to AI-generated code that “hallucinates,” meaning it creates content that looks plausible but doesn’t align with the specific internal conventions, helper functions, or architectural patterns of a given company.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Models will also often retrieve incorrectly, because it retrieves code with a similar name (syntax) rather than functionality and logic, which is what a model might need to know how to write the function. “Standard retrieval techniques are very easily fooled by pieces of code that are doing the same thing but look different,” says Solar‑Lezama.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The authors mention that since there is no silver bullet to these issues, they’re calling instead for community‑scale efforts: richer, having data that captures the process of developers writing code (for example, which code developers keep versus throw away, how code gets refactored over time, etc.), shared evaluation suites that measure progress on refactor quality, bug‑fix longevity, and migration correctness; and transparent tooling that lets models expose uncertainty and invite human steering rather than passive acceptance. Gu frames the agenda as a “call to action” for larger open‑source collaborations that no single lab could muster alone. Solar‑Lezama imagines incremental advances—“research results taking bites out of each one of these challenges separately”—that feed back into commercial tools and gradually move AI from autocomplete sidekick toward genuine engineering partner.&lt;/p&gt;&lt;p dir="ltr"&gt;“Why does any of this matter? Software already underpins finance, transportation, health care, and the minutiae of daily life, and the human effort required to build and maintain it safely is becoming a bottleneck. An AI that can shoulder the grunt work — and do so without introducing hidden failures — would free developers to focus on creativity, strategy, and ethics” says Gu. “But that future depends on acknowledging that code completion is the easy part; the hard part is everything else. Our goal isn’t to replace programmers. It’s to amplify them. When AI can tackle the tedious and the terrifying, human engineers can finally spend their time on what only humans can do.”&lt;/p&gt;&lt;p dir="ltr"&gt;“With so many new works emerging in AI for coding, and the community often chasing the latest trends, it can be hard to step back and reflect on which problems are most important to tackle,” says Baptiste Rozière, an AI scientist at Mistral AI, who wasn’t involved in the paper. “I enjoyed reading this paper because it offers a clear overview of the key tasks and challenges in AI for software engineering. It also outlines promising directions for future research in the field.”&lt;/p&gt;&lt;p dir="ltr"&gt;Gu and Solar-Lezama wrote the paper with University of California at Berkeley Professor Koushik Sen and PhD students Naman Jain and Manish Shetty, Cornell University Assistant Professor Kevin Ellis and PhD student Wen-Ding Li, Stanford University Assistant Professor Diyi Yang and PhD student Yijia Shao, and incoming Johns Hopkins University assistant professor Ziyang Li. Their work was supported, in part, by the National Science Foundation (NSF), SKY Lab industrial sponsors and affiliates, Intel Corp. through an NSF grant, and the Office of Naval Research.&lt;/p&gt;&lt;p&gt;The researchers are presenting their work at the International Conference on Machine Learning (ICML).&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/mit-csail-%20AI-coding.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-3c70286d-7fff-a737-d9dc-ea0a5bb6f3af"&gt;Imagine a future where artificial intelligence quietly shoulders the drudgery of software development: refactoring tangled code, migrating legacy systems, and hunting down race conditions, so that human engineers can devote themselves to architecture, design, and the genuinely novel problems still beyond a machine’s reach. Recent advances appear to have nudged that future tantalizingly close, but a new paper by researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and several collaborating institutions argues that this potential future reality demands a hard look at present-day challenges.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Titled “Challenges and Paths Towards AI for Software Engineering,” the work maps the many software-engineering tasks beyond code generation, identifies current bottlenecks, and highlights research directions to overcome them, aiming to let humans focus on high-level design while routine work is automated.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“Everyone is talking about how we don’t need programmers anymore, and there’s all this automation now available,” says Armando Solar‑Lezama, MIT professor of electrical engineering and computer science, CSAIL principal investigator, and senior author of the study. “On the one hand, the field has made tremendous progress. We have tools that are way more powerful than any we’ve seen before. But there’s also a long way to go toward really getting the full promise of automation that we would expect.”&lt;/p&gt;&lt;p dir="ltr"&gt;Solar-Lezama argues that popular narratives often shrink software engineering to “the undergrad programming part: someone hands you a spec for a little function and you implement it, or solving LeetCode-style programming interviews.” Real practice is far broader. It includes everyday refactors that polish design, plus sweeping migrations that move millions of lines from COBOL to Java and reshape entire businesses. It requires nonstop testing and analysis — fuzzing, property-based testing, and other methods — to catch concurrency bugs, or patch zero-day flaws. And it involves the maintenance grind: documenting decade-old code, summarizing change histories for new teammates, and reviewing pull requests for style, performance, and security.&lt;/p&gt;&lt;p dir="ltr"&gt;Industry-scale code optimization — think re-tuning GPU kernels or the relentless, multi-layered refinements behind Chrome’s V8 engine — remains stubbornly hard to evaluate. Today’s headline metrics were designed for short, self-contained problems, and while multiple-choice tests still dominate natural-language research, they were never the norm in AI-for-code. The field’s de facto yardstick, SWE-Bench, simply asks a model to patch a GitHub issue: useful, but still akin to the “undergrad programming exercise” paradigm. It touches only a few hundred lines of code, risks data leakage from public repositories, and ignores other real-world contexts — AI-assisted refactors, human–AI pair programming, or performance-critical rewrites that span millions of lines. Until benchmarks expand to capture those higher-stakes scenarios, measuring progress — and thus accelerating it — will remain an open challenge.&lt;/p&gt;&lt;p dir="ltr"&gt;If measurement is one obstacle, human‑machine communication is another. First author Alex  Gu, an MIT graduate student in electrical engineering and computer science, sees today’s interaction as “a thin line of communication.” When he asks a system to generate code, he often receives a large, unstructured file and even a set of unit tests, yet those tests tend to be superficial. This gap extends to the AI’s ability to effectively use the wider suite of software engineering tools, from debuggers to static analyzers, that humans rely on for precise control and deeper understanding. “I don’t really have much control over what the model writes,” he says. “Without a channel for the AI to expose its own confidence — ‘this part’s correct … this part, maybe double‑check’ — developers risk blindly trusting hallucinated logic that compiles, but collapses in production. Another critical aspect is having the AI know when to defer to the user for clarification.”&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Scale compounds these difficulties. Current AI models struggle profoundly with large code bases, often spanning millions of lines. Foundation models learn from public GitHub, but “every company’s code base is kind of different and unique,” Gu says, making proprietary coding conventions and specification requirements fundamentally out of distribution. The result is code that looks plausible yet calls non‑existent functions, violates internal style rules, or fails continuous‑integration pipelines. This often leads to AI-generated code that “hallucinates,” meaning it creates content that looks plausible but doesn’t align with the specific internal conventions, helper functions, or architectural patterns of a given company.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Models will also often retrieve incorrectly, because it retrieves code with a similar name (syntax) rather than functionality and logic, which is what a model might need to know how to write the function. “Standard retrieval techniques are very easily fooled by pieces of code that are doing the same thing but look different,” says Solar‑Lezama.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The authors mention that since there is no silver bullet to these issues, they’re calling instead for community‑scale efforts: richer, having data that captures the process of developers writing code (for example, which code developers keep versus throw away, how code gets refactored over time, etc.), shared evaluation suites that measure progress on refactor quality, bug‑fix longevity, and migration correctness; and transparent tooling that lets models expose uncertainty and invite human steering rather than passive acceptance. Gu frames the agenda as a “call to action” for larger open‑source collaborations that no single lab could muster alone. Solar‑Lezama imagines incremental advances—“research results taking bites out of each one of these challenges separately”—that feed back into commercial tools and gradually move AI from autocomplete sidekick toward genuine engineering partner.&lt;/p&gt;&lt;p dir="ltr"&gt;“Why does any of this matter? Software already underpins finance, transportation, health care, and the minutiae of daily life, and the human effort required to build and maintain it safely is becoming a bottleneck. An AI that can shoulder the grunt work — and do so without introducing hidden failures — would free developers to focus on creativity, strategy, and ethics” says Gu. “But that future depends on acknowledging that code completion is the easy part; the hard part is everything else. Our goal isn’t to replace programmers. It’s to amplify them. When AI can tackle the tedious and the terrifying, human engineers can finally spend their time on what only humans can do.”&lt;/p&gt;&lt;p dir="ltr"&gt;“With so many new works emerging in AI for coding, and the community often chasing the latest trends, it can be hard to step back and reflect on which problems are most important to tackle,” says Baptiste Rozière, an AI scientist at Mistral AI, who wasn’t involved in the paper. “I enjoyed reading this paper because it offers a clear overview of the key tasks and challenges in AI for software engineering. It also outlines promising directions for future research in the field.”&lt;/p&gt;&lt;p dir="ltr"&gt;Gu and Solar-Lezama wrote the paper with University of California at Berkeley Professor Koushik Sen and PhD students Naman Jain and Manish Shetty, Cornell University Assistant Professor Kevin Ellis and PhD student Wen-Ding Li, Stanford University Assistant Professor Diyi Yang and PhD student Yijia Shao, and incoming Johns Hopkins University assistant professor Ziyang Li. Their work was supported, in part, by the National Science Foundation (NSF), SKY Lab industrial sponsors and affiliates, Intel Corp. through an NSF grant, and the Office of Naval Research.&lt;/p&gt;&lt;p&gt;The researchers are presenting their work at the International Conference on Machine Learning (ICML).&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/can-ai-really-code-study-maps-roadblocks-to-autonomous-software-engineering-0716</guid><pubDate>Wed, 16 Jul 2025 20:55:00 +0000</pubDate></item><item><title>[NEW] Researchers announce babies born from a trial of three-person IVF (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/16/1120285/babies-born-trial-of-three-person-ivf/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/GettyImages-172594620_1.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Eight babies have been born in the UK thanks to a technology that uses DNA from three people: the two biological parents plus a third person who supplies healthy mitochondrial DNA. The babies were born to mothers who carry genes for mitochondrial diseases and risked passing on severe disorders. The eight babies are healthy, say the researchers behind the trial.&lt;/p&gt;  &lt;p&gt;“Mitochondrial disease can have a devastating impact on families,” Doug Turnbull of Newcastle University, one of the researchers behind the study, said in a statement. “Today’s news offers fresh hope to many more women at risk of passing on this condition, who now have the chance to have children growing up without this terrible disease.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;The study, which makes use of a technology called mitochondrial donation, has been described as a “tour de force” and “a remarkable accomplishment” by others in the field. In the team’s approach, patients’ eggs are fertilized with sperm, and the DNA-containing nuclei of those cells are transferred into donated fertilized eggs that have had their own nuclei removed. The new embryos contain the DNA of the intended parents along with a tiny fraction of mitochondrial DNA from the donor, floating in the embryos’ cytoplasm.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“The concept of [mitochondrial donation] has attracted much commentary and occasionally concern and anxiety,” Stuart Lavery, a consultant in reproductive medicine at University College Hospitals NHS Foundation Trust, said in a statement. “The Newcastle team have demonstrated that it can be used in a clinically effective and ethically acceptable way to prevent disease and suffering.”&lt;/p&gt; 
 &lt;p&gt;Not everyone sees the trial as a resounding success. While five of the children were born “with no health problems,” one developed a fever and a urinary tract infection, and another had muscle jerks. A third was treated for an abnormal heart rhythm. Three of the babies were born with a low level of the very mitochondrial-DNA mutations the treatment was designed to prevent.&lt;/p&gt;  &lt;p&gt;Heidi Mertes, a medical ethicist at Ghent University, says she is “moderately optimistic.” “I’m happy that it worked,” she says. “But at the same time, it’s concerning … it’s a call for caution and treading carefully.”&lt;/p&gt; 
 &lt;p&gt;Pavlo Mazur, a former embryologist who has used a similar approach in the conception of 15 babies in Ukraine, believes that trials like this one should be paused until researchers figure out what’s going on. Others believe that researchers should study the technique in people who don’t have mitochondrial mutations, to lower the risk of passing any disease-causing mutations to children.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Long time coming&lt;/h3&gt;  &lt;p&gt;The news of the births has been long awaited by researchers in the field. Mitochondrial donation was first made legal in the UK in 2015. Two years later, the Human Fertility and Embryology Authority (HFEA), which regulates fertility treatment and research in the UK, granted a fertility clinic in Newcastle the sole license to perform the procedure. Newcastle Fertility Centre at Life launched a trial of mitochondrial donation in 2017 with the aim of treating 25 women a year.&lt;/p&gt;  &lt;p&gt;That was eight years ago. Since then, the Newcastle team have been extremely tight-lipped about the trial. That’s despite the fact that other teams elsewhere have used mitochondrial donation to help people achieve pregnancy. A New York–based doctor used a type of mitochondrial donation to help a Jordanian couple conceive in Mexico in 2016. Mitochondrial donation has also been trialed by teams in Ukraine and Greece.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;But as the only trial overseen by the HFEA, the Newcastle team’s study was viewed by many as the most “official.” Researchers have been itching to hear how the work has been going, given the potential implications for researchers elsewhere (mitochondrial donation was officially made legal in Australia in 2022). “I’m very glad to see [the results] come out at last,” says Dagan Wells, a reproductive biologist at the University of Oxford who worked on the Greece trial. “It would have been nice to have some information out along the way.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;At the Newcastle clinic, each patient must receive approval from the HFEA to be eligible for mitochondrial donation. Since the trial launched in 2017, 39 patients have won this approval. Twenty-five of them underwent hormonal stimulation to release multiple eggs that could be frozen in storage.&lt;/p&gt;  &lt;p&gt;Nineteen of those women went on to have mitochondrial donation. So far, seven of the women have given birth (one had twins), and an eighth is still pregnant. The oldest baby is two years old. The results were published today in the &lt;em&gt;New England Journal of Medicine&lt;/em&gt;.&lt;/p&gt;  &lt;p&gt;“As parents, all we ever wanted was to give our child a healthy start in life,” one of the mothers, who is remaining anonymous, said in a statement. “Mitochondrial donation IVF made that possible. After years of uncertainty this treatment gave us hope—and then it gave us our baby … Science gave us a chance.”&lt;/p&gt;  &lt;p&gt;When each baby was born, the team collected a blood and urine sample to look at the child’s mitochondrial DNA. They found that the levels of mutated DNA were far lower than they would have expected without mitochondrial donation. Three of the mothers were “homoplasmic”—100% of their mitochondrial DNA carried the mutation. But blood tests showed that in the women’s four babies (including the twins), 5% or less of the mitochondrial DNA had the mutation, suggesting they won’t develop disease.&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;A mixed result&lt;/h3&gt;  &lt;p&gt;The researchers see this as a positive result. “Children who would otherwise have inherited very high levels are now inheriting levels that are reduced by 77% to 100%,” coauthor Mary Herbert, a professor of reproductive biology at Newcastle University and Monash University, told me during a press briefing.&lt;/p&gt;  &lt;p&gt;But three of the eight babies had health symptoms. At seven months, one was diagnosed with a rare form of epilepsy, which seemed to resolve within the following three months. Another baby developed a urinary tract infection.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;A third baby developed “prolonged” jaundice, high levels of fat in the blood, and a disturbed heart rhythm that required treatment. The baby seemed to have recovered by 18 months, and doctors believe that the symptoms were not related to the mitochondrial mutations, but the team members admit that they can’t be sure. Given the small sample size, it’s hard to make comparisons with babies conceived in other ways.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And they acknowledge that a phenomenon called “reversal” is happening in some of the babies. In theory, the children shouldn’t inherit any “bad” mitochondrial DNA from their mothers. But three of them did. The levels of “bad” mitochondrial DNA in the babies’ blood ranged between 5% and 16%. And they were higher in the babies’ urine—the highest figure being 20%.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;The researchers don’t know why this is happening. When an embryologist pulls out the nucleus of a fertilized egg, a bit of mitochondria-containing cytoplasm will inevitably be dragged along with it. But the team didn’t see any link between the amount of carried-over cytoplasm and the level of “bad” mitochondria. “We continue to investigate this issue,” Herbert said.&lt;/p&gt;  &lt;p&gt;“As long as they don’t understand what’s happening, I would still be worried,” says Mertes.&lt;/p&gt;  &lt;p&gt;Such low levels aren’t likely to cause mitochondrial diseases, according to experts contacted by &lt;em&gt;MIT Technology Review&lt;/em&gt;. But some are concerned that the percentage of mutated DNA could be higher in different tissues, such as the brain or muscle, or that the levels might change with age. “You never know which tissues [reversal] will show up in,” says Mazur, who has seen the phenomenon in babies born through mitochondrial donation to parents who didn’t have mitochondrial mutations. “It’s chaotic.”&lt;/p&gt;  &lt;p&gt;The Newcastle team says it hasn’t looked at other tissues, because it designed the study to be noninvasive.&lt;/p&gt; 
 &lt;p&gt;There has been at least one case in which similar levels of “bad” mitochondria have caused symptoms, says Joanna Poulton, a mitochondrial geneticist at the University of Oxford. She thinks it’s unlikely that the children in the trial will develop any symptoms but adds that “it’s a bit of a worry.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;The age of reversal&lt;/h3&gt;  &lt;p&gt;No one knows exactly when this reversal happens. But Wells and his colleagues have some idea. In their study in Greece, they looked at the mitochondrial DNA of embryos and checked them again during pregnancy and after birth. The trial was designed to study the impact of mitochondrial donation for infertility—none of the parents involved had genes for mitochondrial disease.&lt;/p&gt; 
 &lt;p&gt;The team has seen mitochondrial reversal in two of the seven babies born in the trial, says Wells. If you put the two sets of results together, mitochondrial donation “seems to have this possibility of reversal occurring in maybe about a third of children,” he says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;In his study, the reversal seemed to occur early on in the embryos’ development, Wells says. Five-day-old embryos “look perfect,” but mitochondrial mutations start showing up in tests taken at around 15 weeks of pregnancy, he says. After that point, the levels appear to be relatively stable. The Newcastle researchers say they will monitor the children until they are five years old.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt;&lt;p&gt;People enrolling in future trials might opt for amniocentesis, which involves sampling blood from the fetus’s amniotic sac at around 15 to 18 weeks, suggests Mertes. That test might reveal the likely level of mitochondrial mutations in the resulting child. “Then the parents could decide what to do,” says Mertes. “If you could see there was a 90% mutation load [for a] very serious mitochondrial disease, they would still have an option to cancel the pregnancy,” she says.&lt;/p&gt;  &lt;p&gt;Wells thinks the Newcastle team’s results are “generally reassuring.” He doesn’t think the trials should be paused. But he wants people to understand that mitochondrial donation is not without risk. “This can only be viewed as a risk reduction strategy, and not a guarantee of having an unaffected child,” he says.&lt;/p&gt;  &lt;p&gt;And, as Mertes points out, there’s another option for women who carry mitochondrial DNA mutations: egg donation. Donor eggs fertilized with a partner’s sperm and transferred to a woman’s uterus won’t have her disease-causing mitochondria.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That option won’t appeal to people who feel strongly about having a genetic link to their children. But Poulton asks: “If you know whose uterus you came out of, does it matter that the [egg] came from somewhere else?”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/GettyImages-172594620_1.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Eight babies have been born in the UK thanks to a technology that uses DNA from three people: the two biological parents plus a third person who supplies healthy mitochondrial DNA. The babies were born to mothers who carry genes for mitochondrial diseases and risked passing on severe disorders. The eight babies are healthy, say the researchers behind the trial.&lt;/p&gt;  &lt;p&gt;“Mitochondrial disease can have a devastating impact on families,” Doug Turnbull of Newcastle University, one of the researchers behind the study, said in a statement. “Today’s news offers fresh hope to many more women at risk of passing on this condition, who now have the chance to have children growing up without this terrible disease.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;The study, which makes use of a technology called mitochondrial donation, has been described as a “tour de force” and “a remarkable accomplishment” by others in the field. In the team’s approach, patients’ eggs are fertilized with sperm, and the DNA-containing nuclei of those cells are transferred into donated fertilized eggs that have had their own nuclei removed. The new embryos contain the DNA of the intended parents along with a tiny fraction of mitochondrial DNA from the donor, floating in the embryos’ cytoplasm.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“The concept of [mitochondrial donation] has attracted much commentary and occasionally concern and anxiety,” Stuart Lavery, a consultant in reproductive medicine at University College Hospitals NHS Foundation Trust, said in a statement. “The Newcastle team have demonstrated that it can be used in a clinically effective and ethically acceptable way to prevent disease and suffering.”&lt;/p&gt; 
 &lt;p&gt;Not everyone sees the trial as a resounding success. While five of the children were born “with no health problems,” one developed a fever and a urinary tract infection, and another had muscle jerks. A third was treated for an abnormal heart rhythm. Three of the babies were born with a low level of the very mitochondrial-DNA mutations the treatment was designed to prevent.&lt;/p&gt;  &lt;p&gt;Heidi Mertes, a medical ethicist at Ghent University, says she is “moderately optimistic.” “I’m happy that it worked,” she says. “But at the same time, it’s concerning … it’s a call for caution and treading carefully.”&lt;/p&gt; 
 &lt;p&gt;Pavlo Mazur, a former embryologist who has used a similar approach in the conception of 15 babies in Ukraine, believes that trials like this one should be paused until researchers figure out what’s going on. Others believe that researchers should study the technique in people who don’t have mitochondrial mutations, to lower the risk of passing any disease-causing mutations to children.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Long time coming&lt;/h3&gt;  &lt;p&gt;The news of the births has been long awaited by researchers in the field. Mitochondrial donation was first made legal in the UK in 2015. Two years later, the Human Fertility and Embryology Authority (HFEA), which regulates fertility treatment and research in the UK, granted a fertility clinic in Newcastle the sole license to perform the procedure. Newcastle Fertility Centre at Life launched a trial of mitochondrial donation in 2017 with the aim of treating 25 women a year.&lt;/p&gt;  &lt;p&gt;That was eight years ago. Since then, the Newcastle team have been extremely tight-lipped about the trial. That’s despite the fact that other teams elsewhere have used mitochondrial donation to help people achieve pregnancy. A New York–based doctor used a type of mitochondrial donation to help a Jordanian couple conceive in Mexico in 2016. Mitochondrial donation has also been trialed by teams in Ukraine and Greece.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;But as the only trial overseen by the HFEA, the Newcastle team’s study was viewed by many as the most “official.” Researchers have been itching to hear how the work has been going, given the potential implications for researchers elsewhere (mitochondrial donation was officially made legal in Australia in 2022). “I’m very glad to see [the results] come out at last,” says Dagan Wells, a reproductive biologist at the University of Oxford who worked on the Greece trial. “It would have been nice to have some information out along the way.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;At the Newcastle clinic, each patient must receive approval from the HFEA to be eligible for mitochondrial donation. Since the trial launched in 2017, 39 patients have won this approval. Twenty-five of them underwent hormonal stimulation to release multiple eggs that could be frozen in storage.&lt;/p&gt;  &lt;p&gt;Nineteen of those women went on to have mitochondrial donation. So far, seven of the women have given birth (one had twins), and an eighth is still pregnant. The oldest baby is two years old. The results were published today in the &lt;em&gt;New England Journal of Medicine&lt;/em&gt;.&lt;/p&gt;  &lt;p&gt;“As parents, all we ever wanted was to give our child a healthy start in life,” one of the mothers, who is remaining anonymous, said in a statement. “Mitochondrial donation IVF made that possible. After years of uncertainty this treatment gave us hope—and then it gave us our baby … Science gave us a chance.”&lt;/p&gt;  &lt;p&gt;When each baby was born, the team collected a blood and urine sample to look at the child’s mitochondrial DNA. They found that the levels of mutated DNA were far lower than they would have expected without mitochondrial donation. Three of the mothers were “homoplasmic”—100% of their mitochondrial DNA carried the mutation. But blood tests showed that in the women’s four babies (including the twins), 5% or less of the mitochondrial DNA had the mutation, suggesting they won’t develop disease.&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;A mixed result&lt;/h3&gt;  &lt;p&gt;The researchers see this as a positive result. “Children who would otherwise have inherited very high levels are now inheriting levels that are reduced by 77% to 100%,” coauthor Mary Herbert, a professor of reproductive biology at Newcastle University and Monash University, told me during a press briefing.&lt;/p&gt;  &lt;p&gt;But three of the eight babies had health symptoms. At seven months, one was diagnosed with a rare form of epilepsy, which seemed to resolve within the following three months. Another baby developed a urinary tract infection.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;A third baby developed “prolonged” jaundice, high levels of fat in the blood, and a disturbed heart rhythm that required treatment. The baby seemed to have recovered by 18 months, and doctors believe that the symptoms were not related to the mitochondrial mutations, but the team members admit that they can’t be sure. Given the small sample size, it’s hard to make comparisons with babies conceived in other ways.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And they acknowledge that a phenomenon called “reversal” is happening in some of the babies. In theory, the children shouldn’t inherit any “bad” mitochondrial DNA from their mothers. But three of them did. The levels of “bad” mitochondrial DNA in the babies’ blood ranged between 5% and 16%. And they were higher in the babies’ urine—the highest figure being 20%.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;The researchers don’t know why this is happening. When an embryologist pulls out the nucleus of a fertilized egg, a bit of mitochondria-containing cytoplasm will inevitably be dragged along with it. But the team didn’t see any link between the amount of carried-over cytoplasm and the level of “bad” mitochondria. “We continue to investigate this issue,” Herbert said.&lt;/p&gt;  &lt;p&gt;“As long as they don’t understand what’s happening, I would still be worried,” says Mertes.&lt;/p&gt;  &lt;p&gt;Such low levels aren’t likely to cause mitochondrial diseases, according to experts contacted by &lt;em&gt;MIT Technology Review&lt;/em&gt;. But some are concerned that the percentage of mutated DNA could be higher in different tissues, such as the brain or muscle, or that the levels might change with age. “You never know which tissues [reversal] will show up in,” says Mazur, who has seen the phenomenon in babies born through mitochondrial donation to parents who didn’t have mitochondrial mutations. “It’s chaotic.”&lt;/p&gt;  &lt;p&gt;The Newcastle team says it hasn’t looked at other tissues, because it designed the study to be noninvasive.&lt;/p&gt; 
 &lt;p&gt;There has been at least one case in which similar levels of “bad” mitochondria have caused symptoms, says Joanna Poulton, a mitochondrial geneticist at the University of Oxford. She thinks it’s unlikely that the children in the trial will develop any symptoms but adds that “it’s a bit of a worry.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;The age of reversal&lt;/h3&gt;  &lt;p&gt;No one knows exactly when this reversal happens. But Wells and his colleagues have some idea. In their study in Greece, they looked at the mitochondrial DNA of embryos and checked them again during pregnancy and after birth. The trial was designed to study the impact of mitochondrial donation for infertility—none of the parents involved had genes for mitochondrial disease.&lt;/p&gt; 
 &lt;p&gt;The team has seen mitochondrial reversal in two of the seven babies born in the trial, says Wells. If you put the two sets of results together, mitochondrial donation “seems to have this possibility of reversal occurring in maybe about a third of children,” he says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;In his study, the reversal seemed to occur early on in the embryos’ development, Wells says. Five-day-old embryos “look perfect,” but mitochondrial mutations start showing up in tests taken at around 15 weeks of pregnancy, he says. After that point, the levels appear to be relatively stable. The Newcastle researchers say they will monitor the children until they are five years old.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt;&lt;p&gt;People enrolling in future trials might opt for amniocentesis, which involves sampling blood from the fetus’s amniotic sac at around 15 to 18 weeks, suggests Mertes. That test might reveal the likely level of mitochondrial mutations in the resulting child. “Then the parents could decide what to do,” says Mertes. “If you could see there was a 90% mutation load [for a] very serious mitochondrial disease, they would still have an option to cancel the pregnancy,” she says.&lt;/p&gt;  &lt;p&gt;Wells thinks the Newcastle team’s results are “generally reassuring.” He doesn’t think the trials should be paused. But he wants people to understand that mitochondrial donation is not without risk. “This can only be viewed as a risk reduction strategy, and not a guarantee of having an unaffected child,” he says.&lt;/p&gt;  &lt;p&gt;And, as Mertes points out, there’s another option for women who carry mitochondrial DNA mutations: egg donation. Donor eggs fertilized with a partner’s sperm and transferred to a woman’s uterus won’t have her disease-causing mitochondria.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That option won’t appeal to people who feel strongly about having a genetic link to their children. But Poulton asks: “If you know whose uterus you came out of, does it matter that the [egg] came from somewhere else?”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/16/1120285/babies-born-trial-of-three-person-ivf/</guid><pubDate>Wed, 16 Jul 2025 21:00:00 +0000</pubDate></item></channel></rss>