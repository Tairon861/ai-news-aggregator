<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 13 Nov 2025 06:34:16 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>Court rules that OpenAI violated German copyright law; orders it to pay damages (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/12/court-rules-that-openai-violated-german-copyright-law-ordered-it-to-pay-damages/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2213399157.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A German court ruled that&amp;nbsp;OpenAI’s&amp;nbsp;ChatGPT violated&amp;nbsp;the nation’s&amp;nbsp;copyright laws by training its language models on licensed musical works&amp;nbsp;without&amp;nbsp;permission, multiple news outlets, including&amp;nbsp;The Guardian, reported.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ruling stemmed from a lawsuit that GEMA, a German collective that manages music rights in Germany, filed last November against OpenAI.&amp;nbsp;The company&amp;nbsp;was ordered to pay an undisclosed amount in damages to GEMA but&amp;nbsp;said it disagreed with the ruling and was “considering next steps.”&amp;nbsp;GEMA, meanwhile, regarded this as the “first landmark AI ruling in Europe.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Today, we have set a precedent that protects and clarifies the rights of authors: even operators of AI tools such as ChatGPT must comply with copyright law,” GEMA chief executive Tobias Holzmüller said, as The Guardian reported. “Today, we have successfully defended the livelihoods of music creators.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is being sued by other creatives and media groups over the same issue.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2213399157.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A German court ruled that&amp;nbsp;OpenAI’s&amp;nbsp;ChatGPT violated&amp;nbsp;the nation’s&amp;nbsp;copyright laws by training its language models on licensed musical works&amp;nbsp;without&amp;nbsp;permission, multiple news outlets, including&amp;nbsp;The Guardian, reported.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ruling stemmed from a lawsuit that GEMA, a German collective that manages music rights in Germany, filed last November against OpenAI.&amp;nbsp;The company&amp;nbsp;was ordered to pay an undisclosed amount in damages to GEMA but&amp;nbsp;said it disagreed with the ruling and was “considering next steps.”&amp;nbsp;GEMA, meanwhile, regarded this as the “first landmark AI ruling in Europe.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Today, we have set a precedent that protects and clarifies the rights of authors: even operators of AI tools such as ChatGPT must comply with copyright law,” GEMA chief executive Tobias Holzmüller said, as The Guardian reported. “Today, we have successfully defended the livelihoods of music creators.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is being sued by other creatives and media groups over the same issue.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/12/court-rules-that-openai-violated-german-copyright-law-ordered-it-to-pay-damages/</guid><pubDate>Wed, 12 Nov 2025 19:18:59 +0000</pubDate></item><item><title>Weibo's new open source AI model VibeThinker-1.5B outperforms DeepSeek-R1 on $7,800 post-training budget (AI | VentureBeat)</title><link>https://venturebeat.com/ai/weibos-new-open-source-ai-model-vibethinker-1-5b-outperforms-deepseek-r1-on</link><description>[unable to retrieve full-text content]&lt;p&gt;Another day in late 2025, another impressive result from a Chinese company in open source artificial intelligence.&lt;/p&gt;&lt;p&gt;Chinese social networking company &lt;a href="https://huggingface.co/WeiboAI/VibeThinker-1.5B"&gt;Weibo&amp;#x27;s AI division recently released its open source VibeThinker-1.5B&lt;/a&gt;—a 1.5 billion parameter large language model (LLM) that is a fine-tuned variant of rival Chinese tech firm &lt;a href="https://huggingface.co/Qwen/Qwen2.5-Math-1.5B"&gt;Alibaba&amp;#x27;s Qwen2.5-Math-1.5B. &lt;/a&gt;&lt;/p&gt;&lt;p&gt;It&amp;#x27;s available now for free download and usage by researchers and enterprise developers—even for commercial purposes—under a permissive MIT License on &lt;a href="https://huggingface.co/WeiboAI/VibeThinker-1.5B"&gt;Hugging Face&lt;/a&gt;, &lt;a href="https://github.com/WeiboAI/VibeThinker"&gt;GitHub&lt;/a&gt; and &lt;a href="https://modelscope.cn/models/WeiboAI/VibeThinker-1.5B"&gt;ModelScope&lt;/a&gt;, with a &lt;a href="https://arxiv.org/pdf/2511.06221"&gt;technical report&lt;/a&gt; on open access science publishing site arxiv.org.&lt;/p&gt;&lt;p&gt;And yet, despite its compact size, VibeThinker-1.5B achieves benchmark-topping reasoning performance on math and code tasks, rivaling or surpassing models hundreds of times its size, even outperforming Chinese rival DeepSeek&amp;#x27;s famed R1 that went viral at the start of this year—a 671-billion parameter model—on formal reasoning benchmark.&lt;/p&gt;&lt;p&gt;It further eclipses Mistral AI&amp;#x27;s Magistral Medium and holds its own against Anthropic&amp;#x27;s Claude Opus 4 and OpenAI&amp;#x27;s gpt-oss-20B Medium, all while requiring a fraction of the infrastructure and investment.&lt;/p&gt;&lt;p&gt;It also does so having been post-trained on a budget of merely $7800 USD for compute resources (3900 GPU hours on Nvidia H800s) — far less than the tens, or even hundreds, of thousands of dollars typically required to fine-tune models of similar or larger scale.&lt;/p&gt;&lt;p&gt;Recall this is not the total cost of the model&amp;#x27;s development, however: LLMs are trained in stages. First comes pre-training, when the model learns basic language structure and general knowledge by predicting the next word across enormous amounts of text from the internet, books, and articles. This gives it fluency but not much sense of how to follow instructions or hold a conversation&lt;/p&gt;&lt;p&gt;Post-training comes next, using much smaller, higher-quality datasets—typically collections of example questions, prompts, and expert-written answers—to teach the model how to respond helpfully, reason through problems, and align with human expectations. Still, Weibo&amp;#x27;s post-training cost effectiveness on VibeThinker-1.5B is noteworthy and should be commended.&lt;/p&gt;&lt;p&gt;The open-source release upends assumptions about parameter scale, compute intensity, and the minimum viable size for high-performance LLMs.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Different Training Approach: Spectrum-to-Signal&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;VibeThinker-1.5B owes its performance not to scale, but to the training framework behind it: the Spectrum-to-Signal Principle (SSP).&lt;/p&gt;&lt;p&gt;Instead of optimizing a model purely for single-answer correctness (Pass@1), the SSP framework decouples supervised fine-tuning (SFT) and reinforcement learning (RL) into two distinct phases with different goals:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;SFT (“Spectrum Phase”)&lt;/b&gt;: The model is trained to maximize diversity across potential correct answers, improving its Pass@K score. This builds a wide range of plausible solution paths.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;RL (“Signal Phase”)&lt;/b&gt;: A second-stage reinforcement learning system (called MaxEnt-Guided Policy Optimization, or MGPO) is used to identify and amplify the most correct paths from this diverse solution pool. MGPO prioritizes problems where the model is most uncertain, using entropy-based weighting to focus learning.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The authors argue this separation allows small models to explore reasoning space more effectively—achieving signal amplification without relying on massive parameter counts.&lt;/p&gt;&lt;p&gt;VibeThinker-1.5B makes a compelling case that the industry’s reliance on parameter scaling as the only route to better reasoning performance may be outdated. &lt;/p&gt;&lt;p&gt;By adopting a diversity-first training pipeline, WeiboAI has shown that smaller, more accessible models can match and even outperform billion-dollar systems in logic-heavy tasks.&lt;/p&gt;&lt;p&gt;The low resource footprint is among the most significant aspects of VibeThinker-1.5B. At under $8,000, the post-training cost is 30–60x lower than models like DeepSeek R1 and MiniMax-M1, which cost between $294K and $535K to train.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Performance Across Domains&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Despite its small size, VibeThinker-1.5B delivers cross-domain reasoning that outpaces many larger open-source and commercial models:&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Model&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;AIME25&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;LiveCodeBench v6&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPQA-Diamond&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;i&gt;VibeThinker-1.5B&lt;/i&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;74.4&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;51.1&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;46.7&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;GPT-OSS-20B-Medium&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;72.1&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;54.9&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;66.0&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Claude Opus 4&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;69.2&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;56.6&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;79.6&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;MiniMax M1 (456B)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;74.6&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;62.3&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;69.2&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;DeepSeek R1 (671B)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;70.0&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;65.9&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;71.5&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Kimi K2 (1.09T)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;49.5&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;53.7&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;75.1&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;VibeThinker was benchmarked against both reasoning-centric models (Magistral, Claude, OpenAI o3-mini) and non-reasoning LLMs (GPT-4.1, Kimi K2, DeepSeek V3). Across structured reasoning benchmarks, the model consistently outperformed non-reasoning models, regardless of size:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;On AIME24 (math), it beat Kimi K2 (1.09T) by over 10 points (80.3 vs. 69.6).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On LiveCodeBench v6, it surpassed Claude Opus 4 (51.1 vs. 47.4).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On GPQA, it scored below GPT-4.1 and Claude, but still doubled its base model (from 16.4 to 46.7).&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This supports the authors’ claim that size is not the only path to reasoning capability—with proper training design, smaller models can reach or even exceed the performance of far larger systems in targeted tasks.&lt;/p&gt;&lt;p&gt;Notably, it achieves parity with models hundreds of times larger on math and code, though it lags behind in general knowledge reasoning (GPQA), where larger models maintain an edge.&lt;/p&gt;&lt;p&gt;This suggests a potential specialization trade-off: while VibeThinker excels at structured logical tasks, it has less capacity for wide-ranging encyclopedic recall, a known limitation of smaller architectures.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Guidance for Enterprise Adoption&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The release includes recommended inference settings (temperature = 0.6, top_p = 0.95, max tokens = 40960).&lt;/p&gt;&lt;p&gt;The model is small enough to be deployed on edge devices, including mobile phones and vehicle-embedded systems, while inference costs are estimated to be 20–70x cheaper than with large models.&lt;/p&gt;&lt;p&gt;This positions VibeThinker-1.5B not just as a research achievement, but as a potential foundation for cost-efficient, locally deployable reasoning systems.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Weibo’s Strategy and Market Position&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Weibo, launched by Sina Corporation in 2009, remains a cornerstone of China’s social media ecosystem. Often described as China’s version of X (formerly Twitter), the platform blends microblogging, multimedia content, and trending-topic features with a regulatory environment shaped by tight government oversight. &lt;/p&gt;&lt;p&gt;Despite counting 600 million monthly active users (more than twice that of X), &lt;a href="https://m.aastocks.com/en/stocks/analysis/stock-aafn-con/9898/HK6/NOW.1483101/hk-stock-news"&gt;investors are not optimistic about its advertising revenue growth potential&lt;/a&gt; in the near term, and Weibo is navigating intensifying competition from video-first platforms like Douyin, which are drawing younger users and increasing time-spent elsewhere. &lt;/p&gt;&lt;p&gt;In response, Weibo has leaned into creator-economy monetization, live-streaming, and vertical video—adding tools for influencer engagement, e-commerce integration, and richer analytics for brands.&lt;/p&gt;&lt;p&gt;The platform’s role as a digital public square also makes it a focus of regulatory scrutiny. Chinese authorities continue to apply pressure on issues ranging from content governance to data security. In September 2025, &lt;a href="https://www.reuters.com/technology/chinas-internet-regulator-issues-warnings-kuaishou-weibo-over-content-violations-2025-09-20/"&gt;Weibo was among the platforms cited in official warnings&lt;/a&gt;, highlighting its ongoing exposure to policy risks.&lt;/p&gt;&lt;p&gt;Weibo’s push into AI R&amp;amp;D—exemplified by the release of VibeThinker-1.5B—signals a shift in ambition. Beyond being a media platform, Weibo is positioning itself as a player in the next phase of Chinese AI development, using its capital reserves, user behavior data, and in-house research capacity to pursue adjacent technical domains.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;What It Means for Enterprise Technical Decision Makers&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For engineering leaders and enterprise AI teams, VibeThinker’s release has practical implications for everything from orchestration pipelines to cost modeling. &lt;/p&gt;&lt;p&gt;A 1.5B-parameter model that outperforms 100x larger models on math and programming tasks doesn’t just save compute—it shifts the architectural balance. It enables LLM inference on constrained infrastructure, reduces latency at the edge, and lowers the barrier to entry for applications that otherwise would have required API access to closed, frontier-scale models.&lt;/p&gt;&lt;p&gt;That matters for enterprise ML leads trying to deploy reasoning-capable agents within existing systems, or for platform owners tasked with integrating LLMs into automated workflows. &lt;/p&gt;&lt;p&gt;It also speaks to those running reinforcement learning from human feedback (RLHF) pipelines or managing inference optimization across hybrid cloud environments. &lt;/p&gt;&lt;p&gt;The model’s post-training methodology—particularly its entropy-targeted reinforcement learning approach—offers a roadmap for teams looking to refine smaller checkpoints instead of relying on large-scale pretraining.&lt;/p&gt;&lt;p&gt;VibeThinker’s benchmark transparency and data decontamination steps also address another emerging priority in enterprise AI: auditability. While its performance on general-knowledge tests still trails large frontier models, its task-specific reliability makes it an attractive candidate for controlled environments where correctness matters more than coverage.&lt;/p&gt;&lt;p&gt;In short, VibeThinker-1.5B isn’t just a research milestone—it’s a strong candidate for practical enterprise use, deployment and learnings. It suggests that a new class of compact, reasoning-optimized models is viable for enterprise use cases that were previously the domain of far larger systems. For organizations trying to balance cost, latency, interpretability, and control, it’s a good new option to the long, growing list of Chinese open source offerings.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Another day in late 2025, another impressive result from a Chinese company in open source artificial intelligence.&lt;/p&gt;&lt;p&gt;Chinese social networking company &lt;a href="https://huggingface.co/WeiboAI/VibeThinker-1.5B"&gt;Weibo&amp;#x27;s AI division recently released its open source VibeThinker-1.5B&lt;/a&gt;—a 1.5 billion parameter large language model (LLM) that is a fine-tuned variant of rival Chinese tech firm &lt;a href="https://huggingface.co/Qwen/Qwen2.5-Math-1.5B"&gt;Alibaba&amp;#x27;s Qwen2.5-Math-1.5B. &lt;/a&gt;&lt;/p&gt;&lt;p&gt;It&amp;#x27;s available now for free download and usage by researchers and enterprise developers—even for commercial purposes—under a permissive MIT License on &lt;a href="https://huggingface.co/WeiboAI/VibeThinker-1.5B"&gt;Hugging Face&lt;/a&gt;, &lt;a href="https://github.com/WeiboAI/VibeThinker"&gt;GitHub&lt;/a&gt; and &lt;a href="https://modelscope.cn/models/WeiboAI/VibeThinker-1.5B"&gt;ModelScope&lt;/a&gt;, with a &lt;a href="https://arxiv.org/pdf/2511.06221"&gt;technical report&lt;/a&gt; on open access science publishing site arxiv.org.&lt;/p&gt;&lt;p&gt;And yet, despite its compact size, VibeThinker-1.5B achieves benchmark-topping reasoning performance on math and code tasks, rivaling or surpassing models hundreds of times its size, even outperforming Chinese rival DeepSeek&amp;#x27;s famed R1 that went viral at the start of this year—a 671-billion parameter model—on formal reasoning benchmark.&lt;/p&gt;&lt;p&gt;It further eclipses Mistral AI&amp;#x27;s Magistral Medium and holds its own against Anthropic&amp;#x27;s Claude Opus 4 and OpenAI&amp;#x27;s gpt-oss-20B Medium, all while requiring a fraction of the infrastructure and investment.&lt;/p&gt;&lt;p&gt;It also does so having been post-trained on a budget of merely $7800 USD for compute resources (3900 GPU hours on Nvidia H800s) — far less than the tens, or even hundreds, of thousands of dollars typically required to fine-tune models of similar or larger scale.&lt;/p&gt;&lt;p&gt;Recall this is not the total cost of the model&amp;#x27;s development, however: LLMs are trained in stages. First comes pre-training, when the model learns basic language structure and general knowledge by predicting the next word across enormous amounts of text from the internet, books, and articles. This gives it fluency but not much sense of how to follow instructions or hold a conversation&lt;/p&gt;&lt;p&gt;Post-training comes next, using much smaller, higher-quality datasets—typically collections of example questions, prompts, and expert-written answers—to teach the model how to respond helpfully, reason through problems, and align with human expectations. Still, Weibo&amp;#x27;s post-training cost effectiveness on VibeThinker-1.5B is noteworthy and should be commended.&lt;/p&gt;&lt;p&gt;The open-source release upends assumptions about parameter scale, compute intensity, and the minimum viable size for high-performance LLMs.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Different Training Approach: Spectrum-to-Signal&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;VibeThinker-1.5B owes its performance not to scale, but to the training framework behind it: the Spectrum-to-Signal Principle (SSP).&lt;/p&gt;&lt;p&gt;Instead of optimizing a model purely for single-answer correctness (Pass@1), the SSP framework decouples supervised fine-tuning (SFT) and reinforcement learning (RL) into two distinct phases with different goals:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;SFT (“Spectrum Phase”)&lt;/b&gt;: The model is trained to maximize diversity across potential correct answers, improving its Pass@K score. This builds a wide range of plausible solution paths.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;RL (“Signal Phase”)&lt;/b&gt;: A second-stage reinforcement learning system (called MaxEnt-Guided Policy Optimization, or MGPO) is used to identify and amplify the most correct paths from this diverse solution pool. MGPO prioritizes problems where the model is most uncertain, using entropy-based weighting to focus learning.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The authors argue this separation allows small models to explore reasoning space more effectively—achieving signal amplification without relying on massive parameter counts.&lt;/p&gt;&lt;p&gt;VibeThinker-1.5B makes a compelling case that the industry’s reliance on parameter scaling as the only route to better reasoning performance may be outdated. &lt;/p&gt;&lt;p&gt;By adopting a diversity-first training pipeline, WeiboAI has shown that smaller, more accessible models can match and even outperform billion-dollar systems in logic-heavy tasks.&lt;/p&gt;&lt;p&gt;The low resource footprint is among the most significant aspects of VibeThinker-1.5B. At under $8,000, the post-training cost is 30–60x lower than models like DeepSeek R1 and MiniMax-M1, which cost between $294K and $535K to train.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Performance Across Domains&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Despite its small size, VibeThinker-1.5B delivers cross-domain reasoning that outpaces many larger open-source and commercial models:&lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Model&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;AIME25&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;LiveCodeBench v6&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPQA-Diamond&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;i&gt;VibeThinker-1.5B&lt;/i&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;74.4&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;51.1&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;46.7&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;GPT-OSS-20B-Medium&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;72.1&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;54.9&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;66.0&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Claude Opus 4&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;69.2&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;56.6&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;79.6&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;MiniMax M1 (456B)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;74.6&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;62.3&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;69.2&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;DeepSeek R1 (671B)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;70.0&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;65.9&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;71.5&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;Kimi K2 (1.09T)&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;49.5&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;53.7&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;75.1&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;VibeThinker was benchmarked against both reasoning-centric models (Magistral, Claude, OpenAI o3-mini) and non-reasoning LLMs (GPT-4.1, Kimi K2, DeepSeek V3). Across structured reasoning benchmarks, the model consistently outperformed non-reasoning models, regardless of size:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;On AIME24 (math), it beat Kimi K2 (1.09T) by over 10 points (80.3 vs. 69.6).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On LiveCodeBench v6, it surpassed Claude Opus 4 (51.1 vs. 47.4).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On GPQA, it scored below GPT-4.1 and Claude, but still doubled its base model (from 16.4 to 46.7).&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This supports the authors’ claim that size is not the only path to reasoning capability—with proper training design, smaller models can reach or even exceed the performance of far larger systems in targeted tasks.&lt;/p&gt;&lt;p&gt;Notably, it achieves parity with models hundreds of times larger on math and code, though it lags behind in general knowledge reasoning (GPQA), where larger models maintain an edge.&lt;/p&gt;&lt;p&gt;This suggests a potential specialization trade-off: while VibeThinker excels at structured logical tasks, it has less capacity for wide-ranging encyclopedic recall, a known limitation of smaller architectures.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Guidance for Enterprise Adoption&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The release includes recommended inference settings (temperature = 0.6, top_p = 0.95, max tokens = 40960).&lt;/p&gt;&lt;p&gt;The model is small enough to be deployed on edge devices, including mobile phones and vehicle-embedded systems, while inference costs are estimated to be 20–70x cheaper than with large models.&lt;/p&gt;&lt;p&gt;This positions VibeThinker-1.5B not just as a research achievement, but as a potential foundation for cost-efficient, locally deployable reasoning systems.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Weibo’s Strategy and Market Position&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Weibo, launched by Sina Corporation in 2009, remains a cornerstone of China’s social media ecosystem. Often described as China’s version of X (formerly Twitter), the platform blends microblogging, multimedia content, and trending-topic features with a regulatory environment shaped by tight government oversight. &lt;/p&gt;&lt;p&gt;Despite counting 600 million monthly active users (more than twice that of X), &lt;a href="https://m.aastocks.com/en/stocks/analysis/stock-aafn-con/9898/HK6/NOW.1483101/hk-stock-news"&gt;investors are not optimistic about its advertising revenue growth potential&lt;/a&gt; in the near term, and Weibo is navigating intensifying competition from video-first platforms like Douyin, which are drawing younger users and increasing time-spent elsewhere. &lt;/p&gt;&lt;p&gt;In response, Weibo has leaned into creator-economy monetization, live-streaming, and vertical video—adding tools for influencer engagement, e-commerce integration, and richer analytics for brands.&lt;/p&gt;&lt;p&gt;The platform’s role as a digital public square also makes it a focus of regulatory scrutiny. Chinese authorities continue to apply pressure on issues ranging from content governance to data security. In September 2025, &lt;a href="https://www.reuters.com/technology/chinas-internet-regulator-issues-warnings-kuaishou-weibo-over-content-violations-2025-09-20/"&gt;Weibo was among the platforms cited in official warnings&lt;/a&gt;, highlighting its ongoing exposure to policy risks.&lt;/p&gt;&lt;p&gt;Weibo’s push into AI R&amp;amp;D—exemplified by the release of VibeThinker-1.5B—signals a shift in ambition. Beyond being a media platform, Weibo is positioning itself as a player in the next phase of Chinese AI development, using its capital reserves, user behavior data, and in-house research capacity to pursue adjacent technical domains.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;What It Means for Enterprise Technical Decision Makers&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For engineering leaders and enterprise AI teams, VibeThinker’s release has practical implications for everything from orchestration pipelines to cost modeling. &lt;/p&gt;&lt;p&gt;A 1.5B-parameter model that outperforms 100x larger models on math and programming tasks doesn’t just save compute—it shifts the architectural balance. It enables LLM inference on constrained infrastructure, reduces latency at the edge, and lowers the barrier to entry for applications that otherwise would have required API access to closed, frontier-scale models.&lt;/p&gt;&lt;p&gt;That matters for enterprise ML leads trying to deploy reasoning-capable agents within existing systems, or for platform owners tasked with integrating LLMs into automated workflows. &lt;/p&gt;&lt;p&gt;It also speaks to those running reinforcement learning from human feedback (RLHF) pipelines or managing inference optimization across hybrid cloud environments. &lt;/p&gt;&lt;p&gt;The model’s post-training methodology—particularly its entropy-targeted reinforcement learning approach—offers a roadmap for teams looking to refine smaller checkpoints instead of relying on large-scale pretraining.&lt;/p&gt;&lt;p&gt;VibeThinker’s benchmark transparency and data decontamination steps also address another emerging priority in enterprise AI: auditability. While its performance on general-knowledge tests still trails large frontier models, its task-specific reliability makes it an attractive candidate for controlled environments where correctness matters more than coverage.&lt;/p&gt;&lt;p&gt;In short, VibeThinker-1.5B isn’t just a research milestone—it’s a strong candidate for practical enterprise use, deployment and learnings. It suggests that a new class of compact, reasoning-optimized models is viable for enterprise use cases that were previously the domain of far larger systems. For organizations trying to balance cost, latency, interpretability, and control, it’s a good new option to the long, growing list of Chinese open source offerings.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/weibos-new-open-source-ai-model-vibethinker-1-5b-outperforms-deepseek-r1-on</guid><pubDate>Wed, 12 Nov 2025 19:31:00 +0000</pubDate></item><item><title>ElevenLabs strike deals with celebs to create AI audio (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/12/elevenlabs-strike-deals-with-celebs-to-create-ai-audio/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/ElevenLabs-co-founders.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ElevenLabs struck a deal with actors Michael Caine and Matthew McConaughey to AI-generate their voices, the company announced this week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hollywood and AI have an up-and-down relationship, with its guardrails — or lack thereof — serving among the main concerns that led to the Hollywood strikes a few years ago. Since then, some artists have started to warm up to the idea of AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last year, Meta announced that its Meta AI would offer voice assistants that sound like actresses Kristen Bell and Judi Dench. With McConaughey, an investor in ElevenLabs, the company will translate his newsletter into Spanish audio with the use of his AI voice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ElevenLabs also announced this week that it was launching a marketplace to let brands use authorized AI-generated voices of celebrities, which will include Caine and other names like Liza Minnelli and Dr. Maya Angelou. ElevenLabs is one of the more popular AI unicorn companies and has backers including a16z and ICONIQ.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/ElevenLabs-co-founders.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ElevenLabs struck a deal with actors Michael Caine and Matthew McConaughey to AI-generate their voices, the company announced this week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hollywood and AI have an up-and-down relationship, with its guardrails — or lack thereof — serving among the main concerns that led to the Hollywood strikes a few years ago. Since then, some artists have started to warm up to the idea of AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last year, Meta announced that its Meta AI would offer voice assistants that sound like actresses Kristen Bell and Judi Dench. With McConaughey, an investor in ElevenLabs, the company will translate his newsletter into Spanish audio with the use of his AI voice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ElevenLabs also announced this week that it was launching a marketplace to let brands use authorized AI-generated voices of celebrities, which will include Caine and other names like Liza Minnelli and Dr. Maya Angelou. ElevenLabs is one of the more popular AI unicorn companies and has backers including a16z and ICONIQ.&amp;nbsp;&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/12/elevenlabs-strike-deals-with-celebs-to-create-ai-audio/</guid><pubDate>Wed, 12 Nov 2025 20:00:00 +0000</pubDate></item><item><title>OpenAI walks a tricky tightrope with GPT-5.1’s eight new personalities (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/openai-walks-a-tricky-tightrope-with-gpt-5-1s-eight-new-personalities/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New controls attempt to please critics on both sides with a balance between bland and habit-forming.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Group of People with differing personalities" class="absolute inset-0 w-full h-full object-cover hidden" height="409" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-640x409.jpg" width="640" /&gt;
                  &lt;img alt="Group of People with differing personalities" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Chris Madden via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Wednesday, OpenAI released GPT-5.1 Instant and GPT-5.1 Thinking, two updated versions of its flagship AI models now available in ChatGPT. The company is wrapping the models in the language of anthropomorphism, claiming that they’re warmer, more conversational, and better at following instructions.&lt;/p&gt;
&lt;p&gt;The release follows complaints earlier this year that its previous models were excessively cheerful and sycophantic, along with an opposing controversy among users over how OpenAI modified the default GPT-5 output style after several suicide lawsuits.&lt;/p&gt;
&lt;p&gt;The company now faces intense scrutiny from lawyers and regulators that could threaten its future operations. In that kind of environment, it’s difficult to just release a new AI model, throw out a few stats, and move on like the company could even a year ago. But here are the basics: The new GPT-5.1 Instant model will serve as ChatGPT’s faster default option for most tasks, while GPT-5.1 Thinking is a simulated reasoning model that attempts to handle more complex problem-solving tasks.&lt;/p&gt;
&lt;p&gt;OpenAI claims that both models perform better on technical benchmarks such as math and coding evaluations (including AIME 2025 and Codeforces) than GPT-5, which was released in August.&lt;/p&gt;
&lt;p&gt;Improved benchmarks may win over some users, but the biggest change with GPT-5.1 is in its presentation. OpenAI says it heard from users that they wanted AI models to simulate different communication styles depending on the task, so the company is offering eight preset options, including Professional, Friendly, Candid, Quirky, Efficient, Cynical, and Nerdy, alongside a Default setting.&lt;/p&gt;
&lt;p&gt;These presets alter the instructions fed into each prompt to simulate different personality styles, but the underlying model capabilities remain the same across all settings.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2127176 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="An illustration showing GPT-5.1's eight personality styles in ChatGPT." class="center large" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/5-1_X_Thread_Card_05_V2-1024x576.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An illustration showing GPT-5.1’s eight personality styles in ChatGPT.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;In addition, the company trained GPT-5.1 Instant to use “adaptive reasoning,” meaning that the model decides when to spend more computational time processing a prompt before generating output.&lt;/p&gt;
&lt;p&gt;The company plans to roll out the models gradually over the next few days, starting with paid subscribers before expanding to free users. OpenAI plans to bring both GPT-5.1 Instant and GPT-5.1 Thinking to its API later this week. GPT-5.1 Instant will appear as gpt-5.1-chat-latest, and GPT-5.1 Thinking will be released as GPT-5.1 in the API, both with adaptive reasoning enabled. The older GPT-5 models will remain available in ChatGPT under the legacy models dropdown for paid subscribers for three months.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The company says it wants to give people time to compare model outputs and adapt at their own pace and that going forward, it will communicate deprecation periods clearly with advance notice. OpenAI also published a system card with information on its safety approach for GPT-5.1.&lt;/p&gt;
&lt;h2&gt;Seeking balance&lt;/h2&gt;
&lt;p&gt;In a blog post published Wednesday, OpenAI CEO of Applications Fidji Simo wrote that the company wants ChatGPT to “feel like yours and work with you in the way that suits you best.” Simo wrote that with more than 800 million people using ChatGPT, the company has moved past one-size-fits-all approaches. She wrote that people experience ChatGPT in individual ways, with some wanting direct and neutral responses while others prefer different output patterns.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The preset “personality” options work by injecting different instructions into the system prompt that the model processes before generating each response. OpenAI says the original Cynical and Nerdy options from earlier this year will remain available in the personalization settings dropdown.&lt;/p&gt;
&lt;p&gt;For users who want more control over outputs, OpenAI is experimenting with options to adjust specific characteristics from personalization settings, including how concise responses are and how frequently the model generates emojis. ChatGPT can also offer to update these settings during conversations when it detects users requesting certain output patterns. The company says updates to personalization settings now take effect across all chats immediately, including ongoing conversations.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2127177 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A benchmark chart from OpenAI. &amp;quot;GPT‑5.1 Thinking varies its thinking time more dynamically than GPT‑5 Thinking,&amp;quot; the company writes." class="center large" height="702" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GPT-5.1-spends-less-time-on-easy-tasks-and-more-time-on-hard-tasks-1024x702.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A benchmark chart from OpenAI. “GPT‑5.1 Thinking varies its thinking time more dynamically than GPT‑5 Thinking,” the company writes.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Simo addressed the balance between customization and accuracy in her blog post. “Personalization taken to an extreme wouldn’t be helpful if it only reinforces your worldview or tells you what you want to hear,” she wrote. She compared excessive customization to editing a spouse’s traits to always agree, noting that “the best people in our lives are the ones who listen and adapt, but also challenge us and help us grow.”&lt;/p&gt;
&lt;p&gt;That concern about excessive personalization is not theoretical. Amid a year full of accusations of AI chatbots inspiring suicides and people descending into obsessive fantasy-rabbit-hole scenarios, OpenAI recently released safety research that details its plan to deal with people who develop unhealthy attachments to its AI chatbots. The company says these situations are rare, but it is working with an expert council and mental health clinicians to understand what healthy interactions with AI models should look like.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Even so, the root problem is arguably that ChatGPT still pretends to be a person—a consistent entity that knows you and learns your preferences over time. It assumes the mantle of human emotion and acts like it understands you and sympathizes with what you’re going through, which could potentially lead users into the same kind of thorny situations we’ve seen repeatedly in the past.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2127175 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot example of new &amp;quot;warmer&amp;quot; GPT-5.1 outputs presented on the OpenAI website." class="center large" height="668" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/screenshot_from_openai-1024x668.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot example of new “warmer” GPT-5.1 outputs presented on the OpenAI website.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;It’s a tricky position for OpenAI to be in. When the company changes ChatGPT’s output style to be too reserved and robotic, it gets complaints from one set of users. When the models are too warm, the company receives criticism from experts who worry about how the models might affect vulnerable users. The new personality choices are OpenAI’s attempt to balance the needs of a broad spectrum of users who approach its chatbot with vastly different use cases, from programming assistance to being a virtual best friend.&lt;/p&gt;
&lt;p&gt;Meanwhile, the company faces a fundamental business tension between making AI models engaging enough for widespread adoption while attempting to avoid inspiring user behavior that could become harmful. Simo addressed some of these concerns in her blog post. “We also have to be vigilant about the potential for some people to develop attachment to our models at the expense of their real world relationships, well being, or obligations,” she wrote. “There will be many new challenges as this technology evolves and people use it in new ways. Building at this scale means never assuming we have all the answers.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New controls attempt to please critics on both sides with a balance between bland and habit-forming.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Group of People with differing personalities" class="absolute inset-0 w-full h-full object-cover hidden" height="409" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-640x409.jpg" width="640" /&gt;
                  &lt;img alt="Group of People with differing personalities" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/aaGettyImages-862457080-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Chris Madden via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Wednesday, OpenAI released GPT-5.1 Instant and GPT-5.1 Thinking, two updated versions of its flagship AI models now available in ChatGPT. The company is wrapping the models in the language of anthropomorphism, claiming that they’re warmer, more conversational, and better at following instructions.&lt;/p&gt;
&lt;p&gt;The release follows complaints earlier this year that its previous models were excessively cheerful and sycophantic, along with an opposing controversy among users over how OpenAI modified the default GPT-5 output style after several suicide lawsuits.&lt;/p&gt;
&lt;p&gt;The company now faces intense scrutiny from lawyers and regulators that could threaten its future operations. In that kind of environment, it’s difficult to just release a new AI model, throw out a few stats, and move on like the company could even a year ago. But here are the basics: The new GPT-5.1 Instant model will serve as ChatGPT’s faster default option for most tasks, while GPT-5.1 Thinking is a simulated reasoning model that attempts to handle more complex problem-solving tasks.&lt;/p&gt;
&lt;p&gt;OpenAI claims that both models perform better on technical benchmarks such as math and coding evaluations (including AIME 2025 and Codeforces) than GPT-5, which was released in August.&lt;/p&gt;
&lt;p&gt;Improved benchmarks may win over some users, but the biggest change with GPT-5.1 is in its presentation. OpenAI says it heard from users that they wanted AI models to simulate different communication styles depending on the task, so the company is offering eight preset options, including Professional, Friendly, Candid, Quirky, Efficient, Cynical, and Nerdy, alongside a Default setting.&lt;/p&gt;
&lt;p&gt;These presets alter the instructions fed into each prompt to simulate different personality styles, but the underlying model capabilities remain the same across all settings.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2127176 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="An illustration showing GPT-5.1's eight personality styles in ChatGPT." class="center large" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/5-1_X_Thread_Card_05_V2-1024x576.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An illustration showing GPT-5.1’s eight personality styles in ChatGPT.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;In addition, the company trained GPT-5.1 Instant to use “adaptive reasoning,” meaning that the model decides when to spend more computational time processing a prompt before generating output.&lt;/p&gt;
&lt;p&gt;The company plans to roll out the models gradually over the next few days, starting with paid subscribers before expanding to free users. OpenAI plans to bring both GPT-5.1 Instant and GPT-5.1 Thinking to its API later this week. GPT-5.1 Instant will appear as gpt-5.1-chat-latest, and GPT-5.1 Thinking will be released as GPT-5.1 in the API, both with adaptive reasoning enabled. The older GPT-5 models will remain available in ChatGPT under the legacy models dropdown for paid subscribers for three months.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The company says it wants to give people time to compare model outputs and adapt at their own pace and that going forward, it will communicate deprecation periods clearly with advance notice. OpenAI also published a system card with information on its safety approach for GPT-5.1.&lt;/p&gt;
&lt;h2&gt;Seeking balance&lt;/h2&gt;
&lt;p&gt;In a blog post published Wednesday, OpenAI CEO of Applications Fidji Simo wrote that the company wants ChatGPT to “feel like yours and work with you in the way that suits you best.” Simo wrote that with more than 800 million people using ChatGPT, the company has moved past one-size-fits-all approaches. She wrote that people experience ChatGPT in individual ways, with some wanting direct and neutral responses while others prefer different output patterns.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The preset “personality” options work by injecting different instructions into the system prompt that the model processes before generating each response. OpenAI says the original Cynical and Nerdy options from earlier this year will remain available in the personalization settings dropdown.&lt;/p&gt;
&lt;p&gt;For users who want more control over outputs, OpenAI is experimenting with options to adjust specific characteristics from personalization settings, including how concise responses are and how frequently the model generates emojis. ChatGPT can also offer to update these settings during conversations when it detects users requesting certain output patterns. The company says updates to personalization settings now take effect across all chats immediately, including ongoing conversations.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2127177 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A benchmark chart from OpenAI. &amp;quot;GPT‑5.1 Thinking varies its thinking time more dynamically than GPT‑5 Thinking,&amp;quot; the company writes." class="center large" height="702" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GPT-5.1-spends-less-time-on-easy-tasks-and-more-time-on-hard-tasks-1024x702.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A benchmark chart from OpenAI. “GPT‑5.1 Thinking varies its thinking time more dynamically than GPT‑5 Thinking,” the company writes.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Simo addressed the balance between customization and accuracy in her blog post. “Personalization taken to an extreme wouldn’t be helpful if it only reinforces your worldview or tells you what you want to hear,” she wrote. She compared excessive customization to editing a spouse’s traits to always agree, noting that “the best people in our lives are the ones who listen and adapt, but also challenge us and help us grow.”&lt;/p&gt;
&lt;p&gt;That concern about excessive personalization is not theoretical. Amid a year full of accusations of AI chatbots inspiring suicides and people descending into obsessive fantasy-rabbit-hole scenarios, OpenAI recently released safety research that details its plan to deal with people who develop unhealthy attachments to its AI chatbots. The company says these situations are rare, but it is working with an expert council and mental health clinicians to understand what healthy interactions with AI models should look like.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Even so, the root problem is arguably that ChatGPT still pretends to be a person—a consistent entity that knows you and learns your preferences over time. It assumes the mantle of human emotion and acts like it understands you and sympathizes with what you’re going through, which could potentially lead users into the same kind of thorny situations we’ve seen repeatedly in the past.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2127175 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot example of new &amp;quot;warmer&amp;quot; GPT-5.1 outputs presented on the OpenAI website." class="center large" height="668" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/screenshot_from_openai-1024x668.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot example of new “warmer” GPT-5.1 outputs presented on the OpenAI website.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;It’s a tricky position for OpenAI to be in. When the company changes ChatGPT’s output style to be too reserved and robotic, it gets complaints from one set of users. When the models are too warm, the company receives criticism from experts who worry about how the models might affect vulnerable users. The new personality choices are OpenAI’s attempt to balance the needs of a broad spectrum of users who approach its chatbot with vastly different use cases, from programming assistance to being a virtual best friend.&lt;/p&gt;
&lt;p&gt;Meanwhile, the company faces a fundamental business tension between making AI models engaging enough for widespread adoption while attempting to avoid inspiring user behavior that could become harmful. Simo addressed some of these concerns in her blog post. “We also have to be vigilant about the potential for some people to develop attachment to our models at the expense of their real world relationships, well being, or obligations,” she wrote. “There will be many new challenges as this technology evolves and people use it in new ways. Building at this scale means never assuming we have all the answers.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/openai-walks-a-tricky-tightrope-with-gpt-5-1s-eight-new-personalities/</guid><pubDate>Wed, 12 Nov 2025 22:54:47 +0000</pubDate></item><item><title>‘Chad: The Brainrot IDE’ is a new Y Combinator-backed product so wild, people thought it was fake (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/12/chad-the-brainrot-ide-is-a-new-y-combinator-backed-product-so-wild-people-thought-it-was-fake/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2019/07/GettyImages-924636730.jpg?resize=1200,1000" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When former Twitter CEO Dick Costolo spoke at TechCrunch Disrupt, someone from the audience asked him if HBO’s hit satire “Silicon Valley”&lt;em&gt; &lt;/em&gt;would be revived. Costolo, who was a writer for the show, essentially answered no (at timestamp 38:17).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the writers talk about that regularly, he said, they don’t pursue it because today’s actual Silicon Valley is so bizarre, it can’t be parodied.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The latest case in point is a new company called Clad Labs that launched out of Y Combinator this week. Clad’s product is so outside-the-box that people thought it was an April Fools’ joke in November.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But it’s a real product, founder Richard Wang told TechCrunch. The product is called “Chad: The Brainrot IDE.” It is yet another vibe coding integrated development environment — an IDE is the software developers use to code — but with a twist. While waiting for the AI coding tool to finish its task, the developer can mess around with their favorite brainrot activities within a window of the IDE.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Or, as the company’s website advertises: “Gamble while you code. Watch TikToks. Swipe on Tinder. Play minigames. This isn’t a joke — it’s Chad IDE, and it’s solving the biggest productivity problem in AI-powered development that nobody’s talking about.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders say their IDE increases productivity by helping with “context switching.” Their argument is, by doing your brainrot activities within the IDE itself, as soon as the AI is done with the task, you’ll get right back to work rather than be focused on your phone or browser.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reaction on X was mixed. While some people thought it was a fake satire, others thought it was a good — or a terrible — idea.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Like it or hate it, everyone had an opinion, even Jordi Hays, co-host of the enthusiastically pro-tech podcast TBPN. Hays penned a post on the product called, “Rage Baiting is for Losers.” In it he said of Chad IDE: “On one hand it’s funny. On the other hand, what are we doing here and why does this belong on the official YC account?”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He argued that products like Chad IDE and Cluely have moved rage bait from a marketing gimmick to a “product strategy” and “it really should not be.” He urged YC to start teaching founders that “rage baiting is for losers.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is particularly interesting advice from someone who, as a founder, had mastered viral marketing without rage. Hays and his wife Sarah founded Party Round, a funding startup that went viral for their friendly marketing gimmicks like launching NFT versions of top “helpful” VCs. (Party Round rebranded to Capital and sold to Rho in 2024.)&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Wang tells TechCrunch what the haters don’t get about his brainrot IDE is that it wasn’t intended to be rage bait. The founders hope it becomes a genuinely beloved AI vibe coder for consumer-app type developers. They want to give these folks a consumer app-like experience in an IDE.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the product is real, it’s not available to the public yet. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;”We’re currently in a closed beta,” Wang said. Right now, Chad is attempting to build a “community” of users who like the idea. Clad Labs hopes to open the product to the public soon, but for now, users must get an invite from someone already in the beta.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;No doubt there’s a certain type of developer who would love Chad. But whatever the future holds for this product, one thing is true: It is nearly impossible to parody Silicon Valley these days.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2019/07/GettyImages-924636730.jpg?resize=1200,1000" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When former Twitter CEO Dick Costolo spoke at TechCrunch Disrupt, someone from the audience asked him if HBO’s hit satire “Silicon Valley”&lt;em&gt; &lt;/em&gt;would be revived. Costolo, who was a writer for the show, essentially answered no (at timestamp 38:17).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the writers talk about that regularly, he said, they don’t pursue it because today’s actual Silicon Valley is so bizarre, it can’t be parodied.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The latest case in point is a new company called Clad Labs that launched out of Y Combinator this week. Clad’s product is so outside-the-box that people thought it was an April Fools’ joke in November.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But it’s a real product, founder Richard Wang told TechCrunch. The product is called “Chad: The Brainrot IDE.” It is yet another vibe coding integrated development environment — an IDE is the software developers use to code — but with a twist. While waiting for the AI coding tool to finish its task, the developer can mess around with their favorite brainrot activities within a window of the IDE.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Or, as the company’s website advertises: “Gamble while you code. Watch TikToks. Swipe on Tinder. Play minigames. This isn’t a joke — it’s Chad IDE, and it’s solving the biggest productivity problem in AI-powered development that nobody’s talking about.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders say their IDE increases productivity by helping with “context switching.” Their argument is, by doing your brainrot activities within the IDE itself, as soon as the AI is done with the task, you’ll get right back to work rather than be focused on your phone or browser.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reaction on X was mixed. While some people thought it was a fake satire, others thought it was a good — or a terrible — idea.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Like it or hate it, everyone had an opinion, even Jordi Hays, co-host of the enthusiastically pro-tech podcast TBPN. Hays penned a post on the product called, “Rage Baiting is for Losers.” In it he said of Chad IDE: “On one hand it’s funny. On the other hand, what are we doing here and why does this belong on the official YC account?”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He argued that products like Chad IDE and Cluely have moved rage bait from a marketing gimmick to a “product strategy” and “it really should not be.” He urged YC to start teaching founders that “rage baiting is for losers.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is particularly interesting advice from someone who, as a founder, had mastered viral marketing without rage. Hays and his wife Sarah founded Party Round, a funding startup that went viral for their friendly marketing gimmicks like launching NFT versions of top “helpful” VCs. (Party Round rebranded to Capital and sold to Rho in 2024.)&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Wang tells TechCrunch what the haters don’t get about his brainrot IDE is that it wasn’t intended to be rage bait. The founders hope it becomes a genuinely beloved AI vibe coder for consumer-app type developers. They want to give these folks a consumer app-like experience in an IDE.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the product is real, it’s not available to the public yet. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;”We’re currently in a closed beta,” Wang said. Right now, Chad is attempting to build a “community” of users who like the idea. Clad Labs hopes to open the product to the public soon, but for now, users must get an invite from someone already in the beta.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;No doubt there’s a certain type of developer who would love Chad. But whatever the future holds for this product, one thing is true: It is nearly impossible to parody Silicon Valley these days.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/12/chad-the-brainrot-ide-is-a-new-y-combinator-backed-product-so-wild-people-thought-it-was-fake/</guid><pubDate>Thu, 13 Nov 2025 00:05:30 +0000</pubDate></item></channel></rss>