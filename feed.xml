<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 18 Jul 2025 18:32:44 +0000</lastBuildDate><item><title>A brief history of “three-parent babies” (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/18/1120383/a-brief-history-of-three-parent-babies/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/GettyImages-1489423262.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;This week we heard that eight babies have been born in the UK following an experimental form of IVF that involves DNA from three people. The approach was used to prevent women with genetic mutations from passing mitochondrial diseases to their children. You can read all about the results, and the reception to them, here.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But these eight babies aren’t the first “three-parent” children out there. Over the last decade, several teams have been using variations of this approach to help people have babies. This week, let’s consider the &lt;em&gt;other &lt;/em&gt;babies born from three-person IVF.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;&lt;strong&gt;I can’t go any further without talking about the term we use to describe these children.&lt;/strong&gt; Journalists, myself included, have called them “three-parent babies” because they are created using DNA from three people. Briefly, the approach typically involves using the DNA from the nuclei of the intended parents’ egg and sperm cells. That’s where most of the DNA in a cell is found.&lt;/p&gt;  &lt;p&gt;But it also makes use of mitochondrial DNA (mtDNA)—the DNA found in the energy-producing organelles of a cell—from a third person. The idea is to avoid using the mtDNA from the intended mother, perhaps because it is carrying genetic mutations. Other teams have done this in the hope of treating infertility.&lt;/p&gt; 
 &lt;p&gt;mtDNA, which is usually inherited from a person’s mother, makes up a tiny fraction of total inherited DNA. It includes only 37 genes, all of which are thought to play a role in how mitochondria work (as opposed to, say, eye color or height).&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;That’s why some scientists despise the term “three-parent baby.”&lt;/strong&gt; Yes, the baby has DNA from three people, but those three can’t all be considered &lt;em&gt;parents&lt;/em&gt;, critics argue. For the sake of argument, this time around I’ll use the term “three-person IVF” from here on out.&lt;/p&gt; 
 &lt;p&gt;So, about these babies. The first were reported back in the 1990s. Jacques Cohen, then at Saint Barnabas Medical Center in Livingston, New Jersey, and his colleagues thought they might be able to treat some cases of infertility by injecting the mitochondria-containing cytoplasm of healthy eggs into eggs from the intended mother.&amp;nbsp;Seventeen babies were ultimately born this way, according to the team. (Side note: In&amp;nbsp;their paper, the authors describe potential resulting children as “three-parental individuals.”)&lt;/p&gt;  &lt;p&gt;But two fetuses appeared to have genetic abnormalities. And one of the children started to show signs of a developmental disorder. In 2002, the US Food and Drug Administration put a stop to the research.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;The babies born during that study&amp;nbsp;are in their 20s now. But scientists still don’t know why they saw those abnormalities. Some think that mixing mtDNA from two people might be problematic.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Newer approaches to three-person IVF aim to include mtDNA from just the donor, completely bypassing the intended mother’s mtDNA.&lt;/strong&gt; John Zhang at the New Hope Fertility Center in New York City tried this approach for a Jordanian couple in 2016. The woman carried genes for a fatal mitochondrial disease and had already lost two children to it. She wanted to avoid passing it on to another child.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;Zhang took the nucleus of the woman’s egg and inserted it into a donor egg that had had its own nucleus removed—but still had its mitochondria-containing cytoplasm. That egg was then fertilized with the woman’s husband’s sperm.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Because it was still illegal in the US, Zhang controversially did the procedure in Mexico, &lt;/strong&gt;where,&amp;nbsp;as he told me at the time, “there are no rules.” The couple eventually welcomed a healthy baby boy. Less than 1% of the boy’s mitochondria carried his mother’s mutation, so the procedure was deemed a success.&lt;/p&gt;  &lt;p&gt;There was a fair bit of outrage from the scientific community, though. Mitochondrial donation had been made legal in the UK the previous year, but no clinic had yet been given a license to do it. Zhang’s experiment seemed to have been conducted with no oversight. Many questioned how ethical it was, although Sian Harding, who reviewed the ethics of the UK procedure, then told me it was “as good as or better than what we’ll do in the UK.”&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The scandal had barely died down by the time the next “three-person IVF” babies were announced.&lt;/strong&gt; In 2017, a team at the Nadiya Clinic in Ukraine&amp;nbsp;announced the birth of a little girl to parents who’d had the treatment for infertility. The news brought more outrage from some quarters, as scientists argued that the experimental procedure should only be used to prevent severe mitochondrial diseases.&lt;/p&gt; 

 &lt;p&gt;It wasn’t until later that year that the UK’s fertility authority granted a team in Newcastle a license to perform mitochondrial donation. That team launched a trial in 2017. It was big news—the first “official” trial to test whether the approach could safely prevent mitochondrial disease.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;&lt;strong&gt;But it was slow going.&lt;/strong&gt; And meanwhile, other teams were making progress. The Nadiya Clinic continued to trial the procedure in couples with infertility. Pavlo Mazur, a former embryologist who worked at that clinic, tells me that 10 babies were born there as a result of mitochondrial donation.&lt;/p&gt;  &lt;p&gt;Mazur then moved to another clinic in Ukraine, where he says he used a different type of mitochondrial donation to achieve another five healthy births for people with infertility. “In total, it’s 15 kids made by me,” he says.&lt;/p&gt;  &lt;p&gt;But he adds that other clinics in Ukraine are also using mitochondrial donation, without sharing their results. “We don’t know the actual number of those kids in Ukraine,” says Mazur. “But there are dozens of them.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt;&lt;p&gt;&lt;strong&gt;In 2020, Nuno Costa-Borges of Embryotools in Barcelona, Spain, and his colleagues described&amp;nbsp;another trial of mitochondrial donation.&lt;/strong&gt; This trial, performed in Greece, was also designed to test the procedure for people with infertility. It involved 25 patients. So far,&amp;nbsp;seven children have been born. “I think it’s a bit strange that they aren’t getting more credit,” says Heidi Mertes, a medical ethicist at Ghent University in Belgium.&lt;/p&gt;  &lt;p&gt;The newly announced UK births are only the latest “three-person IVF” babies. And while their births are being heralded as a success story for mitochondrial donation, the story isn’t quite so simple. Three of the eight babies were born with a non-insignificant proportion of mutated mitochondria, ranging between 5% and 20%, depending on the baby and the sample.&lt;/p&gt;  &lt;p&gt;Dagan Wells of the University of Oxford, who is involved in the Greece trial, says that two of the seven babies in their study also appear to have inherited mtDNA from their intended mothers. Mazur says he has seen several cases of this “reversal” too.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This isn’t a problem for babies whose mothers don’t carry genes for mitochondrial disease.&lt;/strong&gt; But it might be for those whose mothers do.&lt;/p&gt;  &lt;p&gt;I don’t want to pour cold water over the new UK results. It was great to finally see the results of a trial that’s been running for eight years. And the births of healthy babies are something to celebrate. But it’s not a simple success story. Mitochondrial donation doesn’t guarantee a healthy baby. We still have more to learn, not only from these babies, but from the others that have already been born.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/GettyImages-1489423262.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;This week we heard that eight babies have been born in the UK following an experimental form of IVF that involves DNA from three people. The approach was used to prevent women with genetic mutations from passing mitochondrial diseases to their children. You can read all about the results, and the reception to them, here.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But these eight babies aren’t the first “three-parent” children out there. Over the last decade, several teams have been using variations of this approach to help people have babies. This week, let’s consider the &lt;em&gt;other &lt;/em&gt;babies born from three-person IVF.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;&lt;strong&gt;I can’t go any further without talking about the term we use to describe these children.&lt;/strong&gt; Journalists, myself included, have called them “three-parent babies” because they are created using DNA from three people. Briefly, the approach typically involves using the DNA from the nuclei of the intended parents’ egg and sperm cells. That’s where most of the DNA in a cell is found.&lt;/p&gt;  &lt;p&gt;But it also makes use of mitochondrial DNA (mtDNA)—the DNA found in the energy-producing organelles of a cell—from a third person. The idea is to avoid using the mtDNA from the intended mother, perhaps because it is carrying genetic mutations. Other teams have done this in the hope of treating infertility.&lt;/p&gt; 
 &lt;p&gt;mtDNA, which is usually inherited from a person’s mother, makes up a tiny fraction of total inherited DNA. It includes only 37 genes, all of which are thought to play a role in how mitochondria work (as opposed to, say, eye color or height).&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;That’s why some scientists despise the term “three-parent baby.”&lt;/strong&gt; Yes, the baby has DNA from three people, but those three can’t all be considered &lt;em&gt;parents&lt;/em&gt;, critics argue. For the sake of argument, this time around I’ll use the term “three-person IVF” from here on out.&lt;/p&gt; 
 &lt;p&gt;So, about these babies. The first were reported back in the 1990s. Jacques Cohen, then at Saint Barnabas Medical Center in Livingston, New Jersey, and his colleagues thought they might be able to treat some cases of infertility by injecting the mitochondria-containing cytoplasm of healthy eggs into eggs from the intended mother.&amp;nbsp;Seventeen babies were ultimately born this way, according to the team. (Side note: In&amp;nbsp;their paper, the authors describe potential resulting children as “three-parental individuals.”)&lt;/p&gt;  &lt;p&gt;But two fetuses appeared to have genetic abnormalities. And one of the children started to show signs of a developmental disorder. In 2002, the US Food and Drug Administration put a stop to the research.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;The babies born during that study&amp;nbsp;are in their 20s now. But scientists still don’t know why they saw those abnormalities. Some think that mixing mtDNA from two people might be problematic.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Newer approaches to three-person IVF aim to include mtDNA from just the donor, completely bypassing the intended mother’s mtDNA.&lt;/strong&gt; John Zhang at the New Hope Fertility Center in New York City tried this approach for a Jordanian couple in 2016. The woman carried genes for a fatal mitochondrial disease and had already lost two children to it. She wanted to avoid passing it on to another child.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;Zhang took the nucleus of the woman’s egg and inserted it into a donor egg that had had its own nucleus removed—but still had its mitochondria-containing cytoplasm. That egg was then fertilized with the woman’s husband’s sperm.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Because it was still illegal in the US, Zhang controversially did the procedure in Mexico, &lt;/strong&gt;where,&amp;nbsp;as he told me at the time, “there are no rules.” The couple eventually welcomed a healthy baby boy. Less than 1% of the boy’s mitochondria carried his mother’s mutation, so the procedure was deemed a success.&lt;/p&gt;  &lt;p&gt;There was a fair bit of outrage from the scientific community, though. Mitochondrial donation had been made legal in the UK the previous year, but no clinic had yet been given a license to do it. Zhang’s experiment seemed to have been conducted with no oversight. Many questioned how ethical it was, although Sian Harding, who reviewed the ethics of the UK procedure, then told me it was “as good as or better than what we’ll do in the UK.”&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The scandal had barely died down by the time the next “three-person IVF” babies were announced.&lt;/strong&gt; In 2017, a team at the Nadiya Clinic in Ukraine&amp;nbsp;announced the birth of a little girl to parents who’d had the treatment for infertility. The news brought more outrage from some quarters, as scientists argued that the experimental procedure should only be used to prevent severe mitochondrial diseases.&lt;/p&gt; 

 &lt;p&gt;It wasn’t until later that year that the UK’s fertility authority granted a team in Newcastle a license to perform mitochondrial donation. That team launched a trial in 2017. It was big news—the first “official” trial to test whether the approach could safely prevent mitochondrial disease.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;&lt;strong&gt;But it was slow going.&lt;/strong&gt; And meanwhile, other teams were making progress. The Nadiya Clinic continued to trial the procedure in couples with infertility. Pavlo Mazur, a former embryologist who worked at that clinic, tells me that 10 babies were born there as a result of mitochondrial donation.&lt;/p&gt;  &lt;p&gt;Mazur then moved to another clinic in Ukraine, where he says he used a different type of mitochondrial donation to achieve another five healthy births for people with infertility. “In total, it’s 15 kids made by me,” he says.&lt;/p&gt;  &lt;p&gt;But he adds that other clinics in Ukraine are also using mitochondrial donation, without sharing their results. “We don’t know the actual number of those kids in Ukraine,” says Mazur. “But there are dozens of them.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt;&lt;p&gt;&lt;strong&gt;In 2020, Nuno Costa-Borges of Embryotools in Barcelona, Spain, and his colleagues described&amp;nbsp;another trial of mitochondrial donation.&lt;/strong&gt; This trial, performed in Greece, was also designed to test the procedure for people with infertility. It involved 25 patients. So far,&amp;nbsp;seven children have been born. “I think it’s a bit strange that they aren’t getting more credit,” says Heidi Mertes, a medical ethicist at Ghent University in Belgium.&lt;/p&gt;  &lt;p&gt;The newly announced UK births are only the latest “three-person IVF” babies. And while their births are being heralded as a success story for mitochondrial donation, the story isn’t quite so simple. Three of the eight babies were born with a non-insignificant proportion of mutated mitochondria, ranging between 5% and 20%, depending on the baby and the sample.&lt;/p&gt;  &lt;p&gt;Dagan Wells of the University of Oxford, who is involved in the Greece trial, says that two of the seven babies in their study also appear to have inherited mtDNA from their intended mothers. Mazur says he has seen several cases of this “reversal” too.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This isn’t a problem for babies whose mothers don’t carry genes for mitochondrial disease.&lt;/strong&gt; But it might be for those whose mothers do.&lt;/p&gt;  &lt;p&gt;I don’t want to pour cold water over the new UK results. It was great to finally see the results of a trial that’s been running for eight years. And the births of healthy babies are something to celebrate. But it’s not a simple success story. Mitochondrial donation doesn’t guarantee a healthy baby. We still have more to learn, not only from these babies, but from the others that have already been born.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/18/1120383/a-brief-history-of-three-parent-babies/</guid><pubDate>Fri, 18 Jul 2025 09:00:00 +0000</pubDate></item><item><title>[NEW] ChatGPT: Everything you need to know about the AI-powered chatbot (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/18/chatgpt-everything-to-know-about-the-ai-chatbot/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1462188043-e1686340799615.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-july-2025"&gt;July 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-general-purpose-agent-in-chatgpt"&gt;OpenAI launches a general-purpose agent in ChatGPT&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a user’s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-study-warns-of-major-risks-with-ai-therapy-chatbots"&gt;Study warns of major risks with AI therapy chatbots&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-delays-releasing-its-open-model-again"&gt;OpenAI delays releasing its open model again&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;we planned to launch our open-weight model next week.&lt;/p&gt;&lt;p&gt;we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.&lt;/p&gt;&lt;p&gt;while we trust the community will build great things with this model, once weights are…&lt;/p&gt;— Sam Altman (@sama) July 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks"&gt;&lt;strong&gt;OpenAI is reportedly releasing an AI browser in the coming weeks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-is-testing-a-mysterious-new-feature-called-study-together"&gt;ChatGPT is testing a mysterious new feature called ‘study together’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-referrals-from-chatgpt-to-news-sites-are-rising-but-not-enough-to-offset-search-declines"&gt;Referrals from ChatGPT to news sites are rising but not enough to offset search declines&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Referrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="june2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-uses-google-s-ai-chips-to-power-its-products"&gt;&lt;strong&gt;OpenAI uses Google’s AI chips to power its products&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using &lt;em&gt;non&lt;/em&gt;-Nvidia chips in an important way.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-a-new-mit-study-suggests-that-chatgpt-might-be-harming-critical-thinking-skills"&gt;&lt;strong&gt;A new MIT study suggests that ChatGPT might be harming critical thinking skills&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-was-downloaded-30-million-times-last-month"&gt;ChatGPT was downloaded 30 million times last month&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1462188043-e1686340799615.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="h-july-2025"&gt;July 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-general-purpose-agent-in-chatgpt"&gt;OpenAI launches a general-purpose agent in ChatGPT&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a user’s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-study-warns-of-major-risks-with-ai-therapy-chatbots"&gt;Study warns of major risks with AI therapy chatbots&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-delays-releasing-its-open-model-again"&gt;OpenAI delays releasing its open model again&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;we planned to launch our open-weight model next week.&lt;/p&gt;&lt;p&gt;we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.&lt;/p&gt;&lt;p&gt;while we trust the community will build great things with this model, once weights are…&lt;/p&gt;— Sam Altman (@sama) July 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks"&gt;&lt;strong&gt;OpenAI is reportedly releasing an AI browser in the coming weeks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-is-testing-a-mysterious-new-feature-called-study-together"&gt;ChatGPT is testing a mysterious new feature called ‘study together’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-referrals-from-chatgpt-to-news-sites-are-rising-but-not-enough-to-offset-search-declines"&gt;Referrals from ChatGPT to news sites are rising but not enough to offset search declines&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Referrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="june2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-uses-google-s-ai-chips-to-power-its-products"&gt;&lt;strong&gt;OpenAI uses Google’s AI chips to power its products&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using &lt;em&gt;non&lt;/em&gt;-Nvidia chips in an important way.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-a-new-mit-study-suggests-that-chatgpt-might-be-harming-critical-thinking-skills"&gt;&lt;strong&gt;A new MIT study suggests that ChatGPT might be harming critical thinking skills&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-was-downloaded-30-million-times-last-month"&gt;ChatGPT was downloaded 30 million times last month&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/18/chatgpt-everything-to-know-about-the-ai-chatbot/</guid><pubDate>Fri, 18 Jul 2025 10:03:00 +0000</pubDate></item><item><title>The Download: how to run an LLM, and a history of “three-parent babies” (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/18/1120453/the-download-how-to-run-an-llm-and-a-history-of-three-parent-babies/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How to run an LLM on your laptop&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In the early days of large language models, there was a high barrier to entry: it used to be impossible to run anything useful on your own computer without investing in pricey GPUs. But researchers have had so much success in shrinking down and speeding up models that anyone with a laptop, or even a smartphone, can now get in on the action.&lt;/p&gt;&lt;p&gt;For people who are concerned about privacy, want to break free from the control of the big LLM companies, or just enjoy tinkering, local models offer a compelling alternative to ChatGPT and its web-based peers. Here’s how to get started running a useful model from the safety and comfort of your own computer.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is part of MIT Technology Review’s How To series, helping you get things done. You can check out the &lt;/strong&gt;&lt;strong&gt;rest of the series here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;A brief history of “three-parent babies”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This week we heard that eight babies have been born in the UK following an experimental form of IVF that involves DNA from three people. The approach was used to prevent women with genetic mutations from passing mitochondrial diseases to their children.&lt;/p&gt;&lt;p&gt;But these eight babies aren’t the first “three-parent” children out there. Over the last decade, several teams have been using variations of this approach to help people have babies. But the procedure is not without controversy. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 OpenAI has launched ChatGPT Agent&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It undertakes tasks on your behalf by building its own “virtual computer.” (The Verge)&lt;br /&gt;+ &lt;em&gt;It may take a while to actually complete them. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Are we ready to hand AI agents the keys? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The White House is going after “woke AI”&lt;/strong&gt;&lt;br /&gt;It’s preparing an executive order preventing companies with “liberal bias” in their models from landing federal contracts. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Why it’s impossible to build an unbiased AI language model. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 A new law in Russia criminalizes certain online searches&lt;/strong&gt;&lt;br /&gt;Looking up LGBT content, for example, could land Russians in big trouble. (WP $)&lt;br /&gt;+ &lt;em&gt;Dozens of Russian regions have been hit with cellphone internet shutdowns. &lt;/em&gt;(ABC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Elon Musk wants to detonate SpaceX rockets over Hawaii’s waters&lt;/strong&gt;&lt;br /&gt;Even though the proposed area is a sacred Hawaiian religious site. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Rivals are rising to challenge the dominance of SpaceX. &lt;/em&gt;(MIT Technology Review) &lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Meta’s privacy violation trial is over&lt;br /&gt;&lt;/strong&gt;The shareholders suing Mark Zuckerberg and other officials have settled for a (likely very hefty) payout. (Reuters)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Inside ICE’s powerful facial recognition app&lt;/strong&gt;&lt;br /&gt;Mobile Fortify can check a person’s face against a database of 200 million images. (404 Media)&lt;br /&gt;+ &lt;em&gt;The department has unprecedented access to Medicaid data, too. &lt;/em&gt;(Wired $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;7 DOGE has left federal workers exhausted and anxious&lt;br /&gt;&lt;/strong&gt;Six months in, workers are struggling to cope with the fall out. (Insider $)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Netflix has used generative AI in a show for the first time&lt;br /&gt;&lt;/strong&gt;To cut costs, apparently. (BBC)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Does AI really spell the end of loneliness?&lt;/strong&gt;&lt;br /&gt;Virtual companions aren’t always what they’re cracked up to be. (New Yorker $)&lt;br /&gt;+ &lt;em&gt;The AI relationship revolution is already here. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Flip phones are back with a vengeance&lt;/strong&gt;&lt;br /&gt;At least they’re more interesting to look at than a conventional smartphone. (Vox)&lt;br /&gt;+ &lt;em&gt;Triple-folding phones might be a bridge too far, though. &lt;/em&gt;(The Verge)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It is far from perfect.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Kevin Weil, OpenAI’s chief product officer, acknowledges that its new agent still requires a lot of work, Bloomberg reports.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfqQhqd13URJa-FGrqIk0toLkb150vdRBjCGoETIjYCn0c37-XrueisWOO4BH5lF7zaJNV6iKG5fFUpBCYlz9LvF2TMqNOrI22yIqGavdK0gjsisX_9lTeeOEENpdcZ7n4FBsq2?key=BmQhKe9Tv4C1O_dor-ofgA" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;GMOs could reboot chestnut trees&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Living as long as a thousand years, the American chestnut tree once dominated parts of the Eastern forest canopy, with many Native American nations relying on them for food. But by 1950, the tree had largely succumbed to a fungal blight probably introduced by Japanese chestnuts.&lt;/p&gt;&lt;p&gt;As recently as last year, it seemed the 35-year effort to revive the American chestnut might grind to a halt. Now, American Castanea, a new biotech startup, has created more than 2,500 transgenic chestnut seedlings— likely the first genetically modified trees to be considered for federal regulatory approval as a tool for ecological restoration. Read the full story.&lt;/p&gt;  &lt;p&gt;&amp;nbsp;&lt;em&gt;—Anya Kamenetz&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ This stained glass embedded into a rusted old Porsche is strangely beautiful.&lt;br /&gt;+ Uhoh: here comes the next annoying group of people to avoid, the Normans.&lt;br /&gt;+ I bet Dolly Parton knows a thing or two about how to pack for a trip.&lt;br /&gt;+ Aww—orcas have been known to share food with humans in the wild.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How to run an LLM on your laptop&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In the early days of large language models, there was a high barrier to entry: it used to be impossible to run anything useful on your own computer without investing in pricey GPUs. But researchers have had so much success in shrinking down and speeding up models that anyone with a laptop, or even a smartphone, can now get in on the action.&lt;/p&gt;&lt;p&gt;For people who are concerned about privacy, want to break free from the control of the big LLM companies, or just enjoy tinkering, local models offer a compelling alternative to ChatGPT and its web-based peers. Here’s how to get started running a useful model from the safety and comfort of your own computer.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is part of MIT Technology Review’s How To series, helping you get things done. You can check out the &lt;/strong&gt;&lt;strong&gt;rest of the series here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;A brief history of “three-parent babies”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;This week we heard that eight babies have been born in the UK following an experimental form of IVF that involves DNA from three people. The approach was used to prevent women with genetic mutations from passing mitochondrial diseases to their children.&lt;/p&gt;&lt;p&gt;But these eight babies aren’t the first “three-parent” children out there. Over the last decade, several teams have been using variations of this approach to help people have babies. But the procedure is not without controversy. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 OpenAI has launched ChatGPT Agent&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It undertakes tasks on your behalf by building its own “virtual computer.” (The Verge)&lt;br /&gt;+ &lt;em&gt;It may take a while to actually complete them. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Are we ready to hand AI agents the keys? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 The White House is going after “woke AI”&lt;/strong&gt;&lt;br /&gt;It’s preparing an executive order preventing companies with “liberal bias” in their models from landing federal contracts. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Why it’s impossible to build an unbiased AI language model. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 A new law in Russia criminalizes certain online searches&lt;/strong&gt;&lt;br /&gt;Looking up LGBT content, for example, could land Russians in big trouble. (WP $)&lt;br /&gt;+ &lt;em&gt;Dozens of Russian regions have been hit with cellphone internet shutdowns. &lt;/em&gt;(ABC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Elon Musk wants to detonate SpaceX rockets over Hawaii’s waters&lt;/strong&gt;&lt;br /&gt;Even though the proposed area is a sacred Hawaiian religious site. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Rivals are rising to challenge the dominance of SpaceX. &lt;/em&gt;(MIT Technology Review) &lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Meta’s privacy violation trial is over&lt;br /&gt;&lt;/strong&gt;The shareholders suing Mark Zuckerberg and other officials have settled for a (likely very hefty) payout. (Reuters)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Inside ICE’s powerful facial recognition app&lt;/strong&gt;&lt;br /&gt;Mobile Fortify can check a person’s face against a database of 200 million images. (404 Media)&lt;br /&gt;+ &lt;em&gt;The department has unprecedented access to Medicaid data, too. &lt;/em&gt;(Wired $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;7 DOGE has left federal workers exhausted and anxious&lt;br /&gt;&lt;/strong&gt;Six months in, workers are struggling to cope with the fall out. (Insider $)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Netflix has used generative AI in a show for the first time&lt;br /&gt;&lt;/strong&gt;To cut costs, apparently. (BBC)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Does AI really spell the end of loneliness?&lt;/strong&gt;&lt;br /&gt;Virtual companions aren’t always what they’re cracked up to be. (New Yorker $)&lt;br /&gt;+ &lt;em&gt;The AI relationship revolution is already here. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Flip phones are back with a vengeance&lt;/strong&gt;&lt;br /&gt;At least they’re more interesting to look at than a conventional smartphone. (Vox)&lt;br /&gt;+ &lt;em&gt;Triple-folding phones might be a bridge too far, though. &lt;/em&gt;(The Verge)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It is far from perfect.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Kevin Weil, OpenAI’s chief product officer, acknowledges that its new agent still requires a lot of work, Bloomberg reports.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfqQhqd13URJa-FGrqIk0toLkb150vdRBjCGoETIjYCn0c37-XrueisWOO4BH5lF7zaJNV6iKG5fFUpBCYlz9LvF2TMqNOrI22yIqGavdK0gjsisX_9lTeeOEENpdcZ7n4FBsq2?key=BmQhKe9Tv4C1O_dor-ofgA" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;GMOs could reboot chestnut trees&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Living as long as a thousand years, the American chestnut tree once dominated parts of the Eastern forest canopy, with many Native American nations relying on them for food. But by 1950, the tree had largely succumbed to a fungal blight probably introduced by Japanese chestnuts.&lt;/p&gt;&lt;p&gt;As recently as last year, it seemed the 35-year effort to revive the American chestnut might grind to a halt. Now, American Castanea, a new biotech startup, has created more than 2,500 transgenic chestnut seedlings— likely the first genetically modified trees to be considered for federal regulatory approval as a tool for ecological restoration. Read the full story.&lt;/p&gt;  &lt;p&gt;&amp;nbsp;&lt;em&gt;—Anya Kamenetz&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ This stained glass embedded into a rusted old Porsche is strangely beautiful.&lt;br /&gt;+ Uhoh: here comes the next annoying group of people to avoid, the Normans.&lt;br /&gt;+ I bet Dolly Parton knows a thing or two about how to pack for a trip.&lt;br /&gt;+ Aww—orcas have been known to share food with humans in the wild.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/18/1120453/the-download-how-to-run-an-llm-and-a-history-of-three-parent-babies/</guid><pubDate>Fri, 18 Jul 2025 12:10:00 +0000</pubDate></item><item><title>Netflix starts using GenAI in its shows and films (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/18/netflix-starts-using-genai-in-its-shows-and-films/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/02/GettyImages-1240099721.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Companies developing video AI models and tools often talk about working with Hollywood studios to make certain workflows possible. On Thursday, Netflix said that it has started using AI in movies and shows it produces.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking at the company’s post-results conference call, the company’s co-CEO, Ted Sarandos, said that the platform had “the very first GenAI final footage to appear on screen” in an Argentine show called “&lt;em&gt;El Eternauta&lt;/em&gt;.” He noted that Netflix’s internal production group teamed up with producers to use AI to create a scene of a building collapsing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sarandos said that using AI, the scene was finished 10 times faster than it would have with traditional visual effect tools, and that it cost less.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We remain convinced that AI represents an incredible opportunity to help creators make films and series better, not just cheaper. There are AI-powered creator tools. So this is real people doing real work with better tools. Our creators are already seeing the benefits in production through pre-visualization and shot-planning work, and certainly visual effects. It used to be that only big-budget projects would have access to advanced visual effects like de-aging,” he said during the call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Co-CEO Greg Peters said Netflix is using gen AI in other areas as well, including personalization, search and ads, and that the company aims to roll out interactive ads in the second half of this year. Earlier this year, the company rolled out AI-powered search.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the second quarter, Netflix reported revenue of $11.08 billion, up 16% from a year earlier, and profit of $3.13 billion. It noted that users watched over 95 billion hours of content in the first half of 2025, with non-English titles accounting for one-third of all its views.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/02/GettyImages-1240099721.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Companies developing video AI models and tools often talk about working with Hollywood studios to make certain workflows possible. On Thursday, Netflix said that it has started using AI in movies and shows it produces.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking at the company’s post-results conference call, the company’s co-CEO, Ted Sarandos, said that the platform had “the very first GenAI final footage to appear on screen” in an Argentine show called “&lt;em&gt;El Eternauta&lt;/em&gt;.” He noted that Netflix’s internal production group teamed up with producers to use AI to create a scene of a building collapsing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sarandos said that using AI, the scene was finished 10 times faster than it would have with traditional visual effect tools, and that it cost less.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We remain convinced that AI represents an incredible opportunity to help creators make films and series better, not just cheaper. There are AI-powered creator tools. So this is real people doing real work with better tools. Our creators are already seeing the benefits in production through pre-visualization and shot-planning work, and certainly visual effects. It used to be that only big-budget projects would have access to advanced visual effects like de-aging,” he said during the call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Co-CEO Greg Peters said Netflix is using gen AI in other areas as well, including personalization, search and ads, and that the company aims to roll out interactive ads in the second half of this year. Earlier this year, the company rolled out AI-powered search.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the second quarter, Netflix reported revenue of $11.08 billion, up 16% from a year earlier, and profit of $3.13 billion. It noted that users watched over 95 billion hours of content in the first half of 2025, with non-English titles accounting for one-third of all its views.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/18/netflix-starts-using-genai-in-its-shows-and-films/</guid><pubDate>Fri, 18 Jul 2025 12:21:46 +0000</pubDate></item><item><title>[NEW] Salesforce used AI to cut support load by 5% — but the real win was teaching bots to say ‘I’m sorry’ (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/salesforce-used-ai-to-cut-support-load-by-5-but-the-real-win-was-teaching-bots-to-say-im-sorry/</link><description>&lt;p&gt;Salesforce has crossed a significant threshold in the enterprise AI race, surpassing 1 million autonomous agent conversations on its help portal — a milestone that offers a rare glimpse into what it takes to deploy AI agents at massive scale and the surprising lessons learned along the way.&lt;/p&gt;&lt;p&gt;The achievement, confirmed by company executives in exclusive interviews with VentureBeat, comes just nine months after Salesforce launched Agentforce on its Help Portal in October. The platform now resolves 84% of customer queries autonomously, has led to a 5% reduction in support case volume, and enabled the company to redeploy 500 human support engineers to higher-value roles.&lt;/p&gt;&lt;p&gt;But perhaps more valuable than the raw numbers are the hard-won insights Salesforce gleaned from being what executives call “customer zero” for their own AI agent technology — lessons that challenge conventional wisdom about enterprise AI deployment and reveal the delicate balance required between technological capability and human empathy.&lt;/p&gt;&lt;p&gt;“We started really small. We launched basically to a cohort of customers on our Help Portal. It had to be English to start with. You had to be logged in and we released it to about 10% of our traffic,” explains Bernard Slowey, SVP of Digital Customer Success at Salesforce, who led the Agentforce implementation. “The first week, I think there was 126 conversations, if I remember rightly. So me and my team could read through each one of them.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This methodical approach — starting with a controlled rollout before expanding to handle the current average of 45,000 conversations weekly — stands in stark contrast to the “move fast and break things” ethos often associated with AI deployment. The phased release allowed Salesforce to identify and fix critical issues before they could impact the broader customer base.&lt;/p&gt;



&lt;p&gt;The technical foundation proved crucial. Unlike traditional chatbots that rely on decision trees and pre-programmed responses, Agentforce leverages Salesforce’s Data Cloud to access and synthesize information from 740,000 pieces of content across multiple languages and product lines.&lt;/p&gt;



&lt;p&gt;“The biggest difference here is, coming back to my data cloud thing is we were able to go out the gate and answer pretty much any question about any Salesforce product,” Slowey notes. “I don’t think we could have done it without data cloud.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-salesforce-taught-its-ai-agents-empathy-after-customers-rejected-cold-robotic-responses"&gt;&lt;strong&gt;Why Salesforce taught its AI agents empathy after customers rejected cold, robotic responses&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;One of the most striking revelations from Salesforce’s journey involves what Joe Inzerillo, the company’s Chief Digital Officer, calls “the human part” of being a support agent.&lt;/p&gt;



&lt;p&gt;“When we first launched the agent, we were really concerned about, like, data factualism, you know, what is it getting the right data? Is it given the right answers and stuff like that? And what we realized is we kind of forgot about the human part,” Inzerillo reveals. “Somebody calls down and they’re like, hey, my stuff’s broken. I have a sub one incident right now, and you just come into like, ‘All right, well, I’ll open a ticket for you.’ It doesn’t feel great.”&lt;/p&gt;



&lt;p&gt;This realization led to a fundamental shift in how Salesforce approached AI agent design. The company took its existing soft skills training program for human support engineers—what they call “the art of service” — and integrated it directly into Agentforce’s prompts and behaviors.&lt;/p&gt;



&lt;p&gt;“If you come now and say, ‘Hey, I’m having a Salesforce outage,’ Agentforce will apologize. ‘I’m so sorry. Like, that’s terrible. Let me get you through,’ and we’ll get that through to our engineering team,” Slowey explains. The impact on customer satisfaction was immediate and measurable.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-surprising-reason-salesforce-increased-human-handoffs-from-1-to-5-for-better-customer-outcomes"&gt;&lt;strong&gt;The surprising reason Salesforce increased human handoffs from 1% to 5% for better customer outcomes&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Perhaps no metric better illustrates the complexity of deploying enterprise AI agents than Salesforce’s evolving approach to human handoffs. Initially, the company celebrated a 1% handoff rate — meaning only 1% of conversations were escalated from AI to human agents.&lt;/p&gt;



&lt;p&gt;“We were literally high fiving each other, going, ‘oh my god, like only 1%,'” Slowey recalls. “And then we look at the actual conversation. Was terrible. People were frustrated. They wanted to go to a human. The agent kept trying. It was just getting in the way.”&lt;/p&gt;



&lt;p&gt;This led to a counterintuitive insight: making it harder for customers to reach humans actually degraded the overall experience. Salesforce adjusted its approach, and the handoff rate rose to approximately 5%.&lt;/p&gt;



&lt;p&gt;“I actually feel really good about that,” Slowey emphasizes. “If you want to create a case, you want to talk to a support engineer, that’s fine. Go ahead and do that.”&lt;/p&gt;



&lt;p&gt;Inzerillo frames this as a fundamental shift in thinking about service metrics: “At 5% you really did get the vast, vast, vast majority in that 95% solved, and the people who didn’t got to a human faster. And so therefore their CSAT went up in the hybrid approach, where you had an agent and a human working together, you got better results than each of them had independently.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-content-collisions-forced-salesforce-to-delete-thousands-of-help-articles-for-ai-accuracy"&gt;&lt;strong&gt;How ‘content collisions’ forced Salesforce to delete thousands of help articles for AI accuracy&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Salesforce’s experience also revealed critical lessons about content management that many enterprises overlook when deploying AI. Despite having 740,000 pieces of content across multiple languages, the company discovered that abundance created its own problems.&lt;/p&gt;



&lt;p&gt;“There’s this words my team has been using that are new words to me, of content collisions,” Slowey explains. “Loads of password reset articles. And so it struggles on what’s the right article for me to take the chunks into Data Cloud and go to OpenAI and back and answer?”&lt;/p&gt;



&lt;p&gt;This led to an extensive “content hygiene” initiative where Salesforce deleted outdated content, fixed inaccuracies, and consolidated redundant articles. The lesson: AI agents are only as good as the knowledge they can access, and sometimes less is more.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-microsoft-teams-integration-that-exposed-why-rigid-ai-guardrails-backfire"&gt;&lt;strong&gt;The Microsoft Teams integration that exposed why rigid AI guardrails backfire&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;One of the most enlightening mistakes Salesforce made involved being overly restrictive with AI guardrails. Initially, the company instructed Agentforce not to discuss competitors, listing every major rival by name.&lt;/p&gt;



&lt;p&gt;“We were worried people were going to come in and go, ‘is HubSpot better than Salesforce’ or something like that,” Slowey admits. But this created an unexpected problem: when customers asked legitimate questions about integrating Microsoft Teams with Salesforce, the agent refused to answer because Microsoft was on the competitor list.&lt;/p&gt;



&lt;p&gt;The solution was elegantly simple: instead of rigid rules, Salesforce replaced the restrictive guardrails with a single instruction to “act in Salesforce’s best interest in everything you do.”&lt;/p&gt;



&lt;p&gt;“We realized we were still treating it like an old school chatbot, and what we needed to do is we needed to let the LLM be an LLM,” Slowey reflects.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-voice-interfaces-and-multilingual-support-drive-salesforce-s-next-phase-of-ai-agent-evolution"&gt;&lt;strong&gt;Voice interfaces and multilingual support drive Salesforce’s next phase of AI agent evolution&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Looking ahead, Salesforce is preparing for what both executives see as the next major evolution in AI agents: voice interfaces.&lt;/p&gt;



&lt;p&gt;“I actually believe voice is the UX of agents,” Slowey states. The company is developing iOS and Android native apps with voice capabilities, with plans to showcase them at Dreamforce later this year.&lt;/p&gt;



&lt;p&gt;Inzerillo, drawing on his experience leading digital transformation at Disney, adds crucial context: “What’s important about voice is to understand that the chat is really foundational to the voice. Because chat, like, you still have to have all your information, you still have to have all those rules… If you jump right to voice, the real problem with voice is it’s got to be very fast and it’s got to be very accurate.”&lt;/p&gt;



&lt;p&gt;The company has already expanded Agentforce to support Japanese using an innovative approach—rather than translating content, the system translates customer queries to English, retrieves relevant information, and translates responses back. With 87% resolution rates in Japanese after just three weeks, Salesforce plans to add French, German, Italian, and Spanish support by the end of July.&lt;/p&gt;



&lt;h2 class="wp-block-heading"&gt;Four critical lessons from Salesforce’s million-conversation journey for enterprise AI deployment&lt;/h2&gt;



&lt;p&gt;For enterprises considering their own AI agent deployments, Salesforce’s journey offers several critical insights:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Start Small, Think Big&lt;/strong&gt;: “Start small and then grow it out,” Slowey advises. The ability to review every conversation in early stages provides invaluable learning opportunities that would be impossible at scale.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Data Hygiene Matters&lt;/strong&gt;: “Be really conscious of your data,” Inzerillo emphasizes. “Don’t over curate your data, but also don’t under curate your data and really think through, like, how do you best position the company?”&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Embrace Flexibility&lt;/strong&gt;: Traditional organizational structures may not align with AI capabilities. As Inzerillo notes, “If they try to take an agentic future and shove it into yesterday’s org chart, it’s going to be a very frustrating experience.”&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Measure What Matters&lt;/strong&gt;: Success metrics for AI agents differ from traditional support metrics. Response accuracy is important, but so are empathy, appropriate escalation, and overall customer satisfaction.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-the-billion-dollar-question-what-happens-after-you-beat-human-performance"&gt;&lt;strong&gt;The billion-dollar question: what happens after you beat human performance?&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;As Salesforce’s AI agents now outperform human agents on key metrics like resolution rate and handle time, Inzerillo poses a thought-provoking question: “What do you measure after you beat the human?”&lt;/p&gt;



&lt;p&gt;This question gets to the heart of what may be the most significant implication of Salesforce’s million-conversation milestone. The company isn’t just automating customer service—it’s redefining what good service looks like in an AI-first world.&lt;/p&gt;



&lt;p&gt;“We wanted to be the showcase to our customers and how we use Agentforce in our own experiences,” Slowey explains. “Part of why we do this… is so that we can learn these things, feed it back into our product teams, into our engineering teams to improve the product and then share these learnings with our customers.”&lt;/p&gt;



&lt;p&gt;With enterprise spending on generative AI solutions projected to reach $143 billion by 2027, according to forecasts from International Data Corporation (IDC), Salesforce’s real-world lessons from the frontlines of deployment offer a crucial roadmap for organizations navigating their own AI transformations. Deloitte also estimates that global enterprise investments in generative AI could surpass $150 billion by 2027, reinforcing the scale and urgency of this technological shift.&lt;/p&gt;



&lt;p&gt;The message is clear: success in the AI agent era requires more than just sophisticated technology. It demands a fundamental rethinking of how humans and machines work together, a commitment to continuous learning and iteration, and perhaps most surprisingly, a recognition that the most advanced AI agents are those that remember to be human.&lt;/p&gt;



&lt;p&gt;As Slowey puts it: “You now have two employees. You have an agentic AI agent, and you have a human employee. You need to train both on the soft skills, the art of service.”&lt;/p&gt;



&lt;p&gt;In the end, Salesforce’s million conversations may be less about the milestone itself and more about what it represents: the emergence of a new paradigm where digital labor doesn’t replace human work but transforms it, creating possibilities that neither humans nor machines could achieve alone.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Salesforce has crossed a significant threshold in the enterprise AI race, surpassing 1 million autonomous agent conversations on its help portal — a milestone that offers a rare glimpse into what it takes to deploy AI agents at massive scale and the surprising lessons learned along the way.&lt;/p&gt;&lt;p&gt;The achievement, confirmed by company executives in exclusive interviews with VentureBeat, comes just nine months after Salesforce launched Agentforce on its Help Portal in October. The platform now resolves 84% of customer queries autonomously, has led to a 5% reduction in support case volume, and enabled the company to redeploy 500 human support engineers to higher-value roles.&lt;/p&gt;&lt;p&gt;But perhaps more valuable than the raw numbers are the hard-won insights Salesforce gleaned from being what executives call “customer zero” for their own AI agent technology — lessons that challenge conventional wisdom about enterprise AI deployment and reveal the delicate balance required between technological capability and human empathy.&lt;/p&gt;&lt;p&gt;“We started really small. We launched basically to a cohort of customers on our Help Portal. It had to be English to start with. You had to be logged in and we released it to about 10% of our traffic,” explains Bernard Slowey, SVP of Digital Customer Success at Salesforce, who led the Agentforce implementation. “The first week, I think there was 126 conversations, if I remember rightly. So me and my team could read through each one of them.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This methodical approach — starting with a controlled rollout before expanding to handle the current average of 45,000 conversations weekly — stands in stark contrast to the “move fast and break things” ethos often associated with AI deployment. The phased release allowed Salesforce to identify and fix critical issues before they could impact the broader customer base.&lt;/p&gt;



&lt;p&gt;The technical foundation proved crucial. Unlike traditional chatbots that rely on decision trees and pre-programmed responses, Agentforce leverages Salesforce’s Data Cloud to access and synthesize information from 740,000 pieces of content across multiple languages and product lines.&lt;/p&gt;



&lt;p&gt;“The biggest difference here is, coming back to my data cloud thing is we were able to go out the gate and answer pretty much any question about any Salesforce product,” Slowey notes. “I don’t think we could have done it without data cloud.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-salesforce-taught-its-ai-agents-empathy-after-customers-rejected-cold-robotic-responses"&gt;&lt;strong&gt;Why Salesforce taught its AI agents empathy after customers rejected cold, robotic responses&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;One of the most striking revelations from Salesforce’s journey involves what Joe Inzerillo, the company’s Chief Digital Officer, calls “the human part” of being a support agent.&lt;/p&gt;



&lt;p&gt;“When we first launched the agent, we were really concerned about, like, data factualism, you know, what is it getting the right data? Is it given the right answers and stuff like that? And what we realized is we kind of forgot about the human part,” Inzerillo reveals. “Somebody calls down and they’re like, hey, my stuff’s broken. I have a sub one incident right now, and you just come into like, ‘All right, well, I’ll open a ticket for you.’ It doesn’t feel great.”&lt;/p&gt;



&lt;p&gt;This realization led to a fundamental shift in how Salesforce approached AI agent design. The company took its existing soft skills training program for human support engineers—what they call “the art of service” — and integrated it directly into Agentforce’s prompts and behaviors.&lt;/p&gt;



&lt;p&gt;“If you come now and say, ‘Hey, I’m having a Salesforce outage,’ Agentforce will apologize. ‘I’m so sorry. Like, that’s terrible. Let me get you through,’ and we’ll get that through to our engineering team,” Slowey explains. The impact on customer satisfaction was immediate and measurable.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-surprising-reason-salesforce-increased-human-handoffs-from-1-to-5-for-better-customer-outcomes"&gt;&lt;strong&gt;The surprising reason Salesforce increased human handoffs from 1% to 5% for better customer outcomes&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Perhaps no metric better illustrates the complexity of deploying enterprise AI agents than Salesforce’s evolving approach to human handoffs. Initially, the company celebrated a 1% handoff rate — meaning only 1% of conversations were escalated from AI to human agents.&lt;/p&gt;



&lt;p&gt;“We were literally high fiving each other, going, ‘oh my god, like only 1%,'” Slowey recalls. “And then we look at the actual conversation. Was terrible. People were frustrated. They wanted to go to a human. The agent kept trying. It was just getting in the way.”&lt;/p&gt;



&lt;p&gt;This led to a counterintuitive insight: making it harder for customers to reach humans actually degraded the overall experience. Salesforce adjusted its approach, and the handoff rate rose to approximately 5%.&lt;/p&gt;



&lt;p&gt;“I actually feel really good about that,” Slowey emphasizes. “If you want to create a case, you want to talk to a support engineer, that’s fine. Go ahead and do that.”&lt;/p&gt;



&lt;p&gt;Inzerillo frames this as a fundamental shift in thinking about service metrics: “At 5% you really did get the vast, vast, vast majority in that 95% solved, and the people who didn’t got to a human faster. And so therefore their CSAT went up in the hybrid approach, where you had an agent and a human working together, you got better results than each of them had independently.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-content-collisions-forced-salesforce-to-delete-thousands-of-help-articles-for-ai-accuracy"&gt;&lt;strong&gt;How ‘content collisions’ forced Salesforce to delete thousands of help articles for AI accuracy&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Salesforce’s experience also revealed critical lessons about content management that many enterprises overlook when deploying AI. Despite having 740,000 pieces of content across multiple languages, the company discovered that abundance created its own problems.&lt;/p&gt;



&lt;p&gt;“There’s this words my team has been using that are new words to me, of content collisions,” Slowey explains. “Loads of password reset articles. And so it struggles on what’s the right article for me to take the chunks into Data Cloud and go to OpenAI and back and answer?”&lt;/p&gt;



&lt;p&gt;This led to an extensive “content hygiene” initiative where Salesforce deleted outdated content, fixed inaccuracies, and consolidated redundant articles. The lesson: AI agents are only as good as the knowledge they can access, and sometimes less is more.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-microsoft-teams-integration-that-exposed-why-rigid-ai-guardrails-backfire"&gt;&lt;strong&gt;The Microsoft Teams integration that exposed why rigid AI guardrails backfire&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;One of the most enlightening mistakes Salesforce made involved being overly restrictive with AI guardrails. Initially, the company instructed Agentforce not to discuss competitors, listing every major rival by name.&lt;/p&gt;



&lt;p&gt;“We were worried people were going to come in and go, ‘is HubSpot better than Salesforce’ or something like that,” Slowey admits. But this created an unexpected problem: when customers asked legitimate questions about integrating Microsoft Teams with Salesforce, the agent refused to answer because Microsoft was on the competitor list.&lt;/p&gt;



&lt;p&gt;The solution was elegantly simple: instead of rigid rules, Salesforce replaced the restrictive guardrails with a single instruction to “act in Salesforce’s best interest in everything you do.”&lt;/p&gt;



&lt;p&gt;“We realized we were still treating it like an old school chatbot, and what we needed to do is we needed to let the LLM be an LLM,” Slowey reflects.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-voice-interfaces-and-multilingual-support-drive-salesforce-s-next-phase-of-ai-agent-evolution"&gt;&lt;strong&gt;Voice interfaces and multilingual support drive Salesforce’s next phase of AI agent evolution&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Looking ahead, Salesforce is preparing for what both executives see as the next major evolution in AI agents: voice interfaces.&lt;/p&gt;



&lt;p&gt;“I actually believe voice is the UX of agents,” Slowey states. The company is developing iOS and Android native apps with voice capabilities, with plans to showcase them at Dreamforce later this year.&lt;/p&gt;



&lt;p&gt;Inzerillo, drawing on his experience leading digital transformation at Disney, adds crucial context: “What’s important about voice is to understand that the chat is really foundational to the voice. Because chat, like, you still have to have all your information, you still have to have all those rules… If you jump right to voice, the real problem with voice is it’s got to be very fast and it’s got to be very accurate.”&lt;/p&gt;



&lt;p&gt;The company has already expanded Agentforce to support Japanese using an innovative approach—rather than translating content, the system translates customer queries to English, retrieves relevant information, and translates responses back. With 87% resolution rates in Japanese after just three weeks, Salesforce plans to add French, German, Italian, and Spanish support by the end of July.&lt;/p&gt;



&lt;h2 class="wp-block-heading"&gt;Four critical lessons from Salesforce’s million-conversation journey for enterprise AI deployment&lt;/h2&gt;



&lt;p&gt;For enterprises considering their own AI agent deployments, Salesforce’s journey offers several critical insights:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Start Small, Think Big&lt;/strong&gt;: “Start small and then grow it out,” Slowey advises. The ability to review every conversation in early stages provides invaluable learning opportunities that would be impossible at scale.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Data Hygiene Matters&lt;/strong&gt;: “Be really conscious of your data,” Inzerillo emphasizes. “Don’t over curate your data, but also don’t under curate your data and really think through, like, how do you best position the company?”&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Embrace Flexibility&lt;/strong&gt;: Traditional organizational structures may not align with AI capabilities. As Inzerillo notes, “If they try to take an agentic future and shove it into yesterday’s org chart, it’s going to be a very frustrating experience.”&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Measure What Matters&lt;/strong&gt;: Success metrics for AI agents differ from traditional support metrics. Response accuracy is important, but so are empathy, appropriate escalation, and overall customer satisfaction.&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-the-billion-dollar-question-what-happens-after-you-beat-human-performance"&gt;&lt;strong&gt;The billion-dollar question: what happens after you beat human performance?&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;As Salesforce’s AI agents now outperform human agents on key metrics like resolution rate and handle time, Inzerillo poses a thought-provoking question: “What do you measure after you beat the human?”&lt;/p&gt;



&lt;p&gt;This question gets to the heart of what may be the most significant implication of Salesforce’s million-conversation milestone. The company isn’t just automating customer service—it’s redefining what good service looks like in an AI-first world.&lt;/p&gt;



&lt;p&gt;“We wanted to be the showcase to our customers and how we use Agentforce in our own experiences,” Slowey explains. “Part of why we do this… is so that we can learn these things, feed it back into our product teams, into our engineering teams to improve the product and then share these learnings with our customers.”&lt;/p&gt;



&lt;p&gt;With enterprise spending on generative AI solutions projected to reach $143 billion by 2027, according to forecasts from International Data Corporation (IDC), Salesforce’s real-world lessons from the frontlines of deployment offer a crucial roadmap for organizations navigating their own AI transformations. Deloitte also estimates that global enterprise investments in generative AI could surpass $150 billion by 2027, reinforcing the scale and urgency of this technological shift.&lt;/p&gt;



&lt;p&gt;The message is clear: success in the AI agent era requires more than just sophisticated technology. It demands a fundamental rethinking of how humans and machines work together, a commitment to continuous learning and iteration, and perhaps most surprisingly, a recognition that the most advanced AI agents are those that remember to be human.&lt;/p&gt;



&lt;p&gt;As Slowey puts it: “You now have two employees. You have an agentic AI agent, and you have a human employee. You need to train both on the soft skills, the art of service.”&lt;/p&gt;



&lt;p&gt;In the end, Salesforce’s million conversations may be less about the milestone itself and more about what it represents: the emergence of a new paradigm where digital labor doesn’t replace human work but transforms it, creating possibilities that neither humans nor machines could achieve alone.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/salesforce-used-ai-to-cut-support-load-by-5-but-the-real-win-was-teaching-bots-to-say-im-sorry/</guid><pubDate>Fri, 18 Jul 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] A major AI training data set contains millions of examples of personal data (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/18/1120466/a-major-ai-training-data-set-contains-millions-of-examples-of-personal-data/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Millions of images of passports, credit cards, birth certificates, and other documents containing personally identifiable information are likely included in one of the biggest open-source AI training sets, new research has found.&lt;/p&gt;  &lt;p&gt;Thousands of images—including identifiable faces—were found in a small subset of DataComp CommonPool, a major AI training set for image generation scraped from the web. Because the researchers audited just 0.1% of CommonPool’s data, they estimate that the real number of images containing personally identifiable information, including faces and identity documents, is in the hundreds of millions. The study that details the breach was published on arXiv earlier this month.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The bottom line, says William Agnew, a postdoctoral fellow in AI ethics at Carnegie Mellon University and one of the coauthors, is that “anything you put online can [be] and probably has been scraped.”&lt;/p&gt;  &lt;p&gt;The researchers found thousands of&lt;strong&gt; &lt;/strong&gt;instances of validated identity documents—including images of credit cards, driver’s licenses, passports, and birth certificates—as well as over 800 validated job application documents (including résumés and cover letters), which were confirmed through LinkedIn and other web searches as being associated with real people. (In many more cases, the researchers did not have time to validate the documents or were unable to because of issues like image clarity.)&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;A number of the résumés disclosed sensitive information including disability status, the results of background checks, birth dates and birthplaces of dependents, and race. When résumés were linked to people with online presences, researchers also found contact information, government identifiers, sociodemographic information, face photographs, home addresses, and the contact information of other people (like references).&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1120409" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/2506-5.jpeg?w=1744" /&gt;&lt;figcaption class="wp-element-caption"&gt;Examples of identity-related documents found in CommonPool’s small-scale data set show a credit card, a Social Security number, and a driver’s license. For each sample, the type of URL site is shown at the top, the image in the middle, and the caption in quotes below. All personal information has been replaced, and text has been paraphrased to avoid direct quotations. Images have been redacted to show the presence of faces without identifying the individuals.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE RESEARCHERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;When it was released in 2023, DataComp CommonPool, with its 12.8 billion data samples, was the largest existing data set of publicly available image-text pairs, which are often used to train generative text-to-image models. While its curators said that CommonPool was intended for academic research, its license does not prohibit commercial use as well.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;CommonPool was created as a follow-up to the LAION-5B data set, which was used to train models including Stable Diffusion and Midjourney. It draws on the same data source: web scraping done by the nonprofit Common Crawl between 2014 and 2022.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While commercial models often do not disclose what data sets they are trained on, the shared data sources of DataComp CommonPool and LAION-5B mean that the data sets are similar, and that the same personally identifiable information likely appears in LAION-5B, as well as in other downstream models trained on CommonPool data. CommonPool researchers did not respond to emailed questions.&lt;/p&gt;  &lt;p&gt;And since DataComp CommonPool has been downloaded more than 2 million times over the past two years, it is likely that “there [are]many downstream models that are all trained on this exact data set,” says Rachel Hong, a PhD student in computer science at the University of Washington and the paper’s lead author. Those would duplicate similar privacy risks.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Good intentions are not enough&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;“You can assume that any large-scale web-scraped data always contains content that shouldn’t be there,” says Abeba Birhane, a cognitive scientist and tech ethicist who leads Trinity College Dublin’s AI Accountability Lab—whether it’s personally identifiable information (PII), child sexual abuse imagery, or hate speech (which Birhane’s own research into LAION-5B has found).&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Indeed, the curators of DataComp CommonPool were themselves aware it was likely that PII would appear in the data set and did take some measures to preserve privacy, including automatically detecting and blurring faces. But in their limited data set, Hong’s team found and validated over 800 faces that the algorithm had missed, and they estimated that overall, the algorithm had missed 102 million faces in the entire data set. On the other hand, they did not apply filters that could have recognized known PII character strings, like emails or Social Security numbers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Filtering is extremely hard to do well,” says Agnew. “They would have had to make very significant advancements in PII detection and removal that they haven’t made public to be able to effectively filter this.”&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1120410" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/2506-7.jpeg?w=1553" /&gt;&lt;figcaption class="wp-element-caption"&gt;Examples of résumé documents and personal disclosures found in CommonPool’s small-scale data set. For each sample, the type of URL site is shown at the top, the image in the middle, and the caption in quotes below. All personal information has been replaced, and text has been paraphrased to avoid direct quotations. Images have been redacted to show the presence of faces without identifying the individuals. Image courtesy of the researchers.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE RESEARCHERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;There are other privacy issues that the face blurring doesn’t address. While the blurring filter is automatically applied, it is optional and can be removed. Additionally, the captions that often accompany the photos, as well as the photos’ metadata, often contain even more personal information, such as names and exact locations.&lt;/p&gt;  &lt;p&gt;Another privacy mitigation measure comes from Hugging Face, a platform that distributes training data sets and hosts CommonPool, which integrates with a tool that theoretically allows people to search for and remove their own information from a data set. But as the researchers note in their paper, this would require people to know that their data is there to start with. When asked for comment, Florent Daudens of Hugging Face said that “maximizing the privacy of data subjects across the AI ecosystem takes a multilayered approach, which includes but is not limited to the widget mentioned,” and that the platform is “working with our community of users to move the needle in a more privacy-grounded direction.”&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;In any case, just getting your data removed from one data set probably isn’t enough. “Even if someone finds out their data was used in a training data sets and … exercises their right to deletion, technically the law is unclear about what that means,” &amp;nbsp;says Tiffany Li, an associate professor of law at the University of San Francisco School of Law. “If the organization only deletes data from the training data sets—but does not delete or retrain the already trained model—then the harm will nonetheless be done.”&lt;/p&gt;  &lt;p&gt;The bottom line, says Agnew, is that “if you web-scrape, you’re going to have private data in there. Even if you filter, you’re still going to have private data in there, just because of the scale of this. And that’s something that we [machine-learning researchers], as a field, really need to grapple with.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Reconsidering consent&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;CommonPool was built on web data scraped between 2014 and 2022, meaning that many of the images likely date to before 2020, when ChatGPT was released. So even if it’s theoretically possible that some people consented to having their information publicly available to anyone on the web, they could not have consented to having their data used to train large AI models that did not yet exist.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;And with web scrapers often scraping data from each other, an image that was originally uploaded by the owner to one specific location would often find its way into other image repositories. “I might upload something onto the internet, and then … a year or so later, [I] want to take it down, but then that [removal] doesn’t necessarily do anything anymore,” says Agnew.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;The researchers also found numerous examples of children’s personal information, including depictions of birth certificates, passports, and health status, but in contexts suggesting that they had been shared for limited purposes.&lt;/p&gt;  &lt;p&gt;“It really illuminates the original sin of AI systems built off public data—it’s extractive, misleading, and dangerous to people who have been using the internet with one framework of risk, never assuming it would all be hoovered up by a group trying to create an image generator,” says Ben Winters, the director of AI and privacy at the Consumer Federation of America.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Finding a policy that fits&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Ultimately, the paper calls for the machine-learning community to rethink the common practice of indiscriminate web scraping and also lays out the possible violations of current privacy laws represented by the existence of PII in massive machine-learning data sets, as well as the limitations of those laws’ ability to protect privacy.&lt;/p&gt;  &lt;p&gt;“We have the GDPR in Europe, we have the CCPA in California, but there’s still no federal data protection law in America, which also means that different Americans have different rights protections,” says Marietje Schaake, a Dutch lawmaker turned tech policy expert who currently serves as a fellow at Stanford’s Cyber Policy Center.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Besides, these privacy laws apply to companies that meet certain criteria for size and other characteristics. They do not necessarily apply to researchers like those who were responsible for creating and curating DataComp CommonPool.&lt;/p&gt;  &lt;p&gt;And even state laws that do address privacy, like California’s consumer privacy act, have carve-outs for “publicly available” information. Machine-learning researchers have long operated on the principle that if it’s available on the internet, then it is public and no longer private information, but Hong, Agnew, and their colleagues hope that their research challenges this assumption.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“What we found is that ‘publicly available’ includes a lot of stuff that a lot of people might consider private—résumés, photos, credit card numbers, various IDs, news stories from when you were a child, your family blog. These are probably not things people want to just be used anywhere, for anything,” says Hong.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Hopefully, Schaake says, this research “will raise alarm bells and create change.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article previously misstated Tiffany Li's affiliation. This has been fixed. &lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Millions of images of passports, credit cards, birth certificates, and other documents containing personally identifiable information are likely included in one of the biggest open-source AI training sets, new research has found.&lt;/p&gt;  &lt;p&gt;Thousands of images—including identifiable faces—were found in a small subset of DataComp CommonPool, a major AI training set for image generation scraped from the web. Because the researchers audited just 0.1% of CommonPool’s data, they estimate that the real number of images containing personally identifiable information, including faces and identity documents, is in the hundreds of millions. The study that details the breach was published on arXiv earlier this month.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The bottom line, says William Agnew, a postdoctoral fellow in AI ethics at Carnegie Mellon University and one of the coauthors, is that “anything you put online can [be] and probably has been scraped.”&lt;/p&gt;  &lt;p&gt;The researchers found thousands of&lt;strong&gt; &lt;/strong&gt;instances of validated identity documents—including images of credit cards, driver’s licenses, passports, and birth certificates—as well as over 800 validated job application documents (including résumés and cover letters), which were confirmed through LinkedIn and other web searches as being associated with real people. (In many more cases, the researchers did not have time to validate the documents or were unable to because of issues like image clarity.)&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;A number of the résumés disclosed sensitive information including disability status, the results of background checks, birth dates and birthplaces of dependents, and race. When résumés were linked to people with online presences, researchers also found contact information, government identifiers, sociodemographic information, face photographs, home addresses, and the contact information of other people (like references).&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1120409" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/2506-5.jpeg?w=1744" /&gt;&lt;figcaption class="wp-element-caption"&gt;Examples of identity-related documents found in CommonPool’s small-scale data set show a credit card, a Social Security number, and a driver’s license. For each sample, the type of URL site is shown at the top, the image in the middle, and the caption in quotes below. All personal information has been replaced, and text has been paraphrased to avoid direct quotations. Images have been redacted to show the presence of faces without identifying the individuals.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE RESEARCHERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;When it was released in 2023, DataComp CommonPool, with its 12.8 billion data samples, was the largest existing data set of publicly available image-text pairs, which are often used to train generative text-to-image models. While its curators said that CommonPool was intended for academic research, its license does not prohibit commercial use as well.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;CommonPool was created as a follow-up to the LAION-5B data set, which was used to train models including Stable Diffusion and Midjourney. It draws on the same data source: web scraping done by the nonprofit Common Crawl between 2014 and 2022.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While commercial models often do not disclose what data sets they are trained on, the shared data sources of DataComp CommonPool and LAION-5B mean that the data sets are similar, and that the same personally identifiable information likely appears in LAION-5B, as well as in other downstream models trained on CommonPool data. CommonPool researchers did not respond to emailed questions.&lt;/p&gt;  &lt;p&gt;And since DataComp CommonPool has been downloaded more than 2 million times over the past two years, it is likely that “there [are]many downstream models that are all trained on this exact data set,” says Rachel Hong, a PhD student in computer science at the University of Washington and the paper’s lead author. Those would duplicate similar privacy risks.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Good intentions are not enough&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;“You can assume that any large-scale web-scraped data always contains content that shouldn’t be there,” says Abeba Birhane, a cognitive scientist and tech ethicist who leads Trinity College Dublin’s AI Accountability Lab—whether it’s personally identifiable information (PII), child sexual abuse imagery, or hate speech (which Birhane’s own research into LAION-5B has found).&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Indeed, the curators of DataComp CommonPool were themselves aware it was likely that PII would appear in the data set and did take some measures to preserve privacy, including automatically detecting and blurring faces. But in their limited data set, Hong’s team found and validated over 800 faces that the algorithm had missed, and they estimated that overall, the algorithm had missed 102 million faces in the entire data set. On the other hand, they did not apply filters that could have recognized known PII character strings, like emails or Social Security numbers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Filtering is extremely hard to do well,” says Agnew. “They would have had to make very significant advancements in PII detection and removal that they haven’t made public to be able to effectively filter this.”&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1120410" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/2506-7.jpeg?w=1553" /&gt;&lt;figcaption class="wp-element-caption"&gt;Examples of résumé documents and personal disclosures found in CommonPool’s small-scale data set. For each sample, the type of URL site is shown at the top, the image in the middle, and the caption in quotes below. All personal information has been replaced, and text has been paraphrased to avoid direct quotations. Images have been redacted to show the presence of faces without identifying the individuals. Image courtesy of the researchers.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF THE RESEARCHERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;There are other privacy issues that the face blurring doesn’t address. While the blurring filter is automatically applied, it is optional and can be removed. Additionally, the captions that often accompany the photos, as well as the photos’ metadata, often contain even more personal information, such as names and exact locations.&lt;/p&gt;  &lt;p&gt;Another privacy mitigation measure comes from Hugging Face, a platform that distributes training data sets and hosts CommonPool, which integrates with a tool that theoretically allows people to search for and remove their own information from a data set. But as the researchers note in their paper, this would require people to know that their data is there to start with. When asked for comment, Florent Daudens of Hugging Face said that “maximizing the privacy of data subjects across the AI ecosystem takes a multilayered approach, which includes but is not limited to the widget mentioned,” and that the platform is “working with our community of users to move the needle in a more privacy-grounded direction.”&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;In any case, just getting your data removed from one data set probably isn’t enough. “Even if someone finds out their data was used in a training data sets and … exercises their right to deletion, technically the law is unclear about what that means,” &amp;nbsp;says Tiffany Li, an associate professor of law at the University of San Francisco School of Law. “If the organization only deletes data from the training data sets—but does not delete or retrain the already trained model—then the harm will nonetheless be done.”&lt;/p&gt;  &lt;p&gt;The bottom line, says Agnew, is that “if you web-scrape, you’re going to have private data in there. Even if you filter, you’re still going to have private data in there, just because of the scale of this. And that’s something that we [machine-learning researchers], as a field, really need to grapple with.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Reconsidering consent&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;CommonPool was built on web data scraped between 2014 and 2022, meaning that many of the images likely date to before 2020, when ChatGPT was released. So even if it’s theoretically possible that some people consented to having their information publicly available to anyone on the web, they could not have consented to having their data used to train large AI models that did not yet exist.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;And with web scrapers often scraping data from each other, an image that was originally uploaded by the owner to one specific location would often find its way into other image repositories. “I might upload something onto the internet, and then … a year or so later, [I] want to take it down, but then that [removal] doesn’t necessarily do anything anymore,” says Agnew.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;The researchers also found numerous examples of children’s personal information, including depictions of birth certificates, passports, and health status, but in contexts suggesting that they had been shared for limited purposes.&lt;/p&gt;  &lt;p&gt;“It really illuminates the original sin of AI systems built off public data—it’s extractive, misleading, and dangerous to people who have been using the internet with one framework of risk, never assuming it would all be hoovered up by a group trying to create an image generator,” says Ben Winters, the director of AI and privacy at the Consumer Federation of America.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Finding a policy that fits&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Ultimately, the paper calls for the machine-learning community to rethink the common practice of indiscriminate web scraping and also lays out the possible violations of current privacy laws represented by the existence of PII in massive machine-learning data sets, as well as the limitations of those laws’ ability to protect privacy.&lt;/p&gt;  &lt;p&gt;“We have the GDPR in Europe, we have the CCPA in California, but there’s still no federal data protection law in America, which also means that different Americans have different rights protections,” says Marietje Schaake, a Dutch lawmaker turned tech policy expert who currently serves as a fellow at Stanford’s Cyber Policy Center.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Besides, these privacy laws apply to companies that meet certain criteria for size and other characteristics. They do not necessarily apply to researchers like those who were responsible for creating and curating DataComp CommonPool.&lt;/p&gt;  &lt;p&gt;And even state laws that do address privacy, like California’s consumer privacy act, have carve-outs for “publicly available” information. Machine-learning researchers have long operated on the principle that if it’s available on the internet, then it is public and no longer private information, but Hong, Agnew, and their colleagues hope that their research challenges this assumption.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“What we found is that ‘publicly available’ includes a lot of stuff that a lot of people might consider private—résumés, photos, credit card numbers, various IDs, news stories from when you were a child, your family blog. These are probably not things people want to just be used anywhere, for anything,” says Hong.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Hopefully, Schaake says, this research “will raise alarm bells and create change.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article previously misstated Tiffany Li's affiliation. This has been fixed. &lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/18/1120466/a-major-ai-training-data-set-contains-millions-of-examples-of-personal-data/</guid><pubDate>Fri, 18 Jul 2025 13:08:26 +0000</pubDate></item><item><title>[NEW] Meta refuses to sign EU’s AI code of practice (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/18/meta-refuses-to-sign-eus-ai-code-of-practice/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195497483.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta has refused to sign the European Union’s code of practice for its AI Act, weeks before the bloc’s rules for providers of general-purpose AI models take effect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Europe is heading down the wrong path on AI,” wrote Meta’s chief global affairs officer Joel Kaplan in a post on LinkedIn. “We have carefully reviewed the European Commission’s Code of Practice for general-purpose AI (GPAI) models and Meta won’t be signing it. This Code introduces a number of legal uncertainties for model developers, as well as measures which go far beyond the scope of the AI Act.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The EU’s code of practice — a voluntary framework published earlier this month — aims to help companies implement processes and systems to comply with the bloc’s legislation for regulating AI. Among other things, the code requires companies to provide and regularly update documentation about their AI tools and services; bans developers from training AI on pirated content; and comply with content owners’ requests to not use their works in their data sets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Calling the EU’s implementation of the legislation “over-reach,” Kaplan claimed that the law will “throttle the development and deployment of frontier AI models in Europe, and stunt European companies looking to build businesses on top of them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A risk-based regulation for applications of artificial intelligence, the AI Act bans some “unacceptable risk” use cases outright, such as cognitive behavioral manipulation or social scoring. The rules also define a set of “high-risk” uses, such as biometrics and facial recognition, and in domains like education and employment. The act also requires developers to register AI systems and meet risk and quality management obligations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tech companies from across the world, including those at the forefront of the AI race like Alphabet, Meta, Microsoft and Mistral AI have been fighting the rules, even urging the European Commission to delay its roll out. But the Commission has held firm, saying it will not change its timeline.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Also on Friday, the EU published guidelines for providers of AI models ahead of rules that will go into effect on August 2. These rules would affect providers of “general-purpose AI models with systemic risk,” like OpenAI, Anthropic, Google, and Meta. Companies that have such models on the market before August 2 will have to comply with the legislation by August 2, 2027.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195497483.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta has refused to sign the European Union’s code of practice for its AI Act, weeks before the bloc’s rules for providers of general-purpose AI models take effect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Europe is heading down the wrong path on AI,” wrote Meta’s chief global affairs officer Joel Kaplan in a post on LinkedIn. “We have carefully reviewed the European Commission’s Code of Practice for general-purpose AI (GPAI) models and Meta won’t be signing it. This Code introduces a number of legal uncertainties for model developers, as well as measures which go far beyond the scope of the AI Act.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The EU’s code of practice — a voluntary framework published earlier this month — aims to help companies implement processes and systems to comply with the bloc’s legislation for regulating AI. Among other things, the code requires companies to provide and regularly update documentation about their AI tools and services; bans developers from training AI on pirated content; and comply with content owners’ requests to not use their works in their data sets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Calling the EU’s implementation of the legislation “over-reach,” Kaplan claimed that the law will “throttle the development and deployment of frontier AI models in Europe, and stunt European companies looking to build businesses on top of them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A risk-based regulation for applications of artificial intelligence, the AI Act bans some “unacceptable risk” use cases outright, such as cognitive behavioral manipulation or social scoring. The rules also define a set of “high-risk” uses, such as biometrics and facial recognition, and in domains like education and employment. The act also requires developers to register AI systems and meet risk and quality management obligations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tech companies from across the world, including those at the forefront of the AI race like Alphabet, Meta, Microsoft and Mistral AI have been fighting the rules, even urging the European Commission to delay its roll out. But the Commission has held firm, saying it will not change its timeline.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Also on Friday, the EU published guidelines for providers of AI models ahead of rules that will go into effect on August 2. These rules would affect providers of “general-purpose AI models with systemic risk,” like OpenAI, Anthropic, Google, and Meta. Companies that have such models on the market before August 2 will have to comply with the legislation by August 2, 2027.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/18/meta-refuses-to-sign-eus-ai-code-of-practice/</guid><pubDate>Fri, 18 Jul 2025 13:52:44 +0000</pubDate></item><item><title>[NEW] OpenAI, Thinking Machines Lab, and the built-in chaos of a $2B seed round (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/openai-thinking-machines-lab-and-the-built-in-chaos-of-a-2b-seed-round/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2188124206.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;OpenAI’s former chief technology officer, Mira Murati, just raised one of the largest seed rounds in history. Murati secured $2 billion in that seed round for Thinking Machines Lab — a startup so early, it hasn’t even revealed what it’s working on yet. The move is raising eyebrows across Silicon Valley, and it’s only the latest in a wave of top researchers splintering off from OpenAI to chase their own AI moonshots.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today, on TechCrunch’s Equity podcast, hosts Kirsten Korosec, Rebecca Bellan and Anthony Ha break down what’s fueling the OpenAI talent shuffle, investor enthusiasm, and a former employee’s behind-the-scenes peek inside the company. Either way, the team agrees: seed rounds really have changed.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more news from the week, including:&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back for you next week, so don’t miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2188124206.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;OpenAI’s former chief technology officer, Mira Murati, just raised one of the largest seed rounds in history. Murati secured $2 billion in that seed round for Thinking Machines Lab — a startup so early, it hasn’t even revealed what it’s working on yet. The move is raising eyebrows across Silicon Valley, and it’s only the latest in a wave of top researchers splintering off from OpenAI to chase their own AI moonshots.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today, on TechCrunch’s Equity podcast, hosts Kirsten Korosec, Rebecca Bellan and Anthony Ha break down what’s fueling the OpenAI talent shuffle, investor enthusiasm, and a former employee’s behind-the-scenes peek inside the company. Either way, the team agrees: seed rounds really have changed.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more news from the week, including:&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Equity will be back for you next week, so don’t miss it!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/openai-thinking-machines-lab-and-the-built-in-chaos-of-a-2b-seed-round/</guid><pubDate>Fri, 18 Jul 2025 14:35:00 +0000</pubDate></item><item><title>[NEW] Can speed and safety truly coexist in the AI race? (AI News)</title><link>https://www.artificialintelligence-news.com/news/can-speed-and-safety-truly-coexist-ai-race/</link><description>&lt;p&gt;A criticism about AI safety from an OpenAI researcher aimed at a rival opened a window into the industry’s struggle: a battle against itself.&lt;/p&gt;&lt;p&gt;It started with a warning from Boaz Barak, a Harvard professor currently on leave and working on safety at OpenAI. He called the launch of xAI’s Grok model “completely irresponsible,” not because of its headline-grabbing antics, but because of what was missing: a public system card, detailed safety evaluations, the basic artefacts of transparency that have become the fragile norm.&lt;/p&gt;&lt;p&gt;It was a clear and necessary call. But a candid reflection, posted just three weeks after he left the company, from ex-OpenAI engineer Calvin French-Owen, shows us the other half of the story.&lt;/p&gt;&lt;p&gt;French-Owen’s account suggests a large number of people at OpenAI are indeed working on safety, focusing on very real threats like hate speech, bio-weapons, and self-harm. Yet, he delivers the insight: “Most of the work which is done isn’t published,” he wrote, adding that OpenAI “really should do more to get it out there.”&lt;/p&gt;&lt;p&gt;Here, the simple narrative of a good actor scolding a bad one collapses. In its place, we see the real, industry-wide dilemma laid bare. The whole AI industry is caught in the ‘Safety-Velocity Paradox,’ a deep, structural conflict between the need to move at breakneck speed to compete and the moral need to move with caution to keep us safe.&lt;/p&gt;&lt;p&gt;French-Owen suggests that OpenAI is in a state of controlled chaos, having tripled its headcount to over 3,000 in a single year, where “everything breaks when you scale that quickly.” This chaotic energy is channelled by the immense pressure of a “three-horse race” to AGI against Google and Anthropic. The result is a culture of incredible speed, but also one of secrecy.&lt;/p&gt;&lt;p&gt;Consider the creation of Codex, OpenAI’s coding agent. French-Owen calls the project a “mad-dash sprint,” where a small team built a revolutionary product from scratch in just seven weeks.&lt;/p&gt;&lt;p&gt;This is a textbook example of velocity; describing working until midnight most nights and even through weekends to make it happen. This is the human cost of that velocity. In an environment moving this fast, is it any wonder that the slow, methodical work of publishing AI safety research feels like a distraction from the race?&lt;/p&gt;&lt;p&gt;This paradox isn’t born of malice, but of a set of powerful, interlocking forces.&lt;/p&gt;&lt;p&gt;There is the obvious competitive pressure to be first. There is also the cultural DNA of these labs, which began as loose groups of “scientists and tinkerers” and value-shifting breakthroughs over methodical processes. And there is a simple problem of measurement: it is easy to quantify speed and performance, but exceptionally difficult to quantify a disaster that was successfully prevented.&lt;/p&gt;&lt;p&gt;In the boardrooms of today, the visible metrics of velocity will almost always shout louder than the invisible successes of safety. However, to move forward, it cannot be about pointing fingers—it must be about changing the fundamental rules of the game.&lt;/p&gt;&lt;p&gt;We need to redefine what it means to ship a product, making the publication of a safety case as integral as the code itself. We need industry-wide standards that prevent any single company from being competitively punished for its diligence, turning safety from a feature into a shared, non-negotiable foundation.&lt;/p&gt;&lt;p&gt;However, most of all, we need to cultivate a culture within AI labs where every engineer – not just the safety department – feels a sense of responsibility.&lt;/p&gt;&lt;p&gt;The race to create AGI is not about who gets there first; it is about how we arrive. The true winner will not be the company that is merely the fastest, but the one that proves to a watching world that ambition and responsibility can, and must, move forward together.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Olu Olamigoke Jr.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Military AI contracts awarded to Anthropic, OpenAI, Google, and xAI&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A criticism about AI safety from an OpenAI researcher aimed at a rival opened a window into the industry’s struggle: a battle against itself.&lt;/p&gt;&lt;p&gt;It started with a warning from Boaz Barak, a Harvard professor currently on leave and working on safety at OpenAI. He called the launch of xAI’s Grok model “completely irresponsible,” not because of its headline-grabbing antics, but because of what was missing: a public system card, detailed safety evaluations, the basic artefacts of transparency that have become the fragile norm.&lt;/p&gt;&lt;p&gt;It was a clear and necessary call. But a candid reflection, posted just three weeks after he left the company, from ex-OpenAI engineer Calvin French-Owen, shows us the other half of the story.&lt;/p&gt;&lt;p&gt;French-Owen’s account suggests a large number of people at OpenAI are indeed working on safety, focusing on very real threats like hate speech, bio-weapons, and self-harm. Yet, he delivers the insight: “Most of the work which is done isn’t published,” he wrote, adding that OpenAI “really should do more to get it out there.”&lt;/p&gt;&lt;p&gt;Here, the simple narrative of a good actor scolding a bad one collapses. In its place, we see the real, industry-wide dilemma laid bare. The whole AI industry is caught in the ‘Safety-Velocity Paradox,’ a deep, structural conflict between the need to move at breakneck speed to compete and the moral need to move with caution to keep us safe.&lt;/p&gt;&lt;p&gt;French-Owen suggests that OpenAI is in a state of controlled chaos, having tripled its headcount to over 3,000 in a single year, where “everything breaks when you scale that quickly.” This chaotic energy is channelled by the immense pressure of a “three-horse race” to AGI against Google and Anthropic. The result is a culture of incredible speed, but also one of secrecy.&lt;/p&gt;&lt;p&gt;Consider the creation of Codex, OpenAI’s coding agent. French-Owen calls the project a “mad-dash sprint,” where a small team built a revolutionary product from scratch in just seven weeks.&lt;/p&gt;&lt;p&gt;This is a textbook example of velocity; describing working until midnight most nights and even through weekends to make it happen. This is the human cost of that velocity. In an environment moving this fast, is it any wonder that the slow, methodical work of publishing AI safety research feels like a distraction from the race?&lt;/p&gt;&lt;p&gt;This paradox isn’t born of malice, but of a set of powerful, interlocking forces.&lt;/p&gt;&lt;p&gt;There is the obvious competitive pressure to be first. There is also the cultural DNA of these labs, which began as loose groups of “scientists and tinkerers” and value-shifting breakthroughs over methodical processes. And there is a simple problem of measurement: it is easy to quantify speed and performance, but exceptionally difficult to quantify a disaster that was successfully prevented.&lt;/p&gt;&lt;p&gt;In the boardrooms of today, the visible metrics of velocity will almost always shout louder than the invisible successes of safety. However, to move forward, it cannot be about pointing fingers—it must be about changing the fundamental rules of the game.&lt;/p&gt;&lt;p&gt;We need to redefine what it means to ship a product, making the publication of a safety case as integral as the code itself. We need industry-wide standards that prevent any single company from being competitively punished for its diligence, turning safety from a feature into a shared, non-negotiable foundation.&lt;/p&gt;&lt;p&gt;However, most of all, we need to cultivate a culture within AI labs where every engineer – not just the safety department – feels a sense of responsibility.&lt;/p&gt;&lt;p&gt;The race to create AGI is not about who gets there first; it is about how we arrive. The true winner will not be the company that is merely the fastest, but the one that proves to a watching world that ambition and responsibility can, and must, move forward together.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Olu Olamigoke Jr.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Military AI contracts awarded to Anthropic, OpenAI, Google, and xAI&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/can-speed-and-safety-truly-coexist-ai-race/</guid><pubDate>Fri, 18 Jul 2025 14:40:34 +0000</pubDate></item><item><title>[NEW] DuckDuckGo now lets you hide AI-generated images in search results (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/18/duckduckgo-now-lets-you-hide-ai-generated-images-in-search-results/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Privacy-focused browser DuckDuckGo is rolling out a new setting that lets users filter out AI images in search results. The company says it’s launching the feature in response to feedback from users who said AI images can get in the way of finding what they’re looking for. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can access the new setting by conducting a search on DuckDuckGo and heading to the Images tab. From there, they will see a new dropdown menu titled “AI images.” Users can then choose whether or not they want to see AI content by selecting “show” or “hide.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users can also turn on the filter in their search settings by tapping the “Hide AI-Generated Images” option.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="a screenshot showing the new setting in DuckDuckGo's browser, which lets users switch off AI images in search results." class="wp-image-3029132" height="1574" src="https://techcrunch.com/wp-content/uploads/2025/07/duckduckgo-ai-filter.png" width="2220" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;DuckDuckGo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;DuckDuckGo’s new feature comes as the internet is being flooded with AI “slop,” which refers to low-quality media content made using generative AI technology. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The filter relies on manually curated open-source blocklists, including the ‘nuclear’ list, provided by uBlockOrigin and uBlacklist Huge AI Blocklist,” DuckDuckGo said in a post on X. “While it won’t catch 100% of AI-generated results, it will greatly reduce the number of AI-generated images you see.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;DuckDuckGo says it plans on adding additional filters in the future, but didn’t provide specifics. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth noting that DuckDuckGo’s example for the new feature depicts an image search for a baby peacock, likely in reference to Google facing controversy last year for showing more AI-generated images of baby peacocks rather than real-life images when conducting an image search for the bird. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Privacy-focused browser DuckDuckGo is rolling out a new setting that lets users filter out AI images in search results. The company says it’s launching the feature in response to feedback from users who said AI images can get in the way of finding what they’re looking for. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can access the new setting by conducting a search on DuckDuckGo and heading to the Images tab. From there, they will see a new dropdown menu titled “AI images.” Users can then choose whether or not they want to see AI content by selecting “show” or “hide.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users can also turn on the filter in their search settings by tapping the “Hide AI-Generated Images” option.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="a screenshot showing the new setting in DuckDuckGo's browser, which lets users switch off AI images in search results." class="wp-image-3029132" height="1574" src="https://techcrunch.com/wp-content/uploads/2025/07/duckduckgo-ai-filter.png" width="2220" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;DuckDuckGo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;DuckDuckGo’s new feature comes as the internet is being flooded with AI “slop,” which refers to low-quality media content made using generative AI technology. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The filter relies on manually curated open-source blocklists, including the ‘nuclear’ list, provided by uBlockOrigin and uBlacklist Huge AI Blocklist,” DuckDuckGo said in a post on X. “While it won’t catch 100% of AI-generated results, it will greatly reduce the number of AI-generated images you see.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;DuckDuckGo says it plans on adding additional filters in the future, but didn’t provide specifics. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth noting that DuckDuckGo’s example for the new feature depicts an image search for a baby peacock, likely in reference to Google facing controversy last year for showing more AI-generated images of baby peacocks rather than real-life images when conducting an image search for the bird. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/18/duckduckgo-now-lets-you-hide-ai-generated-images-in-search-results/</guid><pubDate>Fri, 18 Jul 2025 16:23:54 +0000</pubDate></item><item><title>[NEW] Netflix’s first show with generative AI is a sign of what’s to come in TV, film (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/07/netflixs-first-show-with-generative-ai-is-a-sign-of-whats-to-come-in-tv-film/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        &lt;em&gt;The Eternaut&lt;/em&gt; debuted on Netflix with a generative AI-assisted scene.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Ricardo Darín in The Eternaut." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/EE_20230621_DARIN_0005-R-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Ricardo Darín in The Eternaut." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="383" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/EE_20230621_DARIN_0005-R.jpg" width="681" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Ricardo Darín in &lt;em&gt;The Eternaut&lt;/em&gt;. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Netflix

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Netflix used generative AI in an original, scripted series that debuted this year, it revealed this week. Producers used the technology to create a scene in which a building collapses, hinting at the growing use of generative AI in entertainment.&lt;/p&gt;
&lt;p&gt;During a call with investors yesterday, Netflix co-CEO Ted Sarandos revealed that Netflix's Argentine show &lt;em&gt;The Eternaut&lt;/em&gt;, which premiered in April, is "the very first GenAI final footage to appear on screen in a Netflix, Inc. original series or film.” Sarandos further explained, per a transcript of the call, saying:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The creators wanted to show a building collapsing in Buenos Aires. So our iLine team, [which is the production innovation group inside the visual effects house at Netflix effects studio Scanline], partnered with their creative team using AI-powered tools. ... And in fact, that VFX sequence was completed 10 times faster than it could have been completed with visual, traditional VFX tools and workflows. And, also, the cost of it would just not have been feasible for a show in that budget.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sarandos claimed that viewers have been "thrilled with the results"; although that likely has much to do with how the rest of the series, based on a comic, plays out, not just one, AI-crafted scene.&lt;/p&gt;
&lt;h2&gt;More generative AI on Netflix&lt;/h2&gt;
&lt;p&gt;Still, Netflix seems open to using generative AI in shows and movies more, with Sarandos saying the tech "represents an incredible opportunity to help creators make films and series better, not just cheaper."&lt;/p&gt;
&lt;p&gt;"Our creators are already seeing the benefits in production through pre-visualization and shot planning work and, certainly, visual effects," he said. "It used to be that only big-budget projects would have access to advanced visual effects like de-aging."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;AI-generated video and images in shows or movies is a popular topic of discussion, but Netflix also has less divisive application ideas. During yesterday's call, Netflix co-CEO Greg Peters highlighted the potential for generative AI to improve Netflix's personalization and recommendation abilities. He said that Netflix is currently piloting the ability for people to ask Netflix for a recommendation via conversational prompts like, "I want to watch a film from the '80s that is a dark, psychological thriller."&lt;/p&gt;
&lt;p&gt;Streaming services, TV manufacturers, and smart TV OS operators have been eager to leverage generative AI for superior search functionality that improves customers' chances of finding something to watch. For Netflix, better search capabilities could keep users engaged with the platform more, which is important for appealing to advertisers and keeping viewers subscribed.&lt;/p&gt;
&lt;p&gt;Netflix previously announced that it will show interactive ads that use generative AI during shows and movies (for ad-tier subscribers) in 2026. On yesterday's call, Peters pointed to efforts to enable the use of generative AI "in more and more" advertising spots.&lt;/p&gt;
&lt;p&gt;Sarandos previously said that Netflix's use of generative AI won't take from its goal of "telling great stories.” In a call with investors a year ago, he compared generative AI in TV and film to the growth of computer-generated animation, claiming that it improved animation and that "more people work in animation today than ever in history." According to the US Department of Labor, there were 73,300 special effects artists and animators in 2023, with 3,200 jobs expected to be added from 2023 to 2033.&lt;/p&gt;
&lt;p&gt;"I’m pretty sure that there’s a better business—and a bigger business—in making content 10 percent better [using technology] than [there is in] making it 50 percent cheaper," Sarandos said at the time. He added that audiences “probably don’t care much about budgets and, arguably, maybe not even the technology to deliver it."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;More generative AI in TV and film&lt;/h2&gt;
&lt;p&gt;The level of interest that audiences have in generative AI in TV and film will vary by person and situation.&lt;/p&gt;
&lt;p&gt;Last year, people accused Netflix's true crime documentary &lt;em&gt;What Jennifer Did&lt;/em&gt; of using undisclosed generative AI—a claim that executive producer Jeremy Grimaldi denied. Documentaries are supposed to be grounded in truth and evidence, so AI-generated imagery could hurt credibility. Contrastingly, using generative AI to avoid destroying a real building for use in a fictional apocalyptic drama is more understandable. Using generative AI to write the script for such a show, however, would likely evoke different reactions.&lt;/p&gt;
&lt;p&gt;TV and films are expected to use generative AI more in the next few years as industry leaders like Disney explore ways to leverage the technology. Generative AI has already been used in theatrical releases, such as &lt;em&gt;The Brutalist&lt;/em&gt;, creepy news broadcasts, clunky movies on free streaming services, and in cartoons. Generative AI can save money, making it a priority for the entertainment industry. The use and touting of generative AI in an original series from Netflix is likely to generate more interest.&lt;/p&gt;
&lt;p&gt;Much of the discussion about generative AI in TV and film centers on the potential to undermine creativity and jobs, and rip off intellectual property. However, there's also a sincere push to understand how to use the tech to enhance creative, human ideas. As society learns what generative AI realistically will and won't do, how the technology is received in shows and movies will likely depend on how, when, and why it's used, as well as how open creators are about its usage.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        &lt;em&gt;The Eternaut&lt;/em&gt; debuted on Netflix with a generative AI-assisted scene.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Ricardo Darín in The Eternaut." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/EE_20230621_DARIN_0005-R-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Ricardo Darín in The Eternaut." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="383" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/EE_20230621_DARIN_0005-R.jpg" width="681" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Ricardo Darín in &lt;em&gt;The Eternaut&lt;/em&gt;. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Netflix

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Netflix used generative AI in an original, scripted series that debuted this year, it revealed this week. Producers used the technology to create a scene in which a building collapses, hinting at the growing use of generative AI in entertainment.&lt;/p&gt;
&lt;p&gt;During a call with investors yesterday, Netflix co-CEO Ted Sarandos revealed that Netflix's Argentine show &lt;em&gt;The Eternaut&lt;/em&gt;, which premiered in April, is "the very first GenAI final footage to appear on screen in a Netflix, Inc. original series or film.” Sarandos further explained, per a transcript of the call, saying:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The creators wanted to show a building collapsing in Buenos Aires. So our iLine team, [which is the production innovation group inside the visual effects house at Netflix effects studio Scanline], partnered with their creative team using AI-powered tools. ... And in fact, that VFX sequence was completed 10 times faster than it could have been completed with visual, traditional VFX tools and workflows. And, also, the cost of it would just not have been feasible for a show in that budget.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Sarandos claimed that viewers have been "thrilled with the results"; although that likely has much to do with how the rest of the series, based on a comic, plays out, not just one, AI-crafted scene.&lt;/p&gt;
&lt;h2&gt;More generative AI on Netflix&lt;/h2&gt;
&lt;p&gt;Still, Netflix seems open to using generative AI in shows and movies more, with Sarandos saying the tech "represents an incredible opportunity to help creators make films and series better, not just cheaper."&lt;/p&gt;
&lt;p&gt;"Our creators are already seeing the benefits in production through pre-visualization and shot planning work and, certainly, visual effects," he said. "It used to be that only big-budget projects would have access to advanced visual effects like de-aging."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;AI-generated video and images in shows or movies is a popular topic of discussion, but Netflix also has less divisive application ideas. During yesterday's call, Netflix co-CEO Greg Peters highlighted the potential for generative AI to improve Netflix's personalization and recommendation abilities. He said that Netflix is currently piloting the ability for people to ask Netflix for a recommendation via conversational prompts like, "I want to watch a film from the '80s that is a dark, psychological thriller."&lt;/p&gt;
&lt;p&gt;Streaming services, TV manufacturers, and smart TV OS operators have been eager to leverage generative AI for superior search functionality that improves customers' chances of finding something to watch. For Netflix, better search capabilities could keep users engaged with the platform more, which is important for appealing to advertisers and keeping viewers subscribed.&lt;/p&gt;
&lt;p&gt;Netflix previously announced that it will show interactive ads that use generative AI during shows and movies (for ad-tier subscribers) in 2026. On yesterday's call, Peters pointed to efforts to enable the use of generative AI "in more and more" advertising spots.&lt;/p&gt;
&lt;p&gt;Sarandos previously said that Netflix's use of generative AI won't take from its goal of "telling great stories.” In a call with investors a year ago, he compared generative AI in TV and film to the growth of computer-generated animation, claiming that it improved animation and that "more people work in animation today than ever in history." According to the US Department of Labor, there were 73,300 special effects artists and animators in 2023, with 3,200 jobs expected to be added from 2023 to 2033.&lt;/p&gt;
&lt;p&gt;"I’m pretty sure that there’s a better business—and a bigger business—in making content 10 percent better [using technology] than [there is in] making it 50 percent cheaper," Sarandos said at the time. He added that audiences “probably don’t care much about budgets and, arguably, maybe not even the technology to deliver it."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;More generative AI in TV and film&lt;/h2&gt;
&lt;p&gt;The level of interest that audiences have in generative AI in TV and film will vary by person and situation.&lt;/p&gt;
&lt;p&gt;Last year, people accused Netflix's true crime documentary &lt;em&gt;What Jennifer Did&lt;/em&gt; of using undisclosed generative AI—a claim that executive producer Jeremy Grimaldi denied. Documentaries are supposed to be grounded in truth and evidence, so AI-generated imagery could hurt credibility. Contrastingly, using generative AI to avoid destroying a real building for use in a fictional apocalyptic drama is more understandable. Using generative AI to write the script for such a show, however, would likely evoke different reactions.&lt;/p&gt;
&lt;p&gt;TV and films are expected to use generative AI more in the next few years as industry leaders like Disney explore ways to leverage the technology. Generative AI has already been used in theatrical releases, such as &lt;em&gt;The Brutalist&lt;/em&gt;, creepy news broadcasts, clunky movies on free streaming services, and in cartoons. Generative AI can save money, making it a priority for the entertainment industry. The use and touting of generative AI in an original series from Netflix is likely to generate more interest.&lt;/p&gt;
&lt;p&gt;Much of the discussion about generative AI in TV and film centers on the potential to undermine creativity and jobs, and rip off intellectual property. However, there's also a sincere push to understand how to use the tech to enhance creative, human ideas. As society learns what generative AI realistically will and won't do, how the technology is received in shows and movies will likely depend on how, when, and why it's used, as well as how open creators are about its usage.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/07/netflixs-first-show-with-generative-ai-is-a-sign-of-whats-to-come-in-tv-film/</guid><pubDate>Fri, 18 Jul 2025 17:29:04 +0000</pubDate></item></channel></rss>