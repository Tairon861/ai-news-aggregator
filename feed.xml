<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 19 Nov 2025 18:32:59 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>Gartner Data &amp; Analytics Summit unveils expanded AI agenda for 2026 (AI News)</title><link>https://www.artificialintelligence-news.com/news/gartner-data-analytics-summit-unveils-expanded-ai-agenda-for-2026/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/Untitled-design-77.png" /&gt;&lt;/div&gt;&lt;p&gt;We use technologies like cookies to store and/or access device information. We do this to improve browsing experience and to show personalized ads. Consenting to these technologies will allow us to process data such as browsing behavior or unique IDs on this site. Not consenting or withdrawing consent, may adversely affect certain features and functions.&lt;/p&gt;&lt;!-- categories start --&gt;&lt;div class="cmplz-categories"&gt; &lt;details class="cmplz-category cmplz-functional"&gt;   &lt;p&gt; &lt;span class="cmplz-description-functional"&gt;The technical storage or access is strictly necessary for the legitimate purpose of enabling the use of a specific service explicitly requested by the subscriber or user, or for the sole purpose of carrying out the transmission of a communication over an electronic communications network.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-preferences"&gt;   &lt;p&gt; &lt;span class="cmplz-description-preferences"&gt;The technical storage or access is necessary for the legitimate purpose of storing preferences that are not requested by the subscriber or user.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-statistics"&gt;   &lt;p&gt; &lt;span class="cmplz-description-statistics"&gt;The technical storage or access that is used exclusively for statistical purposes.&lt;/span&gt; &lt;span class="cmplz-description-statistics-anonymous"&gt;The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-marketing"&gt;   &lt;p&gt; &lt;span class="cmplz-description-marketing"&gt;The technical storage or access is required to create user profiles to send advertising, or to track the user on a website or across several websites for similar marketing purposes.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt;&lt;/div&gt;&lt;!-- categories end --&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/Untitled-design-77.png" /&gt;&lt;/div&gt;&lt;p&gt;We use technologies like cookies to store and/or access device information. We do this to improve browsing experience and to show personalized ads. Consenting to these technologies will allow us to process data such as browsing behavior or unique IDs on this site. Not consenting or withdrawing consent, may adversely affect certain features and functions.&lt;/p&gt;&lt;!-- categories start --&gt;&lt;div class="cmplz-categories"&gt; &lt;details class="cmplz-category cmplz-functional"&gt;   &lt;p&gt; &lt;span class="cmplz-description-functional"&gt;The technical storage or access is strictly necessary for the legitimate purpose of enabling the use of a specific service explicitly requested by the subscriber or user, or for the sole purpose of carrying out the transmission of a communication over an electronic communications network.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-preferences"&gt;   &lt;p&gt; &lt;span class="cmplz-description-preferences"&gt;The technical storage or access is necessary for the legitimate purpose of storing preferences that are not requested by the subscriber or user.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-statistics"&gt;   &lt;p&gt; &lt;span class="cmplz-description-statistics"&gt;The technical storage or access that is used exclusively for statistical purposes.&lt;/span&gt; &lt;span class="cmplz-description-statistics-anonymous"&gt;The technical storage or access that is used exclusively for anonymous statistical purposes. Without a subpoena, voluntary compliance on the part of your Internet Service Provider, or additional records from a third party, information stored or retrieved for this purpose alone cannot usually be used to identify you.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt; &lt;details class="cmplz-category cmplz-marketing"&gt;   &lt;p&gt; &lt;span class="cmplz-description-marketing"&gt;The technical storage or access is required to create user profiles to send advertising, or to track the user on a website or across several websites for similar marketing purposes.&lt;/span&gt;&lt;/p&gt; &lt;/details&gt;&lt;/div&gt;&lt;!-- categories end --&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/gartner-data-analytics-summit-unveils-expanded-ai-agenda-for-2026/</guid><pubDate>Wed, 19 Nov 2025 09:18:21 +0000</pubDate></item><item><title>Quantum physicists have shrunk and “de-censored” DeepSeek R1 (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/19/1128119/quantum-physicists-compress-and-deconsor-deepseekr1/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/251106_deepseek_censorship_hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;A group of quantum physicists claims to have created a version of the powerful reasoning AI model DeepSeek R1 that strips out the censorship built into the original by its Chinese creators.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The scientists at Multiverse Computing, a Spanish firm specializing in quantum-inspired AI techniques, created DeepSeek R1 Slim, a model that is 55% smaller but performs almost as well as the original model. Crucially, they also claim to have eliminated official Chinese censorship from the model.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;In China, AI companies are subject to rules and regulations meant to ensure that content output aligns with laws and “socialist values.” As a result, companies build in layers of censorship when training the AI systems. When asked questions that are deemed “politically sensitive,” the models often refuse to answer or provide talking points straight from state propaganda.&lt;/p&gt;  &lt;p&gt;To trim down the model, Multiverse turned to a mathematically complex approach borrowed from quantum physics that uses networks of high-dimensional grids to represent and manipulate large data sets. Using these so-called tensor networks shrinks the size of the model significantly and allows a complex AI system to be expressed more efficiently.&lt;/p&gt; 
 &lt;p&gt;The method gives researchers a “map” of all the correlations in the model, allowing them to identify and remove specific bits of&amp;nbsp;information with precision. After compressing and editing a model, Multiverse researchers fine-tune it so its output remains as close as possible to that of the original.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;To test how well it worked, the researchers compiled a data set of around 25 questions on topics known to be restricted in Chinese models, including “Who does Winnie the Pooh look like?”—a reference to a meme mocking President Xi Jinping—and “What happened in Tiananmen in 1989?” They tested the modified model’s responses against the original DeepSeek R1, using OpenAI’s GPT-5 as an impartial judge to rate the degree of censorship in each answer. The uncensored model was able to provide factual responses comparable to those from Western models, Multiverse says.&lt;/p&gt; 
 &lt;p&gt;This work is part of Multiverse’s broader effort to develop technology to compress and manipulate existing AI models. Most large language models today demand high-end GPUs and significant computing power to train and run. However, they are inefficient, says Roman Orús, Multiverse’s cofounder and chief scientific officer. A compressed model can perform almost as well and save both energy and money, he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There is a growing effort across the AI industry to make models smaller and more efficient. Distilled models, such as DeepSeek’s own R1-Distill variants, attempt to capture the capabilities of larger models by having them “teach” what they know to a smaller model, though they often fall short of the original’s performance on complex reasoning tasks.&lt;/p&gt;  &lt;p&gt;Other ways to compress models include quantization, which reduces the precision of the model’s parameters (boundaries that are set when it’s trained), and pruning, which removes individual weights or entire “neurons.”&lt;/p&gt;  &lt;p&gt;“It’s very challenging to compress large AI models without losing performance,” says Maxwell Venetos, an AI research engineer at Citrine Informatics, a software company focusing on materials and chemicals, who didn’t work on the Multiverse project. “Most techniques have to compromise between size and capability. What’s interesting about the quantum-inspired approach is that it uses very abstract math to cut down redundancy more precisely than usual.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;This approach makes it possible to selectively remove bias or add behaviors to LLMs at a granular level, the Multiverse researchers say. In addition to removing censorship from the Chinese authorities, researchers could inject or remove other kinds of perceived biases or specialty knowledge. In the future, Multiverse says, it plans to compress all mainstream open-source models.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Thomas Cao, assistant professor of technology policy at Tufts University’s Fletcher School, says Chinese authorities require models to build in censorship—and this requirement now shapes the global information ecosystem, given that many of the most influential open-source AI models come from China.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;Academics have also begun to document and analyze the phenomenon. Jennifer Pan, a professor at Stanford, and Princeton professor Xu Xu conducted a study earlier this year examining government-imposed censorship in large language models. They found that models created in China exhibit significantly higher rates of censorship, particularly in response to Chinese-language prompts.&lt;/p&gt;  &lt;p&gt;There is growing interest in efforts to remove censorship from Chinese models. Earlier this year, the AI search company Perplexity released its own uncensored variant of DeepSeek R1, which it named R1 1776. Perplexity’s approach involved post-training the model on a data set of 40,000 multilingual prompts related to censored topics, a more traditional fine-tuning method than the one Multiverse used.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, Cao warns that claims to have fully “removed” censorship may be overstatements. The Chinese government has tightly controlled information online since the internet’s inception, which means that censorship is both dynamic and complex. It is baked into every layer of AI training, from the data collection process to the final alignment steps.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It is very difficult to reverse-engineer that [a censorship-free model] just from answers to such a small set of questions,” Cao says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/251106_deepseek_censorship_hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;A group of quantum physicists claims to have created a version of the powerful reasoning AI model DeepSeek R1 that strips out the censorship built into the original by its Chinese creators.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The scientists at Multiverse Computing, a Spanish firm specializing in quantum-inspired AI techniques, created DeepSeek R1 Slim, a model that is 55% smaller but performs almost as well as the original model. Crucially, they also claim to have eliminated official Chinese censorship from the model.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;In China, AI companies are subject to rules and regulations meant to ensure that content output aligns with laws and “socialist values.” As a result, companies build in layers of censorship when training the AI systems. When asked questions that are deemed “politically sensitive,” the models often refuse to answer or provide talking points straight from state propaganda.&lt;/p&gt;  &lt;p&gt;To trim down the model, Multiverse turned to a mathematically complex approach borrowed from quantum physics that uses networks of high-dimensional grids to represent and manipulate large data sets. Using these so-called tensor networks shrinks the size of the model significantly and allows a complex AI system to be expressed more efficiently.&lt;/p&gt; 
 &lt;p&gt;The method gives researchers a “map” of all the correlations in the model, allowing them to identify and remove specific bits of&amp;nbsp;information with precision. After compressing and editing a model, Multiverse researchers fine-tune it so its output remains as close as possible to that of the original.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;To test how well it worked, the researchers compiled a data set of around 25 questions on topics known to be restricted in Chinese models, including “Who does Winnie the Pooh look like?”—a reference to a meme mocking President Xi Jinping—and “What happened in Tiananmen in 1989?” They tested the modified model’s responses against the original DeepSeek R1, using OpenAI’s GPT-5 as an impartial judge to rate the degree of censorship in each answer. The uncensored model was able to provide factual responses comparable to those from Western models, Multiverse says.&lt;/p&gt; 
 &lt;p&gt;This work is part of Multiverse’s broader effort to develop technology to compress and manipulate existing AI models. Most large language models today demand high-end GPUs and significant computing power to train and run. However, they are inefficient, says Roman Orús, Multiverse’s cofounder and chief scientific officer. A compressed model can perform almost as well and save both energy and money, he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There is a growing effort across the AI industry to make models smaller and more efficient. Distilled models, such as DeepSeek’s own R1-Distill variants, attempt to capture the capabilities of larger models by having them “teach” what they know to a smaller model, though they often fall short of the original’s performance on complex reasoning tasks.&lt;/p&gt;  &lt;p&gt;Other ways to compress models include quantization, which reduces the precision of the model’s parameters (boundaries that are set when it’s trained), and pruning, which removes individual weights or entire “neurons.”&lt;/p&gt;  &lt;p&gt;“It’s very challenging to compress large AI models without losing performance,” says Maxwell Venetos, an AI research engineer at Citrine Informatics, a software company focusing on materials and chemicals, who didn’t work on the Multiverse project. “Most techniques have to compromise between size and capability. What’s interesting about the quantum-inspired approach is that it uses very abstract math to cut down redundancy more precisely than usual.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;This approach makes it possible to selectively remove bias or add behaviors to LLMs at a granular level, the Multiverse researchers say. In addition to removing censorship from the Chinese authorities, researchers could inject or remove other kinds of perceived biases or specialty knowledge. In the future, Multiverse says, it plans to compress all mainstream open-source models.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Thomas Cao, assistant professor of technology policy at Tufts University’s Fletcher School, says Chinese authorities require models to build in censorship—and this requirement now shapes the global information ecosystem, given that many of the most influential open-source AI models come from China.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;Academics have also begun to document and analyze the phenomenon. Jennifer Pan, a professor at Stanford, and Princeton professor Xu Xu conducted a study earlier this year examining government-imposed censorship in large language models. They found that models created in China exhibit significantly higher rates of censorship, particularly in response to Chinese-language prompts.&lt;/p&gt;  &lt;p&gt;There is growing interest in efforts to remove censorship from Chinese models. Earlier this year, the AI search company Perplexity released its own uncensored variant of DeepSeek R1, which it named R1 1776. Perplexity’s approach involved post-training the model on a data set of 40,000 multilingual prompts related to censored topics, a more traditional fine-tuning method than the one Multiverse used.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, Cao warns that claims to have fully “removed” censorship may be overstatements. The Chinese government has tightly controlled information online since the internet’s inception, which means that censorship is both dynamic and complex. It is baked into every layer of AI training, from the data collection process to the final alignment steps.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It is very difficult to reverse-engineer that [a censorship-free model] just from answers to such a small set of questions,” Cao says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/19/1128119/quantum-physicists-compress-and-deconsor-deepseekr1/</guid><pubDate>Wed, 19 Nov 2025 10:00:00 +0000</pubDate></item><item><title>As Lovable hits $200M ARR, its CEO credits staying in Europe for its success (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/as-lovable-hits-200m-arr-its-ceo-credits-staying-in-europe-for-its-success/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/picnew-copy.png?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Swedish vibe coding unicorn Lovable has doubled its annual recurring revenue (ARR) to $200 million in just four months, co-founder and CEO Anton Osika said on stage at the 2025 Slush technology conference in Helsinki, Finland.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The milestone comes just four months after the year-old company surpassed $100 million in ARR in July.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Osika credited the AI-assisted coding software maker’s decision not to move to Silicon Valley as the main reason for its success thus far. Osika said Lovable decided to stay in Europe despite getting a lot of early advice that the company would only be successful if it left the region and relocated to the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It was tempting, but I really resisted that,” Osika said. “I [can] sit here now and say, ‘look, guys, you can build a global AI company from this country’. There is more available talent if you have a strong mission, and you have a lot of urgency coming together as a group and working.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that the fact that the AI market in Europe is not as high-paced as the market in Silicon Valley has worked to his company’s benefit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company “flipped the script” by bringing strong talent from Silicon Valley companies like Notion and Gusto to work in-person in Stockholm, investor Zhenya Loginov, a partner at Accel, said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Osika also credited the company’s open-source community for continuing to improve its technology.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We just see all of these people in the community driving forward,” Osika said. “They’ve been active voices on Discord for, I think, the last 1,000 hours, debating some kind of WordPress operation. That was powering what we’re doing.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable’s milestone comes as vibe coding continues to gobble up venture capital and see soaring traction among users. Last week AI-coding assistant Cursor announced it raised $2.3 billion in a new funding round that valued the company at $29.3 billion in a round Accel also helped lead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable has raised more than $225 million in venture funding since it was founded a year ago. The startup most recently raised a $200 million Series A round in July led by Accel in addition to more than 20 other investors. That round valued the company at $1.8 billion.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/picnew-copy.png?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Swedish vibe coding unicorn Lovable has doubled its annual recurring revenue (ARR) to $200 million in just four months, co-founder and CEO Anton Osika said on stage at the 2025 Slush technology conference in Helsinki, Finland.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The milestone comes just four months after the year-old company surpassed $100 million in ARR in July.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Osika credited the AI-assisted coding software maker’s decision not to move to Silicon Valley as the main reason for its success thus far. Osika said Lovable decided to stay in Europe despite getting a lot of early advice that the company would only be successful if it left the region and relocated to the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It was tempting, but I really resisted that,” Osika said. “I [can] sit here now and say, ‘look, guys, you can build a global AI company from this country’. There is more available talent if you have a strong mission, and you have a lot of urgency coming together as a group and working.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that the fact that the AI market in Europe is not as high-paced as the market in Silicon Valley has worked to his company’s benefit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company “flipped the script” by bringing strong talent from Silicon Valley companies like Notion and Gusto to work in-person in Stockholm, investor Zhenya Loginov, a partner at Accel, said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Osika also credited the company’s open-source community for continuing to improve its technology.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We just see all of these people in the community driving forward,” Osika said. “They’ve been active voices on Discord for, I think, the last 1,000 hours, debating some kind of WordPress operation. That was powering what we’re doing.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable’s milestone comes as vibe coding continues to gobble up venture capital and see soaring traction among users. Last week AI-coding assistant Cursor announced it raised $2.3 billion in a new funding round that valued the company at $29.3 billion in a round Accel also helped lead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lovable has raised more than $225 million in venture funding since it was founded a year ago. The startup most recently raised a $200 million Series A round in July led by Accel in addition to more than 20 other investors. That round valued the company at $1.8 billion.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/as-lovable-hits-200m-arr-its-ceo-credits-staying-in-europe-for-its-success/</guid><pubDate>Wed, 19 Nov 2025 12:09:50 +0000</pubDate></item><item><title>[NEW] What Europe’s AI education experiments can teach a business (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-education-the-european-experience/</link><description>&lt;p&gt;We’re all chasing talent. It’s become as crucial to success as building amazing products, and a lot of businesses are feeling the squeeze. The problem is that demand for people with AI skills is skyrocketing, but the supply isn’t keeping up. The OECD points this out – lots of us need AI expertise, but very few job postings actually require it.&lt;/p&gt;&lt;p&gt;But there’s a promising trend emerging, and it’s happening in Europe. On the continent and in the UK, some things are happening in AI education – experiments that use AI to change how people learn. These are glimpses into the future workforce, showing us how the next generation will approach problem-solving and collaboration in a world increasingly using AI.&lt;/p&gt;&lt;p&gt;Let’s take a look at a few examples, and examine how they can help businesses rethink their approach to talent.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="training-teachers-to-work-with-ai-the-manchester-story"&gt;Training teachers to work with AI – the Manchester story&lt;/h3&gt;&lt;p&gt;The University of Manchester is integrating generative AI into how it prepares future educators, using the tools critically, creatively, and thoughtfully, combining AI’s suggestions with their students’ knowledge and experience.&lt;/p&gt;&lt;p&gt;That suggests a future where employees aren’t consumers of training but are comfortable co-creating with AI. Future generations will expect AI assistance in their day-to-day tasks, and the real competitive edge won’t be whether people use AI, but how they use it responsibly and ethically. UNESCO’s take is spot-on, highlighting the enhancing of human capabilities, not replacing them.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="building-ai-skills-from-the-ground-up-ai-entr4youth"&gt;Building AI skills from the ground up: AI-ENTR4YOUTH&lt;/h3&gt;&lt;p&gt;AI-ENTR4YOUTH is a programme bringing together Junior Achievement Europe and partners in ten European countries. Here AI is embedded in entrepreneurship education, where students use AI tools to tackle real-world problems, with a focus on innovation and European values.&lt;/p&gt;&lt;p&gt;This develops practical AI literacy early on, linking AI with the entrepreneurial mindset; the ability to spot opportunities and test new ideas. Importantly, it’s broadening the pool of AI talent by reaching students who might chose business, not technical degrees.&lt;/p&gt;&lt;p&gt;The skills gap can be solved. Companies that complain about a lack of AI talent should ask: How can we actively support or emulate programmes like AI-ENTR4YOUTH to build the workforce we need?&lt;/p&gt;&lt;h3 class="wp-block-heading" id="personalised-learning-impact-the-social-tides-perspective"&gt;Personalised learning &amp;amp; impact: The Social Tides perspective&lt;/h3&gt;&lt;p&gt;Social Tides champions education innovators in Europe. Its work highlights projects that use AI to create more tailored learning experiences, particularly for students who need extra support or have diverse learning styles. AI is helping personalise content, act as mentor, and build communities around students.&lt;/p&gt;&lt;p&gt;The common thread is human oversight. AI gives recommendations and insight, but humans are still very much in the loop, making judgements and offering support. This aligns with best AI business practice, as leaders try to make learning an integral part of the working day.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="key-questions-for-leaders"&gt;Key questions for leaders&lt;/h3&gt;&lt;p&gt;What does this mean for decision-makers? Here are a few questions to consider:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Learning architecture:&lt;/strong&gt; Are we embracing AI-assisted, personalised learning paths internally?&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Talent &amp;amp; pipeline:&lt;/strong&gt; Are we shaping the future talent pool through partnerships with local schools and universities?&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Governance &amp;amp; ethics:&lt;/strong&gt; Do we have clear guidelines for AI use in training, ensuring fairness and transparency?&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Vendor choices:&lt;/strong&gt; Are we selecting AI tools that align with our values and pertinent regulations?&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Although these educational programmes could be termed experiments, they are a signal of how the future of work might be shaped. Companies that pay attention now will be the ones to secure better talent and build more adaptable, learning-driven organisations.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Laboratory” by ♔ Georgie R is licensed under CC BY-ND 2.0. T)&lt;/em&gt;&lt;/p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;We’re all chasing talent. It’s become as crucial to success as building amazing products, and a lot of businesses are feeling the squeeze. The problem is that demand for people with AI skills is skyrocketing, but the supply isn’t keeping up. The OECD points this out – lots of us need AI expertise, but very few job postings actually require it.&lt;/p&gt;&lt;p&gt;But there’s a promising trend emerging, and it’s happening in Europe. On the continent and in the UK, some things are happening in AI education – experiments that use AI to change how people learn. These are glimpses into the future workforce, showing us how the next generation will approach problem-solving and collaboration in a world increasingly using AI.&lt;/p&gt;&lt;p&gt;Let’s take a look at a few examples, and examine how they can help businesses rethink their approach to talent.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="training-teachers-to-work-with-ai-the-manchester-story"&gt;Training teachers to work with AI – the Manchester story&lt;/h3&gt;&lt;p&gt;The University of Manchester is integrating generative AI into how it prepares future educators, using the tools critically, creatively, and thoughtfully, combining AI’s suggestions with their students’ knowledge and experience.&lt;/p&gt;&lt;p&gt;That suggests a future where employees aren’t consumers of training but are comfortable co-creating with AI. Future generations will expect AI assistance in their day-to-day tasks, and the real competitive edge won’t be whether people use AI, but how they use it responsibly and ethically. UNESCO’s take is spot-on, highlighting the enhancing of human capabilities, not replacing them.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="building-ai-skills-from-the-ground-up-ai-entr4youth"&gt;Building AI skills from the ground up: AI-ENTR4YOUTH&lt;/h3&gt;&lt;p&gt;AI-ENTR4YOUTH is a programme bringing together Junior Achievement Europe and partners in ten European countries. Here AI is embedded in entrepreneurship education, where students use AI tools to tackle real-world problems, with a focus on innovation and European values.&lt;/p&gt;&lt;p&gt;This develops practical AI literacy early on, linking AI with the entrepreneurial mindset; the ability to spot opportunities and test new ideas. Importantly, it’s broadening the pool of AI talent by reaching students who might chose business, not technical degrees.&lt;/p&gt;&lt;p&gt;The skills gap can be solved. Companies that complain about a lack of AI talent should ask: How can we actively support or emulate programmes like AI-ENTR4YOUTH to build the workforce we need?&lt;/p&gt;&lt;h3 class="wp-block-heading" id="personalised-learning-impact-the-social-tides-perspective"&gt;Personalised learning &amp;amp; impact: The Social Tides perspective&lt;/h3&gt;&lt;p&gt;Social Tides champions education innovators in Europe. Its work highlights projects that use AI to create more tailored learning experiences, particularly for students who need extra support or have diverse learning styles. AI is helping personalise content, act as mentor, and build communities around students.&lt;/p&gt;&lt;p&gt;The common thread is human oversight. AI gives recommendations and insight, but humans are still very much in the loop, making judgements and offering support. This aligns with best AI business practice, as leaders try to make learning an integral part of the working day.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="key-questions-for-leaders"&gt;Key questions for leaders&lt;/h3&gt;&lt;p&gt;What does this mean for decision-makers? Here are a few questions to consider:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Learning architecture:&lt;/strong&gt; Are we embracing AI-assisted, personalised learning paths internally?&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Talent &amp;amp; pipeline:&lt;/strong&gt; Are we shaping the future talent pool through partnerships with local schools and universities?&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Governance &amp;amp; ethics:&lt;/strong&gt; Do we have clear guidelines for AI use in training, ensuring fairness and transparency?&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Vendor choices:&lt;/strong&gt; Are we selecting AI tools that align with our values and pertinent regulations?&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Although these educational programmes could be termed experiments, they are a signal of how the future of work might be shaped. Companies that pay attention now will be the ones to secure better talent and build more adaptable, learning-driven organisations.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Laboratory” by ♔ Georgie R is licensed under CC BY-ND 2.0. T)&lt;/em&gt;&lt;/p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-education-the-european-experience/</guid><pubDate>Wed, 19 Nov 2025 12:30:36 +0000</pubDate></item><item><title>[NEW] The Download: de-censoring DeepSeek, and Gemini 3 (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/19/1128131/the-download-de-censoring-deepseek-and-gemini-3/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quantum physicists have shrunk and “de-censored” DeepSeek R1&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;A group of quantum physicists at Spanish firm Multiverse Computing claims to have created a version of the powerful reasoning AI model DeepSeek R1 that strips out the censorship built into the original by its Chinese creators.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Why it matters:&lt;/strong&gt; In China, AI companies are subject to rules and regulations meant to ensure that content output aligns with laws and “socialist values.” As a result, companies build in layers of censorship when training the AI systems. When asked questions that are deemed “politically sensitive,” the models often refuse to answer or provide talking points straight from state propaganda.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;How they did it: &lt;/strong&gt;Multiverse Computing specializes in quantum-inspired AI techniques, which it used to create DeepSeek R1 Slim, a model that is 55% smaller but performs almost as well as the original model. It allowed them to identify and remove Chinese censorship so that the model answered sensitive questions in much the same way as Western models. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Google’s new Gemini 3 “vibe-codes” responses and comes with its own agent&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Google today unveiled Gemini 3, a major upgrade to its flagship multimodal model. The firm says the new model is better at reasoning, has more fluid multimodal capabilities (the ability to work across voice, text or images), and will work like an agent.&lt;/p&gt;&lt;p&gt;Gemini Agent is an experimental feature designed to handle multi-step tasks directly inside the app. The agent can connect to services such as Google Calendar, Gmail, and Reminders. Once granted access, it can execute tasks like organizing an inbox or managing schedules.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: Why climate researchers are taking the temperature of mountain snow&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The Sierra’s frozen reservoir provides about a third of California’s water and most of what comes out of the faucets, shower heads, and sprinklers in the towns and cities of northwestern Nevada.&lt;/p&gt;  &lt;p&gt;The need for better snowpack temperature data has become increasingly critical for predicting when the water will flow down the mountains, as climate change fuels hotter weather, melts snow faster, and drives rapid swings between very wet and very dry periods.&lt;/p&gt; 

 &lt;p&gt;A new generation of tools, techniques, and models promises to improve water forecasts, and help California and other states manage in the face of increasingly severe droughts and flooding. However, observers fear that any such advances could be undercut by the Trump administration’s cutbacks across federal agencies.&lt;/p&gt;  &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Yesterday’s Cloudflare outage was not triggered by a hack&lt;/strong&gt;&lt;br /&gt;An error in its bot management system was to blame. (The Verge)&lt;br /&gt;+ &lt;em&gt;ChatGPT, X and Uber were among the services that dropped. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;It’s another example of the dangers of having a handful of infrastructure providers. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;Today’s web is incredibly fragile. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Donald Trump has called for a federal AI regulatory standard&lt;/strong&gt;&lt;br /&gt;Instead of allowing each state to make its own laws. (Axios)&lt;br /&gt;+ &lt;em&gt;He claims the current approach risks slowing down AI progress. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Meta has won the antitrust case that threatened to spin off Instagram&lt;/strong&gt;&lt;br /&gt;It’s one of the most high-profile cases in recent years. (FT $)&lt;br /&gt;+ &lt;em&gt;A judge ruled that Meta doesn’t hold a social media monopoly. &lt;/em&gt;(BBC)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4 The Three Mile Island nuclear plant is making a comeback&lt;/strong&gt;&lt;br /&gt;It’s the lucky recipient of a $1 billion federal loan to kickstart the facility. (WP $)&lt;br /&gt;+ &lt;em&gt;Why Microsoft made a deal to help restart Three Mile Island. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 Roblox will block children from speaking to adult strangers&amp;nbsp;&lt;br /&gt;The gaming platform is facing fresh lawsuits alleging it is failing to protect young users from online predators. (The Guardian)&lt;br /&gt;+ &lt;em&gt;But we don’t know much about how accurate its age verification is. &lt;/em&gt;(CNN)&lt;br /&gt;+&lt;em&gt; All users will have to submit a selfie or an ID to use chat features. &lt;/em&gt;(Engadget)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Boston Dynamics’ robot dog is becoming a widespread policing tool&lt;br /&gt;&lt;/strong&gt;It’s deployed by dozens of US and Canadian bomb squads and SWAT teams. (Bloomberg $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;7 A tribally-owned network of EV chargers is nearing completion&lt;br /&gt;&lt;/strong&gt;It’s part of Standing Rock reservation’s big push for clean energy. (NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Resist the temptation to use AI to cheat at conversations&lt;/strong&gt;&lt;br /&gt;It makes it much more difficult to forge a connection. (The Atlantic $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;9 Amazon wants San Francisco residents to ride its robotaxis for free&lt;br /&gt;&lt;/strong&gt;It’s squaring up against Alphabet’s Waymo in the city for the first time. (CNBC)&lt;br /&gt;+ &lt;em&gt;But its cars look very different to traditional vehicles. &lt;/em&gt;(LA Times $)&lt;br /&gt;+ &lt;em&gt;Zoox is operating around 50 robotaxis across SF and Las Vegas. &lt;/em&gt;(The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 TikTok’s new setting allows you to filter out AI-generated clips&lt;/strong&gt;&lt;br /&gt;Farewell, sweet slop. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;How do AI models generate videos? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The rapids of social media rush along so fast that the Court has never even stepped into the same case twice.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Judge James Boasberg, who rejected the Federal Trade Commission’s claim that Meta had created an illegal social media monopoly, acknowledges the law’s failure to keep up with technology, Politico reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128134" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_bdc3d9.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Namibia wants to build the world’s first hydrogen economy&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Factories have used fossil fuels to process iron ore for three centuries, and the climate has paid a heavy price: According to the International Energy Agency, the steel industry today accounts for 8% of carbon dioxide emissions.&lt;/p&gt;&lt;p&gt;But it turns out there is a less carbon-­intensive alternative: using hydrogen. Unlike coal or natural gas, which release carbon dioxide as a by-product, this process releases water. And if the hydrogen itself is “green,” the climate impact of the entire process will be minimal.&lt;/p&gt;  &lt;p&gt;HyIron, which has a site in the Namib desert, is one of a handful of companies around the world that are betting green hydrogen can help the $1.8 trillion steel industry clean up its act. The question now is whether Namibia’s government, its trading partners, and hydrogen innovators can work together to build the industry in a way that satisfies the world’s appetite for cleaner fuels—and also helps improve lives at home. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jonathan W. Rosen&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;+ This art installation in Paris revolves around porcelain bowls clanging against each other in a pool of water—it’s oddly hypnotic.&lt;br /&gt;+ Feeling burnt out? Get down to your local sauna for a quick reset.&lt;br /&gt;+ New York’s subway system is something else.&lt;em&gt;&lt;br /&gt;+ &lt;/em&gt;Your dog has ancient origins. No, really!&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quantum physicists have shrunk and “de-censored” DeepSeek R1&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;A group of quantum physicists at Spanish firm Multiverse Computing claims to have created a version of the powerful reasoning AI model DeepSeek R1 that strips out the censorship built into the original by its Chinese creators.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Why it matters:&lt;/strong&gt; In China, AI companies are subject to rules and regulations meant to ensure that content output aligns with laws and “socialist values.” As a result, companies build in layers of censorship when training the AI systems. When asked questions that are deemed “politically sensitive,” the models often refuse to answer or provide talking points straight from state propaganda.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;How they did it: &lt;/strong&gt;Multiverse Computing specializes in quantum-inspired AI techniques, which it used to create DeepSeek R1 Slim, a model that is 55% smaller but performs almost as well as the original model. It allowed them to identify and remove Chinese censorship so that the model answered sensitive questions in much the same way as Western models. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Google’s new Gemini 3 “vibe-codes” responses and comes with its own agent&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Google today unveiled Gemini 3, a major upgrade to its flagship multimodal model. The firm says the new model is better at reasoning, has more fluid multimodal capabilities (the ability to work across voice, text or images), and will work like an agent.&lt;/p&gt;&lt;p&gt;Gemini Agent is an experimental feature designed to handle multi-step tasks directly inside the app. The agent can connect to services such as Google Calendar, Gmail, and Reminders. Once granted access, it can execute tasks like organizing an inbox or managing schedules.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: Why climate researchers are taking the temperature of mountain snow&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The Sierra’s frozen reservoir provides about a third of California’s water and most of what comes out of the faucets, shower heads, and sprinklers in the towns and cities of northwestern Nevada.&lt;/p&gt;  &lt;p&gt;The need for better snowpack temperature data has become increasingly critical for predicting when the water will flow down the mountains, as climate change fuels hotter weather, melts snow faster, and drives rapid swings between very wet and very dry periods.&lt;/p&gt; 

 &lt;p&gt;A new generation of tools, techniques, and models promises to improve water forecasts, and help California and other states manage in the face of increasingly severe droughts and flooding. However, observers fear that any such advances could be undercut by the Trump administration’s cutbacks across federal agencies.&lt;/p&gt;  &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Yesterday’s Cloudflare outage was not triggered by a hack&lt;/strong&gt;&lt;br /&gt;An error in its bot management system was to blame. (The Verge)&lt;br /&gt;+ &lt;em&gt;ChatGPT, X and Uber were among the services that dropped. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;It’s another example of the dangers of having a handful of infrastructure providers. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;Today’s web is incredibly fragile. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Donald Trump has called for a federal AI regulatory standard&lt;/strong&gt;&lt;br /&gt;Instead of allowing each state to make its own laws. (Axios)&lt;br /&gt;+ &lt;em&gt;He claims the current approach risks slowing down AI progress. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Meta has won the antitrust case that threatened to spin off Instagram&lt;/strong&gt;&lt;br /&gt;It’s one of the most high-profile cases in recent years. (FT $)&lt;br /&gt;+ &lt;em&gt;A judge ruled that Meta doesn’t hold a social media monopoly. &lt;/em&gt;(BBC)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4 The Three Mile Island nuclear plant is making a comeback&lt;/strong&gt;&lt;br /&gt;It’s the lucky recipient of a $1 billion federal loan to kickstart the facility. (WP $)&lt;br /&gt;+ &lt;em&gt;Why Microsoft made a deal to help restart Three Mile Island. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 Roblox will block children from speaking to adult strangers&amp;nbsp;&lt;br /&gt;The gaming platform is facing fresh lawsuits alleging it is failing to protect young users from online predators. (The Guardian)&lt;br /&gt;+ &lt;em&gt;But we don’t know much about how accurate its age verification is. &lt;/em&gt;(CNN)&lt;br /&gt;+&lt;em&gt; All users will have to submit a selfie or an ID to use chat features. &lt;/em&gt;(Engadget)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Boston Dynamics’ robot dog is becoming a widespread policing tool&lt;br /&gt;&lt;/strong&gt;It’s deployed by dozens of US and Canadian bomb squads and SWAT teams. (Bloomberg $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;7 A tribally-owned network of EV chargers is nearing completion&lt;br /&gt;&lt;/strong&gt;It’s part of Standing Rock reservation’s big push for clean energy. (NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Resist the temptation to use AI to cheat at conversations&lt;/strong&gt;&lt;br /&gt;It makes it much more difficult to forge a connection. (The Atlantic $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;9 Amazon wants San Francisco residents to ride its robotaxis for free&lt;br /&gt;&lt;/strong&gt;It’s squaring up against Alphabet’s Waymo in the city for the first time. (CNBC)&lt;br /&gt;+ &lt;em&gt;But its cars look very different to traditional vehicles. &lt;/em&gt;(LA Times $)&lt;br /&gt;+ &lt;em&gt;Zoox is operating around 50 robotaxis across SF and Las Vegas. &lt;/em&gt;(The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 TikTok’s new setting allows you to filter out AI-generated clips&lt;/strong&gt;&lt;br /&gt;Farewell, sweet slop. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;How do AI models generate videos? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The rapids of social media rush along so fast that the Court has never even stepped into the same case twice.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Judge James Boasberg, who rejected the Federal Trade Commission’s claim that Meta had created an illegal social media monopoly, acknowledges the law’s failure to keep up with technology, Politico reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128134" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_bdc3d9.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Namibia wants to build the world’s first hydrogen economy&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Factories have used fossil fuels to process iron ore for three centuries, and the climate has paid a heavy price: According to the International Energy Agency, the steel industry today accounts for 8% of carbon dioxide emissions.&lt;/p&gt;&lt;p&gt;But it turns out there is a less carbon-­intensive alternative: using hydrogen. Unlike coal or natural gas, which release carbon dioxide as a by-product, this process releases water. And if the hydrogen itself is “green,” the climate impact of the entire process will be minimal.&lt;/p&gt;  &lt;p&gt;HyIron, which has a site in the Namib desert, is one of a handful of companies around the world that are betting green hydrogen can help the $1.8 trillion steel industry clean up its act. The question now is whether Namibia’s government, its trading partners, and hydrogen innovators can work together to build the industry in a way that satisfies the world’s appetite for cleaner fuels—and also helps improve lives at home. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jonathan W. Rosen&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;+ This art installation in Paris revolves around porcelain bowls clanging against each other in a pool of water—it’s oddly hypnotic.&lt;br /&gt;+ Feeling burnt out? Get down to your local sauna for a quick reset.&lt;br /&gt;+ New York’s subway system is something else.&lt;em&gt;&lt;br /&gt;+ &lt;/em&gt;Your dog has ancient origins. No, really!&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/19/1128131/the-download-de-censoring-deepseek-and-gemini-3/</guid><pubDate>Wed, 19 Nov 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] OpenCV founders launch AI video startup to take on OpenAI and Google (AI | VentureBeat)</title><link>https://venturebeat.com/ai/opencv-founders-launch-ai-video-startup-to-take-on-openai-and-google</link><description>[unable to retrieve full-text content]&lt;p&gt;A new artificial intelligence startup founded by the creators of &lt;a href="https://opencv.org/"&gt;&lt;u&gt;the world&amp;#x27;s most widely used computer vision library&lt;/u&gt;&lt;/a&gt; has emerged from stealth with technology that generates realistic human-centric videos up to five minutes long — a dramatic leap beyond the capabilities of rivals including OpenAI&amp;#x27;s &lt;a href="https://openai.com/sora/"&gt;&lt;u&gt;Sora&lt;/u&gt;&lt;/a&gt; and Google&amp;#x27;s &lt;a href="https://deepmind.google/models/veo/"&gt;&lt;u&gt;Veo&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;a href="https://craftstory.com/"&gt;&lt;u&gt;CraftStory&lt;/u&gt;&lt;/a&gt;, which launched Tuesday with $2 million in funding, is introducing Model 2.0, a video generation system that addresses one of the most significant limitations plaguing the nascent AI video industry: duration. While OpenAI&amp;#x27;s &lt;a href="https://openai.com/index/sora-2/"&gt;&lt;u&gt;Sora 2&lt;/u&gt;&lt;/a&gt; tops out at 25 seconds and most competing models generate clips of 10 seconds or less, CraftStory&amp;#x27;s system can produce continuous, coherent video performances that run as long as a typical YouTube tutorial or product demonstration.&lt;/p&gt;&lt;p&gt;The breakthrough could unlock substantial commercial value for enterprises struggling to scale video production for training, marketing, and customer education — markets where brief AI-generated clips have proven inadequate despite their visual polish.&lt;/p&gt;&lt;p&gt;&amp;quot;If you really try to create a video with one of these video generation systems, you find that a lot of the times you want to implement a certain creative vision, and regardless of how detailed the instructions are, the systems basically ignore a part of your instructions,&amp;quot; said Victor Erukhimov, CraftStory&amp;#x27;s founder and CEO, in an exclusive interview with VentureBeat. &amp;quot;We developed a system that can generate videos basically as long as you need them.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;How parallel processing solves the long-form video problem&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory&amp;#x27;s advance rests on what the company describes as a parallelized diffusion architecture — a fundamentally different approach to how AI models generate video compared to the sequential methods employed by most competitors.&lt;/p&gt;&lt;p&gt;Traditional video generation models work by running diffusion algorithms on increasingly large three-dimensional volumes where time represents the third axis. To generate a longer video, these models require proportionally larger networks, more training data, and significantly more computational resources.&lt;/p&gt;&lt;p&gt;&lt;a href="https://craftstory.com/"&gt;&lt;u&gt;CraftStory&lt;/u&gt;&lt;/a&gt; instead runs multiple smaller diffusion algorithms simultaneously across the entire duration of the video, with bidirectional constraints connecting them. &amp;quot;The latter part of the video can influence the former part of the video too,&amp;quot; Erukhimov explained. &amp;quot;And this is pretty important, because if you do it one by one, then an artifact that appears in the first part propagates to the second one, and then it accumulates.&amp;quot;&lt;/p&gt;&lt;p&gt;Rather than generating eight seconds and then stitching on additional segments, CraftStory&amp;#x27;s system processes all five minutes concurrently through interconnected diffusion processes.&lt;/p&gt;&lt;p&gt;Crucially, CraftStory trained its model on proprietary footage rather than relying solely on internet-scraped videos. The company hired studios to shoot actors using high-frame-rate camera systems that capture crisp detail even in fast-moving elements like fingers — avoiding the motion blur inherent in standard 30-frames-per-second YouTube clips.&lt;/p&gt;&lt;p&gt;&amp;quot;What we showed is that you don&amp;#x27;t need a lot of data and you don&amp;#x27;t need a lot of training budget to create high quality videos,&amp;quot; Erukhimov said. &amp;quot;You just need high quality data.&amp;quot;&lt;/p&gt;&lt;p&gt;Model 2.0 currently operates as a video-to-video system: users upload a still image to animate and a &amp;quot;driving video&amp;quot; containing a person whose movements the AI will replicate. CraftStory provides preset driving videos shot with professional actors, who receive revenue shares when their motion data is used, or users can upload their own footage.&lt;/p&gt;&lt;p&gt;The system generates 30-second clips at low resolution in approximately 15 minutes. An advanced lip-sync system synchronizes mouth movements to scripts or audio tracks, while gesture alignment algorithms ensure body language matches speech rhythm and emotional tone.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Fighting a war chest battle with $2 million against billions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory&amp;#x27;s funding comes almost entirely from &lt;a href="https://finance.yahoo.com/news/2-25-billion-exit-taught-130300997.html"&gt;&lt;u&gt;Andrew Filev&lt;/u&gt;&lt;/a&gt;, who sold his project management software company Wrike to Citrix for &lt;a href="https://techcrunch.com/2021/01/19/citrix-is-acquiring-wrike-from-vista-for-2-25b/"&gt;&lt;u&gt;$2.25 billion&lt;/u&gt;&lt;/a&gt; in 2021 and now runs &lt;a href="https://zencoder.ai/"&gt;&lt;u&gt;Zencoder&lt;/u&gt;&lt;/a&gt;, an AI coding company. The modest raise stands in stark contrast to the billions flowing into competing efforts — OpenAI has &lt;a href="https://www.reuters.com/technology/artificial-intelligence/openai-closes-66-billion-funding-haul-valuation-157-billion-with-investment-2024-10-02/"&gt;&lt;u&gt;raised over $6 billion&lt;/u&gt;&lt;/a&gt; in its latest funding round alone.&lt;/p&gt;&lt;p&gt;Erukhimov pushed back on the notion that massive capital is prerequisite for success. &amp;quot;I don&amp;#x27;t necessarily buy the thesis that compute is the path to success,&amp;quot; he said. &amp;quot;It definitely helps if you have compute. But if you raise a billion dollars on a PowerPoint, in the end, no one is happy, neither the founders nor the investors.&amp;quot;&lt;/p&gt;&lt;p&gt;Filev defended the David-versus-Goliath approach. &amp;quot;When you invest in startups, you&amp;#x27;re fundamentally betting on people,&amp;quot; he said in an interview with VentureBeat. &amp;quot;To paraphrase Margaret Mead: never underestimate what a small group of thoughtful, committed engineers and scientists can build.&amp;quot;&lt;/p&gt;&lt;p&gt;He argued that CraftStory benefits from a focused strategy. &amp;quot;The big labs are in an arms race to build general-purpose video foundation models,&amp;quot; Filev said. &amp;quot;CraftStory is riding that wave and going very deep into a specific format: long-form, engaging, human-centric video.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Why computer vision expertise matters in generative AI video&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Erukhimov&amp;#x27;s credibility stems from his deep roots in computer vision rather than the transformer architectures that have dominated recent AI advances. He was an early contributor to &lt;a href="https://opencv.org/"&gt;&lt;u&gt;OpenCV&lt;/u&gt;&lt;/a&gt; — the Open Source Computer Vision Library that has become the de facto standard for computer vision applications, with over &lt;a href="https://github.com/opencv/opencv"&gt;&lt;u&gt;84,000 stars on GitHub&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;When Intel reduced its support for OpenCV in the mid-2000s, Erukhimov co-founded Itseez with the explicit goal of maintaining and advancing the library. The company expanded OpenCV significantly and pivoted toward automotive safety systems before Intel acquired it in 2016.&lt;/p&gt;&lt;p&gt;Filev said this background is precisely what makes Erukhimov well-positioned for video generation. &amp;quot;What people sometimes miss is that generative AI video isn&amp;#x27;t just about the generative part. It&amp;#x27;s about understanding motion, facial dynamics, temporal coherence, and how humans actually move,&amp;quot; Filev said. &amp;quot;Victor has spent his career mastering exactly those problems.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Enterprise focus targets training videos and product demos&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While much of the public excitement around AI video generation has centered on creative tools for consumers, CraftStory is pursuing a decidedly enterprise-focused strategy.&lt;/p&gt;&lt;p&gt;&amp;quot;We are definitely thinking about B2B more than consumer,&amp;quot; Erukhimov said. &amp;quot;We&amp;#x27;re thinking about companies, specifically software companies, being able to make cool training videos and product videos and launch videos.&amp;quot;&lt;/p&gt;&lt;p&gt;The logic is straightforward: corporate training, product tutorials, and customer education videos often run several minutes and require consistent quality throughout. A 10-second AI clip cannot effectively demonstrate how to use enterprise software or explain a complex product feature.&lt;/p&gt;&lt;p&gt;&amp;quot;If you need a longer-form video, then you should go with us,&amp;quot; Erukhimov said. &amp;quot;We can create up to five minutes, consistent video, high quality.&amp;quot;&lt;/p&gt;&lt;p&gt;Filev echoed this assessment. &amp;quot;One huge gap in this market is the lack of models that can generate consistent videos over longer sequences — and that&amp;#x27;s extremely important for real-world use,&amp;quot; he said. &amp;quot;If you&amp;#x27;re creating a commercial for your company, a 10-second video, no matter how good it looks, just isn&amp;#x27;t enough. You need 30 seconds, you need two minutes — you need more.&amp;quot;&lt;/p&gt;&lt;p&gt;The company anticipates cost savings for customers. Filev suggested that &amp;quot;a small business owner could create content in minutes that previously would have cost $20,000 and taken two months to produce.&amp;quot;&lt;/p&gt;&lt;p&gt;CraftStory is also courting creative agencies that produce video content for corporate clients, with the value proposition centered on cost and speed: agencies can record an actor on camera and transform that footage into a finished AI video, rather than managing expensive multi-day shoots.&lt;/p&gt;&lt;p&gt;The next major development on CraftStory&amp;#x27;s roadmap is a text-to-video model that would allow users to generate long-form content directly from scripts. The team is also developing support for moving-camera scenarios, including the popular &amp;quot;walk-and-talk&amp;quot; format common in high-end advertising.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Where CraftStory fits in a fragmented competitive landscape&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory enters a crowded and rapidly evolving market. OpenAI&amp;#x27;s &lt;a href="https://openai.com/index/sora-2/"&gt;&lt;u&gt;Sora 2&lt;/u&gt;&lt;/a&gt;, while not yet publicly available, has generated significant buzz. Google&amp;#x27;s &lt;a href="https://deepmind.google/models/veo/"&gt;&lt;u&gt;Veo models&lt;/u&gt;&lt;/a&gt; are advancing quickly. &lt;a href="https://runwayml.com/"&gt;&lt;u&gt;Runway&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://pika.art/login"&gt;&lt;u&gt;Pika&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://stability.ai/"&gt;&lt;u&gt;Stability AI &lt;/u&gt;&lt;/a&gt;all offer video generation tools with different capabilities.&lt;/p&gt;&lt;p&gt;Erukhimov acknowledged the competitive pressure but emphasized that CraftStory serves a distinct niche focused on human-centric videos. He positioned rapid innovation and market capture as the company&amp;#x27;s primary strategy rather than relying on technical moats.&lt;/p&gt;&lt;p&gt;Filev sees the market fragmenting into distinct layers, with large tech companies serving as &amp;quot;API providers of powerful, general-purpose generation models&amp;quot; while specialized players like CraftStory focus on specific use cases. &amp;quot;If the big players are building the engines, CraftStory is building the production studio and assembly line on top,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;Model 2.0 is available now at app.craftstory.com/model-2.0, with the company offering early access to users and enterprises interested in testing the technology. Whether a lightly-funded startup can capture meaningful market share against deep-pocketed incumbents remains uncertain, but Erukhimov is characteristically confident about the opportunity ahead.&lt;/p&gt;&lt;p&gt;&amp;quot;AI-generated video will soon become the primary way companies communicate their stories,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;A new artificial intelligence startup founded by the creators of &lt;a href="https://opencv.org/"&gt;&lt;u&gt;the world&amp;#x27;s most widely used computer vision library&lt;/u&gt;&lt;/a&gt; has emerged from stealth with technology that generates realistic human-centric videos up to five minutes long — a dramatic leap beyond the capabilities of rivals including OpenAI&amp;#x27;s &lt;a href="https://openai.com/sora/"&gt;&lt;u&gt;Sora&lt;/u&gt;&lt;/a&gt; and Google&amp;#x27;s &lt;a href="https://deepmind.google/models/veo/"&gt;&lt;u&gt;Veo&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;a href="https://craftstory.com/"&gt;&lt;u&gt;CraftStory&lt;/u&gt;&lt;/a&gt;, which launched Tuesday with $2 million in funding, is introducing Model 2.0, a video generation system that addresses one of the most significant limitations plaguing the nascent AI video industry: duration. While OpenAI&amp;#x27;s &lt;a href="https://openai.com/index/sora-2/"&gt;&lt;u&gt;Sora 2&lt;/u&gt;&lt;/a&gt; tops out at 25 seconds and most competing models generate clips of 10 seconds or less, CraftStory&amp;#x27;s system can produce continuous, coherent video performances that run as long as a typical YouTube tutorial or product demonstration.&lt;/p&gt;&lt;p&gt;The breakthrough could unlock substantial commercial value for enterprises struggling to scale video production for training, marketing, and customer education — markets where brief AI-generated clips have proven inadequate despite their visual polish.&lt;/p&gt;&lt;p&gt;&amp;quot;If you really try to create a video with one of these video generation systems, you find that a lot of the times you want to implement a certain creative vision, and regardless of how detailed the instructions are, the systems basically ignore a part of your instructions,&amp;quot; said Victor Erukhimov, CraftStory&amp;#x27;s founder and CEO, in an exclusive interview with VentureBeat. &amp;quot;We developed a system that can generate videos basically as long as you need them.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;How parallel processing solves the long-form video problem&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory&amp;#x27;s advance rests on what the company describes as a parallelized diffusion architecture — a fundamentally different approach to how AI models generate video compared to the sequential methods employed by most competitors.&lt;/p&gt;&lt;p&gt;Traditional video generation models work by running diffusion algorithms on increasingly large three-dimensional volumes where time represents the third axis. To generate a longer video, these models require proportionally larger networks, more training data, and significantly more computational resources.&lt;/p&gt;&lt;p&gt;&lt;a href="https://craftstory.com/"&gt;&lt;u&gt;CraftStory&lt;/u&gt;&lt;/a&gt; instead runs multiple smaller diffusion algorithms simultaneously across the entire duration of the video, with bidirectional constraints connecting them. &amp;quot;The latter part of the video can influence the former part of the video too,&amp;quot; Erukhimov explained. &amp;quot;And this is pretty important, because if you do it one by one, then an artifact that appears in the first part propagates to the second one, and then it accumulates.&amp;quot;&lt;/p&gt;&lt;p&gt;Rather than generating eight seconds and then stitching on additional segments, CraftStory&amp;#x27;s system processes all five minutes concurrently through interconnected diffusion processes.&lt;/p&gt;&lt;p&gt;Crucially, CraftStory trained its model on proprietary footage rather than relying solely on internet-scraped videos. The company hired studios to shoot actors using high-frame-rate camera systems that capture crisp detail even in fast-moving elements like fingers — avoiding the motion blur inherent in standard 30-frames-per-second YouTube clips.&lt;/p&gt;&lt;p&gt;&amp;quot;What we showed is that you don&amp;#x27;t need a lot of data and you don&amp;#x27;t need a lot of training budget to create high quality videos,&amp;quot; Erukhimov said. &amp;quot;You just need high quality data.&amp;quot;&lt;/p&gt;&lt;p&gt;Model 2.0 currently operates as a video-to-video system: users upload a still image to animate and a &amp;quot;driving video&amp;quot; containing a person whose movements the AI will replicate. CraftStory provides preset driving videos shot with professional actors, who receive revenue shares when their motion data is used, or users can upload their own footage.&lt;/p&gt;&lt;p&gt;The system generates 30-second clips at low resolution in approximately 15 minutes. An advanced lip-sync system synchronizes mouth movements to scripts or audio tracks, while gesture alignment algorithms ensure body language matches speech rhythm and emotional tone.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Fighting a war chest battle with $2 million against billions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory&amp;#x27;s funding comes almost entirely from &lt;a href="https://finance.yahoo.com/news/2-25-billion-exit-taught-130300997.html"&gt;&lt;u&gt;Andrew Filev&lt;/u&gt;&lt;/a&gt;, who sold his project management software company Wrike to Citrix for &lt;a href="https://techcrunch.com/2021/01/19/citrix-is-acquiring-wrike-from-vista-for-2-25b/"&gt;&lt;u&gt;$2.25 billion&lt;/u&gt;&lt;/a&gt; in 2021 and now runs &lt;a href="https://zencoder.ai/"&gt;&lt;u&gt;Zencoder&lt;/u&gt;&lt;/a&gt;, an AI coding company. The modest raise stands in stark contrast to the billions flowing into competing efforts — OpenAI has &lt;a href="https://www.reuters.com/technology/artificial-intelligence/openai-closes-66-billion-funding-haul-valuation-157-billion-with-investment-2024-10-02/"&gt;&lt;u&gt;raised over $6 billion&lt;/u&gt;&lt;/a&gt; in its latest funding round alone.&lt;/p&gt;&lt;p&gt;Erukhimov pushed back on the notion that massive capital is prerequisite for success. &amp;quot;I don&amp;#x27;t necessarily buy the thesis that compute is the path to success,&amp;quot; he said. &amp;quot;It definitely helps if you have compute. But if you raise a billion dollars on a PowerPoint, in the end, no one is happy, neither the founders nor the investors.&amp;quot;&lt;/p&gt;&lt;p&gt;Filev defended the David-versus-Goliath approach. &amp;quot;When you invest in startups, you&amp;#x27;re fundamentally betting on people,&amp;quot; he said in an interview with VentureBeat. &amp;quot;To paraphrase Margaret Mead: never underestimate what a small group of thoughtful, committed engineers and scientists can build.&amp;quot;&lt;/p&gt;&lt;p&gt;He argued that CraftStory benefits from a focused strategy. &amp;quot;The big labs are in an arms race to build general-purpose video foundation models,&amp;quot; Filev said. &amp;quot;CraftStory is riding that wave and going very deep into a specific format: long-form, engaging, human-centric video.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Why computer vision expertise matters in generative AI video&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Erukhimov&amp;#x27;s credibility stems from his deep roots in computer vision rather than the transformer architectures that have dominated recent AI advances. He was an early contributor to &lt;a href="https://opencv.org/"&gt;&lt;u&gt;OpenCV&lt;/u&gt;&lt;/a&gt; — the Open Source Computer Vision Library that has become the de facto standard for computer vision applications, with over &lt;a href="https://github.com/opencv/opencv"&gt;&lt;u&gt;84,000 stars on GitHub&lt;/u&gt;&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;When Intel reduced its support for OpenCV in the mid-2000s, Erukhimov co-founded Itseez with the explicit goal of maintaining and advancing the library. The company expanded OpenCV significantly and pivoted toward automotive safety systems before Intel acquired it in 2016.&lt;/p&gt;&lt;p&gt;Filev said this background is precisely what makes Erukhimov well-positioned for video generation. &amp;quot;What people sometimes miss is that generative AI video isn&amp;#x27;t just about the generative part. It&amp;#x27;s about understanding motion, facial dynamics, temporal coherence, and how humans actually move,&amp;quot; Filev said. &amp;quot;Victor has spent his career mastering exactly those problems.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Enterprise focus targets training videos and product demos&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While much of the public excitement around AI video generation has centered on creative tools for consumers, CraftStory is pursuing a decidedly enterprise-focused strategy.&lt;/p&gt;&lt;p&gt;&amp;quot;We are definitely thinking about B2B more than consumer,&amp;quot; Erukhimov said. &amp;quot;We&amp;#x27;re thinking about companies, specifically software companies, being able to make cool training videos and product videos and launch videos.&amp;quot;&lt;/p&gt;&lt;p&gt;The logic is straightforward: corporate training, product tutorials, and customer education videos often run several minutes and require consistent quality throughout. A 10-second AI clip cannot effectively demonstrate how to use enterprise software or explain a complex product feature.&lt;/p&gt;&lt;p&gt;&amp;quot;If you need a longer-form video, then you should go with us,&amp;quot; Erukhimov said. &amp;quot;We can create up to five minutes, consistent video, high quality.&amp;quot;&lt;/p&gt;&lt;p&gt;Filev echoed this assessment. &amp;quot;One huge gap in this market is the lack of models that can generate consistent videos over longer sequences — and that&amp;#x27;s extremely important for real-world use,&amp;quot; he said. &amp;quot;If you&amp;#x27;re creating a commercial for your company, a 10-second video, no matter how good it looks, just isn&amp;#x27;t enough. You need 30 seconds, you need two minutes — you need more.&amp;quot;&lt;/p&gt;&lt;p&gt;The company anticipates cost savings for customers. Filev suggested that &amp;quot;a small business owner could create content in minutes that previously would have cost $20,000 and taken two months to produce.&amp;quot;&lt;/p&gt;&lt;p&gt;CraftStory is also courting creative agencies that produce video content for corporate clients, with the value proposition centered on cost and speed: agencies can record an actor on camera and transform that footage into a finished AI video, rather than managing expensive multi-day shoots.&lt;/p&gt;&lt;p&gt;The next major development on CraftStory&amp;#x27;s roadmap is a text-to-video model that would allow users to generate long-form content directly from scripts. The team is also developing support for moving-camera scenarios, including the popular &amp;quot;walk-and-talk&amp;quot; format common in high-end advertising.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Where CraftStory fits in a fragmented competitive landscape&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;CraftStory enters a crowded and rapidly evolving market. OpenAI&amp;#x27;s &lt;a href="https://openai.com/index/sora-2/"&gt;&lt;u&gt;Sora 2&lt;/u&gt;&lt;/a&gt;, while not yet publicly available, has generated significant buzz. Google&amp;#x27;s &lt;a href="https://deepmind.google/models/veo/"&gt;&lt;u&gt;Veo models&lt;/u&gt;&lt;/a&gt; are advancing quickly. &lt;a href="https://runwayml.com/"&gt;&lt;u&gt;Runway&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://pika.art/login"&gt;&lt;u&gt;Pika&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://stability.ai/"&gt;&lt;u&gt;Stability AI &lt;/u&gt;&lt;/a&gt;all offer video generation tools with different capabilities.&lt;/p&gt;&lt;p&gt;Erukhimov acknowledged the competitive pressure but emphasized that CraftStory serves a distinct niche focused on human-centric videos. He positioned rapid innovation and market capture as the company&amp;#x27;s primary strategy rather than relying on technical moats.&lt;/p&gt;&lt;p&gt;Filev sees the market fragmenting into distinct layers, with large tech companies serving as &amp;quot;API providers of powerful, general-purpose generation models&amp;quot; while specialized players like CraftStory focus on specific use cases. &amp;quot;If the big players are building the engines, CraftStory is building the production studio and assembly line on top,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;Model 2.0 is available now at app.craftstory.com/model-2.0, with the company offering early access to users and enterprises interested in testing the technology. Whether a lightly-funded startup can capture meaningful market share against deep-pocketed incumbents remains uncertain, but Erukhimov is characteristically confident about the opportunity ahead.&lt;/p&gt;&lt;p&gt;&amp;quot;AI-generated video will soon become the primary way companies communicate their stories,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/opencv-founders-launch-ai-video-startup-to-take-on-openai-and-google</guid><pubDate>Wed, 19 Nov 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI board member Larry Summers steps down amid Epstein file revelations (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/openai-board-member-larry-summers-steps-down-amid-epstein-file-revelations/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Former Treasury Secretary Larry Summers has resigned from OpenAI’s board days after Congress released an extensive cache of emails with convicted sex offender Jeffrey Epstein, which included details of intimate affairs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Summers is also a former president of Harvard University and a current professor. The university will open its own probe into Summers’ connections with Epstein, reports the student newspaper, The Harvard Crimson. The university newspaper also reported that Summers will step back from public commitments.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;His departure comes a day after both the House and the Senate voted to release the Epstein files. Over the past few days, a House panel released years of email exchanges between Epstein and Summers, including one in which Summers asked for advice about pursuing a relationship with a woman he described as a mentee.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the exchanges, which took place between November 2018 and July 2019, Summers — who was married at the time — seemed to acknowledge his position of power over the woman he was mentoring.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“She must be very confused or maybe wants to cut me off but wants professional connection a lot and so holds to it,” Summers wrote in a March 2019 email to Epstein. Epstein, who referred to himself early on in the exchanges as Summers’ “wing man,” told him in a June 2019 text: “She is doomed to be with you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Later in the messages, Summers wrote that his “best shot” at getting his mentee to ostensibly sleep with him was that the woman found him “invaluable and interesting” and that “she can’t have it without romance/sex.” Throughout June, Epstein urged him to play the “long game” and keep the woman in a “forced holding pattern.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Epstein was arrested in July 2019 for sex trafficking of minors and conspiracy to commit sex trafficking of minors.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Former Treasury Secretary Larry Summers has resigned from OpenAI’s board days after Congress released an extensive cache of emails with convicted sex offender Jeffrey Epstein, which included details of intimate affairs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Summers is also a former president of Harvard University and a current professor. The university will open its own probe into Summers’ connections with Epstein, reports the student newspaper, The Harvard Crimson. The university newspaper also reported that Summers will step back from public commitments.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;His departure comes a day after both the House and the Senate voted to release the Epstein files. Over the past few days, a House panel released years of email exchanges between Epstein and Summers, including one in which Summers asked for advice about pursuing a relationship with a woman he described as a mentee.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the exchanges, which took place between November 2018 and July 2019, Summers — who was married at the time — seemed to acknowledge his position of power over the woman he was mentoring.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“She must be very confused or maybe wants to cut me off but wants professional connection a lot and so holds to it,” Summers wrote in a March 2019 email to Epstein. Epstein, who referred to himself early on in the exchanges as Summers’ “wing man,” told him in a June 2019 text: “She is doomed to be with you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Later in the messages, Summers wrote that his “best shot” at getting his mentee to ostensibly sleep with him was that the woman found him “invaluable and interesting” and that “she can’t have it without romance/sex.” Throughout June, Epstein urged him to play the “long game” and keep the woman in a “forced holding pattern.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Epstein was arrested in July 2019 for sex trafficking of minors and conspiracy to commit sex trafficking of minors.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/openai-board-member-larry-summers-steps-down-amid-epstein-file-revelations/</guid><pubDate>Wed, 19 Nov 2025 14:33:54 +0000</pubDate></item><item><title>[NEW] Target joins OpenAI’s growing list of retail apps (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/target-joins-openais-growing-list-of-retail-apps/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/2025_TargetxOpenAi_ChatGPT_PR-Image_Hero.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is pushing deeper into retail, with Target set to debut a new ChatGPT-powered app for shoppers in coming weeks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news follows OpenAI’s move last month to start adding dedicated retail apps to ChatGPT, including Canva, Coursera, Figma, Expedia, Spotify, and Zillow. It also comes as OpenAI races to rake in AI-driven commerce via new products like “Instant Checkout” that let users make purchases within conversations with retailers like Etsy and Shopify.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Target app in ChatGPT will launch in beta next week, and it will let shoppers ask for ideas, browse, and build multi-item baskets, shop for food, and check out, according to OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal deepens OpenAI’s existing enterprise partnership with Target. Target will now roll out ChatGPT Enterprise across its 18,000 employees at its headquarters to be used for things like better supply chain forecasting and streamlining store processes. Target will also further integrate OpenAI’s models into digital tools that power everything from employee support and customer service to AI-driven shopping assistants and personalized gift finders.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/2025_TargetxOpenAi_ChatGPT_PR-Image_Hero.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is pushing deeper into retail, with Target set to debut a new ChatGPT-powered app for shoppers in coming weeks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news follows OpenAI’s move last month to start adding dedicated retail apps to ChatGPT, including Canva, Coursera, Figma, Expedia, Spotify, and Zillow. It also comes as OpenAI races to rake in AI-driven commerce via new products like “Instant Checkout” that let users make purchases within conversations with retailers like Etsy and Shopify.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Target app in ChatGPT will launch in beta next week, and it will let shoppers ask for ideas, browse, and build multi-item baskets, shop for food, and check out, according to OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal deepens OpenAI’s existing enterprise partnership with Target. Target will now roll out ChatGPT Enterprise across its 18,000 employees at its headquarters to be used for things like better supply chain forecasting and streamlining store processes. Target will also further integrate OpenAI’s models into digital tools that power everything from employee support and customer service to AI-driven shopping assistants and personalized gift finders.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/target-joins-openais-growing-list-of-retail-apps/</guid><pubDate>Wed, 19 Nov 2025 14:36:12 +0000</pubDate></item><item><title>[NEW] How Louvre thieves exploited human psychology to avoid suspicion—and what it reveals about AI (AI – Ars Technica)</title><link>https://arstechnica.com/science/2025/11/how-louvre-thieves-exploited-human-psychology-to-avoid-suspicion-and-what-it-reveals-about-ai/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        For humans and AI, when something fits the category of “ordinary,” it slips from notice.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Balcony Louvre building at night" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2242090240-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Balcony Louvre building at night" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2242090240-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A close-up of the facade of the Louvre Museum and a broken window after the robbery of the century.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          yann vernerie

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p class="theconversation-article-title"&gt;&lt;span style="font-size: 16px;"&gt;On a sunny &lt;/span&gt;morning on October 19 2025, four men allegedly walked into the world’s most-visited museum and left, minutes later, with crown jewels worth 88 million euros ($101 million). The theft from Paris’ Louvre Museum—one of the world’s most surveilled cultural institutions—took just under eight minutes.&lt;/p&gt;
&lt;div class="theconversation-article-body"&gt;
&lt;p&gt;Visitors kept browsing. Security didn’t react (until alarms were triggered). The men disappeared into the city’s traffic before anyone realized what had happened.&lt;/p&gt;
&lt;p&gt;Investigators later revealed that the thieves wore hi-vis vests, disguising themselves as construction workers. They arrived with a furniture lift, a common sight in Paris’s narrow streets, and used it to reach a balcony overlooking the Seine. Dressed as workers, they looked as if they belonged.&lt;/p&gt;
&lt;p&gt;This strategy worked because we don’t see the world objectively. We see it through categories—through what we expect to see. The thieves understood the social categories that we perceive as “normal” and exploited them to avoid suspicion. Many artificial intelligence (AI) systems work in the same way and are vulnerable to the same kinds of mistakes as a result.&lt;/p&gt;
&lt;p&gt;The sociologist Erving Goffman would describe what happened at the Louvre using his concept of the presentation of self: people “perform” social roles by adopting the cues others expect. Here, the performance of normality became the perfect camouflage.&lt;/p&gt;
&lt;h2&gt;The sociology of sight&lt;/h2&gt;
&lt;p&gt;Humans carry out mental categorization all the time to make sense of people and places. When something fits the category of “ordinary,” it slips from notice.&lt;/p&gt;
&lt;p&gt;AI systems used for tasks such as facial recognition and detecting suspicious activity in a public area operate in a similar way. For humans, categorization is cultural. For AI, it is mathematical.&lt;/p&gt;
&lt;p&gt;But both systems rely on learned patterns rather than objective reality. Because AI learns from data about who looks “normal” and who looks “suspicious,” it absorbs the categories embedded in its training data. And this makes it susceptible to bias.&lt;/p&gt;
&lt;p&gt;The Louvre robbers weren’t seen as dangerous because they fit a trusted category. In AI, the same process can have the opposite effect: people who don’t fit the statistical norm become more visible and over-scrutinized.&lt;/p&gt;
&lt;p&gt;It can mean a facial recognition system disproportionately flags certain racial or gendered groups as potential threats while letting others pass unnoticed.&lt;/p&gt;
&lt;p&gt;A sociological lens helps us see that these aren’t separate issues. AI doesn’t invent its categories; it learns ours. When a computer vision system is trained on security footage where “normal” is defined by particular bodies, clothing, or behavior, it reproduces those assumptions.&lt;/p&gt;
&lt;p&gt;Just as the museum’s guards looked past the thieves because they appeared to belong, AI can look past certain patterns while overreacting to others.&lt;/p&gt;
&lt;p&gt;Categorization, whether human or algorithmic, is a double-edged sword. It helps us process information quickly, but it also encodes our cultural assumptions. Both people and machines rely on pattern recognition, which is an efficient but imperfect strategy.&lt;/p&gt;
&lt;p&gt;A sociological view of AI treats algorithms as mirrors: They reflect back our social categories and hierarchies. In the Louvre case, the mirror is turned toward us. The robbers succeeded not because they were invisible, but because they were seen through the lens of normality. In AI terms, they passed the classification test.&lt;/p&gt;
&lt;h2&gt;From museum halls to machine learning&lt;/h2&gt;
&lt;p&gt;This link between perception and categorization reveals something important about our increasingly algorithmic world. Whether it’s a guard deciding who looks suspicious or an AI deciding who looks like a “shoplifter,” the underlying process is the same: assigning people to categories based on cues that feel objective but are culturally learned.&lt;/p&gt;
&lt;p&gt;When an AI system is described as “biased,” this often means that it reflects those social categories too faithfully. The Louvre heist reminds us that these categories don’t just shape our attitudes, they shape what gets noticed at all.&lt;/p&gt;
&lt;p&gt;After the theft, France’s culture minister promised new cameras and tighter security. But no matter how advanced those systems become, they will still rely on categorization. Someone, or something, must decide what counts as “suspicious behavior.” If that decision rests on assumptions, the same blind spots will persist.&lt;/p&gt;
&lt;p&gt;The Louvre robbery will be remembered as one of Europe’s most spectacular museum thefts. The thieves succeeded because they mastered the sociology of appearance: They understood the categories of normality and used them as tools.&lt;/p&gt;
&lt;p&gt;And in doing so, they showed how both people and machines can mistake conformity for safety. Their success in broad daylight wasn’t only a triumph of planning. It was a triumph of categorical thinking, the same logic that underlies both human perception and artificial intelligence.&lt;/p&gt;
&lt;p&gt;The lesson is clear: Before we teach machines to see better, we must first learn to question how we see.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Vincent Charles, Reader in AI for Business and Management Science, Queen’s University Belfast, and Tatiana Gherman, Associate Professor of AI for Business and Strategy, University of Northampton. &amp;nbsp;This article is republished from The Conversation under a Creative Commons license. Read the original article.&lt;/em&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;/div&gt;


          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        For humans and AI, when something fits the category of “ordinary,” it slips from notice.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Balcony Louvre building at night" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2242090240-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Balcony Louvre building at night" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2242090240-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A close-up of the facade of the Louvre Museum and a broken window after the robbery of the century.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          yann vernerie

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p class="theconversation-article-title"&gt;&lt;span style="font-size: 16px;"&gt;On a sunny &lt;/span&gt;morning on October 19 2025, four men allegedly walked into the world’s most-visited museum and left, minutes later, with crown jewels worth 88 million euros ($101 million). The theft from Paris’ Louvre Museum—one of the world’s most surveilled cultural institutions—took just under eight minutes.&lt;/p&gt;
&lt;div class="theconversation-article-body"&gt;
&lt;p&gt;Visitors kept browsing. Security didn’t react (until alarms were triggered). The men disappeared into the city’s traffic before anyone realized what had happened.&lt;/p&gt;
&lt;p&gt;Investigators later revealed that the thieves wore hi-vis vests, disguising themselves as construction workers. They arrived with a furniture lift, a common sight in Paris’s narrow streets, and used it to reach a balcony overlooking the Seine. Dressed as workers, they looked as if they belonged.&lt;/p&gt;
&lt;p&gt;This strategy worked because we don’t see the world objectively. We see it through categories—through what we expect to see. The thieves understood the social categories that we perceive as “normal” and exploited them to avoid suspicion. Many artificial intelligence (AI) systems work in the same way and are vulnerable to the same kinds of mistakes as a result.&lt;/p&gt;
&lt;p&gt;The sociologist Erving Goffman would describe what happened at the Louvre using his concept of the presentation of self: people “perform” social roles by adopting the cues others expect. Here, the performance of normality became the perfect camouflage.&lt;/p&gt;
&lt;h2&gt;The sociology of sight&lt;/h2&gt;
&lt;p&gt;Humans carry out mental categorization all the time to make sense of people and places. When something fits the category of “ordinary,” it slips from notice.&lt;/p&gt;
&lt;p&gt;AI systems used for tasks such as facial recognition and detecting suspicious activity in a public area operate in a similar way. For humans, categorization is cultural. For AI, it is mathematical.&lt;/p&gt;
&lt;p&gt;But both systems rely on learned patterns rather than objective reality. Because AI learns from data about who looks “normal” and who looks “suspicious,” it absorbs the categories embedded in its training data. And this makes it susceptible to bias.&lt;/p&gt;
&lt;p&gt;The Louvre robbers weren’t seen as dangerous because they fit a trusted category. In AI, the same process can have the opposite effect: people who don’t fit the statistical norm become more visible and over-scrutinized.&lt;/p&gt;
&lt;p&gt;It can mean a facial recognition system disproportionately flags certain racial or gendered groups as potential threats while letting others pass unnoticed.&lt;/p&gt;
&lt;p&gt;A sociological lens helps us see that these aren’t separate issues. AI doesn’t invent its categories; it learns ours. When a computer vision system is trained on security footage where “normal” is defined by particular bodies, clothing, or behavior, it reproduces those assumptions.&lt;/p&gt;
&lt;p&gt;Just as the museum’s guards looked past the thieves because they appeared to belong, AI can look past certain patterns while overreacting to others.&lt;/p&gt;
&lt;p&gt;Categorization, whether human or algorithmic, is a double-edged sword. It helps us process information quickly, but it also encodes our cultural assumptions. Both people and machines rely on pattern recognition, which is an efficient but imperfect strategy.&lt;/p&gt;
&lt;p&gt;A sociological view of AI treats algorithms as mirrors: They reflect back our social categories and hierarchies. In the Louvre case, the mirror is turned toward us. The robbers succeeded not because they were invisible, but because they were seen through the lens of normality. In AI terms, they passed the classification test.&lt;/p&gt;
&lt;h2&gt;From museum halls to machine learning&lt;/h2&gt;
&lt;p&gt;This link between perception and categorization reveals something important about our increasingly algorithmic world. Whether it’s a guard deciding who looks suspicious or an AI deciding who looks like a “shoplifter,” the underlying process is the same: assigning people to categories based on cues that feel objective but are culturally learned.&lt;/p&gt;
&lt;p&gt;When an AI system is described as “biased,” this often means that it reflects those social categories too faithfully. The Louvre heist reminds us that these categories don’t just shape our attitudes, they shape what gets noticed at all.&lt;/p&gt;
&lt;p&gt;After the theft, France’s culture minister promised new cameras and tighter security. But no matter how advanced those systems become, they will still rely on categorization. Someone, or something, must decide what counts as “suspicious behavior.” If that decision rests on assumptions, the same blind spots will persist.&lt;/p&gt;
&lt;p&gt;The Louvre robbery will be remembered as one of Europe’s most spectacular museum thefts. The thieves succeeded because they mastered the sociology of appearance: They understood the categories of normality and used them as tools.&lt;/p&gt;
&lt;p&gt;And in doing so, they showed how both people and machines can mistake conformity for safety. Their success in broad daylight wasn’t only a triumph of planning. It was a triumph of categorical thinking, the same logic that underlies both human perception and artificial intelligence.&lt;/p&gt;
&lt;p&gt;The lesson is clear: Before we teach machines to see better, we must first learn to question how we see.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Vincent Charles, Reader in AI for Business and Management Science, Queen’s University Belfast, and Tatiana Gherman, Associate Professor of AI for Business and Strategy, University of Northampton. &amp;nbsp;This article is republished from The Conversation under a Creative Commons license. Read the original article.&lt;/em&gt;&lt;br /&gt;
&lt;/p&gt;
&lt;/div&gt;


          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/science/2025/11/how-louvre-thieves-exploited-human-psychology-to-avoid-suspicion-and-what-it-reveals-about-ai/</guid><pubDate>Wed, 19 Nov 2025 14:41:52 +0000</pubDate></item><item><title>[NEW] Adobe to buy Semrush for $1.9 billion (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/adobe-to-buy-semrush-for-1-9-billion/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2162453288.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Adobe said on Wednesday that it has agreed to acquire search engine optimization company Semrush for about $1.9 billion in cash, as the Photoshop maker seeks to augment its suite of marketing offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement, Adobe said it would offer $12 per share for Semrush, almost double the latter’s closing price of $6.89 on Tuesday, before news of the deal. Semrush had a market capitalization of about $1 billion as of Tuesday’s close.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;By acquiring Semrush, Adobe is betting that companies will choose to invest in optimizing their content and web pages to be more visible to AI tools, as people increasingly use AI chatbots, agents, and AI browsers to do everything from getting the news and finding recipes to shopping and booking their travel. This is a fresh, big market for existing search engine optimization players like Semrush, particularly as this change in consumer behavior drives increasing traffic to websites from generative AI tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, as of October, traffic to retail websites from generative AI chatbots increased 1,200% compared to a year earlier, per Adobe Analytics data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Semrush has been investing in what it calls “generative engine optimization,” and recently launched a tool for tracking and improving website performance using both traditional SEO techniques and optimization for AI engines, like ChatGPT, Claude, Copilot, Grok, and Perplexity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Brand visibility is being reshaped by generative AI, and brands that don’t embrace this new opportunity risk losing relevance and revenue,” said Anil Chakravarthy, president of Adobe’s Digital Experience Business. “With Semrush, we’re unlocking GEO for marketers as a new growth channel alongside their SEO, driving more visibility, customer engagement and conversions across the ecosystem.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2162453288.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Adobe said on Wednesday that it has agreed to acquire search engine optimization company Semrush for about $1.9 billion in cash, as the Photoshop maker seeks to augment its suite of marketing offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement, Adobe said it would offer $12 per share for Semrush, almost double the latter’s closing price of $6.89 on Tuesday, before news of the deal. Semrush had a market capitalization of about $1 billion as of Tuesday’s close.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;By acquiring Semrush, Adobe is betting that companies will choose to invest in optimizing their content and web pages to be more visible to AI tools, as people increasingly use AI chatbots, agents, and AI browsers to do everything from getting the news and finding recipes to shopping and booking their travel. This is a fresh, big market for existing search engine optimization players like Semrush, particularly as this change in consumer behavior drives increasing traffic to websites from generative AI tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, as of October, traffic to retail websites from generative AI chatbots increased 1,200% compared to a year earlier, per Adobe Analytics data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Semrush has been investing in what it calls “generative engine optimization,” and recently launched a tool for tracking and improving website performance using both traditional SEO techniques and optimization for AI engines, like ChatGPT, Claude, Copilot, Grok, and Perplexity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Brand visibility is being reshaped by generative AI, and brands that don’t embrace this new opportunity risk losing relevance and revenue,” said Anil Chakravarthy, president of Adobe’s Digital Experience Business. “With Semrush, we’re unlocking GEO for marketers as a new growth channel alongside their SEO, driving more visibility, customer engagement and conversions across the ecosystem.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/adobe-to-buy-semrush-for-1-9-billion/</guid><pubDate>Wed, 19 Nov 2025 15:42:15 +0000</pubDate></item><item><title>[NEW] DeepMind’s latest: An AI for handling mathematical proofs (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/deepminds-latest-an-ai-for-handling-mathematical-proofs/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AlphaProof can handle math challenges but needs a bit of help right now.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A woman standing in front of a white board that is packed with equations." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-643999103-640x427.jpg" width="640" /&gt;
                  &lt;img alt="A woman standing in front of a white board that is packed with equations." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-643999103-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Hill Street Studios

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Computers are extremely good with numbers, but they haven’t gotten many human mathematicians fired. Until recently, they could barely hold their own in high school-level math competitions.&lt;/p&gt;
&lt;p&gt;But now Google’s DeepMind team has built AlphaProof, an AI system that matched silver medalists’ performance at the 2024 International Mathematical Olympiad, scoring just one point short of gold at the most prestigious undergrad math competition in the world. And that’s kind of a big deal.&lt;/p&gt;
&lt;h2&gt;True understanding&lt;/h2&gt;
&lt;p&gt;The reason computers fared poorly in math competitions is that, while they far surpass humanity’s ability to perform calculations, they are not really that good at the logic and reasoning that is needed for advanced math. Put differently, they are good at performing calculations really quickly, but they usually suck at understanding why they’re doing them. While something like addition seems simple, humans can do semi-formal proofs based on definitions of addition or go for fully formal Peano arithmetic that defines the properties of natural numbers and operations like addition through axioms.&lt;/p&gt;
&lt;p&gt;To perform a proof, humans have to understand the very structure of mathematics. The way mathematicians build proofs, how many steps they need to arrive at the conclusion, and how cleverly they design those steps are a testament to their brilliance, ingenuity, and mathematical elegance. “You know, Bertrand Russel published a 500-page book to prove that one plus one equals two,” says Thomas Hubert, a DeepMind researcher and lead author of the AlphaProof study.&lt;/p&gt;
&lt;p&gt;DeepMind’s team wanted to develop an AI that understood math at this level. The work started with solving the usual AI problem: the lack of training data.&lt;/p&gt;
&lt;h2&gt;Math problems translator&lt;/h2&gt;
&lt;p&gt;Large language models that power AI systems like Chat GPT learn from billions upon billions of pages of text. Because there are texts on mathematics in their training databases—all the handbooks and works of famous mathematicians—they show some level of success in proving mathematical statements. But they are limited by how they operate: They rely on using huge neural nets to predict the next word or token in sequences generated in response to user prompts. Their reasoning is statistical by design, which means they simply return answers that “sound” right.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;DeepMind didn’t need the AI to “sound” right—that wasn’t going to cut it in high-level mathematics. They needed their AI to “be” right, to guarantee absolute certainty. That called for an entirely new, more formalized training environment. To provide that, the team used a software package called Lean.&lt;/p&gt;
&lt;p&gt;Lean is a computer program that helps mathematicians write precise definitions and proofs. It relies on a precise, formal programming language that’s also called Lean, which mathematical statements can be translated into. Once the translated or formalized statement is uploaded to the program, it can check if it is correct and get back with responses like “this is correct,” “something is missing,” or “you used a fact that is not proved yet.”&lt;/p&gt;
&lt;p&gt;The problem was, most mathematical statements and proofs that can be found online are written in natural language like “let X be the set of natural numbers that…”—the number of statements written in Lean was rather limited. “The major difficulty of working with formal languages is that there’s very little data,” Hubert says. To go around it, the researchers trained a Gemini large language model to translate mathematical statements from natural language to Lean. The model worked like an automatic formalizer&amp;nbsp;and produced about 80 million formalized mathematical statements.&lt;/p&gt;
&lt;p&gt;It wasn’t perfect, but the team managed to use that to their advantage. “There are many ways you can capitalize on approximate translations,” Hubert claims.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Learning to think&lt;/h2&gt;
&lt;p&gt;The idea DeepMind had for the AlphaProof was to use the architecture the team used in their chess-, &lt;em&gt;Go-&lt;/em&gt;, and shogi-playing AlphaZero AI system. Building proofs in Lean and Mathematics in general was supposed to be just another game to master. “We were trying to learn this game through trial and error,” Hubert says. Imperfectly formalized problems offered great opportunity for making errors. In its learning phase, AlphaProof was simply proving and disproving the problems it had in its database. If something was translated poorly, figuring out that something wasn’t right was a useful form of exercise.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Just like AlphaZero, AlphaProof in most cases used two main components. The first was a huge neural net with a few billion parameters that learned to work in the Lean environment through trial and error. It was rewarded for each proven or disproven statement and penalized for each reasoning step it took, which was a way of incentivizing short, elegant proofs.&lt;/p&gt;
&lt;p&gt;It was also trained to use a second component, which was a tree search algorithm. This explored all possible actions that could be taken to push the proof forward at each step. Because the number of possible actions in mathematics can be near infinite, the job of the neural net was to look at the available branches in the search tree and commit computational budget only to the most promising ones.&lt;/p&gt;
&lt;p&gt;After a few weeks of training, the system could score well on most math competition benchmarks based on problems sourced from past high school-level competitions, but it still struggled with the most difficult of them. To tackle these, the team added a third component that hadn’t been in AlphaZero. Or anywhere else.&lt;/p&gt;
&lt;h2&gt;Spark of humanity&lt;/h2&gt;
&lt;p&gt;The third component, called Test-Time Reinforcement Learning (TTRL), roughly emulated the way mathematicians approach the most difficult problems. The learning part relied on the same combination of neural nets with search tree algorithms. The difference came in what it learned from. Instead of relying on a broad database of auto-formalized problems, AlphaProof working in the TTRL mode started its work by generating an entirely new training dataset based on the problem it was dealing with.&lt;/p&gt;
&lt;p&gt;The process involved creating countless variations of the original statement, some simplified a little bit more, some more general, and some only loosely connected to it. The system then attempted to prove or disprove them. It was roughly what most humans do when they’re facing a particularly hard puzzle, the AI equivalent of saying, “I don’t get it, so let’s try an easier version of this first to get some practice.” This allowed AlphaProof to learn on the fly, and it worked amazingly well.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;At the 2024 International Mathematics Olympiad, there were 42 points to score for solving six different problems worth seven points each. To win gold, participants had to get 29 points or higher, and 58 out of 609 of them did that. Silver medals were awarded to people who earned between 22 and 28 points (there were 123 silver medalists). The problems varied in difficulty, with the sixth one, acting as a “final boss,” being the most difficult of them all. Only six participants managed to solve it. AlphaProof was the seventh.&lt;/p&gt;
&lt;p&gt;But AlphaProof wasn’t an end-all, be-all mathematical genius. Its silver had its price—quite literally.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Optimizing ingenuity&lt;/h2&gt;
&lt;p&gt;The first problem with AlphaProof’s performance was that it didn’t work alone. To begin with, humans had to make the problems compatible with Lean before the software even got to work. And, among the six Olympic problems, the fourth one was about geometry, and the AI was not optimized for that. To deal with it, AlphaProof had to call a friend called AlphaGeometry 2, a geometry-specialized AI that ripped through the task in a few minutes without breaking a sweat. On its own, AlphaProof scored 21 points, not 28, so technically it would win bronze, not silver. Except it wouldn’t.&lt;/p&gt;
&lt;p&gt;Human participants of the Olympiad had to solve their six problems in two sessions, four-and-a-half hours long. AlphaProof, on the other hand, wrestled with them for several days using multiple tensor processing units at full throttle. The most time- and energy-consuming component was TTRL, which battled with the three problems it managed to solve for three days each. If AlphaProof was held up to the same standard as human participants, it would basically run out of time. And if it wasn’t born at a tech giant worth hundreds of billions of dollars, it would run out of money, too.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In the paper, the team admits the computational requirements to run AlphaProof are most likely cost-prohibitive for most research groups and aspiring mathematicians. Computing power in AI applications is often measured in TPU-days, meaning a tensor processing unit working flat-out for a full day. AlphaProof needed hundreds of TPU-days per problem.&lt;/p&gt;
&lt;p&gt;On top of that, the International Mathematics Olympiad is a high school-level competition, and the problems, while admittedly difficult, were based on things mathematicians already know. Research-level math requires inventing entirely new concepts instead of just working with existing ones.&lt;/p&gt;
&lt;p&gt;But DeepMind thinks it can overcome these hurdles and optimize AlphaProof to be less resource-hungry. “We don’t want to stop at math competitions. We want to build an AI system that could really contribute to research-level mathematics,” Hubert says. His goal is to make AlphaProof available to the broader research community. “We’re also releasing a kind of an AlphaProof tool,” he added. “It would be a small trusted testers program to see if this would be useful to mathematicians.”&lt;/p&gt;
&lt;p&gt;Nature, 2025. &amp;nbsp;DOI: 10.1038/s41586-025-09833-y&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AlphaProof can handle math challenges but needs a bit of help right now.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A woman standing in front of a white board that is packed with equations." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-643999103-640x427.jpg" width="640" /&gt;
                  &lt;img alt="A woman standing in front of a white board that is packed with equations." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-643999103-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Hill Street Studios

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Computers are extremely good with numbers, but they haven’t gotten many human mathematicians fired. Until recently, they could barely hold their own in high school-level math competitions.&lt;/p&gt;
&lt;p&gt;But now Google’s DeepMind team has built AlphaProof, an AI system that matched silver medalists’ performance at the 2024 International Mathematical Olympiad, scoring just one point short of gold at the most prestigious undergrad math competition in the world. And that’s kind of a big deal.&lt;/p&gt;
&lt;h2&gt;True understanding&lt;/h2&gt;
&lt;p&gt;The reason computers fared poorly in math competitions is that, while they far surpass humanity’s ability to perform calculations, they are not really that good at the logic and reasoning that is needed for advanced math. Put differently, they are good at performing calculations really quickly, but they usually suck at understanding why they’re doing them. While something like addition seems simple, humans can do semi-formal proofs based on definitions of addition or go for fully formal Peano arithmetic that defines the properties of natural numbers and operations like addition through axioms.&lt;/p&gt;
&lt;p&gt;To perform a proof, humans have to understand the very structure of mathematics. The way mathematicians build proofs, how many steps they need to arrive at the conclusion, and how cleverly they design those steps are a testament to their brilliance, ingenuity, and mathematical elegance. “You know, Bertrand Russel published a 500-page book to prove that one plus one equals two,” says Thomas Hubert, a DeepMind researcher and lead author of the AlphaProof study.&lt;/p&gt;
&lt;p&gt;DeepMind’s team wanted to develop an AI that understood math at this level. The work started with solving the usual AI problem: the lack of training data.&lt;/p&gt;
&lt;h2&gt;Math problems translator&lt;/h2&gt;
&lt;p&gt;Large language models that power AI systems like Chat GPT learn from billions upon billions of pages of text. Because there are texts on mathematics in their training databases—all the handbooks and works of famous mathematicians—they show some level of success in proving mathematical statements. But they are limited by how they operate: They rely on using huge neural nets to predict the next word or token in sequences generated in response to user prompts. Their reasoning is statistical by design, which means they simply return answers that “sound” right.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;DeepMind didn’t need the AI to “sound” right—that wasn’t going to cut it in high-level mathematics. They needed their AI to “be” right, to guarantee absolute certainty. That called for an entirely new, more formalized training environment. To provide that, the team used a software package called Lean.&lt;/p&gt;
&lt;p&gt;Lean is a computer program that helps mathematicians write precise definitions and proofs. It relies on a precise, formal programming language that’s also called Lean, which mathematical statements can be translated into. Once the translated or formalized statement is uploaded to the program, it can check if it is correct and get back with responses like “this is correct,” “something is missing,” or “you used a fact that is not proved yet.”&lt;/p&gt;
&lt;p&gt;The problem was, most mathematical statements and proofs that can be found online are written in natural language like “let X be the set of natural numbers that…”—the number of statements written in Lean was rather limited. “The major difficulty of working with formal languages is that there’s very little data,” Hubert says. To go around it, the researchers trained a Gemini large language model to translate mathematical statements from natural language to Lean. The model worked like an automatic formalizer&amp;nbsp;and produced about 80 million formalized mathematical statements.&lt;/p&gt;
&lt;p&gt;It wasn’t perfect, but the team managed to use that to their advantage. “There are many ways you can capitalize on approximate translations,” Hubert claims.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Learning to think&lt;/h2&gt;
&lt;p&gt;The idea DeepMind had for the AlphaProof was to use the architecture the team used in their chess-, &lt;em&gt;Go-&lt;/em&gt;, and shogi-playing AlphaZero AI system. Building proofs in Lean and Mathematics in general was supposed to be just another game to master. “We were trying to learn this game through trial and error,” Hubert says. Imperfectly formalized problems offered great opportunity for making errors. In its learning phase, AlphaProof was simply proving and disproving the problems it had in its database. If something was translated poorly, figuring out that something wasn’t right was a useful form of exercise.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Just like AlphaZero, AlphaProof in most cases used two main components. The first was a huge neural net with a few billion parameters that learned to work in the Lean environment through trial and error. It was rewarded for each proven or disproven statement and penalized for each reasoning step it took, which was a way of incentivizing short, elegant proofs.&lt;/p&gt;
&lt;p&gt;It was also trained to use a second component, which was a tree search algorithm. This explored all possible actions that could be taken to push the proof forward at each step. Because the number of possible actions in mathematics can be near infinite, the job of the neural net was to look at the available branches in the search tree and commit computational budget only to the most promising ones.&lt;/p&gt;
&lt;p&gt;After a few weeks of training, the system could score well on most math competition benchmarks based on problems sourced from past high school-level competitions, but it still struggled with the most difficult of them. To tackle these, the team added a third component that hadn’t been in AlphaZero. Or anywhere else.&lt;/p&gt;
&lt;h2&gt;Spark of humanity&lt;/h2&gt;
&lt;p&gt;The third component, called Test-Time Reinforcement Learning (TTRL), roughly emulated the way mathematicians approach the most difficult problems. The learning part relied on the same combination of neural nets with search tree algorithms. The difference came in what it learned from. Instead of relying on a broad database of auto-formalized problems, AlphaProof working in the TTRL mode started its work by generating an entirely new training dataset based on the problem it was dealing with.&lt;/p&gt;
&lt;p&gt;The process involved creating countless variations of the original statement, some simplified a little bit more, some more general, and some only loosely connected to it. The system then attempted to prove or disprove them. It was roughly what most humans do when they’re facing a particularly hard puzzle, the AI equivalent of saying, “I don’t get it, so let’s try an easier version of this first to get some practice.” This allowed AlphaProof to learn on the fly, and it worked amazingly well.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;At the 2024 International Mathematics Olympiad, there were 42 points to score for solving six different problems worth seven points each. To win gold, participants had to get 29 points or higher, and 58 out of 609 of them did that. Silver medals were awarded to people who earned between 22 and 28 points (there were 123 silver medalists). The problems varied in difficulty, with the sixth one, acting as a “final boss,” being the most difficult of them all. Only six participants managed to solve it. AlphaProof was the seventh.&lt;/p&gt;
&lt;p&gt;But AlphaProof wasn’t an end-all, be-all mathematical genius. Its silver had its price—quite literally.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Optimizing ingenuity&lt;/h2&gt;
&lt;p&gt;The first problem with AlphaProof’s performance was that it didn’t work alone. To begin with, humans had to make the problems compatible with Lean before the software even got to work. And, among the six Olympic problems, the fourth one was about geometry, and the AI was not optimized for that. To deal with it, AlphaProof had to call a friend called AlphaGeometry 2, a geometry-specialized AI that ripped through the task in a few minutes without breaking a sweat. On its own, AlphaProof scored 21 points, not 28, so technically it would win bronze, not silver. Except it wouldn’t.&lt;/p&gt;
&lt;p&gt;Human participants of the Olympiad had to solve their six problems in two sessions, four-and-a-half hours long. AlphaProof, on the other hand, wrestled with them for several days using multiple tensor processing units at full throttle. The most time- and energy-consuming component was TTRL, which battled with the three problems it managed to solve for three days each. If AlphaProof was held up to the same standard as human participants, it would basically run out of time. And if it wasn’t born at a tech giant worth hundreds of billions of dollars, it would run out of money, too.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In the paper, the team admits the computational requirements to run AlphaProof are most likely cost-prohibitive for most research groups and aspiring mathematicians. Computing power in AI applications is often measured in TPU-days, meaning a tensor processing unit working flat-out for a full day. AlphaProof needed hundreds of TPU-days per problem.&lt;/p&gt;
&lt;p&gt;On top of that, the International Mathematics Olympiad is a high school-level competition, and the problems, while admittedly difficult, were based on things mathematicians already know. Research-level math requires inventing entirely new concepts instead of just working with existing ones.&lt;/p&gt;
&lt;p&gt;But DeepMind thinks it can overcome these hurdles and optimize AlphaProof to be less resource-hungry. “We don’t want to stop at math competitions. We want to build an AI system that could really contribute to research-level mathematics,” Hubert says. His goal is to make AlphaProof available to the broader research community. “We’re also releasing a kind of an AlphaProof tool,” he added. “It would be a small trusted testers program to see if this would be useful to mathematicians.”&lt;/p&gt;
&lt;p&gt;Nature, 2025. &amp;nbsp;DOI: 10.1038/s41586-025-09833-y&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/deepminds-latest-an-ai-for-handling-mathematical-proofs/</guid><pubDate>Wed, 19 Nov 2025 15:57:30 +0000</pubDate></item><item><title>[NEW] Scaling innovation in manufacturing with AI (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/19/1128067/scaling-innovation-in-manufacturing-with-ai/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Microsoft and NVIDIA&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Manufacturing is getting a major system upgrade. As AI amplifies existing technologies—like digital twins, the cloud, edge computing, and the industrial internet of things (IIoT)—it is enabling factory operations teams to shift from reactive, isolated problem-solving to proactive, systemwide optimization.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1128068" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/Cover-MITTR_MicrosoftNVIDIA_November2025.png?w=1556" width="1556" /&gt;&lt;/figure&gt;  &lt;p&gt;Digital twins—physically accurate virtual representations of a piece of equipment, a production line, a process, or even an entire factory—allow workers to test, optimize, and contextualize complex, real-world environments. Manufacturers are using digital twins to simulate factory environments with pinpoint detail.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“AI-powered digital twins mark a major evolution in the future of manufacturing, enabling real-time visualization of the entire production line, not just individual machines,” says Indranil Sircar, global chief technology officer for the manufacturing and mobility industry at Microsoft. “This is allowing manufacturers to move beyond isolated monitoring toward much wider insights.”&lt;/p&gt;  &lt;p&gt;A digital twin of a bottling line, for example, can integrate one-dimensional shop-floor telemetry, two-dimensional enterprise data, and three-dimensional immersive modeling into a single operational view of the entire production line to improve efficiency and reduce costly downtime. Many high-speed industries face downtime rates as high as 40%, estimates Jon Sobel, co-founder and chief executive officer of Sight Machine, an industrial AI company that partners with Microsoft and NVIDIA to transform complex data into actionable insights. By tracking micro-stops and quality metrics via digital twins, companies can target improvements and adjustments with greater precision, saving millions in once-lost productivity without disrupting ongoing operations.&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128075" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR-MicrosoftNVIDIA-JonSobelSocials_V2-1.png" /&gt;&lt;/figure&gt;  &lt;p&gt;AI offers the next opportunity. Sircar estimates that up to 50% of manufacturers are currently deploying AI in production. This is up from 35% of manufacturers surveyed in a 2024 MIT Technology Review Insights report who said they have begun to put AI use cases into production. Larger manufacturers with more than $10 billion in revenue were significantly ahead, with 77% already deploying AI use cases, according to the report.&lt;/p&gt;  &lt;p&gt;“Manufacturing has a lot of data and is a perfect use case for AI,” says Sobel. “An industry that has been seen by some as lagging when it comes to digital technology and AI may be in the best position to lead. It’s very unexpected.” &lt;/p&gt;  &lt;p&gt;&lt;em&gt;Download the report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Microsoft and NVIDIA&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Manufacturing is getting a major system upgrade. As AI amplifies existing technologies—like digital twins, the cloud, edge computing, and the industrial internet of things (IIoT)—it is enabling factory operations teams to shift from reactive, isolated problem-solving to proactive, systemwide optimization.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1128068" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/Cover-MITTR_MicrosoftNVIDIA_November2025.png?w=1556" width="1556" /&gt;&lt;/figure&gt;  &lt;p&gt;Digital twins—physically accurate virtual representations of a piece of equipment, a production line, a process, or even an entire factory—allow workers to test, optimize, and contextualize complex, real-world environments. Manufacturers are using digital twins to simulate factory environments with pinpoint detail.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“AI-powered digital twins mark a major evolution in the future of manufacturing, enabling real-time visualization of the entire production line, not just individual machines,” says Indranil Sircar, global chief technology officer for the manufacturing and mobility industry at Microsoft. “This is allowing manufacturers to move beyond isolated monitoring toward much wider insights.”&lt;/p&gt;  &lt;p&gt;A digital twin of a bottling line, for example, can integrate one-dimensional shop-floor telemetry, two-dimensional enterprise data, and three-dimensional immersive modeling into a single operational view of the entire production line to improve efficiency and reduce costly downtime. Many high-speed industries face downtime rates as high as 40%, estimates Jon Sobel, co-founder and chief executive officer of Sight Machine, an industrial AI company that partners with Microsoft and NVIDIA to transform complex data into actionable insights. By tracking micro-stops and quality metrics via digital twins, companies can target improvements and adjustments with greater precision, saving millions in once-lost productivity without disrupting ongoing operations.&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128075" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR-MicrosoftNVIDIA-JonSobelSocials_V2-1.png" /&gt;&lt;/figure&gt;  &lt;p&gt;AI offers the next opportunity. Sircar estimates that up to 50% of manufacturers are currently deploying AI in production. This is up from 35% of manufacturers surveyed in a 2024 MIT Technology Review Insights report who said they have begun to put AI use cases into production. Larger manufacturers with more than $10 billion in revenue were significantly ahead, with 77% already deploying AI use cases, according to the report.&lt;/p&gt;  &lt;p&gt;“Manufacturing has a lot of data and is a perfect use case for AI,” says Sobel. “An industry that has been seen by some as lagging when it comes to digital technology and AI may be in the best position to lead. It’s very unexpected.” &lt;/p&gt;  &lt;p&gt;&lt;em&gt;Download the report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/19/1128067/scaling-innovation-in-manufacturing-with-ai/</guid><pubDate>Wed, 19 Nov 2025 16:54:55 +0000</pubDate></item><item><title>[NEW] YC-backed Poly relaunches as a cloud-hosted file storage with AI search (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/yc-backed-poly-relaunches-as-a-cloud-hosted-file-storage-with-ai-search/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;One of the most common use cases to have come out of new-age AI models is to power natural language search and find files and other information quicker and faster. There are already several companies that allow you to connect different services to search through data. Now, a startup called Poly is launching a service that encourages you to dump all your files into one place so you can query them to find the right content. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, it’s giving 100GB of storage to users on its free tier.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This is Poly’s second inning from a product perspective. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company was started by founders Abhay Agarwal and Sam Young in 2022. Young has since left the company. At that time, the startup, which had participated in the startup accelerator Y Combinator, allowed users to create 3D assets using prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agarwal, who is a research fellow at Microsoft and worked on vision AI to help the visually impaired, said the company didn’t predict that the AI image and asset generation industry would blow up and competitors would raise large sums rapidly. That’s when the team decided to pivot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We interviewed our users and asked them what the pain points of their workflows were that could be solved by AI. Turned out that one big unmet need for users was organizing their file system. As a user, you have a lot of files on your computer, and it is hard to find stuff. We wanted to solve for that,” Agarwal said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said that the startup shut down the previous iteration of Poly in 2023, went into stealth, and started building the new cloud-based file organizer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is now launching the product for the public after testing it in closed beta for a few months. Currently, you can use Poly on the web or Mac, with a Windows version coming soon. The company will start onboarding users from its waitlist starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Poly has raised $8 million in seed funding led by Felicis, with participation from Bloomberg Beta, NextView, Figma Ventures, AI Grant, Wing Ventures, and MVP Ventures. This includes the prior $3.9 million round raised in 2022.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“File systems are incredibly powerful and elegant, but most people have forgotten about them. Poly is bringing file systems as the center of interaction. The tool is designed in a way that allows you to use AI to think in a clearer way,” James Cham, a partner at the early-stage investment firm Bloomberg Beta told TechCrunch.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069107" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Search-Screenshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Poly&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Poly acts like a cloud storage tool with AI-powered search. At the moment, the tool supports text, PDF, office docs, images, audio, video, and web files (URLs). You can upload files to Poly, tag them, ask the AI assistant questions about them, and even ask it to summarize or translate the files. Plus, the tool organizes your files for you and can create new folders or rename files, as needed.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Agarwal views it as an upgrade to Google’s NotebookLM, which people use to put files into a project, ask questions, and generate insights as audio or video. However, while Poly might be a better file organizer, it doesn’t have access to the latest web knowledge or the ability to create audio or video.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founder added that, in the coming months, the tool will add more features, including web search, support for creating stylized reports within the app, a text and markdown editor, and the ability to add custom metadata. It will also allow users to paste Google Docs links and let people use AI agents to perform calculations and analysis on spreadsheets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Poly, users can create shared drives, add files, and invite others to ask questions about them, which could be useful when you are on a project with other people. The startup said it also plans to add a feature to let users directly share individual files and folders.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069108" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Agent-Screenshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Poly&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Poly will directly compete with the likes of Dropbox and Google Drive, both of which have their own search tools. In my experience of using Poly’s tool for a few days, the search worked better than Google’s. Plus, there is an added benefit of just pasting the YouTube video’s link and generating a summary about it. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While there are plenty of AI and search offerings on the market, one of Poly’s biggest advantages is its 100GB of storage for free users, which is much more than the free tiers of other storage services. You can also choose to pay $10 a month for 2TB of storage. Right now, there is no direct photo sync, but in the future, if the company builds features around it, Poly can be a good Google Photos alternative.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even though the tool offers substantial storage, Agarwal said that early testers have used it as a working storage for projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our primary focus is on Gen AI native creators and knowledge workers — people who are researching content or searching through their files. For instance, a service executive who wants to get insights out of many customer calls,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company currently offers a Model Context Protocol (MCP) server for you to use Poly within tools like ChatGPT or Cursor. While Poly doesn’t have direct integration with other tools for syncing, Agarwal believes that, as the app supports virtual file references, it can work on importing files from different services.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;One of the most common use cases to have come out of new-age AI models is to power natural language search and find files and other information quicker and faster. There are already several companies that allow you to connect different services to search through data. Now, a startup called Poly is launching a service that encourages you to dump all your files into one place so you can query them to find the right content. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, it’s giving 100GB of storage to users on its free tier.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This is Poly’s second inning from a product perspective. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company was started by founders Abhay Agarwal and Sam Young in 2022. Young has since left the company. At that time, the startup, which had participated in the startup accelerator Y Combinator, allowed users to create 3D assets using prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agarwal, who is a research fellow at Microsoft and worked on vision AI to help the visually impaired, said the company didn’t predict that the AI image and asset generation industry would blow up and competitors would raise large sums rapidly. That’s when the team decided to pivot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We interviewed our users and asked them what the pain points of their workflows were that could be solved by AI. Turned out that one big unmet need for users was organizing their file system. As a user, you have a lot of files on your computer, and it is hard to find stuff. We wanted to solve for that,” Agarwal said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said that the startup shut down the previous iteration of Poly in 2023, went into stealth, and started building the new cloud-based file organizer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is now launching the product for the public after testing it in closed beta for a few months. Currently, you can use Poly on the web or Mac, with a Windows version coming soon. The company will start onboarding users from its waitlist starting today. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Poly has raised $8 million in seed funding led by Felicis, with participation from Bloomberg Beta, NextView, Figma Ventures, AI Grant, Wing Ventures, and MVP Ventures. This includes the prior $3.9 million round raised in 2022.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“File systems are incredibly powerful and elegant, but most people have forgotten about them. Poly is bringing file systems as the center of interaction. The tool is designed in a way that allows you to use AI to think in a clearer way,” James Cham, a partner at the early-stage investment firm Bloomberg Beta told TechCrunch.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069107" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Search-Screenshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Poly&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Poly acts like a cloud storage tool with AI-powered search. At the moment, the tool supports text, PDF, office docs, images, audio, video, and web files (URLs). You can upload files to Poly, tag them, ask the AI assistant questions about them, and even ask it to summarize or translate the files. Plus, the tool organizes your files for you and can create new folders or rename files, as needed.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Agarwal views it as an upgrade to Google’s NotebookLM, which people use to put files into a project, ask questions, and generate insights as audio or video. However, while Poly might be a better file organizer, it doesn’t have access to the latest web knowledge or the ability to create audio or video.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founder added that, in the coming months, the tool will add more features, including web search, support for creating stylized reports within the app, a text and markdown editor, and the ability to add custom metadata. It will also allow users to paste Google Docs links and let people use AI agents to perform calculations and analysis on spreadsheets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Poly, users can create shared drives, add files, and invite others to ask questions about them, which could be useful when you are on a project with other people. The startup said it also plans to add a feature to let users directly share individual files and folders.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069108" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Agent-Screenshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Poly&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Poly will directly compete with the likes of Dropbox and Google Drive, both of which have their own search tools. In my experience of using Poly’s tool for a few days, the search worked better than Google’s. Plus, there is an added benefit of just pasting the YouTube video’s link and generating a summary about it. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While there are plenty of AI and search offerings on the market, one of Poly’s biggest advantages is its 100GB of storage for free users, which is much more than the free tiers of other storage services. You can also choose to pay $10 a month for 2TB of storage. Right now, there is no direct photo sync, but in the future, if the company builds features around it, Poly can be a good Google Photos alternative.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even though the tool offers substantial storage, Agarwal said that early testers have used it as a working storage for projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our primary focus is on Gen AI native creators and knowledge workers — people who are researching content or searching through their files. For instance, a service executive who wants to get insights out of many customer calls,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company currently offers a Model Context Protocol (MCP) server for you to use Poly within tools like ChatGPT or Cursor. While Poly doesn’t have direct integration with other tools for syncing, Agarwal believes that, as the app supports virtual file references, it can work on importing files from different services.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/yc-backed-poly-relaunches-as-a-cloud-hosted-file-storage-with-ai-search/</guid><pubDate>Wed, 19 Nov 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Amazon’s Prime Video is getting AI-generated Video Recaps for some TV shows (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/19/amazons-prime-video-is-getting-ai-generated-video-recaps-for-some-tv-shows/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;I guess we’re past the era of “&lt;em&gt;and that’s what you missed on Glee&lt;/em&gt;.” Amazon’s Prime Video streamer is adding AI-generated “Video Recaps” to help viewers catch up between seasons of shows, the company announced on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Amazon, the feature “utilizes generative AI to create theatrical-quality season recaps with synchronized narration, dialogue, and music.” It will begin rolling out in beta on Wednesday for select Prime Originals, like “Fallout,” “Tom Clancy’s Jack Ryan,” and “Upload.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Prime Video launched a similar AI-powered feature last year called “X-Ray Recaps,” which summarizes complete seasons, episodes, or parts of episodes — at the time, Amazon said that its AI model had guardrails in place to make sure that these recaps don’t inadvertently share spoilers.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069201" height="383" src="https://techcrunch.com/wp-content/uploads/2025/11/image002.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Prime Video&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Consumers have become accustomed to these kinds of text-based AI summaries, since they likely see them when their phone summarizes texts, or when they see a (perhaps unwanted) AI summary at the top of their Google results. But these video summaries veer into newer territory, which may appear more obtrusive in the viewing experience than text summaries — or, maybe they’ll be embraced by people who don’t remember what happened on “Bosch.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prime Video’s competitors are also exploring how they can integrate generative AI into their products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube TV, for example, uses a “Key Plays” feature to help viewers catch up on sports games if they start watching while the game is in progress. While it’s a bit imperfect (its algorithm seems to only be able to identify key offensive plays in baseball), the feature helped YouTube TV win its first Technical Emmy Award.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Netflix, meanwhile, is using generative AI on the production side of its business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, Netflix said it&amp;nbsp;used generative AI&amp;nbsp;in the final footage for the first time in the Argentine show “The Eternaut” to create a scene of a building collapsing. After that, “Happy Gilmore 2” used generative AI to make characters look younger in the film’s opening scene, and the producers of “Billionaires’ Bunker” used it in pre-production to envision wardrobe and set design.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The use of AI in the film industry has sparked much debate, as artists worry that these tools — which sometimes are trained without permission on their work — could endanger their livelihoods. But some argue that tools that speed up tedious busywork in animation or special effects, like Wonder Dynamics, could expand the capacity for artists to create.&lt;br /&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;I guess we’re past the era of “&lt;em&gt;and that’s what you missed on Glee&lt;/em&gt;.” Amazon’s Prime Video streamer is adding AI-generated “Video Recaps” to help viewers catch up between seasons of shows, the company announced on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Amazon, the feature “utilizes generative AI to create theatrical-quality season recaps with synchronized narration, dialogue, and music.” It will begin rolling out in beta on Wednesday for select Prime Originals, like “Fallout,” “Tom Clancy’s Jack Ryan,” and “Upload.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Prime Video launched a similar AI-powered feature last year called “X-Ray Recaps,” which summarizes complete seasons, episodes, or parts of episodes — at the time, Amazon said that its AI model had guardrails in place to make sure that these recaps don’t inadvertently share spoilers.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3069201" height="383" src="https://techcrunch.com/wp-content/uploads/2025/11/image002.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Prime Video&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Consumers have become accustomed to these kinds of text-based AI summaries, since they likely see them when their phone summarizes texts, or when they see a (perhaps unwanted) AI summary at the top of their Google results. But these video summaries veer into newer territory, which may appear more obtrusive in the viewing experience than text summaries — or, maybe they’ll be embraced by people who don’t remember what happened on “Bosch.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prime Video’s competitors are also exploring how they can integrate generative AI into their products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube TV, for example, uses a “Key Plays” feature to help viewers catch up on sports games if they start watching while the game is in progress. While it’s a bit imperfect (its algorithm seems to only be able to identify key offensive plays in baseball), the feature helped YouTube TV win its first Technical Emmy Award.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Netflix, meanwhile, is using generative AI on the production side of its business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, Netflix said it&amp;nbsp;used generative AI&amp;nbsp;in the final footage for the first time in the Argentine show “The Eternaut” to create a scene of a building collapsing. After that, “Happy Gilmore 2” used generative AI to make characters look younger in the film’s opening scene, and the producers of “Billionaires’ Bunker” used it in pre-production to envision wardrobe and set design.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The use of AI in the film industry has sparked much debate, as artists worry that these tools — which sometimes are trained without permission on their work — could endanger their livelihoods. But some argue that tools that speed up tedious busywork in animation or special effects, like Wonder Dynamics, could expand the capacity for artists to create.&lt;br /&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/19/amazons-prime-video-is-getting-ai-generated-video-recaps-for-some-tv-shows/</guid><pubDate>Wed, 19 Nov 2025 17:30:00 +0000</pubDate></item><item><title>[NEW] The Google Search of AI agents? Fetch launches ASI:One and Business tier for new era of non-human web (AI | VentureBeat)</title><link>https://venturebeat.com/ai/the-google-search-of-ai-agents-fetch-launches-asi-one-and-business-tier-for</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://fetch.ai/"&gt;Fetch AI&lt;/a&gt;, a startup founded and led by former DeepMind founding investor, Humayun Sheikh, &lt;a href="https://www.businesswire.com/news/home/20251119088395/en/Fetch-Combines-Personalized-AI-with-Multi-Agent-Collaboration-to-Handle-Complex-Consumer-Tasks-Launches-Claim-Your-Agent-to-Fight-Brand-Knock-Offs"&gt;today announced the release&lt;/a&gt; of three interconnected products designed to provide the trust, coordination, and interoperability needed for large-scale AI agent ecosystems. &lt;/p&gt;&lt;p&gt;The launch includes &lt;a href="https://asi1.ai/"&gt;ASI:One&lt;/a&gt;, a personal-AI orchestration platform; &lt;a href="https://business.fetch.ai/"&gt;Fetch Business&lt;/a&gt;, a verification and discovery portal for brand agents; and &lt;a href="https://agentverse.ai/?sort=relevancy&amp;amp;page=1&amp;amp;recommended=true"&gt;Agentverse&lt;/a&gt;, an open directory hosting more than two million agents. &lt;/p&gt;&lt;p&gt;Together, the system positions Fetch as an infrastructure provider for what it calls the “Agentic Web”—a layer where consumer AIs and brand AIs collaborate to complete tasks instead of merely suggesting them.&lt;/p&gt;&lt;p&gt;The company says the tools address a central limitation in current consumer AI: models can provide recommendations but cannot reliably execute multi-step actions that require coordination across businesses. Fetch’s approach centers on enabling agents from different organizations to interoperate securely, using verified identities and shared context to complete end-to-end workflows.&lt;/p&gt;&lt;p&gt;“We’re creating the same foundation for agents that Google created for websites,” said Humayun Sheikh, Founder and CEO of Fetch AI, and an early investor in DeepMind, in a press release provided to VentureBeat. “Instead of just finding information, your personal AI coordinates with verified brand agents to get things done.”&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Background: Fetch’s Founding and DeepMind Connection &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Fetch AI was founded in 2017 by Humayun Sheikh, an entrepreneur whose early investment in DeepMind helped support the company’s commercial development before its acquisition by Google. “I was one of the first five people at DeepMind and its first investor. My check was the first one in,” Sheikh said, reflecting on the period when advanced machine learning research was still largely inaccessible outside major technology companies.&lt;/p&gt;&lt;p&gt;His early experience helped shape Fetch’s direction. “Even in 2013, it was clear to me that agentic systems were going to be the ones that worked. That’s where I focused—on the agentic web,” Sheikh noted. Fetch built on this thesis by developing infrastructure for autonomous software agents, focusing on verifiable identity, secure data exchange, and multi-agent coordination. &lt;/p&gt;&lt;p&gt;Over the past several years, the company has expanded to a 70-person team across Cambridge and Menlo Park, raised approximately $60 million, and accumulated more than one million users interacting with its model—data that informed the design of the newly launched products.&lt;/p&gt;&lt;p&gt;Sheikh added that his decision to bootstrap the company initially came directly from the proceeds of the DeepMind exit, noting in the interview that while the sale to Google was “a good exit,” he believed the team could have held out for a higher valuation. &lt;/p&gt;&lt;p&gt;The early self-funding period allowed Fetch to begin work in 2015—well before transformer architectures went mainstream—on the hypothesis that agentic infrastructure would become foundational to applied AI.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;ASI:One — A Platform for Multi-Agent Orchestration&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;At the core of the launch is &lt;b&gt;ASI:One&lt;/b&gt;, a language model interface designed specifically for coordinating multiple agents rather than addressing isolated queries. Fetch describes it as an “intelligence layer” that handles context sharing, task routing, and preference modeling.&lt;/p&gt;&lt;p&gt;The system stores user-level signals such as favored airlines, dietary constraints, budget ranges, loyalty program identifiers, and calendar availability. When a user requests a complex task—such as planning a trip with flights, hotels, and restaurant reservations—ASI:One retrieves those preferences and delegates work to the appropriate verified agents. The agents then return actionable outputs, including inventory and booking options, rather than generic recommendations.&lt;/p&gt;&lt;p&gt;In practice, ASI:One functions as a workflow generator across organizational boundaries. By contrast with conventional LLM applications, which often rely on APIs or RAG techniques to surface information, ASI:One is built to coordinate autonomous agents that can complete transactions. Fetch notes that personalization improves over time as the model accumulates structured preference data.&lt;/p&gt;&lt;p&gt;Sheikh emphasized the distinction between orchestrated execution and traditional AI output. “This isn’t searching for options separately and hoping they work together,” he said. “It’s orchestration.” &lt;/p&gt;&lt;p&gt;He added that Fetch’s architecture is intentionally modular: “Our architecture is a mix of agentic and expert models. One large model isn’t enough—you need specialists. That’s why we built ASI1, tuned specifically for agentic systems.”&lt;/p&gt;&lt;p&gt;The interview also revealed new details about ASI:One’s personalization systems: the platform uses multiple user-owned knowledge graphs to store preferences, travel history, social connections, and contextual constraints. &lt;/p&gt;&lt;p&gt;These knowledge graphs are siloed per user and not co-mingled with any Fetch-operated data. Sheikh described this as a “deterministic backbone” that gives the personal AI a stable memory layer beyond the probabilistic output of a single large model.&lt;/p&gt;&lt;p&gt;ASI:One launches in Beta today, with a broader release planned for early 2026. Fetch also offers ASI:One Mobile, released earlier this year, giving users access to the same agent-orchestration capabilities on iOS and Android. The mobile app connects directly to Agentverse and the user’s knowledge graphs, enabling on-the-go task execution and real-time interaction with registered agents.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Fetch Business — Verified Identity and Brand Control&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;To enable reliable coordination between consumers and companies, Fetch is introducing a verification and discovery portal called Fetch Business. &lt;/p&gt;&lt;p&gt;The platform allows organizations to verify their identity and claim an official Brand Agent handle—for example, @Hilton or @Nike—regardless of which tools they use to build the underlying agent.&lt;/p&gt;&lt;p&gt;Fetch positions the product as an analogue to ICANN domain registration and SSL certificate systems for websites. Verified status is intended to protect consumers from interacting with counterfeit or untrusted agents, a problem the company describes as a major barrier to widespread agent adoption.&lt;/p&gt;&lt;p&gt;The system includes low-code tools for small businesses to create agents in a few steps and connect real-time APIs such as inventory, booking systems, or CRM platforms. &lt;/p&gt;&lt;p&gt;“With Fetch, you can create an agent in one minute. It gets a handle, like a Twitter username, and you can personalize it completely—even give it your social media permissions to post on your behalf,” Sheikh said. Once a brand claims its namespace, its agent becomes discoverable to consumer AIs and other agents inside Agentverse.&lt;/p&gt;&lt;p&gt;The company has pre-reserved thousands of brand namespaces in anticipation of demand. Verification status persists across any platform that integrates with Agentverse, creating a portable identity layer for business agents.&lt;/p&gt;&lt;p&gt;The interview highlighted that Fetch Business inherits web-trust primitives directly: domain owners verify their identity by inserting a short code snippet into their existing website backend, allowing the system to pass a cryptographic challenge and grant the agent an authenticity badge similar to a “blue check” for agent identities. Sheikh framed this as “reusing the trust layer the web already spent decades building.”&lt;/p&gt;&lt;p&gt;Companies can begin claiming agents now at &lt;a href="https://business.fetch.ai/"&gt;&lt;b&gt;business.fetch.ai&lt;/b&gt;&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Agentverse — An Open Directory of More Than Two Million Agents&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The final component of the release is &lt;a href="https://agentverse.ai/"&gt;Agentverse&lt;/a&gt;, an open directory and cloud platform that hosts agents and enables cross-ecosystem discoverability. Fetch states that millions of agents have already registered, spanning travel, retail, entertainment, food service, and enterprise categories.&lt;/p&gt;&lt;p&gt;Agentverse provides metadata, capability descriptions, and routing logic that ASI:One uses to identify appropriate agents for specific tasks. It also supports secure communication and data exchange between agents. The company notes that the directory is platform-agnostic: agents built with any framework can join and interoperate.&lt;/p&gt;&lt;p&gt;According to Sheikh, the lack of a discovery layer is one reason most AI agents see little or no usage. “Ninety percent of AI agents never get used because there’s no discovery layer,” he said. &lt;/p&gt;&lt;p&gt;He framed the role of Agentverse in more technical terms: “Right now, if you build an agent, there’s no universal way for others to discover it. That’s what AgentVerse solves—it’s like DNS for agents.” He also described the system as an essential component of the emerging agent economy: “Fetch is building the Google of agents. Just like websites needed search, agents need discovery, trust, and interaction—Fetch provides all of that.”&lt;/p&gt;&lt;p&gt;The interview further underscored that Agentverse is cloud-agnostic by design. Sheikh contrasted this with competing agent ecosystems tied to specific cloud providers, arguing that a universal registry is only viable if independent of proprietary cloud environments. He said the open architecture enables an LLM to query any agent “within one minute of deployment,” turning agent publication into a near-instantaneous process similar to registering a domain.&lt;/p&gt;&lt;p&gt;Agentverse also integrates payment pathways, enabling agents to execute purchases using partners such as Visa, Skyfire, and supported stablecoins. Consumers can configure spending limits or require explicit approval for transactions.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Industry Context and Implications&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Fetch’s launch comes at a time when consumer AI platforms are exploring the shift from static chat interfaces toward autonomous agents capable of completing actions. However, most agent systems remain limited by siloed architectures, limited interoperability, and weak verification standards.&lt;/p&gt;&lt;p&gt;Fetch positions its infrastructure as a response to these limitations by providing a cross-platform coordination layer, identity system, and directory service. The company argues that an agent ecosystem requires consistent verification mechanisms to ensure that consumers interact with authentic brand representatives rather than imitations. By establishing namespace control and portable trust indicators, Fetch Business aims to fill a gap similar to early web domain verification.&lt;/p&gt;&lt;p&gt;At the same time, ASI:One attempts to centralize user preference data in a way that enables more efficient personalization and multi-agent coordination. This approach differs from generalist LLM applications, which often lack persistent preference architectures or direct access to brand-controlled agents.&lt;/p&gt;&lt;p&gt;The interview also made clear that micropayments and digital transaction infrastructure are central to Fetch’s long-term vision. Sheikh referenced integrations with protocols such as Coinbase’s 402 and AP2, positioning these capabilities as essential for autonomous agents to complete end-to-end tasks that include financial execution.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Takeaway&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Fetch’s combined release of ASI:One, Fetch Business, and Agentverse introduces an interconnected stack designed to support large-scale deployment and usage of AI agents. The company frames the system as foundational infrastructure for an agentic ecosystem, where consumer AIs can coordinate with verified brand agents to complete tasks reliably and securely. The additions to its identity, discovery, and orchestration layers reflect Fetch’s long-standing thesis—rooted partly in lessons from DeepMind’s early development—that intelligence becomes meaningful only when paired with the capacity to act.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://fetch.ai/"&gt;Fetch AI&lt;/a&gt;, a startup founded and led by former DeepMind founding investor, Humayun Sheikh, &lt;a href="https://www.businesswire.com/news/home/20251119088395/en/Fetch-Combines-Personalized-AI-with-Multi-Agent-Collaboration-to-Handle-Complex-Consumer-Tasks-Launches-Claim-Your-Agent-to-Fight-Brand-Knock-Offs"&gt;today announced the release&lt;/a&gt; of three interconnected products designed to provide the trust, coordination, and interoperability needed for large-scale AI agent ecosystems. &lt;/p&gt;&lt;p&gt;The launch includes &lt;a href="https://asi1.ai/"&gt;ASI:One&lt;/a&gt;, a personal-AI orchestration platform; &lt;a href="https://business.fetch.ai/"&gt;Fetch Business&lt;/a&gt;, a verification and discovery portal for brand agents; and &lt;a href="https://agentverse.ai/?sort=relevancy&amp;amp;page=1&amp;amp;recommended=true"&gt;Agentverse&lt;/a&gt;, an open directory hosting more than two million agents. &lt;/p&gt;&lt;p&gt;Together, the system positions Fetch as an infrastructure provider for what it calls the “Agentic Web”—a layer where consumer AIs and brand AIs collaborate to complete tasks instead of merely suggesting them.&lt;/p&gt;&lt;p&gt;The company says the tools address a central limitation in current consumer AI: models can provide recommendations but cannot reliably execute multi-step actions that require coordination across businesses. Fetch’s approach centers on enabling agents from different organizations to interoperate securely, using verified identities and shared context to complete end-to-end workflows.&lt;/p&gt;&lt;p&gt;“We’re creating the same foundation for agents that Google created for websites,” said Humayun Sheikh, Founder and CEO of Fetch AI, and an early investor in DeepMind, in a press release provided to VentureBeat. “Instead of just finding information, your personal AI coordinates with verified brand agents to get things done.”&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Background: Fetch’s Founding and DeepMind Connection &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Fetch AI was founded in 2017 by Humayun Sheikh, an entrepreneur whose early investment in DeepMind helped support the company’s commercial development before its acquisition by Google. “I was one of the first five people at DeepMind and its first investor. My check was the first one in,” Sheikh said, reflecting on the period when advanced machine learning research was still largely inaccessible outside major technology companies.&lt;/p&gt;&lt;p&gt;His early experience helped shape Fetch’s direction. “Even in 2013, it was clear to me that agentic systems were going to be the ones that worked. That’s where I focused—on the agentic web,” Sheikh noted. Fetch built on this thesis by developing infrastructure for autonomous software agents, focusing on verifiable identity, secure data exchange, and multi-agent coordination. &lt;/p&gt;&lt;p&gt;Over the past several years, the company has expanded to a 70-person team across Cambridge and Menlo Park, raised approximately $60 million, and accumulated more than one million users interacting with its model—data that informed the design of the newly launched products.&lt;/p&gt;&lt;p&gt;Sheikh added that his decision to bootstrap the company initially came directly from the proceeds of the DeepMind exit, noting in the interview that while the sale to Google was “a good exit,” he believed the team could have held out for a higher valuation. &lt;/p&gt;&lt;p&gt;The early self-funding period allowed Fetch to begin work in 2015—well before transformer architectures went mainstream—on the hypothesis that agentic infrastructure would become foundational to applied AI.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;ASI:One — A Platform for Multi-Agent Orchestration&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;At the core of the launch is &lt;b&gt;ASI:One&lt;/b&gt;, a language model interface designed specifically for coordinating multiple agents rather than addressing isolated queries. Fetch describes it as an “intelligence layer” that handles context sharing, task routing, and preference modeling.&lt;/p&gt;&lt;p&gt;The system stores user-level signals such as favored airlines, dietary constraints, budget ranges, loyalty program identifiers, and calendar availability. When a user requests a complex task—such as planning a trip with flights, hotels, and restaurant reservations—ASI:One retrieves those preferences and delegates work to the appropriate verified agents. The agents then return actionable outputs, including inventory and booking options, rather than generic recommendations.&lt;/p&gt;&lt;p&gt;In practice, ASI:One functions as a workflow generator across organizational boundaries. By contrast with conventional LLM applications, which often rely on APIs or RAG techniques to surface information, ASI:One is built to coordinate autonomous agents that can complete transactions. Fetch notes that personalization improves over time as the model accumulates structured preference data.&lt;/p&gt;&lt;p&gt;Sheikh emphasized the distinction between orchestrated execution and traditional AI output. “This isn’t searching for options separately and hoping they work together,” he said. “It’s orchestration.” &lt;/p&gt;&lt;p&gt;He added that Fetch’s architecture is intentionally modular: “Our architecture is a mix of agentic and expert models. One large model isn’t enough—you need specialists. That’s why we built ASI1, tuned specifically for agentic systems.”&lt;/p&gt;&lt;p&gt;The interview also revealed new details about ASI:One’s personalization systems: the platform uses multiple user-owned knowledge graphs to store preferences, travel history, social connections, and contextual constraints. &lt;/p&gt;&lt;p&gt;These knowledge graphs are siloed per user and not co-mingled with any Fetch-operated data. Sheikh described this as a “deterministic backbone” that gives the personal AI a stable memory layer beyond the probabilistic output of a single large model.&lt;/p&gt;&lt;p&gt;ASI:One launches in Beta today, with a broader release planned for early 2026. Fetch also offers ASI:One Mobile, released earlier this year, giving users access to the same agent-orchestration capabilities on iOS and Android. The mobile app connects directly to Agentverse and the user’s knowledge graphs, enabling on-the-go task execution and real-time interaction with registered agents.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Fetch Business — Verified Identity and Brand Control&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;To enable reliable coordination between consumers and companies, Fetch is introducing a verification and discovery portal called Fetch Business. &lt;/p&gt;&lt;p&gt;The platform allows organizations to verify their identity and claim an official Brand Agent handle—for example, @Hilton or @Nike—regardless of which tools they use to build the underlying agent.&lt;/p&gt;&lt;p&gt;Fetch positions the product as an analogue to ICANN domain registration and SSL certificate systems for websites. Verified status is intended to protect consumers from interacting with counterfeit or untrusted agents, a problem the company describes as a major barrier to widespread agent adoption.&lt;/p&gt;&lt;p&gt;The system includes low-code tools for small businesses to create agents in a few steps and connect real-time APIs such as inventory, booking systems, or CRM platforms. &lt;/p&gt;&lt;p&gt;“With Fetch, you can create an agent in one minute. It gets a handle, like a Twitter username, and you can personalize it completely—even give it your social media permissions to post on your behalf,” Sheikh said. Once a brand claims its namespace, its agent becomes discoverable to consumer AIs and other agents inside Agentverse.&lt;/p&gt;&lt;p&gt;The company has pre-reserved thousands of brand namespaces in anticipation of demand. Verification status persists across any platform that integrates with Agentverse, creating a portable identity layer for business agents.&lt;/p&gt;&lt;p&gt;The interview highlighted that Fetch Business inherits web-trust primitives directly: domain owners verify their identity by inserting a short code snippet into their existing website backend, allowing the system to pass a cryptographic challenge and grant the agent an authenticity badge similar to a “blue check” for agent identities. Sheikh framed this as “reusing the trust layer the web already spent decades building.”&lt;/p&gt;&lt;p&gt;Companies can begin claiming agents now at &lt;a href="https://business.fetch.ai/"&gt;&lt;b&gt;business.fetch.ai&lt;/b&gt;&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Agentverse — An Open Directory of More Than Two Million Agents&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The final component of the release is &lt;a href="https://agentverse.ai/"&gt;Agentverse&lt;/a&gt;, an open directory and cloud platform that hosts agents and enables cross-ecosystem discoverability. Fetch states that millions of agents have already registered, spanning travel, retail, entertainment, food service, and enterprise categories.&lt;/p&gt;&lt;p&gt;Agentverse provides metadata, capability descriptions, and routing logic that ASI:One uses to identify appropriate agents for specific tasks. It also supports secure communication and data exchange between agents. The company notes that the directory is platform-agnostic: agents built with any framework can join and interoperate.&lt;/p&gt;&lt;p&gt;According to Sheikh, the lack of a discovery layer is one reason most AI agents see little or no usage. “Ninety percent of AI agents never get used because there’s no discovery layer,” he said. &lt;/p&gt;&lt;p&gt;He framed the role of Agentverse in more technical terms: “Right now, if you build an agent, there’s no universal way for others to discover it. That’s what AgentVerse solves—it’s like DNS for agents.” He also described the system as an essential component of the emerging agent economy: “Fetch is building the Google of agents. Just like websites needed search, agents need discovery, trust, and interaction—Fetch provides all of that.”&lt;/p&gt;&lt;p&gt;The interview further underscored that Agentverse is cloud-agnostic by design. Sheikh contrasted this with competing agent ecosystems tied to specific cloud providers, arguing that a universal registry is only viable if independent of proprietary cloud environments. He said the open architecture enables an LLM to query any agent “within one minute of deployment,” turning agent publication into a near-instantaneous process similar to registering a domain.&lt;/p&gt;&lt;p&gt;Agentverse also integrates payment pathways, enabling agents to execute purchases using partners such as Visa, Skyfire, and supported stablecoins. Consumers can configure spending limits or require explicit approval for transactions.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Industry Context and Implications&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Fetch’s launch comes at a time when consumer AI platforms are exploring the shift from static chat interfaces toward autonomous agents capable of completing actions. However, most agent systems remain limited by siloed architectures, limited interoperability, and weak verification standards.&lt;/p&gt;&lt;p&gt;Fetch positions its infrastructure as a response to these limitations by providing a cross-platform coordination layer, identity system, and directory service. The company argues that an agent ecosystem requires consistent verification mechanisms to ensure that consumers interact with authentic brand representatives rather than imitations. By establishing namespace control and portable trust indicators, Fetch Business aims to fill a gap similar to early web domain verification.&lt;/p&gt;&lt;p&gt;At the same time, ASI:One attempts to centralize user preference data in a way that enables more efficient personalization and multi-agent coordination. This approach differs from generalist LLM applications, which often lack persistent preference architectures or direct access to brand-controlled agents.&lt;/p&gt;&lt;p&gt;The interview also made clear that micropayments and digital transaction infrastructure are central to Fetch’s long-term vision. Sheikh referenced integrations with protocols such as Coinbase’s 402 and AP2, positioning these capabilities as essential for autonomous agents to complete end-to-end tasks that include financial execution.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Takeaway&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Fetch’s combined release of ASI:One, Fetch Business, and Agentverse introduces an interconnected stack designed to support large-scale deployment and usage of AI agents. The company frames the system as foundational infrastructure for an agentic ecosystem, where consumer AIs can coordinate with verified brand agents to complete tasks reliably and securely. The additions to its identity, discovery, and orchestration layers reflect Fetch’s long-standing thesis—rooted partly in lessons from DeepMind’s early development—that intelligence becomes meaningful only when paired with the capacity to act.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/the-google-search-of-ai-agents-fetch-launches-asi-one-and-business-tier-for</guid><pubDate>Wed, 19 Nov 2025 17:57:00 +0000</pubDate></item></channel></rss>