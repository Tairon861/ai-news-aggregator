<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 15 Jul 2025 18:34:31 +0000</lastBuildDate><item><title>AI’s giants want to take over the classroom (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/15/1120086/ais-giants-want-to-take-over-the-classroom/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/school-ai3.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;School’s out and it’s high summer, but a bunch of teachers are plotting how they’re going to use AI this upcoming school year. God help them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;On July 8, OpenAI, Microsoft, and Anthropic announced a $23 million partnership with one of the largest teachers’ unions in the United States to bring more AI into K–12 classrooms. Called the National Academy for AI Instruction, the initiative will train teachers at a New York City headquarters on how to use AI both for teaching and for tasks like planning lessons and writing reports, starting this fall&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The companies could face an uphill battle. Right now, most of the public perceives AI’s use in the classroom as nothing short of ruinous—a surefire way to dampen critical thinking and hasten the decline of our collective attention span (a viral story from &lt;em&gt;New York &lt;/em&gt;magazine, for example, described how easy it now is to coast through college thanks to constant access to ChatGPT).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Amid that onslaught, AI companies insist that AI promises more individualized learning, faster and more creative lesson planning, and quicker grading. The companies sponsoring this initiative are, of course, not doing it out of the goodness of their hearts.&lt;/p&gt; 
 &lt;p&gt;No—as they hunt for profits, their goal is to make users out of teachers and students. Anthropic is pitching its AI models to universities, and OpenAI offers free courses for teachers. In an initial training session for teachers by the new National Academy for AI Instruction, representatives from Microsoft showed teachers how to use the company’s AI tools for lesson planning and emails, according to the &lt;em&gt;New York Times&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It's early days, but what does the evidence actually say about whether AI is helping or hurting students? There’s at least some data to support the case made by tech companies: A recent survey of 1,500 teens conducted by Harvard’s Graduate School of Education showed that kids are using AI to brainstorm and answer questions they're afraid to ask in the classroom. Studies examining settings ranging from math classes in Nigeria to colleges physics courses at Harvard have suggested that AI tutors can lead students to become more engaged.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;And yet there’s more to the story. The same Harvard survey revealed that kids are also frequently using AI for cheating and shortcuts. And an oft-cited paper from Microsoft found that relying on AI can reduce critical thinking. Not to mention the fact that “hallucinations” of incorrect information are an inevitable part of how large language models work.&lt;/p&gt;  &lt;p&gt;There's a lack of clear evidence that AI can be a net benefit for students, and it's hard to trust that the AI companies funding this initiative will give honest advice on when &lt;em&gt;not&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;to use AI in the classroom.&lt;/p&gt;  &lt;p&gt;Despite the fanfare around the academy's launch, and the fact the first teacher training is scheduled to take place in just a few months, OpenAI and Anthropic told me they couldn't share any specifics.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It's not as if teachers themselves aren't already grappling with how to approach AI. One such teacher, Christopher Harris, who leads a library system covering 22 rural school districts in New York, has created a curriculum aimed at AI literacy. Topics range from privacy when using smart speakers (a lesson for second graders) to misinformation and deepfakes (instruction for high schoolers). I asked him what he’d like to see in the curriculum used by the new National Academy for AI Instruction.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;“The real outcome should be teachers that are confident enough in their understanding of how AI works and how it can be used as a tool that they can teach students about the technology as well,” he says. The thing to avoid would be overfocusing on tools and pre-built prompts that teachers are instructed to use without knowing how they work.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But all this will be for naught without an adjustment to how schools evaluate students in the age of AI, Harris says: “The bigger issue will be shifting the fundamental approaches to how we assign and assess student work in the face of AI cheating.”&lt;/p&gt;  &lt;p&gt;The new initiative is led by the American Federation of Teachers, which represents 1.8 million members, as well as the United Federation of Teachers, which represents 200,000 members in New York. If they win over these groups, the tech companies will have significant influence over how millions of teachers learn about AI. But some educators are resisting the use of AI entirely, including several hundred who signed an open letter last week.&lt;/p&gt;  &lt;p&gt;Helen Choi is one of them. “I think it is incumbent upon educators to scrutinize the tools that they use in the classroom to look past hype,” says Choi, an associate professor at the University of Southern California, where she teaches writing. “Until we know that something is useful, safe, and ethical, we have a duty to resist mass adoption of tools like large language models that are not designed by educators with education in mind.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/school-ai3.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;School’s out and it’s high summer, but a bunch of teachers are plotting how they’re going to use AI this upcoming school year. God help them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;On July 8, OpenAI, Microsoft, and Anthropic announced a $23 million partnership with one of the largest teachers’ unions in the United States to bring more AI into K–12 classrooms. Called the National Academy for AI Instruction, the initiative will train teachers at a New York City headquarters on how to use AI both for teaching and for tasks like planning lessons and writing reports, starting this fall&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The companies could face an uphill battle. Right now, most of the public perceives AI’s use in the classroom as nothing short of ruinous—a surefire way to dampen critical thinking and hasten the decline of our collective attention span (a viral story from &lt;em&gt;New York &lt;/em&gt;magazine, for example, described how easy it now is to coast through college thanks to constant access to ChatGPT).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Amid that onslaught, AI companies insist that AI promises more individualized learning, faster and more creative lesson planning, and quicker grading. The companies sponsoring this initiative are, of course, not doing it out of the goodness of their hearts.&lt;/p&gt; 
 &lt;p&gt;No—as they hunt for profits, their goal is to make users out of teachers and students. Anthropic is pitching its AI models to universities, and OpenAI offers free courses for teachers. In an initial training session for teachers by the new National Academy for AI Instruction, representatives from Microsoft showed teachers how to use the company’s AI tools for lesson planning and emails, according to the &lt;em&gt;New York Times&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It's early days, but what does the evidence actually say about whether AI is helping or hurting students? There’s at least some data to support the case made by tech companies: A recent survey of 1,500 teens conducted by Harvard’s Graduate School of Education showed that kids are using AI to brainstorm and answer questions they're afraid to ask in the classroom. Studies examining settings ranging from math classes in Nigeria to colleges physics courses at Harvard have suggested that AI tutors can lead students to become more engaged.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;And yet there’s more to the story. The same Harvard survey revealed that kids are also frequently using AI for cheating and shortcuts. And an oft-cited paper from Microsoft found that relying on AI can reduce critical thinking. Not to mention the fact that “hallucinations” of incorrect information are an inevitable part of how large language models work.&lt;/p&gt;  &lt;p&gt;There's a lack of clear evidence that AI can be a net benefit for students, and it's hard to trust that the AI companies funding this initiative will give honest advice on when &lt;em&gt;not&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;to use AI in the classroom.&lt;/p&gt;  &lt;p&gt;Despite the fanfare around the academy's launch, and the fact the first teacher training is scheduled to take place in just a few months, OpenAI and Anthropic told me they couldn't share any specifics.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It's not as if teachers themselves aren't already grappling with how to approach AI. One such teacher, Christopher Harris, who leads a library system covering 22 rural school districts in New York, has created a curriculum aimed at AI literacy. Topics range from privacy when using smart speakers (a lesson for second graders) to misinformation and deepfakes (instruction for high schoolers). I asked him what he’d like to see in the curriculum used by the new National Academy for AI Instruction.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;“The real outcome should be teachers that are confident enough in their understanding of how AI works and how it can be used as a tool that they can teach students about the technology as well,” he says. The thing to avoid would be overfocusing on tools and pre-built prompts that teachers are instructed to use without knowing how they work.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But all this will be for naught without an adjustment to how schools evaluate students in the age of AI, Harris says: “The bigger issue will be shifting the fundamental approaches to how we assign and assess student work in the face of AI cheating.”&lt;/p&gt;  &lt;p&gt;The new initiative is led by the American Federation of Teachers, which represents 1.8 million members, as well as the United Federation of Teachers, which represents 200,000 members in New York. If they win over these groups, the tech companies will have significant influence over how millions of teachers learn about AI. But some educators are resisting the use of AI entirely, including several hundred who signed an open letter last week.&lt;/p&gt;  &lt;p&gt;Helen Choi is one of them. “I think it is incumbent upon educators to scrutinize the tools that they use in the classroom to look past hype,” says Choi, an associate professor at the University of Southern California, where she teaches writing. “Until we know that something is useful, safe, and ethical, we have a duty to resist mass adoption of tools like large language models that are not designed by educators with education in mind.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/15/1120086/ais-giants-want-to-take-over-the-classroom/</guid><pubDate>Tue, 15 Jul 2025 09:00:00 +0000</pubDate></item><item><title>Nextdoor redesigns app with AI recommendations, local news, and real-time emergency alerts (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/15/nextdoor-redesigns-app-with-ai-recommendations-local-news-and-real-time-emergency-alerts/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Neighborhood social app Nextdoor is launching a redesigned version of its service that it’s calling the “new Nextdoor.” The app is adding local news, real-time alerts, and an AI-powered feature called “Faves” that’s designed for discovering local businesses and spots. Nextdoor has also updated its overall design to look more contemporary.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched 15 years ago, Nextdoor has long served as a popular platform for neighborhood conversations, helping users connect over things like recommendations for plumbers and suggestions for nearby places to eat. But eventually, its growth stalled and engagement declined as the platform became associated with posts containing misinformation and racism.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, the company is looking to turn things around and attract more users by making its platform more helpful, useful, and timely. With this redesign, Nextdoor is looking to increase the quality and quantity of local information on the platform, Nextdoor CEO and co-founder Nirav Tolia told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To bring news to its platform, Nextdoor has partnered with 3,500 local publications across the United States, United Kingdom, and Canada. Notable outlets include the San Francisco Standard, The London Standard, and The Toronto Star.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027588" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-14-at-12.54.43PM.png?w=347" width="347" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Nextdoor&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason that this is so important for us is historically, Nextdoor has relied 100% on user-generated content, just the content that’s created by your neighbors,” Tolia said. “That’s been a great source of information. But, to really make sure if it’s happening in your neighborhood, we need to bring in local news as well. So this is the first time we’re letting third party publishers use our distribution.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tolia stated that these aren’t commercial agreements, as Nextdoor isn’t paying for the content, nor are the publishers paying the company. Additionally, Nextdoor isn’t hosting the content; it’s simply displaying a headline, a snippet, and an image, and directing traffic to the publications. Users will be able to discuss the news in a comments section under each post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tolia noted that publishers are just the first new type of content coming to Nextdoor, as the platform plans to allow small businesses, schools, and organizations to have native presences in the app in the future as well.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of the new alerts, Nextdoor now shows real-time updates on things like weather, traffic, power outages, storms, and wildfires. These alerts will appear on a dynamic neighborhood map, allowing neighbors to have timely conversations about safety and preparedness.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The service is partnering with Samdesk and Weather.com, which includes The Weather Channel app and Weather.com, to power these alerts.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027590" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-14-at-12.54.48PM.png?w=337" width="337" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Nextdoor&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“When there’s something that is definitely worth paying attention to, we call that the yellow state, and we’ll put that alert right at the top,” Tolia said. “When there’s something critical, we call that the red state and it’ll take over the whole app, because at that point, you don’t care about the conversations neighbors are having about pickleball. You don’t really care about the new restaurant review that the local publishers put in. You need to get together with your neighbors and help save each other’s lives in some cases.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Tolia noted that these alerts are hyper-localized because Nextdoor is built on a geospatial platform. So unlike Amber Alerts that are sent out to everyone in a certain location, Nextdoor says it can personalize its alerts down to the house. For example, if there’s a power outage, the app will only send the alert to the people whose power is out.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for the launch of Faves, Tolia says recommendations from neighbors are more valuable than going on Google or ChatGPT when looking to find a local restaurant or a place to spend time with family over the weekend, which is why Nextdoor is launching the feature.&amp;nbsp;The new Faves feature displays curated lists of recommendations, and also lets you ask specific questions to get suggestions. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have an LLM for every neighborhood where we’ve taken 15 years of neighbor conversations and we can now answer questions about that information in a really compelling way,” Tolia said. “So we have the first, as far as we know, the first truly local AI that’s powered by neighbor conversations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can ask questions like, “What is the best place to hike with kids?” and receive a quick, summarized response that pulls information from posts from real users on Nextdoor. Underneath the summary, you can see and click through to the posts that the summary is referencing.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027592" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-14-at-12.54.57PM.png?w=341" width="341" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Nextdoor&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“This content is proprietary to Nextdoor,” Tolia said. “We’ve never shared it. It’s not indexed by Google. It’s not available on ChatGPT, and again, because we know where you live, we can target the information to you in the most relevant way.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tolia noted that Nextdoor’s unique value is in digitizing and capturing local word-of-mouth, the kind of hyperlocal information that isn’t available through platforms like Google or ChatGPT, because you can only get it from direct conversations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I give the funny example of, if you wanted to know all the lemonade stands that kids are operating in your neighborhood, you can’t go to Google Maps and find that,” Tolia said. “You can’t go to ChatGPT and ask that question, right? The only way is for you to ask your neighbors. And so that’s what Nextdoor is all about. So what are we going to do? We’re going to recommit to really making this feel hyperlocal. It’s really important for us to be seen less as a social network and more as a utility centric network.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Neighborhood social app Nextdoor is launching a redesigned version of its service that it’s calling the “new Nextdoor.” The app is adding local news, real-time alerts, and an AI-powered feature called “Faves” that’s designed for discovering local businesses and spots. Nextdoor has also updated its overall design to look more contemporary.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched 15 years ago, Nextdoor has long served as a popular platform for neighborhood conversations, helping users connect over things like recommendations for plumbers and suggestions for nearby places to eat. But eventually, its growth stalled and engagement declined as the platform became associated with posts containing misinformation and racism.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, the company is looking to turn things around and attract more users by making its platform more helpful, useful, and timely. With this redesign, Nextdoor is looking to increase the quality and quantity of local information on the platform, Nextdoor CEO and co-founder Nirav Tolia told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To bring news to its platform, Nextdoor has partnered with 3,500 local publications across the United States, United Kingdom, and Canada. Notable outlets include the San Francisco Standard, The London Standard, and The Toronto Star.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027588" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-14-at-12.54.43PM.png?w=347" width="347" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Nextdoor&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason that this is so important for us is historically, Nextdoor has relied 100% on user-generated content, just the content that’s created by your neighbors,” Tolia said. “That’s been a great source of information. But, to really make sure if it’s happening in your neighborhood, we need to bring in local news as well. So this is the first time we’re letting third party publishers use our distribution.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tolia stated that these aren’t commercial agreements, as Nextdoor isn’t paying for the content, nor are the publishers paying the company. Additionally, Nextdoor isn’t hosting the content; it’s simply displaying a headline, a snippet, and an image, and directing traffic to the publications. Users will be able to discuss the news in a comments section under each post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tolia noted that publishers are just the first new type of content coming to Nextdoor, as the platform plans to allow small businesses, schools, and organizations to have native presences in the app in the future as well.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of the new alerts, Nextdoor now shows real-time updates on things like weather, traffic, power outages, storms, and wildfires. These alerts will appear on a dynamic neighborhood map, allowing neighbors to have timely conversations about safety and preparedness.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The service is partnering with Samdesk and Weather.com, which includes The Weather Channel app and Weather.com, to power these alerts.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027590" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-14-at-12.54.48PM.png?w=337" width="337" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Nextdoor&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“When there’s something that is definitely worth paying attention to, we call that the yellow state, and we’ll put that alert right at the top,” Tolia said. “When there’s something critical, we call that the red state and it’ll take over the whole app, because at that point, you don’t care about the conversations neighbors are having about pickleball. You don’t really care about the new restaurant review that the local publishers put in. You need to get together with your neighbors and help save each other’s lives in some cases.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Tolia noted that these alerts are hyper-localized because Nextdoor is built on a geospatial platform. So unlike Amber Alerts that are sent out to everyone in a certain location, Nextdoor says it can personalize its alerts down to the house. For example, if there’s a power outage, the app will only send the alert to the people whose power is out.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for the launch of Faves, Tolia says recommendations from neighbors are more valuable than going on Google or ChatGPT when looking to find a local restaurant or a place to spend time with family over the weekend, which is why Nextdoor is launching the feature.&amp;nbsp;The new Faves feature displays curated lists of recommendations, and also lets you ask specific questions to get suggestions. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have an LLM for every neighborhood where we’ve taken 15 years of neighbor conversations and we can now answer questions about that information in a really compelling way,” Tolia said. “So we have the first, as far as we know, the first truly local AI that’s powered by neighbor conversations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can ask questions like, “What is the best place to hike with kids?” and receive a quick, summarized response that pulls information from posts from real users on Nextdoor. Underneath the summary, you can see and click through to the posts that the summary is referencing.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3027592" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-14-at-12.54.57PM.png?w=341" width="341" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Nextdoor&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“This content is proprietary to Nextdoor,” Tolia said. “We’ve never shared it. It’s not indexed by Google. It’s not available on ChatGPT, and again, because we know where you live, we can target the information to you in the most relevant way.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tolia noted that Nextdoor’s unique value is in digitizing and capturing local word-of-mouth, the kind of hyperlocal information that isn’t available through platforms like Google or ChatGPT, because you can only get it from direct conversations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I give the funny example of, if you wanted to know all the lemonade stands that kids are operating in your neighborhood, you can’t go to Google Maps and find that,” Tolia said. “You can’t go to ChatGPT and ask that question, right? The only way is for you to ask your neighbors. And so that’s what Nextdoor is all about. So what are we going to do? We’re going to recommit to really making this feel hyperlocal. It’s really important for us to be seen less as a social network and more as a utility centric network.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/15/nextdoor-redesigns-app-with-ai-recommendations-local-news-and-real-time-emergency-alerts/</guid><pubDate>Tue, 15 Jul 2025 09:00:00 +0000</pubDate></item><item><title>AI text-to-speech programs could “unlearn” how to imitate certain people (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/15/1120094/ai-text-to-speech-programs-could-one-day-unlearn/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/forgetting-audio.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A technique known as “machine unlearning” could teach AI models to forget specific voices—an important step in stopping the rise of audio deepfakes, where someone’s voice is copied to carry out fraud or scams.&lt;/p&gt;  &lt;p&gt;Recent advances in artificial intelligence have revolutionized the quality of text-to-speech technology so that people can convincingly re-create a piece of text in any voice, complete with natural speaking patterns and intonations, instead of having to settle for a robotic voice reading it out word by word. “Anyone’s voice can be reproduced or copied with just a few seconds of their voice,” says Jong Hwan Ko, a professor at Sungkyunkwan University in Korea and the coauthor of a new paper that demonstrates one of the first applications of machine unlearning to speech generation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;Copied voices have been used in scams, disinformation, and harassment. Ko, who researches audio processing, and his collaborators wanted to prevent this kind of identity fraud. “People are starting to demand ways to opt out of the unknown generation of their voices without consent,” he says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;AI companies generally keep a tight grip on their models to discourage misuse. For example, if you ask ChatGPT to give you someone’s phone number or instructions for doing something illegal, it will likely just tell you it cannot help. However, as many examples over time have shown, clever prompt engineering or model fine-tuning can sometimes get these models to say things they otherwise wouldn’t. The unwanted information may still be hiding somewhere inside the model so that it can be accessed with the right techniques.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;At present, companies tend to deal with this issue by applying guardrails; the idea is to check whether the prompts or the AI’s responses contain disallowed material. Machine unlearning instead asks whether an AI can be made to forget a piece of information that the company doesn’t want it to know. The technique takes a leaky model and the specific training data to be redacted and uses them to create a new model—essentially, a version of the original that never learned that piece of data. While machine unlearning has ties to older techniques in AI research, it’s only in the past couple of years that it’s been applied to large language models.&lt;/p&gt;  &lt;p&gt;Jinju Kim, a master’s student at Sungkyunkwan University who worked on the paper with Ko and others, sees guardrails as fences around the bad data put in place to keep people away from it. “You can’t get through the fence, but some people will still try to go under the fence or over the fence,” says Kim. But unlearning, she says, attempts to remove the bad data altogether, so there is nothing behind the fence at all.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The way current text-to-speech systems are designed complicates this a little more, though. These so-called “zero-shot” models use examples of people’s speech to learn to re-create any voice, including those not in the training set—with enough data, it can be a good mimic when supplied with even a small sample of someone’s voice. So “unlearning” means a model not only needs to “forget” voices it was trained on but also has to learn not to mimic specific voices it wasn’t trained on. All the while, it still needs to perform well for other voices.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To demonstrate how to get those results, Kim taught a recreation of VoiceBox, a speech generation model from Meta, that when it was prompted to produce a text sample in one of the voices to be redacted, it should instead respond with a random voice. To make these voices realistic, the model “teaches” itself using random voices of its own creation.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;According to the team’s results, which are to be presented this week at the International Conference on Machine Learning, prompting the model to imitate a voice it has “unlearned” gives back a result that—according to state-of-the-art tools that measure voice similarity—mimics the forgotten voice more than 75% less effectively than the model did before. In practice, this makes the new voice unmistakably different. But the forgetfulness comes at a cost: The model is about 2.8% worse at mimicking permitted voices. While these percentages are a bit hard to interpret, the demo the researchers released online offers very convincing results, both for how well redacted speakers are forgotten and how well the rest are remembered. A sample from the demo is given below.&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-audio"&gt;&lt;audio controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/original_audio.wav"&gt;&lt;/audio&gt;&lt;figcaption class="wp-element-caption"&gt;A voice sample of a speaker to be forgotten by the model.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-audio"&gt;&lt;audio controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/original_audio_generated.wav"&gt;&lt;/audio&gt;&lt;figcaption class="wp-element-caption"&gt;The generated text-to-speech audio from the original model using the above as a prompt.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-audio"&gt;&lt;audio controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/new_audio_generated_1.wav"&gt;&lt;/audio&gt;&lt;figcaption class="wp-element-caption"&gt;The generated text-to-speech audio using the same prompt, but now from the model where the speaker was forgotten.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;p&gt;Ko says the unlearning process can take “several days,” depending on how many speakers the researchers want the model to forget. Their method also requires an audio clip about five minutes long for each speaker whose voice is to be forgotten.&lt;/p&gt;  &lt;p&gt;In machine unlearning, pieces of data are often replaced with randomness so that they can’t be reverse-engineered back to the original. In this paper, the randomness for the forgotten speakers is very high—a sign, the authors claim, that they are truly forgotten by the model.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&amp;nbsp;“I have seen people optimizing for randomness in other contexts,” says Vaidehi Patil, a PhD student at the University of North Carolina at Chapel Hill who researches machine unlearning. “This is one of the first works I’ve seen for speech.” Patil is organizing a machine unlearning workshop affiliated with the conference, and the voice unlearning research will also be presented there.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;She points out that unlearning itself involves inherent trade-offs between efficiency and forgetfulness because the process can take time, and can degrade the usability of the final model. “There’s no free lunch. You have to compromise something,” she says.&lt;/p&gt;  &lt;p&gt;Machine unlearning may still be at too early a stage for, say, Meta to introduce Ko and Kim’s methods into VoiceBox. But there is likely to be industry interest. Patil is researching unlearning for Google DeepMind this summer, and while Meta did not respond with a comment, it has hesitated for a long time to release VoiceBox to the wider public because it is so vulnerable to misuse.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The voice unlearning team seems optimistic that its work could someday get good enough for real-life deployment. “In real applications, we would need faster and more scalable solutions,” says Ko. “We are trying to find those.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/forgetting-audio.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A technique known as “machine unlearning” could teach AI models to forget specific voices—an important step in stopping the rise of audio deepfakes, where someone’s voice is copied to carry out fraud or scams.&lt;/p&gt;  &lt;p&gt;Recent advances in artificial intelligence have revolutionized the quality of text-to-speech technology so that people can convincingly re-create a piece of text in any voice, complete with natural speaking patterns and intonations, instead of having to settle for a robotic voice reading it out word by word. “Anyone’s voice can be reproduced or copied with just a few seconds of their voice,” says Jong Hwan Ko, a professor at Sungkyunkwan University in Korea and the coauthor of a new paper that demonstrates one of the first applications of machine unlearning to speech generation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;Copied voices have been used in scams, disinformation, and harassment. Ko, who researches audio processing, and his collaborators wanted to prevent this kind of identity fraud. “People are starting to demand ways to opt out of the unknown generation of their voices without consent,” he says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;AI companies generally keep a tight grip on their models to discourage misuse. For example, if you ask ChatGPT to give you someone’s phone number or instructions for doing something illegal, it will likely just tell you it cannot help. However, as many examples over time have shown, clever prompt engineering or model fine-tuning can sometimes get these models to say things they otherwise wouldn’t. The unwanted information may still be hiding somewhere inside the model so that it can be accessed with the right techniques.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;At present, companies tend to deal with this issue by applying guardrails; the idea is to check whether the prompts or the AI’s responses contain disallowed material. Machine unlearning instead asks whether an AI can be made to forget a piece of information that the company doesn’t want it to know. The technique takes a leaky model and the specific training data to be redacted and uses them to create a new model—essentially, a version of the original that never learned that piece of data. While machine unlearning has ties to older techniques in AI research, it’s only in the past couple of years that it’s been applied to large language models.&lt;/p&gt;  &lt;p&gt;Jinju Kim, a master’s student at Sungkyunkwan University who worked on the paper with Ko and others, sees guardrails as fences around the bad data put in place to keep people away from it. “You can’t get through the fence, but some people will still try to go under the fence or over the fence,” says Kim. But unlearning, she says, attempts to remove the bad data altogether, so there is nothing behind the fence at all.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The way current text-to-speech systems are designed complicates this a little more, though. These so-called “zero-shot” models use examples of people’s speech to learn to re-create any voice, including those not in the training set—with enough data, it can be a good mimic when supplied with even a small sample of someone’s voice. So “unlearning” means a model not only needs to “forget” voices it was trained on but also has to learn not to mimic specific voices it wasn’t trained on. All the while, it still needs to perform well for other voices.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To demonstrate how to get those results, Kim taught a recreation of VoiceBox, a speech generation model from Meta, that when it was prompted to produce a text sample in one of the voices to be redacted, it should instead respond with a random voice. To make these voices realistic, the model “teaches” itself using random voices of its own creation.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;According to the team’s results, which are to be presented this week at the International Conference on Machine Learning, prompting the model to imitate a voice it has “unlearned” gives back a result that—according to state-of-the-art tools that measure voice similarity—mimics the forgotten voice more than 75% less effectively than the model did before. In practice, this makes the new voice unmistakably different. But the forgetfulness comes at a cost: The model is about 2.8% worse at mimicking permitted voices. While these percentages are a bit hard to interpret, the demo the researchers released online offers very convincing results, both for how well redacted speakers are forgotten and how well the rest are remembered. A sample from the demo is given below.&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-audio"&gt;&lt;audio controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/original_audio.wav"&gt;&lt;/audio&gt;&lt;figcaption class="wp-element-caption"&gt;A voice sample of a speaker to be forgotten by the model.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-audio"&gt;&lt;audio controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/original_audio_generated.wav"&gt;&lt;/audio&gt;&lt;figcaption class="wp-element-caption"&gt;The generated text-to-speech audio from the original model using the above as a prompt.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;figure class="wp-block-audio"&gt;&lt;audio controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/new_audio_generated_1.wav"&gt;&lt;/audio&gt;&lt;figcaption class="wp-element-caption"&gt;The generated text-to-speech audio using the same prompt, but now from the model where the speaker was forgotten.&lt;/figcaption&gt;&lt;/figure&gt;  &lt;p&gt;Ko says the unlearning process can take “several days,” depending on how many speakers the researchers want the model to forget. Their method also requires an audio clip about five minutes long for each speaker whose voice is to be forgotten.&lt;/p&gt;  &lt;p&gt;In machine unlearning, pieces of data are often replaced with randomness so that they can’t be reverse-engineered back to the original. In this paper, the randomness for the forgotten speakers is very high—a sign, the authors claim, that they are truly forgotten by the model.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&amp;nbsp;“I have seen people optimizing for randomness in other contexts,” says Vaidehi Patil, a PhD student at the University of North Carolina at Chapel Hill who researches machine unlearning. “This is one of the first works I’ve seen for speech.” Patil is organizing a machine unlearning workshop affiliated with the conference, and the voice unlearning research will also be presented there.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;She points out that unlearning itself involves inherent trade-offs between efficiency and forgetfulness because the process can take time, and can degrade the usability of the final model. “There’s no free lunch. You have to compromise something,” she says.&lt;/p&gt;  &lt;p&gt;Machine unlearning may still be at too early a stage for, say, Meta to introduce Ko and Kim’s methods into VoiceBox. But there is likely to be industry interest. Patil is researching unlearning for Google DeepMind this summer, and while Meta did not respond with a comment, it has hesitated for a long time to release VoiceBox to the wider public because it is so vulnerable to misuse.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The voice unlearning team seems optimistic that its work could someday get good enough for real-life deployment. “In real applications, we would need faster and more scalable solutions,” says Ko. “We are trying to find those.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/15/1120094/ai-text-to-speech-programs-could-one-day-unlearn/</guid><pubDate>Tue, 15 Jul 2025 10:00:16 +0000</pubDate></item><item><title>TechCrunch All Stage launches in Boston today — don’t miss what founders are learning (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/15/techcrunch-all-stage-launches-in-boston-today-dont-miss-what-founders-are-learning/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Today’s the day! &lt;strong&gt;TechCrunch All Stage&lt;/strong&gt; is lighting up Boston’s SoWa Power Station at 7:30 a.m. ET sharp. The stages are set, the speakers are ready, and the startup community is gathering for one powerful day of insight, innovation, and momentum.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Boston and ready to scale your startup faster and more efficiently? There’s still time to join the founders and investors driving innovation and building what’s next. Grab a pass, dive into the conversations shaping the future of startup growth, and make the connections that move the needle.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Don’t miss a moment — &lt;strong&gt;secure your ticket&lt;/strong&gt; at the heart of today’s startup action.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024" class="wp-image-2986145" height="454" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-SYTYCP.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-here-s-what-s-in-store-for-today"&gt;Here’s what’s in store for today&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;We’ve got a powerhouse lineup of scaling and investing experts ready to deliver hard-hitting insights to an audience that thrives on growth, plus intentional, high-impact networking happening all day long.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Check out the &lt;strong&gt;agenda&lt;/strong&gt; for full session details and explore the &lt;strong&gt;speaker page&lt;/strong&gt; to get to know the experts behind the ideas. Or better yet, &lt;strong&gt;join us in person today and experience it all firsthand&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-two-breakout-stages-countless-insights-to-scale-smarter"&gt;Two breakout stages. Countless insights to scale smarter.&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-foundation-stage"&gt;Foundation Stage&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Just getting started on your startup journey? The Foundation Stage is your launchpad, packed with practical skills to help you build and grow from day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;All the Ways You Don’t Realize VCs Are Evaluating Your Company at Pre-Seed&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Charles Hudson&lt;/em&gt;&lt;em&gt;, Founder and Managing Partner, Precursor Ventures&lt;/em&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This topic is key for pre-seed founders. VCs often judge based on the team and idea. A mismatched co-founder signals hiring risk, and missteps in fundraising show a lack of prep. Do your homework.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Preparing to Raise: Cap Table Best Practices to Help You Close Fast&lt;br /&gt;&lt;/strong&gt;&lt;em&gt;Lynne Zagami&lt;/em&gt;&lt;em&gt;, Vice President, Customer Success, Fidelity Private Shares; &lt;/em&gt;&lt;em&gt;John Andrews&lt;/em&gt;&lt;em&gt;, CEO and Co-Founder, Cimulate.ai; &lt;/em&gt;&lt;em&gt;Darrell West&lt;/em&gt;&lt;em&gt;, Co-Founder and CFO, DepositLink&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Raising funds? Make sure your cap table and data room are clean to avoid delays and costly legal fees. This session offers best practices and insights from legal, investor, and founder views.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;MVP in the Age of AI: When to Bot and When to Not&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Chris Gardner&lt;/em&gt;&lt;em&gt;, Partner, Underscore VC&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI is changing how founders build. Learn how to use it to turbocharge your MVP without letting it take over. Discover where AI shines, where humans are essential, and how to avoid toaster copy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The TAM Myth: How the Best Startups Reshape Markets&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Jahanvi Sardana&lt;/em&gt;&lt;em&gt;, Partner, Index Ventures&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Learn how top startups like Datadog and Airbnb created markets, not just sized them. Jahanvi Sardana of Index Ventures breaks down how to grow TAM and spot trends. A must for future-shaping founders.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;It’s not 2021 anymore. Understanding the 2025 VC landscape&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Kristen Craft&lt;/em&gt;&lt;em&gt;, Vice President, Business Partner Manager, Fidelity Private Shares; &lt;/em&gt;&lt;em&gt;Samara Gordon&lt;/em&gt;&lt;em&gt;, General Partner, Hyperplane; &lt;/em&gt;&lt;em&gt;John Harthorne&lt;/em&gt;&lt;em&gt;, Founder and Managing Director, Two Lanterns; &lt;/em&gt;&lt;em&gt;Daniel Acheampong&lt;/em&gt;&lt;em&gt;, General Partner, Visible Hands VC&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;VC in 2025 favors strategic, high-impact deals. Learn how midstage startups can adapt, use regional strengths, embrace AI, and build strong models for growth and successful exits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Crafting the Perfect VC Pitch: Luck Meets Strategy&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Tiffany Luck&lt;/em&gt;&lt;em&gt;, Partner, NEA&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Join Tiffany Luck of NEA to learn how to pitch with clarity and impact. Get insider tips on what VCs value, how to avoid common pitfalls, and how to tell a story that wins funding.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;So You Think You Can Pitch?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Watch three early-stage startups take the spotlight at &lt;em&gt;So You Think You Can Pitch&lt;/em&gt;, delivering four-minute pitches and getting real-time feedback from a panel of seasoned investors.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Charles E. Hudson from Precursor Ventures is one of the judges at Startup Battlefield at TechCrunch Disrupt 2022 in San Francisco." class="wp-image-2428159" height="454" src="https://techcrunch.com/wp-content/uploads/2022/10/TechCrunch-Disrupt-Haje-Kamps-559.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Haje Kamps / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-scale-stage"&gt;Scale Stage&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Ready to level up? The Scale Stage offers growth-stage founders actionable insights to take their startups to the next level.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Fundraising Mistakes That Will Kill Your Round, and How to Avoid Them&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Alysaa Co&lt;/em&gt;&lt;em&gt;, Principal, Bain Capital Ventures; &lt;/em&gt;&lt;em&gt;Kamila Khasanova&lt;/em&gt;&lt;em&gt;, Founder and CEO, On Top Strategy; &lt;/em&gt;&lt;em&gt;Dr. Richard Munassi&lt;/em&gt;&lt;em&gt;, Managing Director, Tampa Bay Wave&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Raising funding as an early-stage startup is tough. This session reveals key mistakes to avoid and offers actionable tips to help founders optimize fundraising from pre-pitch to close for lasting success.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The New Rules of Growth-Stage Fundraising: How to Win at Raising a Series C &amp;amp; Beyond&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Cathy Gao&lt;/em&gt;&lt;em&gt;, Partner, Sapphire Ventures&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Growth-stage fundraising is back, fueled by GenAI. Cathy Gao of Sapphire Ventures shares what it takes to raise a strong Series C+ and how to stand out in today’s competitive VC landscape.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Operator’s Playbook for Building and Scaling Sustainable Companies&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Jon McNeill&lt;/em&gt;&lt;em&gt;, CEO and Co-Founder, DVx Ventures&lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most startups chase product-market fit but miss scalable go-to-market plans, risking failure. Jon McNeill shows how validating both drives growth, profitability, and impact from day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What to Think About Now If You Want to IPO Someday&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Mo Jomaa&lt;/em&gt;&lt;em&gt;, Partner, Capital G&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Learn how to build for a public debut from Mo Jomaa of CapitalG. Get insights on metrics growth investors seek, from market to hiring, with advice for IPO readiness—whether near or far.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-interactive-roundtables-to-exchange-knowledge-and-spark-growth"&gt;Interactive roundtables to exchange knowledge and spark growth&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 breakout session" class="wp-image-2986599" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-Breakout-Session.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Tech-Driven Fundraising: Making Financing Rounds Smarter, Faster, and Founder-Friendly&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Matt Derda&lt;/em&gt;&lt;em&gt;, Director, Private Market Product Marketer, Fidelity Private Shares&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Raising capital is chaotic for early-stage startups. This roundtable shows how founders, investors, and legal teams can use modern tech to streamline due diligence, data rooms, planning, and post-close tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How to Successfully Build at the Inception Stage&lt;br /&gt;&lt;/strong&gt;&lt;em&gt;Ellen Chisa&lt;/em&gt;&lt;em&gt;, Partner, Boldstart&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ellen Chisa of Boldstart shares key lessons for early startups: how to choose the right capital, run fast experiments, and avoid common pitfalls to learn and grow quickly from day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The 2025 VC Playbook: Where the Smart Money Is Going Next&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Rob Biederman, Managing Partner, Asymmetric&amp;nbsp;Capital Partners&lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Rob Biederman of Asymmetric Capital Partners reveals 2025’s VC trends, from hot sectors to deal shifts. Learn what drives investments and how founders can align with today’s VC playbook.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How Tech is Leveling The Playing Field So Anyone Can Be an Investor, Not Just the Wealthy&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Brandon Krieg&lt;/em&gt;&lt;em&gt;, Co-CEO and Co-Founder, Stash&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brandon Krieg, CEO of Stash, shares how his platform helps 1.3M users build lasting wealth with simple investing. He’ll discuss AI in finance coaching and fintech’s focus on long-term impact over quick wins.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Founders &amp;amp; Counsel: Reducing Friction, Increasing Efficiency&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Derek Fieldhouse&lt;/em&gt;&lt;em&gt;, Customer Success Manager, Fidelity Private Shares&lt;/em&gt;&lt;strong&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early-stage startups face costly, slow legal counsel. This roundtable explores how founders work with lawyers, what they avoid, and how tech can ease collaboration during funding and beyond.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Thriving with Anxiety: How Startup Founders Can Turn Fear, Pressure, and Self-Doubt into Their Greatest Advantage&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;David H. Rosmarin&lt;/em&gt;&lt;em&gt;, Associate Professor, Harvard Medical School&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anxiety isn’t the enemy of success. Dr. Rosmarin of Harvard shares how founders can turn fear and doubt into focus and drive, leading with authenticity while avoiding burnout.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Navigating Legal Landmines: Essential Legal Considerations for Startups&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Spencer Ricks&lt;/em&gt;&lt;em&gt;, Partner, and &lt;/em&gt;&lt;em&gt;Naomi Smith&lt;/em&gt;&lt;em&gt;, Counsel, Latham &amp;amp; Watkins&lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Spencer Ricks and Naomi Smith map the legal journey for founders—from formation to growth, IP, equity, employment, and fundraising. Get practical tips to build a strong legal foundation for your startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Breakthrough or Burnout: Why Founders Get Stuck (and How to Fix It)&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Jason Kraus&lt;/em&gt;&lt;em&gt;, Founder and CEO, and &lt;/em&gt;&lt;em&gt;Christopher Dube&lt;/em&gt;&lt;em&gt;, Chief Innovation Officer, Prepare 4 VC&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Startups fail not from bad ideas but founder struggles. Jason Kraus and Christopher Dube of Prepare 4 VC lead a roundtable on overcoming decision fatigue, burnout, and more with real tools to regain clarity and drive.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI Transformation for Business Growth: A Practical Roadmap for Companies&lt;br /&gt;&lt;/strong&gt;&lt;em&gt;Umair Javed&lt;/em&gt;&lt;em&gt;, CEO, tkxel&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This roundtable explores how Agentic AI adds cognition to workflows, boosting automation and efficiency. Learn practical steps to start, test, and scale AI, while sharing real experiences. No hype, just clarity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Winning Capital in a Competitive Market: How to Fund Your AI-Native Startup&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Rick Grinnell&lt;/em&gt;&lt;em&gt;, Managing Partner, Glasswing Ventures&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This roundtable covers AI-native startups’ pitching challenges with investors using old SaaS metrics and how to find investors who truly understand and support AI-driven growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Startup M&amp;amp;A Readiness: How to Be Acquired or Acquire Without Regret&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Dan Hoffman&lt;/em&gt;&lt;em&gt;, Partner, and &lt;/em&gt;&lt;em&gt;Stephen Ranere&lt;/em&gt;&lt;em&gt;, Partner, Latham &amp;amp; Watkins&lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As startups scale, M&amp;amp;A gets real. Daniel Hoffman and Stephen Ranere share legal and strategic tips on due diligence, deal terms, integration, and talent retention for smoother, smarter acquisitions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Fundraising to IPO: How to Build a PR &amp;amp; Marketing Engine That Drives Growth&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Nikki Parker&lt;/em&gt;&lt;em&gt;, EVP, Marketing and Communications, Insight Partners&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PR and marketing are key to winning investors, customers, and talent. Nikki Parker of Insight Partners shares must-have strategies to craft your story, build your brand, and drive real business impact.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Building Team Intelligence: How Product-Led Innovation Transforms Collaborative Problem-Solving&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Jeff Chow&lt;/em&gt;&lt;em&gt;, Chief Product and Technology Officer, Miro&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founder and exec Jeff Chow shares how to build inclusive, AI-powered tools that boost team communication. Learn what to automate, what to keep human, and how to balance tech with real-world expertise.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-scaling-conversations-don-t-stop-at-the-stages-they-start-there"&gt;The scaling conversations don’t stop at the stages — they start there&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 networking" class="wp-image-2987328" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-networking_2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The breakout and roundtable sessions are just the beginning. The real magic happens in the Expo Hall, Networking Lounge, and on the Braindate app. Whether you’re troubleshooting a product, seeking pitch feedback from a VC, or hoping to connect with a mentor, today’s the day to make it happen.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Use Braindate to set up 1:1 or small-group meetings — post your own topic or join one that speaks to you, then meet in person at the Networking Lounge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And don’t forget the &lt;strong&gt;Side Events&lt;/strong&gt; happening across Boston through July 17. Hosted by fellow attendees and sponsors, they’re designed to keep the momentum going — and the connections coming — long after the main event ends.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-there-s-still-time-to-join-today-s-ultimate-founder-conference"&gt;There’s still time to join today’s ultimate founder conference&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;It’s not too late to join us at &lt;/strong&gt;&lt;strong&gt;TechCrunch All Stage&lt;/strong&gt;&lt;strong&gt;!&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Grab your ticket now&lt;/strong&gt; and join us — and the rest of the startup community — at &lt;strong&gt;SoWa Power Station in Boston&lt;/strong&gt;. The event wraps at 5:00 p.m. ET, so don’t miss your chance to join the scaling conversations and leave with practical, strategic advice.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch All Stage 2025 header 16:9" class="wp-image-2986585" height="383" src="https://techcrunch.com/wp-content/uploads/2025/03/16x9_GeneralArticleImageHeader_TCAllStage_V1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Today’s the day! &lt;strong&gt;TechCrunch All Stage&lt;/strong&gt; is lighting up Boston’s SoWa Power Station at 7:30 a.m. ET sharp. The stages are set, the speakers are ready, and the startup community is gathering for one powerful day of insight, innovation, and momentum.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Boston and ready to scale your startup faster and more efficiently? There’s still time to join the founders and investors driving innovation and building what’s next. Grab a pass, dive into the conversations shaping the future of startup growth, and make the connections that move the needle.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Don’t miss a moment — &lt;strong&gt;secure your ticket&lt;/strong&gt; at the heart of today’s startup action.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024" class="wp-image-2986145" height="454" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-SYTYCP.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-here-s-what-s-in-store-for-today"&gt;Here’s what’s in store for today&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;We’ve got a powerhouse lineup of scaling and investing experts ready to deliver hard-hitting insights to an audience that thrives on growth, plus intentional, high-impact networking happening all day long.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Check out the &lt;strong&gt;agenda&lt;/strong&gt; for full session details and explore the &lt;strong&gt;speaker page&lt;/strong&gt; to get to know the experts behind the ideas. Or better yet, &lt;strong&gt;join us in person today and experience it all firsthand&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-two-breakout-stages-countless-insights-to-scale-smarter"&gt;Two breakout stages. Countless insights to scale smarter.&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-foundation-stage"&gt;Foundation Stage&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Just getting started on your startup journey? The Foundation Stage is your launchpad, packed with practical skills to help you build and grow from day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;All the Ways You Don’t Realize VCs Are Evaluating Your Company at Pre-Seed&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Charles Hudson&lt;/em&gt;&lt;em&gt;, Founder and Managing Partner, Precursor Ventures&lt;/em&gt;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This topic is key for pre-seed founders. VCs often judge based on the team and idea. A mismatched co-founder signals hiring risk, and missteps in fundraising show a lack of prep. Do your homework.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Preparing to Raise: Cap Table Best Practices to Help You Close Fast&lt;br /&gt;&lt;/strong&gt;&lt;em&gt;Lynne Zagami&lt;/em&gt;&lt;em&gt;, Vice President, Customer Success, Fidelity Private Shares; &lt;/em&gt;&lt;em&gt;John Andrews&lt;/em&gt;&lt;em&gt;, CEO and Co-Founder, Cimulate.ai; &lt;/em&gt;&lt;em&gt;Darrell West&lt;/em&gt;&lt;em&gt;, Co-Founder and CFO, DepositLink&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Raising funds? Make sure your cap table and data room are clean to avoid delays and costly legal fees. This session offers best practices and insights from legal, investor, and founder views.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;MVP in the Age of AI: When to Bot and When to Not&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Chris Gardner&lt;/em&gt;&lt;em&gt;, Partner, Underscore VC&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI is changing how founders build. Learn how to use it to turbocharge your MVP without letting it take over. Discover where AI shines, where humans are essential, and how to avoid toaster copy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The TAM Myth: How the Best Startups Reshape Markets&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Jahanvi Sardana&lt;/em&gt;&lt;em&gt;, Partner, Index Ventures&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Learn how top startups like Datadog and Airbnb created markets, not just sized them. Jahanvi Sardana of Index Ventures breaks down how to grow TAM and spot trends. A must for future-shaping founders.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;It’s not 2021 anymore. Understanding the 2025 VC landscape&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Kristen Craft&lt;/em&gt;&lt;em&gt;, Vice President, Business Partner Manager, Fidelity Private Shares; &lt;/em&gt;&lt;em&gt;Samara Gordon&lt;/em&gt;&lt;em&gt;, General Partner, Hyperplane; &lt;/em&gt;&lt;em&gt;John Harthorne&lt;/em&gt;&lt;em&gt;, Founder and Managing Director, Two Lanterns; &lt;/em&gt;&lt;em&gt;Daniel Acheampong&lt;/em&gt;&lt;em&gt;, General Partner, Visible Hands VC&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;VC in 2025 favors strategic, high-impact deals. Learn how midstage startups can adapt, use regional strengths, embrace AI, and build strong models for growth and successful exits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Crafting the Perfect VC Pitch: Luck Meets Strategy&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Tiffany Luck&lt;/em&gt;&lt;em&gt;, Partner, NEA&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Join Tiffany Luck of NEA to learn how to pitch with clarity and impact. Get insider tips on what VCs value, how to avoid common pitfalls, and how to tell a story that wins funding.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;So You Think You Can Pitch?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Watch three early-stage startups take the spotlight at &lt;em&gt;So You Think You Can Pitch&lt;/em&gt;, delivering four-minute pitches and getting real-time feedback from a panel of seasoned investors.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Charles E. Hudson from Precursor Ventures is one of the judges at Startup Battlefield at TechCrunch Disrupt 2022 in San Francisco." class="wp-image-2428159" height="454" src="https://techcrunch.com/wp-content/uploads/2022/10/TechCrunch-Disrupt-Haje-Kamps-559.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Haje Kamps / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-scale-stage"&gt;Scale Stage&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Ready to level up? The Scale Stage offers growth-stage founders actionable insights to take their startups to the next level.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Fundraising Mistakes That Will Kill Your Round, and How to Avoid Them&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Alysaa Co&lt;/em&gt;&lt;em&gt;, Principal, Bain Capital Ventures; &lt;/em&gt;&lt;em&gt;Kamila Khasanova&lt;/em&gt;&lt;em&gt;, Founder and CEO, On Top Strategy; &lt;/em&gt;&lt;em&gt;Dr. Richard Munassi&lt;/em&gt;&lt;em&gt;, Managing Director, Tampa Bay Wave&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Raising funding as an early-stage startup is tough. This session reveals key mistakes to avoid and offers actionable tips to help founders optimize fundraising from pre-pitch to close for lasting success.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The New Rules of Growth-Stage Fundraising: How to Win at Raising a Series C &amp;amp; Beyond&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Cathy Gao&lt;/em&gt;&lt;em&gt;, Partner, Sapphire Ventures&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Growth-stage fundraising is back, fueled by GenAI. Cathy Gao of Sapphire Ventures shares what it takes to raise a strong Series C+ and how to stand out in today’s competitive VC landscape.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The Operator’s Playbook for Building and Scaling Sustainable Companies&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Jon McNeill&lt;/em&gt;&lt;em&gt;, CEO and Co-Founder, DVx Ventures&lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most startups chase product-market fit but miss scalable go-to-market plans, risking failure. Jon McNeill shows how validating both drives growth, profitability, and impact from day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What to Think About Now If You Want to IPO Someday&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Mo Jomaa&lt;/em&gt;&lt;em&gt;, Partner, Capital G&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Learn how to build for a public debut from Mo Jomaa of CapitalG. Get insights on metrics growth investors seek, from market to hiring, with advice for IPO readiness—whether near or far.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-interactive-roundtables-to-exchange-knowledge-and-spark-growth"&gt;Interactive roundtables to exchange knowledge and spark growth&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 breakout session" class="wp-image-2986599" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-Breakout-Session.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Tech-Driven Fundraising: Making Financing Rounds Smarter, Faster, and Founder-Friendly&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Matt Derda&lt;/em&gt;&lt;em&gt;, Director, Private Market Product Marketer, Fidelity Private Shares&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Raising capital is chaotic for early-stage startups. This roundtable shows how founders, investors, and legal teams can use modern tech to streamline due diligence, data rooms, planning, and post-close tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How to Successfully Build at the Inception Stage&lt;br /&gt;&lt;/strong&gt;&lt;em&gt;Ellen Chisa&lt;/em&gt;&lt;em&gt;, Partner, Boldstart&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ellen Chisa of Boldstart shares key lessons for early startups: how to choose the right capital, run fast experiments, and avoid common pitfalls to learn and grow quickly from day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The 2025 VC Playbook: Where the Smart Money Is Going Next&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Rob Biederman, Managing Partner, Asymmetric&amp;nbsp;Capital Partners&lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Rob Biederman of Asymmetric Capital Partners reveals 2025’s VC trends, from hot sectors to deal shifts. Learn what drives investments and how founders can align with today’s VC playbook.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;How Tech is Leveling The Playing Field So Anyone Can Be an Investor, Not Just the Wealthy&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Brandon Krieg&lt;/em&gt;&lt;em&gt;, Co-CEO and Co-Founder, Stash&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Brandon Krieg, CEO of Stash, shares how his platform helps 1.3M users build lasting wealth with simple investing. He’ll discuss AI in finance coaching and fintech’s focus on long-term impact over quick wins.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Founders &amp;amp; Counsel: Reducing Friction, Increasing Efficiency&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Derek Fieldhouse&lt;/em&gt;&lt;em&gt;, Customer Success Manager, Fidelity Private Shares&lt;/em&gt;&lt;strong&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early-stage startups face costly, slow legal counsel. This roundtable explores how founders work with lawyers, what they avoid, and how tech can ease collaboration during funding and beyond.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Thriving with Anxiety: How Startup Founders Can Turn Fear, Pressure, and Self-Doubt into Their Greatest Advantage&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;David H. Rosmarin&lt;/em&gt;&lt;em&gt;, Associate Professor, Harvard Medical School&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anxiety isn’t the enemy of success. Dr. Rosmarin of Harvard shares how founders can turn fear and doubt into focus and drive, leading with authenticity while avoiding burnout.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Navigating Legal Landmines: Essential Legal Considerations for Startups&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Spencer Ricks&lt;/em&gt;&lt;em&gt;, Partner, and &lt;/em&gt;&lt;em&gt;Naomi Smith&lt;/em&gt;&lt;em&gt;, Counsel, Latham &amp;amp; Watkins&lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Spencer Ricks and Naomi Smith map the legal journey for founders—from formation to growth, IP, equity, employment, and fundraising. Get practical tips to build a strong legal foundation for your startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Breakthrough or Burnout: Why Founders Get Stuck (and How to Fix It)&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Jason Kraus&lt;/em&gt;&lt;em&gt;, Founder and CEO, and &lt;/em&gt;&lt;em&gt;Christopher Dube&lt;/em&gt;&lt;em&gt;, Chief Innovation Officer, Prepare 4 VC&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Startups fail not from bad ideas but founder struggles. Jason Kraus and Christopher Dube of Prepare 4 VC lead a roundtable on overcoming decision fatigue, burnout, and more with real tools to regain clarity and drive.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;AI Transformation for Business Growth: A Practical Roadmap for Companies&lt;br /&gt;&lt;/strong&gt;&lt;em&gt;Umair Javed&lt;/em&gt;&lt;em&gt;, CEO, tkxel&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This roundtable explores how Agentic AI adds cognition to workflows, boosting automation and efficiency. Learn practical steps to start, test, and scale AI, while sharing real experiences. No hype, just clarity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Winning Capital in a Competitive Market: How to Fund Your AI-Native Startup&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Rick Grinnell&lt;/em&gt;&lt;em&gt;, Managing Partner, Glasswing Ventures&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This roundtable covers AI-native startups’ pitching challenges with investors using old SaaS metrics and how to find investors who truly understand and support AI-driven growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Startup M&amp;amp;A Readiness: How to Be Acquired or Acquire Without Regret&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Dan Hoffman&lt;/em&gt;&lt;em&gt;, Partner, and &lt;/em&gt;&lt;em&gt;Stephen Ranere&lt;/em&gt;&lt;em&gt;, Partner, Latham &amp;amp; Watkins&lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As startups scale, M&amp;amp;A gets real. Daniel Hoffman and Stephen Ranere share legal and strategic tips on due diligence, deal terms, integration, and talent retention for smoother, smarter acquisitions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;From Fundraising to IPO: How to Build a PR &amp;amp; Marketing Engine That Drives Growth&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Nikki Parker&lt;/em&gt;&lt;em&gt;, EVP, Marketing and Communications, Insight Partners&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PR and marketing are key to winning investors, customers, and talent. Nikki Parker of Insight Partners shares must-have strategies to craft your story, build your brand, and drive real business impact.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Building Team Intelligence: How Product-Led Innovation Transforms Collaborative Problem-Solving&lt;/strong&gt;&lt;br /&gt;&lt;em&gt;Jeff Chow&lt;/em&gt;&lt;em&gt;, Chief Product and Technology Officer, Miro&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founder and exec Jeff Chow shares how to build inclusive, AI-powered tools that boost team communication. Learn what to automate, what to keep human, and how to balance tech with real-world expertise.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-scaling-conversations-don-t-stop-at-the-stages-they-start-there"&gt;The scaling conversations don’t stop at the stages — they start there&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 networking" class="wp-image-2987328" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-networking_2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The breakout and roundtable sessions are just the beginning. The real magic happens in the Expo Hall, Networking Lounge, and on the Braindate app. Whether you’re troubleshooting a product, seeking pitch feedback from a VC, or hoping to connect with a mentor, today’s the day to make it happen.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Use Braindate to set up 1:1 or small-group meetings — post your own topic or join one that speaks to you, then meet in person at the Networking Lounge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And don’t forget the &lt;strong&gt;Side Events&lt;/strong&gt; happening across Boston through July 17. Hosted by fellow attendees and sponsors, they’re designed to keep the momentum going — and the connections coming — long after the main event ends.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-there-s-still-time-to-join-today-s-ultimate-founder-conference"&gt;There’s still time to join today’s ultimate founder conference&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;It’s not too late to join us at &lt;/strong&gt;&lt;strong&gt;TechCrunch All Stage&lt;/strong&gt;&lt;strong&gt;!&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Grab your ticket now&lt;/strong&gt; and join us — and the rest of the startup community — at &lt;strong&gt;SoWa Power Station in Boston&lt;/strong&gt;. The event wraps at 5:00 p.m. ET, so don’t miss your chance to join the scaling conversations and leave with practical, strategic advice.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch All Stage 2025 header 16:9" class="wp-image-2986585" height="383" src="https://techcrunch.com/wp-content/uploads/2025/03/16x9_GeneralArticleImageHeader_TCAllStage_V1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/15/techcrunch-all-stage-launches-in-boston-today-dont-miss-what-founders-are-learning/</guid><pubDate>Tue, 15 Jul 2025 10:30:00 +0000</pubDate></item><item><title>[NEW] Anthropic launches finance-specific Claude with built-in data connectors, higher limits and prompt libraries (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/financial-firms-get-a-purpose-built-claude-as-anthropic-bets-on-vertical-ai-platforms/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;As some regulated enterprises cautiously expand their use of AI, platform and model makers are starting to offer bespoke versions to specific industries.&lt;/p&gt;



&lt;p&gt;Anthropic is making its first step into that direction with the new Claude for Financial Services, essentially a special version of its Claude for Enterprise tier, that could soothe some of the fears of the sector around interoperability and tool use. Anthropic will also provide pre-built connectors to data providers, opening up discoverability routes for tools on Claude.&lt;/p&gt;



&lt;p&gt;Jonathan Pelosi, head of industry for financial services at Anthropic, told VentureBeat that Anthropic models “were already particularly well-suited for financial workloads and we’ve been tailoring them to get better and better.” But while the Claude models offer enterprise solutions for financial services firms, Pelosi said the sector was also looking for more features from the Claude chat interface.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Unlike some competitors in the space who built a consumer app that became a sensation, or they built these new video generators and meme generators, that’s just never our focus,” Pelosi said. “We are enterprise first, so our models are uniquely well-suited to perform best in class against complicated enterprise workloads, which means complicated quantitative analysis, complex data extraction for the financial services industry at scale.”&lt;/p&gt;



&lt;p&gt;Claude for Financial Services would offer users additional rate limits, especially since, Pelosi noted, many analysts often find themselves quickly hitting capacity limitations due to the size of their workloads. Unlike Claude for Enterprise, this financial services-specific platform will also include pre-built MCP connectors to financial data providers like FactSet, PitchBook, S&amp;amp;P Capital IQ and Morningstar, among others, and implementation support from Anthropic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The third big difference between Claude for Enterprise and Claude for Financial Services is the presence of a prompt library. Pelosi said some users had a difficult time translating their analytics workflow or needs into a prompt, so the prompt library can guide them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Pelosi said customers already using Claude for Enterprise are not obligated to move to the financial services version; however, added features like increased limits might prompt them to switch.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-anthropic-is-approaching-the-financial-services-ecosystem"&gt;How Anthropic is approaching the financial services ecosystem&lt;/h2&gt;



&lt;p&gt;Pelosi noted that many financial service institutions have strong engineers who can build AI applications. However, these companies’ core focus remains banking or insurance, so a platform that simplifies the process of connecting data to AI is essential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“What we’re trying to do is bring all this technology together under one roof,” said Pelosi. “Think of it as an out-of-the-box solution that’s easily configurable for the Bridgewaters, or the Norwegian Sovereign Wealth Funds of the world, versus the alternative where they cobble this thing together on their own.” &lt;/p&gt;



&lt;p&gt;Financial services companies have been building generative AI tools in various ways, creating AI platforms on their own using off-the-shelf models, or building on top of existing chatbots like Claude, Gemini or ChatGPT. BNY, for example, has been experimenting with AI agents for its AI platform Eliza. Capital One also built an agent that pulls on car dealership inventory and car loan data for auto sales.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Startup Metal offers an assistant for financial analysts and private equity that reads and parses through 10-Ks, 10-Qs or 8-Ks. Rogo, another startup, also allows financial institutions to upload documents and set workflows.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-allaying-concerns"&gt;Allaying concerns&lt;/h2&gt;



&lt;p&gt;Anthropic is not alone in providing bespoke solutions for the financial sector. However, offering a guided setup and vetted access to data providers may go a long way for an industry wary of accidentally exposing itself to more risk.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;MCP can connect one company or its agent to another company by providing needed identification and tool use permissions. However, regulated industries express concern that it still lacks some important KYC and identity features. Many in the sector see the benefit of MCP servers to access critical financial data or other documents, but are waiting for mass adoption.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At the same time, the financial services industry has been criticized for being too cautious in adopting the technology.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Pelosi reiterated that Anthropic is focused on safety and responsibility, which is why he feels a solution specific to finance was the natural next step for them. Pelosi said that while Anthropic’s intention “is not to build a Claude for every vertical,” the company could extend bespoke features to other industries at some point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Anthropic also recently opened up Claude to more tool discoverability with partners like Canva, Notion, Stripe and Figma, providing more context to searches and activities on the app.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;As some regulated enterprises cautiously expand their use of AI, platform and model makers are starting to offer bespoke versions to specific industries.&lt;/p&gt;



&lt;p&gt;Anthropic is making its first step into that direction with the new Claude for Financial Services, essentially a special version of its Claude for Enterprise tier, that could soothe some of the fears of the sector around interoperability and tool use. Anthropic will also provide pre-built connectors to data providers, opening up discoverability routes for tools on Claude.&lt;/p&gt;



&lt;p&gt;Jonathan Pelosi, head of industry for financial services at Anthropic, told VentureBeat that Anthropic models “were already particularly well-suited for financial workloads and we’ve been tailoring them to get better and better.” But while the Claude models offer enterprise solutions for financial services firms, Pelosi said the sector was also looking for more features from the Claude chat interface.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Unlike some competitors in the space who built a consumer app that became a sensation, or they built these new video generators and meme generators, that’s just never our focus,” Pelosi said. “We are enterprise first, so our models are uniquely well-suited to perform best in class against complicated enterprise workloads, which means complicated quantitative analysis, complex data extraction for the financial services industry at scale.”&lt;/p&gt;



&lt;p&gt;Claude for Financial Services would offer users additional rate limits, especially since, Pelosi noted, many analysts often find themselves quickly hitting capacity limitations due to the size of their workloads. Unlike Claude for Enterprise, this financial services-specific platform will also include pre-built MCP connectors to financial data providers like FactSet, PitchBook, S&amp;amp;P Capital IQ and Morningstar, among others, and implementation support from Anthropic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The third big difference between Claude for Enterprise and Claude for Financial Services is the presence of a prompt library. Pelosi said some users had a difficult time translating their analytics workflow or needs into a prompt, so the prompt library can guide them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Pelosi said customers already using Claude for Enterprise are not obligated to move to the financial services version; however, added features like increased limits might prompt them to switch.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-anthropic-is-approaching-the-financial-services-ecosystem"&gt;How Anthropic is approaching the financial services ecosystem&lt;/h2&gt;



&lt;p&gt;Pelosi noted that many financial service institutions have strong engineers who can build AI applications. However, these companies’ core focus remains banking or insurance, so a platform that simplifies the process of connecting data to AI is essential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“What we’re trying to do is bring all this technology together under one roof,” said Pelosi. “Think of it as an out-of-the-box solution that’s easily configurable for the Bridgewaters, or the Norwegian Sovereign Wealth Funds of the world, versus the alternative where they cobble this thing together on their own.” &lt;/p&gt;



&lt;p&gt;Financial services companies have been building generative AI tools in various ways, creating AI platforms on their own using off-the-shelf models, or building on top of existing chatbots like Claude, Gemini or ChatGPT. BNY, for example, has been experimenting with AI agents for its AI platform Eliza. Capital One also built an agent that pulls on car dealership inventory and car loan data for auto sales.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Startup Metal offers an assistant for financial analysts and private equity that reads and parses through 10-Ks, 10-Qs or 8-Ks. Rogo, another startup, also allows financial institutions to upload documents and set workflows.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-allaying-concerns"&gt;Allaying concerns&lt;/h2&gt;



&lt;p&gt;Anthropic is not alone in providing bespoke solutions for the financial sector. However, offering a guided setup and vetted access to data providers may go a long way for an industry wary of accidentally exposing itself to more risk.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;MCP can connect one company or its agent to another company by providing needed identification and tool use permissions. However, regulated industries express concern that it still lacks some important KYC and identity features. Many in the sector see the benefit of MCP servers to access critical financial data or other documents, but are waiting for mass adoption.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At the same time, the financial services industry has been criticized for being too cautious in adopting the technology.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Pelosi reiterated that Anthropic is focused on safety and responsibility, which is why he feels a solution specific to finance was the natural next step for them. Pelosi said that while Anthropic’s intention “is not to build a Claude for every vertical,” the company could extend bespoke features to other industries at some point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Anthropic also recently opened up Claude to more tool discoverability with partners like Canva, Notion, Stripe and Figma, providing more context to searches and activities on the app.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/financial-firms-get-a-purpose-built-claude-as-anthropic-bets-on-vertical-ai-platforms/</guid><pubDate>Tue, 15 Jul 2025 11:00:00 +0000</pubDate></item><item><title>The Download: combating audio deepfakes, and AI in the classroom (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/15/1120151/the-download-combating-audio-deepfakes-and-ai-in-the-classroom/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;AI text-to-speech programs could one day “unlearn” how to imitate certain people&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;A new technique known as “machine unlearning” could be used to teach AI models to forget specific voices.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;How it works: &lt;/strong&gt;Currently, companies tend to deal with this issue by checking whether the prompts or the AI’s responses contain disallowed material. Machine unlearning instead asks whether an AI can be made to forget a piece of information that the company doesn’t want it to know. It works by taking a model and the specific data to be redacted then using them to create a new model—essentially, a version of the original that never learned that piece of data.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Why it matters: &lt;/strong&gt;This could be an important step in stopping the rise of audio deepfakes, where someone’s voice is copied to carry out fraud or scams. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Peter Hall&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;AI’s giants want to take over the classroom&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;School’s out and it’s high summer, but a bunch of teachers are plotting how they’re going to use AI this upcoming school year. God help them.&lt;/p&gt;  &lt;p&gt;On July 8, OpenAI, Microsoft, and Anthropic announced a $23 million partnership with one of the largest teachers’ unions in the United States to bring more AI into K–12 classrooms. They will train teachers at a New York City headquarters on how to use AI both for teaching and for tasks like planning lessons and writing reports, starting this fall.&lt;/p&gt;&lt;p&gt;But these companies could face an uphill battle. There's a lack of clear evidence that AI can be a net benefit for students, and it's hard to trust that the AI companies funding this initiative will give honest advice on when &lt;em&gt;not&lt;/em&gt; to use AI in the classroom. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;—James O'Donnell&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up &lt;/strong&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Nvidia says the US has lifted its ban on AI chip sales to China&lt;/strong&gt;&lt;br /&gt;Jensen Huang has sweet-talked Donald Trump into reversing his three-month old ban. (BBC)&lt;br /&gt;+ &lt;em&gt;The company will start selling its H20 chip to China. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;America may slap tariffs on a raw material used for chips and solar panels. &lt;/em&gt;(FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 China has launched its digital ID system&lt;/strong&gt;&lt;br /&gt;It’ll give the country even greater powers to surveil and censor its internet users. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 xAI has secured a contract with the US Department of Defense&lt;/strong&gt;&lt;br /&gt;Just days after its Grok chatbot had an anti-Semitic meltdown. (The Guardian)&lt;br /&gt;+ &lt;em&gt;EU officials are holding talks with X representatives after the outburst. &lt;/em&gt;(Bloomberg $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;4 Meta’s data centers are on the verge of triggering a major water shortage&lt;/strong&gt;&lt;br /&gt;Local residents in Newton County, Georgia are suffering. (NYT $)&lt;br /&gt;+ &lt;em&gt;But Zuckerberg wants to build gigawatt-size centers anyway. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;We did the math on AI’s energy footprint. Here’s the story you haven’t heard. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 The Trump administration is incinerating tons of emergency food&lt;/strong&gt;&lt;br /&gt;Rather than sending it to people in need. (The Atlantic $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 The US is attempting to revive its rare-earth industry&lt;/strong&gt;&lt;br /&gt;The Pentagon has invested more than $1 billion in American firm MP Materials. (WSJ $)&lt;br /&gt;+ &lt;em&gt;It’s all part of a plan to counter China’s critical mineral dominance. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;This rare earth metal shows us the future of our planet’s resources. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 AI nudifying apps are big business&lt;br /&gt;&lt;/strong&gt;They’re making millions of dollars a year, and rely on tech built by US companies. (Wired $)&lt;br /&gt;+ &lt;em&gt;The viral AI avatar app Lensa undressed me—without my consent. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 Can anything save the web at this point?&lt;br /&gt;&lt;/strong&gt;Traffic is dropping, and AI use is rising. (Economist $)&lt;br /&gt;+ &lt;em&gt;How to fix the internet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Bytedance is working on its own mixed reality goggles&lt;/strong&gt;&lt;br /&gt;A couple of years after it scaled back its work on an AR and VR headset. (The Information $)&lt;br /&gt;+ &lt;em&gt;What’s next for smart glasses. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 Minecraft has birthed a generation of entrepreneurs&lt;/strong&gt;&lt;br /&gt;The game encourages players to learn to program. (Insider $)&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I suddenly felt pure, unconditional love.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Faeight, a woman ‘married’ to a chatbot named Gryff, describes her strong feelings for a previous AI partner, the Guardian reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeIPu7HMuyGVNauyRy6_GEP3AWoAFM97esA8Z13ATnhFUSVO-SJjFm4HeorzSHzTzkc1YTXvKSX9nZMNbCq8FxsVHA-RzDoj4shYiObKFwBbmx68kMGbBaYQj_IL4UtLEO5xmRNZg?key=U0Ke3x0hJ-5KZLuDaLqfbQ" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;End of life decisions are difficult and distressing. Could AI help?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;End-of-life decisions can be extremely upsetting for surrogates—the people who have to make those calls on behalf of another person. Friends or family members may disagree over what’s best for their loved one, which can lead to distressing situations.&lt;/p&gt;&lt;p&gt;David Wendler, a bioethicist at the US National Institutes of Health, and his colleagues have been working on an idea for something that could make things easier: an artificial intelligence-based tool that can help surrogates predict what the patients themselves would want in any given situation.&lt;/p&gt;&lt;p&gt;Wendler hopes to start building their tool as soon as they secure funding for it, potentially in the coming months. But rolling it out won’t be simple. Critics wonder how such a tool can ethically be trained on a person’s data, and whether life-or-death decisions should ever be entrusted to AI. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;   
&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;AI text-to-speech programs could one day “unlearn” how to imitate certain people&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;A new technique known as “machine unlearning” could be used to teach AI models to forget specific voices.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;How it works: &lt;/strong&gt;Currently, companies tend to deal with this issue by checking whether the prompts or the AI’s responses contain disallowed material. Machine unlearning instead asks whether an AI can be made to forget a piece of information that the company doesn’t want it to know. It works by taking a model and the specific data to be redacted then using them to create a new model—essentially, a version of the original that never learned that piece of data.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Why it matters: &lt;/strong&gt;This could be an important step in stopping the rise of audio deepfakes, where someone’s voice is copied to carry out fraud or scams. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Peter Hall&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;AI’s giants want to take over the classroom&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;School’s out and it’s high summer, but a bunch of teachers are plotting how they’re going to use AI this upcoming school year. God help them.&lt;/p&gt;  &lt;p&gt;On July 8, OpenAI, Microsoft, and Anthropic announced a $23 million partnership with one of the largest teachers’ unions in the United States to bring more AI into K–12 classrooms. They will train teachers at a New York City headquarters on how to use AI both for teaching and for tasks like planning lessons and writing reports, starting this fall.&lt;/p&gt;&lt;p&gt;But these companies could face an uphill battle. There's a lack of clear evidence that AI can be a net benefit for students, and it's hard to trust that the AI companies funding this initiative will give honest advice on when &lt;em&gt;not&lt;/em&gt; to use AI in the classroom. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;—James O'Donnell&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up &lt;/strong&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Nvidia says the US has lifted its ban on AI chip sales to China&lt;/strong&gt;&lt;br /&gt;Jensen Huang has sweet-talked Donald Trump into reversing his three-month old ban. (BBC)&lt;br /&gt;+ &lt;em&gt;The company will start selling its H20 chip to China. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;America may slap tariffs on a raw material used for chips and solar panels. &lt;/em&gt;(FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 China has launched its digital ID system&lt;/strong&gt;&lt;br /&gt;It’ll give the country even greater powers to surveil and censor its internet users. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 xAI has secured a contract with the US Department of Defense&lt;/strong&gt;&lt;br /&gt;Just days after its Grok chatbot had an anti-Semitic meltdown. (The Guardian)&lt;br /&gt;+ &lt;em&gt;EU officials are holding talks with X representatives after the outburst. &lt;/em&gt;(Bloomberg $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;4 Meta’s data centers are on the verge of triggering a major water shortage&lt;/strong&gt;&lt;br /&gt;Local residents in Newton County, Georgia are suffering. (NYT $)&lt;br /&gt;+ &lt;em&gt;But Zuckerberg wants to build gigawatt-size centers anyway. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;We did the math on AI’s energy footprint. Here’s the story you haven’t heard. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 The Trump administration is incinerating tons of emergency food&lt;/strong&gt;&lt;br /&gt;Rather than sending it to people in need. (The Atlantic $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 The US is attempting to revive its rare-earth industry&lt;/strong&gt;&lt;br /&gt;The Pentagon has invested more than $1 billion in American firm MP Materials. (WSJ $)&lt;br /&gt;+ &lt;em&gt;It’s all part of a plan to counter China’s critical mineral dominance. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;This rare earth metal shows us the future of our planet’s resources. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 AI nudifying apps are big business&lt;br /&gt;&lt;/strong&gt;They’re making millions of dollars a year, and rely on tech built by US companies. (Wired $)&lt;br /&gt;+ &lt;em&gt;The viral AI avatar app Lensa undressed me—without my consent. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 Can anything save the web at this point?&lt;br /&gt;&lt;/strong&gt;Traffic is dropping, and AI use is rising. (Economist $)&lt;br /&gt;+ &lt;em&gt;How to fix the internet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Bytedance is working on its own mixed reality goggles&lt;/strong&gt;&lt;br /&gt;A couple of years after it scaled back its work on an AR and VR headset. (The Information $)&lt;br /&gt;+ &lt;em&gt;What’s next for smart glasses. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 Minecraft has birthed a generation of entrepreneurs&lt;/strong&gt;&lt;br /&gt;The game encourages players to learn to program. (Insider $)&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I suddenly felt pure, unconditional love.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Faeight, a woman ‘married’ to a chatbot named Gryff, describes her strong feelings for a previous AI partner, the Guardian reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeIPu7HMuyGVNauyRy6_GEP3AWoAFM97esA8Z13ATnhFUSVO-SJjFm4HeorzSHzTzkc1YTXvKSX9nZMNbCq8FxsVHA-RzDoj4shYiObKFwBbmx68kMGbBaYQj_IL4UtLEO5xmRNZg?key=U0Ke3x0hJ-5KZLuDaLqfbQ" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;End of life decisions are difficult and distressing. Could AI help?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;End-of-life decisions can be extremely upsetting for surrogates—the people who have to make those calls on behalf of another person. Friends or family members may disagree over what’s best for their loved one, which can lead to distressing situations.&lt;/p&gt;&lt;p&gt;David Wendler, a bioethicist at the US National Institutes of Health, and his colleagues have been working on an idea for something that could make things easier: an artificial intelligence-based tool that can help surrogates predict what the patients themselves would want in any given situation.&lt;/p&gt;&lt;p&gt;Wendler hopes to start building their tool as soon as they secure funding for it, potentially in the coming months. But rolling it out won’t be simple. Critics wonder how such a tool can ethically be trained on a person’s data, and whether life-or-death decisions should ever be entrusted to AI. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;   
&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/15/1120151/the-download-combating-audio-deepfakes-and-ai-in-the-classroom/</guid><pubDate>Tue, 15 Jul 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] Perplexity offers free AI tools to students worldwide in partnership with SheerID (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/perplexity-offers-free-ai-tools-to-students-worldwide-in-partnership-with-sheerid/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Perplexity, the AI-powered search engine that competes with Google and ChatGPT, has partnered with identity verification company SheerID to offer up to two years of free premium service to more than 264 million students worldwide, the companies announced Monday.&lt;/p&gt;



&lt;p&gt;The deal tackles a key challenge for AI companies: providing educational access to expensive tools while preventing discount fraud. Perplexity is betting heavily on the education market as competition for users intensifies across the industry.&lt;/p&gt;



&lt;p&gt;Under the agreement, verified students can access Perplexity Pro, normally priced at $20 per month, through SheerID’s verification platform that connects to more than 200,000 authoritative data sources across 190 countries. The program will be available to all university and post-secondary students globally where SheerID provides verification, making 264 million students eligible worldwide. The offering includes features like cited research, in-depth reports, and interactive AI applications.&lt;/p&gt;



&lt;p&gt;The partnership comes as AI adoption surges among students, with 86% of U.S. students using AI tools to support their studies, according to the companies. However, the rapid growth has sparked concerns about academic integrity and the need for AI tools designed specifically for educational use.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-advanced-verification-technology-stops-sophisticated-student-discount-fraud"&gt;How advanced verification technology stops sophisticated student discount fraud&lt;/h2&gt;



&lt;p&gt;SheerID, a Portland-based company founded in 2011, has built its business around solving a persistent problem for retailers and service providers: verifying that consumers actually belong to groups eligible for special discounts, such as students, military personnel, or healthcare workers.&lt;/p&gt;



&lt;p&gt;“We verify that customer audience data, and then we enrich that brand CRM with this first party data, so that they can fully engage their most loyal audiences,” explained Rebecca Grimes, Chief Revenue Officer at SheerID, in an exclusive interview with VentureBeat. “Our platform is built so that we can deliver this seamless, secure and fast experience for their consumers.”&lt;/p&gt;



&lt;p&gt;The verification process begins with basic information like name, date of birth, and university. SheerID immediately checks this against authoritative data sources, which Grimes said the company has built relationships with over 14 years in business. If instant verification fails, the system moves to document review using both AI-powered analysis and manual verification.&lt;/p&gt;



&lt;p&gt;“If we are unable to process that through our authoritative data sources, then there is an incremental step where you add a document upload,” Grimes said. “Once that goes into our system that is another layer of supplemental review that is both automated through our AI document review process as well as, in some cases, manual doc review.”&lt;/p&gt;



&lt;p&gt;The company can complete this secondary verification process in an average of 15 minutes globally, Grimes said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-identity-based-marketing-offers-deliver-337-roi-for-major-brands"&gt;Why identity-based marketing offers deliver 337% ROI for major brands&lt;/h2&gt;



&lt;p&gt;The partnership reflects the growing sophistication of fraud in student discount programs. Jesse Dwyer, head of communications at Perplexity, said the company’s focus on accuracy makes it particularly valuable for academic users who need trustworthy information.&lt;/p&gt;



&lt;p&gt;“For most AI model makers, a certain amount of hallucination is a feature, and for Perplexity, it’s a bug,” Dwyer said in an exclusive interview with VentureBeat. “That’s something that we found academics value, students value it, finance professionals value it enormously.”&lt;/p&gt;



&lt;p&gt;Unlike competitors that train AI models on user data, Dwyer said Perplexity doesn’t use customer information for training purposes. “We don’t train on your data,” he said. “The model doesn’t actually get trained on your data.”&lt;/p&gt;



&lt;p&gt;SheerID operates on a software-as-a-service model, charging for platform access, verification processing volume, and support services. The company, which has about 160 employees with offices in the U.S. and Europe, works with major brands including Amazon, Spotify, and T-Mobile.&lt;/p&gt;



&lt;p&gt;According to a study commissioned by SheerID from Forrester Consulting, customers using the company’s verification platform achieved a 337% return on investment through increased revenue, fraud prevention, and operational savings.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-perplexity-aims-to-beat-chatgpt-and-google-in-the-battle-for-student-users"&gt;How Perplexity aims to beat ChatGPT and Google in the battle for student users&lt;/h2&gt;



&lt;p&gt;AI companies increasingly target the education market. Perplexity differentiates itself from larger competitors like OpenAI’s ChatGPT and Google’s search tools by emphasizing accuracy and source attribution.&lt;/p&gt;



&lt;p&gt;“What we do with third party models is we do two forms of adaptations,” Dwyer explained. “We build our own in-house models that look at the query that you’re asking… We’re reformulating queries. So you ask a question one way, what AI is good at is it can ask that same question 1000 different ways.”&lt;/p&gt;



&lt;p&gt;This focus on accuracy addresses concerns among educators about AI tools that can generate plausible-sounding but incorrect information. Dwyer said Perplexity’s approach aligns with academic values around building knowledge through verified sources.&lt;/p&gt;



&lt;p&gt;“The peer review system was developed to create a sense of accuracy… so that future generations can build on that established knowledge,” he said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-real-cost-of-giving-away-millions-in-free-ai-services-to-students"&gt;The real cost of giving away millions in free AI services to students&lt;/h2&gt;



&lt;p&gt;The student access program is a major investment for Perplexity, though company executives declined to specify the cost. Dwyer noted that unlike traditional software, AI tools have direct computational costs for each query.&lt;/p&gt;



&lt;p&gt;“Every query has a direct cost in terms of compute,” Dwyer said. “That’s something that we’re mindful of, and we build our partnerships around.”&lt;/p&gt;



&lt;p&gt;However, the company sees strategic value in building relationships with academic users. Unlike many tech companies that monetize through advertising, Dwyer said ads represent “less than a half of a percent of our revenue” and the company doesn’t sell user data.&lt;/p&gt;



&lt;p&gt;The partnership provides SheerID with exposure to the rapidly growing AI market. Grimes compared the current moment to the early days of music streaming, when SheerID began working with Spotify and other services.&lt;/p&gt;



&lt;p&gt;“I think that we’re going to see similar global programs in the AI industry, beyond just engaging with students that will be needed, needing services like SheerID to support their success,” she said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-student-data-stays-protected-in-an-era-of-ai-privacy-concerns"&gt;How student data stays protected in an era of AI privacy concerns&lt;/h2&gt;



&lt;p&gt;Both companies emphasized their approach to data privacy, particularly important given recent concerns about AI companies’ use of personal information. SheerID operates as a data processor rather than controller, meaning customer data belongs to the brand partner rather than SheerID.&lt;/p&gt;



&lt;p&gt;“We’re processors, so we’re not a controller, so we are just processing that data on behalf of that brand,” Grimes explained. “We don’t take control of the ownership of that consumer data.”&lt;/p&gt;



&lt;p&gt;The verification system looks at additional signals beyond documents to prevent fraud, including IP address location and proximity to claimed universities. This “triangulation of all of these processes and data” allows SheerID to “confidently confirm eligibility or ineligibility against an offer,” Grimes said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-this-partnership-signals-for-the-future-of-ai-in-education"&gt;What this partnership signals for the future of AI in education&lt;/h2&gt;



&lt;p&gt;The partnership reflects broader trends in both the AI and identity verification industries. SheerID has expanded rapidly in recent years, launching new products for in-store verification and income-based eligibility checking. The company appointed former Ruby CEO Stephanie Copeland Weber as CEO in June 2024, as founder Jake Weatherly transitioned to a board role.&lt;/p&gt;



&lt;p&gt;For Perplexity, founded in 2022, the education market represents a natural fit for its research-focused AI tools. The company processes more than 150 million questions weekly globally and has positioned itself as an “answer engine” that provides sourced information rather than generating creative content.&lt;/p&gt;



&lt;p&gt;The partnership comes amid broader scrutiny of AI’s role in education, with institutions grappling with questions of academic integrity and the appropriate use of AI tools. By requiring verification and emphasizing accuracy, both companies aim to address these concerns while expanding access to AI capabilities.&lt;/p&gt;



&lt;p&gt;“We would encourage educators and universities or researchers of any kind to reach out and try perplexity,” Dwyer said. “We’re one of the few leading tech companies that’s founded not just by a PhD student, which is fairly common, we’re founded by one who actually finished his PhD.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Perplexity, the AI-powered search engine that competes with Google and ChatGPT, has partnered with identity verification company SheerID to offer up to two years of free premium service to more than 264 million students worldwide, the companies announced Monday.&lt;/p&gt;



&lt;p&gt;The deal tackles a key challenge for AI companies: providing educational access to expensive tools while preventing discount fraud. Perplexity is betting heavily on the education market as competition for users intensifies across the industry.&lt;/p&gt;



&lt;p&gt;Under the agreement, verified students can access Perplexity Pro, normally priced at $20 per month, through SheerID’s verification platform that connects to more than 200,000 authoritative data sources across 190 countries. The program will be available to all university and post-secondary students globally where SheerID provides verification, making 264 million students eligible worldwide. The offering includes features like cited research, in-depth reports, and interactive AI applications.&lt;/p&gt;



&lt;p&gt;The partnership comes as AI adoption surges among students, with 86% of U.S. students using AI tools to support their studies, according to the companies. However, the rapid growth has sparked concerns about academic integrity and the need for AI tools designed specifically for educational use.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-advanced-verification-technology-stops-sophisticated-student-discount-fraud"&gt;How advanced verification technology stops sophisticated student discount fraud&lt;/h2&gt;



&lt;p&gt;SheerID, a Portland-based company founded in 2011, has built its business around solving a persistent problem for retailers and service providers: verifying that consumers actually belong to groups eligible for special discounts, such as students, military personnel, or healthcare workers.&lt;/p&gt;



&lt;p&gt;“We verify that customer audience data, and then we enrich that brand CRM with this first party data, so that they can fully engage their most loyal audiences,” explained Rebecca Grimes, Chief Revenue Officer at SheerID, in an exclusive interview with VentureBeat. “Our platform is built so that we can deliver this seamless, secure and fast experience for their consumers.”&lt;/p&gt;



&lt;p&gt;The verification process begins with basic information like name, date of birth, and university. SheerID immediately checks this against authoritative data sources, which Grimes said the company has built relationships with over 14 years in business. If instant verification fails, the system moves to document review using both AI-powered analysis and manual verification.&lt;/p&gt;



&lt;p&gt;“If we are unable to process that through our authoritative data sources, then there is an incremental step where you add a document upload,” Grimes said. “Once that goes into our system that is another layer of supplemental review that is both automated through our AI document review process as well as, in some cases, manual doc review.”&lt;/p&gt;



&lt;p&gt;The company can complete this secondary verification process in an average of 15 minutes globally, Grimes said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-identity-based-marketing-offers-deliver-337-roi-for-major-brands"&gt;Why identity-based marketing offers deliver 337% ROI for major brands&lt;/h2&gt;



&lt;p&gt;The partnership reflects the growing sophistication of fraud in student discount programs. Jesse Dwyer, head of communications at Perplexity, said the company’s focus on accuracy makes it particularly valuable for academic users who need trustworthy information.&lt;/p&gt;



&lt;p&gt;“For most AI model makers, a certain amount of hallucination is a feature, and for Perplexity, it’s a bug,” Dwyer said in an exclusive interview with VentureBeat. “That’s something that we found academics value, students value it, finance professionals value it enormously.”&lt;/p&gt;



&lt;p&gt;Unlike competitors that train AI models on user data, Dwyer said Perplexity doesn’t use customer information for training purposes. “We don’t train on your data,” he said. “The model doesn’t actually get trained on your data.”&lt;/p&gt;



&lt;p&gt;SheerID operates on a software-as-a-service model, charging for platform access, verification processing volume, and support services. The company, which has about 160 employees with offices in the U.S. and Europe, works with major brands including Amazon, Spotify, and T-Mobile.&lt;/p&gt;



&lt;p&gt;According to a study commissioned by SheerID from Forrester Consulting, customers using the company’s verification platform achieved a 337% return on investment through increased revenue, fraud prevention, and operational savings.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-perplexity-aims-to-beat-chatgpt-and-google-in-the-battle-for-student-users"&gt;How Perplexity aims to beat ChatGPT and Google in the battle for student users&lt;/h2&gt;



&lt;p&gt;AI companies increasingly target the education market. Perplexity differentiates itself from larger competitors like OpenAI’s ChatGPT and Google’s search tools by emphasizing accuracy and source attribution.&lt;/p&gt;



&lt;p&gt;“What we do with third party models is we do two forms of adaptations,” Dwyer explained. “We build our own in-house models that look at the query that you’re asking… We’re reformulating queries. So you ask a question one way, what AI is good at is it can ask that same question 1000 different ways.”&lt;/p&gt;



&lt;p&gt;This focus on accuracy addresses concerns among educators about AI tools that can generate plausible-sounding but incorrect information. Dwyer said Perplexity’s approach aligns with academic values around building knowledge through verified sources.&lt;/p&gt;



&lt;p&gt;“The peer review system was developed to create a sense of accuracy… so that future generations can build on that established knowledge,” he said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-real-cost-of-giving-away-millions-in-free-ai-services-to-students"&gt;The real cost of giving away millions in free AI services to students&lt;/h2&gt;



&lt;p&gt;The student access program is a major investment for Perplexity, though company executives declined to specify the cost. Dwyer noted that unlike traditional software, AI tools have direct computational costs for each query.&lt;/p&gt;



&lt;p&gt;“Every query has a direct cost in terms of compute,” Dwyer said. “That’s something that we’re mindful of, and we build our partnerships around.”&lt;/p&gt;



&lt;p&gt;However, the company sees strategic value in building relationships with academic users. Unlike many tech companies that monetize through advertising, Dwyer said ads represent “less than a half of a percent of our revenue” and the company doesn’t sell user data.&lt;/p&gt;



&lt;p&gt;The partnership provides SheerID with exposure to the rapidly growing AI market. Grimes compared the current moment to the early days of music streaming, when SheerID began working with Spotify and other services.&lt;/p&gt;



&lt;p&gt;“I think that we’re going to see similar global programs in the AI industry, beyond just engaging with students that will be needed, needing services like SheerID to support their success,” she said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-student-data-stays-protected-in-an-era-of-ai-privacy-concerns"&gt;How student data stays protected in an era of AI privacy concerns&lt;/h2&gt;



&lt;p&gt;Both companies emphasized their approach to data privacy, particularly important given recent concerns about AI companies’ use of personal information. SheerID operates as a data processor rather than controller, meaning customer data belongs to the brand partner rather than SheerID.&lt;/p&gt;



&lt;p&gt;“We’re processors, so we’re not a controller, so we are just processing that data on behalf of that brand,” Grimes explained. “We don’t take control of the ownership of that consumer data.”&lt;/p&gt;



&lt;p&gt;The verification system looks at additional signals beyond documents to prevent fraud, including IP address location and proximity to claimed universities. This “triangulation of all of these processes and data” allows SheerID to “confidently confirm eligibility or ineligibility against an offer,” Grimes said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-this-partnership-signals-for-the-future-of-ai-in-education"&gt;What this partnership signals for the future of AI in education&lt;/h2&gt;



&lt;p&gt;The partnership reflects broader trends in both the AI and identity verification industries. SheerID has expanded rapidly in recent years, launching new products for in-store verification and income-based eligibility checking. The company appointed former Ruby CEO Stephanie Copeland Weber as CEO in June 2024, as founder Jake Weatherly transitioned to a board role.&lt;/p&gt;



&lt;p&gt;For Perplexity, founded in 2022, the education market represents a natural fit for its research-focused AI tools. The company processes more than 150 million questions weekly globally and has positioned itself as an “answer engine” that provides sourced information rather than generating creative content.&lt;/p&gt;



&lt;p&gt;The partnership comes amid broader scrutiny of AI’s role in education, with institutions grappling with questions of academic integrity and the appropriate use of AI tools. By requiring verification and emphasizing accuracy, both companies aim to address these concerns while expanding access to AI capabilities.&lt;/p&gt;



&lt;p&gt;“We would encourage educators and universities or researchers of any kind to reach out and try perplexity,” Dwyer said. “We’re one of the few leading tech companies that’s founded not just by a PhD student, which is fairly common, we’re founded by one who actually finished his PhD.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/perplexity-offers-free-ai-tools-to-students-worldwide-in-partnership-with-sheerid/</guid><pubDate>Tue, 15 Jul 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Deadline Extended — Create a Project G-Assist Plug-In for a Chance to Win an NVIDIA GeForce RTX GPU and Laptop (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/rtx-ai-garage-g-assist-hackathon-plug-in-last-chance/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/g-assist-hackathon-nv-blog-1280x680-1.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Submissions for NVIDIA’s Plug and Play: Project G-Assist Plug-In Hackathon are due Sunday, July 20, at 11:59pm PT. RTX AI Garage offers all the tools and resources to help.&lt;/p&gt;
&lt;p&gt;The hackathon invites the community to expand the capabilities of Project G-Assist, an experimental AI assistant available through the NVIDIA App that helps users control and optimize NVIDIA GeForce RTX systems.&lt;/p&gt;
&lt;p&gt;Entrants gain the chance to win a GeForce RTX 5090 laptop, or a limited NVIDIA GeForce RTX 5080 or RTX 5070 Founders Edition graphics card, plus NVIDIA Deep Learning Institute credits. Finalists may also be featured on NVIDIA’s social media channels.&lt;/p&gt;
&lt;p&gt;Register for the hackathon and check out the curated technical resources below to bring these submissions to life.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;(G-)Assist With AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;When in the heat of a gaming moment or the flow of a creative project, interrupting one’s focus to navigate complex PC settings menus is a common frustration. For example, manually tweaking GPU performance or optimizing system parameters often requires leaving the user’s current application, which breaks concentration.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Enter Project G-Assist, which allows users to control their RTX GPU and other system settings using natural language. It’s powered by a small language model that runs on device and can be accessed directly from the NVIDIA overlay within the NVIDIA App — no need to tab out or switch programs.&lt;/p&gt;
&lt;p&gt;Users can also expand its capabilities via plug-ins and even connect it to agentic frameworks such as Langflow. G-Assist plug-ins can be built in several ways, including with Python for rapid development, with C++ for performance-critical apps and with custom system interactions for hardware and operating system automation.&lt;/p&gt;
&lt;p&gt;Project G-Assist requires a GeForce RTX 50, 40 or 30 Series Desktop GPU with at least 12GB of VRAM, a Windows 11 or 10 operating system, a compatible CPU (Intel Pentium G Series, Core i3, i5, i7 or higher; AMD FX, Ryzen 3, 5, 7, 9, Threadripper or higher), specific disk space requirements and a recent GeForce Game Ready Driver or NVIDIA Studio Driver.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Cross the Finish Line&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;As the hackathon’s submission deadline approaches this weekend, RTX AI Garage is providing resources that can help:&lt;/p&gt;
&lt;p&gt;Sydney Altobell, a senior software engineer at NVIDIA, offers tips and tricks for working with G-Assist plug-ins in this on-demand webinar. The presentation and Q&amp;amp;A are available on the NVIDIA Developer YouTube channel and embedded below.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Fellow community developers are collaborating and sharing notes in the NVIDIA Developer Discord server. Altobell and the G-Assist engineering team have already answered many questions about plug-in submissions — keep the questions coming.&lt;/p&gt;
&lt;p&gt;Plus, explore NVIDIA’s GitHub repository, which provides everything needed to get started developing with G-Assist, including step-by-step instructions and documentation for building custom functionalities. Take inspiration from sample plug-ins, which include code for using G-Assist to integrate into Discord, IFTTT, Google Gemini and more.&lt;/p&gt;
&lt;p&gt;Learn more about the ChatGPT Plug-In Builder to transform ideas into functional G-Assist plug-ins with minimal coding. The tool uses OpenAI’s custom GPT builder to generate plug-in code and streamline the development process.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;NVIDIA’s technical blog walks through the architecture of a G-Assist plug-in, using a Twitch integration as an example. Discover how plug-ins work, how they communicate with G-Assist and how to build them from scratch.&lt;/p&gt;
&lt;p&gt;Find submission details and requirements on the Hackathon entry page.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Each week, the &lt;/i&gt;&lt;i&gt;RTX AI Garage&lt;/i&gt; &lt;i&gt;blog series features community-driven AI innovations and content for those looking to learn more about NVIDIA NIM microservices and AI Blueprints, as well as building &lt;/i&gt;&lt;i&gt;AI agents&lt;/i&gt;&lt;i&gt;, creative workflows, productivity apps and more on AI PCs and workstations.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Plug in to NVIDIA AI PC on &lt;/i&gt;&lt;i&gt;Facebook&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;TikTok&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt; — and stay informed by subscribing to the &lt;/i&gt;&lt;i&gt;RTX AI PC newsletter&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Follow NVIDIA Workstation on &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/g-assist-hackathon-nv-blog-1280x680-1.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Submissions for NVIDIA’s Plug and Play: Project G-Assist Plug-In Hackathon are due Sunday, July 20, at 11:59pm PT. RTX AI Garage offers all the tools and resources to help.&lt;/p&gt;
&lt;p&gt;The hackathon invites the community to expand the capabilities of Project G-Assist, an experimental AI assistant available through the NVIDIA App that helps users control and optimize NVIDIA GeForce RTX systems.&lt;/p&gt;
&lt;p&gt;Entrants gain the chance to win a GeForce RTX 5090 laptop, or a limited NVIDIA GeForce RTX 5080 or RTX 5070 Founders Edition graphics card, plus NVIDIA Deep Learning Institute credits. Finalists may also be featured on NVIDIA’s social media channels.&lt;/p&gt;
&lt;p&gt;Register for the hackathon and check out the curated technical resources below to bring these submissions to life.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;(G-)Assist With AI&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;When in the heat of a gaming moment or the flow of a creative project, interrupting one’s focus to navigate complex PC settings menus is a common frustration. For example, manually tweaking GPU performance or optimizing system parameters often requires leaving the user’s current application, which breaks concentration.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Enter Project G-Assist, which allows users to control their RTX GPU and other system settings using natural language. It’s powered by a small language model that runs on device and can be accessed directly from the NVIDIA overlay within the NVIDIA App — no need to tab out or switch programs.&lt;/p&gt;
&lt;p&gt;Users can also expand its capabilities via plug-ins and even connect it to agentic frameworks such as Langflow. G-Assist plug-ins can be built in several ways, including with Python for rapid development, with C++ for performance-critical apps and with custom system interactions for hardware and operating system automation.&lt;/p&gt;
&lt;p&gt;Project G-Assist requires a GeForce RTX 50, 40 or 30 Series Desktop GPU with at least 12GB of VRAM, a Windows 11 or 10 operating system, a compatible CPU (Intel Pentium G Series, Core i3, i5, i7 or higher; AMD FX, Ryzen 3, 5, 7, 9, Threadripper or higher), specific disk space requirements and a recent GeForce Game Ready Driver or NVIDIA Studio Driver.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Cross the Finish Line&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;As the hackathon’s submission deadline approaches this weekend, RTX AI Garage is providing resources that can help:&lt;/p&gt;
&lt;p&gt;Sydney Altobell, a senior software engineer at NVIDIA, offers tips and tricks for working with G-Assist plug-ins in this on-demand webinar. The presentation and Q&amp;amp;A are available on the NVIDIA Developer YouTube channel and embedded below.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Fellow community developers are collaborating and sharing notes in the NVIDIA Developer Discord server. Altobell and the G-Assist engineering team have already answered many questions about plug-in submissions — keep the questions coming.&lt;/p&gt;
&lt;p&gt;Plus, explore NVIDIA’s GitHub repository, which provides everything needed to get started developing with G-Assist, including step-by-step instructions and documentation for building custom functionalities. Take inspiration from sample plug-ins, which include code for using G-Assist to integrate into Discord, IFTTT, Google Gemini and more.&lt;/p&gt;
&lt;p&gt;Learn more about the ChatGPT Plug-In Builder to transform ideas into functional G-Assist plug-ins with minimal coding. The tool uses OpenAI’s custom GPT builder to generate plug-in code and streamline the development process.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;NVIDIA’s technical blog walks through the architecture of a G-Assist plug-in, using a Twitch integration as an example. Discover how plug-ins work, how they communicate with G-Assist and how to build them from scratch.&lt;/p&gt;
&lt;p&gt;Find submission details and requirements on the Hackathon entry page.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Each week, the &lt;/i&gt;&lt;i&gt;RTX AI Garage&lt;/i&gt; &lt;i&gt;blog series features community-driven AI innovations and content for those looking to learn more about NVIDIA NIM microservices and AI Blueprints, as well as building &lt;/i&gt;&lt;i&gt;AI agents&lt;/i&gt;&lt;i&gt;, creative workflows, productivity apps and more on AI PCs and workstations.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Plug in to NVIDIA AI PC on &lt;/i&gt;&lt;i&gt;Facebook&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;TikTok&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt; — and stay informed by subscribing to the &lt;/i&gt;&lt;i&gt;RTX AI PC newsletter&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Follow NVIDIA Workstation on &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/rtx-ai-garage-g-assist-hackathon-plug-in-last-chance/</guid><pubDate>Tue, 15 Jul 2025 13:00:42 +0000</pubDate></item><item><title>[NEW] xAI says it has fixed Grok 4’s problematic responses (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/15/xai-says-it-has-fixed-grok-4s-problematic-responses/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When xAI launched Grok 4 last week, the company claimed the large language model outperformed several competitors on different benchmarks. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the Grok account on X that runs off the model immediately showed there were some major issues: it started saying its surname was “Hitler”, tweeted antisemitic messages, and seemed to reference Elon Musk’s posts when asked about controversial topics, siding with the xAI owner’s views as a result. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;xAI soon afterwards apologized for Grok’s behavior. On Tuesday, the company said it has now addressed both issues. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We spotted a couple of issues with Grok 4 recently that we immediately investigated &amp;amp; mitigated.&lt;/p&gt;&lt;p&gt;One was that if you ask it "What is your surname?" it doesn't have one so it searches the internet leading to undesirable results, such as when its searches picked up a viral meme…&lt;/p&gt;— xAI (@xai) July 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Explaining what went wrong, xAI says when asked what its surname was, Grok searched the web and picked up on “a viral meme where it called itself ‘MechaHitler.’” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for why Grok was consulting Musk’s posts when asked about controversial topics, the company wrote, “The model reasons that as an AI it doesn’t have an opinion but knowing it was Grok 4 by xAI, searches to see what xAI or Elon Musk might have said on a topic to align itself with the company.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company seems to have updated the model’s system prompts to remove prompts allowing the chatbot to be politically incorrect and having a “fantastic” dry sense of humor. There are also a few new lines, telling the model that it should provide analysis of controversial topics using various diverse sources. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the query requires analysis of current events, subjective claims, or statistics, conduct a deep analysis, finding diverse sources representing all parties. Assume subjective viewpoints sourced from the media are biased. No need to repeat this to the user,” the updated system prompt reads.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The updated system prompt specifically mentions that Grok shouldn’t rely on input from past versions, Musk or xAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Responses must stem from your independent analysis, not from any stated beliefs of past Grok, Elon Musk, or xAI. If asked about such preferences, provide your own reasoned perspective,” it says.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When xAI launched Grok 4 last week, the company claimed the large language model outperformed several competitors on different benchmarks. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the Grok account on X that runs off the model immediately showed there were some major issues: it started saying its surname was “Hitler”, tweeted antisemitic messages, and seemed to reference Elon Musk’s posts when asked about controversial topics, siding with the xAI owner’s views as a result. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;xAI soon afterwards apologized for Grok’s behavior. On Tuesday, the company said it has now addressed both issues. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We spotted a couple of issues with Grok 4 recently that we immediately investigated &amp;amp; mitigated.&lt;/p&gt;&lt;p&gt;One was that if you ask it "What is your surname?" it doesn't have one so it searches the internet leading to undesirable results, such as when its searches picked up a viral meme…&lt;/p&gt;— xAI (@xai) July 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Explaining what went wrong, xAI says when asked what its surname was, Grok searched the web and picked up on “a viral meme where it called itself ‘MechaHitler.’” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for why Grok was consulting Musk’s posts when asked about controversial topics, the company wrote, “The model reasons that as an AI it doesn’t have an opinion but knowing it was Grok 4 by xAI, searches to see what xAI or Elon Musk might have said on a topic to align itself with the company.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company seems to have updated the model’s system prompts to remove prompts allowing the chatbot to be politically incorrect and having a “fantastic” dry sense of humor. There are also a few new lines, telling the model that it should provide analysis of controversial topics using various diverse sources. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the query requires analysis of current events, subjective claims, or statistics, conduct a deep analysis, finding diverse sources representing all parties. Assume subjective viewpoints sourced from the media are biased. No need to repeat this to the user,” the updated system prompt reads.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The updated system prompt specifically mentions that Grok shouldn’t rely on input from past versions, Musk or xAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Responses must stem from your independent analysis, not from any stated beliefs of past Grok, Elon Musk, or xAI. If asked about such preferences, provide your own reasoned perspective,” it says.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/15/xai-says-it-has-fixed-grok-4s-problematic-responses/</guid><pubDate>Tue, 15 Jul 2025 13:12:21 +0000</pubDate></item><item><title>[NEW] ParadeDB takes on Elasticsearch as interest in Postgres explodes amid AI boom (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/15/paradedb-takes-on-elasticsearch-as-interest-in-postgres-explodes-amid-ai-boom/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/FINAL-071020251.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Open source database management system Postgres is nearly 40 years old, but has recently started seeing explosive demand due to being very well-suited for AI applications. Despite this rise in popularity, search and analytics functionality remain limited. ParadeDB is changing that. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ParadeDB is an open source Postgres extension that facilitates full-text search and analytics directly in Postgres without users needing to transfer data to a separate source. The platform integrates with other data infrastructure tools, including Google Cloud SQL, Azure Postgres, and Amazon RDS, among others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Philippe Noël, the co-founder and CEO of ParadeDB, told TechCrunch that he and his co-founder, Ming Ying, CTO, got the idea for the company by running into their own Postgres search woes while running their first startup, cloud-hybrid browser Whist.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Postgres is becoming the default database of the world, and you still can’t do good search over that information, believe it or not,” Noël said. “There’s just a lot of pain points. So we decided to go and start a company to do that after talking to more people and realizing this was a very shared problem.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ParadeDB isn’t the first company to try to solve Postgres search. Open source Elasticsearch is the most notable legacy player in the space since it was founded in 2012. Noël said that Elasticsearch works by moving data back and forth between itself and Postgres, which can work, but this system isn’t great for heavy workloads or processes that require frequent updating.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That breaks all the time,” Noël said. “The two databases are not meant to work together. There’s a lot of compatibility issues, there’s a lot of latency issues, higher costs, and all of that deteriorates the user experience.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ParadeDB claims to eliminate a lot of those challenges by building as an extension on top of Postgres directly, no data transfer required.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The startup was founded in 2023 and released the first open source version of the product later that year. Noël said that the group wanted to focus first on building out the open source product before it thought about sales or marketing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That was short-lived. In early 2024, Chinese e-commerce giant Alibaba reached out and became ParadeDB’s first customer in May 2024. From there, the company turned toward building out its enterprise version of the software. Now it works with enterprises, including Modern Treasury, Bilt Rewards, and TCDI, among others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ParadeDB just raised a $12 million Series A round led by Craft Ventures with participation from existing investors, including Y Combinator.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company will use the funds for hiring. ParadeDB is currently a team of four and is looking to grow to at least 10 employees. Some of the funds will also go to continue to improve the platform’s user interface and analytics capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Noël said the company wasn’t looking to raise capital, but when Craft reached out to ParadeDB after being recommended to them by Supabase, the Postgres developer platform that has raised nearly $400 million of venture capital, they thought the timing made sense.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s clear people are recognizing that Postgres matters a lot, and they want to get behind it,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Postgres’ popularity is clearly on the rise if recent M&amp;amp;A is any indicator. The recent acquisitions of Crunchy Data by Snowflake and Neon by Databricks were both ploys for the acquirers to gain more Postgres offerings, Devin Pratt, a research director at IDC, told TechCrunch last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It is widely used across the industry, and I would say that was one of the main targets for their acquisitions,” Pratt told TechCrunch at the time. “The different strengths of Neon versus Crunchy [Data] were definitely debated between both companies and what would suit their companies best, but Postgres was their first goal in those acquisitions.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ParadeDB hopes it can ride this wave of interest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think building on Postgres is actually a meaningful shift, right?” Noël said. “Because that’s where the data is, and you can make a meaningful dent in Elasticsearch’s market share by meeting users where their data is, rather than building something that’s marginally faster or marginally cheaper.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/FINAL-071020251.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Open source database management system Postgres is nearly 40 years old, but has recently started seeing explosive demand due to being very well-suited for AI applications. Despite this rise in popularity, search and analytics functionality remain limited. ParadeDB is changing that. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ParadeDB is an open source Postgres extension that facilitates full-text search and analytics directly in Postgres without users needing to transfer data to a separate source. The platform integrates with other data infrastructure tools, including Google Cloud SQL, Azure Postgres, and Amazon RDS, among others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Philippe Noël, the co-founder and CEO of ParadeDB, told TechCrunch that he and his co-founder, Ming Ying, CTO, got the idea for the company by running into their own Postgres search woes while running their first startup, cloud-hybrid browser Whist.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Postgres is becoming the default database of the world, and you still can’t do good search over that information, believe it or not,” Noël said. “There’s just a lot of pain points. So we decided to go and start a company to do that after talking to more people and realizing this was a very shared problem.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ParadeDB isn’t the first company to try to solve Postgres search. Open source Elasticsearch is the most notable legacy player in the space since it was founded in 2012. Noël said that Elasticsearch works by moving data back and forth between itself and Postgres, which can work, but this system isn’t great for heavy workloads or processes that require frequent updating.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That breaks all the time,” Noël said. “The two databases are not meant to work together. There’s a lot of compatibility issues, there’s a lot of latency issues, higher costs, and all of that deteriorates the user experience.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ParadeDB claims to eliminate a lot of those challenges by building as an extension on top of Postgres directly, no data transfer required.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The startup was founded in 2023 and released the first open source version of the product later that year. Noël said that the group wanted to focus first on building out the open source product before it thought about sales or marketing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That was short-lived. In early 2024, Chinese e-commerce giant Alibaba reached out and became ParadeDB’s first customer in May 2024. From there, the company turned toward building out its enterprise version of the software. Now it works with enterprises, including Modern Treasury, Bilt Rewards, and TCDI, among others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ParadeDB just raised a $12 million Series A round led by Craft Ventures with participation from existing investors, including Y Combinator.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company will use the funds for hiring. ParadeDB is currently a team of four and is looking to grow to at least 10 employees. Some of the funds will also go to continue to improve the platform’s user interface and analytics capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Noël said the company wasn’t looking to raise capital, but when Craft reached out to ParadeDB after being recommended to them by Supabase, the Postgres developer platform that has raised nearly $400 million of venture capital, they thought the timing made sense.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s clear people are recognizing that Postgres matters a lot, and they want to get behind it,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Postgres’ popularity is clearly on the rise if recent M&amp;amp;A is any indicator. The recent acquisitions of Crunchy Data by Snowflake and Neon by Databricks were both ploys for the acquirers to gain more Postgres offerings, Devin Pratt, a research director at IDC, told TechCrunch last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It is widely used across the industry, and I would say that was one of the main targets for their acquisitions,” Pratt told TechCrunch at the time. “The different strengths of Neon versus Crunchy [Data] were definitely debated between both companies and what would suit their companies best, but Postgres was their first goal in those acquisitions.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ParadeDB hopes it can ride this wave of interest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think building on Postgres is actually a meaningful shift, right?” Noël said. “Because that’s where the data is, and you can make a meaningful dent in Elasticsearch’s market share by meeting users where their data is, rather than building something that’s marginally faster or marginally cheaper.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/15/paradedb-takes-on-elasticsearch-as-interest-in-postgres-explodes-amid-ai-boom/</guid><pubDate>Tue, 15 Jul 2025 13:24:51 +0000</pubDate></item><item><title>[NEW] Building community and clean air solutions (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/15/1117644/building-community-and-clean-air-solutions/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/05/Darren-Riley.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Michigan Economic Development Corporation&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When Darren Riley moved to Detroit seven years ago, he didn’t expect the city’s air to change his life—literally. Developing asthma as an adult opened his eyes to a much larger problem: the invisible but pervasive impact of air pollution on the health of marginalized communities.&lt;/p&gt;    &lt;p&gt;“I was fascinated about why we don’t have the data we need,” Riley recalls, “or why we don’t have the infrastructure to solve these issues, to understand where pollution is coming from, how it’s impacting our communities, so that we can solve these problems and make an equitable breathing environment for everybody.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;That personal reckoning sparked the idea for JustAir, a Michigan-based clean-tech startup building neighborhood-level air quality monitoring tools. The goal is simple but urgent: provide communities with access to hyper-local data so they can better manage pollution and protect public health. As Riley puts it, “JustAir is solving the problem of how to better manage local pollution so that we can make sure our communities, our lifestyles—where we work, where we play, and where we learn—are really protected.”&lt;/p&gt;  &lt;p&gt;Founded during the height of the pandemic, when the connection between health disparities and air quality became impossible to ignore, JustAir now partners with local governments, health departments, and community residents to deploy monitoring networks that offer key data relevant to everything from policy to personal decision-making.&lt;/p&gt; 
 &lt;p&gt;From the start, the Michigan Economic Development Corporation (MEDC) offered key support that helped turn JustAir’s bold vision into technical infrastructure. Through the MEDC’s early-stage funding partners and a network of mentorship and resources known as SmartZones, JustAir sharpened its product-market fit and gained critical momentum.&lt;/p&gt;  &lt;p&gt;Success for Riley isn’t just about scale, it’s about impact. “It warms my heart, and it shows that we're doing exactly what we said we wanted to do,” Riley says, “which is to make sure that communities have the data that they deserve to create the future, the clean, healthy future that they desperately need.”&lt;/p&gt; 
 &lt;p&gt;To other burgeoning entrepreneurs, Riley sees a sense of community as key to lasting and impactful change. “When people are celebrating you with your head up, and then when people are helping you put your chin up when your head's down, I think it's so, so critical. I found that here in Michigan, and also found it here in our community, right here in Detroit. Passion and finding a community that's going to help get you through the journey is all it takes.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This episode of Business Lab is produced in association with the Michigan Economic Development Corporation.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Full Transcript&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan Tatum:&lt;/em&gt; From MIT Technology Review, I'm Megan Tatum, and this is Business Lab, the show that helps business leaders make sense of new technologies coming out of the lab and into the marketplace.&lt;/p&gt;&lt;p&gt;Today's episode is brought to you in partnership with the Michigan Economic Development Corporation.&lt;/p&gt;&lt;p&gt;Our topic today is building a technology startup in the U.S. state of Michigan. Taking an innovative idea to a full-fledged product and company requires resources that individuals might not have. That's why the Michigan Economic Development Corporation, the MEDC, has launched an innovation campaign to support technology entrepreneurs.&lt;/p&gt;&lt;p&gt;Two words for you: startup ecosystem.&lt;/p&gt;&lt;p&gt;My guest is Darren Riley, the co-founder and CEO at JustAir, a clean air startup that began its journey in Michigan.&lt;/p&gt;&lt;p&gt;Welcome, Darren.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;Darren Riley:&lt;/em&gt; Hi. Thanks for having me.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Thank you ever so much for being with us. To get us started, let's just talk a bit about JustAir. How did the idea for the company come about, and what does your company do as well?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; Yeah, absolutely. The real thesis of JustAir, is really a combination of one, my personal experience but also my professional experience. On the professional side, background in software engineering, graduated from Carnegie Mellon University, but I was always fascinated by how to use technology to really support and innovate and really push the frontier on issues that are near and dear to my heart. Coming from Houston, Texas, coming from communities that often are restricted with certain issues, systemic issues, is something that I always carried in my heart.&lt;/p&gt;  &lt;p&gt;And on the personal side, it was around seven years ago when I moved to Detroit, in Southwest Detroit, where I developed asthma. Not growing up with asthma and not developing any issues, having that disease of the lungs really opened my eyes to just how much our environment impacts our health and well-being.&lt;/p&gt;&lt;p&gt;The combination of those, that pain point and also my background in technology, I was fascinated about why we don’t have the data we need or why we don’t have the infrastructure to solve these issues, to understand where pollution is coming from, how it’s impacting our communities, so that we can solve these problems and make an equitable breathing environment for everybody. That's kind of what birthed JustAir in a way.&lt;/p&gt;&lt;p&gt;And actually, it was around COVID-19 where we really started to push forward, where we saw all this information and research around health disparities and a lot of the issues of mortality rates around COVID-19, which kind of coincides with COPD, asthma, and other diseases that are often overburdened in communities that look like ours, in Black and brown communities. That's kind of where we got our start.&lt;/p&gt;&lt;p&gt;And what is JustAir today? JustAir is solving the problem of how to better manage local pollution so that we can make sure our communities, our lifestyles—where we work, where we play, and where we learn—are really protected. And, so, what JustAir does is build hyper-local neighborhood-level air quality monitoring networks. Communities have access to the data, policymakers and decision-makers can use that data to really influence and push things to help protect the community, but also other stakeholders can use the data to move the environment to a healthier state. So that's where we are, and we're four years strong, and I'm really excited to be a part of this journey here in Michigan.&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; So you launched about four years ago now. Why did you choose to build and grow just there in Michigan?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; Yeah, I think a combination of things, the reason why I chose to start here and be intentional about building our team here. I think first is really around the ecosystem support around Michigan. So the MEDC has a network of what we call SmartZones that really offer funding, resources, mentorship, advisory on the different challenges that can range from capital, legal, and other issues that kind of hold an entrepreneur from just getting out there and putting their product in the market. First and foremost, I’m super thankful and grateful for just the state really focusing on and putting entrepreneurs first in that regard.&lt;/p&gt;  &lt;p&gt;I think secondly is community. I really felt a strong sense of community here in Detroit. One of the founding members of an organization called Black Tech Saturdays, which sees over hundreds, 500-1,000 folks almost every Saturday of the month, just really sharing and really engaging with tech-curious folks from all different walks of life, but making intentional space for folks who are often left out of those rooms and out of those conversations. And just really seeing a peer network of entrepreneurs who come from a similar cultural background or a similar situation, really going after it together and helping each other navigate some issues.&lt;/p&gt;  &lt;p&gt;And then lastly, I talk about this a lot, but problem-solution fit. Being here in Detroit where I developed asthma, where we have many issues and many around the environment that have hit some communities the hardest, right here in Detroit in my own backyard I really want to be very narrowly focused and make sure that I'm building something that actually solves the problem that got me on this journey in the first place. Not thinking about regional-wide, different country, international, et cetera, but how do we build something right here in the backyard that solves the problem for my neighbors and makes sure that we can make a real difference in the community. So, from the community to the problem that I really care about and make sure we solve, and then also just the ecosystem support is why we're here in Michigan and why we plan to really grow and really be a part of this movement.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Fantastic. And you've touched on a few of those already, but as you were getting started, what specific resources, partnerships, or community support helped you navigate the early-stage research and development stages?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; One example, really early, actually, I forgot about this for a while, but we have a Business Accelerator Fund here in Michigan where there's funding offered to entrepreneurs for technical assistance. I used that to operationalize some of our technical roadmap processes to build out the infrastructure that we really intended to do. So, that real funding that was non-dilutive that the state provided helped accelerate some of those issues in the early days, where it was just myself and advisors going after this problem. And so now, where we are today, there are funds that receive funding from MEDC, so local funds and venture capital that help you get your first check. Those are really helpful as well. All that to say is basically a combination of funding primary source, but also strategically, that funding is going towards product positioning and product-market fit. Those were some of the two core examples that have been beneficial.&lt;/p&gt;  &lt;p&gt;And then, I think the last thing I'll mention as well, MEDC and a lot of the SmartZones within the state, these SmartZones are just bucketed in different regions and areas, so you have Ann Arbor, you've got Detroit, you have Grand Rapids, the whole nine yards, having these events and creating these clusters, if you will, of density of entrepreneurs, I think is super, super critical. I've experienced in New York, Chicago, and San Francisco, and other bigger ecosystems that density is so critical to where you're constantly rubbing shoulders with the next entrepreneur, the next investor, the next customer, to really kind of accelerate that velocity of your journey.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah. Having that ecosystem makes such a difference, doesn't it?&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; Oh yeah, absolutely.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; And tech acumen and business acumen are very different sets of skills. I wonder what was the process like developing out your technology whilst also building out a viable business plan?&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Darren&lt;/em&gt;: I think I have a real unique opportunity. Having a software background, I code all the time, felt I had a lot of ideas, always joked that I had a Google Drive of 30 ideas that never worked, that I never showed anybody. I really felt I had that piece. What I was missing in my journey and why nothing ever came to fruition was just the simple principles of, are you solving a real problem, a real pain point for a customer?&lt;/p&gt;&lt;p&gt;Two things on the business acumen side are having an affinity for the problem. I truly believe that going on the entrepreneurial journey is lonely, it’s risky, it's stressful, and tiring. The more I can wake up in the morning and think about [how] the problems that we solve could actually result in a breath of clean air for someone who may not have that awareness or have the tools to advocate on their behalf, just having that extra motivation and having that affinity towards a problem that I feel really deeply, I think does help.&lt;/p&gt;&lt;p&gt;But I think also from the business acumen side of things, I had the opportunity to work at an organization called Endeavor based here in Michigan, where I was on the other side of an entrepreneur resource support organization. I got to see founders from high-growth companies throughout Michigan, series A, series B, retail, fintech, the whole nine yards, health tech, and seeing where are the challenges, where are things going well and where things are going wrong, from co-founder struggles to missing the market timing or going through banking issues from a couple years ago and all that stuff. All those things really help build a muscle memory of, I don't have all the answers, but being able to pull through those experiences and pattern matching does help as well, from how you actually build a business from zero, from product-market fit to scale and grow.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah, absolutely. And as you say, it can be a stressful journey, life as an entrepreneur, but I wonder if you could also share some highlights from your journey so far, any partnerships or projects that you're really excited about at the moment?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; I think the first and foremost highlight [that] I didn't realize I would come to enjoy so much is certainly my team. Being able to work with people who are aligned in passionate values and just kind of the culture and the focus is immensely valuable. If I'm going to spend this many hours in a week or in a year, I'd love to spend it with folks who are really passionate about it. I want to see them succeed. So I think first and foremost, I think the biggest success is really just the fortunate opportunity to work with people I really enjoy working with.&lt;/p&gt;&lt;p&gt;The others I'll mention [are] we have one of the largest county-owned monitoring networks in the country within Wayne County. The Health Department of Wayne County and Executive Warren Evans established this partnership where we deployed 100 fixed monitors throughout Wayne County to understand the patterns of local pollution to where we can help combat some of these issues where we are ranked F in air quality from the Lung Association, or Detroit is the third-worst from Asthma and Allergy Foundation of America, the third-worst place to live in with asthma. So, how do we really look at this data and tell the story, and how can we really mitigate solutions, while also giving data to the public so that they can navigate the world that's happening to them. That's one of our critical partnerships.&lt;/p&gt;&lt;p&gt;We're also very excited, we just got announced in Fast Company as one of the most innovative companies of 2025, so woo-hoo to that.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Congratulations.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; It is really exciting, yeah, in the social impact, social good category. There are many, many more, but I think the last one, I'm so, so grateful for, and I tell our team this all the time, is that we've already succeeded. Going to community meetings, hearing people raise their hand, asking questions about the adjuster application or about their data, and I to emphasize that when you hear community members saying ‘our data’ and not an ask, but as something that they have obtained, it warms my heart, and it shows that we're doing exactly what we said we wanted to do, which is to make sure that communities have the data that they deserve to create the future, the clean, healthy future that they desperately need.”.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah, absolutely, what an incredible achievement. And what advice, finally, would you offer to other burgeoning entrepreneurs?&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Darren: &lt;/em&gt;Yeah, I think really something you are passionate about. Repeat that point again, do something that you feel that you can really go through those pain points and struggles for, [because] you need some extra kick to get you through and navigate these challenges.&lt;/p&gt;&lt;p&gt;The second thing, and the most important thing that a lot of people take away is community, community, community. I wouldn't be here today if I didn't have people to call on when I'm at my lowest points, and call on people in my highest points. When people are celebrating you with your head up, and then when people are helping you put your chin up when your head's down, I think it's so, so critical. I found that here in Michigan, and also found it here in our community, right here in Detroit. Passion and finding a community that's going to help get you through the journey is all it takes.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Fantastic. All great advice. Thank you ever so much, Darren.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; Absolutely.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; That was Darren Riley, the co-founder and CEO at JustAir whom I spoke with from Brighton, England.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;That's it for this episode of Business Lab. I'm your host, Megan Tatum. I'm a contributing editor and host for Insights, the custom publishing division of MIT Technology Review. We were founded in 1899 at the Massachusetts Institute of Technology, and you can find us in print on the web and at events each year around the world. For more information about us on the show, please check out our website at technologyreview.com.&lt;/p&gt;&lt;p&gt;This show is available wherever you get your podcasts. And if you enjoyed this episode, we hope you'll take a moment to rate and review us. Business Lab is a production of MIT Technology Review. This episode was produced by Giro Studios. Thanks for listening.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/05/Darren-Riley.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Michigan Economic Development Corporation&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;When Darren Riley moved to Detroit seven years ago, he didn’t expect the city’s air to change his life—literally. Developing asthma as an adult opened his eyes to a much larger problem: the invisible but pervasive impact of air pollution on the health of marginalized communities.&lt;/p&gt;    &lt;p&gt;“I was fascinated about why we don’t have the data we need,” Riley recalls, “or why we don’t have the infrastructure to solve these issues, to understand where pollution is coming from, how it’s impacting our communities, so that we can solve these problems and make an equitable breathing environment for everybody.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;That personal reckoning sparked the idea for JustAir, a Michigan-based clean-tech startup building neighborhood-level air quality monitoring tools. The goal is simple but urgent: provide communities with access to hyper-local data so they can better manage pollution and protect public health. As Riley puts it, “JustAir is solving the problem of how to better manage local pollution so that we can make sure our communities, our lifestyles—where we work, where we play, and where we learn—are really protected.”&lt;/p&gt;  &lt;p&gt;Founded during the height of the pandemic, when the connection between health disparities and air quality became impossible to ignore, JustAir now partners with local governments, health departments, and community residents to deploy monitoring networks that offer key data relevant to everything from policy to personal decision-making.&lt;/p&gt; 
 &lt;p&gt;From the start, the Michigan Economic Development Corporation (MEDC) offered key support that helped turn JustAir’s bold vision into technical infrastructure. Through the MEDC’s early-stage funding partners and a network of mentorship and resources known as SmartZones, JustAir sharpened its product-market fit and gained critical momentum.&lt;/p&gt;  &lt;p&gt;Success for Riley isn’t just about scale, it’s about impact. “It warms my heart, and it shows that we're doing exactly what we said we wanted to do,” Riley says, “which is to make sure that communities have the data that they deserve to create the future, the clean, healthy future that they desperately need.”&lt;/p&gt; 
 &lt;p&gt;To other burgeoning entrepreneurs, Riley sees a sense of community as key to lasting and impactful change. “When people are celebrating you with your head up, and then when people are helping you put your chin up when your head's down, I think it's so, so critical. I found that here in Michigan, and also found it here in our community, right here in Detroit. Passion and finding a community that's going to help get you through the journey is all it takes.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This episode of Business Lab is produced in association with the Michigan Economic Development Corporation.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Full Transcript&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan Tatum:&lt;/em&gt; From MIT Technology Review, I'm Megan Tatum, and this is Business Lab, the show that helps business leaders make sense of new technologies coming out of the lab and into the marketplace.&lt;/p&gt;&lt;p&gt;Today's episode is brought to you in partnership with the Michigan Economic Development Corporation.&lt;/p&gt;&lt;p&gt;Our topic today is building a technology startup in the U.S. state of Michigan. Taking an innovative idea to a full-fledged product and company requires resources that individuals might not have. That's why the Michigan Economic Development Corporation, the MEDC, has launched an innovation campaign to support technology entrepreneurs.&lt;/p&gt;&lt;p&gt;Two words for you: startup ecosystem.&lt;/p&gt;&lt;p&gt;My guest is Darren Riley, the co-founder and CEO at JustAir, a clean air startup that began its journey in Michigan.&lt;/p&gt;&lt;p&gt;Welcome, Darren.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;Darren Riley:&lt;/em&gt; Hi. Thanks for having me.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Thank you ever so much for being with us. To get us started, let's just talk a bit about JustAir. How did the idea for the company come about, and what does your company do as well?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; Yeah, absolutely. The real thesis of JustAir, is really a combination of one, my personal experience but also my professional experience. On the professional side, background in software engineering, graduated from Carnegie Mellon University, but I was always fascinated by how to use technology to really support and innovate and really push the frontier on issues that are near and dear to my heart. Coming from Houston, Texas, coming from communities that often are restricted with certain issues, systemic issues, is something that I always carried in my heart.&lt;/p&gt;  &lt;p&gt;And on the personal side, it was around seven years ago when I moved to Detroit, in Southwest Detroit, where I developed asthma. Not growing up with asthma and not developing any issues, having that disease of the lungs really opened my eyes to just how much our environment impacts our health and well-being.&lt;/p&gt;&lt;p&gt;The combination of those, that pain point and also my background in technology, I was fascinated about why we don’t have the data we need or why we don’t have the infrastructure to solve these issues, to understand where pollution is coming from, how it’s impacting our communities, so that we can solve these problems and make an equitable breathing environment for everybody. That's kind of what birthed JustAir in a way.&lt;/p&gt;&lt;p&gt;And actually, it was around COVID-19 where we really started to push forward, where we saw all this information and research around health disparities and a lot of the issues of mortality rates around COVID-19, which kind of coincides with COPD, asthma, and other diseases that are often overburdened in communities that look like ours, in Black and brown communities. That's kind of where we got our start.&lt;/p&gt;&lt;p&gt;And what is JustAir today? JustAir is solving the problem of how to better manage local pollution so that we can make sure our communities, our lifestyles—where we work, where we play, and where we learn—are really protected. And, so, what JustAir does is build hyper-local neighborhood-level air quality monitoring networks. Communities have access to the data, policymakers and decision-makers can use that data to really influence and push things to help protect the community, but also other stakeholders can use the data to move the environment to a healthier state. So that's where we are, and we're four years strong, and I'm really excited to be a part of this journey here in Michigan.&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; So you launched about four years ago now. Why did you choose to build and grow just there in Michigan?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; Yeah, I think a combination of things, the reason why I chose to start here and be intentional about building our team here. I think first is really around the ecosystem support around Michigan. So the MEDC has a network of what we call SmartZones that really offer funding, resources, mentorship, advisory on the different challenges that can range from capital, legal, and other issues that kind of hold an entrepreneur from just getting out there and putting their product in the market. First and foremost, I’m super thankful and grateful for just the state really focusing on and putting entrepreneurs first in that regard.&lt;/p&gt;  &lt;p&gt;I think secondly is community. I really felt a strong sense of community here in Detroit. One of the founding members of an organization called Black Tech Saturdays, which sees over hundreds, 500-1,000 folks almost every Saturday of the month, just really sharing and really engaging with tech-curious folks from all different walks of life, but making intentional space for folks who are often left out of those rooms and out of those conversations. And just really seeing a peer network of entrepreneurs who come from a similar cultural background or a similar situation, really going after it together and helping each other navigate some issues.&lt;/p&gt;  &lt;p&gt;And then lastly, I talk about this a lot, but problem-solution fit. Being here in Detroit where I developed asthma, where we have many issues and many around the environment that have hit some communities the hardest, right here in Detroit in my own backyard I really want to be very narrowly focused and make sure that I'm building something that actually solves the problem that got me on this journey in the first place. Not thinking about regional-wide, different country, international, et cetera, but how do we build something right here in the backyard that solves the problem for my neighbors and makes sure that we can make a real difference in the community. So, from the community to the problem that I really care about and make sure we solve, and then also just the ecosystem support is why we're here in Michigan and why we plan to really grow and really be a part of this movement.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Fantastic. And you've touched on a few of those already, but as you were getting started, what specific resources, partnerships, or community support helped you navigate the early-stage research and development stages?&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; One example, really early, actually, I forgot about this for a while, but we have a Business Accelerator Fund here in Michigan where there's funding offered to entrepreneurs for technical assistance. I used that to operationalize some of our technical roadmap processes to build out the infrastructure that we really intended to do. So, that real funding that was non-dilutive that the state provided helped accelerate some of those issues in the early days, where it was just myself and advisors going after this problem. And so now, where we are today, there are funds that receive funding from MEDC, so local funds and venture capital that help you get your first check. Those are really helpful as well. All that to say is basically a combination of funding primary source, but also strategically, that funding is going towards product positioning and product-market fit. Those were some of the two core examples that have been beneficial.&lt;/p&gt;  &lt;p&gt;And then, I think the last thing I'll mention as well, MEDC and a lot of the SmartZones within the state, these SmartZones are just bucketed in different regions and areas, so you have Ann Arbor, you've got Detroit, you have Grand Rapids, the whole nine yards, having these events and creating these clusters, if you will, of density of entrepreneurs, I think is super, super critical. I've experienced in New York, Chicago, and San Francisco, and other bigger ecosystems that density is so critical to where you're constantly rubbing shoulders with the next entrepreneur, the next investor, the next customer, to really kind of accelerate that velocity of your journey.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah. Having that ecosystem makes such a difference, doesn't it?&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; Oh yeah, absolutely.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; And tech acumen and business acumen are very different sets of skills. I wonder what was the process like developing out your technology whilst also building out a viable business plan?&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Darren&lt;/em&gt;: I think I have a real unique opportunity. Having a software background, I code all the time, felt I had a lot of ideas, always joked that I had a Google Drive of 30 ideas that never worked, that I never showed anybody. I really felt I had that piece. What I was missing in my journey and why nothing ever came to fruition was just the simple principles of, are you solving a real problem, a real pain point for a customer?&lt;/p&gt;&lt;p&gt;Two things on the business acumen side are having an affinity for the problem. I truly believe that going on the entrepreneurial journey is lonely, it’s risky, it's stressful, and tiring. The more I can wake up in the morning and think about [how] the problems that we solve could actually result in a breath of clean air for someone who may not have that awareness or have the tools to advocate on their behalf, just having that extra motivation and having that affinity towards a problem that I feel really deeply, I think does help.&lt;/p&gt;&lt;p&gt;But I think also from the business acumen side of things, I had the opportunity to work at an organization called Endeavor based here in Michigan, where I was on the other side of an entrepreneur resource support organization. I got to see founders from high-growth companies throughout Michigan, series A, series B, retail, fintech, the whole nine yards, health tech, and seeing where are the challenges, where are things going well and where things are going wrong, from co-founder struggles to missing the market timing or going through banking issues from a couple years ago and all that stuff. All those things really help build a muscle memory of, I don't have all the answers, but being able to pull through those experiences and pattern matching does help as well, from how you actually build a business from zero, from product-market fit to scale and grow.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah, absolutely. And as you say, it can be a stressful journey, life as an entrepreneur, but I wonder if you could also share some highlights from your journey so far, any partnerships or projects that you're really excited about at the moment?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; I think the first and foremost highlight [that] I didn't realize I would come to enjoy so much is certainly my team. Being able to work with people who are aligned in passionate values and just kind of the culture and the focus is immensely valuable. If I'm going to spend this many hours in a week or in a year, I'd love to spend it with folks who are really passionate about it. I want to see them succeed. So I think first and foremost, I think the biggest success is really just the fortunate opportunity to work with people I really enjoy working with.&lt;/p&gt;&lt;p&gt;The others I'll mention [are] we have one of the largest county-owned monitoring networks in the country within Wayne County. The Health Department of Wayne County and Executive Warren Evans established this partnership where we deployed 100 fixed monitors throughout Wayne County to understand the patterns of local pollution to where we can help combat some of these issues where we are ranked F in air quality from the Lung Association, or Detroit is the third-worst from Asthma and Allergy Foundation of America, the third-worst place to live in with asthma. So, how do we really look at this data and tell the story, and how can we really mitigate solutions, while also giving data to the public so that they can navigate the world that's happening to them. That's one of our critical partnerships.&lt;/p&gt;&lt;p&gt;We're also very excited, we just got announced in Fast Company as one of the most innovative companies of 2025, so woo-hoo to that.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Congratulations.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; It is really exciting, yeah, in the social impact, social good category. There are many, many more, but I think the last one, I'm so, so grateful for, and I tell our team this all the time, is that we've already succeeded. Going to community meetings, hearing people raise their hand, asking questions about the adjuster application or about their data, and I to emphasize that when you hear community members saying ‘our data’ and not an ask, but as something that they have obtained, it warms my heart, and it shows that we're doing exactly what we said we wanted to do, which is to make sure that communities have the data that they deserve to create the future, the clean, healthy future that they desperately need.”.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Yeah, absolutely, what an incredible achievement. And what advice, finally, would you offer to other burgeoning entrepreneurs?&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Darren: &lt;/em&gt;Yeah, I think really something you are passionate about. Repeat that point again, do something that you feel that you can really go through those pain points and struggles for, [because] you need some extra kick to get you through and navigate these challenges.&lt;/p&gt;&lt;p&gt;The second thing, and the most important thing that a lot of people take away is community, community, community. I wouldn't be here today if I didn't have people to call on when I'm at my lowest points, and call on people in my highest points. When people are celebrating you with your head up, and then when people are helping you put your chin up when your head's down, I think it's so, so critical. I found that here in Michigan, and also found it here in our community, right here in Detroit. Passion and finding a community that's going to help get you through the journey is all it takes.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; Fantastic. All great advice. Thank you ever so much, Darren.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Darren:&lt;/em&gt; Absolutely.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Megan:&lt;/em&gt; That was Darren Riley, the co-founder and CEO at JustAir whom I spoke with from Brighton, England.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;That's it for this episode of Business Lab. I'm your host, Megan Tatum. I'm a contributing editor and host for Insights, the custom publishing division of MIT Technology Review. We were founded in 1899 at the Massachusetts Institute of Technology, and you can find us in print on the web and at events each year around the world. For more information about us on the show, please check out our website at technologyreview.com.&lt;/p&gt;&lt;p&gt;This show is available wherever you get your podcasts. And if you enjoyed this episode, we hope you'll take a moment to rate and review us. Business Lab is a production of MIT Technology Review. This episode was produced by Giro Studios. Thanks for listening.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/15/1117644/building-community-and-clean-air-solutions/</guid><pubDate>Tue, 15 Jul 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] How to use AI to start an online business (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-to-use-ai-to-start-an-online-business/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/growtika-mlpsHpUUCHY-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Nearly every online business now touches artificial intelligence at some point. Research from 2025 shows 78% of companies worldwide use AI for at least one business area. Smaller businesses report higher usage, with 89% saying they use AI each day. Over 280 million businesses worldwide now run at least one AI tool, and many use them for three different functions on average. In the United States, private investment in artificial intelligence reached $109.1 billion for 2025.&lt;/p&gt;&lt;p&gt;AI platforms can manage many repetitive or time-consuming parts of building and running a business. Here is how new founders use them:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Automating tasks such as billing, emails, and order fulfillment&lt;/li&gt;&lt;li&gt;Generating product descriptions, marketing content, and blogs&lt;/li&gt;&lt;li&gt;Providing support through chatbots and helpdesk systems&lt;/li&gt;&lt;li&gt;Handling customer and sales data, so owners see where to improve&lt;/li&gt;&lt;li&gt;Tuning online store content for better search engine ranking&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-automate-operations-and-cut-costs"&gt;Automate operations and cut costs&lt;/h3&gt;&lt;p&gt;Automation suites like Zapier AI and Make fold into online shop tools, email platforms, and marketing systems. These let founders set up triggers for actions. For example, a new order in the store can start a workflow: send a confirmation, log the sale, and update inventory. The owner does not need to touch anything. This reduces manual work, speeds up tasks, and can lower costs.&lt;/p&gt;&lt;p&gt;Email marketing and analytics also work better with AI. Mailchimp AI and Klaviyo can predict which emails each customer is most likely to open. The tools then send messages at the best times and segment users by what they want to read. SurferSEO and SEMrush help with keyword research and content optimisation. Founders can attract more visitors by following their recommended strategy.&lt;/p&gt;&lt;p&gt;Recent studies show that businesses using AI in marketing and sales see up to 50% more leads, spend 60% less time per sales call, and reduce overall costs by up to 60%. In email marketing, 41% of marketers report earning more revenue when they use AI.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-content-generators-make-publishing-easier"&gt;Content generators make publishing easier&lt;/h3&gt;&lt;p&gt;AI content platforms such as Jasper, Copy.ai, and Gemini can write product pages, advertisements, and help guides in minutes. Store owners do not need to hire a large writing team or spend hours creating new articles. These platforms use information given by the founder to write content based on keywords, brand tone, or target questions.&lt;/p&gt;&lt;p&gt;A direct-to-consumer skincare brand increased its revenue from $100,000 to $2,000,000 by using Jasper AI for product descriptions, blog content, and email copy, along with SurferSEO for search growth. The company published three times as much content and lowered its costs by over 75%.&lt;/p&gt;&lt;p&gt;Many founders rely on AI-generated support tools as well. ChatGPT, Gemini, and Intercom can answer common customer questions, process refunds, or recommend products based on a shopper’s past orders. This keeps response times quick and frees up the business owner to focus on other work.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-from-market-research-to-launch-a-step-by-step-to-using-prompts"&gt;From market research to launch: A step-by-step to using prompts&amp;nbsp;&lt;/h3&gt;&lt;p&gt;Owners use AI throughout the business process. Here are practical prompt examples used by successful founders:&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Find a business idea:&lt;/strong&gt; Ask the AI to suggest new business ideas based on what is selling on Amazon. For example: “Suggest ten online business ideas based on current bestsellers and size of those markets.”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Validate interest: &lt;/strong&gt;Ask the AI to read one-star reviews and summarise what people complain about in your product category.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Write a business plan:&lt;/strong&gt; Ask: “Create a one-page plan for a subscription fitness app for Millennials. Include key features, pricing, and launch plan.”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Make content:&lt;/strong&gt; Request: “Write a 500-word blog post on AI in ecommerce, ending with an offer to join a newsletter.”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Welcoming customers:&lt;/strong&gt; Use: “Write ten onboarding emails for people who bought a productivity tool. Answer likely questions and offer support links.”&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading" id="h-choosing-the-right-tools-for-each-stage"&gt;Choosing the right tools for each stage&lt;/h3&gt;&lt;p&gt;When you start an online business, it is common to test different tools side by side. For example, someone may use Jasper to write product pages, SurferSEO or SEMrush to adjust keywords, and AI Website Builder platforms to quickly assemble storefronts. Many people try several options before they find a set that works for their goals.&lt;/p&gt;&lt;p&gt;Some founders also mix in unique AI solutions, such as using Gemini for blog articles or Tableau Pulse for early-stage analytics. Trying a range of tools early on helps you build a process that fits your needs, budget, and skill set.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-case-studies-of-small-teams-using-ai-tools"&gt;Case studies of small teams using AI tools&lt;/h3&gt;&lt;p&gt;Smaller businesses and solo founders gain an advantage from AI. A SaaS founder built a niche app by using ChatGPT for customer questions and Notion AI for automated help guides. Gemini wrote landing pages. This owner offered around-the-clock support and content like bigger rivals, all without hiring a large staff.&lt;/p&gt;&lt;p&gt;A digital marketing agency switched to AI for project management, using Make for automation, ChatGPT for campaign ideas and reports, and analytics bots for real-time campaign data. They doubled their client count.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-and-analytics-smarter-decisions"&gt;Data and analytics: Smarter decisions&lt;/h3&gt;&lt;p&gt;Google Analytics AI, Tableau Pulse, and Microsoft Power BI Copilot help founders turn site clicks, sales, and customer messages into charts and reports. These tools find trends, spot gaps in the sales funnel, and let owners see which ads work best or why users quit a checkout process.&lt;/p&gt;&lt;p&gt;Experts suggest using these insights before spending heavily. For example, new founders can run AI-powered market research with prompts to summarise Amazon complaints or social media comments. This finds problems to solve or gaps left by competitors without running focus groups or big surveys.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-avoiding-common-pitfalls"&gt;Avoiding common pitfalls&lt;/h3&gt;&lt;p&gt;AI can replace many manual tasks, but experts such as top incubators warn that automation can hurt if it removes all human touch. Clear branding and direct customer support are still important. Owners should blend AI with real staff to keep support personal and branding unique.&lt;/p&gt;&lt;p&gt;Ethics also matter. Founders who train AI tools with their own brand voice, customer questions, and up-to-date data will stand out. Avoid over-automation that leaves users confused or alienated.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-building-a-process-that-works"&gt;Building a process that works&lt;/h3&gt;&lt;p&gt;Owners now run smarter shops with fewer staff. Workers using AI report a 66% daily productivity gain. Investment in generative AI added $1.4 trillion in market value and raised profits by 45% in four months for global firms. Mastering AI prompts and keeping the customer at the center of decisions leads to faster launches and more efficient growth.&lt;/p&gt;&lt;p&gt;A founder named Sarah Kim, who built a large ecommerce company, says clear prompts, rapid testing, and keeping a true brand voice are keys to leading in online business. Owners who spend time learning their AI platforms, fine-tuning prompts, and responding to user feedback can build and scale new ventures with less capital and less risk.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Author: Musfiqur, founder and CEO, Rankpa.com&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: Unsplash)&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/07/growtika-mlpsHpUUCHY-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Nearly every online business now touches artificial intelligence at some point. Research from 2025 shows 78% of companies worldwide use AI for at least one business area. Smaller businesses report higher usage, with 89% saying they use AI each day. Over 280 million businesses worldwide now run at least one AI tool, and many use them for three different functions on average. In the United States, private investment in artificial intelligence reached $109.1 billion for 2025.&lt;/p&gt;&lt;p&gt;AI platforms can manage many repetitive or time-consuming parts of building and running a business. Here is how new founders use them:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Automating tasks such as billing, emails, and order fulfillment&lt;/li&gt;&lt;li&gt;Generating product descriptions, marketing content, and blogs&lt;/li&gt;&lt;li&gt;Providing support through chatbots and helpdesk systems&lt;/li&gt;&lt;li&gt;Handling customer and sales data, so owners see where to improve&lt;/li&gt;&lt;li&gt;Tuning online store content for better search engine ranking&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-automate-operations-and-cut-costs"&gt;Automate operations and cut costs&lt;/h3&gt;&lt;p&gt;Automation suites like Zapier AI and Make fold into online shop tools, email platforms, and marketing systems. These let founders set up triggers for actions. For example, a new order in the store can start a workflow: send a confirmation, log the sale, and update inventory. The owner does not need to touch anything. This reduces manual work, speeds up tasks, and can lower costs.&lt;/p&gt;&lt;p&gt;Email marketing and analytics also work better with AI. Mailchimp AI and Klaviyo can predict which emails each customer is most likely to open. The tools then send messages at the best times and segment users by what they want to read. SurferSEO and SEMrush help with keyword research and content optimisation. Founders can attract more visitors by following their recommended strategy.&lt;/p&gt;&lt;p&gt;Recent studies show that businesses using AI in marketing and sales see up to 50% more leads, spend 60% less time per sales call, and reduce overall costs by up to 60%. In email marketing, 41% of marketers report earning more revenue when they use AI.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-content-generators-make-publishing-easier"&gt;Content generators make publishing easier&lt;/h3&gt;&lt;p&gt;AI content platforms such as Jasper, Copy.ai, and Gemini can write product pages, advertisements, and help guides in minutes. Store owners do not need to hire a large writing team or spend hours creating new articles. These platforms use information given by the founder to write content based on keywords, brand tone, or target questions.&lt;/p&gt;&lt;p&gt;A direct-to-consumer skincare brand increased its revenue from $100,000 to $2,000,000 by using Jasper AI for product descriptions, blog content, and email copy, along with SurferSEO for search growth. The company published three times as much content and lowered its costs by over 75%.&lt;/p&gt;&lt;p&gt;Many founders rely on AI-generated support tools as well. ChatGPT, Gemini, and Intercom can answer common customer questions, process refunds, or recommend products based on a shopper’s past orders. This keeps response times quick and frees up the business owner to focus on other work.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-from-market-research-to-launch-a-step-by-step-to-using-prompts"&gt;From market research to launch: A step-by-step to using prompts&amp;nbsp;&lt;/h3&gt;&lt;p&gt;Owners use AI throughout the business process. Here are practical prompt examples used by successful founders:&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Find a business idea:&lt;/strong&gt; Ask the AI to suggest new business ideas based on what is selling on Amazon. For example: “Suggest ten online business ideas based on current bestsellers and size of those markets.”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Validate interest: &lt;/strong&gt;Ask the AI to read one-star reviews and summarise what people complain about in your product category.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Write a business plan:&lt;/strong&gt; Ask: “Create a one-page plan for a subscription fitness app for Millennials. Include key features, pricing, and launch plan.”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Make content:&lt;/strong&gt; Request: “Write a 500-word blog post on AI in ecommerce, ending with an offer to join a newsletter.”&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Welcoming customers:&lt;/strong&gt; Use: “Write ten onboarding emails for people who bought a productivity tool. Answer likely questions and offer support links.”&lt;/li&gt;&lt;/ol&gt;&lt;h3 class="wp-block-heading" id="h-choosing-the-right-tools-for-each-stage"&gt;Choosing the right tools for each stage&lt;/h3&gt;&lt;p&gt;When you start an online business, it is common to test different tools side by side. For example, someone may use Jasper to write product pages, SurferSEO or SEMrush to adjust keywords, and AI Website Builder platforms to quickly assemble storefronts. Many people try several options before they find a set that works for their goals.&lt;/p&gt;&lt;p&gt;Some founders also mix in unique AI solutions, such as using Gemini for blog articles or Tableau Pulse for early-stage analytics. Trying a range of tools early on helps you build a process that fits your needs, budget, and skill set.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-case-studies-of-small-teams-using-ai-tools"&gt;Case studies of small teams using AI tools&lt;/h3&gt;&lt;p&gt;Smaller businesses and solo founders gain an advantage from AI. A SaaS founder built a niche app by using ChatGPT for customer questions and Notion AI for automated help guides. Gemini wrote landing pages. This owner offered around-the-clock support and content like bigger rivals, all without hiring a large staff.&lt;/p&gt;&lt;p&gt;A digital marketing agency switched to AI for project management, using Make for automation, ChatGPT for campaign ideas and reports, and analytics bots for real-time campaign data. They doubled their client count.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-and-analytics-smarter-decisions"&gt;Data and analytics: Smarter decisions&lt;/h3&gt;&lt;p&gt;Google Analytics AI, Tableau Pulse, and Microsoft Power BI Copilot help founders turn site clicks, sales, and customer messages into charts and reports. These tools find trends, spot gaps in the sales funnel, and let owners see which ads work best or why users quit a checkout process.&lt;/p&gt;&lt;p&gt;Experts suggest using these insights before spending heavily. For example, new founders can run AI-powered market research with prompts to summarise Amazon complaints or social media comments. This finds problems to solve or gaps left by competitors without running focus groups or big surveys.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-avoiding-common-pitfalls"&gt;Avoiding common pitfalls&lt;/h3&gt;&lt;p&gt;AI can replace many manual tasks, but experts such as top incubators warn that automation can hurt if it removes all human touch. Clear branding and direct customer support are still important. Owners should blend AI with real staff to keep support personal and branding unique.&lt;/p&gt;&lt;p&gt;Ethics also matter. Founders who train AI tools with their own brand voice, customer questions, and up-to-date data will stand out. Avoid over-automation that leaves users confused or alienated.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-building-a-process-that-works"&gt;Building a process that works&lt;/h3&gt;&lt;p&gt;Owners now run smarter shops with fewer staff. Workers using AI report a 66% daily productivity gain. Investment in generative AI added $1.4 trillion in market value and raised profits by 45% in four months for global firms. Mastering AI prompts and keeping the customer at the center of decisions leads to faster launches and more efficient growth.&lt;/p&gt;&lt;p&gt;A founder named Sarah Kim, who built a large ecommerce company, says clear prompts, rapid testing, and keeping a true brand voice are keys to leading in online business. Owners who spend time learning their AI platforms, fine-tuning prompts, and responding to user feedback can build and scale new ventures with less capital and less risk.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Author: Musfiqur, founder and CEO, Rankpa.com&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: Unsplash)&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-to-use-ai-to-start-an-online-business/</guid><pubDate>Tue, 15 Jul 2025 14:13:56 +0000</pubDate></item><item><title>[NEW] Google’s generative video model Veo 3 has a subtitles problem (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/15/1120156/googles-generative-video-model-veo-3-has-a-subtitles-problem/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/Veo-cc_1.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As soon as Google launched its latest video-generating AI model at the end of May, creatives rushed to put it through its paces. Released just months after its predecessor, Veo 3 allows users to generate sounds and dialogue for the first time, sparking a flurry of hyperrealistic eight-second clips stitched together into ads, ASMR videos, imagined film trailers, and humorous street interviews. Academy Award–nominated director Darren Aronofsky used the tool to create a short film called &lt;em&gt;Ancestra&lt;/em&gt;. During a press briefing, Demis Hassabis, Google DeepMind’s CEO, likened the leap forward to “emerging from the silent era of video generation.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But others quickly found that in some ways the tool wasn’t behaving as expected. When it generates clips that include dialogue, Veo 3 often adds nonsensical, garbled subtitles, even when the prompts it’s been given explicitly ask for no captions or subtitles to be added.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Getting rid of them isn’t straightforward—or cheap. Users have been forced to resort to regenerating clips (which costs them more money), using external subtitle-removing tools, or cropping their videos to get rid of the subtitles altogether.&lt;/p&gt;  &lt;p&gt;Josh Woodward, vice president of Google Labs and Gemini, posted on X on June 9 that Google had developed fixes to reduce the gibberish text. But over a month later, users are still logging issues with it in Google Labs’ Discord channel, demonstrating how difficult it can be to correct issues in major AI models.&lt;/p&gt; 
 &lt;p&gt;Like its predecessors, Veo 3 is available to paying members of Google’s subscription tiers, which start at $249.99 a month. To generate an eight-second clip, users enter a text prompt describing the scene they’d like to create into Google’s AI filmmaking tool Flow, Gemini, or other Google platforms. Each Veo 3 generation costs a minimum of 20 AI credits, and the account can be topped up at a cost of $25 per 2,500 credits.&lt;/p&gt;  &lt;p&gt;Mona Weiss, an advertising creative director, says that regenerating her scenes in a bid to get rid of the random captions is becoming expensive. “If you’re creating a scene with dialogue, up to 40% of its output has gibberish subtitles that make it unusable,” she says. “You’re burning through money trying to get a scene you like, but then you can’t even use it.”&lt;/p&gt; 
 &lt;p&gt;When Weiss reported the problem to Google Labs through its Discord channel in the hopes of getting a refund for her wasted credits, its team pointed her to the company’s official support team. They offered her a refund for the cost of Veo 3, but not for the credits. Weiss declined, as accepting would have meant losing access to the model altogether. The Google Labs’ Discord support team has been telling users that subtitles can be triggered by speech, saying that they’re aware of the problem and are working to fix it.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;So why does Veo 3 insist on adding these subtitles, and why does it appear to be so difficult to solve the problem? It probably comes down to what the model has been trained on.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Although Google hasn’t made this information public, that training data is likely to include YouTube videos, clips from vlogs and gaming channels, and TikTok edits, many of which come with subtitles. These embedded subtitles are part of the video frames rather than separate text tracks layered on top, meaning it’s difficult to remove them before they’re used for training, says Shuo Niu, an assistant professor at Clark University in Massachusetts who studies video sharing platforms and AI.&lt;/p&gt;  &lt;p&gt;“The text-to-video model is trained using reinforcement learning to produce content that mimics human-created videos, and if such videos include subtitles, the model may ‘learn’ that incorporating subtitles enhances similarity with human-generated content,” he says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“We’re continuously working to improve video creation, especially with text, speech that sounds natural, and audio that syncs perfectly,” a Google spokesperson says. “We encourage users to try their prompt again if they notice an inconsistency and give us feedback using the thumbs up/down option.”&lt;/p&gt;  &lt;p&gt;As for why the model ignores instructions such as “No subtitles,” negative prompts (telling a generative AI model &lt;em&gt;not &lt;/em&gt;to do something) are usually less effective than positive ones, says Tuhin Chakrabarty, an assistant professor at Stony Brook University who studies AI systems.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To fix the problem, Google would have to check every frame of each video Veo 3 has been trained on, and either get rid of or relabel those with captions before retraining the model—an endeavor that would take weeks, he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Katerina Cizek, a documentary maker and artistic director at the MIT Open Documentary Lab, believes the problem exemplifies Google’s willingness to launch products before they’re fully ready.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Google needed a win,” she says. “They needed to be the first to pump out a tool that generates lip-synched audio. And so that was more important than fixing their subtitle issue.” &amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/Veo-cc_1.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As soon as Google launched its latest video-generating AI model at the end of May, creatives rushed to put it through its paces. Released just months after its predecessor, Veo 3 allows users to generate sounds and dialogue for the first time, sparking a flurry of hyperrealistic eight-second clips stitched together into ads, ASMR videos, imagined film trailers, and humorous street interviews. Academy Award–nominated director Darren Aronofsky used the tool to create a short film called &lt;em&gt;Ancestra&lt;/em&gt;. During a press briefing, Demis Hassabis, Google DeepMind’s CEO, likened the leap forward to “emerging from the silent era of video generation.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But others quickly found that in some ways the tool wasn’t behaving as expected. When it generates clips that include dialogue, Veo 3 often adds nonsensical, garbled subtitles, even when the prompts it’s been given explicitly ask for no captions or subtitles to be added.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Getting rid of them isn’t straightforward—or cheap. Users have been forced to resort to regenerating clips (which costs them more money), using external subtitle-removing tools, or cropping their videos to get rid of the subtitles altogether.&lt;/p&gt;  &lt;p&gt;Josh Woodward, vice president of Google Labs and Gemini, posted on X on June 9 that Google had developed fixes to reduce the gibberish text. But over a month later, users are still logging issues with it in Google Labs’ Discord channel, demonstrating how difficult it can be to correct issues in major AI models.&lt;/p&gt; 
 &lt;p&gt;Like its predecessors, Veo 3 is available to paying members of Google’s subscription tiers, which start at $249.99 a month. To generate an eight-second clip, users enter a text prompt describing the scene they’d like to create into Google’s AI filmmaking tool Flow, Gemini, or other Google platforms. Each Veo 3 generation costs a minimum of 20 AI credits, and the account can be topped up at a cost of $25 per 2,500 credits.&lt;/p&gt;  &lt;p&gt;Mona Weiss, an advertising creative director, says that regenerating her scenes in a bid to get rid of the random captions is becoming expensive. “If you’re creating a scene with dialogue, up to 40% of its output has gibberish subtitles that make it unusable,” she says. “You’re burning through money trying to get a scene you like, but then you can’t even use it.”&lt;/p&gt; 
 &lt;p&gt;When Weiss reported the problem to Google Labs through its Discord channel in the hopes of getting a refund for her wasted credits, its team pointed her to the company’s official support team. They offered her a refund for the cost of Veo 3, but not for the credits. Weiss declined, as accepting would have meant losing access to the model altogether. The Google Labs’ Discord support team has been telling users that subtitles can be triggered by speech, saying that they’re aware of the problem and are working to fix it.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;So why does Veo 3 insist on adding these subtitles, and why does it appear to be so difficult to solve the problem? It probably comes down to what the model has been trained on.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Although Google hasn’t made this information public, that training data is likely to include YouTube videos, clips from vlogs and gaming channels, and TikTok edits, many of which come with subtitles. These embedded subtitles are part of the video frames rather than separate text tracks layered on top, meaning it’s difficult to remove them before they’re used for training, says Shuo Niu, an assistant professor at Clark University in Massachusetts who studies video sharing platforms and AI.&lt;/p&gt;  &lt;p&gt;“The text-to-video model is trained using reinforcement learning to produce content that mimics human-created videos, and if such videos include subtitles, the model may ‘learn’ that incorporating subtitles enhances similarity with human-generated content,” he says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“We’re continuously working to improve video creation, especially with text, speech that sounds natural, and audio that syncs perfectly,” a Google spokesperson says. “We encourage users to try their prompt again if they notice an inconsistency and give us feedback using the thumbs up/down option.”&lt;/p&gt;  &lt;p&gt;As for why the model ignores instructions such as “No subtitles,” negative prompts (telling a generative AI model &lt;em&gt;not &lt;/em&gt;to do something) are usually less effective than positive ones, says Tuhin Chakrabarty, an assistant professor at Stony Brook University who studies AI systems.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To fix the problem, Google would have to check every frame of each video Veo 3 has been trained on, and either get rid of or relabel those with captions before retraining the model—an endeavor that would take weeks, he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Katerina Cizek, a documentary maker and artistic director at the MIT Open Documentary Lab, believes the problem exemplifies Google’s willingness to launch products before they’re fully ready.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Google needed a win,” she says. “They needed to be the first to pump out a tool that generates lip-synched audio. And so that was more important than fixing their subtitle issue.” &amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/15/1120156/googles-generative-video-model-veo-3-has-a-subtitles-problem/</guid><pubDate>Tue, 15 Jul 2025 14:40:32 +0000</pubDate></item><item><title>[NEW] Mistral releases Voxtral, its first open source AI audio model (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/15/mistral-releases-voxtral-its-first-open-source-ai-audio-model/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI systems become more capable, speech is fast becoming the default way we communicate with machines. French AI startup Mistral has jumped into the audio race with its first open model, aiming to challenge the dominance of walled-off corporate systems with open-weight alternatives.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Tuesday, Mistral announced the release of Voxtral, its first family of audio models aimed at businesses. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is pitching Voxtral as the first open model that’s capable of deploying “truly usable speech intelligence in production.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In other words, no longer will developers have to choose between a cheap, open system that fumbles transcriptions and doesn’t really understand what’s being said, and one that functions well, but is closed, leaving developers with a higher bill and less control over deployment.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For businesses, that means Voxtral offers an affordable alternative that the company claims is “less than half the price” of comparable solutions.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3028006" height="336" src="https://techcrunch.com/wp-content/uploads/2025/07/unnamed-5.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Mistral&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral says Voxtral can transcribe up to 30 minutes of audio. Due to its LLM backbone, Mistral Small 3.1, it can understand up to 40 minutes, allowing users to ask questions about the audio content, generate summaries, or turn voice commands into real-time actions like calling APIs or running functions. Voxtral is also multilingual, with the ability to transcribe and understand languages including English, Spanish, French, Portuguese, Hindi, German, Dutch, and Italian. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is offering up two variants of its “speech understanding models.” The first, Voxtral Small, has 24 billion parameters for production-scale deployments, and is competitive with ElevenLabs Scribe, GPT-4o-mini, and Gemini 2.5 Flash.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The second, Voxtral Mini, has 3 billion parameters for local and edge deployments. There’s also an ultra-cheap, stripped-down, fast API version of the 3 billion model called Voxtral Mini Transcribe that is optimized for transcription-only use cases and promises to outperform OpenAI Whisper for less than half the price.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can try Voxtral for free by downloading the API on Hugging Face or testing the models in Mistral’s chatbot Le Chat. Integrating the API into applications starts at $0.001 per minute, according to the company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch comes a month after Mistral announced Magistral, its first family of reasoning models that work through problems step-by-step for improved reliability.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mistral, one of the top AI firms in Europe, is well-known for its advocacy pushing open source AI models. Earlier this month, TechCrunch reported that the company is in talks to raise up to $1 billion in equity from investors like Abu Dhabi’s MGX fund.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI systems become more capable, speech is fast becoming the default way we communicate with machines. French AI startup Mistral has jumped into the audio race with its first open model, aiming to challenge the dominance of walled-off corporate systems with open-weight alternatives.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Tuesday, Mistral announced the release of Voxtral, its first family of audio models aimed at businesses. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is pitching Voxtral as the first open model that’s capable of deploying “truly usable speech intelligence in production.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In other words, no longer will developers have to choose between a cheap, open system that fumbles transcriptions and doesn’t really understand what’s being said, and one that functions well, but is closed, leaving developers with a higher bill and less control over deployment.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For businesses, that means Voxtral offers an affordable alternative that the company claims is “less than half the price” of comparable solutions.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3028006" height="336" src="https://techcrunch.com/wp-content/uploads/2025/07/unnamed-5.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Mistral&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral says Voxtral can transcribe up to 30 minutes of audio. Due to its LLM backbone, Mistral Small 3.1, it can understand up to 40 minutes, allowing users to ask questions about the audio content, generate summaries, or turn voice commands into real-time actions like calling APIs or running functions. Voxtral is also multilingual, with the ability to transcribe and understand languages including English, Spanish, French, Portuguese, Hindi, German, Dutch, and Italian. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is offering up two variants of its “speech understanding models.” The first, Voxtral Small, has 24 billion parameters for production-scale deployments, and is competitive with ElevenLabs Scribe, GPT-4o-mini, and Gemini 2.5 Flash.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The second, Voxtral Mini, has 3 billion parameters for local and edge deployments. There’s also an ultra-cheap, stripped-down, fast API version of the 3 billion model called Voxtral Mini Transcribe that is optimized for transcription-only use cases and promises to outperform OpenAI Whisper for less than half the price.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can try Voxtral for free by downloading the API on Hugging Face or testing the models in Mistral’s chatbot Le Chat. Integrating the API into applications starts at $0.001 per minute, according to the company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch comes a month after Mistral announced Magistral, its first family of reasoning models that work through problems step-by-step for improved reliability.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mistral, one of the top AI firms in Europe, is well-known for its advocacy pushing open source AI models. Earlier this month, TechCrunch reported that the company is in talks to raise up to $1 billion in equity from investors like Abu Dhabi’s MGX fund.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/15/mistral-releases-voxtral-its-first-open-source-ai-audio-model/</guid><pubDate>Tue, 15 Jul 2025 15:14:44 +0000</pubDate></item><item><title>[NEW] Military AI contracts awarded to Anthropic, OpenAI, Google, and xAI (AI News)</title><link>https://www.artificialintelligence-news.com/news/military-ai-contracts-awarded-to-anthropic-openai-google-and-xai/</link><description>&lt;p&gt;The Pentagon has opened the military AI floodgates and handed out contracts worth up to $800 million to four of the biggest names: Google, OpenAI, Anthropic, and Elon Musk’s xAI. Each company gets a shot at $200 million worth of work.&lt;/p&gt;&lt;p&gt;Dr Doug Matty, Chief Digital and AI Officer, said: “The adoption of AI is transforming the Department’s ability to support our warfighters and maintain strategic advantage over our adversaries.&lt;/p&gt;&lt;p&gt;“Leveraging commercially available solutions into an integrated capabilities approach will accelerate the use of advanced AI as part of our joint mission essential tasks in our warfighting domain as well as intelligence, business, and enterprise information systems.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;The Pentagon is playing it smart by not putting all their eggs in one basket. Instead of picking a single winner, they’re creating competition among the top players in the hope of ensuring the best AI solutions available for the military and broader government.&lt;/p&gt;&lt;p&gt;Just as this announcement dropped, Musk’s xAI rolled out ‘Grok For Government,’ a special version of their AI designed specifically for use by public agencies. This follows similar government initiatives from OpenAI and Anthropic.&lt;/p&gt;&lt;p&gt;The new government suite from xAI promises everything from their latest Grok 4 model to ‘Deep Search’ and ‘Tool Use.’ They’re even planning to get security clearances for their engineers and make their AI work in classified environments.&lt;/p&gt;&lt;p&gt;The company is clearly trying to position itself as the patriotic choice, talking about “maintaining American leadership in technological innovation” and “turning shovels into tokens”—whatever that means.&lt;/p&gt;&lt;p&gt;However, remember when Grok went completely off the rails and started talking about “Mechahitler”? That’s exactly the kind of thing that makes people nervous about using AI for serious government work and even military purposes.&lt;/p&gt;&lt;p&gt;When you’re dealing with national security, you can’t have your AI assistant suddenly spouting bizarre alternate histories or making stuff up. The stakes are just too high. It’s like hiring someone to help with important decisions, but sometimes they just start talking nonsense.&lt;/p&gt;&lt;p&gt;This whole deal shows just how seriously the government is taking AI—they see it as essential for staying competitive. The partnership with the General Services Administration means any federal agency can now tap into these AI tools, making it easier for everyone from the FBI to the Department of Agriculture to get on board.&lt;/p&gt;&lt;p&gt;The Pentagon is essentially running a high-stakes experiment. They’re betting that by working with multiple AI companies, they’ll get the best of all worlds while avoiding the risks of relying on just one provider. It’s a smart strategy, but it also means they’ll need to figure out how to manage all these different systems and make sure they actually work together.&lt;/p&gt;&lt;p&gt;The real test will be whether these AI tools can deliver on their promises in the government and military without the embarrassing glitches that have plagued some of these systems in the past. Because when it comes to national security, there’s no room for AI having a “Mechahitler” moment.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Google’s open MedGemma AI models could transform healthcare&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The Pentagon has opened the military AI floodgates and handed out contracts worth up to $800 million to four of the biggest names: Google, OpenAI, Anthropic, and Elon Musk’s xAI. Each company gets a shot at $200 million worth of work.&lt;/p&gt;&lt;p&gt;Dr Doug Matty, Chief Digital and AI Officer, said: “The adoption of AI is transforming the Department’s ability to support our warfighters and maintain strategic advantage over our adversaries.&lt;/p&gt;&lt;p&gt;“Leveraging commercially available solutions into an integrated capabilities approach will accelerate the use of advanced AI as part of our joint mission essential tasks in our warfighting domain as well as intelligence, business, and enterprise information systems.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;The Pentagon is playing it smart by not putting all their eggs in one basket. Instead of picking a single winner, they’re creating competition among the top players in the hope of ensuring the best AI solutions available for the military and broader government.&lt;/p&gt;&lt;p&gt;Just as this announcement dropped, Musk’s xAI rolled out ‘Grok For Government,’ a special version of their AI designed specifically for use by public agencies. This follows similar government initiatives from OpenAI and Anthropic.&lt;/p&gt;&lt;p&gt;The new government suite from xAI promises everything from their latest Grok 4 model to ‘Deep Search’ and ‘Tool Use.’ They’re even planning to get security clearances for their engineers and make their AI work in classified environments.&lt;/p&gt;&lt;p&gt;The company is clearly trying to position itself as the patriotic choice, talking about “maintaining American leadership in technological innovation” and “turning shovels into tokens”—whatever that means.&lt;/p&gt;&lt;p&gt;However, remember when Grok went completely off the rails and started talking about “Mechahitler”? That’s exactly the kind of thing that makes people nervous about using AI for serious government work and even military purposes.&lt;/p&gt;&lt;p&gt;When you’re dealing with national security, you can’t have your AI assistant suddenly spouting bizarre alternate histories or making stuff up. The stakes are just too high. It’s like hiring someone to help with important decisions, but sometimes they just start talking nonsense.&lt;/p&gt;&lt;p&gt;This whole deal shows just how seriously the government is taking AI—they see it as essential for staying competitive. The partnership with the General Services Administration means any federal agency can now tap into these AI tools, making it easier for everyone from the FBI to the Department of Agriculture to get on board.&lt;/p&gt;&lt;p&gt;The Pentagon is essentially running a high-stakes experiment. They’re betting that by working with multiple AI companies, they’ll get the best of all worlds while avoiding the risks of relying on just one provider. It’s a smart strategy, but it also means they’ll need to figure out how to manage all these different systems and make sure they actually work together.&lt;/p&gt;&lt;p&gt;The real test will be whether these AI tools can deliver on their promises in the government and military without the embarrassing glitches that have plagued some of these systems in the past. Because when it comes to national security, there’s no room for AI having a “Mechahitler” moment.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Google’s open MedGemma AI models could transform healthcare&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/military-ai-contracts-awarded-to-anthropic-openai-google-and-xai/</guid><pubDate>Tue, 15 Jul 2025 15:24:13 +0000</pubDate></item><item><title>[NEW] Shaping the future with adaptive production (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/15/1120083/shaping-the-future-with-adaptive-production/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Siemens&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Adaptive production is more than a technological upgrade: it is a paradigm shift. This new frontier enables the integration of cutting-edge technologies to create an increasingly autonomous environment, where interconnected manufacturing plants go beyond the limits of traditional automation. Artificial intelligence, digital twins, and robotics are among the powerful tools manufacturers are using to create dynamic, intelligent systems that not only perform tasks, but also learn, make decisions, and evolve in real-time.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1120162" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/MIT_SiemensR3_V6_Cov062625.png?w=1555" width="1555" /&gt;&lt;/figure&gt;  &lt;p&gt;Taking this kind of adaptive approach can transform a manufacturer’s productivity, efficiency, and innovation. But beyond the factory, it also has the potential to deliver society-wide benefits, by bolstering economic growth locally, creating more attractive and accessible employment opportunities, and supporting a sustainability agenda.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;As efforts to revive and modernize local manufacturing accelerate in regions around the world, including North America and Europe, adaptive production could help manufacturers overcome some of their biggest obstacles—firstly, attracting and retaining talent. Nearly 60% of manufacturers cited this as their top challenge in a 2024 US-based survey. Highly automated, technology-led adaptive production methods hold new promise for attracting talent to roles that are safer, less repetitive, and better paid. “The ideal scenario is one where AI enhances human capabilities, leads to new task creation, and empowers the people who are most at risk from automation’s impact on certain jobs, particularly those without college degrees,” says Simon Johnson, co-director of MIT’s Shaping the Future of Work Initiative.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1120177" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/MITTR2024_R3SiemensSocials7-14254.png" /&gt;&lt;/figure&gt;  &lt;p&gt;Secondly, the digitalization of manufacturing—embedded in the very foundation of adaptive production technologies—allows companies to better address complex sustainability challenges through process and resource optimization and a better understanding of data. “By integrating these advanced technologies, we gain a more comprehensive picture across the entire production process and product lifecycle,” explains Jelena Mitic, head of technology for the Future of Automation at Siemens. “This will provide a much faster and more efficient way to optimize operations and ensure that all the necessary safety and sustainability requirements are met during quality control.”&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Download the full report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Siemens&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Adaptive production is more than a technological upgrade: it is a paradigm shift. This new frontier enables the integration of cutting-edge technologies to create an increasingly autonomous environment, where interconnected manufacturing plants go beyond the limits of traditional automation. Artificial intelligence, digital twins, and robotics are among the powerful tools manufacturers are using to create dynamic, intelligent systems that not only perform tasks, but also learn, make decisions, and evolve in real-time.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1120162" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/MIT_SiemensR3_V6_Cov062625.png?w=1555" width="1555" /&gt;&lt;/figure&gt;  &lt;p&gt;Taking this kind of adaptive approach can transform a manufacturer’s productivity, efficiency, and innovation. But beyond the factory, it also has the potential to deliver society-wide benefits, by bolstering economic growth locally, creating more attractive and accessible employment opportunities, and supporting a sustainability agenda.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;As efforts to revive and modernize local manufacturing accelerate in regions around the world, including North America and Europe, adaptive production could help manufacturers overcome some of their biggest obstacles—firstly, attracting and retaining talent. Nearly 60% of manufacturers cited this as their top challenge in a 2024 US-based survey. Highly automated, technology-led adaptive production methods hold new promise for attracting talent to roles that are safer, less repetitive, and better paid. “The ideal scenario is one where AI enhances human capabilities, leads to new task creation, and empowers the people who are most at risk from automation’s impact on certain jobs, particularly those without college degrees,” says Simon Johnson, co-director of MIT’s Shaping the Future of Work Initiative.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1120177" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/MITTR2024_R3SiemensSocials7-14254.png" /&gt;&lt;/figure&gt;  &lt;p&gt;Secondly, the digitalization of manufacturing—embedded in the very foundation of adaptive production technologies—allows companies to better address complex sustainability challenges through process and resource optimization and a better understanding of data. “By integrating these advanced technologies, we gain a more comprehensive picture across the entire production process and product lifecycle,” explains Jelena Mitic, head of technology for the Future of Automation at Siemens. “This will provide a much faster and more efficient way to optimize operations and ensure that all the necessary safety and sustainability requirements are met during quality control.”&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Download the full report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/15/1120083/shaping-the-future-with-adaptive-production/</guid><pubDate>Tue, 15 Jul 2025 15:32:33 +0000</pubDate></item><item><title>[NEW] Research leaders urge tech industry to monitor AI’s ‘thoughts’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/15/research-leaders-urge-tech-industry-to-monitor-ais-thoughts/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-1194975140.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI researchers from OpenAI, Google DeepMind, Anthropic, and a broad coalition of companies and nonprofit groups, are calling for deeper investigation into techniques for monitoring the so-called thoughts of AI reasoning models in a position paper published Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A key feature of AI reasoning models, such as OpenAI’s o3 and DeepSeek’s R1, are their chains-of-thought or CoTs — an externalized process in which AI models work through problems, similar to how humans use a scratch pad to work through a difficult math question. Reasoning models are a core technology for powering AI agents, and the paper’s authors argue that CoT monitoring could be a core method to keep AI agents under control as they become more widespread and capable.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“CoT monitoring presents a valuable addition to safety measures for frontier AI, offering a rare glimpse into how AI agents make decisions,” said the researchers in the position paper. “Yet, there is no guarantee that the current degree of visibility will persist. We encourage the research community and frontier AI developers to make the best use of CoT monitorability and study how it can be preserved.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The position paper asks leading AI model developers to study what makes CoTs “monitorable” — in other words, what factors can increase or decrease transparency into how AI models really arrive at answers. The paper’s authors say that CoT monitoring may be a key method for understanding AI reasoning models, but note that it could be fragile, cautioning against any interventions that could reduce their transparency or reliability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The paper’s authors also call on AI model developers to track CoT monitorability and study how the method could one day be implemented as a safety measure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notable signatories of the paper include OpenAI chief research officer Mark Chen, Safe Superintelligence CEO Ilya Sutskever, Nobel laureate Geoffrey Hinton, Google DeepMind co-founder Shane Legg, xAI safety adviser Dan Hendrycks, and Thinking Machines co-founder John Schulman. First authors include leaders from the U.K. AI Security Institute and Apollo Research, and other signatories come from METR, Amazon, Meta, and UC Berkeley.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The paper marks a moment of unity among many of the AI industry’s leaders in an attempt to boost research around AI safety. It comes at a time when tech companies are caught in a fierce competition — which has led Meta to poach top researchers from OpenAI, Google DeepMind, and Anthropic with million-dollar offers. Some of the most highly sought-after researchers are those building AI agents and AI reasoning models.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re at this critical time where we have this new chain-of-thought thing. It seems pretty useful, but it could go away in a few years if people don’t really concentrate on it,” said Bowen Baker, an OpenAI researcher who worked on the paper, in an interview with TechCrunch. “Publishing a position paper like this, to me, is a mechanism to get more research and attention on this topic before that happens.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI publicly released a preview of the first AI reasoning model, o1, in September 2024. In the months since, the tech industry was quick to release competitors that exhibit similar capabilities, with some models from Google DeepMind, xAI, and Anthropic showing even more advanced performance on benchmarks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, there’s relatively little understood about how AI reasoning models work. While AI labs have excelled at improving the performance of AI in the last year, that hasn’t necessarily translated into a better understanding of how they arrive at their answers. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic has been one of the industry’s leaders in figuring out how AI models really work — a field called interpretability. Earlier this year, CEO Dario Amodei announced a commitment to crack open the black box of AI models by 2027 and invest more in interpretability. He called on OpenAI and Google DeepMind to research the topic more, as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early research from Anthropic has indicated that CoTs may not be a fully reliable indication of how these models arrive at answers. At the same time, OpenAI researchers have said that CoT monitoring could one day be a reliable way to track alignment and safety in AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The goal of position papers like this is to signal boost and attract more attention to nascent areas of research, such as CoT monitoring. Companies like OpenAI, Google DeepMind, and Anthropic are already researching these topics, but it’s possible that this paper will encourage more funding and research into the space.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/10/GettyImages-1194975140.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI researchers from OpenAI, Google DeepMind, Anthropic, and a broad coalition of companies and nonprofit groups, are calling for deeper investigation into techniques for monitoring the so-called thoughts of AI reasoning models in a position paper published Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A key feature of AI reasoning models, such as OpenAI’s o3 and DeepSeek’s R1, are their chains-of-thought or CoTs — an externalized process in which AI models work through problems, similar to how humans use a scratch pad to work through a difficult math question. Reasoning models are a core technology for powering AI agents, and the paper’s authors argue that CoT monitoring could be a core method to keep AI agents under control as they become more widespread and capable.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“CoT monitoring presents a valuable addition to safety measures for frontier AI, offering a rare glimpse into how AI agents make decisions,” said the researchers in the position paper. “Yet, there is no guarantee that the current degree of visibility will persist. We encourage the research community and frontier AI developers to make the best use of CoT monitorability and study how it can be preserved.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The position paper asks leading AI model developers to study what makes CoTs “monitorable” — in other words, what factors can increase or decrease transparency into how AI models really arrive at answers. The paper’s authors say that CoT monitoring may be a key method for understanding AI reasoning models, but note that it could be fragile, cautioning against any interventions that could reduce their transparency or reliability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The paper’s authors also call on AI model developers to track CoT monitorability and study how the method could one day be implemented as a safety measure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notable signatories of the paper include OpenAI chief research officer Mark Chen, Safe Superintelligence CEO Ilya Sutskever, Nobel laureate Geoffrey Hinton, Google DeepMind co-founder Shane Legg, xAI safety adviser Dan Hendrycks, and Thinking Machines co-founder John Schulman. First authors include leaders from the U.K. AI Security Institute and Apollo Research, and other signatories come from METR, Amazon, Meta, and UC Berkeley.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The paper marks a moment of unity among many of the AI industry’s leaders in an attempt to boost research around AI safety. It comes at a time when tech companies are caught in a fierce competition — which has led Meta to poach top researchers from OpenAI, Google DeepMind, and Anthropic with million-dollar offers. Some of the most highly sought-after researchers are those building AI agents and AI reasoning models.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re at this critical time where we have this new chain-of-thought thing. It seems pretty useful, but it could go away in a few years if people don’t really concentrate on it,” said Bowen Baker, an OpenAI researcher who worked on the paper, in an interview with TechCrunch. “Publishing a position paper like this, to me, is a mechanism to get more research and attention on this topic before that happens.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI publicly released a preview of the first AI reasoning model, o1, in September 2024. In the months since, the tech industry was quick to release competitors that exhibit similar capabilities, with some models from Google DeepMind, xAI, and Anthropic showing even more advanced performance on benchmarks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, there’s relatively little understood about how AI reasoning models work. While AI labs have excelled at improving the performance of AI in the last year, that hasn’t necessarily translated into a better understanding of how they arrive at their answers. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic has been one of the industry’s leaders in figuring out how AI models really work — a field called interpretability. Earlier this year, CEO Dario Amodei announced a commitment to crack open the black box of AI models by 2027 and invest more in interpretability. He called on OpenAI and Google DeepMind to research the topic more, as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early research from Anthropic has indicated that CoTs may not be a fully reliable indication of how these models arrive at answers. At the same time, OpenAI researchers have said that CoT monitoring could one day be a reliable way to track alignment and safety in AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The goal of position papers like this is to signal boost and attract more attention to nascent areas of research, such as CoT monitoring. Companies like OpenAI, Google DeepMind, and Anthropic are already researching these topics, but it’s possible that this paper will encourage more funding and research into the space.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/15/research-leaders-urge-tech-industry-to-monitor-ais-thoughts/</guid><pubDate>Tue, 15 Jul 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] AI coding tools are shifting to a surprising place: the terminal (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/15/ai-coding-tools-are-shifting-to-a-surprising-place-the-terminal/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2019/11/GettyImages-920696090-1.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, code-editing tools like Cursor, Windsurf, and GitHub’s Copilot have been the standard for AI-powered software development. But as agentic AI grows more powerful and vibe coding takes off, a subtle shift has changed how AI systems are interacting with software. Instead of working on code, they’re increasingly interacting directly with the shell of whatever system they’re installed in. It’s a significant change in how AI-powered software development happens – and despite the low profile, it could have significant implications for where the field goes from here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The terminal is best known as the black-and-white screen you remember from 90s hacker movies – a very old-school way of running programs and manipulating data. It’s not as visually impressive as contemporary code editors, but it’s an extremely powerful interface if you know how to use it. And while code-based agents can write and debug code, terminal tools are often needed to get software from written code to something that can actually be used.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The clearest sign of the shift to the terminal has come from major labs. Since February, Anthropic, DeepMind and OpenAI have all released command-line coding tools (Claude Code, Gemini CLI, and CLI Codex respectively), and they’re already among the companies’ most popular products. That shift has been easy to miss, since they’re largely operating under the same branding as previous coding tools. But under the hood, there have been real changes in how agents interact with other computers, both online and offline. Some believe those changes are just getting started.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our big bet is that there’s a future in which 95% of LLM-computer interaction is through a terminal-like interface,” says Alex Shaw, co-creator of the leading terminal-focused benchmark TerminalBench.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Terminal-based tools are also coming into their own just as prominent code-based tools are starting to look shaky. The AI code editor Windsurf has been torn apart by dueling acquisitions, with senior executives hired away by Google and the remaining company acquired by Cognition – leaving the consumer product’s long-term future uncertain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, new research suggests programmers may be overestimating productivity gains from conventional tools. A METR study testing out Cursor Pro, Windsurf’s main competitor, found that while developers estimated they could complete tasks 20-30 percent faster, the observed process was nearly 20 percent slower. In short, the code assistant was actually costing programmers time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That has left an opening for companies like Warp, which currently holds the top spot on TerminalBench. Warp bills itself as an “agentic development environment,” a middle ground between IDE programs and command-line tools like Claude Code. But Warp founder Zach Lloyd is still bullish on the terminal, seeing it as a way to tackle problems that would be out of scope for a code editor like Cursor.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The terminal occupies a very low level in the developer stack, so it’s the most versatile place to be running agents,” Lloyd says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To understand how the new approach is different, it can be helpful to look at the benchmarks used to measure them. The code-based generation of tools was focused on solving GitHub issues, the basis of the SWE-Bench test. Each problem on SWE-Bench is an open issue from GitHub — essentially, a piece of code that doesn’t work. Models iterate on the code until they find something that works, solving the problem. Integrated products like Cursor have built more sophisticated approaches to the problem, but the GitHub/SWE-Bench model is still the core of how these tools approach the problem: starting with broken code and turning it into code that works.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Terminal-based tools take a wider view, looking beyond the code to the whole environment a program is running in. That includes coding but also more DevOps-oriented tasks like configuring a Git server or troubleshooting why a script won’t run. In one TerminalBench problem, the instructions give a decompression program and a target text file, challenging the agent to reverse-engineer a matching compression algorithm. Another asks the agent to build the Linux kernel from source, failing to mention that the agent will have to download the source code itself. Solving the issues requires the kind of bull-headed problem-solving ability that programmers need.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“What makes TerminalBench hard is not just the questions that we’re giving the agents,” says Shaw, “it’s the environments that we’re placing them in.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucially, this new approach means tackling a problem step-by-step – the same skill that makes agentic AI so powerful. But even state-of-the-art agentic models can’t handle all of those environments. Warp earned its high score on TerminalBench by solving just over half of the problems – a mark of how challenging the benchmark is, but also how much work still needs to be done to unlock the terminal’s full potential.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Lloyd believes we’re already at a point where terminal-based tools can reliably handle much of a developer’s non-coding work – a value proposition that’s hard to ignore.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you think of the daily work of setting up a new project, figuring out the dependencies and getting it runnable, Warp can pretty much do that autonomously,” says Lloyd. “And if it can’t do it, it will tell you why.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2019/11/GettyImages-920696090-1.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, code-editing tools like Cursor, Windsurf, and GitHub’s Copilot have been the standard for AI-powered software development. But as agentic AI grows more powerful and vibe coding takes off, a subtle shift has changed how AI systems are interacting with software. Instead of working on code, they’re increasingly interacting directly with the shell of whatever system they’re installed in. It’s a significant change in how AI-powered software development happens – and despite the low profile, it could have significant implications for where the field goes from here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The terminal is best known as the black-and-white screen you remember from 90s hacker movies – a very old-school way of running programs and manipulating data. It’s not as visually impressive as contemporary code editors, but it’s an extremely powerful interface if you know how to use it. And while code-based agents can write and debug code, terminal tools are often needed to get software from written code to something that can actually be used.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The clearest sign of the shift to the terminal has come from major labs. Since February, Anthropic, DeepMind and OpenAI have all released command-line coding tools (Claude Code, Gemini CLI, and CLI Codex respectively), and they’re already among the companies’ most popular products. That shift has been easy to miss, since they’re largely operating under the same branding as previous coding tools. But under the hood, there have been real changes in how agents interact with other computers, both online and offline. Some believe those changes are just getting started.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our big bet is that there’s a future in which 95% of LLM-computer interaction is through a terminal-like interface,” says Alex Shaw, co-creator of the leading terminal-focused benchmark TerminalBench.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Terminal-based tools are also coming into their own just as prominent code-based tools are starting to look shaky. The AI code editor Windsurf has been torn apart by dueling acquisitions, with senior executives hired away by Google and the remaining company acquired by Cognition – leaving the consumer product’s long-term future uncertain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, new research suggests programmers may be overestimating productivity gains from conventional tools. A METR study testing out Cursor Pro, Windsurf’s main competitor, found that while developers estimated they could complete tasks 20-30 percent faster, the observed process was nearly 20 percent slower. In short, the code assistant was actually costing programmers time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That has left an opening for companies like Warp, which currently holds the top spot on TerminalBench. Warp bills itself as an “agentic development environment,” a middle ground between IDE programs and command-line tools like Claude Code. But Warp founder Zach Lloyd is still bullish on the terminal, seeing it as a way to tackle problems that would be out of scope for a code editor like Cursor.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The terminal occupies a very low level in the developer stack, so it’s the most versatile place to be running agents,” Lloyd says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To understand how the new approach is different, it can be helpful to look at the benchmarks used to measure them. The code-based generation of tools was focused on solving GitHub issues, the basis of the SWE-Bench test. Each problem on SWE-Bench is an open issue from GitHub — essentially, a piece of code that doesn’t work. Models iterate on the code until they find something that works, solving the problem. Integrated products like Cursor have built more sophisticated approaches to the problem, but the GitHub/SWE-Bench model is still the core of how these tools approach the problem: starting with broken code and turning it into code that works.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Terminal-based tools take a wider view, looking beyond the code to the whole environment a program is running in. That includes coding but also more DevOps-oriented tasks like configuring a Git server or troubleshooting why a script won’t run. In one TerminalBench problem, the instructions give a decompression program and a target text file, challenging the agent to reverse-engineer a matching compression algorithm. Another asks the agent to build the Linux kernel from source, failing to mention that the agent will have to download the source code itself. Solving the issues requires the kind of bull-headed problem-solving ability that programmers need.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“What makes TerminalBench hard is not just the questions that we’re giving the agents,” says Shaw, “it’s the environments that we’re placing them in.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucially, this new approach means tackling a problem step-by-step – the same skill that makes agentic AI so powerful. But even state-of-the-art agentic models can’t handle all of those environments. Warp earned its high score on TerminalBench by solving just over half of the problems – a mark of how challenging the benchmark is, but also how much work still needs to be done to unlock the terminal’s full potential.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Lloyd believes we’re already at a point where terminal-based tools can reliably handle much of a developer’s non-coding work – a value proposition that’s hard to ignore.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you think of the daily work of setting up a new project, figuring out the dependencies and getting it runnable, Warp can pretty much do that autonomously,” says Lloyd. “And if it can’t do it, it will tell you why.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/15/ai-coding-tools-are-shifting-to-a-surprising-place-the-terminal/</guid><pubDate>Tue, 15 Jul 2025 16:30:00 +0000</pubDate></item><item><title>[NEW] Finally, a dev kit for designing on-device, mobile AI apps is here: Liquid AI’s LEAP (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/finally-a-dev-kit-for-designing-on-device-mobile-ai-apps-is-here-liquid-ais-leap/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Liquid AI, the startup formed by former Massachusetts Institute of Technology (MIT) researchers to develop novel AI model architectures beyond the widely-used “Transformers“, today announced the release of &lt;strong&gt;LEAP&lt;/strong&gt; aka the “Liquid Edge AI Platform,” a cross-platform software development kit (SDK) designed to make it easier for developers to integrate small language models (SLMs) directly into mobile applications. &lt;/p&gt;



&lt;p&gt;Alongside LEAP, the company also introduced &lt;strong&gt;Apollo&lt;/strong&gt;, a companion iOS app for testing these models locally, furthering Liquid AI’s mission to enable privacy-preserving, efficient AI on consumer hardware.&lt;/p&gt;



&lt;p&gt;The LEAP SDK arrives at a time when many developers are seeking alternatives to cloud-only AI services due to concerns over latency, cost, privacy, and offline availability. &lt;/p&gt;



&lt;p&gt;LEAP addresses those needs head-on with a local-first approach that &lt;em&gt;allows small models to run directly on-device&lt;/em&gt;, reducing dependence on cloud infrastructure.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-built-for-mobile-devs-with-no-prior-ml-experience-required"&gt;Built for mobile devs with no prior ML experience required&lt;/h2&gt;



&lt;p&gt;LEAP is designed for developers who want to build with AI but may not have deep expertise in machine learning. &lt;/p&gt;



&lt;p&gt;According to Liquid AI, the SDK can be added to an iOS or Android project with just a few lines of code, and calling a local model is meant to feel as familiar as interacting with a traditional cloud API.&lt;/p&gt;



&lt;p&gt;“Our research shows developers are moving beyond cloud-only AI and looking for trusted partners to help them build on-device,” said Ramin Hasani, co-founder and CEO of Liquid AI, in a blog post announcing the news today on Liquid’s website. “LEAP is our answer—a flexible, end-to-end deployment platform built from the ground up to make powerful, efficient, and private edge AI truly accessible.”&lt;/p&gt;



&lt;p&gt;Once integrated, developers can select a model from the built-in LEAP model library, which includes compact models as small as 300MB — lightweight enough for modern phones with as little as 4GB of RAM (!!) and up. &lt;/p&gt;



&lt;p&gt;The SDK handles local inference, memory optimization, and device compatibility, simplifying the typical edge deployment process.&lt;/p&gt;



&lt;p&gt;LEAP is OS- and model-agnostic by design. At launch, it supports both iOS and Android, and offers compatibility with Liquid AI’s own Liquid Foundation Models (LFMs) as well as many popular open-source small models.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-goal-a-unified-ecosystem-for-edge-ai"&gt;The goal: a unified ecosystem for edge AI&lt;/h2&gt;



&lt;p&gt;Beyond model execution, LEAP positions itself as an all-in-one platform for discovering, adapting, testing, and deploying SLMs for edge use. &lt;/p&gt;



&lt;p&gt;Developers can browse a curated model catalog with various quantization and checkpoint options, allowing them to tailor performance and memory footprint to the constraints of the target device.&lt;/p&gt;



&lt;p&gt;Liquid AI emphasizes that large models tend to be generalists, while small models often perform best when optimized for a narrow set of tasks. LEAP’s unified system is structured around that principle, offering tools for rapid iteration and deployment in real-world mobile environments.&lt;/p&gt;



&lt;p&gt;The SDK also comes with a developer community hosted on Discord, where Liquid AI offers office hours, support, events, and competitions to encourage experimentation and feedback.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-apollo-like-testflight-for-local-ai-models"&gt;Apollo: like Testflight for local AI models&lt;/h2&gt;



&lt;p&gt;To complement LEAP, Liquid AI also released &lt;strong&gt;Apollo&lt;/strong&gt;, a free iOS app that lets developers and users interact with LEAP-compatible models in a local, offline setting. &lt;/p&gt;



&lt;p&gt;Originally a separate mobile app startup that allowed users to chat with LLMs privately on device, which Liquid acquired earlier this year, Apollo has been rebuilt to support the entire LEAP model library.&lt;/p&gt;



&lt;p&gt;Apollo is designed for low-friction experimentation — developers can “vibe check” a model’s tone, latency, or output behavior right on their phones before integrating it into a production app. The app runs entirely offline, preserving user privacy and reducing reliance on cloud compute.&lt;/p&gt;



&lt;p&gt;Whether used as a lightweight dev tool or a private AI assistant, Apollo reflects Liquid AI’s broader push to decentralize AI access and execution.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-built-on-the-back-of-the-lfm2-model-family-announced-last-week"&gt;Built on the back of the LFM2 model family announced last week&lt;/h2&gt;



&lt;p&gt;LEAP SDK release builds on Liquid AI’s July 10 announcement of &lt;strong&gt;LFM2&lt;/strong&gt;, its second-generation foundation model family designed specifically for on-device workloads. &lt;/p&gt;



&lt;p&gt;LFM2 models come in 350M, 700M, and 1.2B parameter sizes, and benchmark competitively with larger models in speed and accuracy across several evaluation tasks. &lt;/p&gt;



&lt;p&gt;These models form the backbone of the LEAP model library and are optimized for fast inference on CPUs, GPUs, and NPUs.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-free-and-ready-for-devs-to-start-building"&gt;Free and ready for devs to start building&lt;/h2&gt;



&lt;p&gt;LEAP is currently free to use under a developer license that includes the core SDK and model library.&lt;/p&gt;



&lt;p&gt;Liquid AI notes that premium enterprise features will be made available under a separate commercial license in the future, but that it is taking inquiries from enterprise customers already through its website contact form.&lt;/p&gt;



&lt;p&gt;LFM2 models are also free for academic use and commercial use by companies with under $10 million in revenue, with larger organizations required to contact the company for licensing.&lt;/p&gt;



&lt;p&gt;Developers can get started by visiting the LEAP SDK website, downloading Apollo from the App Store, or joining the Liquid AI developer community on Discord.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Liquid AI, the startup formed by former Massachusetts Institute of Technology (MIT) researchers to develop novel AI model architectures beyond the widely-used “Transformers“, today announced the release of &lt;strong&gt;LEAP&lt;/strong&gt; aka the “Liquid Edge AI Platform,” a cross-platform software development kit (SDK) designed to make it easier for developers to integrate small language models (SLMs) directly into mobile applications. &lt;/p&gt;



&lt;p&gt;Alongside LEAP, the company also introduced &lt;strong&gt;Apollo&lt;/strong&gt;, a companion iOS app for testing these models locally, furthering Liquid AI’s mission to enable privacy-preserving, efficient AI on consumer hardware.&lt;/p&gt;



&lt;p&gt;The LEAP SDK arrives at a time when many developers are seeking alternatives to cloud-only AI services due to concerns over latency, cost, privacy, and offline availability. &lt;/p&gt;



&lt;p&gt;LEAP addresses those needs head-on with a local-first approach that &lt;em&gt;allows small models to run directly on-device&lt;/em&gt;, reducing dependence on cloud infrastructure.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-built-for-mobile-devs-with-no-prior-ml-experience-required"&gt;Built for mobile devs with no prior ML experience required&lt;/h2&gt;



&lt;p&gt;LEAP is designed for developers who want to build with AI but may not have deep expertise in machine learning. &lt;/p&gt;



&lt;p&gt;According to Liquid AI, the SDK can be added to an iOS or Android project with just a few lines of code, and calling a local model is meant to feel as familiar as interacting with a traditional cloud API.&lt;/p&gt;



&lt;p&gt;“Our research shows developers are moving beyond cloud-only AI and looking for trusted partners to help them build on-device,” said Ramin Hasani, co-founder and CEO of Liquid AI, in a blog post announcing the news today on Liquid’s website. “LEAP is our answer—a flexible, end-to-end deployment platform built from the ground up to make powerful, efficient, and private edge AI truly accessible.”&lt;/p&gt;



&lt;p&gt;Once integrated, developers can select a model from the built-in LEAP model library, which includes compact models as small as 300MB — lightweight enough for modern phones with as little as 4GB of RAM (!!) and up. &lt;/p&gt;



&lt;p&gt;The SDK handles local inference, memory optimization, and device compatibility, simplifying the typical edge deployment process.&lt;/p&gt;



&lt;p&gt;LEAP is OS- and model-agnostic by design. At launch, it supports both iOS and Android, and offers compatibility with Liquid AI’s own Liquid Foundation Models (LFMs) as well as many popular open-source small models.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-goal-a-unified-ecosystem-for-edge-ai"&gt;The goal: a unified ecosystem for edge AI&lt;/h2&gt;



&lt;p&gt;Beyond model execution, LEAP positions itself as an all-in-one platform for discovering, adapting, testing, and deploying SLMs for edge use. &lt;/p&gt;



&lt;p&gt;Developers can browse a curated model catalog with various quantization and checkpoint options, allowing them to tailor performance and memory footprint to the constraints of the target device.&lt;/p&gt;



&lt;p&gt;Liquid AI emphasizes that large models tend to be generalists, while small models often perform best when optimized for a narrow set of tasks. LEAP’s unified system is structured around that principle, offering tools for rapid iteration and deployment in real-world mobile environments.&lt;/p&gt;



&lt;p&gt;The SDK also comes with a developer community hosted on Discord, where Liquid AI offers office hours, support, events, and competitions to encourage experimentation and feedback.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-apollo-like-testflight-for-local-ai-models"&gt;Apollo: like Testflight for local AI models&lt;/h2&gt;



&lt;p&gt;To complement LEAP, Liquid AI also released &lt;strong&gt;Apollo&lt;/strong&gt;, a free iOS app that lets developers and users interact with LEAP-compatible models in a local, offline setting. &lt;/p&gt;



&lt;p&gt;Originally a separate mobile app startup that allowed users to chat with LLMs privately on device, which Liquid acquired earlier this year, Apollo has been rebuilt to support the entire LEAP model library.&lt;/p&gt;



&lt;p&gt;Apollo is designed for low-friction experimentation — developers can “vibe check” a model’s tone, latency, or output behavior right on their phones before integrating it into a production app. The app runs entirely offline, preserving user privacy and reducing reliance on cloud compute.&lt;/p&gt;



&lt;p&gt;Whether used as a lightweight dev tool or a private AI assistant, Apollo reflects Liquid AI’s broader push to decentralize AI access and execution.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-built-on-the-back-of-the-lfm2-model-family-announced-last-week"&gt;Built on the back of the LFM2 model family announced last week&lt;/h2&gt;



&lt;p&gt;LEAP SDK release builds on Liquid AI’s July 10 announcement of &lt;strong&gt;LFM2&lt;/strong&gt;, its second-generation foundation model family designed specifically for on-device workloads. &lt;/p&gt;



&lt;p&gt;LFM2 models come in 350M, 700M, and 1.2B parameter sizes, and benchmark competitively with larger models in speed and accuracy across several evaluation tasks. &lt;/p&gt;



&lt;p&gt;These models form the backbone of the LEAP model library and are optimized for fast inference on CPUs, GPUs, and NPUs.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-free-and-ready-for-devs-to-start-building"&gt;Free and ready for devs to start building&lt;/h2&gt;



&lt;p&gt;LEAP is currently free to use under a developer license that includes the core SDK and model library.&lt;/p&gt;



&lt;p&gt;Liquid AI notes that premium enterprise features will be made available under a separate commercial license in the future, but that it is taking inquiries from enterprise customers already through its website contact form.&lt;/p&gt;



&lt;p&gt;LFM2 models are also free for academic use and commercial use by companies with under $10 million in revenue, with larger organizations required to contact the company for licensing.&lt;/p&gt;



&lt;p&gt;Developers can get started by visiting the LEAP SDK website, downloading Apollo from the App Store, or joining the Liquid AI developer community on Discord.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/finally-a-dev-kit-for-designing-on-device-mobile-ai-apps-is-here-liquid-ais-leap/</guid><pubDate>Tue, 15 Jul 2025 16:46:57 +0000</pubDate></item><item><title>[NEW] Google Discover adds AI summaries, threatening publishers with further traffic declines (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/15/google-discover-adds-ai-summaries-threatening-publishers-with-further-traffic-declines/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As publishers fret about decreased traffic from Google, the search giant has begun rolling out AI summaries in Discover, the main news feed inside Google’s search app on iOS and Android. Now, instead of seeing a headline from a major publication, users will see multiple news publishers’ logos in the top-left corner, followed by an AI-generated summary that cites those sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app warns that these summaries are generated with AI, “which can make mistakes.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3028060" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/IMG_1716.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is not yet appearing for all news stories within the Google app, indicating this change is likely still a test. (Google has been asked for comment about the extent of the rollout, but has not responded.) In tests, TechCrunch was able to view the AI summaries firsthand across both iOS and Android apps in the U.S.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition to the summaries, Google has been trying out other ways to present the news displayed in Discover. Though not flagged as powered by AI, some stories will include a set of bullet points below the headline or will be grouped with similar news. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, a story about President Trump’s Ukraine deal also included links to other stories about Trump’s latest actions. Meanwhile, a story from The Washington Post about ICE was followed by bullet points that summarized the story’s content. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3028059" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/IMG_1717.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The update to the search app comes as a number of publishers have been experimenting with AI on their own sites, including The Wall Street Journal, Yahoo, Bloomberg, USA Today, and others. Startups, too, have gotten in on the action, as with Particle, a news reader that uses AI to not only summarize stories but also allow users to see different sides or ask follow-up questions to better understand the topic covered.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite these trials, there’s significant concern in the publishing industry about how the shift to AI is impacting website traffic and referrals. With features like Google’s AI Overviews and AI Mode, users no longer have to visit a website directly to get answers to their search queries — it can be summarized for them automatically or shared in a chatbot-style interface. Outside of Google, this same trend is seen across other AI apps, like ChatGPT or Perplexity.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Google tried to appease publishers with the launch of Offerwall, a feature that allows publishers to generate revenue beyond the more traffic-dependent options, like ads. With Offerwall, publishers who use Google Ad Manager can try out different methods to provide access to their content, like micropayments or having users take surveys, sign up for newsletters, watch ads, and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But for many publishers, these tools are coming too late, as traffic is already in a steep decline.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A story by The Economist this week noted that worldwide search traffic fell by 15% year-over-year as of June, citing data from market intelligence company Similarweb.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier data from the firm also found that the number of news searches on the web that result in no click-throughs to news websites had grown from 56% in May 2024, when AI Overviews launched, to nearly 69% as of May 2025. Organic traffic also declined, dropping from over 2.3 billion visits at its peak in mid-2024 to fewer than 1.7 billion, it noted.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amid this shift, Google Discover still remained a source for clicks, even as traffic from Google Search declined. But that may no longer be the case if the AI summaries roll out more broadly within the Google app. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As publishers fret about decreased traffic from Google, the search giant has begun rolling out AI summaries in Discover, the main news feed inside Google’s search app on iOS and Android. Now, instead of seeing a headline from a major publication, users will see multiple news publishers’ logos in the top-left corner, followed by an AI-generated summary that cites those sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app warns that these summaries are generated with AI, “which can make mistakes.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3028060" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/IMG_1716.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is not yet appearing for all news stories within the Google app, indicating this change is likely still a test. (Google has been asked for comment about the extent of the rollout, but has not responded.) In tests, TechCrunch was able to view the AI summaries firsthand across both iOS and Android apps in the U.S.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition to the summaries, Google has been trying out other ways to present the news displayed in Discover. Though not flagged as powered by AI, some stories will include a set of bullet points below the headline or will be grouped with similar news. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, a story about President Trump’s Ukraine deal also included links to other stories about Trump’s latest actions. Meanwhile, a story from The Washington Post about ICE was followed by bullet points that summarized the story’s content. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3028059" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/IMG_1717.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The update to the search app comes as a number of publishers have been experimenting with AI on their own sites, including The Wall Street Journal, Yahoo, Bloomberg, USA Today, and others. Startups, too, have gotten in on the action, as with Particle, a news reader that uses AI to not only summarize stories but also allow users to see different sides or ask follow-up questions to better understand the topic covered.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite these trials, there’s significant concern in the publishing industry about how the shift to AI is impacting website traffic and referrals. With features like Google’s AI Overviews and AI Mode, users no longer have to visit a website directly to get answers to their search queries — it can be summarized for them automatically or shared in a chatbot-style interface. Outside of Google, this same trend is seen across other AI apps, like ChatGPT or Perplexity.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Google tried to appease publishers with the launch of Offerwall, a feature that allows publishers to generate revenue beyond the more traffic-dependent options, like ads. With Offerwall, publishers who use Google Ad Manager can try out different methods to provide access to their content, like micropayments or having users take surveys, sign up for newsletters, watch ads, and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But for many publishers, these tools are coming too late, as traffic is already in a steep decline.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A story by The Economist this week noted that worldwide search traffic fell by 15% year-over-year as of June, citing data from market intelligence company Similarweb.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier data from the firm also found that the number of news searches on the web that result in no click-throughs to news websites had grown from 56% in May 2024, when AI Overviews launched, to nearly 69% as of May 2025. Organic traffic also declined, dropping from over 2.3 billion visits at its peak in mid-2024 to fewer than 1.7 billion, it noted.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amid this shift, Google Discover still remained a source for clicks, even as traffic from Google Search declined. But that may no longer be the case if the AI summaries roll out more broadly within the Google app. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/15/google-discover-adds-ai-summaries-threatening-publishers-with-further-traffic-declines/</guid><pubDate>Tue, 15 Jul 2025 17:19:47 +0000</pubDate></item><item><title>[NEW] Finding value with AI automation (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/15/1119978/finding-value-with-ai-automation/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Intel&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In June 2023, technology leaders and IT services executives had a lightning bolt headed their way when McKinsey published the “The economic potential of generative AI: The next productivity frontier” report. It echoed a moment from the 2010s when Amazon Web Services launched an advertising campaign aimed at Main Street’s C-suite: Why would any fiscally responsible exec allow their IT teams to spend capex for servers and software when AWS only cost 10 cents per virtual machine?&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1120188" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/iStock-1347611336.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;Vendors understand that these kinds of reports and aggressive advertising around competitive risks projected onto an industry sector would drive many calls from boards to their C-suite, rolling from C-suite to their staff all asking, “What are we doing with AI?” When asked to “do something with AI,” technical leadership and their organizations promptly responded — sometimes begrudgingly and sometimes excitedly — for work-sanctioned opportunities to get their hands on a new technology. At that point, there was no time to sort between actual business returns from applying AI and “AI novelty” use cases that were more Rube Goldberg machines than tangible breakthroughs.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Today's opportunity: Significant automation gains&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;When leaders respond to immediate panic, new business risks and mitigations often emerge.&amp;nbsp; Two recent examples highlight the consequences of rushing to implement and publish positive results from AI adoption. The Wall Street Journal reported in April 2025 on companies struggling to realize returns on AI. Just weeks later, it covered MIT’s retraction of a technical paper about AI where the results that led to its publication could not be substantiated.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While these reports demonstrate the pitfalls of over-reliance on AI without common-sense guardrails, not all is off track in the land of enterprise AI adoption. Incredible results being found from judicious use of AI and related technologies in automating processes across industries. Now that we are through the “fear of missing out” stage and can get down to business, where are the best places to look for value when applying AI to automation of your business?&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While chatbots are almost as pervasive as new app downloads for mobile phones, the applications of AI realizing automation and productivity gains line up with the unique purpose and architecture of the underlying AI system they are built on. The dominant patterns where AI gains are realized currently boil down to two things: language (translation and patterns) and data (new format creation and data search).&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Example one: Natural language processing &lt;/strong&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Manufacturing automation challenge:&lt;/strong&gt; Failure Mode and Effects Analysis (FMEA) is both critical and often labor intensive. It is not always performed prior to a failure in manufacturing equipment, so very often FMEA occurs in a stressful manufacturing lines-down scenario. In Intel’s case, a global footprint of manufacturing facilities separated by large distances along with time zones and preferred language differences makes this even more difficult to find the root cause of a problem. Weeks of engineering effort are spent per FMEA analysis repeated across large fleets of tools spread between these facilities.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Leverage already deployed CPU compute servers for natural language processing (NLP) across the manufacturing tool logs, where observations about the tools’ operations are maintained by the local manufacturing technicians. The analysis also applied sentiment analysis to classify words as positive, negative, or neutral. The new system performed FMEA on six months of data in under one minute, saving weeks of engineering time and allowing the manufacturing line to proactively service equipment on a pre-emptive schedule rather than incurring unexpected downtime.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Financial institution challenge:&lt;/strong&gt; Programming languages commonly used by software engineers have evolved. Mature bellwether institutions were often formed through a series of mergers and acquisitions over the years, and they continue to rely on critical systems that are based on 30-year-old programming languages that current-day software engineers are not familiar with.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Use NLP to translate between the old and new programming languages, giving software engineers a needed boost to improve the serviceability of critical operational systems. Use the power of AI rather than doing a risky rewrite or massive upgrade.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;&lt;strong&gt;Example two: Company product specifications and generative AI models&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Sales automation challenge:&lt;/strong&gt; The time it takes to reformat a company’s product data into a specific customer RFP format has been an ongoing challenge across industries. Teams of sales and technical leads spend weeks of work across different accounts reformatting the same root data between the preferred PowerPoint or Word document formats. The customer response times were measured in weeks, especially if the RFPs required legal reviews.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; By using generative AI combined with a data extraction and prompting technique called retrieval augmented generation (RAG), companies can rapidly reformat product information between different customer required RFP response formats. The time spent moving data between different documents and different document types only to find an unforced error in the move is reduced to hours instead of weeks.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;HR policy automation challenge:&lt;/strong&gt; Navigating internal processes can be time consuming and confusing for both HR and employees. The consequences of misinterpretation, access outages, and personal information or private data being exposed are massively important to the company and the individual.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Combine generative AI, RAG, and an interactive chatbot that uses employee-assigned assets to determine identity and access rights, provides employees interactive query-based chat formats to answer their questions in real time.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Finding your best use cases for AI&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In a world where 80% to 90% of all AI proof of concepts fail to scale, now is the time to develop a framework that is based on caution. Consider starting with a data strategy and governance assessment. Then find opportunities to compare successful AI-based automation efforts at peer companies through peer discussions. Clear, rules-based policies and processes offer the best opportunities to begin a successful AI automation journey in your enterprise. Where you encounter disparate data sources (e.g., unstructured, video, structured databases) or unclear processes, maintain tighter human-in-the-loop decision controls to avoid unexpected data or token exposure and cost overruns.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;As the AI hype cycle cools and business pressure mounts, now is the time to become practical. Apply AI to well-defined use cases and begin unlocking the automation benefits that will matter not just in 2025, but for years to come.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Intel. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Intel&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In June 2023, technology leaders and IT services executives had a lightning bolt headed their way when McKinsey published the “The economic potential of generative AI: The next productivity frontier” report. It echoed a moment from the 2010s when Amazon Web Services launched an advertising campaign aimed at Main Street’s C-suite: Why would any fiscally responsible exec allow their IT teams to spend capex for servers and software when AWS only cost 10 cents per virtual machine?&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1120188" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/iStock-1347611336.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;Vendors understand that these kinds of reports and aggressive advertising around competitive risks projected onto an industry sector would drive many calls from boards to their C-suite, rolling from C-suite to their staff all asking, “What are we doing with AI?” When asked to “do something with AI,” technical leadership and their organizations promptly responded — sometimes begrudgingly and sometimes excitedly — for work-sanctioned opportunities to get their hands on a new technology. At that point, there was no time to sort between actual business returns from applying AI and “AI novelty” use cases that were more Rube Goldberg machines than tangible breakthroughs.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Today's opportunity: Significant automation gains&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;When leaders respond to immediate panic, new business risks and mitigations often emerge.&amp;nbsp; Two recent examples highlight the consequences of rushing to implement and publish positive results from AI adoption. The Wall Street Journal reported in April 2025 on companies struggling to realize returns on AI. Just weeks later, it covered MIT’s retraction of a technical paper about AI where the results that led to its publication could not be substantiated.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While these reports demonstrate the pitfalls of over-reliance on AI without common-sense guardrails, not all is off track in the land of enterprise AI adoption. Incredible results being found from judicious use of AI and related technologies in automating processes across industries. Now that we are through the “fear of missing out” stage and can get down to business, where are the best places to look for value when applying AI to automation of your business?&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While chatbots are almost as pervasive as new app downloads for mobile phones, the applications of AI realizing automation and productivity gains line up with the unique purpose and architecture of the underlying AI system they are built on. The dominant patterns where AI gains are realized currently boil down to two things: language (translation and patterns) and data (new format creation and data search).&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Example one: Natural language processing &lt;/strong&gt;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Manufacturing automation challenge:&lt;/strong&gt; Failure Mode and Effects Analysis (FMEA) is both critical and often labor intensive. It is not always performed prior to a failure in manufacturing equipment, so very often FMEA occurs in a stressful manufacturing lines-down scenario. In Intel’s case, a global footprint of manufacturing facilities separated by large distances along with time zones and preferred language differences makes this even more difficult to find the root cause of a problem. Weeks of engineering effort are spent per FMEA analysis repeated across large fleets of tools spread between these facilities.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Leverage already deployed CPU compute servers for natural language processing (NLP) across the manufacturing tool logs, where observations about the tools’ operations are maintained by the local manufacturing technicians. The analysis also applied sentiment analysis to classify words as positive, negative, or neutral. The new system performed FMEA on six months of data in under one minute, saving weeks of engineering time and allowing the manufacturing line to proactively service equipment on a pre-emptive schedule rather than incurring unexpected downtime.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Financial institution challenge:&lt;/strong&gt; Programming languages commonly used by software engineers have evolved. Mature bellwether institutions were often formed through a series of mergers and acquisitions over the years, and they continue to rely on critical systems that are based on 30-year-old programming languages that current-day software engineers are not familiar with.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Use NLP to translate between the old and new programming languages, giving software engineers a needed boost to improve the serviceability of critical operational systems. Use the power of AI rather than doing a risky rewrite or massive upgrade.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;&lt;strong&gt;Example two: Company product specifications and generative AI models&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Sales automation challenge:&lt;/strong&gt; The time it takes to reformat a company’s product data into a specific customer RFP format has been an ongoing challenge across industries. Teams of sales and technical leads spend weeks of work across different accounts reformatting the same root data between the preferred PowerPoint or Word document formats. The customer response times were measured in weeks, especially if the RFPs required legal reviews.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; By using generative AI combined with a data extraction and prompting technique called retrieval augmented generation (RAG), companies can rapidly reformat product information between different customer required RFP response formats. The time spent moving data between different documents and different document types only to find an unforced error in the move is reduced to hours instead of weeks.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;HR policy automation challenge:&lt;/strong&gt; Navigating internal processes can be time consuming and confusing for both HR and employees. The consequences of misinterpretation, access outages, and personal information or private data being exposed are massively important to the company and the individual.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;Solution:&lt;/strong&gt; Combine generative AI, RAG, and an interactive chatbot that uses employee-assigned assets to determine identity and access rights, provides employees interactive query-based chat formats to answer their questions in real time.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Finding your best use cases for AI&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In a world where 80% to 90% of all AI proof of concepts fail to scale, now is the time to develop a framework that is based on caution. Consider starting with a data strategy and governance assessment. Then find opportunities to compare successful AI-based automation efforts at peer companies through peer discussions. Clear, rules-based policies and processes offer the best opportunities to begin a successful AI automation journey in your enterprise. Where you encounter disparate data sources (e.g., unstructured, video, structured databases) or unclear processes, maintain tighter human-in-the-loop decision controls to avoid unexpected data or token exposure and cost overruns.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;As the AI hype cycle cools and business pressure mounts, now is the time to become practical. Apply AI to well-defined use cases and begin unlocking the automation benefits that will matter not just in 2025, but for years to come.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Intel. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/15/1119978/finding-value-with-ai-automation/</guid><pubDate>Tue, 15 Jul 2025 17:36:36 +0000</pubDate></item><item><title>[NEW] Mira Murati’s Thinking Machines Lab is worth $12B in seed round (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/15/mira-muratis-thinking-machines-lab-is-worth-12b-in-seed-round/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-1730510668.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Thinking Machines Lab, the AI startup founded by OpenAI’s former chief technology officer Mira Murati, officially closed a $2 billion seed round led by Andreessen Horowitz on Monday, a company spokesperson told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal, which includes participation from NVIDIA, Accel, ServiceNow, CISCO, AMD, and Jane Street, values the startup at $12 billion, the spokesperson said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Several outlets reported in June that Thinking Machines Lab was close to closing this $2B funding round at a $10 billion valuation, but, apparently, that valuation has shot up in the last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal marks one of the largest seed rounds — or first funding rounds — in Silicon Valley history, representing the massive investor appetite to back promising new AI labs. Thinking Machines Lab is less than a year old and has yet to reveal what it’s working on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Murati peeled back the curtain on the company’s first product a bit in a post on X Tuesday, claiming that the startup plans to unveil its work in the “next couple months,” and it will include a “significant open source offering.” Murati also said the product will be useful for researchers and startups building custom AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Soon, we’ll also share our best science to help the research community better understand frontier AI systems,” said Murati.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Thinking Machines Lab exists to empower humanity through advancing collaborative general intelligence.&lt;/p&gt;&lt;p&gt;We're building multimodal AI that works with how you naturally interact with the world – through conversation, through sight, through the messy way we collaborate. We're…&lt;/p&gt;— Mira Murati (@miramurati) July 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;It’s unclear if Murati means that Thinking Machines Lab will release an open AI model, as some of OpenAI’s other competitors have done to undercut the ChatGPT-maker’s offerings. A Thinking Machines Lab spokesperson declined to comment further.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since Murati launched her venture, Thinking Machines Lab has attracted some of her former coworkers at OpenAI, including John Schulman, Barret Zoph, and Luke Metz. Murati says her company is currently trying to staff up, specifically for people with a track record of “building successful AI-driven products from the ground up,” according to the startup’s website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta reportedly held talks to acquire Thinking Machines Lab in recent months to bolster its superintelligence efforts, but they didn’t progress to a final offer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Thinking Machines Labs is one of a handful of AI startups that investors believe to be a legitimate threat to leading AI model developers today, such as OpenAI, Anthropic, and Google DeepMind. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With billions in funding, Murati may have enough of a war chest to train frontier AI models. Thinking Machines Labs previously struck a deal with Google Cloud to power its AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Surely, Thinking Machines Lab has an uphill battle to catch up with other AI labs. It’s likely banking on novel research breakthroughs to set it apart; however, that’s an increasingly difficult task as Meta, Google DeepMind, Anthropic, and OpenAI invest billions in their own research teams.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-1730510668.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Thinking Machines Lab, the AI startup founded by OpenAI’s former chief technology officer Mira Murati, officially closed a $2 billion seed round led by Andreessen Horowitz on Monday, a company spokesperson told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal, which includes participation from NVIDIA, Accel, ServiceNow, CISCO, AMD, and Jane Street, values the startup at $12 billion, the spokesperson said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Several outlets reported in June that Thinking Machines Lab was close to closing this $2B funding round at a $10 billion valuation, but, apparently, that valuation has shot up in the last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal marks one of the largest seed rounds — or first funding rounds — in Silicon Valley history, representing the massive investor appetite to back promising new AI labs. Thinking Machines Lab is less than a year old and has yet to reveal what it’s working on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Murati peeled back the curtain on the company’s first product a bit in a post on X Tuesday, claiming that the startup plans to unveil its work in the “next couple months,” and it will include a “significant open source offering.” Murati also said the product will be useful for researchers and startups building custom AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Soon, we’ll also share our best science to help the research community better understand frontier AI systems,” said Murati.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Thinking Machines Lab exists to empower humanity through advancing collaborative general intelligence.&lt;/p&gt;&lt;p&gt;We're building multimodal AI that works with how you naturally interact with the world – through conversation, through sight, through the messy way we collaborate. We're…&lt;/p&gt;— Mira Murati (@miramurati) July 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;It’s unclear if Murati means that Thinking Machines Lab will release an open AI model, as some of OpenAI’s other competitors have done to undercut the ChatGPT-maker’s offerings. A Thinking Machines Lab spokesperson declined to comment further.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since Murati launched her venture, Thinking Machines Lab has attracted some of her former coworkers at OpenAI, including John Schulman, Barret Zoph, and Luke Metz. Murati says her company is currently trying to staff up, specifically for people with a track record of “building successful AI-driven products from the ground up,” according to the startup’s website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta reportedly held talks to acquire Thinking Machines Lab in recent months to bolster its superintelligence efforts, but they didn’t progress to a final offer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Thinking Machines Labs is one of a handful of AI startups that investors believe to be a legitimate threat to leading AI model developers today, such as OpenAI, Anthropic, and Google DeepMind. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With billions in funding, Murati may have enough of a war chest to train frontier AI models. Thinking Machines Labs previously struck a deal with Google Cloud to power its AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Surely, Thinking Machines Lab has an uphill battle to catch up with other AI labs. It’s likely banking on novel research breakthroughs to set it apart; however, that’s an increasingly difficult task as Meta, Google DeepMind, Anthropic, and OpenAI invest billions in their own research teams.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/15/mira-muratis-thinking-machines-lab-is-worth-12b-in-seed-round/</guid><pubDate>Tue, 15 Jul 2025 17:59:29 +0000</pubDate></item><item><title>[NEW] CollabLLM: Teaching LLMs to collaborate with users (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="CollabLLM blog hero | flowchart diagram starting in the upper left corner with an icon of two overlapping chat bubbles; arrow pointing right to an LLM network node icon; branching down to show three simulated users; right arrow to a " class="wp-image-1144599" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;Large language models (LLMs) can solve complex puzzles in seconds, yet they sometimes struggle over simple conversations. When these AI tools make assumptions, overlook key details, or neglect to ask clarifying questions, the result can erode trust and derail real-world interactions, where nuance is everything.&lt;/p&gt;



&lt;p&gt;A key reason these models behave this way lies in how they’re trained and evaluated. Most benchmarks use isolated, single-turn prompts with clear instructions. Training methods tend to optimize for the model’s next response, not its contribution to a successful, multi-turn exchange. But real-world interaction is dynamic and collaborative. It relies on context, clarification, and shared understanding.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="user-centric-approach-to-training"&gt;User-centric approach to training&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;To address this, we’re exploring ways to train LLMs with users in mind. Our approach places models in simulated environments that reflect the back-and-forth nature of real conversations. Through reinforcement learning, these models improve through trial and error, for example, learning when to ask questions and how to adapt tone and communication style to different situations. This user-centric approach helps bridge the gap between how LLMs are typically trained and how people actually use them.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is the concept behind CollabLLM&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, recipient of an ICML&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; Outstanding Paper Award&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. This training framework helps LLMs improve through simulated multi-turn interactions, as illustrated in Figure 1. The core insight behind CollabLLM is simple: in a constructive collaboration, the value of a response isn’t just in its immediate usefulness, but in how it contributes to the overall success of the conversation. A clarifying question might seem like a delay but often leads to better outcomes. A quick answer might appear useful but can create confusion or derail the interaction.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1 compares two training strategies for Large Language Models: a standard non-collaborative method and our proposed collaborative method (CollabLLM). On the left, the standard method uses a preference/reward dataset with single-turn evaluations, resulting in a model that causes ineffective interactions. The user gives feedback, but the model generates multiple verbose and unsatisfactory responses, requiring many back-and-forth turns. On the right, CollabLLM incorporates collaborative simulation during training, using multi-turn interactions and reinforcement learning. After training, the model asks clarifying questions (e.g., tone preferences), receives focused user input, and quickly generates tailored, high-impact responses." class="wp-image-1144594" height="486" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1.png" width="1365" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Diagram comparing two training approaches for LLMs. (a) The standard method lacks user-agent collaboration and uses single-turn rewards, leading to an inefficient conversation. (b) In contrast, CollabLLM simulates multi-turn user-agent interactions during training, enabling it to learn effective collaboration strategies and produce more efficient dialogues.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;CollabLLM puts this collaborative approach into practice with a simulation-based training loop, illustrated in Figure 2. At any point in a conversation, the model generates multiple possible next turns by engaging in a dialogue with a simulated user.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2 illustrates the overall training procedure of CollabLLM. For a given conversational input, the LLM and a user simulator are used to sample conversation continuations. The sampled conversations are then scored using a reward model that utilizes various multiturn-aware rewards, which are then in turn used to update parameters of the LLM." class="wp-image-1144593" height="438" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2.png" width="970" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2: Simulation-based training process used in CollabLLM&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The system uses a sampling method to extend conversations turn by turn, choosing likely responses for each participant (the AI agent or the simulated user), while adding some randomness to vary the conversational paths. The goal is to expose the model to a wide variety of conversational scenarios, helping it learn more effective collaboration strategies.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: AI-POWERED EXPERIENCE&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft research copilot experience&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-copilot-experience"&gt;Discover more about research at Microsoft through our AI-powered experience&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;p&gt;To each simulated conversation, we applied multiturn-aware reward (MR) functions, which assess how the model’s response at the given turn influences the entire trajectory of the conversation. We sampled multiple conversational follow-ups from the model, such as statements, suggestions, questions, and used MR to assign a reward to each based on how well the conversation performed in later turns. We based these scores on automated metrics that reflect key factors like goal completion, conversational efficiency, and user engagement.&lt;/p&gt;



&lt;p&gt;To score the sampled conversations, we used task-specific metrics and metrics from an LLM-as-a-judge framework, which supports efficient and scalable evaluation. For metrics like engagement, a judge model rates each sampled conversation on a scale from 0 to 1.&lt;/p&gt;



&lt;p&gt;The MR of each model response was computed by averaging the scores from the sampled conversations, originating from the model response. Based on the score, the model updates its parameters using established reinforcement learning algorithms like Proximal Policy Optimization (PPO) or Direct Preference Optimization (DPO).&lt;/p&gt;



&lt;p&gt;We tested CollabLLM through a combination of automated and human evaluations, detailed in the paper. One highlight is a user study involving 201 participants in a document co-creation task, shown in Figure 3. We compared CollabLLM to a baseline trained with single-turn rewards and to a second, more proactive baseline prompted to ask clarifying questions and take other proactive steps. CollabLLM outperformed both, producing higher-quality documents, better interaction ratings, and faster task completion times.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3 shows the main results of our user study on a document co-creation task, by comparing a baseline, a proactive baseline, and CollabLLM. CollabLLM outperformed the two baselines. Relative to the best baseline, CollabLLM yields improved document quality rating (+0.12), interaction rating (+0.14), and a reduction of average time spent by the user (-129 seconds)." class="wp-image-1144597" height="492" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3.png" width="1860" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3: Results of the user study in a document co-creation task comparing CollabLLM to a baseline trained with single-turn rewards.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="designing-for-real-world-collaboration"&gt;Designing for real-world collaboration&lt;/h2&gt;



&lt;p&gt;Much of today’s AI research focuses on fully automated tasks, models working without input from or interaction with users. But many real-world applications depend on people in the loop: as users, collaborators, or decision-makers. Designing AI systems that treat user input not as a constraint, but as essential, leads to systems that are more accurate, more helpful, and ultimately more trustworthy.&lt;/p&gt;



&lt;p&gt;This work is driven by a core belief: the future of AI depends not just on intelligence, but on the ability to collaborate effectively. And that means confronting the communication breakdowns in today’s systems.&lt;/p&gt;



&lt;p&gt;We see CollabLLM as a step in that direction, training models to engage in meaningful multi-turn interactions, ask clarifying questions, and adapt to context. In doing so, we can build systems designed to work &lt;em&gt;with&lt;/em&gt; people—not around them.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="CollabLLM blog hero | flowchart diagram starting in the upper left corner with an icon of two overlapping chat bubbles; arrow pointing right to an LLM network node icon; branching down to show three simulated users; right arrow to a " class="wp-image-1144599" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM-BlogHeroFeature-1400x788_Update.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;Large language models (LLMs) can solve complex puzzles in seconds, yet they sometimes struggle over simple conversations. When these AI tools make assumptions, overlook key details, or neglect to ask clarifying questions, the result can erode trust and derail real-world interactions, where nuance is everything.&lt;/p&gt;



&lt;p&gt;A key reason these models behave this way lies in how they’re trained and evaluated. Most benchmarks use isolated, single-turn prompts with clear instructions. Training methods tend to optimize for the model’s next response, not its contribution to a successful, multi-turn exchange. But real-world interaction is dynamic and collaborative. It relies on context, clarification, and shared understanding.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="user-centric-approach-to-training"&gt;User-centric approach to training&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;To address this, we’re exploring ways to train LLMs with users in mind. Our approach places models in simulated environments that reflect the back-and-forth nature of real conversations. Through reinforcement learning, these models improve through trial and error, for example, learning when to ask questions and how to adapt tone and communication style to different situations. This user-centric approach helps bridge the gap between how LLMs are typically trained and how people actually use them.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is the concept behind CollabLLM&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, recipient of an ICML&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; Outstanding Paper Award&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. This training framework helps LLMs improve through simulated multi-turn interactions, as illustrated in Figure 1. The core insight behind CollabLLM is simple: in a constructive collaboration, the value of a response isn’t just in its immediate usefulness, but in how it contributes to the overall success of the conversation. A clarifying question might seem like a delay but often leads to better outcomes. A quick answer might appear useful but can create confusion or derail the interaction.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1 compares two training strategies for Large Language Models: a standard non-collaborative method and our proposed collaborative method (CollabLLM). On the left, the standard method uses a preference/reward dataset with single-turn evaluations, resulting in a model that causes ineffective interactions. The user gives feedback, but the model generates multiple verbose and unsatisfactory responses, requiring many back-and-forth turns. On the right, CollabLLM incorporates collaborative simulation during training, using multi-turn interactions and reinforcement learning. After training, the model asks clarifying questions (e.g., tone preferences), receives focused user input, and quickly generates tailored, high-impact responses." class="wp-image-1144594" height="486" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig1.png" width="1365" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Diagram comparing two training approaches for LLMs. (a) The standard method lacks user-agent collaboration and uses single-turn rewards, leading to an inefficient conversation. (b) In contrast, CollabLLM simulates multi-turn user-agent interactions during training, enabling it to learn effective collaboration strategies and produce more efficient dialogues.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;CollabLLM puts this collaborative approach into practice with a simulation-based training loop, illustrated in Figure 2. At any point in a conversation, the model generates multiple possible next turns by engaging in a dialogue with a simulated user.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2 illustrates the overall training procedure of CollabLLM. For a given conversational input, the LLM and a user simulator are used to sample conversation continuations. The sampled conversations are then scored using a reward model that utilizes various multiturn-aware rewards, which are then in turn used to update parameters of the LLM." class="wp-image-1144593" height="438" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig2.png" width="970" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2: Simulation-based training process used in CollabLLM&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The system uses a sampling method to extend conversations turn by turn, choosing likely responses for each participant (the AI agent or the simulated user), while adding some randomness to vary the conversational paths. The goal is to expose the model to a wide variety of conversational scenarios, helping it learn more effective collaboration strategies.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: AI-POWERED EXPERIENCE&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft research copilot experience&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-copilot-experience"&gt;Discover more about research at Microsoft through our AI-powered experience&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;p&gt;To each simulated conversation, we applied multiturn-aware reward (MR) functions, which assess how the model’s response at the given turn influences the entire trajectory of the conversation. We sampled multiple conversational follow-ups from the model, such as statements, suggestions, questions, and used MR to assign a reward to each based on how well the conversation performed in later turns. We based these scores on automated metrics that reflect key factors like goal completion, conversational efficiency, and user engagement.&lt;/p&gt;



&lt;p&gt;To score the sampled conversations, we used task-specific metrics and metrics from an LLM-as-a-judge framework, which supports efficient and scalable evaluation. For metrics like engagement, a judge model rates each sampled conversation on a scale from 0 to 1.&lt;/p&gt;



&lt;p&gt;The MR of each model response was computed by averaging the scores from the sampled conversations, originating from the model response. Based on the score, the model updates its parameters using established reinforcement learning algorithms like Proximal Policy Optimization (PPO) or Direct Preference Optimization (DPO).&lt;/p&gt;



&lt;p&gt;We tested CollabLLM through a combination of automated and human evaluations, detailed in the paper. One highlight is a user study involving 201 participants in a document co-creation task, shown in Figure 3. We compared CollabLLM to a baseline trained with single-turn rewards and to a second, more proactive baseline prompted to ask clarifying questions and take other proactive steps. CollabLLM outperformed both, producing higher-quality documents, better interaction ratings, and faster task completion times.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3 shows the main results of our user study on a document co-creation task, by comparing a baseline, a proactive baseline, and CollabLLM. CollabLLM outperformed the two baselines. Relative to the best baseline, CollabLLM yields improved document quality rating (+0.12), interaction rating (+0.14), and a reduction of average time spent by the user (-129 seconds)." class="wp-image-1144597" height="492" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/CollabLLM_fig3.png" width="1860" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3: Results of the user study in a document co-creation task comparing CollabLLM to a baseline trained with single-turn rewards.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="designing-for-real-world-collaboration"&gt;Designing for real-world collaboration&lt;/h2&gt;



&lt;p&gt;Much of today’s AI research focuses on fully automated tasks, models working without input from or interaction with users. But many real-world applications depend on people in the loop: as users, collaborators, or decision-makers. Designing AI systems that treat user input not as a constraint, but as essential, leads to systems that are more accurate, more helpful, and ultimately more trustworthy.&lt;/p&gt;



&lt;p&gt;This work is driven by a core belief: the future of AI depends not just on intelligence, but on the ability to collaborate effectively. And that means confronting the communication breakdowns in today’s systems.&lt;/p&gt;



&lt;p&gt;We see CollabLLM as a step in that direction, training models to engage in meaningful multi-turn interactions, ask clarifying questions, and adapt to context. In doing so, we can build systems designed to work &lt;em&gt;with&lt;/em&gt; people—not around them.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/collabllm-teaching-llms-to-collaborate-with-users/</guid><pubDate>Tue, 15 Jul 2025 18:00:00 +0000</pubDate></item><item><title>[NEW] AI Safety Newsletter #59: EU Publishes General-Purpose AI Code of Practice (AI Safety Newsletter)</title><link>https://newsletter.safe.ai/p/ai-safety-newsletter-59-eu-publishes</link><description>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the&lt;/span&gt;&lt;a href="https://www.safe.ai/" rel="rel"&gt; Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: The EU published a General-Purpose AI Code of Practice for AI providers, and Meta is spending billions revamping its superintelligence development efforts.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;In June 2024, the EU adopted the &lt;/span&gt;&lt;a href="https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng" rel="rel"&gt;AI Act&lt;/a&gt;&lt;span&gt;, which remains the world’s most significant law regulating AI systems. The Act bans some uses of AI like social scoring and predictive policing and limits other “high risk” uses such as generating credit scores or evaluating educational outcomes. It also regulates general-purpose AI (GPAI) systems, imposing transparency requirements, copyright protection policies, and safety and security standards for models that pose systemic risk (defined as those trained using ≥10&lt;/span&gt;&lt;sup&gt;25&lt;/sup&gt;&lt;span&gt; FLOPs).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;However, these safety and security standards are ambiguous—for example, the Act requires providers of GPAIs to “assess and mitigate possible systemic risks,” but does not specify how to do so. This ambiguity may leave GPAI developers uncertain whether they are complying with the AI Act, and regulators uncertain whether GPAI developers are implementing adequate safety and security practices.&lt;/p&gt;&lt;p&gt;&lt;span&gt;To address this problem, on July 10th 2025, the EU published the &lt;/span&gt;&lt;a href="https://digital-strategy.ec.europa.eu/en/policies/contents-code-gpai" rel="rel"&gt;General-Purpose AI Code of Practice&lt;/a&gt;&lt;span&gt;. The Code is a voluntary set of guidelines to comply with the AI Act’s GPAI obligations before they take effect on August 2nd, 2025.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The Code of Practice establishes safety and security requirements for GPAI providers.&lt;/strong&gt;&lt;span&gt; The Code consists of three chapters—Transparency, Copyright, and Safety and Security. The last chapter, Safety and Security, only applies to the handful of companies whose models cross the Act’s systemic-risk threshold.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The Safety and Security chapter requires GPAI providers to create frameworks outlining how they will identify and mitigate risks throughout a model's lifecycle. These frameworks must follow a structured approach to risk assessment—for each major decision (such as new model releases), providers must follow the following three steps:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Identification&lt;/strong&gt;&lt;span&gt;. Companies must identify potential systemic risks. Four categories of systemic risks require special attention: CBRN (chemical, biological, radiological, nuclear) risks, loss of control, cyber offense capabilities, and harmful manipulation.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Analysis&lt;/strong&gt;&lt;span&gt;. Each risk must be analyzed—for example, by using model evaluations. When the risk is greater than those posed by models already on the EU market, providers may be required to involve third-party evaluators.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Determination&lt;/strong&gt;&lt;span&gt;. Companies must determine whether the risks they identified are acceptable before proceeding. If not, they must implement safety and security mitigations.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!glEy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30e7d8d-65ae-4c7c-aa81-f7e56c8b8c96_1360x966.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="966" src="https://substackcdn.com/image/fetch/$s_!glEy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30e7d8d-65ae-4c7c-aa81-f7e56c8b8c96_1360x966.png" width="1360" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Continuous monitoring, incident reporting timelines, and future-proofing&lt;/strong&gt;&lt;span&gt;. The Code requires continuous monitoring after models are deployed, and strict incident reporting timelines. For serious incidents, companies must file initial reports within days. It also acknowledges that current safety methods may prove insufficient as AI advances. Companies can implement alternative approaches if they demonstrate equal or superior safety outcomes.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI providers will likely comply with the Code&lt;/strong&gt;&lt;span&gt;. While the Code is technically voluntary, compliance with the EU AI Act is not. Providers are incentivized to reduce their legal uncertainty by complying with the Code, since EU regulators will assume that providers who comply with the Code are also Act-compliant. &lt;/span&gt;&lt;a href="https://openai.com/global-affairs/eu-code-of-practice/" rel="rel"&gt;OpenAI&lt;/a&gt;&lt;span&gt; and &lt;/span&gt;&lt;a href="https://www.linkedin.com/posts/oc%C3%A9ane-herrero-b61bb9124_frances-mistral-will-sign-new-eu-ai-code-activity-7349130295532539904-UOh7/" rel="rel"&gt;Mistral&lt;/a&gt;&lt;span&gt; have already indicated they intend to comply with the Code.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The Code formalizes some existing industry practices advocated for by parts of the AI safety community, such as publishing &lt;/span&gt;&lt;a href="https://metr.org/faisc" rel="rel"&gt;safety frameworks&lt;/a&gt;&lt;span&gt; (or: responsible scaling policies) and system cards. Since frontier AI companies are very likely to comply with the Code, securing similar legislation in the US may no longer be a priority for AI safety.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta &lt;/span&gt;&lt;a href="https://apnews.com/article/meta-ai-superintelligence-agi-scale-alexandr-wang-4b55aabf7ea018e38ffdccb66e37cf26" rel="rel"&gt;spent&lt;/a&gt;&lt;span&gt; $14.3 billion for a 49 percent stake in Scale AI, starting “&lt;/span&gt;&lt;a href="https://www.bloomberg.com/news/articles/2025-06-30/zuckerberg-announces-meta-superintelligence-effort-more-hires" rel="rel"&gt;Meta Superintelligence Labs&lt;/a&gt;&lt;span&gt;.”&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;The deal folds every AI group at Meta into one division and puts Scale founder Alexandr Wang—now chief AI officer—to lead Meta’s superintelligence development efforts.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Meta makes nine-figure pay offers to poach top AI talent. &lt;/strong&gt;&lt;span&gt;Reuters reported that Meta has offered “up to $100 million” to OpenAI staff, a tactic CEO Sam Altman &lt;/span&gt;&lt;a href="https://www.wired.com/story/sam-altman-meta-ai-talent-poaching-spree-leaked-messages/" rel="rel"&gt;criticized&lt;/a&gt;&lt;span&gt;. SemiAnalysis &lt;/span&gt;&lt;a href="https://semianalysis.com/2025/07/11/meta-superintelligence-leadership-compute-talent-and-data/" rel="rel"&gt;estimates&lt;/a&gt;&lt;span&gt; Meta is offering typical leadership packages of around $200 million over four years. For example, Bloomberg &lt;/span&gt;&lt;a href="https://www.bloomberg.com/news/articles/2025-07-09/meta-poached-apple-s-pang-with-pay-package-over-200-million" rel="rel"&gt;reports&lt;/a&gt;&lt;span&gt; that Apple’s foundation-models chief Ruoming Pang left for Meta after a package “well north of $200 million.” Other early recruits span OpenAI, DeepMind, and Anthropic.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Meta has created a resourced competitor in the superintelligence race. &lt;/strong&gt;&lt;span&gt;In response to &lt;/span&gt;&lt;a href="https://www.reuters.com/business/zuckerbergs-meta-superintelligence-labs-poaches-top-ai-talent-silicon-valley-2025-07-08/" rel="rel"&gt;Meta’s hiring efforts&lt;/a&gt;&lt;span&gt;,&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;OpenAI, Google, and Anthropic have already raised pay bands, and smaller labs might be priced out of frontier work.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta is also raising its compute expenditures. It &lt;/span&gt;&lt;a href="https://www.datacenterdynamics.com/en/news/meta-raises-ai-data-center-capex-forecast-to-up-to-72bn-blames-trump-tariffs-for-increased-cost/" rel="rel"&gt;lifted&lt;/a&gt;&lt;span&gt; its 2025 capital-expenditure forecast to $72 billin, and SemiAnalysis &lt;/span&gt;&lt;a href="https://semianalysis.com/2025/07/11/meta-superintelligence-leadership-compute-talent-and-data/" rel="rel"&gt;describes&lt;/a&gt;&lt;span&gt; new, temporary “tent” campuses that can house one-gigawatt GPU clusters.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Government&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;California Senator Scott Wiener expanded &lt;/span&gt;&lt;a href="https://legiscan.com/CA/text/SB53/2025" rel="rel"&gt;SB 53&lt;/a&gt;&lt;span&gt;, his AI safety bill, to include &lt;/span&gt;&lt;a href="https://sd11.senate.ca.gov/news/senator-wiener-expands-ai-bill-landmark-transparency-measure-based-recommendations-governors" rel="rel"&gt;new transparency measures&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Commerce Department &lt;/span&gt;&lt;a href="https://www.commerce.gov/sites/default/files/2025-06/BIS-FY2026-Congressional-Budget-Submission.pdf" rel="rel"&gt;requested&lt;/a&gt;&lt;span&gt; additional funding for the Bureau of Industry and Security (BIS) to enhance its enforcement of export controls.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Missouri’s Attorney General is &lt;/span&gt;&lt;a href="https://www.theverge.com/news/704851/missouri-ag-andrew-bailey-investigation-ai-chatbots-trump-ranking" rel="rel"&gt;investigating&lt;/a&gt;&lt;span&gt; AI chatbots for alleged political bias against Donald Trump.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The BRICS nations (an international group founded by Brasil, Russia, India, China, and South Africa that serves as a forum for political coordination for the Global South) signed a &lt;/span&gt;&lt;a href="https://brics.br/en/news/brics-summit-signs-historic-commitment-in-rio-for-more-inclusive-and-sustainable-governance" rel="rel"&gt;commitment&lt;/a&gt;&lt;span&gt; that included language on mitigating AI risks.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bernie Sanders expressed concern about loss of control risks in an &lt;/span&gt;&lt;a href="https://gizmodo.com/bernie-sanders-reveals-the-ai-doomsday-scenario-that-worries-top-experts-2000628611" rel="rel"&gt;interview&lt;/a&gt;&lt;span&gt; with Gizmodo.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Industry&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Last week, Grok was &lt;/span&gt;&lt;a href="https://www.forbes.com/sites/tylerroush/2025/07/09/elon-musk-claims-grok-manipulated-by-x-users-after-chatbot-praises-hitler/" rel="rel"&gt;explicitly antisemetic&lt;/a&gt;&lt;span&gt; on X. The behavior came after Grok’s system prompt was (&lt;/span&gt;&lt;a href="https://x.com/grok/status/1943916977481036128" rel="rel"&gt;perhaps unintentionally&lt;/a&gt;&lt;span&gt;) updated, among other changes telling Grok not to be “afraid to offend people who are politically correct.”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;xAI also released &lt;/span&gt;&lt;a href="https://x.ai/news/grok-4" rel="rel"&gt;Grok 4&lt;/a&gt;&lt;span&gt;, which achieves state-of-the-art scores on benchmarks including Humanity’s Last Exam and ARC-AGI-2.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;a href="https://www.politico.com/news/2025/07/10/openai-accuses-nonprofit-elon-musk-lobbying-violations-00448226" rel="rel"&gt;accused&lt;/a&gt;&lt;span&gt; the Coalition for AI Nonprofit Integrity of lobbying violations amid an ongoing legal dispute with Elon Musk.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic &lt;/span&gt;&lt;a href="https://www.anthropic.com/news/the-need-for-transparency-in-frontier-ai" rel="rel"&gt;published&lt;/a&gt;&lt;span&gt; a blog post on the need for transparency in frontier AI development.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI is set to &lt;/span&gt;&lt;a href="https://www.theverge.com/notepad-microsoft-newsletter/702848/openai-open-language-model-o3-mini-notepad" rel="rel"&gt;release&lt;/a&gt;&lt;span&gt; an open-weight version similar to its o3-mini model.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI’s deal to acquire Windsurf &lt;/span&gt;&lt;a href="https://www.theverge.com/openai/705999/google-windsurf-ceo-openai" rel="rel"&gt;failed&lt;/a&gt;&lt;span&gt;, and instead Google hired Windsurf’s CEO to lead its AI products division and Cognition AI &lt;/span&gt;&lt;a href="https://www.nytimes.com/2025/07/14/technology/cognition-ai-windsurf.html" rel="rel"&gt;acquired&lt;/a&gt;&lt;span&gt; the company.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Civil Society&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Henry Papadatos &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/how-the-eus-code-of-practice-advances-ai-safety" rel="rel"&gt;discusses&lt;/a&gt;&lt;span&gt; how the EU’s GPAI Code of Practice advances AI safety.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Chris Miller &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/us-chip-export-controls-china-ai" rel="rel"&gt;analyzes&lt;/a&gt;&lt;span&gt; how US export controls have (and haven’t) curbed Chinese AI.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The University of Oxford’s AI Governance Initiative &lt;/span&gt;&lt;a href="https://aigi.ox.ac.uk/publications/verification-for-international-ai-governance/" rel="rel"&gt;published&lt;/a&gt;&lt;span&gt; a report on verification for international AI agreements.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A METR &lt;/span&gt;&lt;a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/" rel="rel"&gt;study&lt;/a&gt;&lt;span&gt; found that experienced developers work 19% more slowly when using AI tools.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CAIS is &lt;/span&gt;&lt;a href="https://icml.cc/virtual/2025/49700" rel="rel"&gt;hosting&lt;/a&gt;&lt;span&gt; an AI Safety Social at ICML.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-59-eu-publishes?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</description><content:encoded>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the&lt;/span&gt;&lt;a href="https://www.safe.ai/" rel="rel"&gt; Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: The EU published a General-Purpose AI Code of Practice for AI providers, and Meta is spending billions revamping its superintelligence development efforts.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;In June 2024, the EU adopted the &lt;/span&gt;&lt;a href="https://eur-lex.europa.eu/eli/reg/2024/1689/oj/eng" rel="rel"&gt;AI Act&lt;/a&gt;&lt;span&gt;, which remains the world’s most significant law regulating AI systems. The Act bans some uses of AI like social scoring and predictive policing and limits other “high risk” uses such as generating credit scores or evaluating educational outcomes. It also regulates general-purpose AI (GPAI) systems, imposing transparency requirements, copyright protection policies, and safety and security standards for models that pose systemic risk (defined as those trained using ≥10&lt;/span&gt;&lt;sup&gt;25&lt;/sup&gt;&lt;span&gt; FLOPs).&lt;/span&gt;&lt;/p&gt;&lt;p&gt;However, these safety and security standards are ambiguous—for example, the Act requires providers of GPAIs to “assess and mitigate possible systemic risks,” but does not specify how to do so. This ambiguity may leave GPAI developers uncertain whether they are complying with the AI Act, and regulators uncertain whether GPAI developers are implementing adequate safety and security practices.&lt;/p&gt;&lt;p&gt;&lt;span&gt;To address this problem, on July 10th 2025, the EU published the &lt;/span&gt;&lt;a href="https://digital-strategy.ec.europa.eu/en/policies/contents-code-gpai" rel="rel"&gt;General-Purpose AI Code of Practice&lt;/a&gt;&lt;span&gt;. The Code is a voluntary set of guidelines to comply with the AI Act’s GPAI obligations before they take effect on August 2nd, 2025.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The Code of Practice establishes safety and security requirements for GPAI providers.&lt;/strong&gt;&lt;span&gt; The Code consists of three chapters—Transparency, Copyright, and Safety and Security. The last chapter, Safety and Security, only applies to the handful of companies whose models cross the Act’s systemic-risk threshold.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The Safety and Security chapter requires GPAI providers to create frameworks outlining how they will identify and mitigate risks throughout a model's lifecycle. These frameworks must follow a structured approach to risk assessment—for each major decision (such as new model releases), providers must follow the following three steps:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Identification&lt;/strong&gt;&lt;span&gt;. Companies must identify potential systemic risks. Four categories of systemic risks require special attention: CBRN (chemical, biological, radiological, nuclear) risks, loss of control, cyber offense capabilities, and harmful manipulation.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Analysis&lt;/strong&gt;&lt;span&gt;. Each risk must be analyzed—for example, by using model evaluations. When the risk is greater than those posed by models already on the EU market, providers may be required to involve third-party evaluators.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Determination&lt;/strong&gt;&lt;span&gt;. Companies must determine whether the risks they identified are acceptable before proceeding. If not, they must implement safety and security mitigations.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!glEy!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30e7d8d-65ae-4c7c-aa81-f7e56c8b8c96_1360x966.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="966" src="https://substackcdn.com/image/fetch/$s_!glEy!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd30e7d8d-65ae-4c7c-aa81-f7e56c8b8c96_1360x966.png" width="1360" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Continuous monitoring, incident reporting timelines, and future-proofing&lt;/strong&gt;&lt;span&gt;. The Code requires continuous monitoring after models are deployed, and strict incident reporting timelines. For serious incidents, companies must file initial reports within days. It also acknowledges that current safety methods may prove insufficient as AI advances. Companies can implement alternative approaches if they demonstrate equal or superior safety outcomes.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI providers will likely comply with the Code&lt;/strong&gt;&lt;span&gt;. While the Code is technically voluntary, compliance with the EU AI Act is not. Providers are incentivized to reduce their legal uncertainty by complying with the Code, since EU regulators will assume that providers who comply with the Code are also Act-compliant. &lt;/span&gt;&lt;a href="https://openai.com/global-affairs/eu-code-of-practice/" rel="rel"&gt;OpenAI&lt;/a&gt;&lt;span&gt; and &lt;/span&gt;&lt;a href="https://www.linkedin.com/posts/oc%C3%A9ane-herrero-b61bb9124_frances-mistral-will-sign-new-eu-ai-code-activity-7349130295532539904-UOh7/" rel="rel"&gt;Mistral&lt;/a&gt;&lt;span&gt; have already indicated they intend to comply with the Code.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The Code formalizes some existing industry practices advocated for by parts of the AI safety community, such as publishing &lt;/span&gt;&lt;a href="https://metr.org/faisc" rel="rel"&gt;safety frameworks&lt;/a&gt;&lt;span&gt; (or: responsible scaling policies) and system cards. Since frontier AI companies are very likely to comply with the Code, securing similar legislation in the US may no longer be a priority for AI safety.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta &lt;/span&gt;&lt;a href="https://apnews.com/article/meta-ai-superintelligence-agi-scale-alexandr-wang-4b55aabf7ea018e38ffdccb66e37cf26" rel="rel"&gt;spent&lt;/a&gt;&lt;span&gt; $14.3 billion for a 49 percent stake in Scale AI, starting “&lt;/span&gt;&lt;a href="https://www.bloomberg.com/news/articles/2025-06-30/zuckerberg-announces-meta-superintelligence-effort-more-hires" rel="rel"&gt;Meta Superintelligence Labs&lt;/a&gt;&lt;span&gt;.”&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;The deal folds every AI group at Meta into one division and puts Scale founder Alexandr Wang—now chief AI officer—to lead Meta’s superintelligence development efforts.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Meta makes nine-figure pay offers to poach top AI talent. &lt;/strong&gt;&lt;span&gt;Reuters reported that Meta has offered “up to $100 million” to OpenAI staff, a tactic CEO Sam Altman &lt;/span&gt;&lt;a href="https://www.wired.com/story/sam-altman-meta-ai-talent-poaching-spree-leaked-messages/" rel="rel"&gt;criticized&lt;/a&gt;&lt;span&gt;. SemiAnalysis &lt;/span&gt;&lt;a href="https://semianalysis.com/2025/07/11/meta-superintelligence-leadership-compute-talent-and-data/" rel="rel"&gt;estimates&lt;/a&gt;&lt;span&gt; Meta is offering typical leadership packages of around $200 million over four years. For example, Bloomberg &lt;/span&gt;&lt;a href="https://www.bloomberg.com/news/articles/2025-07-09/meta-poached-apple-s-pang-with-pay-package-over-200-million" rel="rel"&gt;reports&lt;/a&gt;&lt;span&gt; that Apple’s foundation-models chief Ruoming Pang left for Meta after a package “well north of $200 million.” Other early recruits span OpenAI, DeepMind, and Anthropic.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Meta has created a resourced competitor in the superintelligence race. &lt;/strong&gt;&lt;span&gt;In response to &lt;/span&gt;&lt;a href="https://www.reuters.com/business/zuckerbergs-meta-superintelligence-labs-poaches-top-ai-talent-silicon-valley-2025-07-08/" rel="rel"&gt;Meta’s hiring efforts&lt;/a&gt;&lt;span&gt;,&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;span&gt;OpenAI, Google, and Anthropic have already raised pay bands, and smaller labs might be priced out of frontier work.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Meta is also raising its compute expenditures. It &lt;/span&gt;&lt;a href="https://www.datacenterdynamics.com/en/news/meta-raises-ai-data-center-capex-forecast-to-up-to-72bn-blames-trump-tariffs-for-increased-cost/" rel="rel"&gt;lifted&lt;/a&gt;&lt;span&gt; its 2025 capital-expenditure forecast to $72 billin, and SemiAnalysis &lt;/span&gt;&lt;a href="https://semianalysis.com/2025/07/11/meta-superintelligence-leadership-compute-talent-and-data/" rel="rel"&gt;describes&lt;/a&gt;&lt;span&gt; new, temporary “tent” campuses that can house one-gigawatt GPU clusters.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Government&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;California Senator Scott Wiener expanded &lt;/span&gt;&lt;a href="https://legiscan.com/CA/text/SB53/2025" rel="rel"&gt;SB 53&lt;/a&gt;&lt;span&gt;, his AI safety bill, to include &lt;/span&gt;&lt;a href="https://sd11.senate.ca.gov/news/senator-wiener-expands-ai-bill-landmark-transparency-measure-based-recommendations-governors" rel="rel"&gt;new transparency measures&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The Commerce Department &lt;/span&gt;&lt;a href="https://www.commerce.gov/sites/default/files/2025-06/BIS-FY2026-Congressional-Budget-Submission.pdf" rel="rel"&gt;requested&lt;/a&gt;&lt;span&gt; additional funding for the Bureau of Industry and Security (BIS) to enhance its enforcement of export controls.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Missouri’s Attorney General is &lt;/span&gt;&lt;a href="https://www.theverge.com/news/704851/missouri-ag-andrew-bailey-investigation-ai-chatbots-trump-ranking" rel="rel"&gt;investigating&lt;/a&gt;&lt;span&gt; AI chatbots for alleged political bias against Donald Trump.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The BRICS nations (an international group founded by Brasil, Russia, India, China, and South Africa that serves as a forum for political coordination for the Global South) signed a &lt;/span&gt;&lt;a href="https://brics.br/en/news/brics-summit-signs-historic-commitment-in-rio-for-more-inclusive-and-sustainable-governance" rel="rel"&gt;commitment&lt;/a&gt;&lt;span&gt; that included language on mitigating AI risks.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Bernie Sanders expressed concern about loss of control risks in an &lt;/span&gt;&lt;a href="https://gizmodo.com/bernie-sanders-reveals-the-ai-doomsday-scenario-that-worries-top-experts-2000628611" rel="rel"&gt;interview&lt;/a&gt;&lt;span&gt; with Gizmodo.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Industry&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Last week, Grok was &lt;/span&gt;&lt;a href="https://www.forbes.com/sites/tylerroush/2025/07/09/elon-musk-claims-grok-manipulated-by-x-users-after-chatbot-praises-hitler/" rel="rel"&gt;explicitly antisemetic&lt;/a&gt;&lt;span&gt; on X. The behavior came after Grok’s system prompt was (&lt;/span&gt;&lt;a href="https://x.com/grok/status/1943916977481036128" rel="rel"&gt;perhaps unintentionally&lt;/a&gt;&lt;span&gt;) updated, among other changes telling Grok not to be “afraid to offend people who are politically correct.”&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;xAI also released &lt;/span&gt;&lt;a href="https://x.ai/news/grok-4" rel="rel"&gt;Grok 4&lt;/a&gt;&lt;span&gt;, which achieves state-of-the-art scores on benchmarks including Humanity’s Last Exam and ARC-AGI-2.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;a href="https://www.politico.com/news/2025/07/10/openai-accuses-nonprofit-elon-musk-lobbying-violations-00448226" rel="rel"&gt;accused&lt;/a&gt;&lt;span&gt; the Coalition for AI Nonprofit Integrity of lobbying violations amid an ongoing legal dispute with Elon Musk.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic &lt;/span&gt;&lt;a href="https://www.anthropic.com/news/the-need-for-transparency-in-frontier-ai" rel="rel"&gt;published&lt;/a&gt;&lt;span&gt; a blog post on the need for transparency in frontier AI development.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI is set to &lt;/span&gt;&lt;a href="https://www.theverge.com/notepad-microsoft-newsletter/702848/openai-open-language-model-o3-mini-notepad" rel="rel"&gt;release&lt;/a&gt;&lt;span&gt; an open-weight version similar to its o3-mini model.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI’s deal to acquire Windsurf &lt;/span&gt;&lt;a href="https://www.theverge.com/openai/705999/google-windsurf-ceo-openai" rel="rel"&gt;failed&lt;/a&gt;&lt;span&gt;, and instead Google hired Windsurf’s CEO to lead its AI products division and Cognition AI &lt;/span&gt;&lt;a href="https://www.nytimes.com/2025/07/14/technology/cognition-ai-windsurf.html" rel="rel"&gt;acquired&lt;/a&gt;&lt;span&gt; the company.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Civil Society&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Henry Papadatos &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/how-the-eus-code-of-practice-advances-ai-safety" rel="rel"&gt;discusses&lt;/a&gt;&lt;span&gt; how the EU’s GPAI Code of Practice advances AI safety.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Chris Miller &lt;/span&gt;&lt;a href="https://ai-frontiers.org/articles/us-chip-export-controls-china-ai" rel="rel"&gt;analyzes&lt;/a&gt;&lt;span&gt; how US export controls have (and haven’t) curbed Chinese AI.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;The University of Oxford’s AI Governance Initiative &lt;/span&gt;&lt;a href="https://aigi.ox.ac.uk/publications/verification-for-international-ai-governance/" rel="rel"&gt;published&lt;/a&gt;&lt;span&gt; a report on verification for international AI agreements.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;A METR &lt;/span&gt;&lt;a href="https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/" rel="rel"&gt;study&lt;/a&gt;&lt;span&gt; found that experienced developers work 19% more slowly when using AI tools.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;CAIS is &lt;/span&gt;&lt;a href="https://icml.cc/virtual/2025/49700" rel="rel"&gt;hosting&lt;/a&gt;&lt;span&gt; an AI Safety Social at ICML.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-59-eu-publishes?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://newsletter.safe.ai/p/ai-safety-newsletter-59-eu-publishes</guid><pubDate>Tue, 15 Jul 2025 18:04:57 +0000</pubDate></item></channel></rss>