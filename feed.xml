<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 08 Oct 2025 01:37:56 +0000</lastBuildDate><item><title>OpenAI and the race for AI-driven commerce (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/07/openai-and-the-race-for-ai-driven-commerce/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screen-Shot-2025-10-07-at-9.35.14-AM.jpg?resize=1200,603" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI held its annual dev day on Monday, where the company rolled out its plan to build apps into ChatGPT. The demo was impressive, showing how programs like Spotify and Figma can be called or discovered without leaving the ChatGPT window. With so much of the tech world barreling toward AI integration, OpenAI’s demo was the best picture yet of what an AI-first internet might actually look like, with interfaces like ChatGPT querying information and executing commands directly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re watching closely, you may have noticed that there’s a lot of room in this system for money to change hands. Just last week, the company launched Instant Checkout, an agentic shopping system that serves as payment infrastructure for one-off purchases, plugging in any stores that sell through Shopify, Etsy, or Stripe. Now, apps provide the front-end infrastructure, letting service providers build their own interface into ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In short, OpenAI now has all the pieces in place for AI-driven commerce, establishing ChatGPT as a place customers go to buy and retailers go to sell. It’s a huge new line of business for the company — and one with huge implications for the tech industry. In this world, OpenAI isn’t just competing with Google and Anthropic, but with Amazon and Wal-Mart.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you look at OpenAI’s pending app partners in the launch announcement, you can see how far the vision reaches. ChatGPT will be able to call you a cab through Uber, book a trip on Expedia, call a plumber or locksmith through Thumbtack, and order groceries from Instacart, prepared food from DoorDash, or big-box goods from Target. Without too much more work, ChatGPT could become a portal for most of its users’ discretionary spending.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If it works, this would be worth a lot more than just a $20-a-month subscription. The precise terms of the arrangement are still unclear, but like any app store, OpenAI is well-positioned to get a portion of any money spent on its platform. ChatGPT is also recommending products, drawing on its wealth of data about its users, which tips the balance of power between OpenAI and retailers even more. In Ben Thompson’s terms, ChatGPT becomes a super-aggregator, funneling customers to retailers and providing an entry point for ever-larger amounts of commerce. OpenAI has lots of potential lines of business to pursue, but it’s no exaggeration to say that AI-driven commerce is one of the most lucrative options.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI isn’t the only company with an eye on this prospect. On the same day as the ChatGPT announcement, Adobe released a report predicting that this year’s holiday would be dominated by AI-assisted shopping, with shoppers turning to chatbots instead of search engines to find the best deals available. A separate report from Mastercard dubbed agentic commerce as a “new competitive arena” for finance. Google has already launched its own competing protocol for agentic commerce called AP2, which arrives with a broader scope but less momentum than OpenAI’s version.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The simplest version of AI-driven shopping is using ChatGPT to find products in place of search: If you’re looking for a canvas tennis shoe under $80, ChatGPT can find it for you just as easily as Google Search. But AI systems don’t need to be passive. The AP2 specification includes a provision for agent-initiated purchases, if you want an agent to buy concert tickets as soon as they become available, say, or book a flight as soon as it falls below a certain price. Of course, there could be agents on the other side of the transaction too, negotiating with purchasing agents for the best deal, and willing to bundle goods under the right circumstances. If retailers and customers are willing to take the leap, the changes could extend pretty far beyond a simple “buy” button.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The biggest unanswered question is whether the shopping public will actually be interested. AI shopping is obviously attractive to OpenAI, and companies like Stripe and Mastercard see plenty of benefit in it too — but users haven’t shown much interest in agentic shopping systems beyond simple product searches. But then, they haven’t had a chance to; these systems aren’t even properly available now, and it will be months before the average user can try out a fully agentic shopping system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When they finally do, there will be a lot riding on how they react.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screen-Shot-2025-10-07-at-9.35.14-AM.jpg?resize=1200,603" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI held its annual dev day on Monday, where the company rolled out its plan to build apps into ChatGPT. The demo was impressive, showing how programs like Spotify and Figma can be called or discovered without leaving the ChatGPT window. With so much of the tech world barreling toward AI integration, OpenAI’s demo was the best picture yet of what an AI-first internet might actually look like, with interfaces like ChatGPT querying information and executing commands directly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you’re watching closely, you may have noticed that there’s a lot of room in this system for money to change hands. Just last week, the company launched Instant Checkout, an agentic shopping system that serves as payment infrastructure for one-off purchases, plugging in any stores that sell through Shopify, Etsy, or Stripe. Now, apps provide the front-end infrastructure, letting service providers build their own interface into ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In short, OpenAI now has all the pieces in place for AI-driven commerce, establishing ChatGPT as a place customers go to buy and retailers go to sell. It’s a huge new line of business for the company — and one with huge implications for the tech industry. In this world, OpenAI isn’t just competing with Google and Anthropic, but with Amazon and Wal-Mart.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you look at OpenAI’s pending app partners in the launch announcement, you can see how far the vision reaches. ChatGPT will be able to call you a cab through Uber, book a trip on Expedia, call a plumber or locksmith through Thumbtack, and order groceries from Instacart, prepared food from DoorDash, or big-box goods from Target. Without too much more work, ChatGPT could become a portal for most of its users’ discretionary spending.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If it works, this would be worth a lot more than just a $20-a-month subscription. The precise terms of the arrangement are still unclear, but like any app store, OpenAI is well-positioned to get a portion of any money spent on its platform. ChatGPT is also recommending products, drawing on its wealth of data about its users, which tips the balance of power between OpenAI and retailers even more. In Ben Thompson’s terms, ChatGPT becomes a super-aggregator, funneling customers to retailers and providing an entry point for ever-larger amounts of commerce. OpenAI has lots of potential lines of business to pursue, but it’s no exaggeration to say that AI-driven commerce is one of the most lucrative options.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI isn’t the only company with an eye on this prospect. On the same day as the ChatGPT announcement, Adobe released a report predicting that this year’s holiday would be dominated by AI-assisted shopping, with shoppers turning to chatbots instead of search engines to find the best deals available. A separate report from Mastercard dubbed agentic commerce as a “new competitive arena” for finance. Google has already launched its own competing protocol for agentic commerce called AP2, which arrives with a broader scope but less momentum than OpenAI’s version.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The simplest version of AI-driven shopping is using ChatGPT to find products in place of search: If you’re looking for a canvas tennis shoe under $80, ChatGPT can find it for you just as easily as Google Search. But AI systems don’t need to be passive. The AP2 specification includes a provision for agent-initiated purchases, if you want an agent to buy concert tickets as soon as they become available, say, or book a flight as soon as it falls below a certain price. Of course, there could be agents on the other side of the transaction too, negotiating with purchasing agents for the best deal, and willing to bundle goods under the right circumstances. If retailers and customers are willing to take the leap, the changes could extend pretty far beyond a simple “buy” button.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The biggest unanswered question is whether the shopping public will actually be interested. AI shopping is obviously attractive to OpenAI, and companies like Stripe and Mastercard see plenty of benefit in it too — but users haven’t shown much interest in agentic shopping systems beyond simple product searches. But then, they haven’t had a chance to; these systems aren’t even properly available now, and it will be months before the average user can try out a fully agentic shopping system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When they finally do, there will be a lot riding on how they react.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/07/openai-and-the-race-for-ai-driven-commerce/</guid><pubDate>Tue, 07 Oct 2025 14:24:25 +0000</pubDate></item><item><title>[NEW] ​​Speech-to-Retrieval (S2R): A new approach to voice search (The latest research from Google)</title><link>https://research.google/blog/speech-to-retrieval-s2r-a-new-approach-to-voice-search/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;h2&gt;Evaluating the potential of S2R&lt;/h2&gt;&lt;p&gt;When a traditional ASR system converts audio into a single text string, it may lose contextual cues that could help disambiguate the meaning (i.e., information loss). If the system misinterprets the audio early on, that error is passed along to the search engine, which typically lacks the ability to correct it (i.e., error propagation). As a result, the final search result may not reflect the user's intent.&lt;/p&gt;&lt;p&gt;To investigate this relationship, we conducted an experiment designed to simulate an ideal ASR performance. We began by collecting a representative set of test queries reflecting typical voice search traffic. Crucially, these queries were then manually transcribed by human annotators, effectively creating a "perfect ASR" scenario where the transcription is the absolute truth.&lt;/p&gt;&lt;p&gt;We then established two distinct search systems for comparison (see chart below):&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Cascade ASR represents a typical real-world setup, where speech is converted to text by an automatic speech recognition (ASR) system, and that text is then fed to a retrieval system.&lt;/li&gt;&lt;li&gt;Cascade groundtruth simulates a "perfect" cascade model by sending the flawless ground-truth text directly to the same retrieval system.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The retrieved documents from both systems (cascade ASR and cascade groundtruth) were then presented to human evaluators, or "raters", alongside the original true query. The evaluators were tasked with comparing the search results from both systems, providing a subjective assessment of their respective quality.&lt;/p&gt;&lt;p&gt;We use word error rate (WER) to measure the ASR quality and to measure the search performance, we use mean reciprocal rank (MRR) — a statistical metric for evaluating any process that produces a list of possible responses to a sample of queries, ordered by probability of correctness and calculated as the average of the reciprocals of the rank of the first correct answer across all queries. The difference in MRR and WER between the real-world system and the groundtruth system reveals the potential performance gains across some of the most commonly used voice search languages in the SVQ dataset (shown below).&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;h2&gt;Evaluating the potential of S2R&lt;/h2&gt;&lt;p&gt;When a traditional ASR system converts audio into a single text string, it may lose contextual cues that could help disambiguate the meaning (i.e., information loss). If the system misinterprets the audio early on, that error is passed along to the search engine, which typically lacks the ability to correct it (i.e., error propagation). As a result, the final search result may not reflect the user's intent.&lt;/p&gt;&lt;p&gt;To investigate this relationship, we conducted an experiment designed to simulate an ideal ASR performance. We began by collecting a representative set of test queries reflecting typical voice search traffic. Crucially, these queries were then manually transcribed by human annotators, effectively creating a "perfect ASR" scenario where the transcription is the absolute truth.&lt;/p&gt;&lt;p&gt;We then established two distinct search systems for comparison (see chart below):&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Cascade ASR represents a typical real-world setup, where speech is converted to text by an automatic speech recognition (ASR) system, and that text is then fed to a retrieval system.&lt;/li&gt;&lt;li&gt;Cascade groundtruth simulates a "perfect" cascade model by sending the flawless ground-truth text directly to the same retrieval system.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The retrieved documents from both systems (cascade ASR and cascade groundtruth) were then presented to human evaluators, or "raters", alongside the original true query. The evaluators were tasked with comparing the search results from both systems, providing a subjective assessment of their respective quality.&lt;/p&gt;&lt;p&gt;We use word error rate (WER) to measure the ASR quality and to measure the search performance, we use mean reciprocal rank (MRR) — a statistical metric for evaluating any process that produces a list of possible responses to a sample of queries, ordered by probability of correctness and calculated as the average of the reciprocals of the rank of the first correct answer across all queries. The difference in MRR and WER between the real-world system and the groundtruth system reveals the potential performance gains across some of the most commonly used voice search languages in the SVQ dataset (shown below).&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/speech-to-retrieval-s2r-a-new-approach-to-voice-search/</guid><pubDate>Tue, 07 Oct 2025 15:22:00 +0000</pubDate></item><item><title>Anthropic and IBM announce strategic partnership (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/07/anthropic-and-ibm-announce-strategic-partnership/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/YouTube-Thumb-Text-2-3.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tech behemoth IBM is teaming up with AI research lab Anthropic to&amp;nbsp;bring AI into its software. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Armonk, New York-based&amp;nbsp;IBM announced it will be adding&amp;nbsp;Anthropic’s&amp;nbsp;Claude large language model family into some of its software products on Tuesday. The first&amp;nbsp;product to tap Claude will be IBM’s integrated development environment, which&amp;nbsp;is already available to a select group of customers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;IBM also announced&amp;nbsp;it created a guide in partnership with Anthropic on how enterprises can build, deploy, and&amp;nbsp;maintain&amp;nbsp;enterprise-grade&amp;nbsp;AI agents.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Terms of the deal were not disclosed. TechCrunch reached out to IBM for more information on the future of the partnership. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic has&amp;nbsp;been making&amp;nbsp;a big push into the enterprise sector since it released&amp;nbsp;Claude Enterprise&amp;nbsp;in September 2024.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced a deal to bring Claude to consulting giant Deloitte’s nearly 500,000-person global workforce on Monday. Anthropic said this would be the largest enterprise rollout for the company yet. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A July study conducted by Menlo Ventures found that enterprises prefer Claude models over any other AI models, including OpenAI’s. The study found that usage of OpenAI’s models by enterprises has been declining since 2023.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/YouTube-Thumb-Text-2-3.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tech behemoth IBM is teaming up with AI research lab Anthropic to&amp;nbsp;bring AI into its software. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Armonk, New York-based&amp;nbsp;IBM announced it will be adding&amp;nbsp;Anthropic’s&amp;nbsp;Claude large language model family into some of its software products on Tuesday. The first&amp;nbsp;product to tap Claude will be IBM’s integrated development environment, which&amp;nbsp;is already available to a select group of customers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;IBM also announced&amp;nbsp;it created a guide in partnership with Anthropic on how enterprises can build, deploy, and&amp;nbsp;maintain&amp;nbsp;enterprise-grade&amp;nbsp;AI agents.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Terms of the deal were not disclosed. TechCrunch reached out to IBM for more information on the future of the partnership. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic has&amp;nbsp;been making&amp;nbsp;a big push into the enterprise sector since it released&amp;nbsp;Claude Enterprise&amp;nbsp;in September 2024.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced a deal to bring Claude to consulting giant Deloitte’s nearly 500,000-person global workforce on Monday. Anthropic said this would be the largest enterprise rollout for the company yet. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A July study conducted by Menlo Ventures found that enterprises prefer Claude models over any other AI models, including OpenAI’s. The study found that usage of OpenAI’s models by enterprises has been declining since 2023.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/07/anthropic-and-ibm-announce-strategic-partnership/</guid><pubDate>Tue, 07 Oct 2025 16:22:51 +0000</pubDate></item><item><title>Anthropic plans to open India office, eyes tie-up with billionaire Ambani (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/07/anthropic-plans-to-open-india-office-eyes-tie-up-with-billionaire-ambani/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic co-founder and CEO Dario Amodei is in India this week, with plans to set up an office in Bengaluru and explore a partnership with Mukesh Ambani’s Reliance Industries, TechCrunch has learned. The move signals the AI startup’s push to deepen its presence in its second-largest market after the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amodei is expected to visit Mumbai to meet Ambani and other senior executives at Reliance Industries, India’s most valuable company and the parent of the nation’s top telecom operator, Reliance Jio, people familiar with the matter told TechCrunch. Anthropic has been in discussions with Reliance for some time over a potential partnership to expand access to its Claude AI assistant in India, the people said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;India — the world’s second-largest online market after China, with more than a billion internet subscribers — has emerged as an important growth region for Anthropic. Several Indian AI startups already use its Claude models in their products for both domestic and U.S. clients. India also accounts for the second-highest share of traffic to Claude’s website after the U.S., according to digital intelligence firm Similarweb.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3054946" height="1374" src="https://techcrunch.com/wp-content/uploads/2025/10/anthropic-claude-monthly-visits-india-us_1dabf3.jpg" width="1907" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In August, Reliance Industries partnered with major technology companies, including its existing investors Google and Meta, to build AI infrastructure and enterprise solutions through its new unit, Reliance Intelligence. The Mumbai-headquartered conglomerate had also explored a potential collaboration with OpenAI, which rolled out its under-$5 ChatGPT plan in India earlier this year and announced plans to open an office in New Delhi later in 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That Reliance-OpenAI partnership was expected to be announced during OpenAI CEO Sam Altman’s planned visit to India last month, but Altman ultimately postponed the trip.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reliance Industries did not respond to a request for comment. TechCrunch has also reached out to OpenAI for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside Mumbai, Amodei is visiting New Delhi to meet top lawmakers and senior federal government officials, sources said. He is also expected to meet Indian Prime Minister Narendra Modi, two people familiar with his trip plans told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Later in the week, Amodei will be in Bengaluru to announce Anthropic’s office opening on Thursday, sources told TechCrunch. Anthropic EMEA head Guillaume Princen and startups chief Daniel Delaney are also accompanying him. Prominent venture funds, including Accel and Lightspeed, are also hosting dedicated sessions with Anthropic executives this week to share insights on how developers and startups can leverage Claude for their offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s Claude app, available on iOS and Android, recorded a 48% year-over-year increase in downloads in India in September, reaching about 767,000 installs this year, according to Appfigures. Consumer spending on the app in India surged 572% year-over-year, generating $195,000 in September alone, the data showed.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3054947" height="5632" src="https://techcrunch.com/wp-content/uploads/2025/10/claude-app-spending.png" width="8140" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The India figures, however, remain modest compared with those in the United States, where downloads rose 91% year-over-year and consumer spending jumped 604%. U.S. users spent $2.5 million on the Claude app in September, per Appfigures. Globally, the app saw 74% growth in downloads to 1.01 million and a 546% rise in consumer spending to $5.62 million in the same month.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Unlike OpenAI, which aims to establish a sales and marketing setup while overseeing policy updates from New Delhi, Anthropic plans to target developers and startups with its office in Bengaluru.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3054950" height="5720" src="https://techcrunch.com/wp-content/uploads/2025/10/claude-downloads.png" width="8140" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic is seeing its largest usage coming from India, a founder who works closely with the AI company told TechCrunch, requesting anonymity.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside Anthropic and OpenAI, Perplexity is also looking to tap India’s market. The company has partnered with Indian telecom operator Bharti Airtel to offer its Perplexity Pro subscription to over 360 million Airtel customers for 12 months. The AI search startup has also refined its product for local users, including by launching live earnings call transcripts for Indian stocks to attract more engagement from India.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic did not respond to a request for comment.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic co-founder and CEO Dario Amodei is in India this week, with plans to set up an office in Bengaluru and explore a partnership with Mukesh Ambani’s Reliance Industries, TechCrunch has learned. The move signals the AI startup’s push to deepen its presence in its second-largest market after the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amodei is expected to visit Mumbai to meet Ambani and other senior executives at Reliance Industries, India’s most valuable company and the parent of the nation’s top telecom operator, Reliance Jio, people familiar with the matter told TechCrunch. Anthropic has been in discussions with Reliance for some time over a potential partnership to expand access to its Claude AI assistant in India, the people said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;India — the world’s second-largest online market after China, with more than a billion internet subscribers — has emerged as an important growth region for Anthropic. Several Indian AI startups already use its Claude models in their products for both domestic and U.S. clients. India also accounts for the second-highest share of traffic to Claude’s website after the U.S., according to digital intelligence firm Similarweb.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3054946" height="1374" src="https://techcrunch.com/wp-content/uploads/2025/10/anthropic-claude-monthly-visits-india-us_1dabf3.jpg" width="1907" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In August, Reliance Industries partnered with major technology companies, including its existing investors Google and Meta, to build AI infrastructure and enterprise solutions through its new unit, Reliance Intelligence. The Mumbai-headquartered conglomerate had also explored a potential collaboration with OpenAI, which rolled out its under-$5 ChatGPT plan in India earlier this year and announced plans to open an office in New Delhi later in 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That Reliance-OpenAI partnership was expected to be announced during OpenAI CEO Sam Altman’s planned visit to India last month, but Altman ultimately postponed the trip.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reliance Industries did not respond to a request for comment. TechCrunch has also reached out to OpenAI for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside Mumbai, Amodei is visiting New Delhi to meet top lawmakers and senior federal government officials, sources said. He is also expected to meet Indian Prime Minister Narendra Modi, two people familiar with his trip plans told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Later in the week, Amodei will be in Bengaluru to announce Anthropic’s office opening on Thursday, sources told TechCrunch. Anthropic EMEA head Guillaume Princen and startups chief Daniel Delaney are also accompanying him. Prominent venture funds, including Accel and Lightspeed, are also hosting dedicated sessions with Anthropic executives this week to share insights on how developers and startups can leverage Claude for their offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s Claude app, available on iOS and Android, recorded a 48% year-over-year increase in downloads in India in September, reaching about 767,000 installs this year, according to Appfigures. Consumer spending on the app in India surged 572% year-over-year, generating $195,000 in September alone, the data showed.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3054947" height="5632" src="https://techcrunch.com/wp-content/uploads/2025/10/claude-app-spending.png" width="8140" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The India figures, however, remain modest compared with those in the United States, where downloads rose 91% year-over-year and consumer spending jumped 604%. U.S. users spent $2.5 million on the Claude app in September, per Appfigures. Globally, the app saw 74% growth in downloads to 1.01 million and a 546% rise in consumer spending to $5.62 million in the same month.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Unlike OpenAI, which aims to establish a sales and marketing setup while overseeing policy updates from New Delhi, Anthropic plans to target developers and startups with its office in Bengaluru.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3054950" height="5720" src="https://techcrunch.com/wp-content/uploads/2025/10/claude-downloads.png" width="8140" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic is seeing its largest usage coming from India, a founder who works closely with the AI company told TechCrunch, requesting anonymity.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside Anthropic and OpenAI, Perplexity is also looking to tap India’s market. The company has partnered with Indian telecom operator Bharti Airtel to offer its Perplexity Pro subscription to over 360 million Airtel customers for 12 months. The AI search startup has also refined its product for local users, including by launching live earnings call transcripts for Indian stocks to attract more engagement from India.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic did not respond to a request for comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/07/anthropic-plans-to-open-india-office-eyes-tie-up-with-billionaire-ambani/</guid><pubDate>Tue, 07 Oct 2025 16:27:15 +0000</pubDate></item><item><title>AI toys are all the rage in China—and now they’re appearing on shelves in the US too (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/07/1125191/ai-toys-in-china/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Screenshot-2025-10-06-161500.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Kids have always played with and talked to stuffed animals. But now their toys can talk back, thanks to a wave of companies that are fitting children’s playthings with chatbots and voice assistants.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s a trend that has particularly taken off in China: A recent report by the Shenzhen Toy Industry Association and JD.com predicts that the sector will surpass ¥100 billion ($14 billion) by 2030, growing faster than almost any other branch of consumer AI. According to the Chinese corporation registration database Qichamao, there are over 1,500 AI toy companies operating in China as of October 2025.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;One of the latest entrants to the market is a toy called BubblePal, a device the size of a Ping-Pong ball that clips onto a child’s favorite stuffed animal and makes it “talk.” The gadget comes with a smartphone app that lets parents switch between 39 characters, from Disney’s Elsa to the Chinese cartoon classic Nezha. It costs $149, and 200,000 units have been sold since it launched last summer. It’s made by the Chinese company Haivivi and runs on DeepSeek’s large language models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Other companies are approaching the market differently. FoloToy, another Chinese startup, allows parents to customize a bear, bunny, or cactus toy by training it to speak with their own voice and speech pattern. FoloToy reported selling more than 20,000 of its AI-equipped plush toys in the first quarter of 2025, nearly equaling its total sales for 2024, and it projects sales of 300,000 units this year.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;But Chinese AI toy companies have their sights set beyond the nation’s borders. BubblePal was launched in the US in December 2024 and is now also available in Canada and the UK. And FoloToy is now sold in more than 10 countries, including the US, UK, Canada, Brazil, Germany, and Thailand. Rui Ma, a China tech analyst at AlphaWatch.AI, says that AI devices for children make particular sense in China, where there is already a well-established market for kid-focused educational electronics—a market that does not exist to the same extent globally. FoloToy’s CEO, Kong Miaomiao, told the Chinese outlet Baijing Chuhai that outside China, his firm is still just “reaching early adopters who are curious about AI.”&lt;/p&gt;  &lt;p&gt;China’s AI toy boom builds on decades of consumer electronics designed specifically for children. As early as the 1990s, companies such as BBK popularized devices like electronic dictionaries and “study machines,” marketed to parents as educational aids. These toy-electronics hybrids read aloud, tell interactive stories, and simulate the role of a playmate.&lt;/p&gt; 
 &lt;p&gt;The competition is heating up, however—US companies have also started to develop and sell AI toys. The musician Grimes helped to create Grok, a plush toy that chats with kids and adapts to their personality. Toy giant Mattel is working with OpenAI to bring conversational AI to brands like Barbie and Hot Wheels, with the first products expected to be announced later this year.&lt;/p&gt;  &lt;p&gt;However, reviews from parents who’ve bought AI toys in China are mixed. Although many appreciate the fact they are screen-free and come with strict parental controls, some parents say their AI capabilities can be glitchy, leading children to tire of them easily.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Penny Huang, based in Beijing, bought a BubblePal for her five-year-old daughter, who is cared for mostly by grandparents. Huang hoped that the toy could make her less lonely and reduce her constant requests to play with adults’ smartphones. But the novelty wore off quickly.&lt;/p&gt;  &lt;p&gt;“The responses are too long and wordy. My daughter quickly loses patience,” says Huang, “It [the role-play] doesn’t feel immersive—just a voice that sometimes sounds out of place.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Another parent who uses BubblePal, Hongyi Li, found the voice recognition lagging: “Children’s speech is fragmented and unclear. The toy frequently interrupts my kid or misunderstands what she says. It also still requires pressing a button to interact, which can be hard for toddlers.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Huang recently listed her BubblePal for sale on Xianyu, a secondhand marketplace. “This is just like one of the many toys that my daughter plays for five minutes then gets tired of,” she says. “She wants to play with my phone more than anything else.”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Screenshot-2025-10-06-161500.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Kids have always played with and talked to stuffed animals. But now their toys can talk back, thanks to a wave of companies that are fitting children’s playthings with chatbots and voice assistants.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s a trend that has particularly taken off in China: A recent report by the Shenzhen Toy Industry Association and JD.com predicts that the sector will surpass ¥100 billion ($14 billion) by 2030, growing faster than almost any other branch of consumer AI. According to the Chinese corporation registration database Qichamao, there are over 1,500 AI toy companies operating in China as of October 2025.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;One of the latest entrants to the market is a toy called BubblePal, a device the size of a Ping-Pong ball that clips onto a child’s favorite stuffed animal and makes it “talk.” The gadget comes with a smartphone app that lets parents switch between 39 characters, from Disney’s Elsa to the Chinese cartoon classic Nezha. It costs $149, and 200,000 units have been sold since it launched last summer. It’s made by the Chinese company Haivivi and runs on DeepSeek’s large language models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Other companies are approaching the market differently. FoloToy, another Chinese startup, allows parents to customize a bear, bunny, or cactus toy by training it to speak with their own voice and speech pattern. FoloToy reported selling more than 20,000 of its AI-equipped plush toys in the first quarter of 2025, nearly equaling its total sales for 2024, and it projects sales of 300,000 units this year.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;But Chinese AI toy companies have their sights set beyond the nation’s borders. BubblePal was launched in the US in December 2024 and is now also available in Canada and the UK. And FoloToy is now sold in more than 10 countries, including the US, UK, Canada, Brazil, Germany, and Thailand. Rui Ma, a China tech analyst at AlphaWatch.AI, says that AI devices for children make particular sense in China, where there is already a well-established market for kid-focused educational electronics—a market that does not exist to the same extent globally. FoloToy’s CEO, Kong Miaomiao, told the Chinese outlet Baijing Chuhai that outside China, his firm is still just “reaching early adopters who are curious about AI.”&lt;/p&gt;  &lt;p&gt;China’s AI toy boom builds on decades of consumer electronics designed specifically for children. As early as the 1990s, companies such as BBK popularized devices like electronic dictionaries and “study machines,” marketed to parents as educational aids. These toy-electronics hybrids read aloud, tell interactive stories, and simulate the role of a playmate.&lt;/p&gt; 
 &lt;p&gt;The competition is heating up, however—US companies have also started to develop and sell AI toys. The musician Grimes helped to create Grok, a plush toy that chats with kids and adapts to their personality. Toy giant Mattel is working with OpenAI to bring conversational AI to brands like Barbie and Hot Wheels, with the first products expected to be announced later this year.&lt;/p&gt;  &lt;p&gt;However, reviews from parents who’ve bought AI toys in China are mixed. Although many appreciate the fact they are screen-free and come with strict parental controls, some parents say their AI capabilities can be glitchy, leading children to tire of them easily.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Penny Huang, based in Beijing, bought a BubblePal for her five-year-old daughter, who is cared for mostly by grandparents. Huang hoped that the toy could make her less lonely and reduce her constant requests to play with adults’ smartphones. But the novelty wore off quickly.&lt;/p&gt;  &lt;p&gt;“The responses are too long and wordy. My daughter quickly loses patience,” says Huang, “It [the role-play] doesn’t feel immersive—just a voice that sometimes sounds out of place.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Another parent who uses BubblePal, Hongyi Li, found the voice recognition lagging: “Children’s speech is fragmented and unclear. The toy frequently interrupts my kid or misunderstands what she says. It also still requires pressing a button to interact, which can be hard for toddlers.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Huang recently listed her BubblePal for sale on Xianyu, a secondhand marketplace. “This is just like one of the many toys that my daughter plays for five minutes then gets tired of,” she says. “She wants to play with my phone more than anything else.”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/07/1125191/ai-toys-in-china/</guid><pubDate>Tue, 07 Oct 2025 16:51:02 +0000</pubDate></item><item><title>Dead celebrities are apparently fair game for Sora 2 video manipulation (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/dj-bruce-lee-and-jackass-mr-rogers-dead-celebrities-become-puppets-in-sora-2-videos/</link><description>&lt;article class="double-column h-entry post-2121034 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-ai tag-celebrities tag-dead tag-deceased tag-law tag-openai tag-public-figures tag-publicity tag-sora-2 tag-video-2"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI's likeness protections for living "public figures" don't apply to "historical figures."
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="354" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/jacksonbanana-640x354.png" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/jacksonbanana-1152x648-1759855287.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Michael Jackson never did a banana-based comedy routine, but Sora 2 is here to fix that.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI / fAIkout

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;When OpenAI launched the Sora 2 video generator last week, the company wrote that it was taking measures to "block depictions of public figures" by default. But creators and viewers of Sora 2 videos are finding that prohibition has a rather large loophole, allowing for videos of public figures that happen to be dead.&lt;/p&gt;
&lt;p&gt;Examples of celebrities being posthumously inserted into Sora 2 video creations are not hard to find all over social media these days. Tupac Shakur chatting with Malcolm X. Bruce Lee running a "dragon energy" DJ set. Michael Jackson doing kitchen-based standup comedy. Stephen Hawking's wheelchair wiping out on a giant skateboard ramp. Mister Rogers doing a cameo on &lt;em&gt;Jackass&lt;/em&gt;. Kurt Cobain stealing KFC chicken fingers. Martin Luther King Jr. stuttering through a major speech. The list goes on and on.&lt;/p&gt;
&lt;p&gt;OpenAI places a moving Sora watermark over each generated video, which limits the risk of viewers being fooled by fake footage of real people. Still, seeing these deceased celebrities used as props by an AI tool can obviously be upsetting to their living relatives and fans.&lt;/p&gt;
&lt;p&gt;"Please stop sending me AI videos of dad," Zelda Williams said in a since-deleted Instagram story Monday (archived here), referring to her late father Robin Williams. "Stop believing I wanna see it or that I'll understand, I don't and I won't... It's dumb, it's a waste of time and energy, and believe me, it's NOT what he'd want."&lt;/p&gt;
&lt;blockquote cite="https://www.tiktok.com/@sorasynth/video/7557981958135991583" class="tiktok-embed"&gt;
&lt;section&gt;@sorasynth Martin Luther King forgot his lines mid-speech🎤🤔🤔 #mlk #speech #fyu #sora #ai ♬ original sound - SoraVerseAl&lt;/section&gt;
&lt;/blockquote&gt;

&lt;p&gt;The reference to what the late Williams would have wanted is important here. OpenAI notes that living users, including public figures, can opt in to Sora 2's "cameos" feature by scanning their own face with a smartphone to "drop yourself straight into any Sora scene with remarkable fidelity." OpenAI promises that cameo users "are in control of your likeness end-to-end" and that the feature is designed "to ensure that your audio and image likeness are used with your consent." Cameo users can also revoke access to their scanned images at any time and have moderation control over other videos created with that scan.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But deceased public figures obviously can't consent to Sora 2's cameo feature or exercise that kind of "end-to-end" control of their own likeness. And OpenAI seems OK with that. "We don’t have a comment to add, but we do allow the generation of historical figures," an OpenAI spokesperson recently told PCMag.&lt;/p&gt;
&lt;h2&gt;The countdown to lawsuits begins&lt;/h2&gt;
&lt;p&gt;The use of digital re-creations of dead celebrities isn't exactly a new issue—back in the '90s, we were collectively wrestling with John Lennon chatting to Forrest Gump and Fred Astaire dancing with a Dirt Devil vacuum. Back then, though, that kind of footage required painstaking digital editing and technology only easily accessible to major video production houses. Now, more convincing footage of deceased public figures can be generated by any Sora 2 user in minutes for just a few bucks.&lt;/p&gt;
&lt;p&gt;In the US, the right of publicity for deceased public figures is governed by various laws in at least 24 states. California's statute, which dates back to 1985, bars unauthorized post-mortem use of a public figure's likeness "for purposes of advertising or selling, or soliciting purchases of products, merchandise, goods, or services." But a 2001 California Supreme Court ruling explicitly allows those likenesses to be used for "transformative" purposes under the First Amendment.&lt;/p&gt;
&lt;p&gt;The New York version of the law, signed in 2022, contains specific language barring the unauthorized use of a "digital replicas" that are "so realistic that a reasonable observer would believe it is a performance by the individual being portrayed and no other individual" and in a manner "likely to deceive the public into thinking it was authorized by the person or persons." But video makers can get around this prohibition with a "conspicuous disclaimer" explicitly noting that the use is unauthorized.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote class="reddit-embed-bq" style="height: 500px;"&gt;&lt;p&gt;I’m definitely falling for AI when I’m older&lt;br /&gt;
byu/Suspicious-Bee-5487 inaivideo&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Control over AI re-creations of performers was a major focus of the 2023 SAG-AFTRA strike, resulting in a contract that gave members full control over the use of digital replicas in future unionized projects. Zelda Williams wrote publicly during that strike about the "disturbing" efforts to re-create her father's voice at the time. "These recreations are, at their very best, a poor facsimile of greater people, but at their worst, a horrendous Frankensteinian monster, cobbled together from the worst bits of everything this industry is, instead of what it should stand for," she wrote.&lt;/p&gt;
&lt;p&gt;OpenAI has already been forced to change the way Sora handles fictional copyrighted works. CEO Sam Altman wrote this weekend that copyright holders now have to opt in to allow their characters in Sora 2 videos (rather than opting out when the service launched) and will share in some of the revenue from any Sora videos of their characters. Altman also promised "many more [changes] to come" and to "expect a very high rate of change from us... we will make some good decisions and some missteps, but we will take feedback and try to fix the missteps very quickly."&lt;/p&gt;
&lt;p&gt;Last year, a pair of podcasters were sued after creating an "AI" version of a George Carlin comedy routine that used a re-creation of Carlin's voice (but which was actually written by a human). And OpenAI previously faced threats of legal action for mimicking Scarlett Johansson's vocal performance in ChatGPT-4o's voice mode.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #82b1ff; background-color: #1e88e5;"&gt;&lt;img alt="adespoton" class="ars-avatar-image" src="https://cdn.arstechnica.net/civis/data/avatars/m/383/383477.jpg?1668096452" /&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              adespoton
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            So... fictional characters that never existed have to be opted in, but real people that have died and have historical significance are fair game.&lt;p&gt;What a world we live in.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-10-07T18:53:45+00:00"&gt;October 7, 2025 at 6:53 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2121034 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-ai tag-celebrities tag-dead tag-deceased tag-law tag-openai tag-public-figures tag-publicity tag-sora-2 tag-video-2"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI's likeness protections for living "public figures" don't apply to "historical figures."
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="354" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/jacksonbanana-640x354.png" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/jacksonbanana-1152x648-1759855287.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Michael Jackson never did a banana-based comedy routine, but Sora 2 is here to fix that.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI / fAIkout

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;When OpenAI launched the Sora 2 video generator last week, the company wrote that it was taking measures to "block depictions of public figures" by default. But creators and viewers of Sora 2 videos are finding that prohibition has a rather large loophole, allowing for videos of public figures that happen to be dead.&lt;/p&gt;
&lt;p&gt;Examples of celebrities being posthumously inserted into Sora 2 video creations are not hard to find all over social media these days. Tupac Shakur chatting with Malcolm X. Bruce Lee running a "dragon energy" DJ set. Michael Jackson doing kitchen-based standup comedy. Stephen Hawking's wheelchair wiping out on a giant skateboard ramp. Mister Rogers doing a cameo on &lt;em&gt;Jackass&lt;/em&gt;. Kurt Cobain stealing KFC chicken fingers. Martin Luther King Jr. stuttering through a major speech. The list goes on and on.&lt;/p&gt;
&lt;p&gt;OpenAI places a moving Sora watermark over each generated video, which limits the risk of viewers being fooled by fake footage of real people. Still, seeing these deceased celebrities used as props by an AI tool can obviously be upsetting to their living relatives and fans.&lt;/p&gt;
&lt;p&gt;"Please stop sending me AI videos of dad," Zelda Williams said in a since-deleted Instagram story Monday (archived here), referring to her late father Robin Williams. "Stop believing I wanna see it or that I'll understand, I don't and I won't... It's dumb, it's a waste of time and energy, and believe me, it's NOT what he'd want."&lt;/p&gt;
&lt;blockquote cite="https://www.tiktok.com/@sorasynth/video/7557981958135991583" class="tiktok-embed"&gt;
&lt;section&gt;@sorasynth Martin Luther King forgot his lines mid-speech🎤🤔🤔 #mlk #speech #fyu #sora #ai ♬ original sound - SoraVerseAl&lt;/section&gt;
&lt;/blockquote&gt;

&lt;p&gt;The reference to what the late Williams would have wanted is important here. OpenAI notes that living users, including public figures, can opt in to Sora 2's "cameos" feature by scanning their own face with a smartphone to "drop yourself straight into any Sora scene with remarkable fidelity." OpenAI promises that cameo users "are in control of your likeness end-to-end" and that the feature is designed "to ensure that your audio and image likeness are used with your consent." Cameo users can also revoke access to their scanned images at any time and have moderation control over other videos created with that scan.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But deceased public figures obviously can't consent to Sora 2's cameo feature or exercise that kind of "end-to-end" control of their own likeness. And OpenAI seems OK with that. "We don’t have a comment to add, but we do allow the generation of historical figures," an OpenAI spokesperson recently told PCMag.&lt;/p&gt;
&lt;h2&gt;The countdown to lawsuits begins&lt;/h2&gt;
&lt;p&gt;The use of digital re-creations of dead celebrities isn't exactly a new issue—back in the '90s, we were collectively wrestling with John Lennon chatting to Forrest Gump and Fred Astaire dancing with a Dirt Devil vacuum. Back then, though, that kind of footage required painstaking digital editing and technology only easily accessible to major video production houses. Now, more convincing footage of deceased public figures can be generated by any Sora 2 user in minutes for just a few bucks.&lt;/p&gt;
&lt;p&gt;In the US, the right of publicity for deceased public figures is governed by various laws in at least 24 states. California's statute, which dates back to 1985, bars unauthorized post-mortem use of a public figure's likeness "for purposes of advertising or selling, or soliciting purchases of products, merchandise, goods, or services." But a 2001 California Supreme Court ruling explicitly allows those likenesses to be used for "transformative" purposes under the First Amendment.&lt;/p&gt;
&lt;p&gt;The New York version of the law, signed in 2022, contains specific language barring the unauthorized use of a "digital replicas" that are "so realistic that a reasonable observer would believe it is a performance by the individual being portrayed and no other individual" and in a manner "likely to deceive the public into thinking it was authorized by the person or persons." But video makers can get around this prohibition with a "conspicuous disclaimer" explicitly noting that the use is unauthorized.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote class="reddit-embed-bq" style="height: 500px;"&gt;&lt;p&gt;I’m definitely falling for AI when I’m older&lt;br /&gt;
byu/Suspicious-Bee-5487 inaivideo&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Control over AI re-creations of performers was a major focus of the 2023 SAG-AFTRA strike, resulting in a contract that gave members full control over the use of digital replicas in future unionized projects. Zelda Williams wrote publicly during that strike about the "disturbing" efforts to re-create her father's voice at the time. "These recreations are, at their very best, a poor facsimile of greater people, but at their worst, a horrendous Frankensteinian monster, cobbled together from the worst bits of everything this industry is, instead of what it should stand for," she wrote.&lt;/p&gt;
&lt;p&gt;OpenAI has already been forced to change the way Sora handles fictional copyrighted works. CEO Sam Altman wrote this weekend that copyright holders now have to opt in to allow their characters in Sora 2 videos (rather than opting out when the service launched) and will share in some of the revenue from any Sora videos of their characters. Altman also promised "many more [changes] to come" and to "expect a very high rate of change from us... we will make some good decisions and some missteps, but we will take feedback and try to fix the missteps very quickly."&lt;/p&gt;
&lt;p&gt;Last year, a pair of podcasters were sued after creating an "AI" version of a George Carlin comedy routine that used a re-creation of Carlin's voice (but which was actually written by a human). And OpenAI previously faced threats of legal action for mimicking Scarlett Johansson's vocal performance in ChatGPT-4o's voice mode.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #82b1ff; background-color: #1e88e5;"&gt;&lt;img alt="adespoton" class="ars-avatar-image" src="https://cdn.arstechnica.net/civis/data/avatars/m/383/383477.jpg?1668096452" /&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              adespoton
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            So... fictional characters that never existed have to be opted in, but real people that have died and have historical significance are fair game.&lt;p&gt;What a world we live in.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-10-07T18:53:45+00:00"&gt;October 7, 2025 at 6:53 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/dj-bruce-lee-and-jackass-mr-rogers-dead-celebrities-become-puppets-in-sora-2-videos/</guid><pubDate>Tue, 07 Oct 2025 17:08:05 +0000</pubDate></item><item><title>[NEW] The Trump administration may cut funding for two major direct-air capture plants (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/07/1125207/the-us-is-set-to-cancel-funding-for-two-major-direct-air-capture-plants/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2022/04/AP_21258339664472.jpeg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The US Department of Energy appears poised to terminate funding for a pair of large carbon-sucking factories that were originally set to receive more than $1 billion in government grants, according to a department-issued list of projects obtained by &lt;em&gt;MIT Technology Review &lt;/em&gt;and circulating among federal agencies.&lt;/p&gt;  &lt;p&gt;One of the projects is the South Texas Direct Air Capture Hub, a facility that Occidental Petroleum’s 1PointFive subsidiary planned to develop in Kleberg County, Texas. The other is Project Cypress in Louisiana, a collaboration between Battelle, Climeworks, and Heirloom.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The list features a "latest status" column, which includes the word "terminate" next to the roughly $50 million award amounts for each project. Those line up with the initial tranche of Department of Energy (DOE) funding for each development. According to the original announcement in 2023, the projects could have received $500 million or more in total grants as they proceeded.&lt;/p&gt;  &lt;p&gt;It’s not clear if the termination of the initial grants would mean the full funding would also be canceled.&lt;/p&gt; 
 &lt;p&gt;“It could mean nothing,” says Erin Burns, executive director of Carbon180, a nonprofit that advocates for the removal and reuse of carbon dioxide. “It could mean there's a renegotiation of the awards. Or it could mean they’re entirely cut. But the uncertainty certainly doesn’t help projects.”&lt;/p&gt;&lt;p&gt;A DOE spokesman stressed that no final decision has been made.&lt;/p&gt;&lt;p&gt;"It is incorrect to suggest those two projects have been terminated and we are unable to verify any lists provided by anonymous sources,” Ben Dietderich, the department’s press secretary, said in an email, adding: “The Department continues to conduct an individualized and thorough review of financial awards made by the previous administration.”&lt;/p&gt;  &lt;p&gt;Last week, the DOE announced it would terminate about $7.5 billion dollars in grants for more than 200 projects, stating that they "did not adequately advance the nation’s energy needs, were not economically viable, and would not provide a positive return on investment of taxpayer dollars."&lt;br /&gt;&lt;br /&gt;Battelle and 1PointFive didn’t respond to inquiries from &lt;em&gt;MIT Technology Review&lt;/em&gt;. &lt;/p&gt; 
 &lt;p&gt;"Market rumors have surfaced, and Climeworks is prepared for all scenarios,” Christoph Gebald, one of the company's co-CEOs, said in a statement. He added later: “The need for DAC is growing as the world falls short of its climate goals and we’re working to achieve the gigaton capacity that will be needed.”&lt;/p&gt;&lt;p&gt;“We aren’t aware of a decision from DOE and continue to productively engage with the administration in a project review,” Heirloom said in a statement.&lt;/p&gt;  &lt;p&gt;The rising dangers of climate change have driven the development of the direct-air capture industry in recent years.&lt;/p&gt;  &lt;p&gt;Climate models have found that the world may need to suck down billions of tons of carbon dioxide per year by around midcentury, on top of dramatic emissions cuts, to prevent the planet from warming past 2˚ C.&lt;/p&gt;  &lt;p&gt;Carbon-sucking direct-air factories are considered one of the most reliable ways of drawing the greenhouse gas out of the atmosphere, but they also remain one of the most expensive and energy-intensive methods.&lt;/p&gt;&lt;p&gt;Under former President Joe Biden, the US began providing increasingly generous grants, subsidies and other forms of support to help scale up the nascent sector.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;The grants now in question were allocated under the DOE’s Regional Direct Air Capture Hubs program, which was funded through the Bipartisan Infrastructure Law. The goal was to set up several major carbon removal clusters across the US, each capable of sucking down and sequestering at least a million tons of the greenhouse gas per year.&lt;/p&gt;  &lt;p&gt;“Today’s news that a decision to cancel lawfully designated funding for the [direct-air-capture projects] could come soon risks handing a win to competitors abroad and undermines the commitments made to businesses, communities, and leaders in Louisiana and South Texas,” said Giana Amador of the Carbon Removal Alliance and Ben Rubin of the Carbon Business Council in a joint statement.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;&lt;em&gt;This story was updated to include additional quotes, a response from the Department of Energy and added context on the development of the carbon removal sector.&lt;/em&gt;&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2022/04/AP_21258339664472.jpeg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;The US Department of Energy appears poised to terminate funding for a pair of large carbon-sucking factories that were originally set to receive more than $1 billion in government grants, according to a department-issued list of projects obtained by &lt;em&gt;MIT Technology Review &lt;/em&gt;and circulating among federal agencies.&lt;/p&gt;  &lt;p&gt;One of the projects is the South Texas Direct Air Capture Hub, a facility that Occidental Petroleum’s 1PointFive subsidiary planned to develop in Kleberg County, Texas. The other is Project Cypress in Louisiana, a collaboration between Battelle, Climeworks, and Heirloom.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The list features a "latest status" column, which includes the word "terminate" next to the roughly $50 million award amounts for each project. Those line up with the initial tranche of Department of Energy (DOE) funding for each development. According to the original announcement in 2023, the projects could have received $500 million or more in total grants as they proceeded.&lt;/p&gt;  &lt;p&gt;It’s not clear if the termination of the initial grants would mean the full funding would also be canceled.&lt;/p&gt; 
 &lt;p&gt;“It could mean nothing,” says Erin Burns, executive director of Carbon180, a nonprofit that advocates for the removal and reuse of carbon dioxide. “It could mean there's a renegotiation of the awards. Or it could mean they’re entirely cut. But the uncertainty certainly doesn’t help projects.”&lt;/p&gt;&lt;p&gt;A DOE spokesman stressed that no final decision has been made.&lt;/p&gt;&lt;p&gt;"It is incorrect to suggest those two projects have been terminated and we are unable to verify any lists provided by anonymous sources,” Ben Dietderich, the department’s press secretary, said in an email, adding: “The Department continues to conduct an individualized and thorough review of financial awards made by the previous administration.”&lt;/p&gt;  &lt;p&gt;Last week, the DOE announced it would terminate about $7.5 billion dollars in grants for more than 200 projects, stating that they "did not adequately advance the nation’s energy needs, were not economically viable, and would not provide a positive return on investment of taxpayer dollars."&lt;br /&gt;&lt;br /&gt;Battelle and 1PointFive didn’t respond to inquiries from &lt;em&gt;MIT Technology Review&lt;/em&gt;. &lt;/p&gt; 
 &lt;p&gt;"Market rumors have surfaced, and Climeworks is prepared for all scenarios,” Christoph Gebald, one of the company's co-CEOs, said in a statement. He added later: “The need for DAC is growing as the world falls short of its climate goals and we’re working to achieve the gigaton capacity that will be needed.”&lt;/p&gt;&lt;p&gt;“We aren’t aware of a decision from DOE and continue to productively engage with the administration in a project review,” Heirloom said in a statement.&lt;/p&gt;  &lt;p&gt;The rising dangers of climate change have driven the development of the direct-air capture industry in recent years.&lt;/p&gt;  &lt;p&gt;Climate models have found that the world may need to suck down billions of tons of carbon dioxide per year by around midcentury, on top of dramatic emissions cuts, to prevent the planet from warming past 2˚ C.&lt;/p&gt;  &lt;p&gt;Carbon-sucking direct-air factories are considered one of the most reliable ways of drawing the greenhouse gas out of the atmosphere, but they also remain one of the most expensive and energy-intensive methods.&lt;/p&gt;&lt;p&gt;Under former President Joe Biden, the US began providing increasingly generous grants, subsidies and other forms of support to help scale up the nascent sector.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;The grants now in question were allocated under the DOE’s Regional Direct Air Capture Hubs program, which was funded through the Bipartisan Infrastructure Law. The goal was to set up several major carbon removal clusters across the US, each capable of sucking down and sequestering at least a million tons of the greenhouse gas per year.&lt;/p&gt;  &lt;p&gt;“Today’s news that a decision to cancel lawfully designated funding for the [direct-air-capture projects] could come soon risks handing a win to competitors abroad and undermines the commitments made to businesses, communities, and leaders in Louisiana and South Texas,” said Giana Amador of the Carbon Removal Alliance and Ben Rubin of the Carbon Business Council in a joint statement.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;&lt;em&gt;This story was updated to include additional quotes, a response from the Department of Energy and added context on the development of the carbon removal sector.&lt;/em&gt;&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/07/1125207/the-us-is-set-to-cancel-funding-for-two-major-direct-air-capture-plants/</guid><pubDate>Tue, 07 Oct 2025 18:29:20 +0000</pubDate></item><item><title>[NEW] Has this stealth startup finally cracked the code on enterprise AI agent reliability? Meet AUI's Apollo-1 (AI | VentureBeat)</title><link>https://venturebeat.com/ai/has-this-stealth-startup-finally-cracked-the-code-on-enterprise-ai-agent</link><description>[unable to retrieve full-text content]&lt;p&gt;For more than a decade, conversational AI has promised human-like assistants that can do more than chat. Yet even as large language models (LLMs) like ChatGPT, Gemini, and Claude learn to reason, explain, and code, one critical category of interaction remains largely unsolved — reliably completing tasks for people &lt;i&gt;outside of chat&lt;/i&gt;. &lt;/p&gt;&lt;p&gt;Even the&lt;b&gt; best AI models score only in the &lt;/b&gt;&lt;a href="https://artificialanalysis.ai/evaluations/terminalbench-hard"&gt;&lt;b&gt;30th percentile on Terminal-Bench Hard,&lt;/b&gt;&lt;/a&gt; a third-party benchmark designed to evaluate the performance of AI agents on completing a variety of browser-based tasks, far below the reliability demanded by most enterprises and users. And task-specific benchmarks &lt;a href="https://hal.cs.princeton.edu/taubench_airline"&gt;like TAU-Bench airline,&lt;/a&gt; which measures the &lt;b&gt;reliability of AI agents on finding and booking flights&lt;/b&gt; on behalf of a user, also don&amp;#x27;t have much higher pass rates, with &lt;b&gt;only 56% for the top performing agents and models&lt;/b&gt; (Claude 3.7 Sonnet) — meaning the agent fails nearly half the time. &lt;/p&gt;&lt;p&gt;New York City-based &lt;a href="https://www.aui.io/"&gt;&lt;b&gt;Augmented Intelligence (AUI) Inc.&lt;/b&gt;&lt;/a&gt;, co-founded by &lt;b&gt;Ohad Elhelo&lt;/b&gt; and &lt;b&gt;Ori Cohen&lt;/b&gt;, believes it has finally come with a solution to boost AI agent reliability to a level where most enterprises can trust they will do as instructed, reliably. &lt;/p&gt;&lt;p&gt;The company’s new foundation model, called &lt;a href="https://www.aui.io/resources/beyond-generative-ai/"&gt;&lt;b&gt;Apollo-1&lt;/b&gt;&lt;/a&gt;&lt;b&gt; &lt;/b&gt;— which remains in preview with early testers now but is close to an impending general release — is built on a principle it calls &lt;i&gt;stateful neuro-symbolic reasoning.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;It&amp;#x27;s a hybrid architecture championed by even &lt;a href="https://garymarcus.substack.com/p/how-o3-and-grok-4-accidentally-vindicated"&gt;LLM skeptics like Gary Marcus&lt;/a&gt;, designed to guarantee consistent, policy-compliant outcomes in every customer interaction.&lt;/p&gt;&lt;p&gt;“Conversational AI is essentially two halves,” said Elhelo in a recent interview with VentureBeat. “The first half — open-ended dialogue — is handled beautifully by LLMs. They’re designed for creative or exploratory use cases. The other half is task-oriented dialogue, where there’s always a specific goal behind the conversation. That half has remained unsolved because it requires certainty.”&lt;/p&gt;&lt;p&gt;AUI defines &lt;i&gt;certainty&lt;/i&gt; as the difference between an agent that “probably” performs a task and one that almost “always” does. &lt;/p&gt;&lt;p&gt;For example, on &lt;b&gt;TAU-Bench Airline, it performs at a staggering 92.5% pass rate&lt;/b&gt;, leaving all the other current competitors far behind in the dust — according to benchmarks shared with VentureBeat and &lt;a href="https://www.aui.io/resources/beyond-generative-ai/"&gt;posted on AUI&amp;#x27;s website.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Elhelo offered simple examples: a bank that must enforce ID verification for refunds over $200, or an airline that must always offer a business-class upgrade before economy. &lt;/p&gt;&lt;p&gt;“Those aren’t preferences,” he said. “They’re requirements. And no purely generative approach can deliver that kind of behavioral certainty.”&lt;/p&gt;&lt;p&gt;AUI and its work on improving reliability was previously covered by subscription news outlet &lt;a href="https://www.theinformation.com/articles/startup-teaching-ai-agents-shop"&gt;&lt;i&gt;The Information&lt;/i&gt;&lt;/a&gt;, but has not received widespread coverage in publicly accessible media — until now. &lt;/p&gt;&lt;h3&gt;&lt;b&gt;From Pattern Matching to Predictable Action&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The team argues that transformer models, by design, can’t meet that bar. Large language models generate plausible text, not guaranteed behavior. “When you tell an LLM to always offer insurance before payment, it might — usually,” Elhelo said. “Configure Apollo-1 with that rule, and it will — every time.”&lt;/p&gt;&lt;p&gt;That distinction, he said, stems from the architecture itself. Transformers predict the next token in a sequence. Apollo-1, by contrast, predicts the &lt;i&gt;next action&lt;/i&gt; in a conversation, operating on what AUI calls a &lt;i&gt;typed symbolic state&lt;/i&gt;.&lt;/p&gt;&lt;p&gt;Cohen explained the idea in more technical terms. “Neuro-symbolic means we’re merging the two dominant paradigms,” he said. “The symbolic layer gives you structure — it knows what an intent, an entity, and a parameter are — while the neural layer gives you language fluency. The neuro-symbolic reasoner sits between them. It’s a different kind of brain for dialogue.”&lt;/p&gt;&lt;p&gt;Where transformers treat every output as text generation, Apollo-1 runs a closed reasoning loop: an encoder translates natural language into a symbolic state, a state machine maintains that state, a decision engine determines the next action, a planner executes it, and a decoder turns the result back into language. “The process is iterative,” Cohen said. “It loops until the task is done. That’s how you get determinism instead of probability.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Foundation Model for Task Execution&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Unlike traditional chatbots or bespoke automation systems, Apollo-1 is meant to serve as a &lt;i&gt;foundation model&lt;/i&gt; for task-oriented dialogue — a single, domain-agnostic system that can be configured for banking, travel, retail, or insurance through what AUI calls a &lt;b&gt;System Prompt&lt;/b&gt;.&lt;/p&gt;&lt;p&gt;“The System Prompt isn’t a configuration file,” Elhelo said. “It’s a behavioral contract. You define exactly how your agent must behave in situations of interest, and Apollo-1 guarantees those behaviors will execute.”&lt;/p&gt;&lt;p&gt;Organizations can use the prompt to encode symbolic slots — intents, parameters, and policies — as well as tool boundaries and state-dependent rules. &lt;/p&gt;&lt;p&gt;A food delivery app, for example, might enforce “if allergy mentioned, always inform the restaurant,” while a telecom provider might define “after three failed payment attempts, suspend service.” In both cases, the behavior executes deterministically, not statistically.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Eight Years in the Making&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;AUI’s path to Apollo-1 began in 2017, when the team started encoding millions of real task-oriented conversations handled by a 60,000-person human agent workforce. &lt;/p&gt;&lt;p&gt;That work led to a symbolic language capable of separating &lt;i&gt;procedural knowledge&lt;/i&gt; — steps, constraints, and flows — from &lt;i&gt;descriptive knowledge&lt;/i&gt; like entities and attributes.&lt;/p&gt;&lt;p&gt;“The insight was that task-oriented dialogue has universal procedural patterns,” said Elhelo. “Food delivery, claims processing, and order management all share similar structures. Once you model that explicitly, you can compute over it deterministically.”&lt;/p&gt;&lt;p&gt;From there, the company built the neuro-symbolic reasoner — a system that uses the symbolic state to decide what happens next rather than guessing through token prediction.&lt;/p&gt;&lt;p&gt;Benchmarks suggest the architecture makes a measurable difference. &lt;/p&gt;&lt;p&gt;In AUI’s own evaluations, Apollo-1 achieved over &lt;b&gt;90 percent&lt;/b&gt; task completion on the τ-Bench-Airline benchmark, compared with &lt;b&gt;60 percent&lt;/b&gt; for Claude-4. &lt;/p&gt;&lt;p&gt;It completed &lt;b&gt;83 percent&lt;/b&gt; of live booking chats on Google Flights versus &lt;b&gt;22 percent&lt;/b&gt; for Gemini 2.5-Flash, and &lt;b&gt;91 percent&lt;/b&gt; of retail scenarios on Amazon versus &lt;b&gt;17 percent&lt;/b&gt; for Rufus.&lt;/p&gt;&lt;p&gt;“These aren’t incremental improvements,” said Cohen. “They’re order-of-magnitude reliability differences.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Complement, Not a Competitor&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;AUI isn’t pitching Apollo-1 as a replacement for large language models, but as their necessary counterpart. In Elhelo’s words: “Transformers optimize for creative probability. Apollo-1 optimizes for behavioral certainty. Together, they form the complete spectrum of conversational AI.”&lt;/p&gt;&lt;p&gt;The model is already running in limited pilots with undisclosed Fortune 500 companies across sectors including finance, travel, and retail. &lt;/p&gt;&lt;p&gt;AUI has also confirmed a &lt;a href="https://cloud.google.com/blog/topics/partners/google-cloud-partners-with-aui/"&gt;&lt;b&gt;strategic partnership with Google&lt;/b&gt;&lt;/a&gt; and plans for &lt;b&gt;general availability in November 2025&lt;/b&gt;, when it will open APIs, release full documentation, and add voice and image capabilities. Interested potential customers and partners can sign up to receive more information when it &lt;a href="https://www.aui.io/request-access/"&gt;becomes available on AUI&amp;#x27;s website form.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Until then, the company is keeping details under wraps. When asked about what comes next, Elhelo smiled. “Let’s just say we’re preparing an announcement,” he said. “Soon.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Toward Conversations That Act&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For all its technical sophistication, Apollo-1’s pitch is simple: make AI that businesses can trust to act — not just talk. “We’re on a mission to democratize access to AI that works,” Cohen said near the end of the interview.&lt;/p&gt;&lt;p&gt;Whether Apollo-1 becomes the new standard for task-oriented dialogue remains to be seen. But if AUI’s architecture performs as promised, the long-standing divide between chatbots that sound human and agents that reliably do human work may finally start to close.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;For more than a decade, conversational AI has promised human-like assistants that can do more than chat. Yet even as large language models (LLMs) like ChatGPT, Gemini, and Claude learn to reason, explain, and code, one critical category of interaction remains largely unsolved — reliably completing tasks for people &lt;i&gt;outside of chat&lt;/i&gt;. &lt;/p&gt;&lt;p&gt;Even the&lt;b&gt; best AI models score only in the &lt;/b&gt;&lt;a href="https://artificialanalysis.ai/evaluations/terminalbench-hard"&gt;&lt;b&gt;30th percentile on Terminal-Bench Hard,&lt;/b&gt;&lt;/a&gt; a third-party benchmark designed to evaluate the performance of AI agents on completing a variety of browser-based tasks, far below the reliability demanded by most enterprises and users. And task-specific benchmarks &lt;a href="https://hal.cs.princeton.edu/taubench_airline"&gt;like TAU-Bench airline,&lt;/a&gt; which measures the &lt;b&gt;reliability of AI agents on finding and booking flights&lt;/b&gt; on behalf of a user, also don&amp;#x27;t have much higher pass rates, with &lt;b&gt;only 56% for the top performing agents and models&lt;/b&gt; (Claude 3.7 Sonnet) — meaning the agent fails nearly half the time. &lt;/p&gt;&lt;p&gt;New York City-based &lt;a href="https://www.aui.io/"&gt;&lt;b&gt;Augmented Intelligence (AUI) Inc.&lt;/b&gt;&lt;/a&gt;, co-founded by &lt;b&gt;Ohad Elhelo&lt;/b&gt; and &lt;b&gt;Ori Cohen&lt;/b&gt;, believes it has finally come with a solution to boost AI agent reliability to a level where most enterprises can trust they will do as instructed, reliably. &lt;/p&gt;&lt;p&gt;The company’s new foundation model, called &lt;a href="https://www.aui.io/resources/beyond-generative-ai/"&gt;&lt;b&gt;Apollo-1&lt;/b&gt;&lt;/a&gt;&lt;b&gt; &lt;/b&gt;— which remains in preview with early testers now but is close to an impending general release — is built on a principle it calls &lt;i&gt;stateful neuro-symbolic reasoning.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;It&amp;#x27;s a hybrid architecture championed by even &lt;a href="https://garymarcus.substack.com/p/how-o3-and-grok-4-accidentally-vindicated"&gt;LLM skeptics like Gary Marcus&lt;/a&gt;, designed to guarantee consistent, policy-compliant outcomes in every customer interaction.&lt;/p&gt;&lt;p&gt;“Conversational AI is essentially two halves,” said Elhelo in a recent interview with VentureBeat. “The first half — open-ended dialogue — is handled beautifully by LLMs. They’re designed for creative or exploratory use cases. The other half is task-oriented dialogue, where there’s always a specific goal behind the conversation. That half has remained unsolved because it requires certainty.”&lt;/p&gt;&lt;p&gt;AUI defines &lt;i&gt;certainty&lt;/i&gt; as the difference between an agent that “probably” performs a task and one that almost “always” does. &lt;/p&gt;&lt;p&gt;For example, on &lt;b&gt;TAU-Bench Airline, it performs at a staggering 92.5% pass rate&lt;/b&gt;, leaving all the other current competitors far behind in the dust — according to benchmarks shared with VentureBeat and &lt;a href="https://www.aui.io/resources/beyond-generative-ai/"&gt;posted on AUI&amp;#x27;s website.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Elhelo offered simple examples: a bank that must enforce ID verification for refunds over $200, or an airline that must always offer a business-class upgrade before economy. &lt;/p&gt;&lt;p&gt;“Those aren’t preferences,” he said. “They’re requirements. And no purely generative approach can deliver that kind of behavioral certainty.”&lt;/p&gt;&lt;p&gt;AUI and its work on improving reliability was previously covered by subscription news outlet &lt;a href="https://www.theinformation.com/articles/startup-teaching-ai-agents-shop"&gt;&lt;i&gt;The Information&lt;/i&gt;&lt;/a&gt;, but has not received widespread coverage in publicly accessible media — until now. &lt;/p&gt;&lt;h3&gt;&lt;b&gt;From Pattern Matching to Predictable Action&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The team argues that transformer models, by design, can’t meet that bar. Large language models generate plausible text, not guaranteed behavior. “When you tell an LLM to always offer insurance before payment, it might — usually,” Elhelo said. “Configure Apollo-1 with that rule, and it will — every time.”&lt;/p&gt;&lt;p&gt;That distinction, he said, stems from the architecture itself. Transformers predict the next token in a sequence. Apollo-1, by contrast, predicts the &lt;i&gt;next action&lt;/i&gt; in a conversation, operating on what AUI calls a &lt;i&gt;typed symbolic state&lt;/i&gt;.&lt;/p&gt;&lt;p&gt;Cohen explained the idea in more technical terms. “Neuro-symbolic means we’re merging the two dominant paradigms,” he said. “The symbolic layer gives you structure — it knows what an intent, an entity, and a parameter are — while the neural layer gives you language fluency. The neuro-symbolic reasoner sits between them. It’s a different kind of brain for dialogue.”&lt;/p&gt;&lt;p&gt;Where transformers treat every output as text generation, Apollo-1 runs a closed reasoning loop: an encoder translates natural language into a symbolic state, a state machine maintains that state, a decision engine determines the next action, a planner executes it, and a decoder turns the result back into language. “The process is iterative,” Cohen said. “It loops until the task is done. That’s how you get determinism instead of probability.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Foundation Model for Task Execution&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Unlike traditional chatbots or bespoke automation systems, Apollo-1 is meant to serve as a &lt;i&gt;foundation model&lt;/i&gt; for task-oriented dialogue — a single, domain-agnostic system that can be configured for banking, travel, retail, or insurance through what AUI calls a &lt;b&gt;System Prompt&lt;/b&gt;.&lt;/p&gt;&lt;p&gt;“The System Prompt isn’t a configuration file,” Elhelo said. “It’s a behavioral contract. You define exactly how your agent must behave in situations of interest, and Apollo-1 guarantees those behaviors will execute.”&lt;/p&gt;&lt;p&gt;Organizations can use the prompt to encode symbolic slots — intents, parameters, and policies — as well as tool boundaries and state-dependent rules. &lt;/p&gt;&lt;p&gt;A food delivery app, for example, might enforce “if allergy mentioned, always inform the restaurant,” while a telecom provider might define “after three failed payment attempts, suspend service.” In both cases, the behavior executes deterministically, not statistically.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Eight Years in the Making&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;AUI’s path to Apollo-1 began in 2017, when the team started encoding millions of real task-oriented conversations handled by a 60,000-person human agent workforce. &lt;/p&gt;&lt;p&gt;That work led to a symbolic language capable of separating &lt;i&gt;procedural knowledge&lt;/i&gt; — steps, constraints, and flows — from &lt;i&gt;descriptive knowledge&lt;/i&gt; like entities and attributes.&lt;/p&gt;&lt;p&gt;“The insight was that task-oriented dialogue has universal procedural patterns,” said Elhelo. “Food delivery, claims processing, and order management all share similar structures. Once you model that explicitly, you can compute over it deterministically.”&lt;/p&gt;&lt;p&gt;From there, the company built the neuro-symbolic reasoner — a system that uses the symbolic state to decide what happens next rather than guessing through token prediction.&lt;/p&gt;&lt;p&gt;Benchmarks suggest the architecture makes a measurable difference. &lt;/p&gt;&lt;p&gt;In AUI’s own evaluations, Apollo-1 achieved over &lt;b&gt;90 percent&lt;/b&gt; task completion on the τ-Bench-Airline benchmark, compared with &lt;b&gt;60 percent&lt;/b&gt; for Claude-4. &lt;/p&gt;&lt;p&gt;It completed &lt;b&gt;83 percent&lt;/b&gt; of live booking chats on Google Flights versus &lt;b&gt;22 percent&lt;/b&gt; for Gemini 2.5-Flash, and &lt;b&gt;91 percent&lt;/b&gt; of retail scenarios on Amazon versus &lt;b&gt;17 percent&lt;/b&gt; for Rufus.&lt;/p&gt;&lt;p&gt;“These aren’t incremental improvements,” said Cohen. “They’re order-of-magnitude reliability differences.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Complement, Not a Competitor&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;AUI isn’t pitching Apollo-1 as a replacement for large language models, but as their necessary counterpart. In Elhelo’s words: “Transformers optimize for creative probability. Apollo-1 optimizes for behavioral certainty. Together, they form the complete spectrum of conversational AI.”&lt;/p&gt;&lt;p&gt;The model is already running in limited pilots with undisclosed Fortune 500 companies across sectors including finance, travel, and retail. &lt;/p&gt;&lt;p&gt;AUI has also confirmed a &lt;a href="https://cloud.google.com/blog/topics/partners/google-cloud-partners-with-aui/"&gt;&lt;b&gt;strategic partnership with Google&lt;/b&gt;&lt;/a&gt; and plans for &lt;b&gt;general availability in November 2025&lt;/b&gt;, when it will open APIs, release full documentation, and add voice and image capabilities. Interested potential customers and partners can sign up to receive more information when it &lt;a href="https://www.aui.io/request-access/"&gt;becomes available on AUI&amp;#x27;s website form.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Until then, the company is keeping details under wraps. When asked about what comes next, Elhelo smiled. “Let’s just say we’re preparing an announcement,” he said. “Soon.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Toward Conversations That Act&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;For all its technical sophistication, Apollo-1’s pitch is simple: make AI that businesses can trust to act — not just talk. “We’re on a mission to democratize access to AI that works,” Cohen said near the end of the interview.&lt;/p&gt;&lt;p&gt;Whether Apollo-1 becomes the new standard for task-oriented dialogue remains to be seen. But if AUI’s architecture performs as promised, the long-standing divide between chatbots that sound human and agents that reliably do human work may finally start to close.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/has-this-stealth-startup-finally-cracked-the-code-on-enterprise-ai-agent</guid><pubDate>Tue, 07 Oct 2025 18:34:00 +0000</pubDate></item><item><title>[NEW] How Otter.ai’s CEO is pushing the company to be more than just a meeting scribe (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/07/how-otter-ais-ceo-is-pushing-the-company-to-be-more-than-just-a-meeting-scribe/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2154742440.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;br /&gt;Otter.ai CEO Sam Liang isn’t satisfied with the company being viewed, and used, as just a meeting notetaker. Liang wants Otter.ai to become a go-to source for enterprises and a new batch of products released Tuesday is the first step in that evolution. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Silicon Valley-based AI meeting assistant startup on Tuesday released a new suite of tools for enterprises designed to better incorporate data from meetings into other workflows by funneling that information to a central knowledge base. The aim is to grow Otter’s business by helping companies get more out of the meetings they record.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Otter’s new product suite includes an API that allows users to build custom integrations with platforms like Jira and HubSpot, an MCP server — which connects users’ Otter data to external AI models — and a new AI agent that can search a company’s meetings notes or presentations.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liang told TechCrunch it is the next phase of Otter’s life.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are evolving from a meeting notetaker to a corporate meeting knowledge base,” Liang said. “This is a system record for conversations. It can help corporations scale their growth and drive measurable business value.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When Otter was founded in 2016, there were just a handful of meeting transcription companies — a far leap from today. The AI boom that kicked off in 2022 fueled a surge in startups like Granola or Circleback. Even older players like Fireflies have seen a surge in interest.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liang argues this transition puts Otter into a separate division than its former peers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meetings are where the majority of company knowledge is stored, in Liang’s opinion, whether that is notes from a customer sales call or discussions around a marketing strategy. But without a centralized place for these meeting notes, that information can only help a company so much.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A lot of times, inefficiency happens because of information silos,” Liang said. “One team doesn’t know what the other team is doing, and it thinks that that was planned like a month ago. Oftentimes the plan changes, but not everybody is informed. So, the idea is to create a permission system so that you know most of the [nonconfidential] information is shared as broadly as possible.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Not every meeting with Otter will be directly added to this companywide knowledge base, and users can choose to restrict meeting note access&amp;nbsp;for&amp;nbsp;recordings that deal with sensitive information.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Employee and information privacy remains a concern despite access controls. Even if a meeting is around a neutral topic, Otter transcriptions pick the small talk and chatter that happens before and after meetings, which could contain gossip or information meant for only certain participants to hear.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Otter is also the subject of an August class-action lawsuit that claims the company was recording private conversations without user consent and using that information to train its transcription services.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liang said that while he can’t comment on the lawsuit specifically, this isn’t an issue specific to Otter, and that when looking at the bigger picture, more access to information is better than not.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If they accuse us, then they could accuse everyone else, all the tools you heard about doing meeting notes,” Liang said. “My view is that we are on the right side of history. We’re building this new AI revolution. If you want AI to help, you need to put AI in the meetings.”&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2154742440.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;br /&gt;Otter.ai CEO Sam Liang isn’t satisfied with the company being viewed, and used, as just a meeting notetaker. Liang wants Otter.ai to become a go-to source for enterprises and a new batch of products released Tuesday is the first step in that evolution. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Silicon Valley-based AI meeting assistant startup on Tuesday released a new suite of tools for enterprises designed to better incorporate data from meetings into other workflows by funneling that information to a central knowledge base. The aim is to grow Otter’s business by helping companies get more out of the meetings they record.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Otter’s new product suite includes an API that allows users to build custom integrations with platforms like Jira and HubSpot, an MCP server — which connects users’ Otter data to external AI models — and a new AI agent that can search a company’s meetings notes or presentations.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liang told TechCrunch it is the next phase of Otter’s life.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are evolving from a meeting notetaker to a corporate meeting knowledge base,” Liang said. “This is a system record for conversations. It can help corporations scale their growth and drive measurable business value.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When Otter was founded in 2016, there were just a handful of meeting transcription companies — a far leap from today. The AI boom that kicked off in 2022 fueled a surge in startups like Granola or Circleback. Even older players like Fireflies have seen a surge in interest.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liang argues this transition puts Otter into a separate division than its former peers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meetings are where the majority of company knowledge is stored, in Liang’s opinion, whether that is notes from a customer sales call or discussions around a marketing strategy. But without a centralized place for these meeting notes, that information can only help a company so much.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A lot of times, inefficiency happens because of information silos,” Liang said. “One team doesn’t know what the other team is doing, and it thinks that that was planned like a month ago. Oftentimes the plan changes, but not everybody is informed. So, the idea is to create a permission system so that you know most of the [nonconfidential] information is shared as broadly as possible.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Not every meeting with Otter will be directly added to this companywide knowledge base, and users can choose to restrict meeting note access&amp;nbsp;for&amp;nbsp;recordings that deal with sensitive information.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Employee and information privacy remains a concern despite access controls. Even if a meeting is around a neutral topic, Otter transcriptions pick the small talk and chatter that happens before and after meetings, which could contain gossip or information meant for only certain participants to hear.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Otter is also the subject of an August class-action lawsuit that claims the company was recording private conversations without user consent and using that information to train its transcription services.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liang said that while he can’t comment on the lawsuit specifically, this isn’t an issue specific to Otter, and that when looking at the bigger picture, more access to information is better than not.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If they accuse us, then they could accuse everyone else, all the tools you heard about doing meeting notes,” Liang said. “My view is that we are on the right side of history. We’re building this new AI revolution. If you want AI to help, you need to put AI in the meetings.”&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/07/how-otter-ais-ceo-is-pushing-the-company-to-be-more-than-just-a-meeting-scribe/</guid><pubDate>Tue, 07 Oct 2025 19:15:17 +0000</pubDate></item><item><title>Ars Live: Is the AI bubble about to pop? Ed Zitron is on with Ars at 3:30pm EDT today (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/ars-live-is-the-ai-bubble-about-to-pop-a-live-chat-with-ed-zitron/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Our discussion happens today, October 7, at 3:30pm US Eastern time.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Wong Yu Liang via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;As generative AI has taken off since ChatGPT's debut, inspiring hundreds of billions of dollars in investments and infrastructure developments, the top question on many people's minds has been: Is generative AI a bubble, and if so, when will it pop?&lt;/p&gt;
&lt;p&gt;To help us potentially answer that question, I'll be hosting a live conversation with prominent AI critic Ed Zitron on October 7 at 3:30 pm ET as part of the Ars Live series. As Ars Technica's senior AI reporter, I've been tracking both the explosive growth of this industry and the mounting skepticism about its sustainability.&lt;/p&gt;
&lt;p&gt;You can watch the discussion live on YouTube when the time comes.&lt;/p&gt;
&lt;p&gt;Zitron is the host of the &lt;em&gt;Better Offline&lt;/em&gt; podcast and CEO of EZPR, a media relations company. He writes the newsletter Where's Your Ed At, where he frequently dissects OpenAI's finances and questions the actual utility of current AI products. His recent posts have examined whether companies are losing money on AI investments, the economics of GPU rentals, OpenAI's trillion-dollar funding needs, and what he calls "The Subprime AI Crisis."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2120644 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Alt text for this image: &amp;quot;Promotional graphic for an Ars Technica live stream event titled 'Is the Artificial Intelligence Bubble About to Pop?' scheduled for October 7th at 3:30 PM ET / 4:30 PM CT. The dark blue background features scattered light bokeh effects. The Ars Technica logo appears in an orange circle on the left. Below are two speaker profile photos in circular frames with orange borders: Ed Zitron (Host of Better Offline Podcast, CEO of EZPR) on the left, and Benj Edwards (Senior AI Reporter at Ars Technica) on the right. The bottom text indicates the stream will be live at youtube.com/@arstechnica." class="center large" height="1034" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ArsLive_25_Edwards_Social-1024x1034.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ars Technica

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;During our conversation, we'll dig into whether the current AI investment frenzy matches the actual business value being created, what happens when companies realize their AI spending isn't generating returns, and whether we're seeing signs of a peak in the current AI hype cycle. We'll also discuss what it's like to be a prominent and sometimes controversial AI critic amid the drumbeat of AI mania in the tech industry.&lt;/p&gt;
&lt;p&gt;While Ed and I don't see eye to eye on everything, his sharp criticism of the AI industry's excesses should make for an engaging discussion about one of tech's most consequential questions right now.&lt;/p&gt;
&lt;p&gt;Please join us for what should be a lively conversation about the sustainability of the current AI boom.&lt;/p&gt;
&lt;p&gt;Add to Google Calendar | Add to calendar (.ics download)&lt;/p&gt;


          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Our discussion happens today, October 7, at 3:30pm US Eastern time.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Wong Yu Liang via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;As generative AI has taken off since ChatGPT's debut, inspiring hundreds of billions of dollars in investments and infrastructure developments, the top question on many people's minds has been: Is generative AI a bubble, and if so, when will it pop?&lt;/p&gt;
&lt;p&gt;To help us potentially answer that question, I'll be hosting a live conversation with prominent AI critic Ed Zitron on October 7 at 3:30 pm ET as part of the Ars Live series. As Ars Technica's senior AI reporter, I've been tracking both the explosive growth of this industry and the mounting skepticism about its sustainability.&lt;/p&gt;
&lt;p&gt;You can watch the discussion live on YouTube when the time comes.&lt;/p&gt;
&lt;p&gt;Zitron is the host of the &lt;em&gt;Better Offline&lt;/em&gt; podcast and CEO of EZPR, a media relations company. He writes the newsletter Where's Your Ed At, where he frequently dissects OpenAI's finances and questions the actual utility of current AI products. His recent posts have examined whether companies are losing money on AI investments, the economics of GPU rentals, OpenAI's trillion-dollar funding needs, and what he calls "The Subprime AI Crisis."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2120644 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Alt text for this image: &amp;quot;Promotional graphic for an Ars Technica live stream event titled 'Is the Artificial Intelligence Bubble About to Pop?' scheduled for October 7th at 3:30 PM ET / 4:30 PM CT. The dark blue background features scattered light bokeh effects. The Ars Technica logo appears in an orange circle on the left. Below are two speaker profile photos in circular frames with orange borders: Ed Zitron (Host of Better Offline Podcast, CEO of EZPR) on the left, and Benj Edwards (Senior AI Reporter at Ars Technica) on the right. The bottom text indicates the stream will be live at youtube.com/@arstechnica." class="center large" height="1034" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ArsLive_25_Edwards_Social-1024x1034.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ars Technica

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;During our conversation, we'll dig into whether the current AI investment frenzy matches the actual business value being created, what happens when companies realize their AI spending isn't generating returns, and whether we're seeing signs of a peak in the current AI hype cycle. We'll also discuss what it's like to be a prominent and sometimes controversial AI critic amid the drumbeat of AI mania in the tech industry.&lt;/p&gt;
&lt;p&gt;While Ed and I don't see eye to eye on everything, his sharp criticism of the AI industry's excesses should make for an engaging discussion about one of tech's most consequential questions right now.&lt;/p&gt;
&lt;p&gt;Please join us for what should be a lively conversation about the sustainability of the current AI boom.&lt;/p&gt;
&lt;p&gt;Add to Google Calendar | Add to calendar (.ics download)&lt;/p&gt;


          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/ars-live-is-the-ai-bubble-about-to-pop-a-live-chat-with-ed-zitron/</guid><pubDate>Tue, 07 Oct 2025 19:15:26 +0000</pubDate></item><item><title>[NEW] Google launches its AI vibe-coding app Opal in 15 more countries (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/07/google-launches-its-ai-vibe-coding-app-opal-in-15-more-countries/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Google-Opal.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is expanding access to Opal, its AI vibe-coding app, to 15 more countries. The app, which lets you create mini web apps using text prompts,&amp;nbsp;is now available in Canada, India, Japan, South Korea, Vietnam, Indonesia, Brazil, Singapore, Colombia, El Salvador, Costa Rica, Panamá, Honduras, Argentina, and Pakistan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we opened up Opal to users in the U.S. we anticipated they might build simple, fun tools,” said Megan Li, a senior product manager at Google Labs, in a blog post. “We didn’t expect the surge of sophisticated, practical and highly creative Opal apps we got instead. The ingenuity of these early adopters made one thing clear: we need to get Opal into the hands of more creators globally.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Opal works by getting users to enter a description of the app they want to make, after which the tool uses different Google models to do so. Once the app is ready, users can open the editor panel to view and customize the visual workflow of inputs, outputs, and generation steps. They can click any step to review or edit the prompt, or add new steps manually using Opal’s toolbar. Users can also publish their app to the web and share a link so others can test it with their own Google accounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the expansion, Google also announced improvements coming to Opal. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant says it has improved the debugging program but intentionally kept it no-code. Users can now run their workflow step by step in the visual editor or tweak specific steps in the console. Errors show up right where they happen to provide immediate context and eliminate guesswork. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google also says that it’s made significant improvements to Opal’s core performance. The company notes that previously it would take up to five seconds or more to create a new Opal. Now, it’s worked to speed that up to make it easier to get started. Plus, users can now run steps in parallel, allowing complex workflows with multiple steps to execute simultaneously.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the U.S. launch of Opal in July, Google joined a growing list of competitors including Canva, Figma, and Replit that are building tools to help nontechnical users design app prototypes without writing any code. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Google-Opal.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is expanding access to Opal, its AI vibe-coding app, to 15 more countries. The app, which lets you create mini web apps using text prompts,&amp;nbsp;is now available in Canada, India, Japan, South Korea, Vietnam, Indonesia, Brazil, Singapore, Colombia, El Salvador, Costa Rica, Panamá, Honduras, Argentina, and Pakistan.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we opened up Opal to users in the U.S. we anticipated they might build simple, fun tools,” said Megan Li, a senior product manager at Google Labs, in a blog post. “We didn’t expect the surge of sophisticated, practical and highly creative Opal apps we got instead. The ingenuity of these early adopters made one thing clear: we need to get Opal into the hands of more creators globally.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Opal works by getting users to enter a description of the app they want to make, after which the tool uses different Google models to do so. Once the app is ready, users can open the editor panel to view and customize the visual workflow of inputs, outputs, and generation steps. They can click any step to review or edit the prompt, or add new steps manually using Opal’s toolbar. Users can also publish their app to the web and share a link so others can test it with their own Google accounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the expansion, Google also announced improvements coming to Opal. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant says it has improved the debugging program but intentionally kept it no-code. Users can now run their workflow step by step in the visual editor or tweak specific steps in the console. Errors show up right where they happen to provide immediate context and eliminate guesswork. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google also says that it’s made significant improvements to Opal’s core performance. The company notes that previously it would take up to five seconds or more to create a new Opal. Now, it’s worked to speed that up to make it easier to get started. Plus, users can now run steps in parallel, allowing complex workflows with multiple steps to execute simultaneously.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the U.S. launch of Opal in July, Google joined a growing list of competitors including Canva, Figma, and Replit that are building tools to help nontechnical users design app prototypes without writing any code. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/07/google-launches-its-ai-vibe-coding-app-opal-in-15-more-countries/</guid><pubDate>Tue, 07 Oct 2025 19:54:34 +0000</pubDate></item><item><title>[NEW] Fighting for the health of the planet with AI (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/fighting-health-planet-ai-priya-donti-1007</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-LIDS-Priya-Donti.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;For Priya Donti, childhood trips to India were more than an opportunity to visit extended family. The biennial journeys activated in her a motivation that continues to shape her research and her teaching.&lt;/p&gt;&lt;p&gt;Contrasting her family home in Massachusetts, Donti — now the Silverman Family Career Development Professor in the Department of Electrical Engineering and Computer Science (EECS), a shared position between the MIT Schwarzman College of Computing and EECS, and a principal investigator at the MIT Laboratory for Information and Decision Systems (LIDS) — was struck by the disparities in how people live.&lt;/p&gt;&lt;p&gt;“It was very clear to me the extent to which inequity is a rampant issue around the world,” Donti says. “From a young age, I knew that I definitely wanted to address that issue.”&lt;/p&gt;&lt;p&gt;That motivation was further stoked by a high school biology teacher, who focused his class on climate and sustainability.&lt;/p&gt;&lt;p&gt;“We learned that climate change, this huge, important issue, would exacerbate inequity,” Donti says. “That really stuck with me and put a fire in my belly.”&lt;/p&gt;&lt;p&gt;So, when Donti enrolled at Harvey Mudd College, she thought she would direct her energy toward the study of chemistry or materials science to create next-generation solar panels.&lt;/p&gt;&lt;p&gt;Those plans, however, were jilted. Donti “fell in love” with computer science, and then discovered work by researchers in the United Kingdom who were arguing that artificial intelligence and machine learning would be essential to help integrate renewables into power grids.&lt;/p&gt;&lt;p&gt;“It was the first time I’d seen those two interests brought together,” she says. “I got hooked and have been working on that topic ever since.”&lt;/p&gt;&lt;p&gt;Pursuing a PhD at Carnegie Mellon University, Donti was able to design her degree to include computer science and public policy. In her research, she explored the need for fundamental algorithms and tools that could manage, at scale, power grids relying heavily on renewables.&lt;/p&gt;&lt;p&gt;“I wanted to have a hand in developing those algorithms and tool kits by creating new machine learning techniques grounded in computer science,” she says. “But I wanted to make sure that the way I was doing the work was grounded both in the actual energy systems domain and working with people in that domain” to provide what was actually needed.&lt;/p&gt;&lt;p&gt;While Donti was working on her PhD, she co-founded a nonprofit called Climate Change AI. Her objective, she says, was to help the community of people involved in climate and sustainability — “be they computer scientists, academics, practitioners, or policymakers” — to come together and access resources, connection, and education “to help them along that journey.”&lt;/p&gt;&lt;p&gt;“In the climate space,” she says, “you need experts in particular climate change-related sectors, experts in different technical and social science tool kits, problem owners, affected users, policymakers who know the regulations — all of those — to have on-the-ground scalable impact.”&lt;/p&gt;&lt;p&gt;When Donti came to MIT in September 2023, it was not surprising that she was drawn by its initiatives directing the application of computer science toward society’s biggest problems, especially the current threat to the health of the planet.&lt;/p&gt;&lt;p&gt;“We’re really thinking about where technology has a much longer-horizon impact and how technology, society, and policy all have to work together,” Donti says. “Technology is not just one-and-done and monetizable in the context of a year.”&lt;/p&gt;&lt;p&gt;Her work uses deep learning models to incorporate the physics and hard constraints of electric power systems that employ renewables for better forecasting, optimization, and control.&lt;/p&gt;&lt;p&gt;“Machine learning is already really widely used for things like solar power forecasting, which is a prerequisite to managing and balancing power grids,” she says. “My focus is, how do you improve the algorithms for actually balancing power grids in the face of a range of time-varying renewables?”&lt;/p&gt;&lt;p&gt;Among Donti’s breakthroughs is a promising solution for power grid operators to be able to optimize for cost, taking into account the actual physical realities&amp;nbsp;of the grid, rather than relying on approximations. While the solution is not yet deployed, it appears to work 10 times faster, and far more cheaply, than previous technologies, and has attracted the attention of grid operators.&lt;/p&gt;&lt;p&gt;Another technology she is developing works to provide data that can be used in training machine learning systems for power system optimization. In general, much data related to the systems is private, either because it is proprietary or because of security concerns. Donti and her research group are working to create synthetic data and benchmarks that, Donti says, “can help to expose some of the underlying problems” in making power systems more efficient.&lt;/p&gt;&lt;p&gt;“The question is,” Donti says, “can we bring our datasets to a point such that they are just hard enough to drive progress?”&lt;/p&gt;&lt;p&gt;For her efforts, Donti has been awarded the U.S. Department of Energy Computational Science Graduate Fellowship and the NSF Graduate Research Fellowship. She was recognized as part of &lt;em&gt;MIT Technology Review&lt;/em&gt;’s 2021 list of “35 Innovators Under 35” and Vox’s 2023 “Future Perfect 50.”&lt;/p&gt;&lt;p&gt;Next spring, Donti will co-teach a class called AI for Climate Action with Sara Beery, EECS assistant professor, whose focus is AI for biodiversity and ecosystems, and Abigail Bodner, assistant professor in the departments of EECS and Earth, Atmospheric and Planetary Sciences, whose focus is AI for climate and Earth science.&lt;/p&gt;&lt;p&gt;“We’re all super-excited about it,” Donti says.&lt;/p&gt;&lt;p&gt;Coming to MIT, Donti says, “I knew that there would be an ecosystem of people who really cared, not just about success metrics like publications and citation counts, but about the impact of our work on society.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-LIDS-Priya-Donti.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;For Priya Donti, childhood trips to India were more than an opportunity to visit extended family. The biennial journeys activated in her a motivation that continues to shape her research and her teaching.&lt;/p&gt;&lt;p&gt;Contrasting her family home in Massachusetts, Donti — now the Silverman Family Career Development Professor in the Department of Electrical Engineering and Computer Science (EECS), a shared position between the MIT Schwarzman College of Computing and EECS, and a principal investigator at the MIT Laboratory for Information and Decision Systems (LIDS) — was struck by the disparities in how people live.&lt;/p&gt;&lt;p&gt;“It was very clear to me the extent to which inequity is a rampant issue around the world,” Donti says. “From a young age, I knew that I definitely wanted to address that issue.”&lt;/p&gt;&lt;p&gt;That motivation was further stoked by a high school biology teacher, who focused his class on climate and sustainability.&lt;/p&gt;&lt;p&gt;“We learned that climate change, this huge, important issue, would exacerbate inequity,” Donti says. “That really stuck with me and put a fire in my belly.”&lt;/p&gt;&lt;p&gt;So, when Donti enrolled at Harvey Mudd College, she thought she would direct her energy toward the study of chemistry or materials science to create next-generation solar panels.&lt;/p&gt;&lt;p&gt;Those plans, however, were jilted. Donti “fell in love” with computer science, and then discovered work by researchers in the United Kingdom who were arguing that artificial intelligence and machine learning would be essential to help integrate renewables into power grids.&lt;/p&gt;&lt;p&gt;“It was the first time I’d seen those two interests brought together,” she says. “I got hooked and have been working on that topic ever since.”&lt;/p&gt;&lt;p&gt;Pursuing a PhD at Carnegie Mellon University, Donti was able to design her degree to include computer science and public policy. In her research, she explored the need for fundamental algorithms and tools that could manage, at scale, power grids relying heavily on renewables.&lt;/p&gt;&lt;p&gt;“I wanted to have a hand in developing those algorithms and tool kits by creating new machine learning techniques grounded in computer science,” she says. “But I wanted to make sure that the way I was doing the work was grounded both in the actual energy systems domain and working with people in that domain” to provide what was actually needed.&lt;/p&gt;&lt;p&gt;While Donti was working on her PhD, she co-founded a nonprofit called Climate Change AI. Her objective, she says, was to help the community of people involved in climate and sustainability — “be they computer scientists, academics, practitioners, or policymakers” — to come together and access resources, connection, and education “to help them along that journey.”&lt;/p&gt;&lt;p&gt;“In the climate space,” she says, “you need experts in particular climate change-related sectors, experts in different technical and social science tool kits, problem owners, affected users, policymakers who know the regulations — all of those — to have on-the-ground scalable impact.”&lt;/p&gt;&lt;p&gt;When Donti came to MIT in September 2023, it was not surprising that she was drawn by its initiatives directing the application of computer science toward society’s biggest problems, especially the current threat to the health of the planet.&lt;/p&gt;&lt;p&gt;“We’re really thinking about where technology has a much longer-horizon impact and how technology, society, and policy all have to work together,” Donti says. “Technology is not just one-and-done and monetizable in the context of a year.”&lt;/p&gt;&lt;p&gt;Her work uses deep learning models to incorporate the physics and hard constraints of electric power systems that employ renewables for better forecasting, optimization, and control.&lt;/p&gt;&lt;p&gt;“Machine learning is already really widely used for things like solar power forecasting, which is a prerequisite to managing and balancing power grids,” she says. “My focus is, how do you improve the algorithms for actually balancing power grids in the face of a range of time-varying renewables?”&lt;/p&gt;&lt;p&gt;Among Donti’s breakthroughs is a promising solution for power grid operators to be able to optimize for cost, taking into account the actual physical realities&amp;nbsp;of the grid, rather than relying on approximations. While the solution is not yet deployed, it appears to work 10 times faster, and far more cheaply, than previous technologies, and has attracted the attention of grid operators.&lt;/p&gt;&lt;p&gt;Another technology she is developing works to provide data that can be used in training machine learning systems for power system optimization. In general, much data related to the systems is private, either because it is proprietary or because of security concerns. Donti and her research group are working to create synthetic data and benchmarks that, Donti says, “can help to expose some of the underlying problems” in making power systems more efficient.&lt;/p&gt;&lt;p&gt;“The question is,” Donti says, “can we bring our datasets to a point such that they are just hard enough to drive progress?”&lt;/p&gt;&lt;p&gt;For her efforts, Donti has been awarded the U.S. Department of Energy Computational Science Graduate Fellowship and the NSF Graduate Research Fellowship. She was recognized as part of &lt;em&gt;MIT Technology Review&lt;/em&gt;’s 2021 list of “35 Innovators Under 35” and Vox’s 2023 “Future Perfect 50.”&lt;/p&gt;&lt;p&gt;Next spring, Donti will co-teach a class called AI for Climate Action with Sara Beery, EECS assistant professor, whose focus is AI for biodiversity and ecosystems, and Abigail Bodner, assistant professor in the departments of EECS and Earth, Atmospheric and Planetary Sciences, whose focus is AI for climate and Earth science.&lt;/p&gt;&lt;p&gt;“We’re all super-excited about it,” Donti says.&lt;/p&gt;&lt;p&gt;Coming to MIT, Donti says, “I knew that there would be an ecosystem of people who really cared, not just about success metrics like publications and citation counts, but about the impact of our work on society.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/fighting-health-planet-ai-priya-donti-1007</guid><pubDate>Tue, 07 Oct 2025 20:55:00 +0000</pubDate></item><item><title>[NEW] Wall Street analysts explain how AMD’s own stock will pay for OpenAI’s billions in chip purchases (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/07/wall-street-analysts-explain-how-amds-own-stock-will-pay-for-openais-billions-in-chip-purchases/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2019/08/GettyImages-1165704565.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After AMD and OpenAI announced an&amp;nbsp;expanded partnership on Monday, the chatter immediately turned to&amp;nbsp;the unusual way OpenAI would pay for its AMD purchases. It will use AMD’s own stock to do so.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To recap: OpenAI has agreed to help AMD refine its line of Nvidia competitor chips, the Instinct GPUs, as well as to purchase and deploy 6 gigawatts of compute capacity from AMD over multiple years. AMD said this deal is worth billions in revenue.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But OpenAI&amp;nbsp;isn’t&amp;nbsp;paying for this out of&amp;nbsp;its&amp;nbsp;own revenues.&amp;nbsp;Instead&amp;nbsp;AMD has granted OpenAI a boatload of stock&amp;nbsp;warrants&amp;nbsp;—&amp;nbsp;up to 160 million AMD shares&amp;nbsp;—&amp;nbsp;which will vest&amp;nbsp;in tranches&amp;nbsp;as certain milestones are achieved. Those milestones include&amp;nbsp;specific&amp;nbsp;increases in the stock price, with the last tranche dependent on AMD shares soaring to $600 apiece, AMD disclosed. They were trading at&amp;nbsp;about $165 before the news&amp;nbsp;hit and&amp;nbsp;soared to $214 by&amp;nbsp;market close&amp;nbsp;Monday&amp;nbsp;after the announcement.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If the stock price hits its marks, and OpenAI achieves all its required contributions, and OpenAI holds all of AMD’s shares, not selling any along the way, OpenAI may make enough on AMD stock to pay for a lot of GPUs. The stock could be worth about $100 billion.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We would note that the final 6th tranche requires ~$1T market cap to vest – ergo, if OAI were to hold stock until the end of the deal, its stake would be worth ~$100B,” writes UBS analyst Timothy Arcuri in a research note on Tuesday.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Arcuri believes that a more likely scenario is that OpenAI will sell its AMD stock along the way to pay its AMD bill. So, essentially, this is a scheme for AMD to finance this customer’s purchases.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Arcuri argues, the validation that AMD’s AI GPUs can handle OpenAI workloads, and ergo any other AI workloads, is valuable enough for AMD to make this financing gambit. “AMD highlighted ongoing customer dialogs beyond OpenAI and expects this agreement to ultimately accelerate AMD adoption momentum,” he writes. In particular, OpenAI’s stamp of approval gives it an in to sell its GPUs to the many cloud service providers it already provides with CPUs.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;So in the long run, the ones who will truly be paying for OpenAI’s giant multi-year purchase of AMD GPUs will be retail and institutional investors if they do indeed bid the stock price up.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In many ways Nvidia is also financing OpenAI’s purchases of Nvidia’s wares with&amp;nbsp;its&amp;nbsp;own&amp;nbsp;$100 billion investment&amp;nbsp;announced last month. The difference, of course, is that&amp;nbsp;Nvidia’s&amp;nbsp;multiple&amp;nbsp;investments&amp;nbsp;in OpenAI&amp;nbsp;has granted Nvidia a&amp;nbsp;stake in the fast-growing AI provider, not the other way around.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what choice did AMD have? By financially engineering&amp;nbsp;a deal that costs OpenAI little,&amp;nbsp;it gets a significant&amp;nbsp;foothold&amp;nbsp;— as much as 30%&amp;nbsp;market share,&amp;nbsp;USB estimates&amp;nbsp;—&amp;nbsp;into one of the biggest&amp;nbsp;build-outs&amp;nbsp;of next-generation data centers the world has ever seen.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While Arcuri admits that AMD’s deal is “arguably less attractive” than Nvidia’s, “we see this as a major validation of its [AMD’s] roadmap that could snowball to other customers.”&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2019/08/GettyImages-1165704565.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After AMD and OpenAI announced an&amp;nbsp;expanded partnership on Monday, the chatter immediately turned to&amp;nbsp;the unusual way OpenAI would pay for its AMD purchases. It will use AMD’s own stock to do so.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To recap: OpenAI has agreed to help AMD refine its line of Nvidia competitor chips, the Instinct GPUs, as well as to purchase and deploy 6 gigawatts of compute capacity from AMD over multiple years. AMD said this deal is worth billions in revenue.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But OpenAI&amp;nbsp;isn’t&amp;nbsp;paying for this out of&amp;nbsp;its&amp;nbsp;own revenues.&amp;nbsp;Instead&amp;nbsp;AMD has granted OpenAI a boatload of stock&amp;nbsp;warrants&amp;nbsp;—&amp;nbsp;up to 160 million AMD shares&amp;nbsp;—&amp;nbsp;which will vest&amp;nbsp;in tranches&amp;nbsp;as certain milestones are achieved. Those milestones include&amp;nbsp;specific&amp;nbsp;increases in the stock price, with the last tranche dependent on AMD shares soaring to $600 apiece, AMD disclosed. They were trading at&amp;nbsp;about $165 before the news&amp;nbsp;hit and&amp;nbsp;soared to $214 by&amp;nbsp;market close&amp;nbsp;Monday&amp;nbsp;after the announcement.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If the stock price hits its marks, and OpenAI achieves all its required contributions, and OpenAI holds all of AMD’s shares, not selling any along the way, OpenAI may make enough on AMD stock to pay for a lot of GPUs. The stock could be worth about $100 billion.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We would note that the final 6th tranche requires ~$1T market cap to vest – ergo, if OAI were to hold stock until the end of the deal, its stake would be worth ~$100B,” writes UBS analyst Timothy Arcuri in a research note on Tuesday.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Arcuri believes that a more likely scenario is that OpenAI will sell its AMD stock along the way to pay its AMD bill. So, essentially, this is a scheme for AMD to finance this customer’s purchases.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Arcuri argues, the validation that AMD’s AI GPUs can handle OpenAI workloads, and ergo any other AI workloads, is valuable enough for AMD to make this financing gambit. “AMD highlighted ongoing customer dialogs beyond OpenAI and expects this agreement to ultimately accelerate AMD adoption momentum,” he writes. In particular, OpenAI’s stamp of approval gives it an in to sell its GPUs to the many cloud service providers it already provides with CPUs.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;So in the long run, the ones who will truly be paying for OpenAI’s giant multi-year purchase of AMD GPUs will be retail and institutional investors if they do indeed bid the stock price up.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In many ways Nvidia is also financing OpenAI’s purchases of Nvidia’s wares with&amp;nbsp;its&amp;nbsp;own&amp;nbsp;$100 billion investment&amp;nbsp;announced last month. The difference, of course, is that&amp;nbsp;Nvidia’s&amp;nbsp;multiple&amp;nbsp;investments&amp;nbsp;in OpenAI&amp;nbsp;has granted Nvidia a&amp;nbsp;stake in the fast-growing AI provider, not the other way around.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what choice did AMD have? By financially engineering&amp;nbsp;a deal that costs OpenAI little,&amp;nbsp;it gets a significant&amp;nbsp;foothold&amp;nbsp;— as much as 30%&amp;nbsp;market share,&amp;nbsp;USB estimates&amp;nbsp;—&amp;nbsp;into one of the biggest&amp;nbsp;build-outs&amp;nbsp;of next-generation data centers the world has ever seen.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While Arcuri admits that AMD’s deal is “arguably less attractive” than Nvidia’s, “we see this as a major validation of its [AMD’s] roadmap that could snowball to other customers.”&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/07/wall-street-analysts-explain-how-amds-own-stock-will-pay-for-openais-billions-in-chip-purchases/</guid><pubDate>Tue, 07 Oct 2025 21:00:19 +0000</pubDate></item><item><title>[NEW] Google's AI can now surf the web for you, click on buttons, and fill out forms with Gemini 2.5 Computer Use (AI | VentureBeat)</title><link>https://venturebeat.com/ai/googles-ai-can-now-surf-the-web-for-you-click-on-buttons-and-fill-out-forms</link><description>[unable to retrieve full-text content]&lt;p&gt;Some of the largest providers of large language models (LLMs) have sought to move beyond multimodal chatbots — extending their models out into &amp;quot;agents&amp;quot; that can actually take more actions on behalf of the user across websites. Recall &lt;a href="https://venturebeat.com/ai/openai-unveils-chatgpt-agent-that-gives-chatgpt-its-own-computer-to-autonomously-use-your-email-and-web-apps-download-and-create-files-for-you"&gt;OpenAI&amp;#x27;s ChatGPT Agent &lt;/a&gt;(formerly known as &amp;quot;&lt;a href="https://venturebeat.com/ai/meet-openais-operator-an-ai-agent-that-uses-the-web-to-book-you-dinner-reservations-order-tickets-compile-grocery-lists-and-more"&gt;Operator&lt;/a&gt;&amp;quot;) and &lt;a href="https://venturebeat.com/ai/anthropic-new-ai-can-use-computers-like-a-human-redefining-automation-for-enterprises"&gt;Anthropic&amp;#x27;s Computer Use&lt;/a&gt;, both released over the last two years. &lt;/p&gt;&lt;p&gt;Now, Google is getting into that same game as well. Today, the search giant&amp;#x27;s&lt;b&gt; DeepMind AI lab subsidiary unveiled a new, fine-tuned and custom-trained version of its powerful Gemini 2.5 Pro LLM&lt;/b&gt; known as &amp;quot;&lt;a href="https://blog.google/technology/google-deepmind/gemini-computer-use-model/?utm_source=x&amp;amp;utm_medium=social&amp;amp;utm_campaign=&amp;amp;utm_content="&gt;Gemini 2.5 Pro Computer Use&lt;/a&gt;,&amp;quot; which can&lt;b&gt; use a virtual browser to surf the web on your behalf, retrieve information, fill out forms, and even take actions on websites&lt;/b&gt; — all from a user&amp;#x27;s single text prompt.&lt;/p&gt;&lt;p&gt;&amp;quot;These are early days, but the model’s ability to interact with the web – like scrolling, filling forms + navigating dropdowns – is an &lt;b&gt;important next step in building general-purpose agents,&amp;quot; &lt;/b&gt;said &lt;b&gt;Google CEO Sundar Pichai,&lt;/b&gt; as part of a &lt;a href="https://x.com/sundarpichai/status/1975668337364590913"&gt;longer statement on the social network, X.&lt;/a&gt;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;The model is not available for consumers directly from Google, though.&lt;/p&gt;&lt;p&gt;Instead, &lt;a href="https://x.com/browserbasehq/status/1975649022112374913"&gt;Google partnered &lt;/a&gt;with another company, &lt;a href="https://www.browserbase.com/"&gt;Browserbase&lt;/a&gt;, founded by &lt;a href="https://youtu.be/T8D9jfNEs9M?si=uaz2eHbvFByP0HBu"&gt;former Twilio engineer Paul Klein in early 2024&lt;/a&gt;, which offers virtual &amp;quot;headless&amp;quot; web browser specifically for use by AI agents and applications. (A &amp;quot;headless&amp;quot; browser is one that doesn&amp;#x27;t require a graphical user interface, or GUI, to navigate the web, though in this case and others, Browserbase does show a graphical representation for the user). &lt;/p&gt;&lt;p&gt;Users can demo the new Gemini 2.5 Computer Use model directly on Browserbase &lt;a href="https://gemini.browserbase.com/"&gt;here&lt;/a&gt; and even compare it side-by-side with the older, rival offerings from OpenAI and Anthropic in a new &amp;quot;&lt;a href="https://arena.browserbase.com/"&gt;Browser Arena&lt;/a&gt;&amp;quot; launched by the startup (though only one additional model can be selected alongside Gemini at a time).&lt;/p&gt;&lt;p&gt;For AI builders and developers, it&amp;#x27;s being made as a raw, albeit propreitary LLM &lt;!-- --&gt;through the &lt;a href="https://ai.google.dev/gemini-api/docs/computer-use"&gt;&lt;b&gt;Gemini API in Google AI Studio&lt;/b&gt;&lt;/a&gt; for &lt;a href="https://cloud.google.com/ai/gemini?hl=en"&gt;rapid prototyping&lt;/a&gt;, and Google Cloud&amp;#x27;s &lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/computer-use"&gt;&lt;b&gt;Vertex AI&lt;/b&gt;&lt;/a&gt; model selector and applications building platform. &lt;/p&gt;&lt;p&gt;The new offering builds on the capabilities of&lt;b&gt; Gemini 2.5 Pro&lt;/b&gt;, &lt;a href="https://venturebeat.com/ai/google-releases-most-intelligent-model-to-date-gemini-2-5-pro"&gt;released back in March 2025&lt;/a&gt; but which has been updated significantly several times since then, with a specific focus on enabling AI agents to perform direct interactions with user interfaces, including browsers and mobile applications.&lt;/p&gt;&lt;p&gt;Overall, it appears &lt;!-- --&gt;Gemini 2.5 Computer Use is designed to let developers create agents that can complete interface-driven tasks autonomously — such as clicking, typing, scrolling, filling out forms, and navigating behind login screens. &lt;/p&gt;&lt;p&gt;Rather than relying solely on APIs or structured inputs, this model allows AI systems to interact with software visually and functionally, much like a human would.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Brief User Hands-On Tests&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In my brief, unscientific initial hands-on tests on the Browserbase website, Gemini 2.5 Computer Use successfully navigate to Taylor Swift&amp;#x27;s official website as instructed and provided me a summary of what was being sold or promoted at the top — a special edition of her newest album, &amp;quot;The Life of A Showgirl.&amp;quot;&lt;/p&gt;&lt;p&gt;In another test, I asked Gemini 2.5 Computer Use to search Amazon for highly rated and well-reviewed solar lights I could stake into my back yard, and I was delighted to watch as it successfully completed a Google Search Captcha designed to weed out non-human users (&amp;quot;Select all the boxes with a motorcycle.&amp;quot;) It did so in a matter of seconds.&lt;/p&gt;&lt;p&gt;However, once it got through there, it stalled and was unable to complete the task, despite serving up a &amp;quot;task competed&amp;quot; message. &lt;/p&gt;&lt;p&gt;I should also note here that while the &lt;a href="https://venturebeat.com/ai/openai-unveils-chatgpt-agent-that-gives-chatgpt-its-own-computer-to-autonomously-use-your-email-and-web-apps-download-and-create-files-for-you"&gt;ChatGPT agent from OpenAI&lt;/a&gt; and &lt;a href="https://venturebeat.com/ai/claude-deepens-its-enterprise-push-with-document-generation-taking-the-ai"&gt;Anthropic&amp;#x27;s Claude&lt;/a&gt; can create and edit local files — such as PowerPoint presentations, spreadsheets, or text documents — on the user’s behalf, Gemini 2.5 Computer Use does not currently offer direct file system access or native file creation capabilities. &lt;/p&gt;&lt;p&gt;Instead, it is designed to control and navigate web and mobile user interfaces through actions like clicking, typing, and scrolling. Its output is limited to suggested UI actions or chatbot-style text responses; any structured output like a document or file must be handled separately by the developer, often through custom code or third-party integrations.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Performance Benchmarks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Google says Gemini 2.5 Computer Use  has demonstrated leading results in multiple interface control benchmarks, particularly when compared to other major AI systems including Claude Sonnet and OpenAI’s agent-based models. &lt;/p&gt;&lt;p&gt;Evaluations were conducted via Browserbase and Google’s own testing.&lt;/p&gt;&lt;p&gt;Some highlights include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Online-Mind2Web (Browserbase):&lt;/b&gt; 65.7% for Gemini 2.5 vs. 61.0% (Claude Sonnet 4) and 44.3% (OpenAI Agent)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;WebVoyager (Browserbase):&lt;/b&gt; 79.9% for Gemini 2.5 vs. 69.4% (Claude Sonnet 4) and 61.0% (OpenAI Agent)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;AndroidWorld (DeepMind):&lt;/b&gt; 69.7% for Gemini 2.5 vs. 62.1% (Claude Sonnet 4); OpenAI&amp;#x27;s model could not be measured due to lack of access&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;OSWorld:&lt;/b&gt; Currently not supported by Gemini 2.5; top competitor result was 61.4%&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In addition to strong accuracy, Google reports that the model operates at lower latency than other browser control solutions — a key factor in production use cases like UI automation and testing.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;How It Works&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Agents powered by the Computer Use model operate within an interaction loop. They receive:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A user task prompt&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A screenshot of the interface&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A history of past actions&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The model analyzes this input and produces a recommended UI action, such as clicking a button or typing into a field. &lt;/p&gt;&lt;p&gt;If needed, it can request confirmation from the end user for riskier tasks, such as making a purchase.&lt;/p&gt;&lt;p&gt;Once the action is executed, the interface state is updated and a new screenshot is sent back to the model. The loop continues until the task is completed or halted due to an error or a safety decision.&lt;/p&gt;&lt;p&gt;The model uses a specialized tool called &lt;code&gt;computer_use&lt;/code&gt;, and it can be integrated into custom environments using tools like &lt;b&gt;Playwright&lt;/b&gt; or via the &lt;b&gt;Browserbase&lt;/b&gt; demo sandbox.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Use Cases and Adoption&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;According to Google, teams internally and externally have already started using the model across several domains:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Google’s payments platform team&lt;/b&gt; reports that Gemini 2.5 Computer Use successfully recovers over 60% of failed test executions, reducing a major source of engineering inefficiencies.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Autotab&lt;/b&gt;, a third-party AI agent platform, said the model outperformed others on complex data parsing tasks, boosting performance by up to 18% in their hardest evaluations.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Poke.com&lt;/b&gt;, a proactive AI assistant provider, noted that the Gemini model often operates &lt;b&gt;50% faster&lt;/b&gt; than competing solutions during interface interactions.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The model is also being used in Google’s own product development efforts, including in &lt;b&gt;Project Mariner&lt;/b&gt;, the &lt;b&gt;Firebase Testing Agent&lt;/b&gt;, and &lt;b&gt;AI Mode in Search&lt;/b&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Safety Measures&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Because this model directly controls software interfaces, Google emphasizes a multi-layered approach to safety:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A &lt;b&gt;per-step safety service&lt;/b&gt; inspects every proposed action before execution.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Developers can define &lt;b&gt;system-level instructions&lt;/b&gt; to block or require confirmation for specific actions.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The model includes built-in safeguards to avoid actions that might compromise security or violate Google’s prohibited use policies.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For example, if the model encounters a CAPTCHA, it will generate an action to click the checkbox but flag it as requiring user confirmation, ensuring the system does not proceed without human oversight.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Technical Capabilities&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The model supports a wide array of built-in UI actions such as:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;click_at&lt;/code&gt;, &lt;code&gt;type_text_at&lt;/code&gt;, &lt;code&gt;scroll_document&lt;/code&gt;, &lt;code&gt;drag_and_drop&lt;/code&gt;, and more&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;User-defined functions can be added to extend its reach to mobile or custom environments&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Screen coordinates are normalized (0–1000 scale) and translated back to pixel dimensions during execution&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;It accepts &lt;b&gt;image and text&lt;/b&gt; input and outputs &lt;b&gt;text responses&lt;/b&gt; or &lt;b&gt;function calls&lt;/b&gt; to perform tasks. The recommended screen resolution for optimal results is &lt;b&gt;1440x900&lt;/b&gt;, though it can work with other sizes.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;API Pricing Remains Almost Identical to Gemini 2.5 Pro&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The pricing for &lt;b&gt;Gemini 2.5 Computer Use&lt;/b&gt; aligns closely with the standard Gemini 2.5 Pro model. Both follow the same per-token billing structure: input tokens are priced at &lt;b&gt;$1.25 per one million tokens&lt;/b&gt; for prompts under 200,000 tokens, and &lt;b&gt;$2.50 per million tokens&lt;/b&gt; for prompts longer than that. &lt;/p&gt;&lt;p&gt;Output tokens follow a similar split, priced at &lt;b&gt;$10.00 per million&lt;/b&gt; for smaller responses and &lt;b&gt;$15.00&lt;/b&gt; for larger ones.&lt;/p&gt;&lt;p&gt;Where the models diverge is in availability and additional features. &lt;/p&gt;&lt;p&gt;&lt;b&gt;Gemini 2.5 Pro includes a free tier &lt;/b&gt;that allows developers to use the model at no cost, with no explicit token cap published, though usage may be subject to rate limits or quota constraints depending on the platform (e.g. Google AI Studio). &lt;/p&gt;&lt;p&gt;This free access includes both input and output tokens. Once developers exceed their allotted quota or switch to the paid tier, standard per-token pricing applies.&lt;/p&gt;&lt;p&gt;In contrast, &lt;b&gt;Gemini 2.5 Computer Use is available exclusively through the paid tier.&lt;/b&gt; There is &lt;b&gt;no free access&lt;/b&gt; currently offered for this model, and all usage incurs token-based charges from the outset.&lt;/p&gt;&lt;p&gt;Feature-wise, Gemini 2.5 Pro supports optional capabilities like context caching (starting at $0.31 per million tokens) and grounding with Google Search (free for up to 1,500 requests per day, then $35 per 1,000 additional requests). These are not available for Computer Use at this time.&lt;/p&gt;&lt;p&gt;Another distinction is in data handling: output from the Computer Use model is not used to improve Google products in the paid tier, while free-tier usage of Gemini 2.5 Pro contributes to model improvement unless explicitly opted out.&lt;/p&gt;&lt;p&gt;Overall, developers can expect similar token-based costs across both models, but they should consider tier access, included capabilities, and data use policies when deciding which model fits their needs.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Some of the largest providers of large language models (LLMs) have sought to move beyond multimodal chatbots — extending their models out into &amp;quot;agents&amp;quot; that can actually take more actions on behalf of the user across websites. Recall &lt;a href="https://venturebeat.com/ai/openai-unveils-chatgpt-agent-that-gives-chatgpt-its-own-computer-to-autonomously-use-your-email-and-web-apps-download-and-create-files-for-you"&gt;OpenAI&amp;#x27;s ChatGPT Agent &lt;/a&gt;(formerly known as &amp;quot;&lt;a href="https://venturebeat.com/ai/meet-openais-operator-an-ai-agent-that-uses-the-web-to-book-you-dinner-reservations-order-tickets-compile-grocery-lists-and-more"&gt;Operator&lt;/a&gt;&amp;quot;) and &lt;a href="https://venturebeat.com/ai/anthropic-new-ai-can-use-computers-like-a-human-redefining-automation-for-enterprises"&gt;Anthropic&amp;#x27;s Computer Use&lt;/a&gt;, both released over the last two years. &lt;/p&gt;&lt;p&gt;Now, Google is getting into that same game as well. Today, the search giant&amp;#x27;s&lt;b&gt; DeepMind AI lab subsidiary unveiled a new, fine-tuned and custom-trained version of its powerful Gemini 2.5 Pro LLM&lt;/b&gt; known as &amp;quot;&lt;a href="https://blog.google/technology/google-deepmind/gemini-computer-use-model/?utm_source=x&amp;amp;utm_medium=social&amp;amp;utm_campaign=&amp;amp;utm_content="&gt;Gemini 2.5 Pro Computer Use&lt;/a&gt;,&amp;quot; which can&lt;b&gt; use a virtual browser to surf the web on your behalf, retrieve information, fill out forms, and even take actions on websites&lt;/b&gt; — all from a user&amp;#x27;s single text prompt.&lt;/p&gt;&lt;p&gt;&amp;quot;These are early days, but the model’s ability to interact with the web – like scrolling, filling forms + navigating dropdowns – is an &lt;b&gt;important next step in building general-purpose agents,&amp;quot; &lt;/b&gt;said &lt;b&gt;Google CEO Sundar Pichai,&lt;/b&gt; as part of a &lt;a href="https://x.com/sundarpichai/status/1975668337364590913"&gt;longer statement on the social network, X.&lt;/a&gt;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;The model is not available for consumers directly from Google, though.&lt;/p&gt;&lt;p&gt;Instead, &lt;a href="https://x.com/browserbasehq/status/1975649022112374913"&gt;Google partnered &lt;/a&gt;with another company, &lt;a href="https://www.browserbase.com/"&gt;Browserbase&lt;/a&gt;, founded by &lt;a href="https://youtu.be/T8D9jfNEs9M?si=uaz2eHbvFByP0HBu"&gt;former Twilio engineer Paul Klein in early 2024&lt;/a&gt;, which offers virtual &amp;quot;headless&amp;quot; web browser specifically for use by AI agents and applications. (A &amp;quot;headless&amp;quot; browser is one that doesn&amp;#x27;t require a graphical user interface, or GUI, to navigate the web, though in this case and others, Browserbase does show a graphical representation for the user). &lt;/p&gt;&lt;p&gt;Users can demo the new Gemini 2.5 Computer Use model directly on Browserbase &lt;a href="https://gemini.browserbase.com/"&gt;here&lt;/a&gt; and even compare it side-by-side with the older, rival offerings from OpenAI and Anthropic in a new &amp;quot;&lt;a href="https://arena.browserbase.com/"&gt;Browser Arena&lt;/a&gt;&amp;quot; launched by the startup (though only one additional model can be selected alongside Gemini at a time).&lt;/p&gt;&lt;p&gt;For AI builders and developers, it&amp;#x27;s being made as a raw, albeit propreitary LLM &lt;!-- --&gt;through the &lt;a href="https://ai.google.dev/gemini-api/docs/computer-use"&gt;&lt;b&gt;Gemini API in Google AI Studio&lt;/b&gt;&lt;/a&gt; for &lt;a href="https://cloud.google.com/ai/gemini?hl=en"&gt;rapid prototyping&lt;/a&gt;, and Google Cloud&amp;#x27;s &lt;a href="https://cloud.google.com/vertex-ai/generative-ai/docs/computer-use"&gt;&lt;b&gt;Vertex AI&lt;/b&gt;&lt;/a&gt; model selector and applications building platform. &lt;/p&gt;&lt;p&gt;The new offering builds on the capabilities of&lt;b&gt; Gemini 2.5 Pro&lt;/b&gt;, &lt;a href="https://venturebeat.com/ai/google-releases-most-intelligent-model-to-date-gemini-2-5-pro"&gt;released back in March 2025&lt;/a&gt; but which has been updated significantly several times since then, with a specific focus on enabling AI agents to perform direct interactions with user interfaces, including browsers and mobile applications.&lt;/p&gt;&lt;p&gt;Overall, it appears &lt;!-- --&gt;Gemini 2.5 Computer Use is designed to let developers create agents that can complete interface-driven tasks autonomously — such as clicking, typing, scrolling, filling out forms, and navigating behind login screens. &lt;/p&gt;&lt;p&gt;Rather than relying solely on APIs or structured inputs, this model allows AI systems to interact with software visually and functionally, much like a human would.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Brief User Hands-On Tests&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In my brief, unscientific initial hands-on tests on the Browserbase website, Gemini 2.5 Computer Use successfully navigate to Taylor Swift&amp;#x27;s official website as instructed and provided me a summary of what was being sold or promoted at the top — a special edition of her newest album, &amp;quot;The Life of A Showgirl.&amp;quot;&lt;/p&gt;&lt;p&gt;In another test, I asked Gemini 2.5 Computer Use to search Amazon for highly rated and well-reviewed solar lights I could stake into my back yard, and I was delighted to watch as it successfully completed a Google Search Captcha designed to weed out non-human users (&amp;quot;Select all the boxes with a motorcycle.&amp;quot;) It did so in a matter of seconds.&lt;/p&gt;&lt;p&gt;However, once it got through there, it stalled and was unable to complete the task, despite serving up a &amp;quot;task competed&amp;quot; message. &lt;/p&gt;&lt;p&gt;I should also note here that while the &lt;a href="https://venturebeat.com/ai/openai-unveils-chatgpt-agent-that-gives-chatgpt-its-own-computer-to-autonomously-use-your-email-and-web-apps-download-and-create-files-for-you"&gt;ChatGPT agent from OpenAI&lt;/a&gt; and &lt;a href="https://venturebeat.com/ai/claude-deepens-its-enterprise-push-with-document-generation-taking-the-ai"&gt;Anthropic&amp;#x27;s Claude&lt;/a&gt; can create and edit local files — such as PowerPoint presentations, spreadsheets, or text documents — on the user’s behalf, Gemini 2.5 Computer Use does not currently offer direct file system access or native file creation capabilities. &lt;/p&gt;&lt;p&gt;Instead, it is designed to control and navigate web and mobile user interfaces through actions like clicking, typing, and scrolling. Its output is limited to suggested UI actions or chatbot-style text responses; any structured output like a document or file must be handled separately by the developer, often through custom code or third-party integrations.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Performance Benchmarks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Google says Gemini 2.5 Computer Use  has demonstrated leading results in multiple interface control benchmarks, particularly when compared to other major AI systems including Claude Sonnet and OpenAI’s agent-based models. &lt;/p&gt;&lt;p&gt;Evaluations were conducted via Browserbase and Google’s own testing.&lt;/p&gt;&lt;p&gt;Some highlights include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Online-Mind2Web (Browserbase):&lt;/b&gt; 65.7% for Gemini 2.5 vs. 61.0% (Claude Sonnet 4) and 44.3% (OpenAI Agent)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;WebVoyager (Browserbase):&lt;/b&gt; 79.9% for Gemini 2.5 vs. 69.4% (Claude Sonnet 4) and 61.0% (OpenAI Agent)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;AndroidWorld (DeepMind):&lt;/b&gt; 69.7% for Gemini 2.5 vs. 62.1% (Claude Sonnet 4); OpenAI&amp;#x27;s model could not be measured due to lack of access&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;OSWorld:&lt;/b&gt; Currently not supported by Gemini 2.5; top competitor result was 61.4%&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In addition to strong accuracy, Google reports that the model operates at lower latency than other browser control solutions — a key factor in production use cases like UI automation and testing.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;How It Works&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Agents powered by the Computer Use model operate within an interaction loop. They receive:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A user task prompt&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A screenshot of the interface&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A history of past actions&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The model analyzes this input and produces a recommended UI action, such as clicking a button or typing into a field. &lt;/p&gt;&lt;p&gt;If needed, it can request confirmation from the end user for riskier tasks, such as making a purchase.&lt;/p&gt;&lt;p&gt;Once the action is executed, the interface state is updated and a new screenshot is sent back to the model. The loop continues until the task is completed or halted due to an error or a safety decision.&lt;/p&gt;&lt;p&gt;The model uses a specialized tool called &lt;code&gt;computer_use&lt;/code&gt;, and it can be integrated into custom environments using tools like &lt;b&gt;Playwright&lt;/b&gt; or via the &lt;b&gt;Browserbase&lt;/b&gt; demo sandbox.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Use Cases and Adoption&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;According to Google, teams internally and externally have already started using the model across several domains:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Google’s payments platform team&lt;/b&gt; reports that Gemini 2.5 Computer Use successfully recovers over 60% of failed test executions, reducing a major source of engineering inefficiencies.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Autotab&lt;/b&gt;, a third-party AI agent platform, said the model outperformed others on complex data parsing tasks, boosting performance by up to 18% in their hardest evaluations.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Poke.com&lt;/b&gt;, a proactive AI assistant provider, noted that the Gemini model often operates &lt;b&gt;50% faster&lt;/b&gt; than competing solutions during interface interactions.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The model is also being used in Google’s own product development efforts, including in &lt;b&gt;Project Mariner&lt;/b&gt;, the &lt;b&gt;Firebase Testing Agent&lt;/b&gt;, and &lt;b&gt;AI Mode in Search&lt;/b&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Safety Measures&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Because this model directly controls software interfaces, Google emphasizes a multi-layered approach to safety:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A &lt;b&gt;per-step safety service&lt;/b&gt; inspects every proposed action before execution.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Developers can define &lt;b&gt;system-level instructions&lt;/b&gt; to block or require confirmation for specific actions.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The model includes built-in safeguards to avoid actions that might compromise security or violate Google’s prohibited use policies.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For example, if the model encounters a CAPTCHA, it will generate an action to click the checkbox but flag it as requiring user confirmation, ensuring the system does not proceed without human oversight.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Technical Capabilities&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The model supports a wide array of built-in UI actions such as:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;click_at&lt;/code&gt;, &lt;code&gt;type_text_at&lt;/code&gt;, &lt;code&gt;scroll_document&lt;/code&gt;, &lt;code&gt;drag_and_drop&lt;/code&gt;, and more&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;User-defined functions can be added to extend its reach to mobile or custom environments&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Screen coordinates are normalized (0–1000 scale) and translated back to pixel dimensions during execution&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;It accepts &lt;b&gt;image and text&lt;/b&gt; input and outputs &lt;b&gt;text responses&lt;/b&gt; or &lt;b&gt;function calls&lt;/b&gt; to perform tasks. The recommended screen resolution for optimal results is &lt;b&gt;1440x900&lt;/b&gt;, though it can work with other sizes.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;API Pricing Remains Almost Identical to Gemini 2.5 Pro&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The pricing for &lt;b&gt;Gemini 2.5 Computer Use&lt;/b&gt; aligns closely with the standard Gemini 2.5 Pro model. Both follow the same per-token billing structure: input tokens are priced at &lt;b&gt;$1.25 per one million tokens&lt;/b&gt; for prompts under 200,000 tokens, and &lt;b&gt;$2.50 per million tokens&lt;/b&gt; for prompts longer than that. &lt;/p&gt;&lt;p&gt;Output tokens follow a similar split, priced at &lt;b&gt;$10.00 per million&lt;/b&gt; for smaller responses and &lt;b&gt;$15.00&lt;/b&gt; for larger ones.&lt;/p&gt;&lt;p&gt;Where the models diverge is in availability and additional features. &lt;/p&gt;&lt;p&gt;&lt;b&gt;Gemini 2.5 Pro includes a free tier &lt;/b&gt;that allows developers to use the model at no cost, with no explicit token cap published, though usage may be subject to rate limits or quota constraints depending on the platform (e.g. Google AI Studio). &lt;/p&gt;&lt;p&gt;This free access includes both input and output tokens. Once developers exceed their allotted quota or switch to the paid tier, standard per-token pricing applies.&lt;/p&gt;&lt;p&gt;In contrast, &lt;b&gt;Gemini 2.5 Computer Use is available exclusively through the paid tier.&lt;/b&gt; There is &lt;b&gt;no free access&lt;/b&gt; currently offered for this model, and all usage incurs token-based charges from the outset.&lt;/p&gt;&lt;p&gt;Feature-wise, Gemini 2.5 Pro supports optional capabilities like context caching (starting at $0.31 per million tokens) and grounding with Google Search (free for up to 1,500 requests per day, then $35 per 1,000 additional requests). These are not available for Computer Use at this time.&lt;/p&gt;&lt;p&gt;Another distinction is in data handling: output from the Computer Use model is not used to improve Google products in the paid tier, while free-tier usage of Gemini 2.5 Pro contributes to model improvement unless explicitly opted out.&lt;/p&gt;&lt;p&gt;Overall, developers can expect similar token-based costs across both models, but they should consider tier access, included capabilities, and data use policies when deciding which model fits their needs.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/googles-ai-can-now-surf-the-web-for-you-click-on-buttons-and-fill-out-forms</guid><pubDate>Tue, 07 Oct 2025 22:20:00 +0000</pubDate></item><item><title>[NEW] OpenAI Dev Day 2025: ChatGPT becomes the new app store — and hardware is coming (AI | VentureBeat)</title><link>https://venturebeat.com/ai/openai-dev-day-2025-chatgpt-becomes-the-new-app-store-and-hardware-is-coming</link><description>[unable to retrieve full-text content]&lt;p&gt;In a packed hall at Fort Mason Center in San Francisco, against a backdrop of the Golden Gate Bridge, &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt; CEO Sam Altman laid out a bold vision to remake the digital world. The company that brought generative AI to the mainstream with a simple chatbot is now building the foundations for its next act: a comprehensive computing platform designed to move beyond the screen and browser, with legendary designer Jony Ive enlisted to help shape its physical form.&lt;/p&gt;&lt;p&gt;At its &lt;a href="https://openai.com/devday/"&gt;&lt;u&gt;third annual DevDay&lt;/u&gt;&lt;/a&gt;, OpenAI unveiled a suite of tools that signals a strategic pivot from a model provider to a full-fledged ecosystem. The message was clear: the era of simply asking an AI questions is over. The future is about commanding AI to perform complex tasks, build software autonomously, and live inside every application, a transition Altman framed as moving from &amp;quot;systems that you can ask anything to, to systems that you can ask to do anything for you.&amp;quot; &lt;/p&gt;&lt;p&gt;The day’s announcements were a three-pronged assault on the status quo, targeting how users interact with software, how developers build it, and how businesses deploy intelligent agents. But it was the sessions held behind closed doors, away from the &lt;a href="https://www.youtube.com/live/hS1YqcewH0c?si=mFE2rRx3QrK7z6NF"&gt;&lt;u&gt;public livestream&lt;/u&gt;&lt;/a&gt;, that revealed the true scope of OpenAI’s ambition — a future that includes new hardware, a relentless pursuit of computational power, and a philosophical quest to redefine our relationship with technology.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;From chatbot to operating system: The new &amp;#x27;App Store&amp;#x27;&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The centerpiece of the public-facing keynote was the transformation of &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt; itself. With the new &lt;a href="https://openai.com/index/introducing-apps-in-chatgpt/"&gt;&lt;u&gt;Apps SDK&lt;/u&gt;&lt;/a&gt;, OpenAI is turning its wildly popular chatbot into a dynamic, interactive platform, effectively an operating system where developers can build and distribute their own applications.&lt;/p&gt;&lt;p&gt;“Today, we&amp;#x27;re going to open up ChatGPT for developers to build real apps inside of ChatGPT,” Altman announced during the keynote presentation to applause. “This will enable a new generation of apps that are interactive, adaptive and personalized, that you can chat with.”&lt;/p&gt;&lt;p&gt;Live demonstrations showcased apps from partners like &lt;a href="https://www.coursera.org/"&gt;&lt;u&gt;Coursera&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.canva.com/"&gt;&lt;u&gt;Canva&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.zillow.com/"&gt;&lt;u&gt;Zillow&lt;/u&gt;&lt;/a&gt; running seamlessly within a chat conversation. A user could watch a machine learning lecture, ask &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt; to explain a concept in real-time, and then use Canva to generate a poster based on the conversation, all without leaving the chat interface. The apps can render rich, interactive UIs, even going full-screen to offer a complete experience, like exploring a Zillow map of homes.&lt;/p&gt;&lt;p&gt;For developers, this represents a powerful new distribution channel. “When you build with the Apps SDK, your apps can reach hundreds of millions of chat users,” Altman said, highlighting a direct path to a massive user base that has grown to over &lt;a href="https://venturebeat.com/ai/openai-announces-apps-sdk-allowing-chatgpt-to-launch-and-run-third-party"&gt;&lt;u&gt;800 million weekly active users&lt;/u&gt;&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;In a private press conference later, Nick Turley, head of ChatGPT, elaborated on the grander vision. &amp;quot;We never meant to build a chatbot,&amp;quot; he stated. &amp;quot;When we set out to make ChatGPT, we meant to build a super assistant and we got a little sidetracked. And one of the tragedies of getting a little sidetracked is that we built a great chatbot, but we are the first ones to say that not all software needs to be a chatbot, not all interaction with the commercial world needs to be a chatbot.&amp;quot;&lt;/p&gt;&lt;p&gt;Turley emphasized that while OpenAI is excited about natural language interfaces, &amp;quot;the interface really needs to evolve, which is why you see so much UI in the demos today. In fact, you can even go full screen and chat is in the background.&amp;quot; He described a future where users might &amp;quot;start your day in ChatGPT, just because it kind of has become the de facto entry point into the commercial web and into a lot of software,&amp;quot; but clarified that &amp;quot;our incentive is not to keep you in. Our product is to allow other people to build amazing businesses on top and to evolve the form factor of software.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The rise of the agents: Building the &amp;#x27;do anything&amp;#x27; AI&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;If apps are about bringing the world into ChatGPT, the new &amp;quot;&lt;a href="https://openai.com/index/introducing-agentkit/"&gt;&lt;u&gt;Agent Kit&lt;/u&gt;&lt;/a&gt;&amp;quot; is about sending AI out into the world to get things done. OpenAI is providing a complete &amp;quot;set of building blocks... to help you take agents from prototype to production,&amp;quot; Altman explained in his keynote. &lt;/p&gt;&lt;p&gt;&lt;a href="https://openai.com/index/introducing-agentkit/"&gt;&lt;u&gt;Agent Kit&lt;/u&gt;&lt;/a&gt; is an integrated development environment for creating autonomous AI workers. It features a visual canvas to design complex workflows, an embeddable chat interface (&amp;quot;Chat Kit&amp;quot;) for deploying agents in any app, and a sophisticated evaluation suite to measure and improve performance.&lt;/p&gt;&lt;p&gt;A compelling demo from financial operations platform &lt;a href="https://ramp.com/"&gt;&lt;u&gt;Ramp&lt;/u&gt;&lt;/a&gt; showed how Agent Kit was used to build a procurement agent. An employee could simply type, &amp;quot;I need five more ChatGPT business seats,&amp;quot; and the agent would parse the request, check it against company expense policies, find vendor details, and prepare a virtual credit card for the purchase — a process that once took weeks now completed in minutes. &lt;/p&gt;&lt;p&gt;This push into agents is a direct response to a growing enterprise need to move beyond AI as a simple information retrieval tool and toward AI as a productivity engine that automates complex business processes. Brad Lightcap, OpenAI&amp;#x27;s COO, noted that for enterprise adoption, &amp;quot;you needed this kind of shift to more agentic AI that could actually do things for you, versus just respond with text outputs.&amp;quot; &lt;/p&gt;&lt;h3&gt;&lt;b&gt;The future of code and the Jony Ive bBombshell&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Perhaps the most profound shift is occurring in software development itself. &lt;a href="https://openai.com/index/codex-now-generally-available/"&gt;&lt;u&gt;Codex&lt;/u&gt;&lt;/a&gt;, OpenAI&amp;#x27;s AI coding agent, has graduated from a research preview to a full-fledged product, now powered by a specialized version of the new GPT-5 model. It is, as one speaker put it, &amp;quot;a teammate that understands your context.&amp;quot; &lt;/p&gt;&lt;p&gt;The capabilities are staggering. Developers can now assign &lt;a href="https://openai.com/index/codex-now-generally-available/"&gt;&lt;u&gt;Codex&lt;/u&gt;&lt;/a&gt; tasks directly from &lt;a href="https://slack.com/"&gt;&lt;u&gt;Slack&lt;/u&gt;&lt;/a&gt;, and the agent can autonomously write code, create pull requests, and even review other engineers&amp;#x27; work on &lt;a href="https://github.com/"&gt;&lt;u&gt;GitHub&lt;/u&gt;&lt;/a&gt;. A live demo showed Codex taking a simple photo of a whiteboard sketch and turning it into a fully functional, beautifully designed mobile app screen. Another demo showed an app that could &amp;quot;self-evolve,&amp;quot; reprogramming itself in real-time based on a user&amp;#x27;s natural language request. &lt;/p&gt;&lt;p&gt;But the day&amp;#x27;s biggest surprise came in a closing fireside chat, which was not livestreamed, between &lt;a href="https://openai.com/sam-and-jony/"&gt;&lt;u&gt;Altman and Jony Ive&lt;/u&gt;&lt;/a&gt;, the iconic former chief design officer of Apple. The two revealed they have been collaborating for three years on a new family of AI-centric hardware.&lt;/p&gt;&lt;p&gt;Ive, whose design philosophy shaped the iPhone, iMac, and Apple Watch, said his creative team’s purpose &amp;quot;became clear&amp;quot; with the launch of ChatGPT. He argued that our current relationship with technology is broken and that AI presents an opportunity for a fundamental reset.&lt;/p&gt;&lt;p&gt;“I think it would be absurd to assume that you could have technology that is this breathtaking, delivered to us through legacy products, products that are decades old,” Ive said. “I see it as a chance to use this most remarkable capability to full-on address a lot of the overwhelm and despair that people feel right now.”&lt;/p&gt;&lt;p&gt;While details of the devices remain secret, Ive spoke of his motivation in deeply human terms. “We love our species, and we want to be useful. We think that humanity deserves much better than humanity generally is given,” he said. He emphasized the importance of &amp;quot;care&amp;quot; in the design process, stating, &amp;quot;We sense when people have cared... you sense carelessness. You sense when somebody does not care about you, they care about money and schedule.&amp;quot; &lt;/p&gt;&lt;p&gt;This collaboration confirms that OpenAI&amp;#x27;s ambitions are not confined to the cloud; it is actively exploring the physical interface through which humanity will interact with its powerful new intelligence.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The Unquenchable Thirst for Compute&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Underpinning this entire platform strategy is a single, overwhelming constraint: the availability of computing power. In both the private press conference and the un-streamed Developer State of the Union, OpenAI’s leadership returned to this theme again and again.&lt;/p&gt;&lt;p&gt;“The degree to which we are all constrained by compute... Everyone is just so constrained on being able to offer the services at the scale required to get the revenue that at this point, we&amp;#x27;re quite confident we can push it pretty far,” Altman told reporters. He added that even with massive new hardware partnerships with AMD and others, &amp;quot;we&amp;#x27;ll be saying the same thing again. We&amp;#x27;re so convinced... There&amp;#x27;s so much more demand.&amp;quot; &lt;/p&gt;&lt;p&gt;This explains the company’s aggressive, &lt;a href="https://www.reuters.com/business/autos-transportation/companies-pouring-billions-advance-ai-infrastructure-2025-10-06/"&gt;&lt;u&gt;multi-billion-dollar investment in infrastructure&lt;/u&gt;&lt;/a&gt;. When asked about profitability, Altman was candid that the company is in a phase of &amp;quot;investment and growth.&amp;quot; He invoked a famous quote from Walt Disney, paraphrasing, &amp;quot;We make more money so we can make more movies.&amp;quot; For OpenAI, the &amp;quot;movies&amp;quot; are ever-more-powerful AI models.&lt;/p&gt;&lt;p&gt;Greg Brockman, OpenAI’s President, put the ultimate goal in stark economic terms during the Developer State of the Union. &amp;quot;AI is going to become, probably in the not too distant future, the fundamental driver of economic growth,&amp;quot; he said. &amp;quot;Asking ‘How much compute do you want?’ is a little bit like asking how much workforce do you want? The answer is, you can always get more out of more.&amp;quot; &lt;/p&gt;&lt;p&gt;As the day concluded and developers mingled at the reception, the scale of OpenAI&amp;#x27;s project came into focus. Fueled by new models like the powerful &lt;a href="https://platform.openai.com/docs/models/gpt-5-pro"&gt;&lt;u&gt;GPT-5 Pro&lt;/u&gt;&lt;/a&gt; and the stunning &lt;a href="https://openai.com/index/sora-2/"&gt;&lt;u&gt;Sora 2&lt;/u&gt;&lt;/a&gt; video generator, the company is no longer just building AI. It is building the world where AI will live — a world of intelligent apps, autonomous agents, and new physical devices, betting that in the near future, intelligence itself will be the ultimate platform.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;In a packed hall at Fort Mason Center in San Francisco, against a backdrop of the Golden Gate Bridge, &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt; CEO Sam Altman laid out a bold vision to remake the digital world. The company that brought generative AI to the mainstream with a simple chatbot is now building the foundations for its next act: a comprehensive computing platform designed to move beyond the screen and browser, with legendary designer Jony Ive enlisted to help shape its physical form.&lt;/p&gt;&lt;p&gt;At its &lt;a href="https://openai.com/devday/"&gt;&lt;u&gt;third annual DevDay&lt;/u&gt;&lt;/a&gt;, OpenAI unveiled a suite of tools that signals a strategic pivot from a model provider to a full-fledged ecosystem. The message was clear: the era of simply asking an AI questions is over. The future is about commanding AI to perform complex tasks, build software autonomously, and live inside every application, a transition Altman framed as moving from &amp;quot;systems that you can ask anything to, to systems that you can ask to do anything for you.&amp;quot; &lt;/p&gt;&lt;p&gt;The day’s announcements were a three-pronged assault on the status quo, targeting how users interact with software, how developers build it, and how businesses deploy intelligent agents. But it was the sessions held behind closed doors, away from the &lt;a href="https://www.youtube.com/live/hS1YqcewH0c?si=mFE2rRx3QrK7z6NF"&gt;&lt;u&gt;public livestream&lt;/u&gt;&lt;/a&gt;, that revealed the true scope of OpenAI’s ambition — a future that includes new hardware, a relentless pursuit of computational power, and a philosophical quest to redefine our relationship with technology.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;From chatbot to operating system: The new &amp;#x27;App Store&amp;#x27;&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The centerpiece of the public-facing keynote was the transformation of &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt; itself. With the new &lt;a href="https://openai.com/index/introducing-apps-in-chatgpt/"&gt;&lt;u&gt;Apps SDK&lt;/u&gt;&lt;/a&gt;, OpenAI is turning its wildly popular chatbot into a dynamic, interactive platform, effectively an operating system where developers can build and distribute their own applications.&lt;/p&gt;&lt;p&gt;“Today, we&amp;#x27;re going to open up ChatGPT for developers to build real apps inside of ChatGPT,” Altman announced during the keynote presentation to applause. “This will enable a new generation of apps that are interactive, adaptive and personalized, that you can chat with.”&lt;/p&gt;&lt;p&gt;Live demonstrations showcased apps from partners like &lt;a href="https://www.coursera.org/"&gt;&lt;u&gt;Coursera&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://www.canva.com/"&gt;&lt;u&gt;Canva&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.zillow.com/"&gt;&lt;u&gt;Zillow&lt;/u&gt;&lt;/a&gt; running seamlessly within a chat conversation. A user could watch a machine learning lecture, ask &lt;a href="https://chatgpt.com/"&gt;&lt;u&gt;ChatGPT&lt;/u&gt;&lt;/a&gt; to explain a concept in real-time, and then use Canva to generate a poster based on the conversation, all without leaving the chat interface. The apps can render rich, interactive UIs, even going full-screen to offer a complete experience, like exploring a Zillow map of homes.&lt;/p&gt;&lt;p&gt;For developers, this represents a powerful new distribution channel. “When you build with the Apps SDK, your apps can reach hundreds of millions of chat users,” Altman said, highlighting a direct path to a massive user base that has grown to over &lt;a href="https://venturebeat.com/ai/openai-announces-apps-sdk-allowing-chatgpt-to-launch-and-run-third-party"&gt;&lt;u&gt;800 million weekly active users&lt;/u&gt;&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;In a private press conference later, Nick Turley, head of ChatGPT, elaborated on the grander vision. &amp;quot;We never meant to build a chatbot,&amp;quot; he stated. &amp;quot;When we set out to make ChatGPT, we meant to build a super assistant and we got a little sidetracked. And one of the tragedies of getting a little sidetracked is that we built a great chatbot, but we are the first ones to say that not all software needs to be a chatbot, not all interaction with the commercial world needs to be a chatbot.&amp;quot;&lt;/p&gt;&lt;p&gt;Turley emphasized that while OpenAI is excited about natural language interfaces, &amp;quot;the interface really needs to evolve, which is why you see so much UI in the demos today. In fact, you can even go full screen and chat is in the background.&amp;quot; He described a future where users might &amp;quot;start your day in ChatGPT, just because it kind of has become the de facto entry point into the commercial web and into a lot of software,&amp;quot; but clarified that &amp;quot;our incentive is not to keep you in. Our product is to allow other people to build amazing businesses on top and to evolve the form factor of software.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The rise of the agents: Building the &amp;#x27;do anything&amp;#x27; AI&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;If apps are about bringing the world into ChatGPT, the new &amp;quot;&lt;a href="https://openai.com/index/introducing-agentkit/"&gt;&lt;u&gt;Agent Kit&lt;/u&gt;&lt;/a&gt;&amp;quot; is about sending AI out into the world to get things done. OpenAI is providing a complete &amp;quot;set of building blocks... to help you take agents from prototype to production,&amp;quot; Altman explained in his keynote. &lt;/p&gt;&lt;p&gt;&lt;a href="https://openai.com/index/introducing-agentkit/"&gt;&lt;u&gt;Agent Kit&lt;/u&gt;&lt;/a&gt; is an integrated development environment for creating autonomous AI workers. It features a visual canvas to design complex workflows, an embeddable chat interface (&amp;quot;Chat Kit&amp;quot;) for deploying agents in any app, and a sophisticated evaluation suite to measure and improve performance.&lt;/p&gt;&lt;p&gt;A compelling demo from financial operations platform &lt;a href="https://ramp.com/"&gt;&lt;u&gt;Ramp&lt;/u&gt;&lt;/a&gt; showed how Agent Kit was used to build a procurement agent. An employee could simply type, &amp;quot;I need five more ChatGPT business seats,&amp;quot; and the agent would parse the request, check it against company expense policies, find vendor details, and prepare a virtual credit card for the purchase — a process that once took weeks now completed in minutes. &lt;/p&gt;&lt;p&gt;This push into agents is a direct response to a growing enterprise need to move beyond AI as a simple information retrieval tool and toward AI as a productivity engine that automates complex business processes. Brad Lightcap, OpenAI&amp;#x27;s COO, noted that for enterprise adoption, &amp;quot;you needed this kind of shift to more agentic AI that could actually do things for you, versus just respond with text outputs.&amp;quot; &lt;/p&gt;&lt;h3&gt;&lt;b&gt;The future of code and the Jony Ive bBombshell&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Perhaps the most profound shift is occurring in software development itself. &lt;a href="https://openai.com/index/codex-now-generally-available/"&gt;&lt;u&gt;Codex&lt;/u&gt;&lt;/a&gt;, OpenAI&amp;#x27;s AI coding agent, has graduated from a research preview to a full-fledged product, now powered by a specialized version of the new GPT-5 model. It is, as one speaker put it, &amp;quot;a teammate that understands your context.&amp;quot; &lt;/p&gt;&lt;p&gt;The capabilities are staggering. Developers can now assign &lt;a href="https://openai.com/index/codex-now-generally-available/"&gt;&lt;u&gt;Codex&lt;/u&gt;&lt;/a&gt; tasks directly from &lt;a href="https://slack.com/"&gt;&lt;u&gt;Slack&lt;/u&gt;&lt;/a&gt;, and the agent can autonomously write code, create pull requests, and even review other engineers&amp;#x27; work on &lt;a href="https://github.com/"&gt;&lt;u&gt;GitHub&lt;/u&gt;&lt;/a&gt;. A live demo showed Codex taking a simple photo of a whiteboard sketch and turning it into a fully functional, beautifully designed mobile app screen. Another demo showed an app that could &amp;quot;self-evolve,&amp;quot; reprogramming itself in real-time based on a user&amp;#x27;s natural language request. &lt;/p&gt;&lt;p&gt;But the day&amp;#x27;s biggest surprise came in a closing fireside chat, which was not livestreamed, between &lt;a href="https://openai.com/sam-and-jony/"&gt;&lt;u&gt;Altman and Jony Ive&lt;/u&gt;&lt;/a&gt;, the iconic former chief design officer of Apple. The two revealed they have been collaborating for three years on a new family of AI-centric hardware.&lt;/p&gt;&lt;p&gt;Ive, whose design philosophy shaped the iPhone, iMac, and Apple Watch, said his creative team’s purpose &amp;quot;became clear&amp;quot; with the launch of ChatGPT. He argued that our current relationship with technology is broken and that AI presents an opportunity for a fundamental reset.&lt;/p&gt;&lt;p&gt;“I think it would be absurd to assume that you could have technology that is this breathtaking, delivered to us through legacy products, products that are decades old,” Ive said. “I see it as a chance to use this most remarkable capability to full-on address a lot of the overwhelm and despair that people feel right now.”&lt;/p&gt;&lt;p&gt;While details of the devices remain secret, Ive spoke of his motivation in deeply human terms. “We love our species, and we want to be useful. We think that humanity deserves much better than humanity generally is given,” he said. He emphasized the importance of &amp;quot;care&amp;quot; in the design process, stating, &amp;quot;We sense when people have cared... you sense carelessness. You sense when somebody does not care about you, they care about money and schedule.&amp;quot; &lt;/p&gt;&lt;p&gt;This collaboration confirms that OpenAI&amp;#x27;s ambitions are not confined to the cloud; it is actively exploring the physical interface through which humanity will interact with its powerful new intelligence.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;The Unquenchable Thirst for Compute&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Underpinning this entire platform strategy is a single, overwhelming constraint: the availability of computing power. In both the private press conference and the un-streamed Developer State of the Union, OpenAI’s leadership returned to this theme again and again.&lt;/p&gt;&lt;p&gt;“The degree to which we are all constrained by compute... Everyone is just so constrained on being able to offer the services at the scale required to get the revenue that at this point, we&amp;#x27;re quite confident we can push it pretty far,” Altman told reporters. He added that even with massive new hardware partnerships with AMD and others, &amp;quot;we&amp;#x27;ll be saying the same thing again. We&amp;#x27;re so convinced... There&amp;#x27;s so much more demand.&amp;quot; &lt;/p&gt;&lt;p&gt;This explains the company’s aggressive, &lt;a href="https://www.reuters.com/business/autos-transportation/companies-pouring-billions-advance-ai-infrastructure-2025-10-06/"&gt;&lt;u&gt;multi-billion-dollar investment in infrastructure&lt;/u&gt;&lt;/a&gt;. When asked about profitability, Altman was candid that the company is in a phase of &amp;quot;investment and growth.&amp;quot; He invoked a famous quote from Walt Disney, paraphrasing, &amp;quot;We make more money so we can make more movies.&amp;quot; For OpenAI, the &amp;quot;movies&amp;quot; are ever-more-powerful AI models.&lt;/p&gt;&lt;p&gt;Greg Brockman, OpenAI’s President, put the ultimate goal in stark economic terms during the Developer State of the Union. &amp;quot;AI is going to become, probably in the not too distant future, the fundamental driver of economic growth,&amp;quot; he said. &amp;quot;Asking ‘How much compute do you want?’ is a little bit like asking how much workforce do you want? The answer is, you can always get more out of more.&amp;quot; &lt;/p&gt;&lt;p&gt;As the day concluded and developers mingled at the reception, the scale of OpenAI&amp;#x27;s project came into focus. Fueled by new models like the powerful &lt;a href="https://platform.openai.com/docs/models/gpt-5-pro"&gt;&lt;u&gt;GPT-5 Pro&lt;/u&gt;&lt;/a&gt; and the stunning &lt;a href="https://openai.com/index/sora-2/"&gt;&lt;u&gt;Sora 2&lt;/u&gt;&lt;/a&gt; video generator, the company is no longer just building AI. It is building the world where AI will live — a world of intelligent apps, autonomous agents, and new physical devices, betting that in the near future, intelligence itself will be the ultimate platform.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openai-dev-day-2025-chatgpt-becomes-the-new-app-store-and-hardware-is-coming</guid><pubDate>Tue, 07 Oct 2025 22:30:00 +0000</pubDate></item><item><title>[NEW] You can’t libel the dead. But that doesn’t mean you should deepfake them. (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/07/you-cant-libel-the-dead-but-that-doesnt-mean-you-should-deepfake-them/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Zelda Williams, daughter of the late actor Robin Williams, has a poignant message for her father’s fans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Please, just stop sending me AI videos of Dad. Stop believing I wanna see it or that I’ll understand. I don’t and I won’t,” she wrote in a post on her Instagram story on Monday. “If you’ve got any decency, just stop doing this to him and to me, to everyone even, full stop. It’s dumb, it’s a waste of time and energy, and believe me, it’s NOT what he’d want.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s probably not a coincidence that Williams was moved to post this just days after the release of OpenAI’s Sora 2 video model and Sora social app, which gives users the power to generate highly realistic deepfakes of themselves, their friends, and certain cartoon characters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That also includes dead people, who are seemingly fair game because it is not illegal to libel the deceased, according to the Student Press Law Center.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3054964" height="546" src="https://techcrunch.com/wp-content/uploads/2025/10/zelda-williams-deepfakes.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Sora will not let you generate videos of living people — unless it is of yourself, or a friend who has given you permission to use their likeness (or “cameo,” as OpenAI calls it). But these limits don’t apply to the dead, who can mostly be generated without roadblocks. The app, which is still only available via invite, has been flooded with videos of historical figures like Martin Luther King, Jr., Franklin Delano Roosevelt, and Richard Nixon, as well as deceased celebrities like Bob Ross, John Lennon, Alex Trebek, and yes, Robin Williams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;How OpenAI draws the line on generating videos of the dead is unclear. Sora 2 won’t, for example, generate former President Jimmy Carter, who died in 2024, or Michael Jackson, who died in 2009, though it did create videos with the likeness of Robin Williams, who died in 2014, according to TechCrunch’s tests. And while OpenAI’s cameo feature allows people to set instructions for how they appear in videos others generate of them — guardrails that came in response to early criticism of Sora — the deceased have no such say. I’ll bet Richard Nixon would be rolling over in his grave if he could see the deepfake I made of him advocating for police abolition.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Deepfakes of Richard Nixon, John Lennon, Martin Luther King, Jr., and Robin Williams" class="wp-image-3054969" height="264" src="https://techcrunch.com/wp-content/uploads/2025/10/sora-ai-deepfakes.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Deepfakes of Richard Nixon, John Lennon, Martin Luther King, Jr., and Robin Williams&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sora, screenshots by TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI did not respond to TechCrunch’s request for comment on the permissibility of deepfaking dead people. However, it’s possible that deepfaking dead celebrities like Williams is within the firm’s acceptable practices; legal precedent shows that the company likely wouldn’t be held liable for the defamation of the deceased.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“To watch the legacies of real people be condensed down to ‘this vaguely looks and sounds like them so that’s enough,’ just so other people can churn out horrible TikTok slop puppeteering them is maddening,” Williams wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s critics accuse the company of taking a fast-and-loose approach on such issues, which is why Sora was quickly flooded with AI clips of copyrighted characters like Peter Griffin and Pikachu upon its release. CEO Sam Altman originally said that Hollywood studios and agencies would need to explicitly opt out if they didn’t want their IP to be included in Sora-generated videos. The Motion Picture Association has already called on OpenAI to take action on this issue, declaring in a statement that “well-established copyright law safeguards the rights of creators and applies here.” He has since said the company will reverse this position.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora is, perhaps, the most dangerous deepfake-capable AI model accessible to people so far, given how realistic its outputs are. Other platforms like xAI lag behind, but have even fewer guardrails than Sora, making it possible to generate pornographic deepfakes of real people. As other companies catch up to OpenAI, we will set a horrifying precedent if we treat real people — living or dead — like our own personal playthings.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Zelda Williams, daughter of the late actor Robin Williams, has a poignant message for her father’s fans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Please, just stop sending me AI videos of Dad. Stop believing I wanna see it or that I’ll understand. I don’t and I won’t,” she wrote in a post on her Instagram story on Monday. “If you’ve got any decency, just stop doing this to him and to me, to everyone even, full stop. It’s dumb, it’s a waste of time and energy, and believe me, it’s NOT what he’d want.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s probably not a coincidence that Williams was moved to post this just days after the release of OpenAI’s Sora 2 video model and Sora social app, which gives users the power to generate highly realistic deepfakes of themselves, their friends, and certain cartoon characters.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That also includes dead people, who are seemingly fair game because it is not illegal to libel the deceased, according to the Student Press Law Center.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3054964" height="546" src="https://techcrunch.com/wp-content/uploads/2025/10/zelda-williams-deepfakes.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Sora will not let you generate videos of living people — unless it is of yourself, or a friend who has given you permission to use their likeness (or “cameo,” as OpenAI calls it). But these limits don’t apply to the dead, who can mostly be generated without roadblocks. The app, which is still only available via invite, has been flooded with videos of historical figures like Martin Luther King, Jr., Franklin Delano Roosevelt, and Richard Nixon, as well as deceased celebrities like Bob Ross, John Lennon, Alex Trebek, and yes, Robin Williams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;How OpenAI draws the line on generating videos of the dead is unclear. Sora 2 won’t, for example, generate former President Jimmy Carter, who died in 2024, or Michael Jackson, who died in 2009, though it did create videos with the likeness of Robin Williams, who died in 2014, according to TechCrunch’s tests. And while OpenAI’s cameo feature allows people to set instructions for how they appear in videos others generate of them — guardrails that came in response to early criticism of Sora — the deceased have no such say. I’ll bet Richard Nixon would be rolling over in his grave if he could see the deepfake I made of him advocating for police abolition.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Deepfakes of Richard Nixon, John Lennon, Martin Luther King, Jr., and Robin Williams" class="wp-image-3054969" height="264" src="https://techcrunch.com/wp-content/uploads/2025/10/sora-ai-deepfakes.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Deepfakes of Richard Nixon, John Lennon, Martin Luther King, Jr., and Robin Williams&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sora, screenshots by TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI did not respond to TechCrunch’s request for comment on the permissibility of deepfaking dead people. However, it’s possible that deepfaking dead celebrities like Williams is within the firm’s acceptable practices; legal precedent shows that the company likely wouldn’t be held liable for the defamation of the deceased.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“To watch the legacies of real people be condensed down to ‘this vaguely looks and sounds like them so that’s enough,’ just so other people can churn out horrible TikTok slop puppeteering them is maddening,” Williams wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s critics accuse the company of taking a fast-and-loose approach on such issues, which is why Sora was quickly flooded with AI clips of copyrighted characters like Peter Griffin and Pikachu upon its release. CEO Sam Altman originally said that Hollywood studios and agencies would need to explicitly opt out if they didn’t want their IP to be included in Sora-generated videos. The Motion Picture Association has already called on OpenAI to take action on this issue, declaring in a statement that “well-established copyright law safeguards the rights of creators and applies here.” He has since said the company will reverse this position.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora is, perhaps, the most dangerous deepfake-capable AI model accessible to people so far, given how realistic its outputs are. Other platforms like xAI lag behind, but have even fewer guardrails than Sora, making it possible to generate pornographic deepfakes of real people. As other companies catch up to OpenAI, we will set a horrifying precedent if we treat real people — living or dead — like our own personal playthings.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/07/you-cant-libel-the-dead-but-that-doesnt-mean-you-should-deepfake-them/</guid><pubDate>Tue, 07 Oct 2025 22:49:46 +0000</pubDate></item></channel></rss>