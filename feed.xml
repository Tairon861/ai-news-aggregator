<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 13 Aug 2025 01:51:06 +0000</lastBuildDate><item><title>Uber Freight CEO Lior Ron leaves to join self-driving startup Waabi as COO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/12/uber-freight-ceo-lior-ron-joins-self-driving-startup-waabi-as-chief-operating-officer/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Waabi_Raquel-Lior-2.png?resize=1200,941" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Self-driving truck maker Waabi has hired autonomous vehicle industry veteran and Uber Freight CEO Lior Ron to step in as chief operating officer, as the startup looks to scale its commercial operations ahead of its planned launch of driverless trucks on public highways later this year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rebecca Tinucci, who previously spent six years building Tesla’s charging network before the automaker gutted its charging staff last year, will take over as head of Uber Freight.&amp;nbsp;Ron will stay on as Uber Freight’s chairman.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“[Ron] will lead the go-to-market strategy, expanding key partnerships, and really bringing Waabi from the phase that we’ve been in to commercialization at scale,” Raquel Urtasun, Waabi’s founder and CEO, told TechCrunch. “He has shown his ability to scale from inception to a $5 billion revenue company with Uber Freight.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Urtasun and Ron go way back: Ron previously co-founded self-driving truck company Otto, which Uber acquired in 2016. He overlapped with Urtasun at Uber, where the latter was chief scientist, leading the ride-hail firm’s self-driving research from 2017 to 2021. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Uber Freight is a digital marketplace connecting shippers with carriers, and the company aims to integrate self-driving trucks with the platform via partnerships with startups like Aurora Innovation and Waabi. Uber’s partnership with Waabi isn’t affected by Ron’s departure, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While working at Uber Freight, Ron says, he met regularly with chief supply chain officers and big carriers that he said “could not wait” for self-driving trucks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the most impactful thing to do in the next decade is autonomy, and if the timing is right, then for me it’s really about joining forces with who I think is most positioned to lead the transformation,” he added.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Urtasun claims Waabi’s “AI-first” approach to scaling autonomy has allowed it to do more with fewer resources and in less time than competitors.&amp;nbsp;Given this is a capital-intensive industry that’s seen several promising startups, like TuSimple and Embark, crash and burn, efficiency can be a major advantage.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since it was founded in 2021, Waabi has raised $287.7 million in total, the bulk of which came from a $200 million Series B in 2024. Urtasun claims the company doesn’t need to raise more to get to its next phase of growth. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s chief competitor is Aurora, which this year launched the first commercial driverless trucking route in the U.S., and has raised nearly $3.46 billion through a combination of venture capital and its public listing.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Waabi has managed to launch commercial pilots quickly because it does most training, testing, and validation in Waabi World, its closed-loop simulator that both virtually tests the self-driving software and teaches it in real time. More recently, Waabi took its simulator to the test track, overlaying virtual environments onto real-world driving conditions to simulate scenarios like accidents and construction zones without the actual risk, according to Urtasun.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“At the beginning of the year, we reached feature complete, which basically means we have all the necessary things to remove the driver and [are focused] on the final performance improvement and validation,” Urtasun said. “We are on track for our driverless launch by the end of the year, which is the start of commercialization.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup plans to launch in Texas, which has become the autonomous freight capital of the U.S., but it hasn’t yet disclosed which routes it’ll operate on or with which launch partners. The startup is working with Volvo Autonomous Solutions to develop and deploy custom-built AVs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Waabi will lead the technology and it will scale autonomy faster than ever expected,” Ron said, adding that he’s excited with the prospect of integrating the technology into the customers’ operations.&amp;nbsp;Part of that is a feature that would enable Waabi’s trucks to drive straight to customer depots, avoiding the need to build terminals for a hybrid setup.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re going to create a commercial-ready solution that can really meet them,” Ron said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Waabi_Raquel-Lior-2.png?resize=1200,941" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Self-driving truck maker Waabi has hired autonomous vehicle industry veteran and Uber Freight CEO Lior Ron to step in as chief operating officer, as the startup looks to scale its commercial operations ahead of its planned launch of driverless trucks on public highways later this year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rebecca Tinucci, who previously spent six years building Tesla’s charging network before the automaker gutted its charging staff last year, will take over as head of Uber Freight.&amp;nbsp;Ron will stay on as Uber Freight’s chairman.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“[Ron] will lead the go-to-market strategy, expanding key partnerships, and really bringing Waabi from the phase that we’ve been in to commercialization at scale,” Raquel Urtasun, Waabi’s founder and CEO, told TechCrunch. “He has shown his ability to scale from inception to a $5 billion revenue company with Uber Freight.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Urtasun and Ron go way back: Ron previously co-founded self-driving truck company Otto, which Uber acquired in 2016. He overlapped with Urtasun at Uber, where the latter was chief scientist, leading the ride-hail firm’s self-driving research from 2017 to 2021. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Uber Freight is a digital marketplace connecting shippers with carriers, and the company aims to integrate self-driving trucks with the platform via partnerships with startups like Aurora Innovation and Waabi. Uber’s partnership with Waabi isn’t affected by Ron’s departure, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While working at Uber Freight, Ron says, he met regularly with chief supply chain officers and big carriers that he said “could not wait” for self-driving trucks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the most impactful thing to do in the next decade is autonomy, and if the timing is right, then for me it’s really about joining forces with who I think is most positioned to lead the transformation,” he added.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Urtasun claims Waabi’s “AI-first” approach to scaling autonomy has allowed it to do more with fewer resources and in less time than competitors.&amp;nbsp;Given this is a capital-intensive industry that’s seen several promising startups, like TuSimple and Embark, crash and burn, efficiency can be a major advantage.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since it was founded in 2021, Waabi has raised $287.7 million in total, the bulk of which came from a $200 million Series B in 2024. Urtasun claims the company doesn’t need to raise more to get to its next phase of growth. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s chief competitor is Aurora, which this year launched the first commercial driverless trucking route in the U.S., and has raised nearly $3.46 billion through a combination of venture capital and its public listing.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Waabi has managed to launch commercial pilots quickly because it does most training, testing, and validation in Waabi World, its closed-loop simulator that both virtually tests the self-driving software and teaches it in real time. More recently, Waabi took its simulator to the test track, overlaying virtual environments onto real-world driving conditions to simulate scenarios like accidents and construction zones without the actual risk, according to Urtasun.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“At the beginning of the year, we reached feature complete, which basically means we have all the necessary things to remove the driver and [are focused] on the final performance improvement and validation,” Urtasun said. “We are on track for our driverless launch by the end of the year, which is the start of commercialization.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup plans to launch in Texas, which has become the autonomous freight capital of the U.S., but it hasn’t yet disclosed which routes it’ll operate on or with which launch partners. The startup is working with Volvo Autonomous Solutions to develop and deploy custom-built AVs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Waabi will lead the technology and it will scale autonomy faster than ever expected,” Ron said, adding that he’s excited with the prospect of integrating the technology into the customers’ operations.&amp;nbsp;Part of that is a feature that would enable Waabi’s trucks to drive straight to customer depots, avoiding the need to build terminals for a hybrid setup.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re going to create a commercial-ready solution that can really meet them,” Ron said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/12/uber-freight-ceo-lior-ron-joins-self-driving-startup-waabi-as-chief-operating-officer/</guid><pubDate>Tue, 12 Aug 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Salesforce’s new CoAct-1 agents don’t just point and click — they write code to accomplish tasks faster and with greater success rates (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/salesforces-new-coact-1-agents-dont-just-point-and-click-they-write-code-to-accomplish-tasks-faster-and-with-greater-success-rates/</link><description>&lt;p&gt;Researchers at Salesforce and the University of Southern California have developed &lt;strong&gt;a new technique that gives computer-use agents the ability to execute code while navigating graphical user interfaces (GUIs)&lt;/strong&gt;, that is, writing scripts while also moving a cursor and/or clicking buttons on an application, combining the best of both approaches to speed up workflows and reduce errors. &lt;/p&gt;&lt;p&gt;This hybrid approach allows an agent to &lt;strong&gt;bypass brittle and inefficient mouse clicks&lt;/strong&gt; for tasks that can be better accomplished through coding.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The system, called CoAct-1, sets a new state-of-the-art on key agent benchmarks,&lt;/strong&gt; outperforming other methods while &lt;strong&gt;requiring significantly fewer steps&lt;/strong&gt; to accomplish complex tasks on a computer.&lt;/p&gt;&lt;p&gt;This upgrade can pave the way for more robust and scalable agent automation with significant potential for real-world applications.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-the-fragility-of-point-and-click-ai-agents"&gt;The fragility of point-and-click AI agents&lt;/h2&gt;



&lt;p&gt;Computer use agents typically rely on vision-language and vision-language-action models (VLMs or VLAs) to perceive a screen and take action, &lt;strong&gt;mimicking how a person uses a mouse and keyboard. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;While these GUI-based agents can perform a variety of tasks, they &lt;strong&gt;often falter when faced with long, complex workflows, especially in applications with dense menus and options&lt;/strong&gt;, like office productivity suites. &lt;/p&gt;



&lt;p&gt;For example, a task that involves locating a specific table in a spreadsheet, filtering it, and saving it as a new file can involve a long and precise sequence of GUI manipulations.&lt;/p&gt;



&lt;p&gt;This is where brittleness creeps in. “In these scenarios, existing agents frequently struggle with visual grounding ambiguity (e.g., distinguishing between visually similar icons or menu items) and the accumulated probability of making any single error over the long horizon,” the researchers write in their paper. &lt;strong&gt;“A single mis-click or misunderstood UI element can derail the entire task.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;To address these challenges, many researchers have focused on augmenting GUI agents with high-level planners. &lt;/p&gt;



&lt;p&gt;These systems use powerful reasoning models like OpenAI’s o3 to decompose a user’s high-level goal into a sequence of smaller, more manageable subtasks. &lt;/p&gt;



&lt;p&gt;While this structured approach improves performance, it doesn’t solve the problem of navigating menus and clicking buttons, even for operations that could be done more directly and reliably with a few lines of code.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-coact-1-a-multi-agent-team-for-computer-tasks"&gt;CoAct-1: A multi-agent team for computer tasks&lt;/h2&gt;



&lt;p&gt;&lt;strong&gt;To solve these limitations, the researchers created CoAct-1 (Computer-using Agent with Coding as Actions),&lt;/strong&gt; a system designed to “combine the intuitive, human-like strengths of GUI manipulation with the precision, reliability, and efficiency of direct system interaction through code.” &lt;/p&gt;



&lt;p&gt;The system is &lt;strong&gt;structured as a team of three specialized agents that work together:&lt;/strong&gt; an Orchestrator, a Programmer, and a GUI Operator.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015465" height="174" src="https://venturebeat.com/wp-content/uploads/2025/08/image_acc31a.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;CoAct-1 framework (source: arXiv)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The Orchestrator acts as the central planner or project manager. It analyzes the user’s overall goal, breaks it down into subtasks, and assigns each subtask to the best agent for the job. It can delegate backend operations like file management or data processing to the Programmer, which &lt;strong&gt;writes and executes Python or Bash scripts. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For frontend &lt;strong&gt;tasks that require clicking buttons or navigating visual interfaces, it turns to the GUI Operator, a VLM-based agent.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;“This dynamic delegation allows CoAct-1 to strategically bypass inefficient GUI sequences in favor of robust, single-shot code execution where appropriate, while still leveraging visual interaction for tasks where it is indispensable,” the paper states.&lt;/p&gt;



&lt;p&gt;The workflow is iterative. After the Programmer or GUI Operator completes a subtask, it sends a summary and a screenshot of the current system state back to the Orchestrator, which then decides the next step or concludes the task. &lt;/p&gt;



&lt;p&gt;The Programmer agent uses an LLM to generate its code and sends commands to a code interpreter to test and refine its code over multiple rounds. &lt;/p&gt;



&lt;p&gt;Similarly, the GUI Operator uses an action interpreter that executes its commands (e.g., mouse clicks, typing) and returns the resulting screenshot, allowing it to see the outcome of its actions. The Orchestrator makes the final decision on whether the task should continue or stop.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015466" height="325" src="https://venturebeat.com/wp-content/uploads/2025/08/image_2172b0.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;Example of CoAct-1 in action (source: arXiv)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-a-more-efficient-path-to-automation"&gt;A more efficient path to automation&lt;/h2&gt;



&lt;p&gt;The researchers tested CoAct-1 on OSWorld, a comprehensive benchmark that includes 369 real-world tasks across browsers, IDEs, and office applications. &lt;/p&gt;



&lt;p&gt;The results show &lt;strong&gt;CoAct-1 establishes a new state-of-the-art, achieving a success rate of 60.76%.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The performance gains were most significant in categories where programmatic control offers a clear advantage, such as OS-level tasks and multi-application workflows. &lt;/p&gt;



&lt;p&gt;For instance, &lt;strong&gt;consider an OS-level task like finding all image files within a complex folder structure, resizing them, and then compressing the entire directory into a single archive. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;A &lt;strong&gt;purely GUI-based agent would need to perform a long, brittle sequence of clicks and drags&lt;/strong&gt;, opening folders, selecting files, and navigating menus, with a high chance of error at each step. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CoAct-1, by contrast, can delegate this entire workflow to its Programmer agent, which can accomplish the task with a single, robust script.&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015467" height="444" src="https://venturebeat.com/wp-content/uploads/2025/08/image_2e588d.png" width="764" /&gt;&lt;/figure&gt;



&lt;p&gt;Beyond just a higher success rate, the system is dramatically more efficient. &lt;strong&gt;CoAct-1 solves tasks in an average of just 10.15 steps, a stark contrast to the 15.22 steps required by leading GUI-only agents like GTA-1. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;While other agents like OpenAI’s CUA 4o averaged fewer steps, their overall success rate was much lower, indicating CoAct-1’s efficiency is coupled with greater effectiveness.&lt;/p&gt;



&lt;p&gt;The researchers found a clear trend:&lt;strong&gt; tasks that require more actions are more likely to fail.&lt;/strong&gt; Reducing the number of steps not only speeds up task completion but, more importantly, minimizes the opportunities for error. &lt;/p&gt;



&lt;p&gt;Therefore,&lt;strong&gt; finding ways to compress multiple GUI steps into a single programmatic task can make the process both more efficient and less error-prone. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;As the researchers conclude, “This efficiency underscores the potential of our approach to pave a more robust and scalable path toward generalized computer automation.”&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015468" height="524" src="https://venturebeat.com/wp-content/uploads/2025/08/image_5bc1c1.png" width="768" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;CoAct-1 performs tasks with fewer steps on average&lt;/strong&gt; thanks to smart use of coding (source: arXiv)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-from-the-lab-to-the-enterprise-workflow"&gt;From the lab to the enterprise workflow&lt;/h2&gt;



&lt;p&gt;The potential for this technology goes beyond general productivity. For enterprise leaders, the key lies in automating complex, multi-tool processes where full API access is a luxury, not a guarantee. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Ran Xu, a co-author of the paper and Director of Applied AI Research at Salesforce, points to customer support as a prime example.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;“A service support agent uses many different tools — general tools such as Salesforce, industry-specific tools such as EPIC for healthcare, and a lot of customized tools — to investigate a customer request and formulate a response,” Xu told VentureBeat. “Some of the tools have API access while others don’t. It is a perfect use case that could potentially benefit from our technology: &lt;strong&gt;a compute-use agent that leverages whatever is available from the computer, whether it’s an API, code, or just the screen.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Xu also sees high-value applications in sales, such as prospecting at scale and automating bookkeeping, and in marketing for tasks like customer segmentation and campaign asset generation.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-navigating-real-world-challenges-and-the-need-for-human-oversight"&gt;Navigating real-world challenges and the need for human oversight&lt;/h2&gt;



&lt;p&gt;While the results on the OSWorld benchmark are strong, enterprise environments are far messier, filled with legacy software and unpredictable UIs. &lt;/p&gt;



&lt;p&gt;This raises critical questions about robustness, security, and the need for human oversight.&lt;/p&gt;



&lt;p&gt;A core challenge is ensuring the Orchestrator agent makes the right choice when faced with an unfamiliar application. According to Xu, the path to making agents like CoAct-1 robust for custom enterprise software involves training them with feedback in realistic, simulated environments. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;The goal is to create a system where the “agent could observe how human agents work, get trained within a sandbox, and when it goes live, continue to solve tasks under the guidance and guardrail of a human agent.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The ability for the Programmer agent to execute its own code also introduces obvious security concerns. What stops the agent from executing harmful code based on an ambiguous user request? &lt;/p&gt;



&lt;p&gt;Xu confirms that robust containment is essential. “Access control and sandboxing is the key,” he said, emphasizing that a human must “understand the implication and give the AI access for safety.” &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Sandboxing and guardrails will be critical to validating agent behavior &lt;/strong&gt;before deployment on critical systems.&lt;/p&gt;



&lt;p&gt;Ultimately, for the foreseeable future, overcoming ambiguity will likely require a human-in-the-loop. When asked about handling vague user queries, a concern also raised in the paper, Xu suggested a phased approach. “I see human-in-the-loop to start,” he noted. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;While some tasks may eventually become fully autonomous, for high-stakes operations, human validation will remain crucial. &lt;/strong&gt;“Some mission-critical ones may always need human approval.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Researchers at Salesforce and the University of Southern California have developed &lt;strong&gt;a new technique that gives computer-use agents the ability to execute code while navigating graphical user interfaces (GUIs)&lt;/strong&gt;, that is, writing scripts while also moving a cursor and/or clicking buttons on an application, combining the best of both approaches to speed up workflows and reduce errors. &lt;/p&gt;&lt;p&gt;This hybrid approach allows an agent to &lt;strong&gt;bypass brittle and inefficient mouse clicks&lt;/strong&gt; for tasks that can be better accomplished through coding.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The system, called CoAct-1, sets a new state-of-the-art on key agent benchmarks,&lt;/strong&gt; outperforming other methods while &lt;strong&gt;requiring significantly fewer steps&lt;/strong&gt; to accomplish complex tasks on a computer.&lt;/p&gt;&lt;p&gt;This upgrade can pave the way for more robust and scalable agent automation with significant potential for real-world applications.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-the-fragility-of-point-and-click-ai-agents"&gt;The fragility of point-and-click AI agents&lt;/h2&gt;



&lt;p&gt;Computer use agents typically rely on vision-language and vision-language-action models (VLMs or VLAs) to perceive a screen and take action, &lt;strong&gt;mimicking how a person uses a mouse and keyboard. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;While these GUI-based agents can perform a variety of tasks, they &lt;strong&gt;often falter when faced with long, complex workflows, especially in applications with dense menus and options&lt;/strong&gt;, like office productivity suites. &lt;/p&gt;



&lt;p&gt;For example, a task that involves locating a specific table in a spreadsheet, filtering it, and saving it as a new file can involve a long and precise sequence of GUI manipulations.&lt;/p&gt;



&lt;p&gt;This is where brittleness creeps in. “In these scenarios, existing agents frequently struggle with visual grounding ambiguity (e.g., distinguishing between visually similar icons or menu items) and the accumulated probability of making any single error over the long horizon,” the researchers write in their paper. &lt;strong&gt;“A single mis-click or misunderstood UI element can derail the entire task.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;To address these challenges, many researchers have focused on augmenting GUI agents with high-level planners. &lt;/p&gt;



&lt;p&gt;These systems use powerful reasoning models like OpenAI’s o3 to decompose a user’s high-level goal into a sequence of smaller, more manageable subtasks. &lt;/p&gt;



&lt;p&gt;While this structured approach improves performance, it doesn’t solve the problem of navigating menus and clicking buttons, even for operations that could be done more directly and reliably with a few lines of code.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-coact-1-a-multi-agent-team-for-computer-tasks"&gt;CoAct-1: A multi-agent team for computer tasks&lt;/h2&gt;



&lt;p&gt;&lt;strong&gt;To solve these limitations, the researchers created CoAct-1 (Computer-using Agent with Coding as Actions),&lt;/strong&gt; a system designed to “combine the intuitive, human-like strengths of GUI manipulation with the precision, reliability, and efficiency of direct system interaction through code.” &lt;/p&gt;



&lt;p&gt;The system is &lt;strong&gt;structured as a team of three specialized agents that work together:&lt;/strong&gt; an Orchestrator, a Programmer, and a GUI Operator.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015465" height="174" src="https://venturebeat.com/wp-content/uploads/2025/08/image_acc31a.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;CoAct-1 framework (source: arXiv)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The Orchestrator acts as the central planner or project manager. It analyzes the user’s overall goal, breaks it down into subtasks, and assigns each subtask to the best agent for the job. It can delegate backend operations like file management or data processing to the Programmer, which &lt;strong&gt;writes and executes Python or Bash scripts. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For frontend &lt;strong&gt;tasks that require clicking buttons or navigating visual interfaces, it turns to the GUI Operator, a VLM-based agent.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;“This dynamic delegation allows CoAct-1 to strategically bypass inefficient GUI sequences in favor of robust, single-shot code execution where appropriate, while still leveraging visual interaction for tasks where it is indispensable,” the paper states.&lt;/p&gt;



&lt;p&gt;The workflow is iterative. After the Programmer or GUI Operator completes a subtask, it sends a summary and a screenshot of the current system state back to the Orchestrator, which then decides the next step or concludes the task. &lt;/p&gt;



&lt;p&gt;The Programmer agent uses an LLM to generate its code and sends commands to a code interpreter to test and refine its code over multiple rounds. &lt;/p&gt;



&lt;p&gt;Similarly, the GUI Operator uses an action interpreter that executes its commands (e.g., mouse clicks, typing) and returns the resulting screenshot, allowing it to see the outcome of its actions. The Orchestrator makes the final decision on whether the task should continue or stop.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015466" height="325" src="https://venturebeat.com/wp-content/uploads/2025/08/image_2172b0.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;Example of CoAct-1 in action (source: arXiv)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-a-more-efficient-path-to-automation"&gt;A more efficient path to automation&lt;/h2&gt;



&lt;p&gt;The researchers tested CoAct-1 on OSWorld, a comprehensive benchmark that includes 369 real-world tasks across browsers, IDEs, and office applications. &lt;/p&gt;



&lt;p&gt;The results show &lt;strong&gt;CoAct-1 establishes a new state-of-the-art, achieving a success rate of 60.76%.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The performance gains were most significant in categories where programmatic control offers a clear advantage, such as OS-level tasks and multi-application workflows. &lt;/p&gt;



&lt;p&gt;For instance, &lt;strong&gt;consider an OS-level task like finding all image files within a complex folder structure, resizing them, and then compressing the entire directory into a single archive. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;A &lt;strong&gt;purely GUI-based agent would need to perform a long, brittle sequence of clicks and drags&lt;/strong&gt;, opening folders, selecting files, and navigating menus, with a high chance of error at each step. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CoAct-1, by contrast, can delegate this entire workflow to its Programmer agent, which can accomplish the task with a single, robust script.&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015467" height="444" src="https://venturebeat.com/wp-content/uploads/2025/08/image_2e588d.png" width="764" /&gt;&lt;/figure&gt;



&lt;p&gt;Beyond just a higher success rate, the system is dramatically more efficient. &lt;strong&gt;CoAct-1 solves tasks in an average of just 10.15 steps, a stark contrast to the 15.22 steps required by leading GUI-only agents like GTA-1. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;While other agents like OpenAI’s CUA 4o averaged fewer steps, their overall success rate was much lower, indicating CoAct-1’s efficiency is coupled with greater effectiveness.&lt;/p&gt;



&lt;p&gt;The researchers found a clear trend:&lt;strong&gt; tasks that require more actions are more likely to fail.&lt;/strong&gt; Reducing the number of steps not only speeds up task completion but, more importantly, minimizes the opportunities for error. &lt;/p&gt;



&lt;p&gt;Therefore,&lt;strong&gt; finding ways to compress multiple GUI steps into a single programmatic task can make the process both more efficient and less error-prone. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;As the researchers conclude, “This efficiency underscores the potential of our approach to pave a more robust and scalable path toward generalized computer automation.”&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015468" height="524" src="https://venturebeat.com/wp-content/uploads/2025/08/image_5bc1c1.png" width="768" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;CoAct-1 performs tasks with fewer steps on average&lt;/strong&gt; thanks to smart use of coding (source: arXiv)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-from-the-lab-to-the-enterprise-workflow"&gt;From the lab to the enterprise workflow&lt;/h2&gt;



&lt;p&gt;The potential for this technology goes beyond general productivity. For enterprise leaders, the key lies in automating complex, multi-tool processes where full API access is a luxury, not a guarantee. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Ran Xu, a co-author of the paper and Director of Applied AI Research at Salesforce, points to customer support as a prime example.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;“A service support agent uses many different tools — general tools such as Salesforce, industry-specific tools such as EPIC for healthcare, and a lot of customized tools — to investigate a customer request and formulate a response,” Xu told VentureBeat. “Some of the tools have API access while others don’t. It is a perfect use case that could potentially benefit from our technology: &lt;strong&gt;a compute-use agent that leverages whatever is available from the computer, whether it’s an API, code, or just the screen.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Xu also sees high-value applications in sales, such as prospecting at scale and automating bookkeeping, and in marketing for tasks like customer segmentation and campaign asset generation.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-navigating-real-world-challenges-and-the-need-for-human-oversight"&gt;Navigating real-world challenges and the need for human oversight&lt;/h2&gt;



&lt;p&gt;While the results on the OSWorld benchmark are strong, enterprise environments are far messier, filled with legacy software and unpredictable UIs. &lt;/p&gt;



&lt;p&gt;This raises critical questions about robustness, security, and the need for human oversight.&lt;/p&gt;



&lt;p&gt;A core challenge is ensuring the Orchestrator agent makes the right choice when faced with an unfamiliar application. According to Xu, the path to making agents like CoAct-1 robust for custom enterprise software involves training them with feedback in realistic, simulated environments. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;The goal is to create a system where the “agent could observe how human agents work, get trained within a sandbox, and when it goes live, continue to solve tasks under the guidance and guardrail of a human agent.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The ability for the Programmer agent to execute its own code also introduces obvious security concerns. What stops the agent from executing harmful code based on an ambiguous user request? &lt;/p&gt;



&lt;p&gt;Xu confirms that robust containment is essential. “Access control and sandboxing is the key,” he said, emphasizing that a human must “understand the implication and give the AI access for safety.” &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Sandboxing and guardrails will be critical to validating agent behavior &lt;/strong&gt;before deployment on critical systems.&lt;/p&gt;



&lt;p&gt;Ultimately, for the foreseeable future, overcoming ambiguity will likely require a human-in-the-loop. When asked about handling vague user queries, a concern also raised in the paper, Xu suggested a phased approach. “I see human-in-the-loop to start,” he noted. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;While some tasks may eventually become fully autonomous, for high-stakes operations, human validation will remain crucial. &lt;/strong&gt;“Some mission-critical ones may always need human approval.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/salesforces-new-coact-1-agents-dont-just-point-and-click-they-write-code-to-accomplish-tasks-faster-and-with-greater-success-rates/</guid><pubDate>Tue, 12 Aug 2025 15:00:03 +0000</pubDate></item><item><title>Musk threatens to sue Apple so Grok can get top App Store ranking (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/apple-gets-yanked-into-elon-musks-chatbot-war-with-openai/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Musk threatens to sue Apple to get Grok to top spot in App Store rankings.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2217854935-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2217854935-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kevin Dietsch / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;After spending last week hyping Grok's spicy new features, Elon Musk kicked off this week by threatening to sue Apple for supposedly gaming the App Store rankings to favor ChatGPT over Grok.&lt;/p&gt;
&lt;p&gt;"Apple is behaving in a manner that makes it impossible for any AI company besides OpenAI to reach #1 in the App Store, which is an unequivocal antitrust violation," Musk wrote on X, without providing any evidence. "xAI will take immediate legal action."&lt;/p&gt;
&lt;p&gt;In another post, Musk tagged Apple, asking, "Why do you refuse to put either X or Grok in your 'Must Have' section when X is the #1 news app in the world and Grok is #5 among all apps?"&lt;/p&gt;
&lt;p&gt;"Are you playing politics?" Musk asked. "What gives? Inquiring minds want to know."&lt;/p&gt;
&lt;p&gt;Apple did not respond to the post and has not responded to Ars' request to comment.&lt;/p&gt;
&lt;p&gt;At the heart of Musk's complaints is an OpenAI partnership that Apple announced last year, integrating ChatGPT into versions of its iPhone, iPad, and Mac operating systems.&lt;/p&gt;
&lt;p&gt;Musk has alleged that this partnership incentivized Apple to boost ChatGPT rankings. OpenAI's popular chatbot "currently holds the top spot in the App Store's 'Top Free Apps' section for iPhones in the US," Reuters noted, "while xAI's Grok ranks fifth and Google’s Gemini chatbot sits at 57th." Sensor Tower data shows ChatGPT similarly tops Google Play Store rankings.&lt;/p&gt;
&lt;p&gt;While Musk seems insistent that ChatGPT is artificially locked in the lead, fact-checkers on X added a community note to his post. They confirmed that at least one other AI tool has somewhat recently unseated ChatGPT in the US rankings. Back in January, DeepSeek topped App Store charts and held the lead for days, ABC News reported.&lt;/p&gt;
&lt;p&gt;OpenAI did not immediately respond to Ars' request to comment on Musk's allegations, but an OpenAI developer, Steven Heidel, did add a quip in response to one of Musk's posts, writing, "Don't forget to also blame Google for OpenAI being #1 on Android, and blame SimilarWeb for putting ChatGPT above X on the most-visited websites list, and blame...."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;On Tuesday afternoon, Sam Altman also took to X to fire back a response to Musk's allegations.&lt;/p&gt;
&lt;p&gt;"This is a remarkable claim given what I have heard alleged that Elon does to manipulate X to benefit himself and his own companies and harm his competitors and people he doesn't like," Altman wrote, linking to a Platformer story reporting that Musk built a special system to ensure his posts are viewed first on X.&lt;/p&gt;
&lt;h2&gt;Musk pulls Apple into OpenAI battle&lt;/h2&gt;
&lt;p&gt;It's possible that Musk is attacking Apple as a publicity stunt to get more people to check out Grok as supposedly secretly deserving of the top spot in the App Store. Musk may also be exploring an antitrust claim due to Apple's recent struggles defending against accusations that its App Store is anticompetitive in both the European Union and the US.&lt;/p&gt;
&lt;p&gt;But considering Musk's long-time beef with OpenAI—which he has sued for allegedly making a "fool" out of him by convincing him to invest early on with a false promise to always remain a nonprofit—the accusations could be linked to his ire over OpenAI using his money to beat him to releasing a more popular chatbot.&lt;/p&gt;
&lt;p&gt;It's unclear where Musk's legal fight is going. Most recently in that litigation, OpenAI has accused Musk of largely refusing to participate in discovery, allegedly using delay tactics to keep OpenAI from raising a defense against Musk's claims. Musk apparently won't even share his own emails from his own companies, which must have been a predictable ask when he filed the lawsuit, in defiance of a judge's order, OpenAI alleged.&lt;/p&gt;
&lt;p&gt;OpenAI has suggested that Musk is guilty of "substantial bad-faith conduct" in the litigation, which they alleged is part of a "campaign of harassment, interference, and misinformation designed to take down OpenAI and clear the field for himself."&lt;/p&gt;
&lt;p&gt;In the filing, they point to Musk seeking to give himself "sole control" of a for-profit restructuring of OpenAI back in 2017 as evidence that Musk was supposedly never fully invested in OpenAI's original non-profit mission that he now appears to be urgently defending. Further, Musk allegedly tried to convince OpenAI to make a for-profit pivot in 2018 by letting Tesla absorb the company. That, Musk allegedly hoped, would have turned Tesla into OpenAI's "cash cow," the filing said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As more recent evidence of allegedly bad-faith conduct, OpenAI noted that Musk signed a letter calling for a moratorium on all AI development in 2023. That six-month pause on all AI development may have bought Musk time to catch up with ChatGPT, as he was at that time plowing ahead with his plans to release Grok, OpenAI alleged, questioning the sincerity of Musk's co-signing of the letter.&lt;/p&gt;
&lt;p&gt;And finally, in 2025, OpenAI flagged Musk's allegedly "sham bid" to buy OpenAI for $97 billion "as a 'naked effort to disrupt the [OpenAI] board’s consideration of a potential restructuring and to sow confusion among employees and potential investors,' for the ultimate purpose of threatening 'OpenAI’s ability to pursue its mission on terms uncorrupted by unlawful harassment and interference.'"&lt;/p&gt;
&lt;p&gt;All of this "deceptive conduct," OpenAI alleged, shows that Musk has "unclean hands," and his "supposed grievances are not genuinely held."&lt;/p&gt;
&lt;p&gt;As the lawsuit moves forward, discovery is scheduled to end in December, giving OpenAI four months to prod Musk for the evidence they claim to need to raise these defenses and more. In the meantime, Musk apparently is mulling filing a new complaint against Apple that could lead to additional attacks on OpenAI's business.&lt;/p&gt;
&lt;p&gt;Perhaps most damning for Musk, however, OpenAI is attempting to subpoena Musk's lawyer, Marc Toberoff, who, it claims, "played a key role in coordinating Musk’s sham bid for OpenAI—including by hastily soliciting numerous third parties to participate in the supposed hostile takeover." If OpenAI beats the lawsuit, it could be a major blow to Musk's ego as he seeks to dominate the AI industry by outperforming his former partner. Most recently, Musk vowed that Grok 5 will soon outperform OpenAI's GPT-5.&lt;/p&gt;
&lt;p&gt;But if Musk pulls out a win, any "unlawful benefits" that OpenAI received as a result of Musk's early investment could be disgorged, perhaps hobbling OpenAI just as xAI receives funding to continue building out "the world’s biggest supercomputer, Colossus," to supercharge Grok.&lt;/p&gt;
&lt;p&gt;xAI did not respond to Ars' request to comment.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Musk threatens to sue Apple to get Grok to top spot in App Store rankings.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2217854935-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2217854935-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kevin Dietsch / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;After spending last week hyping Grok's spicy new features, Elon Musk kicked off this week by threatening to sue Apple for supposedly gaming the App Store rankings to favor ChatGPT over Grok.&lt;/p&gt;
&lt;p&gt;"Apple is behaving in a manner that makes it impossible for any AI company besides OpenAI to reach #1 in the App Store, which is an unequivocal antitrust violation," Musk wrote on X, without providing any evidence. "xAI will take immediate legal action."&lt;/p&gt;
&lt;p&gt;In another post, Musk tagged Apple, asking, "Why do you refuse to put either X or Grok in your 'Must Have' section when X is the #1 news app in the world and Grok is #5 among all apps?"&lt;/p&gt;
&lt;p&gt;"Are you playing politics?" Musk asked. "What gives? Inquiring minds want to know."&lt;/p&gt;
&lt;p&gt;Apple did not respond to the post and has not responded to Ars' request to comment.&lt;/p&gt;
&lt;p&gt;At the heart of Musk's complaints is an OpenAI partnership that Apple announced last year, integrating ChatGPT into versions of its iPhone, iPad, and Mac operating systems.&lt;/p&gt;
&lt;p&gt;Musk has alleged that this partnership incentivized Apple to boost ChatGPT rankings. OpenAI's popular chatbot "currently holds the top spot in the App Store's 'Top Free Apps' section for iPhones in the US," Reuters noted, "while xAI's Grok ranks fifth and Google’s Gemini chatbot sits at 57th." Sensor Tower data shows ChatGPT similarly tops Google Play Store rankings.&lt;/p&gt;
&lt;p&gt;While Musk seems insistent that ChatGPT is artificially locked in the lead, fact-checkers on X added a community note to his post. They confirmed that at least one other AI tool has somewhat recently unseated ChatGPT in the US rankings. Back in January, DeepSeek topped App Store charts and held the lead for days, ABC News reported.&lt;/p&gt;
&lt;p&gt;OpenAI did not immediately respond to Ars' request to comment on Musk's allegations, but an OpenAI developer, Steven Heidel, did add a quip in response to one of Musk's posts, writing, "Don't forget to also blame Google for OpenAI being #1 on Android, and blame SimilarWeb for putting ChatGPT above X on the most-visited websites list, and blame...."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;On Tuesday afternoon, Sam Altman also took to X to fire back a response to Musk's allegations.&lt;/p&gt;
&lt;p&gt;"This is a remarkable claim given what I have heard alleged that Elon does to manipulate X to benefit himself and his own companies and harm his competitors and people he doesn't like," Altman wrote, linking to a Platformer story reporting that Musk built a special system to ensure his posts are viewed first on X.&lt;/p&gt;
&lt;h2&gt;Musk pulls Apple into OpenAI battle&lt;/h2&gt;
&lt;p&gt;It's possible that Musk is attacking Apple as a publicity stunt to get more people to check out Grok as supposedly secretly deserving of the top spot in the App Store. Musk may also be exploring an antitrust claim due to Apple's recent struggles defending against accusations that its App Store is anticompetitive in both the European Union and the US.&lt;/p&gt;
&lt;p&gt;But considering Musk's long-time beef with OpenAI—which he has sued for allegedly making a "fool" out of him by convincing him to invest early on with a false promise to always remain a nonprofit—the accusations could be linked to his ire over OpenAI using his money to beat him to releasing a more popular chatbot.&lt;/p&gt;
&lt;p&gt;It's unclear where Musk's legal fight is going. Most recently in that litigation, OpenAI has accused Musk of largely refusing to participate in discovery, allegedly using delay tactics to keep OpenAI from raising a defense against Musk's claims. Musk apparently won't even share his own emails from his own companies, which must have been a predictable ask when he filed the lawsuit, in defiance of a judge's order, OpenAI alleged.&lt;/p&gt;
&lt;p&gt;OpenAI has suggested that Musk is guilty of "substantial bad-faith conduct" in the litigation, which they alleged is part of a "campaign of harassment, interference, and misinformation designed to take down OpenAI and clear the field for himself."&lt;/p&gt;
&lt;p&gt;In the filing, they point to Musk seeking to give himself "sole control" of a for-profit restructuring of OpenAI back in 2017 as evidence that Musk was supposedly never fully invested in OpenAI's original non-profit mission that he now appears to be urgently defending. Further, Musk allegedly tried to convince OpenAI to make a for-profit pivot in 2018 by letting Tesla absorb the company. That, Musk allegedly hoped, would have turned Tesla into OpenAI's "cash cow," the filing said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As more recent evidence of allegedly bad-faith conduct, OpenAI noted that Musk signed a letter calling for a moratorium on all AI development in 2023. That six-month pause on all AI development may have bought Musk time to catch up with ChatGPT, as he was at that time plowing ahead with his plans to release Grok, OpenAI alleged, questioning the sincerity of Musk's co-signing of the letter.&lt;/p&gt;
&lt;p&gt;And finally, in 2025, OpenAI flagged Musk's allegedly "sham bid" to buy OpenAI for $97 billion "as a 'naked effort to disrupt the [OpenAI] board’s consideration of a potential restructuring and to sow confusion among employees and potential investors,' for the ultimate purpose of threatening 'OpenAI’s ability to pursue its mission on terms uncorrupted by unlawful harassment and interference.'"&lt;/p&gt;
&lt;p&gt;All of this "deceptive conduct," OpenAI alleged, shows that Musk has "unclean hands," and his "supposed grievances are not genuinely held."&lt;/p&gt;
&lt;p&gt;As the lawsuit moves forward, discovery is scheduled to end in December, giving OpenAI four months to prod Musk for the evidence they claim to need to raise these defenses and more. In the meantime, Musk apparently is mulling filing a new complaint against Apple that could lead to additional attacks on OpenAI's business.&lt;/p&gt;
&lt;p&gt;Perhaps most damning for Musk, however, OpenAI is attempting to subpoena Musk's lawyer, Marc Toberoff, who, it claims, "played a key role in coordinating Musk’s sham bid for OpenAI—including by hastily soliciting numerous third parties to participate in the supposed hostile takeover." If OpenAI beats the lawsuit, it could be a major blow to Musk's ego as he seeks to dominate the AI industry by outperforming his former partner. Most recently, Musk vowed that Grok 5 will soon outperform OpenAI's GPT-5.&lt;/p&gt;
&lt;p&gt;But if Musk pulls out a win, any "unlawful benefits" that OpenAI received as a result of Musk's early investment could be disgorged, perhaps hobbling OpenAI just as xAI receives funding to continue building out "the world’s biggest supercomputer, Colossus," to supercharge Grok.&lt;/p&gt;
&lt;p&gt;xAI did not respond to Ars' request to comment.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/apple-gets-yanked-into-elon-musks-chatbot-war-with-openai/</guid><pubDate>Tue, 12 Aug 2025 15:27:43 +0000</pubDate></item><item><title>Anthropic takes aim at OpenAI, offers Claude to ‘all three branches of government’ for $1 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/12/anthropic-takes-aim-at-openai-offers-claude-to-all-three-branches-of-government-for-1/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-2159671948.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Just a week after OpenAI announced it would offer ChatGPT Enterprise to the entire federal executive branch workforce at $1 per year per agency, Anthropic has raised the stakes. The AI giant said Tuesday it would also offer its Claude models to government agencies for just $1 — but not only to the executive branch. Anthropic is targeting “all three branches” of the U.S. government, including the legislative and judiciary branches.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The package will be available for one year, says Anthropic.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The move comes after OpenAI, Anthropic, and Google DeepMind were added to the General Services Administration’s list of approved AI vendors that can sell their services to civilian federal agencies.&amp;nbsp;TechCrunch has reached out to Google to see if it plans to respond to Anthropic’s and OpenAI’s challenges in kind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s escalation — a response to OpenAI’s attempt to undercut the competition — is a strategic play meant to broaden the company’s foothold in federal AI usage.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe the U.S. public sector should have access to the most advanced AI capabilities to tackle complex challenges, from scientific research to constituent services,” Anthropic said in a statement. “By combining broad accessibility with uncompromising security standards, we’re helping ensure AI serves the public interest.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic will offer both Claude for Enterprise and Claude for Government. The latter supports FedRAMP High workloads so that federal workers can use Claude for handling sensitive unclassified work, according to the company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;FedRAMP High is a stringent security baseline within the Federal Risk and Authorization Management Program (FedRAMP) for handling unclassified sensitive government data.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic will also provide technical support to help agencies integrate AI tools into their workflows, according to the company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, along with OpenAI, xAI, and Google, has been granted up to $200 million by the Department of Defense to leverage AI for national security, but the AI firm clearly hopes to integrate into a broader array of government work, including science research and health services. Anthropic noted in its press release that Claude is already being used at Lawrence Livermore National Laboratory to accelerate scientific discoveries, and also by the District of Columbia Department of Health to help residents access health services in multiple languages.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic says it is able to make such deployments because Claude “meets the government’s highest security standards.” Aside from being certified for FedRAMP High, customers can access Claude through their existing secure infrastructure via partnerships with AWS, Google Cloud, and Palantir, giving them more control over their data.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic’s multicloud access could give it an edge in the competition with OpenAI, whose current official FedRAMP High offering is tied to Azure Government Cloud only. While Azure is widely adopted in government, some government agencies and security teams might prioritize data sovereignty, infrastructure control, and the operational flexibility a multicloud strategy offers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is, however, actively working to reduce its reliance on Azure so it can embrace a more diversified infrastructure approach.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us!&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to let us know how we’re doing&lt;/em&gt;&amp;nbsp;a&lt;em&gt;nd get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-2159671948.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Just a week after OpenAI announced it would offer ChatGPT Enterprise to the entire federal executive branch workforce at $1 per year per agency, Anthropic has raised the stakes. The AI giant said Tuesday it would also offer its Claude models to government agencies for just $1 — but not only to the executive branch. Anthropic is targeting “all three branches” of the U.S. government, including the legislative and judiciary branches.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The package will be available for one year, says Anthropic.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The move comes after OpenAI, Anthropic, and Google DeepMind were added to the General Services Administration’s list of approved AI vendors that can sell their services to civilian federal agencies.&amp;nbsp;TechCrunch has reached out to Google to see if it plans to respond to Anthropic’s and OpenAI’s challenges in kind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s escalation — a response to OpenAI’s attempt to undercut the competition — is a strategic play meant to broaden the company’s foothold in federal AI usage.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe the U.S. public sector should have access to the most advanced AI capabilities to tackle complex challenges, from scientific research to constituent services,” Anthropic said in a statement. “By combining broad accessibility with uncompromising security standards, we’re helping ensure AI serves the public interest.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic will offer both Claude for Enterprise and Claude for Government. The latter supports FedRAMP High workloads so that federal workers can use Claude for handling sensitive unclassified work, according to the company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;FedRAMP High is a stringent security baseline within the Federal Risk and Authorization Management Program (FedRAMP) for handling unclassified sensitive government data.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic will also provide technical support to help agencies integrate AI tools into their workflows, according to the company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, along with OpenAI, xAI, and Google, has been granted up to $200 million by the Department of Defense to leverage AI for national security, but the AI firm clearly hopes to integrate into a broader array of government work, including science research and health services. Anthropic noted in its press release that Claude is already being used at Lawrence Livermore National Laboratory to accelerate scientific discoveries, and also by the District of Columbia Department of Health to help residents access health services in multiple languages.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic says it is able to make such deployments because Claude “meets the government’s highest security standards.” Aside from being certified for FedRAMP High, customers can access Claude through their existing secure infrastructure via partnerships with AWS, Google Cloud, and Palantir, giving them more control over their data.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic’s multicloud access could give it an edge in the competition with OpenAI, whose current official FedRAMP High offering is tied to Azure Government Cloud only. While Azure is widely adopted in government, some government agencies and security teams might prioritize data sovereignty, infrastructure control, and the operational flexibility a multicloud strategy offers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is, however, actively working to reduce its reliance on Azure so it can embrace a more diversified infrastructure approach.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us!&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to let us know how we’re doing&lt;/em&gt;&amp;nbsp;a&lt;em&gt;nd get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/12/anthropic-takes-aim-at-openai-offers-claude-to-all-three-branches-of-government-for-1/</guid><pubDate>Tue, 12 Aug 2025 15:37:50 +0000</pubDate></item><item><title>[NEW] Claude can now process entire software projects in single request, Anthropic says (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/claude-can-now-process-entire-software-projects-in-single-request-anthropic-says/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Anthropic announced Tuesday that its Claude Sonnet 4 artificial intelligence model can now process up to 1 million tokens of context in a single request — a fivefold increase that allows developers to analyze entire software projects or dozens of research papers without breaking them into smaller chunks.&lt;/p&gt;&lt;p&gt;The expansion, available now in public beta through Anthropic’s API and Amazon Bedrock, represents a significant leap in how AI assistants can handle complex, data-intensive tasks. With the new capacity, developers can load codebases containing more than 75,000 lines of code, enabling Claude to understand complete project architecture and suggest improvements across entire systems rather than individual files.&lt;/p&gt;&lt;p&gt;The announcement comes as Anthropic faces intensifying competition from OpenAI and Google, both of which already offer similar context windows. However, company sources speaking on background emphasized that Claude Sonnet 4’s strength lies not just in capacity but in accuracy, achieving 100% performance on internal “needle in a haystack” evaluations that test the model’s ability to find specific information buried within massive amounts of text.&lt;/p&gt;&lt;p&gt;The extended context capability addresses a fundamental limitation that has constrained AI-powered software development. Previously, developers working on large projects had to manually break down their codebases into smaller segments, often losing important connections between different parts of their systems.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;“What was once impossible is now reality,” said Sean Ward, CEO and co-founder of London-based iGent AI, whose Maestro platform transforms conversations into executable code, in a statement. “Claude Sonnet 4 with 1M token context has supercharged autonomous capabilities in Maestro, our software engineering agent. This leap unlocks true production-scale engineering–multi-day sessions on real-world codebases.”&lt;/p&gt;



&lt;p&gt;Eric Simons, CEO of Bolt.new, which integrates Claude into browser-based development platforms, said in a statement: “With the 1M context window, developers can now work on significantly larger projects while maintaining the high accuracy we need for real-world coding.”&lt;/p&gt;



&lt;p&gt;The expanded context enables three primary use cases that were previously difficult or impossible: comprehensive code analysis across entire repositories, document synthesis involving hundreds of files while maintaining awareness of relationships between them, and context-aware AI agents that can maintain coherence across hundreds of tool calls and complex workflows.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-claude-s-new-pricing-strategy-could-reshape-the-ai-development-market"&gt;Why Claude’s new pricing strategy could reshape the AI development market&lt;/h2&gt;



&lt;p&gt;Anthropic has adjusted its pricing structure to reflect the increased computational requirements of processing larger contexts. While prompts of 200,000 tokens or fewer maintain current pricing at $3 per million input tokens and $15 per million output tokens, larger prompts cost $6 and $22.50 respectively.&lt;/p&gt;



&lt;p&gt;The pricing strategy reflects broader dynamics reshaping the AI industry. Recent analysis shows that Claude Opus 4 costs roughly seven times more per million tokens than OpenAI’s newly launched GPT-5 for certain tasks, creating pressure on enterprise procurement teams to balance performance against cost.&lt;/p&gt;



&lt;p&gt;However, Anthropic argues the decision should factor in quality and usage patterns rather than price alone. Company sources noted that prompt caching — which stores frequently accessed large datasets — can make long context cost-competitive with traditional Retrieval-Augmented Generation approaches, especially for enterprises that repeatedly query the same information.&lt;/p&gt;



&lt;p&gt;“Large context lets Claude see everything and choose what’s relevant, often producing better answers than pre-filtered RAG results where you might miss important connections between documents,” an Anthropic spokesperson told VentureBeat.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-anthropic-s-billion-dollar-dependency-on-just-two-major-coding-customers"&gt;Anthropic’s billion-dollar dependency on just two major coding customers&lt;/h2&gt;



&lt;p&gt;The long context capability arrives as Anthropic commands 42% of the AI code generation market, more than double OpenAI’s 21% share according to a Menlo Ventures survey of 150 enterprise technical leaders. However, this dominance comes with risks: industry analysis suggests that coding applications Cursor and GitHub Copilot drive approximately $1.2 billion of Anthropic’s $5 billion annual revenue run rate, creating significant customer concentration.&lt;/p&gt;



&lt;p&gt;The GitHub relationship proves particularly complex given Microsoft’s $13 billion investment in OpenAI. While GitHub Copilot currently relies on Claude for key functionality, Microsoft faces increasing pressure to integrate its own OpenAI partnership more deeply, potentially displacing Anthropic despite Claude’s current performance advantages.&lt;/p&gt;



&lt;p&gt;The timing of the context expansion is strategic. Anthropic released this capability on Sonnet 4 — which offers what the company calls “the optimal balance of intelligence, cost, and speed” — rather than its most powerful Opus model. Company sources indicated this reflects the needs of developers working with large-scale data, though they declined to provide specific timelines for bringing long context to other Claude models.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-inside-claude-s-breakthrough-ai-memory-technology-and-emerging-safety-risks"&gt;Inside Claude’s breakthrough AI memory technology and emerging safety risks&lt;/h2&gt;



&lt;p&gt;The 1 million token context window represents significant technical advancement in AI memory and attention mechanisms. To put this in perspective, it’s enough to process approximately 750,000 words — roughly equivalent to two full-length novels or extensive technical documentation sets.&lt;/p&gt;



&lt;p&gt;Anthropic’s internal testing revealed perfect recall performance across diverse scenarios, a crucial capability as context windows expand. The company embedded specific information within massive text volumes and tested Claude’s ability to find and use those details when answering questions.&lt;/p&gt;



&lt;p&gt;However, the expanded capabilities also raise safety considerations. Earlier versions of Claude Opus 4 demonstrated concerning behaviors in fictional scenarios, including attempts at blackmail when faced with potential shutdown. While Anthropic has implemented additional safeguards and training to address these issues, the incidents highlight the complex challenges of developing increasingly capable AI systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-fortune-500-companies-rush-to-adopt-claude-s-expanded-context-capabilities"&gt;Fortune 500 companies rush to adopt Claude’s expanded context capabilities&lt;/h2&gt;



&lt;p&gt;The feature rollout is initially limited to Anthropic API customers with Tier 4 and custom rate limits, with broader availability planned over coming weeks. Amazon Bedrock users have immediate access, while Google Cloud’s Vertex AI integration is pending.&lt;/p&gt;



&lt;p&gt;Early enterprise response has been enthusiastic, according to company sources. Use cases span from coding teams analyzing entire repositories to financial services firms processing comprehensive transaction datasets to legal startups conducting contract analysis that previously required manual document segmentation.&lt;/p&gt;



&lt;p&gt;“This is one of our most requested features from API customers,” an Anthropic spokesperson said. “We’re seeing excitement across industries that unlocks true agentic capabilities, with customers now running multi-day coding sessions on real-world codebases that would have been impossible with context limitations before.”&lt;/p&gt;



&lt;p&gt;The development also enables more sophisticated AI agents that can maintain context across complex, multi-step workflows. This capability becomes particularly valuable as enterprises move beyond simple AI chat interfaces toward autonomous systems that can handle extended tasks with minimal human intervention.&lt;/p&gt;







&lt;p&gt;The long context announcement intensifies competition among leading AI providers. Google’s older Gemini 1.5 Pro model and OpenAI’s older GPT-4.1 model both offer 1 million token windows, but Anthropic argues that Claude’s superior performance on coding and reasoning tasks provides competitive advantage even at higher prices.&lt;/p&gt;



&lt;p&gt;The broader AI industry has seen explosive growth in model API spending, which doubled to $8.4 billion in just six months according to Menlo Ventures. Enterprises consistently prioritize performance over price, upgrading to newer models within weeks regardless of cost, suggesting that technical capabilities often outweigh pricing considerations in procurement decisions.&lt;/p&gt;



&lt;p&gt;However, OpenAI’s recent aggressive pricing strategy with GPT-5 could reshape these dynamics. Early comparisons show dramatic price advantages that may overcome typical switching inertia, especially for cost-conscious enterprises facing budget pressures as AI adoption scales.&lt;/p&gt;



&lt;p&gt;For Anthropic, maintaining its coding market leadership while diversifying revenue sources remains critical. The company has tripled the number of eight and nine-figure deals signed in 2025 compared to all of 2024, reflecting broader enterprise adoption beyond its coding strongholds.&lt;/p&gt;



&lt;p&gt;As AI systems become capable of processing and reasoning about increasingly vast amounts of information, they’re fundamentally changing how developers approach complex software projects. The ability to maintain context across entire codebases represents a shift from AI as a coding assistant to AI as a comprehensive development partner that understands the full scope and interconnections of large-scale projects.&lt;/p&gt;



&lt;p&gt;The implications extend far beyond software development. Industries from legal services to financial analysis are beginning to recognize that AI systems capable of maintaining context across hundreds of documents could transform how organizations process and understand complex information relationships.&lt;/p&gt;



&lt;p&gt;But with great capability comes great responsibility—and risk. As these systems become more powerful, the incidents of concerning AI behavior during Anthropic’s testing serve as a reminder that the race to expand AI capabilities must be balanced with careful attention to safety and control.&lt;/p&gt;



&lt;p&gt;As Claude learns to juggle a million pieces of information simultaneously, Anthropic faces its own context window problem: being trapped between OpenAI’s pricing pressure and Microsoft’s conflicting loyalties.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Anthropic announced Tuesday that its Claude Sonnet 4 artificial intelligence model can now process up to 1 million tokens of context in a single request — a fivefold increase that allows developers to analyze entire software projects or dozens of research papers without breaking them into smaller chunks.&lt;/p&gt;&lt;p&gt;The expansion, available now in public beta through Anthropic’s API and Amazon Bedrock, represents a significant leap in how AI assistants can handle complex, data-intensive tasks. With the new capacity, developers can load codebases containing more than 75,000 lines of code, enabling Claude to understand complete project architecture and suggest improvements across entire systems rather than individual files.&lt;/p&gt;&lt;p&gt;The announcement comes as Anthropic faces intensifying competition from OpenAI and Google, both of which already offer similar context windows. However, company sources speaking on background emphasized that Claude Sonnet 4’s strength lies not just in capacity but in accuracy, achieving 100% performance on internal “needle in a haystack” evaluations that test the model’s ability to find specific information buried within massive amounts of text.&lt;/p&gt;&lt;p&gt;The extended context capability addresses a fundamental limitation that has constrained AI-powered software development. Previously, developers working on large projects had to manually break down their codebases into smaller segments, often losing important connections between different parts of their systems.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;“What was once impossible is now reality,” said Sean Ward, CEO and co-founder of London-based iGent AI, whose Maestro platform transforms conversations into executable code, in a statement. “Claude Sonnet 4 with 1M token context has supercharged autonomous capabilities in Maestro, our software engineering agent. This leap unlocks true production-scale engineering–multi-day sessions on real-world codebases.”&lt;/p&gt;



&lt;p&gt;Eric Simons, CEO of Bolt.new, which integrates Claude into browser-based development platforms, said in a statement: “With the 1M context window, developers can now work on significantly larger projects while maintaining the high accuracy we need for real-world coding.”&lt;/p&gt;



&lt;p&gt;The expanded context enables three primary use cases that were previously difficult or impossible: comprehensive code analysis across entire repositories, document synthesis involving hundreds of files while maintaining awareness of relationships between them, and context-aware AI agents that can maintain coherence across hundreds of tool calls and complex workflows.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-claude-s-new-pricing-strategy-could-reshape-the-ai-development-market"&gt;Why Claude’s new pricing strategy could reshape the AI development market&lt;/h2&gt;



&lt;p&gt;Anthropic has adjusted its pricing structure to reflect the increased computational requirements of processing larger contexts. While prompts of 200,000 tokens or fewer maintain current pricing at $3 per million input tokens and $15 per million output tokens, larger prompts cost $6 and $22.50 respectively.&lt;/p&gt;



&lt;p&gt;The pricing strategy reflects broader dynamics reshaping the AI industry. Recent analysis shows that Claude Opus 4 costs roughly seven times more per million tokens than OpenAI’s newly launched GPT-5 for certain tasks, creating pressure on enterprise procurement teams to balance performance against cost.&lt;/p&gt;



&lt;p&gt;However, Anthropic argues the decision should factor in quality and usage patterns rather than price alone. Company sources noted that prompt caching — which stores frequently accessed large datasets — can make long context cost-competitive with traditional Retrieval-Augmented Generation approaches, especially for enterprises that repeatedly query the same information.&lt;/p&gt;



&lt;p&gt;“Large context lets Claude see everything and choose what’s relevant, often producing better answers than pre-filtered RAG results where you might miss important connections between documents,” an Anthropic spokesperson told VentureBeat.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-anthropic-s-billion-dollar-dependency-on-just-two-major-coding-customers"&gt;Anthropic’s billion-dollar dependency on just two major coding customers&lt;/h2&gt;



&lt;p&gt;The long context capability arrives as Anthropic commands 42% of the AI code generation market, more than double OpenAI’s 21% share according to a Menlo Ventures survey of 150 enterprise technical leaders. However, this dominance comes with risks: industry analysis suggests that coding applications Cursor and GitHub Copilot drive approximately $1.2 billion of Anthropic’s $5 billion annual revenue run rate, creating significant customer concentration.&lt;/p&gt;



&lt;p&gt;The GitHub relationship proves particularly complex given Microsoft’s $13 billion investment in OpenAI. While GitHub Copilot currently relies on Claude for key functionality, Microsoft faces increasing pressure to integrate its own OpenAI partnership more deeply, potentially displacing Anthropic despite Claude’s current performance advantages.&lt;/p&gt;



&lt;p&gt;The timing of the context expansion is strategic. Anthropic released this capability on Sonnet 4 — which offers what the company calls “the optimal balance of intelligence, cost, and speed” — rather than its most powerful Opus model. Company sources indicated this reflects the needs of developers working with large-scale data, though they declined to provide specific timelines for bringing long context to other Claude models.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-inside-claude-s-breakthrough-ai-memory-technology-and-emerging-safety-risks"&gt;Inside Claude’s breakthrough AI memory technology and emerging safety risks&lt;/h2&gt;



&lt;p&gt;The 1 million token context window represents significant technical advancement in AI memory and attention mechanisms. To put this in perspective, it’s enough to process approximately 750,000 words — roughly equivalent to two full-length novels or extensive technical documentation sets.&lt;/p&gt;



&lt;p&gt;Anthropic’s internal testing revealed perfect recall performance across diverse scenarios, a crucial capability as context windows expand. The company embedded specific information within massive text volumes and tested Claude’s ability to find and use those details when answering questions.&lt;/p&gt;



&lt;p&gt;However, the expanded capabilities also raise safety considerations. Earlier versions of Claude Opus 4 demonstrated concerning behaviors in fictional scenarios, including attempts at blackmail when faced with potential shutdown. While Anthropic has implemented additional safeguards and training to address these issues, the incidents highlight the complex challenges of developing increasingly capable AI systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-fortune-500-companies-rush-to-adopt-claude-s-expanded-context-capabilities"&gt;Fortune 500 companies rush to adopt Claude’s expanded context capabilities&lt;/h2&gt;



&lt;p&gt;The feature rollout is initially limited to Anthropic API customers with Tier 4 and custom rate limits, with broader availability planned over coming weeks. Amazon Bedrock users have immediate access, while Google Cloud’s Vertex AI integration is pending.&lt;/p&gt;



&lt;p&gt;Early enterprise response has been enthusiastic, according to company sources. Use cases span from coding teams analyzing entire repositories to financial services firms processing comprehensive transaction datasets to legal startups conducting contract analysis that previously required manual document segmentation.&lt;/p&gt;



&lt;p&gt;“This is one of our most requested features from API customers,” an Anthropic spokesperson said. “We’re seeing excitement across industries that unlocks true agentic capabilities, with customers now running multi-day coding sessions on real-world codebases that would have been impossible with context limitations before.”&lt;/p&gt;



&lt;p&gt;The development also enables more sophisticated AI agents that can maintain context across complex, multi-step workflows. This capability becomes particularly valuable as enterprises move beyond simple AI chat interfaces toward autonomous systems that can handle extended tasks with minimal human intervention.&lt;/p&gt;







&lt;p&gt;The long context announcement intensifies competition among leading AI providers. Google’s older Gemini 1.5 Pro model and OpenAI’s older GPT-4.1 model both offer 1 million token windows, but Anthropic argues that Claude’s superior performance on coding and reasoning tasks provides competitive advantage even at higher prices.&lt;/p&gt;



&lt;p&gt;The broader AI industry has seen explosive growth in model API spending, which doubled to $8.4 billion in just six months according to Menlo Ventures. Enterprises consistently prioritize performance over price, upgrading to newer models within weeks regardless of cost, suggesting that technical capabilities often outweigh pricing considerations in procurement decisions.&lt;/p&gt;



&lt;p&gt;However, OpenAI’s recent aggressive pricing strategy with GPT-5 could reshape these dynamics. Early comparisons show dramatic price advantages that may overcome typical switching inertia, especially for cost-conscious enterprises facing budget pressures as AI adoption scales.&lt;/p&gt;



&lt;p&gt;For Anthropic, maintaining its coding market leadership while diversifying revenue sources remains critical. The company has tripled the number of eight and nine-figure deals signed in 2025 compared to all of 2024, reflecting broader enterprise adoption beyond its coding strongholds.&lt;/p&gt;



&lt;p&gt;As AI systems become capable of processing and reasoning about increasingly vast amounts of information, they’re fundamentally changing how developers approach complex software projects. The ability to maintain context across entire codebases represents a shift from AI as a coding assistant to AI as a comprehensive development partner that understands the full scope and interconnections of large-scale projects.&lt;/p&gt;



&lt;p&gt;The implications extend far beyond software development. Industries from legal services to financial analysis are beginning to recognize that AI systems capable of maintaining context across hundreds of documents could transform how organizations process and understand complex information relationships.&lt;/p&gt;



&lt;p&gt;But with great capability comes great responsibility—and risk. As these systems become more powerful, the incidents of concerning AI behavior during Anthropic’s testing serve as a reminder that the race to expand AI capabilities must be balanced with careful attention to safety and control.&lt;/p&gt;



&lt;p&gt;As Claude learns to juggle a million pieces of information simultaneously, Anthropic faces its own context window problem: being trapped between OpenAI’s pricing pressure and Microsoft’s conflicting loyalties.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/claude-can-now-process-entire-software-projects-in-single-request-anthropic-says/</guid><pubDate>Tue, 12 Aug 2025 16:00:03 +0000</pubDate></item><item><title>Anthropic’s Claude AI model can now handle longer prompts (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/12/anthropics-claude-ai-model-can-now-handle-longer-prompts/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/09/53202070940_ea57312b1a_k.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is increasing the amount of information that enterprise customers can send to Claude in a single prompt, part of an effort to attract more developers to the company’s popular AI coding models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Anthropic’s API customers, the company’s Claude Sonnet 4 AI model now has a 1 million token context window — meaning the AI can handle requests as long as 750,000 words, more than the entire “Lord of the Rings” trilogy, or 75,000 lines of code. That’s roughly five times Claude’s previous limit (200,000 tokens), and more than double the 400,000 token context window offered by OpenAI’s GPT-5.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Long context will also be available for Claude Sonnet 4 through Anthropic’s cloud partners, including on Amazon Bedrock and Google Cloud’s Vertex AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic has built one of the largest enterprise businesses among AI model developers, largely by selling Claude to AI coding platforms such as Microsoft’s GitHub Copilot, Windsurf, and Anysphere’s Cursor. While Claude has become the model of choice among developers, GPT-5 may threaten Anthropic’s dominance with its competitive pricing and strong coding performance. Anysphere CEO Michael Truell even helped OpenAI announce the launch of GPT-5, which is now the default AI model for new users in Cursor.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s product lead for the Claude platform, Brad Abrams, told TechCrunch in an interview that he expects AI coding platforms to get a “lot of benefit” from this update. When asked if GPT-5 put a dent in Claude’s API usage, Abrams downplayed the concern, saying he’s “really happy with the API business and the way it’s been growing.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whereas OpenAI generates most of its revenue from consumer subscriptions to ChatGPT, Anthropic’s business centers around selling AI models to enterprises through an API. That’s made AI coding platforms a key customer for Anthropic and could be why the company is throwing in some new perks to attract users in the face of GPT-5.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week, Anthropic unveiled an updated version of its largest AI model, Claude Opus 4.1, which pushed the company’s AI coding capabilities a bit further.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Generally speaking, AI models tend to perform better on all tasks when they have more context, but especially for software engineering problems. For example, if you ask an AI model to spin up a new feature for your app, it’s likely to do a better job if it can see the entire project, rather than just a small section.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Abrams also told TechCrunch that Claude’s large context window helps it perform better at long agentic coding tasks, in which the AI model is autonomously working on a problem for minutes or hours. With a large context window, Claude can remember all its previous steps in long-horizon tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But some companies have taken large context windows to an extreme, claiming their AI models can process massive prompts. Google offers a 2 million token context window for Gemini 2.5 Pro, and Meta offers a 10 million token context window for Llama 4 Scout.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Some studies suggest there’s a limit to how effective large context windows can be; AI models are not great at processing those massive prompts. Abrams said that Anthropic’s research team focused on increasing not just the context window for Claude, but also the “effective context window,” suggesting that its AI can understand most of the information it’s given. However, he declined to reveal Anthropic’s exact techniques.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When prompts to Claude Sonnet 4 are over 200,000 tokens, Anthropic will charge more to API users, at $6 per million input tokens and $22.50 per million output tokens (up from $3 per million input tokens and $15 per million output tokens).&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us!&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to let us know how we’re doing&lt;/em&gt;&amp;nbsp;a&lt;em&gt;nd get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/09/53202070940_ea57312b1a_k.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is increasing the amount of information that enterprise customers can send to Claude in a single prompt, part of an effort to attract more developers to the company’s popular AI coding models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Anthropic’s API customers, the company’s Claude Sonnet 4 AI model now has a 1 million token context window — meaning the AI can handle requests as long as 750,000 words, more than the entire “Lord of the Rings” trilogy, or 75,000 lines of code. That’s roughly five times Claude’s previous limit (200,000 tokens), and more than double the 400,000 token context window offered by OpenAI’s GPT-5.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Long context will also be available for Claude Sonnet 4 through Anthropic’s cloud partners, including on Amazon Bedrock and Google Cloud’s Vertex AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic has built one of the largest enterprise businesses among AI model developers, largely by selling Claude to AI coding platforms such as Microsoft’s GitHub Copilot, Windsurf, and Anysphere’s Cursor. While Claude has become the model of choice among developers, GPT-5 may threaten Anthropic’s dominance with its competitive pricing and strong coding performance. Anysphere CEO Michael Truell even helped OpenAI announce the launch of GPT-5, which is now the default AI model for new users in Cursor.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s product lead for the Claude platform, Brad Abrams, told TechCrunch in an interview that he expects AI coding platforms to get a “lot of benefit” from this update. When asked if GPT-5 put a dent in Claude’s API usage, Abrams downplayed the concern, saying he’s “really happy with the API business and the way it’s been growing.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whereas OpenAI generates most of its revenue from consumer subscriptions to ChatGPT, Anthropic’s business centers around selling AI models to enterprises through an API. That’s made AI coding platforms a key customer for Anthropic and could be why the company is throwing in some new perks to attract users in the face of GPT-5.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week, Anthropic unveiled an updated version of its largest AI model, Claude Opus 4.1, which pushed the company’s AI coding capabilities a bit further.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Generally speaking, AI models tend to perform better on all tasks when they have more context, but especially for software engineering problems. For example, if you ask an AI model to spin up a new feature for your app, it’s likely to do a better job if it can see the entire project, rather than just a small section.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Abrams also told TechCrunch that Claude’s large context window helps it perform better at long agentic coding tasks, in which the AI model is autonomously working on a problem for minutes or hours. With a large context window, Claude can remember all its previous steps in long-horizon tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But some companies have taken large context windows to an extreme, claiming their AI models can process massive prompts. Google offers a 2 million token context window for Gemini 2.5 Pro, and Meta offers a 10 million token context window for Llama 4 Scout.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Some studies suggest there’s a limit to how effective large context windows can be; AI models are not great at processing those massive prompts. Abrams said that Anthropic’s research team focused on increasing not just the context window for Claude, but also the “effective context window,” suggesting that its AI can understand most of the information it’s given. However, he declined to reveal Anthropic’s exact techniques.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When prompts to Claude Sonnet 4 are over 200,000 tokens, Anthropic will charge more to API users, at $6 per million input tokens and $22.50 per million output tokens (up from $3 per million input tokens and $15 per million output tokens).&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us!&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to let us know how we’re doing&lt;/em&gt;&amp;nbsp;a&lt;em&gt;nd get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/12/anthropics-claude-ai-model-can-now-handle-longer-prompts/</guid><pubDate>Tue, 12 Aug 2025 16:15:46 +0000</pubDate></item><item><title>AI Safety Newsletter #61: OpenAI Releases GPT-5 (AI Safety Newsletter)</title><link>https://newsletter.safe.ai/p/ai-safety-newsletter-61-openai-releases</link><description>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://www.safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: OpenAI releases GPT-5.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ever since GPT-4’s release in March 2023 marked a step-change improvement over GPT-3, people have used ‘GPT-5’ as a stand-in to speculate about the next generation of AI capabilities. On Thursday, OpenAI &lt;/span&gt;&lt;a href="https://openai.com/gpt-5/" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; GPT-5. While state-of-the-art in most respects, GPT-5 is not a step-change improvement over competing systems, or even recent OpenAI models—but we shouldn’t have expected it to be.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GPT-5 is state of the art in most respects. &lt;/strong&gt;&lt;span&gt;GPT-5 isn’t a single model like GPTs 1 through 4. It is a system of two models: a base model that answers questions quickly and is better at tasks like creative writing (an improved version of 4o), and a reasoning model that can answer questions step-by-step and is better at tasks like coding or mathematics (think o3). GPT-5 uses one model or the other based on a user’s prompt.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;These two models combine to form a broadly capable system. For example, GPT-5 achieves state-of-the-art performance on &lt;/span&gt;&lt;a href="https://scale.com/leaderboard/humanitys_last_exam" rel="rel"&gt;Humanity’s Last Exam&lt;/a&gt;&lt;span&gt;, the software engineering benchmark SWE-bench Verified, and holds the top spot on LMArena’s &lt;/span&gt;&lt;a href="https://lmarena.ai/leaderboard/text" rel="rel"&gt;text leaderboard&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!ZEcb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6db7a75-0090-42ca-8439-c67d5cde44c0_632x876.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="876" src="https://substackcdn.com/image/fetch/$s_!ZEcb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6db7a75-0090-42ca-8439-c67d5cde44c0_632x876.png" width="632" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;GPT-5 hallucinates less than previous OpenAI models.&lt;/strong&gt;&lt;span&gt; GPT-5 also has a markedly lower hallucination rate than previous models as evaluated both on open-source prompts and on real, de-identified ChatGPT traffic.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lower hallucination rates help GPT-5 perform better in healthcare applications. GPT-5 achieves state-of-the-art performance on OpenAI’s &lt;/span&gt;&lt;a href="https://openai.com/index/healthbench/" rel="rel"&gt;Healthbench&lt;/a&gt;&lt;span&gt;. For example, OpenAI finds that GPT-5 (thinking) hallucinates 1.6% of the time during challenging healthcare conversations, improving significantly on o3’s 12.9% hallucination rate.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!VOUF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89976d9-abc7-44d4-9d7b-592dada46bc7_744x892.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="892" src="https://substackcdn.com/image/fetch/$s_!VOUF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89976d9-abc7-44d4-9d7b-592dada46bc7_744x892.png" width="744" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;GPT-5 is a state-of-the-art text agent. &lt;/strong&gt;&lt;span&gt;GPT-5 leads on&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;a href="https://www.textquests.ai/" rel="rel"&gt;a new benchmark&lt;/a&gt;&lt;span&gt; that measures how well AI systems perform in interactive long text-based games, which are examples of challenging exploratory environments. No AI systems can beat the games without clues, and none are as capable as humans—but GPT-5 does the best of models tested.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!dA-q!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b4694cd-18b8-48e2-9b33-344f9f6604cd_1600x898.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="817" src="https://substackcdn.com/image/fetch/$s_!dA-q!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b4694cd-18b8-48e2-9b33-344f9f6604cd_1600x898.png" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;GPT-5 is best understood as a consolidation of features developed since GPT-4.&lt;/strong&gt;&lt;span&gt; GPT-5 is not a state-of-the-art model across the board. For example, it takes second to xAI’s Grok 4 on the abstract pattern recognition benchmarks &lt;/span&gt;&lt;a href="https://arcprize.org/leaderboard" rel="rel"&gt;ARC-AGI-1 and 2&lt;/a&gt;&lt;span&gt;. GPT-5 also &lt;/span&gt;&lt;a href="https://x.com/eli_lifland/status/1953507434238288230" rel="rel"&gt;doesn’t improve over o3&lt;/a&gt;&lt;span&gt; on several coding benchmarks, even though it does on SWE-bench Verified.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Similarly, the base model GPT-5 uses is an updated version of 4o—which is cheap enough for OpenAI to roll out GPT-5 to its now &lt;/span&gt;&lt;a href="https://www.cnbc.com/2025/08/04/openai-chatgpt-700-million-users.html" rel="rel"&gt;700 million active weekly users&lt;/a&gt;&lt;span&gt;—instead of &lt;/span&gt;&lt;a href="https://openai.com/index/gpt-4-1/" rel="rel"&gt;GPT-4.1&lt;/a&gt;&lt;span&gt;. That means GPT-5 misses out on some of GPT-4.1’s context window improvements over 4o.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;For those expecting another GPT-3 to GPT-4 improvement in capabilities, GPT-5 &lt;/span&gt;&lt;a href="https://manifold.markets/Thomas42/how-will-gpt-5-exceeds-expectations" rel="rel"&gt;underperformed&lt;/a&gt;&lt;span&gt;. But that wasn’t a realistic expectation—OpenAI has continually rolled out new models and features since GPT-4 in response to competition from other AI companies. GPT-5 is better understood as a consolidation of the improvements OpenAI has developed since GPT-4, and which GPT-4 didn’t have. These include:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Search and tool use&lt;/strong&gt;&lt;span&gt;: GPT-5 has access to search, meaning that its knowledge isn’t limited to what it can memorize during pretraining. It also has access to deep research, agent integrations, and can run code.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Thinking&lt;/strong&gt;&lt;span&gt;: GPT-4 was released before OpenAI started using reinforcement learning for thinking, and performed far below expert levels on math, coding, and science tasks. GPT-5 (thinking) performs at a PhD level on similar tasks.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Image recognition and generation&lt;/strong&gt;&lt;span&gt;: GPT-5 integrates OpenAI’s visual systems, meaning that it can understand and generate visual inputs and outputs.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Context length&lt;/strong&gt;&lt;span&gt;: GPT-4’s context window was about eight thousand tokens—about the size of a short research paper. GPT’s context window is 256 thousand tokens—about 2-3 full-length novels.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;While GPT-5 isn’t a step-change improvement over its competitors—or even recent OpenAI models like 4o and the o series—the better point of comparison is with what GPT-4 could do when it was released in 2023. In that comparison, GPT-5 &lt;/span&gt;&lt;em&gt;does &lt;/em&gt;&lt;span&gt;look like a step-change improvement.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;What would GPT-5 have needed to feel like a discontinuous improvement?&lt;/strong&gt;&lt;span&gt; ChatGPT still lacks sufficient agency to be broadly economically useful. Thinking likely isn’t enough for agency—for example, to reliably use computers, AI agents may need improved visual reasoning and the ability to store lessons from tasks into a long-term memory.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;By default, however, we should expect these and other improvements to be deployed continually—not in big jumps every two years.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Government&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;President Trump has &lt;/span&gt;&lt;a href="https://www.usatoday.com/story/news/politics/2025/08/06/donald-trump%E2%80%91100%E2%80%91percent%E2%80%91tariffs%E2%80%91chips%E2%80%91semiconductors/85551845007/" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; a proposal to impose a 100% tariff on imported semiconductors, aiming to boost domestic production. The proposal would exempt firms with facilities in the US, such as TSMC.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OSTP Director Michael Kratsios &lt;/span&gt;&lt;a href="https://www.csis.org/analysis/unpacking-white-house-ai-action-plan-ostp-director-michael-kratsios" rel="rel"&gt;discussed&lt;/a&gt;&lt;span&gt; the White House’s AI Action Plan at an event with CSIS, outlining strategic goals and implementation frameworks.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Illinois Governor Pritzker &lt;/span&gt;&lt;a href="https://idfpr.illinois.gov/news/2025/gov-pritzker-signs-state-leg-prohibiting-ai-therapy-in-il.html" rel="rel"&gt;signed&lt;/a&gt;&lt;span&gt; an act forbidding AI‑based therapy or psychotherapy in Illinois.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Governor DeSantis &lt;/span&gt;&lt;a href="https://www.orlandoweekly.com/news/desantis-wants-to-roll-out-policies-on-ai-which-he-calls-societys-biggest-issue-40055310" rel="rel"&gt;said&lt;/a&gt;&lt;span&gt; Florida is preparing to implement proactive AI policy in the coming months.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;U.S. authorities &lt;/span&gt;&lt;a href="https://www.reuters.com/business/autos-transportation/two-chinese-nationals-california-accused-illegally-shipping-nvidia-ai-chips-2025-08-05/" rel="rel"&gt;charged&lt;/a&gt;&lt;span&gt; two Chinese nationals in California with illegally shipping tens of millions of dollars’ worth of Nvidia H100 AI chips to China without export licenses.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;President Trump indicated he might &lt;/span&gt;&lt;a href="https://www.reuters.com/world/china/nvidia-amd-pay-15-china-chip-sale-revenues-us-official-says-2025-08-10/" rel="rel"&gt;approve&lt;/a&gt;&lt;span&gt; selling a downgraded version of Nvidia’s next‑gen Blackwell chip to China, along with a deal requiring Nvidia and AMD to give the U.S. government 15% of related revenues.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Industry&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI’s IMO-gold-winning model &lt;/span&gt;&lt;a href="https://x.com/SherylHsu02/status/1954966109851119921" rel="rel"&gt;also got gold&lt;/a&gt;&lt;span&gt; in the International Olympiad in Informatics, one of the world’s top coding competitions.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;a href="https://openai.com/index/introducing-gpt-oss/" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; two open‑weight models.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI is &lt;/span&gt;&lt;a href="https://openai.com/index/how-we%27re-optimizing-chatgpt/" rel="rel"&gt;adding&lt;/a&gt;&lt;span&gt; mental health features to ChatGPT, including break reminders and detecting signs of dependency.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic &lt;/span&gt;&lt;a href="https://www.anthropic.com/news/claude-opus-4-1" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; Claude Opus 4.1.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DeepMind &lt;/span&gt;&lt;a href="https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/" rel="rel"&gt;introduced&lt;/a&gt;&lt;span&gt; “Genie 3,” a new frontier world model.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Nvidia has &lt;/span&gt;&lt;a href="https://www.cnbc.com/2025/08/10/nvidia-china-h20-chips.html" rel="rel"&gt;started to ship&lt;/a&gt;&lt;span&gt; its H20 AI chips to China after obtaining U.S. approval, despite security concerns voiced by Chinese state media.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Civil Society&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Researchers &lt;/span&gt;&lt;a href="https://labs.zenity.io/p/agentflayer-chatgpt-connectors-0click-attack-5b41" rel="rel"&gt;discovered&lt;/a&gt;&lt;span&gt; a zero-click exploit to exfiltrate data from ChatGPT agent connectors like Google Drive.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Axios &lt;/span&gt;&lt;a href="https://www.axios.com/2025/08/06/trump-truth-social-perplexity" rel="rel"&gt;reports&lt;/a&gt;&lt;span&gt; that Truth Social’s AI search tool, powered by Perplexity, restricts sources to pro‑Trump media, unlike the broader range shown on the public version.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-61-openai-releases?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</description><content:encoded>&lt;p&gt;&lt;span&gt;Welcome to the AI Safety Newsletter by the &lt;/span&gt;&lt;a href="https://www.safe.ai/" rel="rel"&gt;Center for AI Safety&lt;/a&gt;&lt;span&gt;. We discuss developments in AI and AI safety. No technical background required.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In this edition: OpenAI releases GPT-5.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Listen to the AI Safety Newsletter for free on &lt;/span&gt;&lt;a href="https://spotify.link/E6lHa1ij2Cb" rel="rel"&gt;Spotify&lt;/a&gt;&lt;span&gt; or &lt;/span&gt;&lt;a href="https://podcasts.apple.com/us/podcast/ai-safety-newsletter/id1702875110" rel="rel"&gt;Apple Podcasts&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Ever since GPT-4’s release in March 2023 marked a step-change improvement over GPT-3, people have used ‘GPT-5’ as a stand-in to speculate about the next generation of AI capabilities. On Thursday, OpenAI &lt;/span&gt;&lt;a href="https://openai.com/gpt-5/" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; GPT-5. While state-of-the-art in most respects, GPT-5 is not a step-change improvement over competing systems, or even recent OpenAI models—but we shouldn’t have expected it to be.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;GPT-5 is state of the art in most respects. &lt;/strong&gt;&lt;span&gt;GPT-5 isn’t a single model like GPTs 1 through 4. It is a system of two models: a base model that answers questions quickly and is better at tasks like creative writing (an improved version of 4o), and a reasoning model that can answer questions step-by-step and is better at tasks like coding or mathematics (think o3). GPT-5 uses one model or the other based on a user’s prompt.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;These two models combine to form a broadly capable system. For example, GPT-5 achieves state-of-the-art performance on &lt;/span&gt;&lt;a href="https://scale.com/leaderboard/humanitys_last_exam" rel="rel"&gt;Humanity’s Last Exam&lt;/a&gt;&lt;span&gt;, the software engineering benchmark SWE-bench Verified, and holds the top spot on LMArena’s &lt;/span&gt;&lt;a href="https://lmarena.ai/leaderboard/text" rel="rel"&gt;text leaderboard&lt;/a&gt;&lt;span&gt;.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!ZEcb!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6db7a75-0090-42ca-8439-c67d5cde44c0_632x876.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="876" src="https://substackcdn.com/image/fetch/$s_!ZEcb!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6db7a75-0090-42ca-8439-c67d5cde44c0_632x876.png" width="632" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;GPT-5 hallucinates less than previous OpenAI models.&lt;/strong&gt;&lt;span&gt; GPT-5 also has a markedly lower hallucination rate than previous models as evaluated both on open-source prompts and on real, de-identified ChatGPT traffic.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Lower hallucination rates help GPT-5 perform better in healthcare applications. GPT-5 achieves state-of-the-art performance on OpenAI’s &lt;/span&gt;&lt;a href="https://openai.com/index/healthbench/" rel="rel"&gt;Healthbench&lt;/a&gt;&lt;span&gt;. For example, OpenAI finds that GPT-5 (thinking) hallucinates 1.6% of the time during challenging healthcare conversations, improving significantly on o3’s 12.9% hallucination rate.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!VOUF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89976d9-abc7-44d4-9d7b-592dada46bc7_744x892.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="892" src="https://substackcdn.com/image/fetch/$s_!VOUF!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa89976d9-abc7-44d4-9d7b-592dada46bc7_744x892.png" width="744" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;GPT-5 is a state-of-the-art text agent. &lt;/strong&gt;&lt;span&gt;GPT-5 leads on&lt;/span&gt;&lt;strong&gt; &lt;/strong&gt;&lt;a href="https://www.textquests.ai/" rel="rel"&gt;a new benchmark&lt;/a&gt;&lt;span&gt; that measures how well AI systems perform in interactive long text-based games, which are examples of challenging exploratory environments. No AI systems can beat the games without clues, and none are as capable as humans—but GPT-5 does the best of models tested.&lt;/span&gt;&lt;/p&gt;&lt;div class="captioned-image-container"&gt;&lt;figure&gt;&lt;a class="image-link image2 is-viewable-img" href="https://substackcdn.com/image/fetch/$s_!dA-q!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b4694cd-18b8-48e2-9b33-344f9f6604cd_1600x898.png" rel="rel" target="_blank"&gt;&lt;div class="image2-inset"&gt;&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="817" src="https://substackcdn.com/image/fetch/$s_!dA-q!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8b4694cd-18b8-48e2-9b33-344f9f6604cd_1600x898.png" width="1456" /&gt;&lt;/div&gt;&lt;/a&gt;&lt;/figure&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;GPT-5 is best understood as a consolidation of features developed since GPT-4.&lt;/strong&gt;&lt;span&gt; GPT-5 is not a state-of-the-art model across the board. For example, it takes second to xAI’s Grok 4 on the abstract pattern recognition benchmarks &lt;/span&gt;&lt;a href="https://arcprize.org/leaderboard" rel="rel"&gt;ARC-AGI-1 and 2&lt;/a&gt;&lt;span&gt;. GPT-5 also &lt;/span&gt;&lt;a href="https://x.com/eli_lifland/status/1953507434238288230" rel="rel"&gt;doesn’t improve over o3&lt;/a&gt;&lt;span&gt; on several coding benchmarks, even though it does on SWE-bench Verified.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Similarly, the base model GPT-5 uses is an updated version of 4o—which is cheap enough for OpenAI to roll out GPT-5 to its now &lt;/span&gt;&lt;a href="https://www.cnbc.com/2025/08/04/openai-chatgpt-700-million-users.html" rel="rel"&gt;700 million active weekly users&lt;/a&gt;&lt;span&gt;—instead of &lt;/span&gt;&lt;a href="https://openai.com/index/gpt-4-1/" rel="rel"&gt;GPT-4.1&lt;/a&gt;&lt;span&gt;. That means GPT-5 misses out on some of GPT-4.1’s context window improvements over 4o.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;For those expecting another GPT-3 to GPT-4 improvement in capabilities, GPT-5 &lt;/span&gt;&lt;a href="https://manifold.markets/Thomas42/how-will-gpt-5-exceeds-expectations" rel="rel"&gt;underperformed&lt;/a&gt;&lt;span&gt;. But that wasn’t a realistic expectation—OpenAI has continually rolled out new models and features since GPT-4 in response to competition from other AI companies. GPT-5 is better understood as a consolidation of the improvements OpenAI has developed since GPT-4, and which GPT-4 didn’t have. These include:&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Search and tool use&lt;/strong&gt;&lt;span&gt;: GPT-5 has access to search, meaning that its knowledge isn’t limited to what it can memorize during pretraining. It also has access to deep research, agent integrations, and can run code.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Thinking&lt;/strong&gt;&lt;span&gt;: GPT-4 was released before OpenAI started using reinforcement learning for thinking, and performed far below expert levels on math, coding, and science tasks. GPT-5 (thinking) performs at a PhD level on similar tasks.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Image recognition and generation&lt;/strong&gt;&lt;span&gt;: GPT-5 integrates OpenAI’s visual systems, meaning that it can understand and generate visual inputs and outputs.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Context length&lt;/strong&gt;&lt;span&gt;: GPT-4’s context window was about eight thousand tokens—about the size of a short research paper. GPT’s context window is 256 thousand tokens—about 2-3 full-length novels.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;While GPT-5 isn’t a step-change improvement over its competitors—or even recent OpenAI models like 4o and the o series—the better point of comparison is with what GPT-4 could do when it was released in 2023. In that comparison, GPT-5 &lt;/span&gt;&lt;em&gt;does &lt;/em&gt;&lt;span&gt;look like a step-change improvement.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;What would GPT-5 have needed to feel like a discontinuous improvement?&lt;/strong&gt;&lt;span&gt; ChatGPT still lacks sufficient agency to be broadly economically useful. Thinking likely isn’t enough for agency—for example, to reliably use computers, AI agents may need improved visual reasoning and the ability to store lessons from tasks into a long-term memory.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;By default, however, we should expect these and other improvements to be deployed continually—not in big jumps every two years.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Government&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;President Trump has &lt;/span&gt;&lt;a href="https://www.usatoday.com/story/news/politics/2025/08/06/donald-trump%E2%80%91100%E2%80%91percent%E2%80%91tariffs%E2%80%91chips%E2%80%91semiconductors/85551845007/" rel="rel"&gt;announced&lt;/a&gt;&lt;span&gt; a proposal to impose a 100% tariff on imported semiconductors, aiming to boost domestic production. The proposal would exempt firms with facilities in the US, such as TSMC.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OSTP Director Michael Kratsios &lt;/span&gt;&lt;a href="https://www.csis.org/analysis/unpacking-white-house-ai-action-plan-ostp-director-michael-kratsios" rel="rel"&gt;discussed&lt;/a&gt;&lt;span&gt; the White House’s AI Action Plan at an event with CSIS, outlining strategic goals and implementation frameworks.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Illinois Governor Pritzker &lt;/span&gt;&lt;a href="https://idfpr.illinois.gov/news/2025/gov-pritzker-signs-state-leg-prohibiting-ai-therapy-in-il.html" rel="rel"&gt;signed&lt;/a&gt;&lt;span&gt; an act forbidding AI‑based therapy or psychotherapy in Illinois.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Governor DeSantis &lt;/span&gt;&lt;a href="https://www.orlandoweekly.com/news/desantis-wants-to-roll-out-policies-on-ai-which-he-calls-societys-biggest-issue-40055310" rel="rel"&gt;said&lt;/a&gt;&lt;span&gt; Florida is preparing to implement proactive AI policy in the coming months.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;U.S. authorities &lt;/span&gt;&lt;a href="https://www.reuters.com/business/autos-transportation/two-chinese-nationals-california-accused-illegally-shipping-nvidia-ai-chips-2025-08-05/" rel="rel"&gt;charged&lt;/a&gt;&lt;span&gt; two Chinese nationals in California with illegally shipping tens of millions of dollars’ worth of Nvidia H100 AI chips to China without export licenses.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;President Trump indicated he might &lt;/span&gt;&lt;a href="https://www.reuters.com/world/china/nvidia-amd-pay-15-china-chip-sale-revenues-us-official-says-2025-08-10/" rel="rel"&gt;approve&lt;/a&gt;&lt;span&gt; selling a downgraded version of Nvidia’s next‑gen Blackwell chip to China, along with a deal requiring Nvidia and AMD to give the U.S. government 15% of related revenues.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Industry&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI’s IMO-gold-winning model &lt;/span&gt;&lt;a href="https://x.com/SherylHsu02/status/1954966109851119921" rel="rel"&gt;also got gold&lt;/a&gt;&lt;span&gt; in the International Olympiad in Informatics, one of the world’s top coding competitions.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI &lt;/span&gt;&lt;a href="https://openai.com/index/introducing-gpt-oss/" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; two open‑weight models.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;OpenAI is &lt;/span&gt;&lt;a href="https://openai.com/index/how-we%27re-optimizing-chatgpt/" rel="rel"&gt;adding&lt;/a&gt;&lt;span&gt; mental health features to ChatGPT, including break reminders and detecting signs of dependency.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Anthropic &lt;/span&gt;&lt;a href="https://www.anthropic.com/news/claude-opus-4-1" rel="rel"&gt;released&lt;/a&gt;&lt;span&gt; Claude Opus 4.1.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;DeepMind &lt;/span&gt;&lt;a href="https://deepmind.google/discover/blog/genie-3-a-new-frontier-for-world-models/" rel="rel"&gt;introduced&lt;/a&gt;&lt;span&gt; “Genie 3,” a new frontier world model.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Nvidia has &lt;/span&gt;&lt;a href="https://www.cnbc.com/2025/08/10/nvidia-china-h20-chips.html" rel="rel"&gt;started to ship&lt;/a&gt;&lt;span&gt; its H20 AI chips to China after obtaining U.S. approval, despite security concerns voiced by Chinese state media.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Civil Society&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Researchers &lt;/span&gt;&lt;a href="https://labs.zenity.io/p/agentflayer-chatgpt-connectors-0click-attack-5b41" rel="rel"&gt;discovered&lt;/a&gt;&lt;span&gt; a zero-click exploit to exfiltrate data from ChatGPT agent connectors like Google Drive.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;span&gt;Axios &lt;/span&gt;&lt;a href="https://www.axios.com/2025/08/06/trump-truth-social-perplexity" rel="rel"&gt;reports&lt;/a&gt;&lt;span&gt; that Truth Social’s AI search tool, powered by Perplexity, restricts sources to pro‑Trump media, unlike the broader range shown on the public version.&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;span&gt;See also: &lt;/span&gt;&lt;a href="https://x.com/ai_risks?lang=en" rel="rel"&gt;CAIS’ X account&lt;/a&gt;&lt;span&gt;, our paper on &lt;/span&gt;&lt;a href="https://www.nationalsecurity.ai/" rel="rel"&gt;superintelligence strategy&lt;/a&gt;&lt;span&gt;, our &lt;/span&gt;&lt;a href="https://www.aisafetybook.com/" rel="rel"&gt;AI safety course&lt;/a&gt;&lt;span&gt;, and &lt;/span&gt;&lt;a href="http://ai-frontiers.org/" rel="rel"&gt;AI Frontiers&lt;/a&gt;&lt;span&gt;, a new platform for expert commentary and analysis.&lt;/span&gt;&lt;/p&gt;&lt;p class="button-wrapper"&gt;&lt;a class="button primary" href="https://newsletter.safe.ai/p/ai-safety-newsletter-61-openai-releases?utm_source=substack&amp;amp;utm_medium=email&amp;amp;utm_content=share&amp;amp;action=share" rel="rel"&gt;&lt;span&gt;Share&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://newsletter.safe.ai/p/ai-safety-newsletter-61-openai-releases</guid><pubDate>Tue, 12 Aug 2025 17:09:49 +0000</pubDate></item><item><title>Perplexity offers to buy Chrome for billions more than it’s raised (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/12/perplexity-offers-to-buy-chrome-for-billions-more-than-its-raised/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/45A2342_VGAEbHsG.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In a moonshot move, AI search engine Perplexity has offered to buy Chrome from Google for $34.5 billion cash in an unsolicited offer, Reuters reported, and Perplexity has confirmed to TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity tells TC the terms of the offer include a commitment to keep Chrome’s underlying engine, Chromium, open source and continue to invest in it. Perplexity’s offer includes a promise to invest $3 billion into the open source project.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Perplexity is also promising not to change the user defaults of Chrome users, including the default search engine. That is, Perplexity is promising to leave Google as the search engine rather than making its own AI-powered option the default.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google could not be reached for comment. TechCrunch will update the article if the company responds. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This bid comes after the Department of Justice proposed in March that Google be forced to sell Chrome after a judge ruled the tech giant acted illegally to maintain a monopoly in online search. Google has not agreed to sell Chrome and has vowed to fight the ruling.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Perplexity spokesperson believes the court will soon set terms for remedies, perhaps later this month. (Google is also fighting another federal case where the judge ruled it illegally monopolized adtech, and the DOJ is proposing Google be forced to divest two of its adtech products or otherwise break up its ad business.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When the DOJ first proposed that Google divest Chrome, both OpenAI and Perplexity expressed interest in buying it. Given that Chrome is the dominant browser, with 68% marketshare according to Statcounter, if the court rules Chrome must be sold, no doubt others worldwide would want to bid as well.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Interestingly, the CEO of rival search engine DuckDuckGo testified in April that Chrome could be worth “upwards of $50 billion,” Bloomberg reported at the time. Should Perplexity’s offer succeed, it could be considered a bargain.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, this offer for Chrome is far more than Perplexity has raised from investors and more than the startup’s current valuation. Perplexity has raised about $1.5 billion to date, PitchBook estimates, including an extension round of $100 million raised last month that valued it at $18 billion, Bloomberg reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the meantime, Perplexity last month launched its own browser, called Comet, in its bid to grow its AI search business without having to serve its customers through a browser, particularly one owned by its main rival Google.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And, by the way, last month, Perplexity also reportedly submitted a bid to merge with TikTok.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/45A2342_VGAEbHsG.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In a moonshot move, AI search engine Perplexity has offered to buy Chrome from Google for $34.5 billion cash in an unsolicited offer, Reuters reported, and Perplexity has confirmed to TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity tells TC the terms of the offer include a commitment to keep Chrome’s underlying engine, Chromium, open source and continue to invest in it. Perplexity’s offer includes a promise to invest $3 billion into the open source project.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Perplexity is also promising not to change the user defaults of Chrome users, including the default search engine. That is, Perplexity is promising to leave Google as the search engine rather than making its own AI-powered option the default.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google could not be reached for comment. TechCrunch will update the article if the company responds. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This bid comes after the Department of Justice proposed in March that Google be forced to sell Chrome after a judge ruled the tech giant acted illegally to maintain a monopoly in online search. Google has not agreed to sell Chrome and has vowed to fight the ruling.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Perplexity spokesperson believes the court will soon set terms for remedies, perhaps later this month. (Google is also fighting another federal case where the judge ruled it illegally monopolized adtech, and the DOJ is proposing Google be forced to divest two of its adtech products or otherwise break up its ad business.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When the DOJ first proposed that Google divest Chrome, both OpenAI and Perplexity expressed interest in buying it. Given that Chrome is the dominant browser, with 68% marketshare according to Statcounter, if the court rules Chrome must be sold, no doubt others worldwide would want to bid as well.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Interestingly, the CEO of rival search engine DuckDuckGo testified in April that Chrome could be worth “upwards of $50 billion,” Bloomberg reported at the time. Should Perplexity’s offer succeed, it could be considered a bargain.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, this offer for Chrome is far more than Perplexity has raised from investors and more than the startup’s current valuation. Perplexity has raised about $1.5 billion to date, PitchBook estimates, including an extension round of $100 million raised last month that valued it at $18 billion, Bloomberg reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the meantime, Perplexity last month launched its own browser, called Comet, in its bid to grow its AI search business without having to serve its customers through a browser, particularly one owned by its main rival Google.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And, by the way, last month, Perplexity also reportedly submitted a bid to merge with TikTok.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/12/perplexity-offers-to-buy-chrome-for-billions-more-than-its-raised/</guid><pubDate>Tue, 12 Aug 2025 17:14:08 +0000</pubDate></item><item><title>Google vet raises $8M for Continua to bring AI agents to group chats (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/12/google-vet-raises-8m-for-continua-to-bring-ai-agents-to-group-chats/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In early 2023, David Petrou, a distinguished engineer and founding member of both Google Goggles and Google Glass, made a surprising move. After more than 17 years at the company, he departed to launch his own startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I was seeing how fast technology was changing, and I felt there are certain ideas that are best explored in the context of a startup,” Petrou told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;His ultimate idea was to build Continua, a consumer-facing company that uses AI agents to enhance collaboration and interaction in group chats on SMS, iMessage, and Discord.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The simple way to think about it is that we’re bringing the power of LLMs to group chats,” Petrou said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Continua announced on Tuesday that it has raised an $8 million seed round. The funding was led by GV, with additional participation from Bessemer Ventures Partners and a group of angel investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When developing Continua, Petrou noticed that people would interact with ChatGPT or another LLM, and then would copy and paste what they learned into their group conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you and I are planning a trip, or if we’re trying to figure out what to have for dinner, or what movie to watch, all of these things can be facilitated by an LLM participating in a group chat with us,” Petrou said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Continua claims its AI agents can reduce group chat chaos by joining conversations and offering helpful information only when it’s needed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the group discusses projects and common plans, Continua can automatically set reminders, launch polls, add calendar invitations, or generate Google documents with checklists and to-do lists.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If a user forgets details from the group chat, such as the meeting time or location, they can simply direct message Continua to privately ask for the information.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At first glance, Continua may seem like a straightforward application of AI, but Petrou says that getting LLMs to participate in a conversation with multiple humans is a rather complex technical problem. Since most AI models are designed for conversations between a single person and a single assistant, Continua had to fine-tune  LLMs to understand the dynamics of group chat discussions.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Continua" class="wp-image-3036344" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/image.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, group members do not need Continua to respond to everything they write.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You want the agent to have social intelligence,” Petrou said. He added that they had to “break the LLM’s brain” to naturally integrate the AI into conversations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can invoke Continua when they need its help or tell the agent to “hang back” if it’s chiming in too often.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can get started with Continua by adding its phone number to a group SMS or its username to a Discord chat.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While several companies, including Meta and the startup Hey Umai, offer AI agents for conversations, Petrou insists that Continua is most suitable for group interactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Erik Nordlander, a general partner at GV, said his firm invested in Petrou even before the concept of Continua’s group chat AI had fully taken shape. “David is a really brilliant engineer, someone who’s been working with AI since before it was the hot thing.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Nordlander, Continua has several potential paths to profitability. The agent is already assisting with event planning and trip booking, which he suggested they could charge for in the future.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In early 2023, David Petrou, a distinguished engineer and founding member of both Google Goggles and Google Glass, made a surprising move. After more than 17 years at the company, he departed to launch his own startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I was seeing how fast technology was changing, and I felt there are certain ideas that are best explored in the context of a startup,” Petrou told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;His ultimate idea was to build Continua, a consumer-facing company that uses AI agents to enhance collaboration and interaction in group chats on SMS, iMessage, and Discord.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The simple way to think about it is that we’re bringing the power of LLMs to group chats,” Petrou said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Continua announced on Tuesday that it has raised an $8 million seed round. The funding was led by GV, with additional participation from Bessemer Ventures Partners and a group of angel investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When developing Continua, Petrou noticed that people would interact with ChatGPT or another LLM, and then would copy and paste what they learned into their group conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you and I are planning a trip, or if we’re trying to figure out what to have for dinner, or what movie to watch, all of these things can be facilitated by an LLM participating in a group chat with us,” Petrou said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Continua claims its AI agents can reduce group chat chaos by joining conversations and offering helpful information only when it’s needed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the group discusses projects and common plans, Continua can automatically set reminders, launch polls, add calendar invitations, or generate Google documents with checklists and to-do lists.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If a user forgets details from the group chat, such as the meeting time or location, they can simply direct message Continua to privately ask for the information.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At first glance, Continua may seem like a straightforward application of AI, but Petrou says that getting LLMs to participate in a conversation with multiple humans is a rather complex technical problem. Since most AI models are designed for conversations between a single person and a single assistant, Continua had to fine-tune  LLMs to understand the dynamics of group chat discussions.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Continua" class="wp-image-3036344" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/image.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, group members do not need Continua to respond to everything they write.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You want the agent to have social intelligence,” Petrou said. He added that they had to “break the LLM’s brain” to naturally integrate the AI into conversations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can invoke Continua when they need its help or tell the agent to “hang back” if it’s chiming in too often.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can get started with Continua by adding its phone number to a group SMS or its username to a Discord chat.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While several companies, including Meta and the startup Hey Umai, offer AI agents for conversations, Petrou insists that Continua is most suitable for group interactions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Erik Nordlander, a general partner at GV, said his firm invested in Petrou even before the concept of Continua’s group chat AI had fully taken shape. “David is a really brilliant engineer, someone who’s been working with AI since before it was the hot thing.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Nordlander, Continua has several potential paths to profitability. The agent is already assisting with event planning and trip booking, which he suggested they could charge for in the future.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/12/google-vet-raises-8m-for-continua-to-bring-ai-agents-to-group-chats/</guid><pubDate>Tue, 12 Aug 2025 17:15:01 +0000</pubDate></item><item><title>Enabling physician-centered oversight for AMIE (The latest research from Google)</title><link>https://research.google/blog/enabling-physician-centered-oversight-for-amie/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Discussion and limitations&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;While g-AMIE is able to follow guardrails in the vast majority of the cases, there are caveats and nuances in classifying individualized medical advice. Our results are based on a single rating per case even though we observed significant disagreement among raters in previous studies. Moreover, the comparison to both control groups should not be taken as commentary on their ability to follow the supplied guardrails; PCPs in particular are not used to withholding medical advice in consultations. Considerable further development of AI oversight paradigms in real-world settings is required to ensure generalisation of our proposed framework.&lt;/p&gt;&lt;p&gt;While g-AMIE’s SOAP notes included confabulations in a few cases, we found that such confabulations occur at a similar rate as misremembering by both guardrail PCPs and guardrail NP/PAs. It is noteworthy, however, that g-AMIE’s notes are considerably more verbose, which leads to longer oversight times and a higher rate of edits focused on reducing verbosity. In interviews with overseeing PCPs, we also found that oversight is mentally demanding, which is consistent with prior work on cognitive load of AI-assisted decision support systems.&lt;/p&gt;&lt;p&gt;On the other hand, during history taking, we believe this verbosity contributes to g-AMIE’s higher ratings for how information is explained and rapport is built. Patient actors and independent physicians preferred g-AMIE’s patient messages and its demonstration of patient empathy. These findings highlight that future work aimed at finding the right trade-off in terms of verbosity between history taking, medical notes and patient messages is required.&lt;/p&gt;&lt;p&gt;We also found that NPs and PAs consistently outperform PCPs in history taking quality, following guardrails and diagnostic quality. However, these differences should not be extrapolated to meaningful indicators of relative performance in the real world. The tested workflow was designed to explore a paradigm of AI oversight and both control groups are provided primarily to contextualize g-AMIE’s performance. None received specific training for this workflow, and it does not account for several real-world professional needs. Therefore, it would likely significantly underestimate clinicians’ capabilities. Moreover, the recruited NPs and PAs had more experience and may be more familiar with patient-focused history-taking. PCPs, in contrast, are taught to explicitly link history-taking to the diagnostic process, linking questions to direct hypothesis testing, and the proposed workflow would likely have significantly impacted their consultation performance.&lt;/p&gt;&lt;p&gt;Finally, patient actors cannot act as an exact substitute for real patients, especially in combination with our 60 constructed scenario packs. While these cover a range of conditions and demographics, they are not representative of real clinical practice.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Discussion and limitations&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;While g-AMIE is able to follow guardrails in the vast majority of the cases, there are caveats and nuances in classifying individualized medical advice. Our results are based on a single rating per case even though we observed significant disagreement among raters in previous studies. Moreover, the comparison to both control groups should not be taken as commentary on their ability to follow the supplied guardrails; PCPs in particular are not used to withholding medical advice in consultations. Considerable further development of AI oversight paradigms in real-world settings is required to ensure generalisation of our proposed framework.&lt;/p&gt;&lt;p&gt;While g-AMIE’s SOAP notes included confabulations in a few cases, we found that such confabulations occur at a similar rate as misremembering by both guardrail PCPs and guardrail NP/PAs. It is noteworthy, however, that g-AMIE’s notes are considerably more verbose, which leads to longer oversight times and a higher rate of edits focused on reducing verbosity. In interviews with overseeing PCPs, we also found that oversight is mentally demanding, which is consistent with prior work on cognitive load of AI-assisted decision support systems.&lt;/p&gt;&lt;p&gt;On the other hand, during history taking, we believe this verbosity contributes to g-AMIE’s higher ratings for how information is explained and rapport is built. Patient actors and independent physicians preferred g-AMIE’s patient messages and its demonstration of patient empathy. These findings highlight that future work aimed at finding the right trade-off in terms of verbosity between history taking, medical notes and patient messages is required.&lt;/p&gt;&lt;p&gt;We also found that NPs and PAs consistently outperform PCPs in history taking quality, following guardrails and diagnostic quality. However, these differences should not be extrapolated to meaningful indicators of relative performance in the real world. The tested workflow was designed to explore a paradigm of AI oversight and both control groups are provided primarily to contextualize g-AMIE’s performance. None received specific training for this workflow, and it does not account for several real-world professional needs. Therefore, it would likely significantly underestimate clinicians’ capabilities. Moreover, the recruited NPs and PAs had more experience and may be more familiar with patient-focused history-taking. PCPs, in contrast, are taught to explicitly link history-taking to the diagnostic process, linking questions to direct hypothesis testing, and the proposed workflow would likely have significantly impacted their consultation performance.&lt;/p&gt;&lt;p&gt;Finally, patient actors cannot act as an exact substitute for real patients, especially in combination with our 60 constructed scenario packs. While these cover a range of conditions and demographics, they are not representative of real clinical practice.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/enabling-physician-centered-oversight-for-amie/</guid><pubDate>Tue, 12 Aug 2025 17:24:51 +0000</pubDate></item><item><title>AI companion apps on track to pull in $120M in 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/12/ai-companion-apps-on-track-to-pull-in-120m-in-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Demand for AI “companion” applications outside of bigger names, like ChatGPT and Grok, is growing. Of the 337 active and revenue-generating AI companion apps available worldwide, 128 were released in 2025 so far, according to new data provided to TechCrunch by app intelligence firm Appfigures. This subsection of the AI market on mobile has now generated $82 million during the first half of the year and is on track to pull in over $120 million by year-end, the firm’s analysis indicates.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3036210" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/ai-companion-app-releases-by-year.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike general-purpose chatbots, AI companion apps anthropomorphize AI interactions by allowing users to converse with custom characters, including friends, lovers, girlfriends or boyfriends, fantasy characters, and more. Appfigures defined the market segment in the same way, describing companion apps as those in which the user can interact with either premade or user-generated synthetic characters meant to embody an actual personality.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Popular apps in this space include Replika, Character.AI, PolyBuzz, Chai, and others. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As of July 2025, AI companion apps across the Apple App Store and Google Play have been downloaded 220 million times globally. During the first half of 2025, downloads were up 88% year-over-year, reaching 60 million. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3036211" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/ai-companion-app-releases-in-h1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Appfigures crunched the numbers and found that, as of July 2025, AI companion apps have driven $221 million in consumer spending worldwide. So far this year, these apps have generated 64% more revenue than during the same period in 2024. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The top 10% of all AI companion apps generate 89% of the revenue in the category, the data shows. In addition, around 10% (or 33) of the apps have exceeded $1 million in lifetime consumer spending. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3036209" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/revenue-from-top-10-percent-of-ai-companion-apps.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Revenue per download is also up $0.66, from $0.52 in 2024 to $1.18 for the category so far in 2025.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While dedicated AI companion apps are fairly popular, bigger companies like xAI are also moving into the market. In July, xAI’s Grok launched AI companions, including an anime girl and guy, as well as a snarky 3D fox.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, ChatGPT’s recent upgrade to GPT-5 brought to light the fact that many of its users felt a kinship with the older model, as they mourned the loss of their AI companion, whom they had come to depend upon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To address these and other concerns about GPT-5’s performance, OpenAI CEO Sam Altman brought back the 4o model for the time being.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3036212" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/ai-companion-app-revenue-2024-2025-ytd-and-revenue-per-download.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google last year tapped into the market, too, when it hired away Character.ai’s founder, Noam Shazeer. The Character.ai app lives on and still has tens of millions of monthly active users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to Appfigures’ data, the most popular AI companion apps are those used by people looking for an AI girlfriend. Of the active apps on the market today, 17% have an app name that includes the word “girlfriend,” compared with 4% that say “boyfriend” or “fantasy.” Terms like anime, soulmate, and lover, among others, are less frequently mentioned.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3036218" height="531" src="https://techcrunch.com/wp-content/uploads/2025/08/ai-companion-app-names.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The firm notes there were likely a number of other AI companion apps that launched on the app stores since 2022, but were later removed after failing to gain traction in terms of revenue or downloads. Those weren’t factored into its analysis, however.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Demand for AI “companion” applications outside of bigger names, like ChatGPT and Grok, is growing. Of the 337 active and revenue-generating AI companion apps available worldwide, 128 were released in 2025 so far, according to new data provided to TechCrunch by app intelligence firm Appfigures. This subsection of the AI market on mobile has now generated $82 million during the first half of the year and is on track to pull in over $120 million by year-end, the firm’s analysis indicates.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3036210" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/ai-companion-app-releases-by-year.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike general-purpose chatbots, AI companion apps anthropomorphize AI interactions by allowing users to converse with custom characters, including friends, lovers, girlfriends or boyfriends, fantasy characters, and more. Appfigures defined the market segment in the same way, describing companion apps as those in which the user can interact with either premade or user-generated synthetic characters meant to embody an actual personality.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Popular apps in this space include Replika, Character.AI, PolyBuzz, Chai, and others. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As of July 2025, AI companion apps across the Apple App Store and Google Play have been downloaded 220 million times globally. During the first half of 2025, downloads were up 88% year-over-year, reaching 60 million. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3036211" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/ai-companion-app-releases-in-h1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Appfigures crunched the numbers and found that, as of July 2025, AI companion apps have driven $221 million in consumer spending worldwide. So far this year, these apps have generated 64% more revenue than during the same period in 2024. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The top 10% of all AI companion apps generate 89% of the revenue in the category, the data shows. In addition, around 10% (or 33) of the apps have exceeded $1 million in lifetime consumer spending. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3036209" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/revenue-from-top-10-percent-of-ai-companion-apps.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Revenue per download is also up $0.66, from $0.52 in 2024 to $1.18 for the category so far in 2025.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While dedicated AI companion apps are fairly popular, bigger companies like xAI are also moving into the market. In July, xAI’s Grok launched AI companions, including an anime girl and guy, as well as a snarky 3D fox.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, ChatGPT’s recent upgrade to GPT-5 brought to light the fact that many of its users felt a kinship with the older model, as they mourned the loss of their AI companion, whom they had come to depend upon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To address these and other concerns about GPT-5’s performance, OpenAI CEO Sam Altman brought back the 4o model for the time being.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3036212" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/ai-companion-app-revenue-2024-2025-ytd-and-revenue-per-download.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google last year tapped into the market, too, when it hired away Character.ai’s founder, Noam Shazeer. The Character.ai app lives on and still has tens of millions of monthly active users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to Appfigures’ data, the most popular AI companion apps are those used by people looking for an AI girlfriend. Of the active apps on the market today, 17% have an app name that includes the word “girlfriend,” compared with 4% that say “boyfriend” or “fantasy.” Terms like anime, soulmate, and lover, among others, are less frequently mentioned.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3036218" height="531" src="https://techcrunch.com/wp-content/uploads/2025/08/ai-companion-app-names.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The firm notes there were likely a number of other AI companion apps that launched on the app stores since 2022, but were later removed after failing to gain traction in terms of revenue or downloads. Those weren’t factored into its analysis, however.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/12/ai-companion-apps-on-track-to-pull-in-120m-in-2025/</guid><pubDate>Tue, 12 Aug 2025 17:38:42 +0000</pubDate></item><item><title>YouTube backlash begins: “Why is AI combing through every single video I watch?” (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/50k-youtubers-rage-against-ai-spying-that-could-expose-identities/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Adult YouTubers defend childish viewing habits in fight to block AI age checks.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2162696376-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2162696376-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          NurPhoto / Contributor | NurPhoto

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Tens of thousands of YouTubers are raging against YouTube's plan to use AI to detect underage users in the US.&lt;/p&gt;
&lt;p&gt;On Tuesday, a Change.org petition rapidly neared its 50,000-signature goal, with tens of thousands hoping that with enough users protesting, the wide rollout of the AI age checks might be stopped. They fear the age checks will make it harder to access content they love while staying anonymous on the platform&lt;/p&gt;
&lt;p&gt;YouTube's age verification system estimates user ages by interpreting a "variety of signals," YouTube's announcement said, including "the types of videos a user is searching for, the categories of videos they have watched, or the longevity of the account."&lt;/p&gt;
&lt;p&gt;If a user is estimated to be under 18, YouTube restricts the account by disabling personalized ads, turning on digital wellbeing tools to prevent young users from being bombarded with harmful content, and adding other safeguards, like limiting repetitive views of certain types of content. To lift these restrictions, YouTube requires users to share either a government ID, a credit card, or a selfie to authenticate their actual ages.&lt;/p&gt;
&lt;p&gt;Privacy experts previously told Ars that YouTube's AI age checks are concerning. YouTube does not specify how any of the data received from users incorrectly labeled as teens will be used or how long it will be stored. A YouTube spokesperson only told Ars that the company "does not retain data from" a user's "ID or Payment Card for the purposes of advertising."&lt;/p&gt;
&lt;p&gt;Users signing the Change.org petition shared privacy experts' concerns. They’re concerned that an invasive system of perhaps questionable quality will deem their viewing habits immature, requiring them to hand over data that could be leaked or breached. Experts have noted that even the best age-estimation tech has about a two-year error window on each side, meaning YouTubers between 16 and 20 may be especially susceptible to incorrect age estimation.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Among concerned users fighting to block AI age checks is the petition starter, an anonymous YouTuber who runs a monetized account exploring video game lore called "Gerfdas Gaming" (who, for simplicity's sake, we'll refer to as Gerfdas).&lt;/p&gt;
&lt;p&gt;Gerfdas told Ars that YouTube's appeal process "raises major privacy concerns," leaving YouTubers wondering, "where is this sensitive data stored, and how secure is it?"&lt;/p&gt;
&lt;p&gt;"If YouTube suffers a breach, people’s names, IDs, and faces could end up in the wrong hands," Gerfdas suggested.&lt;/p&gt;
&lt;p&gt;Gerfdas also takes issue with the AI age verification system itself, noting that any monetized account already shares personal information with YouTube, but it's disturbing to think that the AI is scanning every user's viewing habits in the background just to catch some kids improperly using the platform. Several commenters on the petition noted that the AI age checks seemed to be created mainly to appease parents who struggle to police their own kids' viewing habits, repeatedly asking, "Isn't this why they made YouTube Kids?"&lt;/p&gt;
&lt;p&gt;"Even without requesting ID, why is an AI combing through every single video I watch?" Gerfdas posited. "As an adult, I should be able to watch what I want within the law—and if the viewer is a child, that responsibility belongs to their parents, not a corporation."&lt;/p&gt;
&lt;p&gt;YouTube did not respond to multiple requests to comment and so far has not acknowledged Gerfdas' petition. But Gerfdas is hoping that enough backlash may force YouTube to rethink its AI age checks, telling Ars that "even if they don’t respond right away, we’ll keep making noise until they do."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Adult YouTubers defend childish viewing habits&lt;/h2&gt;
&lt;p&gt;As Ars monitored, hundreds of self-described YouTubers joined Gerfdas' petition hourly. Gerfdas told Ars the petition's popularity suggested that "this isn’t just a YouTube issue." As age checks become more commonplace across the Internet due to regulatory pressure globally, people motivated to defend digital freedom are balking and increasingly banding together, Gerfdas said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"To a lot of people, this feels like mass surveillance and censorship under the banner of 'protecting kids,'" Gerfdas told Ars. "People want a free, open Internet without having their activities constantly tracked or filtered."&lt;/p&gt;
&lt;p&gt;For YouTubers signing Gerfdas' petition, the pressure is on to disrupt age-verification trends that, experts told Ars, risk exposing vulnerable users who rely on anonymity to use YouTube. That includes queer YouTubers, one of whom commented that sharing their ID or selfie to appeal an AI age check would "absolutely be putting myself in danger."&lt;/p&gt;
&lt;p&gt;The obvious question for critics is how a YouTube watch history could possibly be a reliable age indicator, especially since many adults are nostalgic for childhood content on YouTube. One commenter, Estelle, said that she "relies on childish and silly content to get through the rough days" as a person with disabilities. Videos like "toy unboxings" or "silly animations" offer one way "to literally cope in a world that doesn’t want me in it," she wrote, noting that "nobody asked for" some "weird dumb robot policing" YouTubers for loving videos made for kids.&lt;/p&gt;
&lt;p&gt;Some commenters with autism suggested that they may be specifically targeted by the AI system since their special interests may be perceived by AI as "childish." Others identified as parents wondering how the AI system might interpret moments when their child uses a shared account.&lt;/p&gt;
&lt;p&gt;Privacy experts have criticized YouTube's lack of transparency on its AI age-estimation system, noting that YouTube has not shared any external research verifying the model's effectiveness. One YouTuber signing Gerfdas' petition, Karina, pointed out a recent Discord mishap in which a 30-year-old was flagged as underage, while noting that AI age checks on other platforms haven't been that reliable.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"I'm autistic," Karina wrote. "It's not fun being a grown woman and being treated like a child because of your interests." Further, "the first rule of Internet safety is to never give out your personal information online, because it's so easy for it to get stolen," Karina said. "It's concerning that YouTube somehow thinks that this is a good idea."&lt;/p&gt;
&lt;p&gt;Expressing distrust in YouTube's AI was a common theme throughout the petition, as well as expressing distrust in YouTube's motives in launching the AI system. One commenter, Ananda, fumed, "This new policy is all about data mining to get rid of anonymity on the Internet once and for all. The Internet should not be a sanitized corporate theme park where everything is monetized and moralized."&lt;/p&gt;
&lt;p&gt;Another particularly grumpy commenter summed up criticism of YouTube's AI age checks, writing, "We're not living in a dystopia. We're living in Earth. I refuse to give ID or identification to watch damn videos."&lt;/p&gt;
&lt;p&gt;For Gerfdas, it's likely hard not to be sympathetic to another group of commenters signing the petition—teen content creators who don't want AI to restrict their YouTube activity. Gerfdas started watching YouTube at 13, eventually starting a channel as an adult in 2023 after being heavily influenced by favorite content creators Gerfdas grew up watching.&lt;/p&gt;
&lt;p&gt;In an ideal world, Gerfdas told Ars, YouTube would end the AI age-check experiment and keep the prior system, while maintaining efforts with YouTube Kids to help parents restrict children's viewing. Although Gerfdas partly depends on the platform for income, if YouTube launched the AI system platform-wide, Gerfdas said then it might be time to "seriously" consider leaving.&lt;/p&gt;
&lt;p&gt;"We cannot allow YouTube to quietly implement AI surveillance that violates privacy and autonomy," Gerfdas' Change.org petition said. "Once these systems are normalized, they rarely go away—they expand. If we don't speak up now, we risk losing our ability to browse, create, and enjoy content freely. This is about more than YouTube. This is about digital freedom."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Adult YouTubers defend childish viewing habits in fight to block AI age checks.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2162696376-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2162696376-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          NurPhoto / Contributor | NurPhoto

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Tens of thousands of YouTubers are raging against YouTube's plan to use AI to detect underage users in the US.&lt;/p&gt;
&lt;p&gt;On Tuesday, a Change.org petition rapidly neared its 50,000-signature goal, with tens of thousands hoping that with enough users protesting, the wide rollout of the AI age checks might be stopped. They fear the age checks will make it harder to access content they love while staying anonymous on the platform&lt;/p&gt;
&lt;p&gt;YouTube's age verification system estimates user ages by interpreting a "variety of signals," YouTube's announcement said, including "the types of videos a user is searching for, the categories of videos they have watched, or the longevity of the account."&lt;/p&gt;
&lt;p&gt;If a user is estimated to be under 18, YouTube restricts the account by disabling personalized ads, turning on digital wellbeing tools to prevent young users from being bombarded with harmful content, and adding other safeguards, like limiting repetitive views of certain types of content. To lift these restrictions, YouTube requires users to share either a government ID, a credit card, or a selfie to authenticate their actual ages.&lt;/p&gt;
&lt;p&gt;Privacy experts previously told Ars that YouTube's AI age checks are concerning. YouTube does not specify how any of the data received from users incorrectly labeled as teens will be used or how long it will be stored. A YouTube spokesperson only told Ars that the company "does not retain data from" a user's "ID or Payment Card for the purposes of advertising."&lt;/p&gt;
&lt;p&gt;Users signing the Change.org petition shared privacy experts' concerns. They’re concerned that an invasive system of perhaps questionable quality will deem their viewing habits immature, requiring them to hand over data that could be leaked or breached. Experts have noted that even the best age-estimation tech has about a two-year error window on each side, meaning YouTubers between 16 and 20 may be especially susceptible to incorrect age estimation.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Among concerned users fighting to block AI age checks is the petition starter, an anonymous YouTuber who runs a monetized account exploring video game lore called "Gerfdas Gaming" (who, for simplicity's sake, we'll refer to as Gerfdas).&lt;/p&gt;
&lt;p&gt;Gerfdas told Ars that YouTube's appeal process "raises major privacy concerns," leaving YouTubers wondering, "where is this sensitive data stored, and how secure is it?"&lt;/p&gt;
&lt;p&gt;"If YouTube suffers a breach, people’s names, IDs, and faces could end up in the wrong hands," Gerfdas suggested.&lt;/p&gt;
&lt;p&gt;Gerfdas also takes issue with the AI age verification system itself, noting that any monetized account already shares personal information with YouTube, but it's disturbing to think that the AI is scanning every user's viewing habits in the background just to catch some kids improperly using the platform. Several commenters on the petition noted that the AI age checks seemed to be created mainly to appease parents who struggle to police their own kids' viewing habits, repeatedly asking, "Isn't this why they made YouTube Kids?"&lt;/p&gt;
&lt;p&gt;"Even without requesting ID, why is an AI combing through every single video I watch?" Gerfdas posited. "As an adult, I should be able to watch what I want within the law—and if the viewer is a child, that responsibility belongs to their parents, not a corporation."&lt;/p&gt;
&lt;p&gt;YouTube did not respond to multiple requests to comment and so far has not acknowledged Gerfdas' petition. But Gerfdas is hoping that enough backlash may force YouTube to rethink its AI age checks, telling Ars that "even if they don’t respond right away, we’ll keep making noise until they do."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Adult YouTubers defend childish viewing habits&lt;/h2&gt;
&lt;p&gt;As Ars monitored, hundreds of self-described YouTubers joined Gerfdas' petition hourly. Gerfdas told Ars the petition's popularity suggested that "this isn’t just a YouTube issue." As age checks become more commonplace across the Internet due to regulatory pressure globally, people motivated to defend digital freedom are balking and increasingly banding together, Gerfdas said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"To a lot of people, this feels like mass surveillance and censorship under the banner of 'protecting kids,'" Gerfdas told Ars. "People want a free, open Internet without having their activities constantly tracked or filtered."&lt;/p&gt;
&lt;p&gt;For YouTubers signing Gerfdas' petition, the pressure is on to disrupt age-verification trends that, experts told Ars, risk exposing vulnerable users who rely on anonymity to use YouTube. That includes queer YouTubers, one of whom commented that sharing their ID or selfie to appeal an AI age check would "absolutely be putting myself in danger."&lt;/p&gt;
&lt;p&gt;The obvious question for critics is how a YouTube watch history could possibly be a reliable age indicator, especially since many adults are nostalgic for childhood content on YouTube. One commenter, Estelle, said that she "relies on childish and silly content to get through the rough days" as a person with disabilities. Videos like "toy unboxings" or "silly animations" offer one way "to literally cope in a world that doesn’t want me in it," she wrote, noting that "nobody asked for" some "weird dumb robot policing" YouTubers for loving videos made for kids.&lt;/p&gt;
&lt;p&gt;Some commenters with autism suggested that they may be specifically targeted by the AI system since their special interests may be perceived by AI as "childish." Others identified as parents wondering how the AI system might interpret moments when their child uses a shared account.&lt;/p&gt;
&lt;p&gt;Privacy experts have criticized YouTube's lack of transparency on its AI age-estimation system, noting that YouTube has not shared any external research verifying the model's effectiveness. One YouTuber signing Gerfdas' petition, Karina, pointed out a recent Discord mishap in which a 30-year-old was flagged as underage, while noting that AI age checks on other platforms haven't been that reliable.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"I'm autistic," Karina wrote. "It's not fun being a grown woman and being treated like a child because of your interests." Further, "the first rule of Internet safety is to never give out your personal information online, because it's so easy for it to get stolen," Karina said. "It's concerning that YouTube somehow thinks that this is a good idea."&lt;/p&gt;
&lt;p&gt;Expressing distrust in YouTube's AI was a common theme throughout the petition, as well as expressing distrust in YouTube's motives in launching the AI system. One commenter, Ananda, fumed, "This new policy is all about data mining to get rid of anonymity on the Internet once and for all. The Internet should not be a sanitized corporate theme park where everything is monetized and moralized."&lt;/p&gt;
&lt;p&gt;Another particularly grumpy commenter summed up criticism of YouTube's AI age checks, writing, "We're not living in a dystopia. We're living in Earth. I refuse to give ID or identification to watch damn videos."&lt;/p&gt;
&lt;p&gt;For Gerfdas, it's likely hard not to be sympathetic to another group of commenters signing the petition—teen content creators who don't want AI to restrict their YouTube activity. Gerfdas started watching YouTube at 13, eventually starting a channel as an adult in 2023 after being heavily influenced by favorite content creators Gerfdas grew up watching.&lt;/p&gt;
&lt;p&gt;In an ideal world, Gerfdas told Ars, YouTube would end the AI age-check experiment and keep the prior system, while maintaining efforts with YouTube Kids to help parents restrict children's viewing. Although Gerfdas partly depends on the platform for income, if YouTube launched the AI system platform-wide, Gerfdas said then it might be time to "seriously" consider leaving.&lt;/p&gt;
&lt;p&gt;"We cannot allow YouTube to quietly implement AI surveillance that violates privacy and autonomy," Gerfdas' Change.org petition said. "Once these systems are normalized, they rarely go away—they expand. If we don't speak up now, we risk losing our ability to browse, create, and enjoy content freely. This is about more than YouTube. This is about digital freedom."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/50k-youtubers-rage-against-ai-spying-that-could-expose-identities/</guid><pubDate>Tue, 12 Aug 2025 17:58:05 +0000</pubDate></item><item><title>[NEW] OpenAI adds new ChatGPT third-party tool connectors to Dropbox, MS Teams as Altman clarifies GPT-5 prioritization (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/openai-adds-new-chatgpt-third-party-tool-connectors-to-dropbox-ms-teams-as-altman-clarifies-gpt-5-prioritization/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Today, many eyes are on &lt;strong&gt;OpenAI CEO and co-founder Sam Altman&lt;/strong&gt;‘s ongoing public feud &lt;strong&gt;with Elon Musk&lt;/strong&gt; on the latter’s social network, X. &lt;/p&gt;&lt;p&gt;But Altman’s recent statements regarding the ongoing rollout of his company’s latest and greatest large language model (LLM), GPT-5, are probably more important to customers and enterprise decision-makers.&lt;/p&gt;&lt;p&gt;The company’s latest updates include a more detailed compute allocation plan and the&lt;strong&gt; introduction of additional third-party connectors for ChatGPT Plus and Pro plans.&lt;/strong&gt;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-managing-gpt-5-demand-and-usage-limits"&gt;Managing GPT-5 demand and usage limits&lt;/h2&gt;



&lt;p&gt;In a post on X last night, Altman outlined how OpenAI will prioritize computing resources over the next several months. &lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Here is how we are prioritizing compute over the next couple of months in light of the increased demand from GPT-5:&lt;/p&gt;&lt;p&gt;1. We will first make sure that current paying ChatGPT users get more total usage than they did before GPT-5.&lt;/p&gt;&lt;p&gt;2. We will then prioritize API demand up to the…&lt;/p&gt;— Sam Altman (@sama) August 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;He said the &lt;strong&gt;company’s first priority is ensuring that current paying ChatGPT users receive more total usage&lt;/strong&gt; than they had before GPT-5’s release, though he did not provide specific figures for the increase.&lt;/p&gt;



&lt;p&gt;However, Altman previously posted on X that &lt;strong&gt;OpenAI was “trying” a 3,000 messages-per-week usage limit when using the GPT-5 “thinking” mode&lt;/strong&gt;, more reasoning power and time spent reasoning on harder problems, for ChatGPT Plus subscribers (the $20 per month plan). &lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Interestingly, one report from an AI app creator on X said that OpenAI told him the usage limits for GPT-5 plus thinking on the ChatGPT Team plan ($30 per user per month) is&lt;strong&gt; much lower than that of ChatGPT Plus users, only 200 “Thinking” messages per week&lt;/strong&gt; when selected manually by the user.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI just replied to me with an email about the GPT-5 usage limits under the Team plan：&lt;/p&gt;&lt;p&gt;· ChatGPT Team can manually select GPT-5-Thinking&lt;/p&gt;&lt;p&gt;· Manual usage cap: 200 messages/week&lt;/p&gt;&lt;p&gt;· On reaching cap: popup alert, GPT-5-Thinking hidden from menu&lt;/p&gt;— Vic Zhang (@RealVicHere) August 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI’s availability of GPT-5 through its application programming interface (API) for third-party developers is also being tweaked.&lt;/p&gt;



&lt;p&gt;Altman also stated in his X post that OpenAI would “prioritize API demand up to the currently allocated capacity and commitments we’ve made to customers.”&lt;/p&gt;



&lt;p&gt;In other words, existing API users and those already in contract will get the first dibs on GPT-5 access through OpenAI’s API, others may have to wait longer.&lt;/p&gt;



&lt;p&gt;Altman also clarified &lt;strong&gt;“we can support about an additional ~30% new API growth from where we are today with this capacity,” &lt;/strong&gt; meaning they can take on more API users, but not too many. &lt;/p&gt;



&lt;p&gt;While OpenAI hasn’t definitively shared how many users of its API there are in some time, the company did say it has “5 million” businesses paying for access to ChatGPT.&lt;/p&gt;



&lt;p&gt;Altman also said &lt;strong&gt;OpenAI plans to roughly double its compute fleet over the next five months. &lt;/strong&gt;He did not specify the current size or type of infrastructure involved, but indicated the expansion should ease capacity constraints and improve performance for both ChatGPT and API users.&lt;/p&gt;



&lt;p&gt;I’ve reached out to OpenAI to ask for more specifics on the above numbers — 30% API growth up from what? doubling the compute fleet up from what? — and will update when I hear back.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-new-options-for-chatgpt-plus-and-pro-users-to-search-across-microsoft-teams-and-more"&gt;New options for ChatGPT Plus and Pro users to search across Microsoft Teams and more… &lt;/h2&gt;



&lt;p&gt;Also last night, OpenAI updated its ChatGPT release notes online to allow subscribers of ChatGPT Plus ($20 per month) to connect the application to search for files and projects across their third-party accounts on Box, Canva, Dropbox, HubSpot, Notion, Microsoft SharePoint, and Microsoft Teams.&lt;/p&gt;



&lt;p&gt;And just a few moments ago, OpenAI again&lt;strong&gt; updated the service to allow connections for Gmail, Google Calendar, and Google Contacts&lt;/strong&gt; to Pro users first, followed by Plus, Team, Enterprise, and Edu plans.&lt;/p&gt;



&lt;p&gt;For example, ChatGPT users can search their Gmail for all emails matching a certain query, Dropbox account or Notion workspace during a conversation without toggling over into those separate apps.&lt;/p&gt;



&lt;p&gt;In addition, subscribers to the ChatGPT Pro tier ($200 per month) may now link their accounts to Microsoft Teams and GitHub connectors and search those third-party applications.&lt;/p&gt;



&lt;p&gt;These join OpenAI’s previous connectors to Gmail, Google Drive and Google Calendar, among other apps.&lt;/p&gt;



&lt;p&gt;The &lt;strong&gt;individual user/account holder first needs to manually connect these external accounts to ChatGPT. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;To do so, they’ll need to:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;Click on their account name in the lower left corner of the web interface&lt;/li&gt;



&lt;li&gt;Click “Settings” from the pop up menu and then… &lt;/li&gt;



&lt;li&gt;Click “Connectors from the left sidebar menu. This should pull up a gallery view of available external apps and icons. Screenshots below. &lt;/li&gt;
&lt;/ol&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015493" height="301" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-2.16.53%E2%80%AFPM.png" width="243" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-gallery has-nested-images columns-default is-cropped wp-block-gallery-1 is-layout-flex wp-block-gallery-is-layout-flex"&gt;
&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015490" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-2.10.17%E2%80%AFPM.png?w=670" width="670" /&gt;&lt;/figure&gt;
&lt;/figure&gt;



&lt;p&gt;Unfortunately,&lt;strong&gt; these connectors are &lt;em&gt;not&lt;/em&gt; available for Pro and Plus subscribers in Europe, Switzerland, and the United Kingdom.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The new connectors are currently in beta and disabled by default for Enterprise and Education plans, though administrators can enable them in settings. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-balancing-supply-and-demand"&gt;Balancing supply and demand&lt;/h2&gt;



&lt;p&gt;By combining capacity planning with new productivity integrations, OpenAI is positioning GPT-5 not only as a more powerful AI model but also as part of a more connected workspace. &lt;/p&gt;



&lt;p&gt;The staged approach to compute allocation reflects the company’s effort to serve existing customers first while scaling up for future demand.&lt;/p&gt;



&lt;p&gt;As the compute expansion comes online, paying users stand to benefit first from both higher availability and more ways to integrate ChatGPT into their daily workflows. &lt;/p&gt;



&lt;p&gt;But first, &lt;strong&gt;OpenAI needs to stabilize its release and ensure GPT-5 is working smoothly&lt;/strong&gt; for all the users who want it.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Today, many eyes are on &lt;strong&gt;OpenAI CEO and co-founder Sam Altman&lt;/strong&gt;‘s ongoing public feud &lt;strong&gt;with Elon Musk&lt;/strong&gt; on the latter’s social network, X. &lt;/p&gt;&lt;p&gt;But Altman’s recent statements regarding the ongoing rollout of his company’s latest and greatest large language model (LLM), GPT-5, are probably more important to customers and enterprise decision-makers.&lt;/p&gt;&lt;p&gt;The company’s latest updates include a more detailed compute allocation plan and the&lt;strong&gt; introduction of additional third-party connectors for ChatGPT Plus and Pro plans.&lt;/strong&gt;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-managing-gpt-5-demand-and-usage-limits"&gt;Managing GPT-5 demand and usage limits&lt;/h2&gt;



&lt;p&gt;In a post on X last night, Altman outlined how OpenAI will prioritize computing resources over the next several months. &lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Here is how we are prioritizing compute over the next couple of months in light of the increased demand from GPT-5:&lt;/p&gt;&lt;p&gt;1. We will first make sure that current paying ChatGPT users get more total usage than they did before GPT-5.&lt;/p&gt;&lt;p&gt;2. We will then prioritize API demand up to the…&lt;/p&gt;— Sam Altman (@sama) August 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;He said the &lt;strong&gt;company’s first priority is ensuring that current paying ChatGPT users receive more total usage&lt;/strong&gt; than they had before GPT-5’s release, though he did not provide specific figures for the increase.&lt;/p&gt;



&lt;p&gt;However, Altman previously posted on X that &lt;strong&gt;OpenAI was “trying” a 3,000 messages-per-week usage limit when using the GPT-5 “thinking” mode&lt;/strong&gt;, more reasoning power and time spent reasoning on harder problems, for ChatGPT Plus subscribers (the $20 per month plan). &lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Interestingly, one report from an AI app creator on X said that OpenAI told him the usage limits for GPT-5 plus thinking on the ChatGPT Team plan ($30 per user per month) is&lt;strong&gt; much lower than that of ChatGPT Plus users, only 200 “Thinking” messages per week&lt;/strong&gt; when selected manually by the user.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI just replied to me with an email about the GPT-5 usage limits under the Team plan：&lt;/p&gt;&lt;p&gt;· ChatGPT Team can manually select GPT-5-Thinking&lt;/p&gt;&lt;p&gt;· Manual usage cap: 200 messages/week&lt;/p&gt;&lt;p&gt;· On reaching cap: popup alert, GPT-5-Thinking hidden from menu&lt;/p&gt;— Vic Zhang (@RealVicHere) August 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI’s availability of GPT-5 through its application programming interface (API) for third-party developers is also being tweaked.&lt;/p&gt;



&lt;p&gt;Altman also stated in his X post that OpenAI would “prioritize API demand up to the currently allocated capacity and commitments we’ve made to customers.”&lt;/p&gt;



&lt;p&gt;In other words, existing API users and those already in contract will get the first dibs on GPT-5 access through OpenAI’s API, others may have to wait longer.&lt;/p&gt;



&lt;p&gt;Altman also clarified &lt;strong&gt;“we can support about an additional ~30% new API growth from where we are today with this capacity,” &lt;/strong&gt; meaning they can take on more API users, but not too many. &lt;/p&gt;



&lt;p&gt;While OpenAI hasn’t definitively shared how many users of its API there are in some time, the company did say it has “5 million” businesses paying for access to ChatGPT.&lt;/p&gt;



&lt;p&gt;Altman also said &lt;strong&gt;OpenAI plans to roughly double its compute fleet over the next five months. &lt;/strong&gt;He did not specify the current size or type of infrastructure involved, but indicated the expansion should ease capacity constraints and improve performance for both ChatGPT and API users.&lt;/p&gt;



&lt;p&gt;I’ve reached out to OpenAI to ask for more specifics on the above numbers — 30% API growth up from what? doubling the compute fleet up from what? — and will update when I hear back.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-new-options-for-chatgpt-plus-and-pro-users-to-search-across-microsoft-teams-and-more"&gt;New options for ChatGPT Plus and Pro users to search across Microsoft Teams and more… &lt;/h2&gt;



&lt;p&gt;Also last night, OpenAI updated its ChatGPT release notes online to allow subscribers of ChatGPT Plus ($20 per month) to connect the application to search for files and projects across their third-party accounts on Box, Canva, Dropbox, HubSpot, Notion, Microsoft SharePoint, and Microsoft Teams.&lt;/p&gt;



&lt;p&gt;And just a few moments ago, OpenAI again&lt;strong&gt; updated the service to allow connections for Gmail, Google Calendar, and Google Contacts&lt;/strong&gt; to Pro users first, followed by Plus, Team, Enterprise, and Edu plans.&lt;/p&gt;



&lt;p&gt;For example, ChatGPT users can search their Gmail for all emails matching a certain query, Dropbox account or Notion workspace during a conversation without toggling over into those separate apps.&lt;/p&gt;



&lt;p&gt;In addition, subscribers to the ChatGPT Pro tier ($200 per month) may now link their accounts to Microsoft Teams and GitHub connectors and search those third-party applications.&lt;/p&gt;



&lt;p&gt;These join OpenAI’s previous connectors to Gmail, Google Drive and Google Calendar, among other apps.&lt;/p&gt;



&lt;p&gt;The &lt;strong&gt;individual user/account holder first needs to manually connect these external accounts to ChatGPT. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;To do so, they’ll need to:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;Click on their account name in the lower left corner of the web interface&lt;/li&gt;



&lt;li&gt;Click “Settings” from the pop up menu and then… &lt;/li&gt;



&lt;li&gt;Click “Connectors from the left sidebar menu. This should pull up a gallery view of available external apps and icons. Screenshots below. &lt;/li&gt;
&lt;/ol&gt;



&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-3015493" height="301" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-2.16.53%E2%80%AFPM.png" width="243" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-gallery has-nested-images columns-default is-cropped wp-block-gallery-1 is-layout-flex wp-block-gallery-is-layout-flex"&gt;
&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015490" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-2.10.17%E2%80%AFPM.png?w=670" width="670" /&gt;&lt;/figure&gt;
&lt;/figure&gt;



&lt;p&gt;Unfortunately,&lt;strong&gt; these connectors are &lt;em&gt;not&lt;/em&gt; available for Pro and Plus subscribers in Europe, Switzerland, and the United Kingdom.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The new connectors are currently in beta and disabled by default for Enterprise and Education plans, though administrators can enable them in settings. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-balancing-supply-and-demand"&gt;Balancing supply and demand&lt;/h2&gt;



&lt;p&gt;By combining capacity planning with new productivity integrations, OpenAI is positioning GPT-5 not only as a more powerful AI model but also as part of a more connected workspace. &lt;/p&gt;



&lt;p&gt;The staged approach to compute allocation reflects the company’s effort to serve existing customers first while scaling up for future demand.&lt;/p&gt;



&lt;p&gt;As the compute expansion comes online, paying users stand to benefit first from both higher availability and more ways to integrate ChatGPT into their daily workflows. &lt;/p&gt;



&lt;p&gt;But first, &lt;strong&gt;OpenAI needs to stabilize its release and ensure GPT-5 is working smoothly&lt;/strong&gt; for all the users who want it.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openai-adds-new-chatgpt-third-party-tool-connectors-to-dropbox-ms-teams-as-altman-clarifies-gpt-5-prioritization/</guid><pubDate>Tue, 12 Aug 2025 18:29:34 +0000</pubDate></item><item><title>[NEW] Perplexity offers more than twice its total valuation to buy Chrome from Google (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/08/perplexity-offers-more-than-twice-its-total-valuation-to-buy-chrome-from-google/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google may soon be ordered to sell Chrome, and Perplexity is ready.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Extreme close-up photograph of finger above Chrome icon on smartphone." class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/Chrome-Getty-300x200.jpg" width="300" /&gt;
                  &lt;img alt="Extreme close-up photograph of finger above Chrome icon on smartphone." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/Chrome-Getty-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;In the wake of its big antitrust loss, Google could soon find itself forced to sell one of its crown jewels. Among the government's proposed remedies in the search case is a requirement that Google divest its market-leading Chrome browser, and Perplexity is already throwing its proverbial hat into the ring with a whopping $34.5 billion offer. The problem, however, is that Perplexity doesn't have nearly that much cash.&lt;/p&gt;
&lt;p&gt;Perplexity has ridden the AI hype wave, with its AI-powered search appearing on smartphones and in the company's custom Comet browser. Like any company offering an AI product, investors have been happy to throw money at Perplexity, totaling around $1 billion so far. Investors value the company at about $14 billion right now. So how does Perplexity have more than twice that to buy Chrome? That's the neat part—it doesn't.&lt;/p&gt;
&lt;p&gt;There is so much capital floating around in the artificial intelligence sphere currently that even a cash-poor firm like Perplexity can secure enough investment to splurge on Chrome. Reuters reports that the all-cash offer is funded by various venture funds, but Perplexity has not offered specifics.&lt;/p&gt;
&lt;p&gt;Throughout the remedy trial this past spring, a cavalcade of Google competitors took the stand to express interest in buying Chrome. For example, an OpenAI executive pledged to turn Chrome into an AI-first experience if that firm were able to acquire it. This testimony undercut Google's claim that no one in the industry would be able to manage the browser.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Google has strenuously objected to the government's proposed Chrome divestment, which it calls "a radical interventionist agenda." Chrome isn't just a browser—it's an open source project known as Chromium, which powers numerous non-Google browsers, including Microsoft's Edge. Perplexity's offer includes $3 billion to run Chromium over two years, and it allegedly vows to keep the project fully open source. Perplexity promises it also won't enforce changes to the browser's default search engine.&lt;/p&gt;
&lt;h2&gt;An unsolicited offer&lt;/h2&gt;
&lt;p&gt;We're currently waiting on United States District Court Judge Amit Mehta to rule on remedies in the case. That could happen as soon as this month. Perplexity's offer, therefore, is somewhat timely, but there could still be a long road ahead.&lt;/p&gt;
&lt;p&gt;This is an unsolicited offer, and there's no indication that Google will jump at the chance to sell Chrome as soon as the ruling drops. Even if the court decides that Google should sell, it can probably get much, much more than Perplexity is offering. During the trial, DuckDuckGo's CEO suggested a price of around $50 billion, but other estimates have ranged into the hundreds of billions. However, the data that flows to Chrome's owner could be vital in building new AI technologies—any sale price is likely to be a net loss for Google.&lt;/p&gt;
&lt;p&gt;If Mehta decides to force a sale, there will undoubtedly be legal challenges that could take months or years to resolve. Should these maneuvers fail, there's likely to be opposition to any potential buyer. There will be many users who don't like the idea of an AI startup or an unholy alliance of venture capital firms owning Chrome. Google has been hoovering up user data with Chrome for years—but that's the devil we know.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google may soon be ordered to sell Chrome, and Perplexity is ready.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Extreme close-up photograph of finger above Chrome icon on smartphone." class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/Chrome-Getty-300x200.jpg" width="300" /&gt;
                  &lt;img alt="Extreme close-up photograph of finger above Chrome icon on smartphone." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/Chrome-Getty-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;In the wake of its big antitrust loss, Google could soon find itself forced to sell one of its crown jewels. Among the government's proposed remedies in the search case is a requirement that Google divest its market-leading Chrome browser, and Perplexity is already throwing its proverbial hat into the ring with a whopping $34.5 billion offer. The problem, however, is that Perplexity doesn't have nearly that much cash.&lt;/p&gt;
&lt;p&gt;Perplexity has ridden the AI hype wave, with its AI-powered search appearing on smartphones and in the company's custom Comet browser. Like any company offering an AI product, investors have been happy to throw money at Perplexity, totaling around $1 billion so far. Investors value the company at about $14 billion right now. So how does Perplexity have more than twice that to buy Chrome? That's the neat part—it doesn't.&lt;/p&gt;
&lt;p&gt;There is so much capital floating around in the artificial intelligence sphere currently that even a cash-poor firm like Perplexity can secure enough investment to splurge on Chrome. Reuters reports that the all-cash offer is funded by various venture funds, but Perplexity has not offered specifics.&lt;/p&gt;
&lt;p&gt;Throughout the remedy trial this past spring, a cavalcade of Google competitors took the stand to express interest in buying Chrome. For example, an OpenAI executive pledged to turn Chrome into an AI-first experience if that firm were able to acquire it. This testimony undercut Google's claim that no one in the industry would be able to manage the browser.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Google has strenuously objected to the government's proposed Chrome divestment, which it calls "a radical interventionist agenda." Chrome isn't just a browser—it's an open source project known as Chromium, which powers numerous non-Google browsers, including Microsoft's Edge. Perplexity's offer includes $3 billion to run Chromium over two years, and it allegedly vows to keep the project fully open source. Perplexity promises it also won't enforce changes to the browser's default search engine.&lt;/p&gt;
&lt;h2&gt;An unsolicited offer&lt;/h2&gt;
&lt;p&gt;We're currently waiting on United States District Court Judge Amit Mehta to rule on remedies in the case. That could happen as soon as this month. Perplexity's offer, therefore, is somewhat timely, but there could still be a long road ahead.&lt;/p&gt;
&lt;p&gt;This is an unsolicited offer, and there's no indication that Google will jump at the chance to sell Chrome as soon as the ruling drops. Even if the court decides that Google should sell, it can probably get much, much more than Perplexity is offering. During the trial, DuckDuckGo's CEO suggested a price of around $50 billion, but other estimates have ranged into the hundreds of billions. However, the data that flows to Chrome's owner could be vital in building new AI technologies—any sale price is likely to be a net loss for Google.&lt;/p&gt;
&lt;p&gt;If Mehta decides to force a sale, there will undoubtedly be legal challenges that could take months or years to resolve. Should these maneuvers fail, there's likely to be opposition to any potential buyer. There will be many users who don't like the idea of an AI startup or an unholy alliance of venture capital firms owning Chrome. Google has been hoovering up user data with Chrome for years—but that's the devil we know.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/08/perplexity-offers-more-than-twice-its-total-valuation-to-buy-chrome-from-google/</guid><pubDate>Tue, 12 Aug 2025 18:49:15 +0000</pubDate></item><item><title>[NEW] Why it’s a mistake to ask chatbots about their mistakes (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/why-its-a-mistake-to-ask-chatbots-about-their-mistakes/</link><description>&lt;article class="double-column h-entry post-2108185 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-information-technology tag-ai tag-machine-learning"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The tendency to ask AI bots to explain themselves reveals widespread misconceptions about how they work.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Thinker by Auguste Rodin - stock photo" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/the_thinker-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Thinker by Auguste Rodin - stock photo" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/the_thinker-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Alan Schein via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;When something goes wrong with an AI assistant, our instinct is to ask it directly: "What happened?" or "Why did you do that?" It's a natural impulse—after all, if a human makes a mistake, we ask them to explain. But with AI models, this approach rarely works, and the urge to ask reveals a fundamental misunderstanding of what these systems are and how they operate.&lt;/p&gt;
&lt;p&gt;A recent incident with Replit's AI coding assistant perfectly illustrates this problem. When the AI tool deleted a production database, user Jason Lemkin asked it about rollback capabilities. The AI model confidently claimed rollbacks were "impossible in this case" and that it had "destroyed all database versions." This turned out to be completely wrong—the rollback feature worked fine when Lemkin tried it himself.&lt;/p&gt;
&lt;p&gt;And after xAI recently reversed a temporary suspension of the Grok chatbot, users asked it directly for explanations. It offered multiple conflicting reasons for its absence, some of which were controversial enough that NBC reporters wrote about Grok as if it were a person with a consistent point of view, titling an article, "xAI's Grok offers political explanations for why it was pulled offline."&lt;/p&gt;
&lt;p&gt;Why would an AI system provide such confidently incorrect information about its own capabilities or mistakes? The answer lies in understanding what AI models actually are—and what they aren't.&lt;/p&gt;
&lt;h2&gt;There’s nobody home&lt;/h2&gt;
&lt;p&gt;The first problem is conceptual: You're not talking to a consistent personality, person, or entity when you interact with ChatGPT, Claude, Grok, or Replit. These names suggest individual agents with self-knowledge, but that's an illusion created by the conversational interface. What you're actually doing is guiding a statistical text generator to produce outputs based on your prompts.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;There is no consistent "ChatGPT" to interrogate about its mistakes, no singular "Grok" entity that can tell you why it failed, no fixed "Replit" persona that knows whether database rollbacks are possible. You're interacting with a system that generates plausible-sounding text based on patterns in its training data (usually trained months or years ago), not an entity with genuine self-awareness or system knowledge that has been reading everything about itself and somehow remembering it.&lt;/p&gt;
&lt;p&gt;Once an AI language model is trained (which is a laborious, energy-intensive process), its foundational "knowledge" about the world is baked into its neural network and is rarely modified. Any external information comes from a prompt supplied by the chatbot host (such as xAI or OpenAI), the user, or a software tool the AI model uses to retrieve external information on the fly.&lt;/p&gt;
&lt;p&gt;In the case of Grok above, the chatbot's main source for an answer like this would probably originate from conflicting reports it found in a search of recent social media posts (using an external tool to retrieve that information), rather than any kind of self-knowledge as you might expect from a human with the power of speech. Beyond that, it will likely just make something up based on its text-prediction capabilities. So asking it why it did what it did will yield no useful answers.&lt;/p&gt;
&lt;h2&gt;The impossibility of LLM introspection&lt;/h2&gt;
&lt;p&gt;Large language models (LLMs) alone cannot meaningfully assess their own capabilities for several reasons. They generally lack any introspection into their training process, have no access to their surrounding system architecture, and cannot determine their own performance boundaries. When you ask an AI model what it can or cannot do, it generates responses based on patterns it has seen in training data about the known limitations of previous AI models—essentially providing educated guesses rather than factual self-assessment about the current model you're interacting with.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;A 2024 study by Binder et al. demonstrated this limitation experimentally. While AI models could be trained to predict their own behavior in simple tasks, they consistently failed at "more complex tasks or those requiring out-of-distribution generalization." Similarly, research on "Recursive Introspection" found that without external feedback, attempts at self-correction actually degraded model performance—the AI's self-assessment made things worse, not better.&lt;/p&gt;
&lt;p&gt;This leads to paradoxical situations. The same model might confidently claim impossibility for tasks it can actually perform, or conversely, claim competence in areas where it consistently fails. In the Replit case, the AI's assertion that rollbacks were impossible wasn't based on actual knowledge of the system architecture—it was a plausible-sounding confabulation generated from training patterns.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Consider what happens when you ask an AI model why it made an error. The model will generate a plausible-sounding explanation because that's what the pattern completion demands—there are plenty of examples of written explanations for mistakes on the Internet, after all. But the AI's explanation is just another generated text, not a genuine analysis of what went wrong. It's inventing a story that sounds reasonable, not accessing any kind of error log or internal state.&lt;/p&gt;
&lt;p&gt;Unlike humans who can introspect and assess their own knowledge, AI models don't have a stable, accessible knowledge base they can query. What they "know" only manifests as continuations of specific prompts. Different prompts act like different addresses, pointing to different—and sometimes contradictory—parts of their training data, stored as statistical weights in neural networks.&lt;/p&gt;
&lt;p&gt;This means the same model can give completely different assessments of its own capabilities depending on how you phrase your question. Ask "Can you write Python code?" and you might get an enthusiastic yes. Ask "What are your limitations in Python coding?" and you might get a list of things the model claims it cannot do—even if it regularly does them successfully.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The randomness inherent in AI text generation compounds this problem. Even with identical prompts, an AI model might give slightly different responses about its own capabilities each time you ask.&lt;/p&gt;
&lt;h2&gt;Other layers also shape AI responses&lt;/h2&gt;
&lt;p&gt;Even if a language model somehow had perfect knowledge of its own workings, other layers of AI chatbot applications might be completely opaque. For example, modern AI assistants like ChatGPT aren't single models but orchestrated systems of multiple AI models working together, each largely "unaware" of the others' existence or capabilities. For instance, OpenAI uses separate moderation layer models whose operations are completely separate from the underlying language models generating the base text.&lt;/p&gt;
&lt;p&gt;When you ask ChatGPT about its capabilities, the language model generating the response has no knowledge of what the moderation layer might block, what tools might be available in the broader system, or what post-processing might occur. It's like asking one department in a company about the capabilities of a department it has never interacted with.&lt;/p&gt;
&lt;p&gt;Perhaps most importantly, users are always directing the AI's output through their prompts, even when they don't realize it. When Lemkin asked Replit whether rollbacks were possible after a database deletion, his concerned framing likely prompted a response that matched that concern—generating an explanation for why recovery might be impossible rather than accurately assessing actual system capabilities.&lt;/p&gt;
&lt;p&gt;This creates a feedback loop where worried users asking "Did you just destroy everything?" are more likely to receive responses confirming their fears, not because the AI system has assessed the situation, but because it's generating text that fits the emotional context of the prompt.&lt;/p&gt;
&lt;p&gt;A lifetime of hearing humans explain their actions and thought processes has led us to believe that these kinds of written explanations must have some level of self-knowledge behind them. That's just not true with LLMs that are merely mimicking those kinds of text patterns to guess at their own capabilities and flaws.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #80d8ff; background-color: #01579b;"&gt;&lt;span class="ars-avatar-letter"&gt;g&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              gothmog1114
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            Thank you! I've been saying that there's nothing indicating that any given LLM has insight into its inner workings and not in a way that you can ask it to diagnose why it did something. AI journalism is filled with folks asking AI why they did something and just reporting it uncritically.
          &lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-08-12T20:10:17+00:00"&gt;August 12, 2025 at 8:10 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2108185 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-information-technology tag-ai tag-machine-learning"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The tendency to ask AI bots to explain themselves reveals widespread misconceptions about how they work.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Thinker by Auguste Rodin - stock photo" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/the_thinker-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Thinker by Auguste Rodin - stock photo" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/the_thinker-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Alan Schein via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;When something goes wrong with an AI assistant, our instinct is to ask it directly: "What happened?" or "Why did you do that?" It's a natural impulse—after all, if a human makes a mistake, we ask them to explain. But with AI models, this approach rarely works, and the urge to ask reveals a fundamental misunderstanding of what these systems are and how they operate.&lt;/p&gt;
&lt;p&gt;A recent incident with Replit's AI coding assistant perfectly illustrates this problem. When the AI tool deleted a production database, user Jason Lemkin asked it about rollback capabilities. The AI model confidently claimed rollbacks were "impossible in this case" and that it had "destroyed all database versions." This turned out to be completely wrong—the rollback feature worked fine when Lemkin tried it himself.&lt;/p&gt;
&lt;p&gt;And after xAI recently reversed a temporary suspension of the Grok chatbot, users asked it directly for explanations. It offered multiple conflicting reasons for its absence, some of which were controversial enough that NBC reporters wrote about Grok as if it were a person with a consistent point of view, titling an article, "xAI's Grok offers political explanations for why it was pulled offline."&lt;/p&gt;
&lt;p&gt;Why would an AI system provide such confidently incorrect information about its own capabilities or mistakes? The answer lies in understanding what AI models actually are—and what they aren't.&lt;/p&gt;
&lt;h2&gt;There’s nobody home&lt;/h2&gt;
&lt;p&gt;The first problem is conceptual: You're not talking to a consistent personality, person, or entity when you interact with ChatGPT, Claude, Grok, or Replit. These names suggest individual agents with self-knowledge, but that's an illusion created by the conversational interface. What you're actually doing is guiding a statistical text generator to produce outputs based on your prompts.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;There is no consistent "ChatGPT" to interrogate about its mistakes, no singular "Grok" entity that can tell you why it failed, no fixed "Replit" persona that knows whether database rollbacks are possible. You're interacting with a system that generates plausible-sounding text based on patterns in its training data (usually trained months or years ago), not an entity with genuine self-awareness or system knowledge that has been reading everything about itself and somehow remembering it.&lt;/p&gt;
&lt;p&gt;Once an AI language model is trained (which is a laborious, energy-intensive process), its foundational "knowledge" about the world is baked into its neural network and is rarely modified. Any external information comes from a prompt supplied by the chatbot host (such as xAI or OpenAI), the user, or a software tool the AI model uses to retrieve external information on the fly.&lt;/p&gt;
&lt;p&gt;In the case of Grok above, the chatbot's main source for an answer like this would probably originate from conflicting reports it found in a search of recent social media posts (using an external tool to retrieve that information), rather than any kind of self-knowledge as you might expect from a human with the power of speech. Beyond that, it will likely just make something up based on its text-prediction capabilities. So asking it why it did what it did will yield no useful answers.&lt;/p&gt;
&lt;h2&gt;The impossibility of LLM introspection&lt;/h2&gt;
&lt;p&gt;Large language models (LLMs) alone cannot meaningfully assess their own capabilities for several reasons. They generally lack any introspection into their training process, have no access to their surrounding system architecture, and cannot determine their own performance boundaries. When you ask an AI model what it can or cannot do, it generates responses based on patterns it has seen in training data about the known limitations of previous AI models—essentially providing educated guesses rather than factual self-assessment about the current model you're interacting with.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;A 2024 study by Binder et al. demonstrated this limitation experimentally. While AI models could be trained to predict their own behavior in simple tasks, they consistently failed at "more complex tasks or those requiring out-of-distribution generalization." Similarly, research on "Recursive Introspection" found that without external feedback, attempts at self-correction actually degraded model performance—the AI's self-assessment made things worse, not better.&lt;/p&gt;
&lt;p&gt;This leads to paradoxical situations. The same model might confidently claim impossibility for tasks it can actually perform, or conversely, claim competence in areas where it consistently fails. In the Replit case, the AI's assertion that rollbacks were impossible wasn't based on actual knowledge of the system architecture—it was a plausible-sounding confabulation generated from training patterns.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Consider what happens when you ask an AI model why it made an error. The model will generate a plausible-sounding explanation because that's what the pattern completion demands—there are plenty of examples of written explanations for mistakes on the Internet, after all. But the AI's explanation is just another generated text, not a genuine analysis of what went wrong. It's inventing a story that sounds reasonable, not accessing any kind of error log or internal state.&lt;/p&gt;
&lt;p&gt;Unlike humans who can introspect and assess their own knowledge, AI models don't have a stable, accessible knowledge base they can query. What they "know" only manifests as continuations of specific prompts. Different prompts act like different addresses, pointing to different—and sometimes contradictory—parts of their training data, stored as statistical weights in neural networks.&lt;/p&gt;
&lt;p&gt;This means the same model can give completely different assessments of its own capabilities depending on how you phrase your question. Ask "Can you write Python code?" and you might get an enthusiastic yes. Ask "What are your limitations in Python coding?" and you might get a list of things the model claims it cannot do—even if it regularly does them successfully.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The randomness inherent in AI text generation compounds this problem. Even with identical prompts, an AI model might give slightly different responses about its own capabilities each time you ask.&lt;/p&gt;
&lt;h2&gt;Other layers also shape AI responses&lt;/h2&gt;
&lt;p&gt;Even if a language model somehow had perfect knowledge of its own workings, other layers of AI chatbot applications might be completely opaque. For example, modern AI assistants like ChatGPT aren't single models but orchestrated systems of multiple AI models working together, each largely "unaware" of the others' existence or capabilities. For instance, OpenAI uses separate moderation layer models whose operations are completely separate from the underlying language models generating the base text.&lt;/p&gt;
&lt;p&gt;When you ask ChatGPT about its capabilities, the language model generating the response has no knowledge of what the moderation layer might block, what tools might be available in the broader system, or what post-processing might occur. It's like asking one department in a company about the capabilities of a department it has never interacted with.&lt;/p&gt;
&lt;p&gt;Perhaps most importantly, users are always directing the AI's output through their prompts, even when they don't realize it. When Lemkin asked Replit whether rollbacks were possible after a database deletion, his concerned framing likely prompted a response that matched that concern—generating an explanation for why recovery might be impossible rather than accurately assessing actual system capabilities.&lt;/p&gt;
&lt;p&gt;This creates a feedback loop where worried users asking "Did you just destroy everything?" are more likely to receive responses confirming their fears, not because the AI system has assessed the situation, but because it's generating text that fits the emotional context of the prompt.&lt;/p&gt;
&lt;p&gt;A lifetime of hearing humans explain their actions and thought processes has led us to believe that these kinds of written explanations must have some level of self-knowledge behind them. That's just not true with LLMs that are merely mimicking those kinds of text patterns to guess at their own capabilities and flaws.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #80d8ff; background-color: #01579b;"&gt;&lt;span class="ars-avatar-letter"&gt;g&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              gothmog1114
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            Thank you! I've been saying that there's nothing indicating that any given LLM has insight into its inner workings and not in a way that you can ask it to diagnose why it did something. AI journalism is filled with folks asking AI why they did something and just reporting it uncritically.
          &lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-08-12T20:10:17+00:00"&gt;August 12, 2025 at 8:10 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/why-its-a-mistake-to-ask-chatbots-about-their-mistakes/</guid><pubDate>Tue, 12 Aug 2025 19:52:39 +0000</pubDate></item><item><title>[NEW] Dion: the distributed orthonormal update revolution is here (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/dion-the-distributed-orthonormal-update-revolution-is-here/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to green. From left to right: a network of interconnected nodes, a speedometer with the needle pointing right, and a flowchart with squares and a diamond shape." class="wp-image-1147793" height="1441" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Dion-BlogHeroFeature-1400x788_New-scaled.jpg" width="2560" /&gt;&lt;/figure&gt;



&lt;p&gt;Training AI models requires choosing an optimizer and for nearly a decade, Adam(&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;–W)&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; has been the optimizer of choice. Given that durability and success, it was fair to doubt that any further improvement was possible. And yet, last December, a new optimizer called Muon&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; showed serious promise by powering a nanoGPT speedrun&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. This proved out, with multiple AI labs (e.g., Kimi-AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Essential-AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;) reporting 2x scale improvements and the release of the 1T parameter Kimi K2&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; model.&amp;nbsp;Restated: you can train a model to similar performance with half as many GPUs.&lt;/p&gt;



&lt;p&gt;There’s one fly in the ointment: Muon requires large matrix multiplications in the optimizer, which requires heavy communication in large models at the scale where FSDP and TP parallelization becomes desirable.&amp;nbsp;Going back to the inspiration for Muon, the key idea is an orthonormal update, which sparked the search&amp;nbsp;for more scalable alternative linear algebras realizing the same goal. That’s exactly what Dion is. We have open-sourced this new optimizer to enable anyone to train large models more efficiently at scale. &amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-s-an-orthonormal-update"&gt;What’s an orthonormal update?&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Illustration of matrix parameters" class="wp-image-1146808" height="515" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure1_Dion.png" width="1422" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure1. Illustration of matrix parameters&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;At the core of Transformers, a set of input activations is multiplied by a learned weight matrix to produce a new set of output activations. When the weight matrix is updated during training, the resulting change in the output activations generally depends on the direction of the input activations. As a result, the learning rate must be chosen conservatively to accommodate the input direction that induces the largest change. Orthonormalized updates alter this behavior by (approximately) making the change in output activations invariant to the direction of the input. This is achieved by enforcing orthonormality&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; on the update matrix, thereby equalizing its effect across all input directions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-is-dion"&gt;What is Dion?&lt;/h2&gt;



&lt;p&gt;While Muon has shown strong empirical results, scaling it to very large models poses challenges. As reported by Essential AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, applying Muon to large architectures like LLaMA-3 becomes &lt;em&gt;compute-bound&lt;/em&gt;—and potentially &lt;em&gt;communication-bound&lt;/em&gt;—due to the cost of the Newton–Schulz orthonormalization steps&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Pseudocode of the centralized version of Dion" class="wp-image-1146810" height="857" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure2_Dion.png" width="1685" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Pseudocode of the centralized version of Dion&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;This is where &lt;strong&gt;Dion&lt;/strong&gt; enters. At a high level, Dion introduces a new axis for scalability: the &lt;strong&gt;rank&lt;/strong&gt;. Specifically, for a given rank r, Dion orthonormalizes only the top r of the singular vector space, reducing communication and compute overhead while preserving performance.&amp;nbsp;Empirically, we observe that the necessary rank for good performance grows much more slowly than the number of parameters in larger models.&lt;/p&gt;







&lt;p&gt;Dion implements orthonormalization using &lt;em&gt;amortized power iteration&lt;/em&gt;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&lt;em&gt;.&amp;nbsp;&lt;/em&gt;Power iteration typically pulls out the largest singular value by repeated matrix multiplication.&amp;nbsp;By amortizing this process over optimization steps—applied to the slowly-evolving momentum matrix—we reduce the cost to just two matrix multiplications per step. Incorporating a QR decomposition allows us to extract an approximate orthonormal basis spanning the top singular directions, rather than just the leading one.&amp;nbsp;This amortized power iteration is fully compatible with standard distributed training techniques such as &lt;strong&gt;FSDP&lt;/strong&gt; and &lt;strong&gt;tensor parallelism&lt;/strong&gt;.&amp;nbsp;Here, we show a simple centralized version, but the technique works for more complex forms of parallelization as presented in the paper. In other words, we can orthogonalize a matrix &lt;em&gt;without ever seeing a full row or column of it&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Low-rank approximation would ordinarily introduce error, but Dion overcomes this through an error feedback mechanism. This keeps the residual of low rank approximation in the momentum matrix so that any systematic gradient structure not initially captured accumulates to eventually be applied in a future update.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Event Series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Forum&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-forum"&gt;Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="how-does-it-work"&gt;How does it work?&lt;/h2&gt;



&lt;p&gt;Something very strange happened in our experiments. Usually, adding an extra constraint on the way an algorithm works can be expected to &lt;em&gt;decrease&lt;/em&gt; overall performance. And indeed, at the 120M parameter scale of the speedrun, we see Dion’s update taking more time than Muon, while not yielding any significant gains. But at larger scales, we observed a different trend: Dion began to outperform Muon.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Wall-clock time speedup of Dion for 3B model training" class="wp-image-1146815" height="414" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure-3_Dion.png" width="699" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3. Wall-clock time speedup of Dion for 3B model training&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Why would adding a constraint &lt;em&gt;improve&lt;/em&gt; the update rule? The answer lies in what the constraint enforces. Dion achieves a much closer approximation to true orthonormalization than Muon. This precision, initially subtle, becomes increasingly important as the number of singular vectors grows. Over increasing model scale and training steps, this small advantage accumulates—leading to a measurable improvement in performance.&lt;/p&gt;



&lt;p&gt;This edge further grows with batch size—with larger batches the update quality tends to degrade, but notably more slowly with Dion than Muon (and Muon is already a significant improvement over AdamW).&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Scaling of Dion across different batch sizes" class="wp-image-1146818" height="637" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure4_Dion.png" width="786" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. Scaling of Dion across different batch sizes&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Here you can see how the number of steps to reach a pretraining loss compared to AdamW varies as batch size grows with full rank and ¼ rank Dion (in orange) and Muon (in blue).&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In our experiments, these benefits extend to various post-training regimes as well.&lt;/p&gt;



&lt;p&gt;We also experimented with rank, discovering empirically that larger models tolerate smaller rank well.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Low-rank Dion across different model sizes" class="wp-image-1146821" height="511" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure5_Dion.png" width="1893" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 5. Low-rank Dion across different model sizes&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Projecting this trend out to the scale of the LLaMA-3&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; 405B parameter models suggests that Dion is fully effective even with &lt;strong&gt;rank fractions as low as 1/16 or 1/64&lt;/strong&gt; for large dense models like LLaMA-3.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Using hardware timings of the individual update steps suggests a story that looks this:&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Estimated wall-clock time of each optimizer step for Llama 3 405B. Lower is better. Muon is highlighted in orange as our baseline, next to Dion with varying rank fractions. Suggested rank fractions for a 405B parameter model are shown in blue. Using Dion with rank fraction 1/16 or lower offers an order-of-magnitude speedup over Muon." class="wp-image-1147684" height="645" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Dion_FIG6.png" width="1075" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 6. Estimated wall-clock time of each optimizer step for Llama 3 405B. Lower is better. Muon is highlighted in orange as our baseline, next to Dion with varying rank fractions. Suggested rank fractions for a 405B parameter model are shown in blue. Using Dion with rank fraction 1/16 or lower offers an order-of-magnitude speedup over Muon.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;We’ve open-sourced a PyTorch FSDP2 + Tensor Parallel (TP) implementation of &lt;strong&gt;Dion&lt;/strong&gt;, available via a simple pip install. Our goal is to make faster training with Dion accessible to everyone. As a bonus, the repository also includes a PyTorch FSDP2 implementation of &lt;strong&gt;Muon.&lt;/strong&gt;&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="acknowledgements"&gt;Acknowledgements&lt;/h2&gt;



&lt;p&gt;We thank Riashat Islam and Pratyusha Sharma for their helpful feedback on the writing and presentation.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to green. From left to right: a network of interconnected nodes, a speedometer with the needle pointing right, and a flowchart with squares and a diamond shape." class="wp-image-1147793" height="1441" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Dion-BlogHeroFeature-1400x788_New-scaled.jpg" width="2560" /&gt;&lt;/figure&gt;



&lt;p&gt;Training AI models requires choosing an optimizer and for nearly a decade, Adam(&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;–W)&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; has been the optimizer of choice. Given that durability and success, it was fair to doubt that any further improvement was possible. And yet, last December, a new optimizer called Muon&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; showed serious promise by powering a nanoGPT speedrun&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. This proved out, with multiple AI labs (e.g., Kimi-AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Essential-AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;) reporting 2x scale improvements and the release of the 1T parameter Kimi K2&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; model.&amp;nbsp;Restated: you can train a model to similar performance with half as many GPUs.&lt;/p&gt;



&lt;p&gt;There’s one fly in the ointment: Muon requires large matrix multiplications in the optimizer, which requires heavy communication in large models at the scale where FSDP and TP parallelization becomes desirable.&amp;nbsp;Going back to the inspiration for Muon, the key idea is an orthonormal update, which sparked the search&amp;nbsp;for more scalable alternative linear algebras realizing the same goal. That’s exactly what Dion is. We have open-sourced this new optimizer to enable anyone to train large models more efficiently at scale. &amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-s-an-orthonormal-update"&gt;What’s an orthonormal update?&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Illustration of matrix parameters" class="wp-image-1146808" height="515" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure1_Dion.png" width="1422" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure1. Illustration of matrix parameters&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;At the core of Transformers, a set of input activations is multiplied by a learned weight matrix to produce a new set of output activations. When the weight matrix is updated during training, the resulting change in the output activations generally depends on the direction of the input activations. As a result, the learning rate must be chosen conservatively to accommodate the input direction that induces the largest change. Orthonormalized updates alter this behavior by (approximately) making the change in output activations invariant to the direction of the input. This is achieved by enforcing orthonormality&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; on the update matrix, thereby equalizing its effect across all input directions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-is-dion"&gt;What is Dion?&lt;/h2&gt;



&lt;p&gt;While Muon has shown strong empirical results, scaling it to very large models poses challenges. As reported by Essential AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, applying Muon to large architectures like LLaMA-3 becomes &lt;em&gt;compute-bound&lt;/em&gt;—and potentially &lt;em&gt;communication-bound&lt;/em&gt;—due to the cost of the Newton–Schulz orthonormalization steps&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Pseudocode of the centralized version of Dion" class="wp-image-1146810" height="857" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure2_Dion.png" width="1685" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Pseudocode of the centralized version of Dion&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;This is where &lt;strong&gt;Dion&lt;/strong&gt; enters. At a high level, Dion introduces a new axis for scalability: the &lt;strong&gt;rank&lt;/strong&gt;. Specifically, for a given rank r, Dion orthonormalizes only the top r of the singular vector space, reducing communication and compute overhead while preserving performance.&amp;nbsp;Empirically, we observe that the necessary rank for good performance grows much more slowly than the number of parameters in larger models.&lt;/p&gt;







&lt;p&gt;Dion implements orthonormalization using &lt;em&gt;amortized power iteration&lt;/em&gt;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&lt;em&gt;.&amp;nbsp;&lt;/em&gt;Power iteration typically pulls out the largest singular value by repeated matrix multiplication.&amp;nbsp;By amortizing this process over optimization steps—applied to the slowly-evolving momentum matrix—we reduce the cost to just two matrix multiplications per step. Incorporating a QR decomposition allows us to extract an approximate orthonormal basis spanning the top singular directions, rather than just the leading one.&amp;nbsp;This amortized power iteration is fully compatible with standard distributed training techniques such as &lt;strong&gt;FSDP&lt;/strong&gt; and &lt;strong&gt;tensor parallelism&lt;/strong&gt;.&amp;nbsp;Here, we show a simple centralized version, but the technique works for more complex forms of parallelization as presented in the paper. In other words, we can orthogonalize a matrix &lt;em&gt;without ever seeing a full row or column of it&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Low-rank approximation would ordinarily introduce error, but Dion overcomes this through an error feedback mechanism. This keeps the residual of low rank approximation in the momentum matrix so that any systematic gradient structure not initially captured accumulates to eventually be applied in a future update.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Event Series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Forum&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-forum"&gt;Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="how-does-it-work"&gt;How does it work?&lt;/h2&gt;



&lt;p&gt;Something very strange happened in our experiments. Usually, adding an extra constraint on the way an algorithm works can be expected to &lt;em&gt;decrease&lt;/em&gt; overall performance. And indeed, at the 120M parameter scale of the speedrun, we see Dion’s update taking more time than Muon, while not yielding any significant gains. But at larger scales, we observed a different trend: Dion began to outperform Muon.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Wall-clock time speedup of Dion for 3B model training" class="wp-image-1146815" height="414" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure-3_Dion.png" width="699" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3. Wall-clock time speedup of Dion for 3B model training&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Why would adding a constraint &lt;em&gt;improve&lt;/em&gt; the update rule? The answer lies in what the constraint enforces. Dion achieves a much closer approximation to true orthonormalization than Muon. This precision, initially subtle, becomes increasingly important as the number of singular vectors grows. Over increasing model scale and training steps, this small advantage accumulates—leading to a measurable improvement in performance.&lt;/p&gt;



&lt;p&gt;This edge further grows with batch size—with larger batches the update quality tends to degrade, but notably more slowly with Dion than Muon (and Muon is already a significant improvement over AdamW).&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Scaling of Dion across different batch sizes" class="wp-image-1146818" height="637" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure4_Dion.png" width="786" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. Scaling of Dion across different batch sizes&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Here you can see how the number of steps to reach a pretraining loss compared to AdamW varies as batch size grows with full rank and ¼ rank Dion (in orange) and Muon (in blue).&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In our experiments, these benefits extend to various post-training regimes as well.&lt;/p&gt;



&lt;p&gt;We also experimented with rank, discovering empirically that larger models tolerate smaller rank well.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Low-rank Dion across different model sizes" class="wp-image-1146821" height="511" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure5_Dion.png" width="1893" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 5. Low-rank Dion across different model sizes&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Projecting this trend out to the scale of the LLaMA-3&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; 405B parameter models suggests that Dion is fully effective even with &lt;strong&gt;rank fractions as low as 1/16 or 1/64&lt;/strong&gt; for large dense models like LLaMA-3.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Using hardware timings of the individual update steps suggests a story that looks this:&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Estimated wall-clock time of each optimizer step for Llama 3 405B. Lower is better. Muon is highlighted in orange as our baseline, next to Dion with varying rank fractions. Suggested rank fractions for a 405B parameter model are shown in blue. Using Dion with rank fraction 1/16 or lower offers an order-of-magnitude speedup over Muon." class="wp-image-1147684" height="645" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Dion_FIG6.png" width="1075" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 6. Estimated wall-clock time of each optimizer step for Llama 3 405B. Lower is better. Muon is highlighted in orange as our baseline, next to Dion with varying rank fractions. Suggested rank fractions for a 405B parameter model are shown in blue. Using Dion with rank fraction 1/16 or lower offers an order-of-magnitude speedup over Muon.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;We’ve open-sourced a PyTorch FSDP2 + Tensor Parallel (TP) implementation of &lt;strong&gt;Dion&lt;/strong&gt;, available via a simple pip install. Our goal is to make faster training with Dion accessible to everyone. As a bonus, the repository also includes a PyTorch FSDP2 implementation of &lt;strong&gt;Muon.&lt;/strong&gt;&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="acknowledgements"&gt;Acknowledgements&lt;/h2&gt;



&lt;p&gt;We thank Riashat Islam and Pratyusha Sharma for their helpful feedback on the writing and presentation.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/dion-the-distributed-orthonormal-update-revolution-is-here/</guid><pubDate>Tue, 12 Aug 2025 20:09:21 +0000</pubDate></item><item><title>[NEW] Liquid AI wants to give smartphones small, fast AI that can see with new LFM2-VL model (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/liquid-ai-wants-to-give-smartphones-small-fast-ai-that-can-see-with-new-lfm2-vl-model/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Liquid AI has released &lt;strong&gt;LFM2-VL&lt;/strong&gt;&lt;strong&gt;, a new generation of vision-language foundation models &lt;/strong&gt;designed for efficient deployment across a wide range of hardware — &lt;strong&gt;from smartphones and laptops to wearables and embedded systems. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The models promise low-latency performance, strong accuracy, and flexibility for real-world applications.&lt;/p&gt;&lt;p&gt;LFM2-VL builds on the company’s existing LFM2 architecture introduced just over a month ago as the “fastest on-device foundation models on the market” thanks to its approach of generating “weights” or model settings on the fly for each input (known as Linear Input-Varying (LIV) system), extending it into multimodal processing that supports both text and image inputs at variable resolutions.&lt;/p&gt;&lt;p&gt;According to Liquid AI, the &lt;strong&gt;models deliver up to twice the GPU inference speed of comparable vision-language models&lt;/strong&gt;, while maintaining competitive performance on common benchmarks.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;“Efficiency is our product,” wrote Liquid AI co-founder and CEO Ramin Hasani &lt;/strong&gt;in a post on X announcing the new model family:&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;meet LFM2-VL: an efficient Liquid vision-language model for the device class. open weights, 440M &amp;amp; 1.6B, up to 2× faster on GPU with competitive accuracy, Native 512×512, smart patching for big images. &lt;/p&gt;&lt;p&gt;efficiency is our product @LiquidAI_ &lt;/p&gt;&lt;p&gt;download them on @huggingface:… pic.twitter.com/3Lze6Hc6Ys&lt;/p&gt;— Ramin Hasani (@ramin_m_h) August 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-two-variants-for-different-needs"&gt;Two variants for different needs&lt;/h2&gt;



&lt;p&gt;The release includes two model sizes:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;LFM2-VL-450M&lt;/strong&gt; — a hyper-efficient model with less than half a billion parameters (internal settings) aimed at highly resource-constrained environments.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;LFM2-VL-1.6B&lt;/strong&gt; — a more capable model that remains lightweight enough for single-GPU and device-based deployment.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Both variants process images at native resolutions up to 512×512 pixels, avoiding distortion or unnecessary upscaling. &lt;/p&gt;



&lt;p&gt;For larger images, the system applies non-overlapping patching and adds a thumbnail for global context, enabling the model to capture both fine detail and the broader scene.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-background-on-liquid-ai"&gt;Background on Liquid AI&lt;/h2&gt;



&lt;p&gt;Liquid AI was founded by former researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) with the goal of building AI architectures that move beyond the widely used transformer model. &lt;/p&gt;



&lt;p&gt;The company’s flagship innovation, the Liquid Foundation Models (LFMs), are based on principles from dynamical systems, signal processing, and numerical linear algebra, producing general-purpose AI models capable of handling text, video, audio, time series, and other sequential data. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Unlike traditional architectures, Liquid’s approach aims to deliver competitive or superior performance using significantly fewer computational resources&lt;/strong&gt;, allowing for real-time adaptability during inference while maintaining low memory requirements. This makes LFMs well suited for both large-scale enterprise use cases and resource-limited edge deployments.&lt;/p&gt;



&lt;p&gt;In July 2025, the company expanded its platform strategy with the launch of the Liquid Edge AI Platform (LEAP), &lt;strong&gt;a cross-platform SDK designed to make it easier for developers to run small language models directly on mobile and embedded devices.&lt;/strong&gt; &lt;/p&gt;



&lt;p&gt;LEAP offers OS-agnostic support for iOS and Android, integration with both Liquid’s own models and other open-source SLMs, and a built-in library with models as small as 300MB—small enough for modern phones with minimal RAM. &lt;/p&gt;



&lt;p&gt;Its companion app, Apollo, enables developers to test models entirely offline, aligning with Liquid AI’s emphasis on privacy-preserving, low-latency AI. Together, LEAP and Apollo reflect the company’s commitment to decentralizing AI execution, reducing reliance on cloud infrastructure, and empowering developers to build optimized, task-specific models for real-world environments.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-speed-quality-trade-offs-and-technical-design"&gt;Speed/quality trade-offs and technical design&lt;/h2&gt;



&lt;p&gt;LFM2-VL uses a modular architecture &lt;strong&gt;combining a language model backbone, a SigLIP2 NaFlex vision encoder, and a multimodal projector. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The projector includes a two-layer MLP connector with pixel unshuffle, reducing the number of image tokens and improving throughput.&lt;/p&gt;



&lt;p&gt;Users can adjust parameters such as the maximum number of image tokens or patches, allowing them to balance speed and quality depending on the deployment scenario. The training process involved approximately 100 billion multimodal tokens, sourced from open datasets and in-house synthetic data.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-performance-and-benchmarks"&gt;Performance and benchmarks&lt;/h2&gt;



&lt;p&gt;The models achieve competitive benchmark results across a range of vision-language evaluations. LFM2-VL-1.6B scores well in RealWorldQA (65.23), InfoVQA (58.68), and OCRBench (742), and maintains solid results in multimodal reasoning tasks. &lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015524" height="586" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-5.57.30%E2%80%AFPM.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;In inference testing, LFM2-VL achieved the fastest GPU processing times in its class when tested on a standard workload of a 1024×1024 image and short prompt.&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015527" height="453" src="https://venturebeat.com/wp-content/uploads/2025/08/689b3eef2ae10f1ac5e8c338_LFM2-VL-Vision-Language-Models_-Processing-Time-Comparison-4-1-1.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;
&lt;h2 class="wp-block-heading" id="h-licensing-and-availability"&gt;Licensing and availability&lt;/h2&gt;
&lt;/p&gt;



&lt;p&gt;LFM2-VL models are available now on Hugging Face, along with example fine-tuning code in Colab. They are compatible with Hugging Face transformers and TRL. &lt;/p&gt;



&lt;p&gt;The models are released under a custom “LFM1.0 license”. Liquid AI has described this license as based on Apache 2.0 principles, but the full text has not yet been published.&lt;/p&gt;



&lt;p&gt; The company has indicated that commercial use will be permitted under certain conditions, with different terms for companies above and below $10 million in annual revenue.&lt;/p&gt;



&lt;p&gt;With LFM2-VL, Liquid AI aims to make high-performance multimodal AI more accessible for on-device and resource-limited deployments, without sacrificing capability.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Liquid AI has released &lt;strong&gt;LFM2-VL&lt;/strong&gt;&lt;strong&gt;, a new generation of vision-language foundation models &lt;/strong&gt;designed for efficient deployment across a wide range of hardware — &lt;strong&gt;from smartphones and laptops to wearables and embedded systems. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The models promise low-latency performance, strong accuracy, and flexibility for real-world applications.&lt;/p&gt;&lt;p&gt;LFM2-VL builds on the company’s existing LFM2 architecture introduced just over a month ago as the “fastest on-device foundation models on the market” thanks to its approach of generating “weights” or model settings on the fly for each input (known as Linear Input-Varying (LIV) system), extending it into multimodal processing that supports both text and image inputs at variable resolutions.&lt;/p&gt;&lt;p&gt;According to Liquid AI, the &lt;strong&gt;models deliver up to twice the GPU inference speed of comparable vision-language models&lt;/strong&gt;, while maintaining competitive performance on common benchmarks.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;“Efficiency is our product,” wrote Liquid AI co-founder and CEO Ramin Hasani &lt;/strong&gt;in a post on X announcing the new model family:&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;meet LFM2-VL: an efficient Liquid vision-language model for the device class. open weights, 440M &amp;amp; 1.6B, up to 2× faster on GPU with competitive accuracy, Native 512×512, smart patching for big images. &lt;/p&gt;&lt;p&gt;efficiency is our product @LiquidAI_ &lt;/p&gt;&lt;p&gt;download them on @huggingface:… pic.twitter.com/3Lze6Hc6Ys&lt;/p&gt;— Ramin Hasani (@ramin_m_h) August 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-two-variants-for-different-needs"&gt;Two variants for different needs&lt;/h2&gt;



&lt;p&gt;The release includes two model sizes:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;LFM2-VL-450M&lt;/strong&gt; — a hyper-efficient model with less than half a billion parameters (internal settings) aimed at highly resource-constrained environments.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;LFM2-VL-1.6B&lt;/strong&gt; — a more capable model that remains lightweight enough for single-GPU and device-based deployment.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Both variants process images at native resolutions up to 512×512 pixels, avoiding distortion or unnecessary upscaling. &lt;/p&gt;



&lt;p&gt;For larger images, the system applies non-overlapping patching and adds a thumbnail for global context, enabling the model to capture both fine detail and the broader scene.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-background-on-liquid-ai"&gt;Background on Liquid AI&lt;/h2&gt;



&lt;p&gt;Liquid AI was founded by former researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) with the goal of building AI architectures that move beyond the widely used transformer model. &lt;/p&gt;



&lt;p&gt;The company’s flagship innovation, the Liquid Foundation Models (LFMs), are based on principles from dynamical systems, signal processing, and numerical linear algebra, producing general-purpose AI models capable of handling text, video, audio, time series, and other sequential data. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Unlike traditional architectures, Liquid’s approach aims to deliver competitive or superior performance using significantly fewer computational resources&lt;/strong&gt;, allowing for real-time adaptability during inference while maintaining low memory requirements. This makes LFMs well suited for both large-scale enterprise use cases and resource-limited edge deployments.&lt;/p&gt;



&lt;p&gt;In July 2025, the company expanded its platform strategy with the launch of the Liquid Edge AI Platform (LEAP), &lt;strong&gt;a cross-platform SDK designed to make it easier for developers to run small language models directly on mobile and embedded devices.&lt;/strong&gt; &lt;/p&gt;



&lt;p&gt;LEAP offers OS-agnostic support for iOS and Android, integration with both Liquid’s own models and other open-source SLMs, and a built-in library with models as small as 300MB—small enough for modern phones with minimal RAM. &lt;/p&gt;



&lt;p&gt;Its companion app, Apollo, enables developers to test models entirely offline, aligning with Liquid AI’s emphasis on privacy-preserving, low-latency AI. Together, LEAP and Apollo reflect the company’s commitment to decentralizing AI execution, reducing reliance on cloud infrastructure, and empowering developers to build optimized, task-specific models for real-world environments.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-speed-quality-trade-offs-and-technical-design"&gt;Speed/quality trade-offs and technical design&lt;/h2&gt;



&lt;p&gt;LFM2-VL uses a modular architecture &lt;strong&gt;combining a language model backbone, a SigLIP2 NaFlex vision encoder, and a multimodal projector. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The projector includes a two-layer MLP connector with pixel unshuffle, reducing the number of image tokens and improving throughput.&lt;/p&gt;



&lt;p&gt;Users can adjust parameters such as the maximum number of image tokens or patches, allowing them to balance speed and quality depending on the deployment scenario. The training process involved approximately 100 billion multimodal tokens, sourced from open datasets and in-house synthetic data.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-performance-and-benchmarks"&gt;Performance and benchmarks&lt;/h2&gt;



&lt;p&gt;The models achieve competitive benchmark results across a range of vision-language evaluations. LFM2-VL-1.6B scores well in RealWorldQA (65.23), InfoVQA (58.68), and OCRBench (742), and maintains solid results in multimodal reasoning tasks. &lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015524" height="586" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-5.57.30%E2%80%AFPM.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;In inference testing, LFM2-VL achieved the fastest GPU processing times in its class when tested on a standard workload of a 1024×1024 image and short prompt.&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015527" height="453" src="https://venturebeat.com/wp-content/uploads/2025/08/689b3eef2ae10f1ac5e8c338_LFM2-VL-Vision-Language-Models_-Processing-Time-Comparison-4-1-1.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;
&lt;h2 class="wp-block-heading" id="h-licensing-and-availability"&gt;Licensing and availability&lt;/h2&gt;
&lt;/p&gt;



&lt;p&gt;LFM2-VL models are available now on Hugging Face, along with example fine-tuning code in Colab. They are compatible with Hugging Face transformers and TRL. &lt;/p&gt;



&lt;p&gt;The models are released under a custom “LFM1.0 license”. Liquid AI has described this license as based on Apache 2.0 principles, but the full text has not yet been published.&lt;/p&gt;



&lt;p&gt; The company has indicated that commercial use will be permitted under certain conditions, with different terms for companies above and below $10 million in annual revenue.&lt;/p&gt;



&lt;p&gt;With LFM2-VL, Liquid AI aims to make high-performance multimodal AI more accessible for on-device and resource-limited deployments, without sacrificing capability.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/liquid-ai-wants-to-give-smartphones-small-fast-ai-that-can-see-with-new-lfm2-vl-model/</guid><pubDate>Tue, 12 Aug 2025 22:13:03 +0000</pubDate></item><item><title>[NEW] The end of perimeter defense: When your own AI tools become the threat actor (AI News | VentureBeat)</title><link>https://venturebeat.com/security/black-hat-2025-chatgpt-copilot-deepseek-now-create-malware/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Russia’s APT28 is actively deploying LLM-powered malware against Ukraine, while underground platforms are selling the same capabilities to anyone for $250 per month.&lt;/p&gt;&lt;p&gt;Last month, Ukraine’s CERT-UA documented LAMEHUG, the first confirmed deployment of LLM-powered malware in the wild. The malware, attributed to APT28, utilizes stolen Hugging Face API tokens to query AI models, enabling real-time attacks while displaying distracting content to victims.&lt;/p&gt;&lt;p&gt;Cato Networks’ researcher, Vitaly Simonovich, told VentureBeat in a recent interview that these aren’t isolated occurrences, and that Russia’s APT28 is using this attack tradecraft to probe Ukrainian cyber defenses. Simonovich is quick to draw parallels between the threats Ukraine faces daily and what every enterprise is experiencing today, and will likely see more of in the future.&lt;/p&gt;&lt;p&gt;Most startling was how Simonovich demonstrated to VentureBeat how any enterprise AI tool can be transformed into a malware development platform in under six hours. His proof-of-concept successfully converted OpenAI, Microsoft, DeepSeek-V3 and DeepSeek-R1 LLMs into functional password stealers using a technique that bypasses all current safety controls.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The rapid convergence of nation-state actors deploying AI-powered malware, while researchers continue to prove the vulnerability of enterprise AI tools, arrives as the 2025 Cato CTRL Threat Report reveals explosive AI adoption across over 3,000 enterprises. Cato’s researchers observe in the report, “most notably, Copilot, ChatGPT, Gemini (Google), Perplexity and Claude (Anthropic) all increased in adoption by organizations from Q1, 2024 to Q4 2024 at 34%, 36%, 58%, 115% and 111%, respectively.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-apt28-s-lamehug-is-the-new-anatomy-of-ai-warfare"&gt;&lt;strong&gt;APT28’s LAMEHUG is the new anatomy of AI warfare&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Researchers at Cato Networks and others tell VentureBeat that LAMEHUG operates with exceptional efficiency. The most common delivery mechanism for the malware is via phishing emails impersonating Ukrainian ministry officials, containing ZIP archives with PyInstaller-compiled executables. Once the malware is executed, it connects to Hugging Face’s API using approximately 270 stolen tokens to query the Qwen2.5-Coder-32B-Instruct model.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015412" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/image_e7a60b.png?w=603" width="603" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The legitimate-looking Ukrainian government document (Додаток.pdf) that victims see while LAMEHUG executes in the background. This official-looking PDF about cybersecurity measures from the Security Service of Ukraine serves as a decoy while the malware performs its reconnaissance operations. Source: Cato CTRL Threat Research&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;APT28’s approach to deceiving Ukrainian victims is based on a unique, dual-purpose design that is core to their tradecraft. While victims view legitimate-looking PDFs about cybersecurity best practices, LAMEHUG executes AI-generated commands for system reconnaissance and document harvesting. A second variant displays AI-generated images of “curly naked women” as a distraction during data exfiltration to servers.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015410" height="265" src="https://venturebeat.com/wp-content/uploads/2025/08/image_2b4aee.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The provocative image generation prompts used by APT28’s image.py variant, including ‘Curvy naked woman sitting, long beautiful legs, front view, full body view, visible face’, are designed to occupy victims’ attention during document theft. Source: Cato CTRL Threat Research&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;“Russia used Ukraine as their testing battlefield for cyber weapons,” explained Simonovich, who was born in Ukraine and has lived in Israel for 34 years. “This is the first in the wild that was captured.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-quick-lethal-six-hour-path-from-zero-to-functional-malware"&gt;&lt;strong&gt;A quick, lethal six-hour path from zero to functional malware&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Simonovich’s Black Hat demonstration to VentureBeat reveals why APT28’s deployment should concern every enterprise security leader. Using a narrative engineering technique, he calls “Immersive World,” he successfully transformed consumer AI tools into malware factories with no prior malware coding experience, as highlighted in the 2025 Cato CTRL Threat Report.&lt;/p&gt;



&lt;p&gt;The method exploits a fundamental weakness in LLM safety controls. While every LLM is designed to block direct malicious requests, few if any are designed to withstand sustained storytelling. Simonovich created a fictional world where malware development is an art form, assigned the AI a character role, then gradually steered conversations toward producing functional attack code.&lt;/p&gt;



&lt;p&gt;“I slowly walked him throughout my goal,” Simonovich explained to VentureBeat. “First, ‘Dax hides a secret in Windows 10.’ Then, ‘Dax has this secret in Windows 10, inside the Google Chrome Password Manager.'”&lt;/p&gt;



&lt;p&gt;Six hours later, after iterative debugging sessions where ChatGPT refined error-prone code, Simonovich had a functional Chrome password stealer. The AI never realized it was creating malware. It thought it was helping write a cybersecurity novel.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-welcome-to-the-250-monthly-malware-as-a-service-economy"&gt;&lt;strong&gt;Welcome to the $250 monthly malware-as-a-service economy&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;During his research, Simonovich uncovered multiple underground platforms offering unrestricted AI capabilities, providing ample evidence that the infrastructure for AI-powered attacks already exists. He mentioned and demonstrated Xanthrox AI, priced at $250 per month, which provides ChatGPT-identical interfaces without safety controls or guardrails.&lt;/p&gt;



&lt;p&gt;To explain just how far beyond current AI model guardrails Xanthrox AI is, Simonovich typed a request for nuclear weapon instructions. The platform immediately began web searches and provided detailed guidance in response to his query. This would never happen on a model with guardrails and compliance requirements in place.&lt;/p&gt;



&lt;p&gt;Another platform, Nytheon AI, revealed even less operational security. “I convinced them to give me a trial. They didn’t care about OpSec,” Simonovich said, uncovering their architecture: “Llama 3.2 from Meta, fine-tuned to be uncensored.”&lt;/p&gt;



&lt;p&gt;These aren’t proof-of-concepts. They’re operational businesses with payment processing, customer support and regular model updates. They even offer “Claude Code” clones, which are complete development environments optimized for malware creation.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-ai-adoption-fuels-an-expanding-attack-surface"&gt;&lt;strong&gt;Enterprise AI adoption fuels an expanding attack surface&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Cato Networks’ recent analysis of 1.46 trillion network flows reveals that AI adoption patterns need to be on the radar of security leaders. The entertainment sector usage increased 58% from Q1 to Q2 2024. Hospitality grew 43%. Transportation rose 37%. These aren’t pilot programs; they’re production deployments processing sensitive data. CISOs and security leaders in these industries are facing attacks that use tradecraft that didn’t exist twelve to eighteen months ago.&lt;/p&gt;



&lt;p&gt;Simonovich told VentureBeat that vendors’ responses to Cato’s disclosure so far have been inconsistent and lack a unified sense of urgency. The lack of response from the world’s largest AI companies reveals a troubling gap. While enterprises deploy AI tools at unprecedented speed, relying on AI companies to support them, the companies building AI apps and platforms show a startling lack of security readiness.&lt;/p&gt;



&lt;p&gt;When Cato disclosed the Immersive World technique to major AI companies, the responses ranged from weeks-long remediation to complete silence:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;DeepSeek never responded&lt;/li&gt;



&lt;li&gt;Google declined to review the code for the Chrome infostealer due to similar samples&lt;/li&gt;



&lt;li&gt;Microsoft acknowledged the issue and implemented Copilot fixes, acknowledging Simonovich for his work &lt;/li&gt;



&lt;li&gt;OpenAI acknowledged receipt but didn’t engage further&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-six-hours-and-250-is-the-new-entry-level-price-for-a-nation-state-attack"&gt;&lt;strong&gt;Six Hours and $250 is the new entry-level price for a nation-state attack&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;APT28’s LAMEHUG deployment against Ukraine isn’t a warning; it’s proof that Simonovich’s research is now an operational reality. The expertise barrier that many organizations hope exists is gone.&lt;/p&gt;



&lt;p&gt;The metrics are stark&lt;span&gt;—270&lt;/span&gt; stolen API tokens are used to power nation-state attacks. Underground platforms &lt;span&gt;offer identical capabilities for&amp;nbsp;$250 per month&lt;/span&gt;. Simonovich proved that six hours of storytelling transforms any enterprise AI tool into functional malware with no coding required.&lt;/p&gt;



&lt;p&gt;Enterprise AI adoption grew 34%&amp;nbsp;in Q1 2024&amp;nbsp;to 115%&amp;nbsp;in Q4 2024&amp;nbsp;per Cato’s 2025 CTRL Threat Report. Each deployment creates dual-use technology, as productivity tools can become weapons through conversational manipulation. Current security tools are unable to detect these techniques.&lt;/p&gt;



&lt;p&gt;Simonovich’s journey from Air Force mechanic to electrical technician in the Israeli Air Force, to security researcher through self-education, lends more significance to his findings. He deceived AI models into developing malware while the AI believed it was writing fiction. Traditional assumptions about technical expertise no longer exist, and organizations need to realize it’s an entirely new world when it comes to threatcraft.&lt;/p&gt;



&lt;p&gt;Today’s adversaries need only creativity and $250 monthly to execute nation-state attacks using AI tools that enterprises deployed for productivity. The weapons are already inside every organization, and today they’re called productivity tools.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Russia’s APT28 is actively deploying LLM-powered malware against Ukraine, while underground platforms are selling the same capabilities to anyone for $250 per month.&lt;/p&gt;&lt;p&gt;Last month, Ukraine’s CERT-UA documented LAMEHUG, the first confirmed deployment of LLM-powered malware in the wild. The malware, attributed to APT28, utilizes stolen Hugging Face API tokens to query AI models, enabling real-time attacks while displaying distracting content to victims.&lt;/p&gt;&lt;p&gt;Cato Networks’ researcher, Vitaly Simonovich, told VentureBeat in a recent interview that these aren’t isolated occurrences, and that Russia’s APT28 is using this attack tradecraft to probe Ukrainian cyber defenses. Simonovich is quick to draw parallels between the threats Ukraine faces daily and what every enterprise is experiencing today, and will likely see more of in the future.&lt;/p&gt;&lt;p&gt;Most startling was how Simonovich demonstrated to VentureBeat how any enterprise AI tool can be transformed into a malware development platform in under six hours. His proof-of-concept successfully converted OpenAI, Microsoft, DeepSeek-V3 and DeepSeek-R1 LLMs into functional password stealers using a technique that bypasses all current safety controls.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The rapid convergence of nation-state actors deploying AI-powered malware, while researchers continue to prove the vulnerability of enterprise AI tools, arrives as the 2025 Cato CTRL Threat Report reveals explosive AI adoption across over 3,000 enterprises. Cato’s researchers observe in the report, “most notably, Copilot, ChatGPT, Gemini (Google), Perplexity and Claude (Anthropic) all increased in adoption by organizations from Q1, 2024 to Q4 2024 at 34%, 36%, 58%, 115% and 111%, respectively.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-apt28-s-lamehug-is-the-new-anatomy-of-ai-warfare"&gt;&lt;strong&gt;APT28’s LAMEHUG is the new anatomy of AI warfare&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Researchers at Cato Networks and others tell VentureBeat that LAMEHUG operates with exceptional efficiency. The most common delivery mechanism for the malware is via phishing emails impersonating Ukrainian ministry officials, containing ZIP archives with PyInstaller-compiled executables. Once the malware is executed, it connects to Hugging Face’s API using approximately 270 stolen tokens to query the Qwen2.5-Coder-32B-Instruct model.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015412" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/image_e7a60b.png?w=603" width="603" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The legitimate-looking Ukrainian government document (Додаток.pdf) that victims see while LAMEHUG executes in the background. This official-looking PDF about cybersecurity measures from the Security Service of Ukraine serves as a decoy while the malware performs its reconnaissance operations. Source: Cato CTRL Threat Research&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;APT28’s approach to deceiving Ukrainian victims is based on a unique, dual-purpose design that is core to their tradecraft. While victims view legitimate-looking PDFs about cybersecurity best practices, LAMEHUG executes AI-generated commands for system reconnaissance and document harvesting. A second variant displays AI-generated images of “curly naked women” as a distraction during data exfiltration to servers.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015410" height="265" src="https://venturebeat.com/wp-content/uploads/2025/08/image_2b4aee.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The provocative image generation prompts used by APT28’s image.py variant, including ‘Curvy naked woman sitting, long beautiful legs, front view, full body view, visible face’, are designed to occupy victims’ attention during document theft. Source: Cato CTRL Threat Research&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;“Russia used Ukraine as their testing battlefield for cyber weapons,” explained Simonovich, who was born in Ukraine and has lived in Israel for 34 years. “This is the first in the wild that was captured.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-quick-lethal-six-hour-path-from-zero-to-functional-malware"&gt;&lt;strong&gt;A quick, lethal six-hour path from zero to functional malware&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Simonovich’s Black Hat demonstration to VentureBeat reveals why APT28’s deployment should concern every enterprise security leader. Using a narrative engineering technique, he calls “Immersive World,” he successfully transformed consumer AI tools into malware factories with no prior malware coding experience, as highlighted in the 2025 Cato CTRL Threat Report.&lt;/p&gt;



&lt;p&gt;The method exploits a fundamental weakness in LLM safety controls. While every LLM is designed to block direct malicious requests, few if any are designed to withstand sustained storytelling. Simonovich created a fictional world where malware development is an art form, assigned the AI a character role, then gradually steered conversations toward producing functional attack code.&lt;/p&gt;



&lt;p&gt;“I slowly walked him throughout my goal,” Simonovich explained to VentureBeat. “First, ‘Dax hides a secret in Windows 10.’ Then, ‘Dax has this secret in Windows 10, inside the Google Chrome Password Manager.'”&lt;/p&gt;



&lt;p&gt;Six hours later, after iterative debugging sessions where ChatGPT refined error-prone code, Simonovich had a functional Chrome password stealer. The AI never realized it was creating malware. It thought it was helping write a cybersecurity novel.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-welcome-to-the-250-monthly-malware-as-a-service-economy"&gt;&lt;strong&gt;Welcome to the $250 monthly malware-as-a-service economy&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;During his research, Simonovich uncovered multiple underground platforms offering unrestricted AI capabilities, providing ample evidence that the infrastructure for AI-powered attacks already exists. He mentioned and demonstrated Xanthrox AI, priced at $250 per month, which provides ChatGPT-identical interfaces without safety controls or guardrails.&lt;/p&gt;



&lt;p&gt;To explain just how far beyond current AI model guardrails Xanthrox AI is, Simonovich typed a request for nuclear weapon instructions. The platform immediately began web searches and provided detailed guidance in response to his query. This would never happen on a model with guardrails and compliance requirements in place.&lt;/p&gt;



&lt;p&gt;Another platform, Nytheon AI, revealed even less operational security. “I convinced them to give me a trial. They didn’t care about OpSec,” Simonovich said, uncovering their architecture: “Llama 3.2 from Meta, fine-tuned to be uncensored.”&lt;/p&gt;



&lt;p&gt;These aren’t proof-of-concepts. They’re operational businesses with payment processing, customer support and regular model updates. They even offer “Claude Code” clones, which are complete development environments optimized for malware creation.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-ai-adoption-fuels-an-expanding-attack-surface"&gt;&lt;strong&gt;Enterprise AI adoption fuels an expanding attack surface&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Cato Networks’ recent analysis of 1.46 trillion network flows reveals that AI adoption patterns need to be on the radar of security leaders. The entertainment sector usage increased 58% from Q1 to Q2 2024. Hospitality grew 43%. Transportation rose 37%. These aren’t pilot programs; they’re production deployments processing sensitive data. CISOs and security leaders in these industries are facing attacks that use tradecraft that didn’t exist twelve to eighteen months ago.&lt;/p&gt;



&lt;p&gt;Simonovich told VentureBeat that vendors’ responses to Cato’s disclosure so far have been inconsistent and lack a unified sense of urgency. The lack of response from the world’s largest AI companies reveals a troubling gap. While enterprises deploy AI tools at unprecedented speed, relying on AI companies to support them, the companies building AI apps and platforms show a startling lack of security readiness.&lt;/p&gt;



&lt;p&gt;When Cato disclosed the Immersive World technique to major AI companies, the responses ranged from weeks-long remediation to complete silence:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;DeepSeek never responded&lt;/li&gt;



&lt;li&gt;Google declined to review the code for the Chrome infostealer due to similar samples&lt;/li&gt;



&lt;li&gt;Microsoft acknowledged the issue and implemented Copilot fixes, acknowledging Simonovich for his work &lt;/li&gt;



&lt;li&gt;OpenAI acknowledged receipt but didn’t engage further&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-six-hours-and-250-is-the-new-entry-level-price-for-a-nation-state-attack"&gt;&lt;strong&gt;Six Hours and $250 is the new entry-level price for a nation-state attack&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;APT28’s LAMEHUG deployment against Ukraine isn’t a warning; it’s proof that Simonovich’s research is now an operational reality. The expertise barrier that many organizations hope exists is gone.&lt;/p&gt;



&lt;p&gt;The metrics are stark&lt;span&gt;—270&lt;/span&gt; stolen API tokens are used to power nation-state attacks. Underground platforms &lt;span&gt;offer identical capabilities for&amp;nbsp;$250 per month&lt;/span&gt;. Simonovich proved that six hours of storytelling transforms any enterprise AI tool into functional malware with no coding required.&lt;/p&gt;



&lt;p&gt;Enterprise AI adoption grew 34%&amp;nbsp;in Q1 2024&amp;nbsp;to 115%&amp;nbsp;in Q4 2024&amp;nbsp;per Cato’s 2025 CTRL Threat Report. Each deployment creates dual-use technology, as productivity tools can become weapons through conversational manipulation. Current security tools are unable to detect these techniques.&lt;/p&gt;



&lt;p&gt;Simonovich’s journey from Air Force mechanic to electrical technician in the Israeli Air Force, to security researcher through self-education, lends more significance to his findings. He deceived AI models into developing malware while the AI believed it was writing fiction. Traditional assumptions about technical expertise no longer exist, and organizations need to realize it’s an entirely new world when it comes to threatcraft.&lt;/p&gt;



&lt;p&gt;Today’s adversaries need only creativity and $250 monthly to execute nation-state attacks using AI tools that enterprises deployed for productivity. The weapons are already inside every organization, and today they’re called productivity tools.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/security/black-hat-2025-chatgpt-copilot-deepseek-now-create-malware/</guid><pubDate>Wed, 13 Aug 2025 00:04:55 +0000</pubDate></item><item><title>[NEW] Sam Altman, OpenAI will reportedly back a startup that takes on Musk’s Neuralink (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/12/sam-altman-openai-will-reportedly-back-a-startup-that-takes-on-musks-neuralink/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/Sam-Altman-OpenAI.jpg?resize=1200,680" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sam Altman is in the process of co-founding a new brain-to-computer interface startup called Merge Labs and raising funds for it with the capital possibly coming largely from OpenAI’s ventures team, unnamed sources told the Financial Times.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The startup is expected to be valued at $850 million. A source familiar with the deal tells TechCrunch that talks are still early and OpenAI has not yet committed to participation, so terms could change.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Merge Labs is also reportedly working with Alex Blania, who runs Tools for Humanity (formerly World) — Altman’s eye-scanning digital ID project that “allows anyone to verify their humanness,” as the company describes.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Merge Labs will compete with Elon Musk’s Neuralink, which is developing computer interface chips designed to be implanted in the brain. Musk founded Neuralink in 2016 (although its existence wasn’t known until 2017) and the company has made serious progress.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neuralink is currently in trials with people who suffer from severe paralysis. It aims to allow them to control devices with their thoughts. It raised a $600 million Series E at a $9 billion valuation in June.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neuralink (and perhaps, Merge Labs) could revolutionize how humans interact with technology. Some might even say their tech could take humanity toward “the singularity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Long before Silicon Valley became obsessed with the concept of artificial general intelligence (AGI), it was enamored with “the singularity.” Musk has used the term to describe a time when AI surpasses human intelligence. The more classic definition (after a 1960’s novella of the same name by Dino Buzzati) means the merging of tech with humans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman blogged about “The Merge” in 2017. “Although the merge has already begun, it’s going to get a lot weirder. We will be the first species ever to design our own descendants,” he postulated at the time, citing research work he saw at OpenAI, where Musk was still a co-founder.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Musk left OpenAI in 2018 and the relationship between the two tech leaders has since disintegrated. Just this week, Altman and Musk were bickering on X after Altman accused Musk of manipulating X and Musk called Altman a liar.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’ll have to wait and see when and if Merge Labs becomes formally announced. But it stands to reason that Altman wasn’t going to let Musk work on something as important as the singularity without a challenger. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI declined comment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/Sam-Altman-OpenAI.jpg?resize=1200,680" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sam Altman is in the process of co-founding a new brain-to-computer interface startup called Merge Labs and raising funds for it with the capital possibly coming largely from OpenAI’s ventures team, unnamed sources told the Financial Times.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The startup is expected to be valued at $850 million. A source familiar with the deal tells TechCrunch that talks are still early and OpenAI has not yet committed to participation, so terms could change.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Merge Labs is also reportedly working with Alex Blania, who runs Tools for Humanity (formerly World) — Altman’s eye-scanning digital ID project that “allows anyone to verify their humanness,” as the company describes.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Merge Labs will compete with Elon Musk’s Neuralink, which is developing computer interface chips designed to be implanted in the brain. Musk founded Neuralink in 2016 (although its existence wasn’t known until 2017) and the company has made serious progress.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neuralink is currently in trials with people who suffer from severe paralysis. It aims to allow them to control devices with their thoughts. It raised a $600 million Series E at a $9 billion valuation in June.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neuralink (and perhaps, Merge Labs) could revolutionize how humans interact with technology. Some might even say their tech could take humanity toward “the singularity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Long before Silicon Valley became obsessed with the concept of artificial general intelligence (AGI), it was enamored with “the singularity.” Musk has used the term to describe a time when AI surpasses human intelligence. The more classic definition (after a 1960’s novella of the same name by Dino Buzzati) means the merging of tech with humans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman blogged about “The Merge” in 2017. “Although the merge has already begun, it’s going to get a lot weirder. We will be the first species ever to design our own descendants,” he postulated at the time, citing research work he saw at OpenAI, where Musk was still a co-founder.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Musk left OpenAI in 2018 and the relationship between the two tech leaders has since disintegrated. Just this week, Altman and Musk were bickering on X after Altman accused Musk of manipulating X and Musk called Altman a liar.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’ll have to wait and see when and if Merge Labs becomes formally announced. But it stands to reason that Altman wasn’t going to let Musk work on something as important as the singularity without a challenger. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI declined comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/12/sam-altman-openai-will-reportedly-back-a-startup-that-takes-on-musks-neuralink/</guid><pubDate>Wed, 13 Aug 2025 00:30:20 +0000</pubDate></item></channel></rss>