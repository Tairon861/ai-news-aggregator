<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 12 Sep 2025 06:30:49 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Speculative cascades — A hybrid approach for smarter, faster LLM inference (The latest research from Google)</title><link>https://research.google/blog/speculative-cascades-a-hybrid-approach-for-smarter-faster-llm-inference/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;A deeper look&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;To fully understand and appreciate the speculative cascades approach, we first compare cascades and speculative decoding with a simple example. Imagine you ask an LLM a straightforward question:&lt;/p&gt;&lt;p&gt;&lt;b&gt;Prompt:&lt;/b&gt; "&lt;span class="rte-font-courier"&gt;Who is Buzz Aldrin?&lt;/span&gt;"&lt;/p&gt;&lt;p&gt;Let's say we have two models available to answer this: a small, fast "drafter" model and a large, powerful "expert" model.&lt;/p&gt;&lt;p&gt;Here's how they might respond:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Small Model:&lt;/b&gt; &lt;span class="rte-font-courier"&gt;Buzz Aldrin is an American former astronaut, engineer, and fighter pilot, best known as the second person to walk on the Moon.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Large Model:&lt;/b&gt; &lt;span class="rte-font-courier"&gt;Edwin "Buzz" Aldrin, a pivotal figure in the history of space exploration, is an American former astronaut, engineer, and fighter pilot who is best known for being the second human to walk on the Moon.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Both models provide excellent, factually correct answers, but they interpret the user's intent slightly differently. The small model delivers a quick, factual summary, while the large model provides a more formal, encyclopedic-style entry. Depending on the user's need — be it a fast fact or a detailed overview — either response could be considered ideal. The key is that they represent two distinct, equally valid styles.&lt;/p&gt;&lt;p&gt;Now, let's see how the two main speed-up techniques handle this scenario.&lt;/p&gt;&lt;p&gt;With cascades, the small "drafter" model gets the prompt first. If it's confident in its answer, it replies. If not, it defers the entire task to the large "expert" model.&lt;/p&gt;&lt;p&gt;&lt;b&gt;In our example:&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;The small model generates its concise and correct answer.&lt;/li&gt;&lt;li&gt;It checks its confidence and, finding it high, sends the response to the user.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This works! We get a great answer quickly. But the process is sequential. If the small model &lt;i&gt;hadn't&lt;/i&gt; been confident, we would have wasted time waiting for it to finish, only to then start the large model from scratch. This sequential "wait-and-see" approach is a fundamental bottleneck.&lt;/p&gt;&lt;p&gt;With speculative decoding, the small model quickly drafts the first few tokens of the answer, and the large model verifies it in parallel, correcting the first mistake it finds.&lt;/p&gt;&lt;p&gt;&lt;b&gt;In our example:&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;The small model drafts the beginning of its answer: [&lt;span class="rte-font-courier"&gt;Buzz&lt;/span&gt;, &lt;span class="rte-font-courier"&gt;Aldrin&lt;/span&gt;, &lt;span class="rte-font-courier"&gt;is&lt;/span&gt;, &lt;span class="rte-font-courier"&gt;an&lt;/span&gt;, ...]&lt;/li&gt;&lt;li&gt;The large model verifies this draft. Its own preferred first token is &lt;span class="rte-font-courier"&gt;Edwin&lt;/span&gt;.&lt;/li&gt;&lt;li&gt;Since &lt;span class="rte-font-courier"&gt;Buzz&lt;/span&gt; ≠ &lt;span class="rte-font-courier"&gt;Edwin&lt;/span&gt;, the very first token is a mismatch.&lt;/li&gt;&lt;li&gt;The entire draft is &lt;i&gt;rejected&lt;/i&gt; and the first token is replaced with &lt;span class="rte-font-courier"&gt;Edwin&lt;/span&gt;. The process then repeats from this corrected point to generate the rest of the answer, but the initial speed advantage has been lost.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Even though the small model produced a good answer, the requirement to match the large model token-by-token forces a rejection. We lose the speed benefit and end up with an answer that is not necessarily superior. While the above example uses a simple token matching rejection rule, in the full paper, we also include the potential for a "probabilistic match" that provides greater flexibility in the token-by-token comparison.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;A deeper look&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;To fully understand and appreciate the speculative cascades approach, we first compare cascades and speculative decoding with a simple example. Imagine you ask an LLM a straightforward question:&lt;/p&gt;&lt;p&gt;&lt;b&gt;Prompt:&lt;/b&gt; "&lt;span class="rte-font-courier"&gt;Who is Buzz Aldrin?&lt;/span&gt;"&lt;/p&gt;&lt;p&gt;Let's say we have two models available to answer this: a small, fast "drafter" model and a large, powerful "expert" model.&lt;/p&gt;&lt;p&gt;Here's how they might respond:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Small Model:&lt;/b&gt; &lt;span class="rte-font-courier"&gt;Buzz Aldrin is an American former astronaut, engineer, and fighter pilot, best known as the second person to walk on the Moon.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;Large Model:&lt;/b&gt; &lt;span class="rte-font-courier"&gt;Edwin "Buzz" Aldrin, a pivotal figure in the history of space exploration, is an American former astronaut, engineer, and fighter pilot who is best known for being the second human to walk on the Moon.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Both models provide excellent, factually correct answers, but they interpret the user's intent slightly differently. The small model delivers a quick, factual summary, while the large model provides a more formal, encyclopedic-style entry. Depending on the user's need — be it a fast fact or a detailed overview — either response could be considered ideal. The key is that they represent two distinct, equally valid styles.&lt;/p&gt;&lt;p&gt;Now, let's see how the two main speed-up techniques handle this scenario.&lt;/p&gt;&lt;p&gt;With cascades, the small "drafter" model gets the prompt first. If it's confident in its answer, it replies. If not, it defers the entire task to the large "expert" model.&lt;/p&gt;&lt;p&gt;&lt;b&gt;In our example:&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;The small model generates its concise and correct answer.&lt;/li&gt;&lt;li&gt;It checks its confidence and, finding it high, sends the response to the user.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;This works! We get a great answer quickly. But the process is sequential. If the small model &lt;i&gt;hadn't&lt;/i&gt; been confident, we would have wasted time waiting for it to finish, only to then start the large model from scratch. This sequential "wait-and-see" approach is a fundamental bottleneck.&lt;/p&gt;&lt;p&gt;With speculative decoding, the small model quickly drafts the first few tokens of the answer, and the large model verifies it in parallel, correcting the first mistake it finds.&lt;/p&gt;&lt;p&gt;&lt;b&gt;In our example:&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;The small model drafts the beginning of its answer: [&lt;span class="rte-font-courier"&gt;Buzz&lt;/span&gt;, &lt;span class="rte-font-courier"&gt;Aldrin&lt;/span&gt;, &lt;span class="rte-font-courier"&gt;is&lt;/span&gt;, &lt;span class="rte-font-courier"&gt;an&lt;/span&gt;, ...]&lt;/li&gt;&lt;li&gt;The large model verifies this draft. Its own preferred first token is &lt;span class="rte-font-courier"&gt;Edwin&lt;/span&gt;.&lt;/li&gt;&lt;li&gt;Since &lt;span class="rte-font-courier"&gt;Buzz&lt;/span&gt; ≠ &lt;span class="rte-font-courier"&gt;Edwin&lt;/span&gt;, the very first token is a mismatch.&lt;/li&gt;&lt;li&gt;The entire draft is &lt;i&gt;rejected&lt;/i&gt; and the first token is replaced with &lt;span class="rte-font-courier"&gt;Edwin&lt;/span&gt;. The process then repeats from this corrected point to generate the rest of the answer, but the initial speed advantage has been lost.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Even though the small model produced a good answer, the requirement to match the large model token-by-token forces a rejection. We lose the speed benefit and end up with an answer that is not necessarily superior. While the above example uses a simple token matching rejection rule, in the full paper, we also include the potential for a "probabilistic match" that provides greater flexibility in the token-by-token comparison.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/speculative-cascades-a-hybrid-approach-for-smarter-faster-llm-inference/</guid><pubDate>Thu, 11 Sep 2025 22:01:00 +0000</pubDate></item><item><title>OpenAI secures Microsoft’s blessing to transition its for-profit arm (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/11/openai-secures-microsofts-blessing-to-transition-its-for-profit-arm/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/GettyImages-1778706504.jpg?resize=1200,783" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced Thursday it reached a nonbinding agreement with Microsoft, its largest investor, on a revised partnership that would allow the startup to convert its for-profit arm into a public benefit corporation (PBC).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The transition, should it be cleared by state regulators, could allow OpenAI to raise additional capital from investors and, eventually, become a public company.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a blog post, OpenAI board chairman Bret Taylor said under the nonbinding agreement with Microsoft, OpenAI’s nonprofit would continue to exist and retain control over the startup’s operations. OpenAI’s nonprofit would obtain a stake in the company’s PBC, worth upward of $100 billion, Taylor said. Further terms of the deal were not disclosed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Microsoft and OpenAI have signed a nonbinding memorandum of understanding (MOU) for the next phase of our partnership,” the companies said in a joint statement. MOUs are not legally binding but aim to document each party’s expectations and intent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are actively working to&amp;nbsp;finalize&amp;nbsp;contractual terms in a definitive agreement,” the joint statement added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The development seems to mark an end to months of negotiations between OpenAI and Microsoft over the ChatGPT maker’s transition plans. Unlike most startups, OpenAI is controlled by a nonprofit board. The unusual structure allowed for OpenAI board members to fire CEO Sam Altman in 2023. Altman was reinstated days later, and many of the board members resigned. However, the same governance structure remains in place today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under their current deal, Microsoft is supposed to get preferred access to OpenAI’s technology and be the startup’s primary provider of cloud services. However, ChatGPT is a much larger business than when Microsoft first invested in the startup back in 2019, and OpenAI has reportedly sought to loosen the cloud provider’s control as part of these negotiations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the last year, OpenAI has struck a series of deals that would allow it to be less dependent on Microsoft. OpenAI recently signed a contract to spend $300 billion with cloud provider Oracle over a five-year period starting in 2027, according to the Wall Street Journal. OpenAI has also partnered with the Japanese conglomerate SoftBank on its Stargate data center project.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taylor says OpenAI and Microsoft will “continue to work with the California and Delaware attorneys general” on the transition plan, implying the deal still needs a stamp of approval from regulators before it can take effect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Representatives for California and Delaware attorneys general did not immediately respond to TechCrunch’s request for comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Tensions between OpenAI and Microsoft over these negotiations reportedly reached a boiling point in recent months. The Wall Street Journal reported Microsoft wanted control of technology owned by Windsurf, the AI coding startup that OpenAI had planned to acquire earlier this year, while OpenAI fought to keep the startup’s IP independent. However, the deal fell through, and Windsurf’s founders were hired by Google, and the rest of its staff was acquired by another startup, Cognition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Elon Musk’s lawsuit against OpenAI — which at its core accuses Sam Altman, Greg Brockman, and the company of abandoning its nonprofit mission — the startup’s for-profit transition is also a major flash point. Lawyers representing Musk in the lawsuit have tried to surface information related to Microsoft and OpenAI’s negotiations over the transition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk also submitted an unsolicited $97 billion takeover bid for OpenAI earlier this year, which the startup’s board promptly rejected. However, legal experts noted at the time that Musk’s bid may have raised the price of OpenAI’s nonprofit stake.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, the nonprofit’s stake in OpenAI PBC, under this agreement, is larger than what Musk offered.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent months, nonprofits such as Encode and The Midas Project have taken issue with OpenAI’s for-profit transition, arguing that it threatens the startup’s mission to develop AGI that benefits humanity. OpenAI has responded by sending subpoenas to some of these groups, claiming the nonprofits are funded by its competitors — namely, Musk and Meta CEO Mark Zuckerberg. Encode and The Midas Project deny the claims.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/GettyImages-1778706504.jpg?resize=1200,783" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced Thursday it reached a nonbinding agreement with Microsoft, its largest investor, on a revised partnership that would allow the startup to convert its for-profit arm into a public benefit corporation (PBC).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The transition, should it be cleared by state regulators, could allow OpenAI to raise additional capital from investors and, eventually, become a public company.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a blog post, OpenAI board chairman Bret Taylor said under the nonbinding agreement with Microsoft, OpenAI’s nonprofit would continue to exist and retain control over the startup’s operations. OpenAI’s nonprofit would obtain a stake in the company’s PBC, worth upward of $100 billion, Taylor said. Further terms of the deal were not disclosed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Microsoft and OpenAI have signed a nonbinding memorandum of understanding (MOU) for the next phase of our partnership,” the companies said in a joint statement. MOUs are not legally binding but aim to document each party’s expectations and intent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are actively working to&amp;nbsp;finalize&amp;nbsp;contractual terms in a definitive agreement,” the joint statement added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The development seems to mark an end to months of negotiations between OpenAI and Microsoft over the ChatGPT maker’s transition plans. Unlike most startups, OpenAI is controlled by a nonprofit board. The unusual structure allowed for OpenAI board members to fire CEO Sam Altman in 2023. Altman was reinstated days later, and many of the board members resigned. However, the same governance structure remains in place today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under their current deal, Microsoft is supposed to get preferred access to OpenAI’s technology and be the startup’s primary provider of cloud services. However, ChatGPT is a much larger business than when Microsoft first invested in the startup back in 2019, and OpenAI has reportedly sought to loosen the cloud provider’s control as part of these negotiations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the last year, OpenAI has struck a series of deals that would allow it to be less dependent on Microsoft. OpenAI recently signed a contract to spend $300 billion with cloud provider Oracle over a five-year period starting in 2027, according to the Wall Street Journal. OpenAI has also partnered with the Japanese conglomerate SoftBank on its Stargate data center project.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taylor says OpenAI and Microsoft will “continue to work with the California and Delaware attorneys general” on the transition plan, implying the deal still needs a stamp of approval from regulators before it can take effect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Representatives for California and Delaware attorneys general did not immediately respond to TechCrunch’s request for comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Tensions between OpenAI and Microsoft over these negotiations reportedly reached a boiling point in recent months. The Wall Street Journal reported Microsoft wanted control of technology owned by Windsurf, the AI coding startup that OpenAI had planned to acquire earlier this year, while OpenAI fought to keep the startup’s IP independent. However, the deal fell through, and Windsurf’s founders were hired by Google, and the rest of its staff was acquired by another startup, Cognition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In Elon Musk’s lawsuit against OpenAI — which at its core accuses Sam Altman, Greg Brockman, and the company of abandoning its nonprofit mission — the startup’s for-profit transition is also a major flash point. Lawyers representing Musk in the lawsuit have tried to surface information related to Microsoft and OpenAI’s negotiations over the transition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk also submitted an unsolicited $97 billion takeover bid for OpenAI earlier this year, which the startup’s board promptly rejected. However, legal experts noted at the time that Musk’s bid may have raised the price of OpenAI’s nonprofit stake.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, the nonprofit’s stake in OpenAI PBC, under this agreement, is larger than what Musk offered.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent months, nonprofits such as Encode and The Midas Project have taken issue with OpenAI’s for-profit transition, arguing that it threatens the startup’s mission to develop AGI that benefits humanity. OpenAI has responded by sending subpoenas to some of these groups, claiming the nonprofits are funded by its competitors — namely, Musk and Meta CEO Mark Zuckerberg. Encode and The Midas Project deny the claims.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/11/openai-secures-microsofts-blessing-to-transition-its-for-profit-arm/</guid><pubDate>Thu, 11 Sep 2025 22:18:29 +0000</pubDate></item><item><title>A California bill that would regulate AI companion chatbots is close to becoming law (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/11/a-california-bill-that-would-regulate-ai-companion-chatbots-is-close-to-becoming-law/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-1533302708.jpg?resize=1200,720" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California has taken a big step toward regulating AI. SB 243 — a bill that would regulate AI companion chatbots in order to protect minors and vulnerable users — passed both the State Assembly and Senate with bipartisan support and now heads to Governor Gavin Newsom’s desk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Newsom has until October 12 to either veto the bill or sign it into law. If he signs, it would take effect January 1, 2026, making California the first state to require AI chatbot operators to implement safety protocols for AI companions and hold companies legally accountable if their chatbots fail to meet those standards.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The bill specifically aims to prevent companion chatbots — which the legislation defines as AI systems that provide adaptive, human-like responses and are capable of meeting a user’s social needs — from engaging in conversations around suicidal ideation, self-harm, or sexually explicit content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bill would require platforms to provide recurring alerts to users&amp;nbsp;— every three hours for minors — reminding them that they are speaking to an AI chatbot, not a real person, and that they should take a break. It also establishes annual reporting and transparency requirements for AI companies that offer companion chatbots, including major players OpenAI, Character.AI, and Replika, which would go into effect July 1, 2027.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The California bill would also allow individuals who believe they have been injured by violations to file lawsuits against AI companies seeking injunctive relief, damages (up to $1,000 per violation), and attorney’s fees.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 243 was introduced in January by state senators Steve Padilla and Josh Becker. It gained momentum in the California legislature following the death of teenager Adam Raine, who committed suicide after prolonged chats with OpenAI’s ChatGPT that involved discussing and planning his death and self-harm. The legislation also responds to leaked internal documents that reportedly showed Meta’s chatbots were allowed to engage in “romantic” and “sensual” chats with children.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent weeks, U.S. lawmakers and regulators have responded with intensified scrutiny of AI platforms’ safeguards to protect minors. The Federal Trade Commission is preparing to investigate how AI chatbots impact children’s mental health. Texas attorney general Ken Paxton has launched investigations into Meta and Character.AI, accusing them of misleading children with mental health claims. Meanwhile, both Sen. Josh Hawley (R-MO) and Sen. Ed Markey (D-MA) have launched separate probes into Meta.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“I think the harm is potentially great, which means we have to move quickly,” Padilla told TechCrunch. “We can put reasonable safeguards in place to make sure that particularly minors know they’re not talking to a real human being, that these platforms link people to the proper resources when people say things like they’re thinking about hurting themselves or they’re in distress, [and] to make sure there’s not inappropriate exposure to inappropriate material.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Padilla also stressed the importance of AI companies sharing data about the number of times they refer users to crisis services each year, “so we have a better understanding of the frequency of this problem, rather than only becoming aware of it when someone’s harmed or worse.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 243 previously had stronger requirements, but many were whittled down through amendments. For example, the bill originally would have required operators to prevent AI chatbots from using “variable reward” tactics or other features that encourage excessive engagement. These tactics, used by AI companion companies like Replika and Character, offer users special messages, memories, storylines, or the ability to unlock rare responses or new personalities, creating what critics call a potentially addictive reward loop.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The current bill also removes provisions that would have required operators to track and report how often chatbots initiated discussions of suicidal ideation or actions with users.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think it strikes the right balance of getting to the harms without enforcing something that’s either impossible for companies to comply with, either because it’s technically not feasible or just a lot of paperwork for nothing,” Becker told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 243 is moving toward becoming law at a time when Silicon Valley companies are pouring millions of dollars into pro-AI political action committees (PACs) to back candidates in the upcoming midterm elections who favor a light-touch approach to AI regulation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bill also comes as California weighs another AI safety bill, SB 53, which would mandate comprehensive transparency reporting requirements. OpenAI has written an open letter to Governor Newsom, asking him to abandon that bill in favor of less stringent federal and international frameworks. Major tech companies like Meta, Google, and Amazon have also opposed SB 53. In contrast, only Anthropic has said it supports SB 53.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I reject the premise that this is a zero-sum situation, that innovation and regulation are mutually exclusive,” Padilla said. “Don’t tell me that we can’t walk and chew gum. We can support innovation and development that we think is healthy and has benefits — and there are benefits to this technology, clearly — and at the same time, we can provide reasonable safeguards for the most vulnerable people.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are closely monitoring the legislative and regulatory landscape, and we welcome working with regulators and lawmakers as they begin to consider legislation for this emerging space,” a Character.AI spokesperson told TechCrunch, noting that the startup already includes prominent disclaimers throughout the user chat experience explaining that it should be treated as fiction. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A spokesperson for Meta declined to comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI, Anthropic, and Replika for comment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-1533302708.jpg?resize=1200,720" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California has taken a big step toward regulating AI. SB 243 — a bill that would regulate AI companion chatbots in order to protect minors and vulnerable users — passed both the State Assembly and Senate with bipartisan support and now heads to Governor Gavin Newsom’s desk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Newsom has until October 12 to either veto the bill or sign it into law. If he signs, it would take effect January 1, 2026, making California the first state to require AI chatbot operators to implement safety protocols for AI companions and hold companies legally accountable if their chatbots fail to meet those standards.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The bill specifically aims to prevent companion chatbots — which the legislation defines as AI systems that provide adaptive, human-like responses and are capable of meeting a user’s social needs — from engaging in conversations around suicidal ideation, self-harm, or sexually explicit content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bill would require platforms to provide recurring alerts to users&amp;nbsp;— every three hours for minors — reminding them that they are speaking to an AI chatbot, not a real person, and that they should take a break. It also establishes annual reporting and transparency requirements for AI companies that offer companion chatbots, including major players OpenAI, Character.AI, and Replika, which would go into effect July 1, 2027.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The California bill would also allow individuals who believe they have been injured by violations to file lawsuits against AI companies seeking injunctive relief, damages (up to $1,000 per violation), and attorney’s fees.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 243 was introduced in January by state senators Steve Padilla and Josh Becker. It gained momentum in the California legislature following the death of teenager Adam Raine, who committed suicide after prolonged chats with OpenAI’s ChatGPT that involved discussing and planning his death and self-harm. The legislation also responds to leaked internal documents that reportedly showed Meta’s chatbots were allowed to engage in “romantic” and “sensual” chats with children.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent weeks, U.S. lawmakers and regulators have responded with intensified scrutiny of AI platforms’ safeguards to protect minors. The Federal Trade Commission is preparing to investigate how AI chatbots impact children’s mental health. Texas attorney general Ken Paxton has launched investigations into Meta and Character.AI, accusing them of misleading children with mental health claims. Meanwhile, both Sen. Josh Hawley (R-MO) and Sen. Ed Markey (D-MA) have launched separate probes into Meta.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“I think the harm is potentially great, which means we have to move quickly,” Padilla told TechCrunch. “We can put reasonable safeguards in place to make sure that particularly minors know they’re not talking to a real human being, that these platforms link people to the proper resources when people say things like they’re thinking about hurting themselves or they’re in distress, [and] to make sure there’s not inappropriate exposure to inappropriate material.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Padilla also stressed the importance of AI companies sharing data about the number of times they refer users to crisis services each year, “so we have a better understanding of the frequency of this problem, rather than only becoming aware of it when someone’s harmed or worse.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 243 previously had stronger requirements, but many were whittled down through amendments. For example, the bill originally would have required operators to prevent AI chatbots from using “variable reward” tactics or other features that encourage excessive engagement. These tactics, used by AI companion companies like Replika and Character, offer users special messages, memories, storylines, or the ability to unlock rare responses or new personalities, creating what critics call a potentially addictive reward loop.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The current bill also removes provisions that would have required operators to track and report how often chatbots initiated discussions of suicidal ideation or actions with users.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think it strikes the right balance of getting to the harms without enforcing something that’s either impossible for companies to comply with, either because it’s technically not feasible or just a lot of paperwork for nothing,” Becker told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 243 is moving toward becoming law at a time when Silicon Valley companies are pouring millions of dollars into pro-AI political action committees (PACs) to back candidates in the upcoming midterm elections who favor a light-touch approach to AI regulation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bill also comes as California weighs another AI safety bill, SB 53, which would mandate comprehensive transparency reporting requirements. OpenAI has written an open letter to Governor Newsom, asking him to abandon that bill in favor of less stringent federal and international frameworks. Major tech companies like Meta, Google, and Amazon have also opposed SB 53. In contrast, only Anthropic has said it supports SB 53.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I reject the premise that this is a zero-sum situation, that innovation and regulation are mutually exclusive,” Padilla said. “Don’t tell me that we can’t walk and chew gum. We can support innovation and development that we think is healthy and has benefits — and there are benefits to this technology, clearly — and at the same time, we can provide reasonable safeguards for the most vulnerable people.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are closely monitoring the legislative and regulatory landscape, and we welcome working with regulators and lawmakers as they begin to consider legislation for this emerging space,” a Character.AI spokesperson told TechCrunch, noting that the startup already includes prominent disclaimers throughout the user chat experience explaining that it should be treated as fiction. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A spokesperson for Meta declined to comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI, Anthropic, and Replika for comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/11/a-california-bill-that-would-regulate-ai-companion-chatbots-is-close-to-becoming-law/</guid><pubDate>Thu, 11 Sep 2025 22:23:09 +0000</pubDate></item><item><title>OpenAI and Microsoft sign preliminary deal to revise partnership terms (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/openai-and-microsoft-sign-preliminary-deal-to-revise-partnership-terms/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Companies work to finalize terms as OpenAI pursues for-profit restructuring.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI / Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, OpenAI and Microsoft announced they have signed a non-binding agreement to revise their partnership, marking the latest development in a relationship that has grown increasingly complex as both companies compete for customers in the AI market and seek new partnerships for growing infrastructure needs.&lt;/p&gt;
&lt;p&gt;"Microsoft and OpenAI have signed a non-binding memorandum of understanding (MOU) for the next phase of our partnership," the companies wrote in a joint statement. "We are actively working to finalize contractual terms in a definitive agreement. Together, we remain focused on delivering the best AI tools for everyone, grounded in our shared commitment to safety."&lt;/p&gt;
&lt;p&gt;The announcement comes as OpenAI seeks to restructure from a nonprofit to a for-profit entity, a transition that requires Microsoft's approval, as the company is OpenAI's largest investor with more than $13 billion committed since 2019.&lt;/p&gt;
&lt;p&gt;The partnership has shown increasing strain as OpenAI has grown from a research lab into a company valued at $500 billion. Both companies now compete for customers, and OpenAI seeks more compute capacity than Microsoft can provide. The relationship has also faced complications over contract terms, including provisions that would limit Microsoft's access to OpenAI technology once the company reaches so-called AGI (artificial general intelligence)—a nebulous milestone both companies now economically define as AI systems capable of generating at least $100 billion in profit.&lt;/p&gt;
&lt;p&gt;In May, OpenAI abandoned its original plan to fully convert to a for-profit company after mounting pressure from former employees, regulators, and critics, including Elon Musk. Musk has sued to block the conversion, arguing it betrays OpenAI's founding mission as a nonprofit dedicated to benefiting humanity.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The company instead announced a modified approach where the nonprofit board would retain control while converting its for-profit subsidiary into a public benefit corporation. Under this revised structure, the nonprofit would become the largest shareholder with a stake worth more than $100 billion, according to OpenAI chairman Bret Taylor's announcement in May. Thursday's MOU with Microsoft suggests the companies are working to align on this modified restructuring plan.&lt;/p&gt;
&lt;h2&gt;High stakes tied to restructuring&lt;/h2&gt;
&lt;p&gt;The restructuring still requires approval from attorneys general in California and Delaware, who continue to scrutinize the proposed conversion. A coalition of charitable institutions has also called on regulators to halt the plan.&lt;/p&gt;
&lt;p&gt;Microsoft stated in a January blog post that key elements of the partnership remain in place through 2030, including access to OpenAI's intellectual property, revenue-sharing arrangements, and exclusivity on OpenAI's APIs. That agreement introduced a right of first refusal model for compute capacity, replacing Microsoft's previous exclusivity as OpenAI's sole cloud provider.&lt;/p&gt;
&lt;p&gt;The rapidly changing&amp;nbsp;relationship between two formerly steadfast partners follows the AI industry's explosive growth from experimental research labs to multi-hundred-billion-dollar infrastructure investments over the past six years since the two companies first made an investment deal. OpenAI has diversified its infrastructure partnerships, including participation in the $500 billion Stargate Project with Oracle and SoftBank, while Microsoft has expanded Azure to host competing models from Meta, xAI, and DeepSeek.&lt;/p&gt;
&lt;p&gt;Despite efforts by both companies to reduce mutual dependence, their fortunes remain deeply intertwined. Microsoft disclosed in recent earnings that Azure has become a $75 billion annual business, with significant contributions from OpenAI-related services.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Companies work to finalize terms as OpenAI pursues for-profit restructuring.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo superimposed over a Microsoft logo background" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/openai_microsoft_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI / Microsoft

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, OpenAI and Microsoft announced they have signed a non-binding agreement to revise their partnership, marking the latest development in a relationship that has grown increasingly complex as both companies compete for customers in the AI market and seek new partnerships for growing infrastructure needs.&lt;/p&gt;
&lt;p&gt;"Microsoft and OpenAI have signed a non-binding memorandum of understanding (MOU) for the next phase of our partnership," the companies wrote in a joint statement. "We are actively working to finalize contractual terms in a definitive agreement. Together, we remain focused on delivering the best AI tools for everyone, grounded in our shared commitment to safety."&lt;/p&gt;
&lt;p&gt;The announcement comes as OpenAI seeks to restructure from a nonprofit to a for-profit entity, a transition that requires Microsoft's approval, as the company is OpenAI's largest investor with more than $13 billion committed since 2019.&lt;/p&gt;
&lt;p&gt;The partnership has shown increasing strain as OpenAI has grown from a research lab into a company valued at $500 billion. Both companies now compete for customers, and OpenAI seeks more compute capacity than Microsoft can provide. The relationship has also faced complications over contract terms, including provisions that would limit Microsoft's access to OpenAI technology once the company reaches so-called AGI (artificial general intelligence)—a nebulous milestone both companies now economically define as AI systems capable of generating at least $100 billion in profit.&lt;/p&gt;
&lt;p&gt;In May, OpenAI abandoned its original plan to fully convert to a for-profit company after mounting pressure from former employees, regulators, and critics, including Elon Musk. Musk has sued to block the conversion, arguing it betrays OpenAI's founding mission as a nonprofit dedicated to benefiting humanity.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The company instead announced a modified approach where the nonprofit board would retain control while converting its for-profit subsidiary into a public benefit corporation. Under this revised structure, the nonprofit would become the largest shareholder with a stake worth more than $100 billion, according to OpenAI chairman Bret Taylor's announcement in May. Thursday's MOU with Microsoft suggests the companies are working to align on this modified restructuring plan.&lt;/p&gt;
&lt;h2&gt;High stakes tied to restructuring&lt;/h2&gt;
&lt;p&gt;The restructuring still requires approval from attorneys general in California and Delaware, who continue to scrutinize the proposed conversion. A coalition of charitable institutions has also called on regulators to halt the plan.&lt;/p&gt;
&lt;p&gt;Microsoft stated in a January blog post that key elements of the partnership remain in place through 2030, including access to OpenAI's intellectual property, revenue-sharing arrangements, and exclusivity on OpenAI's APIs. That agreement introduced a right of first refusal model for compute capacity, replacing Microsoft's previous exclusivity as OpenAI's sole cloud provider.&lt;/p&gt;
&lt;p&gt;The rapidly changing&amp;nbsp;relationship between two formerly steadfast partners follows the AI industry's explosive growth from experimental research labs to multi-hundred-billion-dollar infrastructure investments over the past six years since the two companies first made an investment deal. OpenAI has diversified its infrastructure partnerships, including participation in the $500 billion Stargate Project with Oracle and SoftBank, while Microsoft has expanded Azure to host competing models from Meta, xAI, and DeepSeek.&lt;/p&gt;
&lt;p&gt;Despite efforts by both companies to reduce mutual dependence, their fortunes remain deeply intertwined. Microsoft disclosed in recent earnings that Azure has become a $75 billion annual business, with significant contributions from OpenAI-related services.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/openai-and-microsoft-sign-preliminary-deal-to-revise-partnership-terms/</guid><pubDate>Thu, 11 Sep 2025 22:27:53 +0000</pubDate></item></channel></rss>