<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 10 Feb 2026 02:39:53 +0000</lastBuildDate><item><title>Call for speakers: TechCrunch Founder Summit 2026 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/call-for-speakers-techcrunch-founder-summit-2026/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Have real-world scaling experience? The&amp;nbsp;&lt;strong&gt;TechCrunch Founder Summit 2026&lt;/strong&gt;&amp;nbsp;stage is calling.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On&amp;nbsp;&lt;strong&gt;June 23 in Boston&lt;/strong&gt;, this annual founder-focused event will&amp;nbsp;bring together&amp;nbsp;1,100+ founders and investors to explore the realities of scaling startups across every stage.&amp;nbsp;We’re&amp;nbsp;seeking experienced founders, VCs, and startup operators to lead interactive roundtable discussions rooted in practical, real-world insight.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Experienced leaders from across the startup ecosystem will convene to host&amp;nbsp;interactive roundtable sessions&amp;nbsp;designed to spark real conversations. This is where founders get honest guidance, tactical takeaways, and clarity on the challenges that come with growth.&amp;nbsp;&lt;strong&gt;Apply here to get started.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-apply-to-lead-a-roundtable-session"&gt;Apply to lead a roundtable session&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Roundtables at TC Founder Summit are built for depth, not decks. Each session is a&amp;nbsp;30-minute, informal discussion&amp;nbsp;led by up to two speakers, with no slides or video — just meaningful dialogue and practical insight. These intimate conversations create space for founders to ask real questions and connect directly with experts&amp;nbsp;who’ve&amp;nbsp;been there before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To apply, click&amp;nbsp;&lt;strong&gt;Apply to Speak&lt;/strong&gt;&amp;nbsp;on the&amp;nbsp;&lt;strong&gt;event page&lt;/strong&gt;,&amp;nbsp;submit&amp;nbsp;your proposed topic, and share your experience as a scaling expert.&amp;nbsp;TC&amp;nbsp;Founder Summit is the ideal platform to contribute to the next generation of startup leaders.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 roundtable sessions" class="wp-image-2966337" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/Early-Stage-Roundtable-Sessions-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-speaker-benefits"&gt;Speaker benefits&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking at TC Founder Summit is more than visibility.&amp;nbsp;It’s&amp;nbsp;full access to the experience. Along with elevating your authority and brand,&amp;nbsp;you’ll&amp;nbsp;gain premium entry to breakout sessions, roundtables, and curated networking with founders seeking guidance and VCs scouting&amp;nbsp;what’s&amp;nbsp;next.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, TechCrunch will amplify your participation through:&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Event agenda placement on the web and mobile app.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Inclusion in a shared TechCrunch.com article.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Social media promotion across TechCrunch channels.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-make-your-impact-by-applying-today"&gt;Make your impact by applying today&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Lead the conversation. Share what&amp;nbsp;you’ve&amp;nbsp;learned. Help founders navigate the highs and lows of&amp;nbsp;scaling, and&amp;nbsp;strengthen your reputation as a trusted voice in the startup community.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apply early.&amp;nbsp;TC&amp;nbsp;Founder Summit takes place on June 23, but speaker applications close well before then.&amp;nbsp;&lt;strong&gt;Submit now&lt;/strong&gt;&amp;nbsp;and be part of TechCrunch’s annual founder bootcamp.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Founder Summit breakout audience" class="wp-image-3086922" height="453" src="https://techcrunch.com/wp-content/uploads/2026/01/TC-All-Stage-2025-Breakout-QA.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Have real-world scaling experience? The&amp;nbsp;&lt;strong&gt;TechCrunch Founder Summit 2026&lt;/strong&gt;&amp;nbsp;stage is calling.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On&amp;nbsp;&lt;strong&gt;June 23 in Boston&lt;/strong&gt;, this annual founder-focused event will&amp;nbsp;bring together&amp;nbsp;1,100+ founders and investors to explore the realities of scaling startups across every stage.&amp;nbsp;We’re&amp;nbsp;seeking experienced founders, VCs, and startup operators to lead interactive roundtable discussions rooted in practical, real-world insight.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Experienced leaders from across the startup ecosystem will convene to host&amp;nbsp;interactive roundtable sessions&amp;nbsp;designed to spark real conversations. This is where founders get honest guidance, tactical takeaways, and clarity on the challenges that come with growth.&amp;nbsp;&lt;strong&gt;Apply here to get started.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-apply-to-lead-a-roundtable-session"&gt;Apply to lead a roundtable session&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Roundtables at TC Founder Summit are built for depth, not decks. Each session is a&amp;nbsp;30-minute, informal discussion&amp;nbsp;led by up to two speakers, with no slides or video — just meaningful dialogue and practical insight. These intimate conversations create space for founders to ask real questions and connect directly with experts&amp;nbsp;who’ve&amp;nbsp;been there before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To apply, click&amp;nbsp;&lt;strong&gt;Apply to Speak&lt;/strong&gt;&amp;nbsp;on the&amp;nbsp;&lt;strong&gt;event page&lt;/strong&gt;,&amp;nbsp;submit&amp;nbsp;your proposed topic, and share your experience as a scaling expert.&amp;nbsp;TC&amp;nbsp;Founder Summit is the ideal platform to contribute to the next generation of startup leaders.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 roundtable sessions" class="wp-image-2966337" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/Early-Stage-Roundtable-Sessions-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-speaker-benefits"&gt;Speaker benefits&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking at TC Founder Summit is more than visibility.&amp;nbsp;It’s&amp;nbsp;full access to the experience. Along with elevating your authority and brand,&amp;nbsp;you’ll&amp;nbsp;gain premium entry to breakout sessions, roundtables, and curated networking with founders seeking guidance and VCs scouting&amp;nbsp;what’s&amp;nbsp;next.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, TechCrunch will amplify your participation through:&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Event agenda placement on the web and mobile app.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Inclusion in a shared TechCrunch.com article.&lt;/li&gt;
&lt;/ul&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Social media promotion across TechCrunch channels.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-make-your-impact-by-applying-today"&gt;Make your impact by applying today&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Lead the conversation. Share what&amp;nbsp;you’ve&amp;nbsp;learned. Help founders navigate the highs and lows of&amp;nbsp;scaling, and&amp;nbsp;strengthen your reputation as a trusted voice in the startup community.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apply early.&amp;nbsp;TC&amp;nbsp;Founder Summit takes place on June 23, but speaker applications close well before then.&amp;nbsp;&lt;strong&gt;Submit now&lt;/strong&gt;&amp;nbsp;and be part of TechCrunch’s annual founder bootcamp.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Founder Summit breakout audience" class="wp-image-3086922" height="453" src="https://techcrunch.com/wp-content/uploads/2026/01/TC-All-Stage-2025-Breakout-QA.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/call-for-speakers-techcrunch-founder-summit-2026/</guid><pubDate>Mon, 09 Feb 2026 15:00:00 +0000</pubDate></item><item><title>Ex-Googlers are building infrastructure to help companies understand their video data (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/ex-googlers-are-building-infrastructure-to-help-companies-understand-their-video-data/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Businesses are generating more video than ever. From years of broadcast archives to thousands of store cameras and countless hours of production footage, most of it just sits unused on servers, unwatched and unanalyzed. This is dark data: a massive, untapped resource that companies collect automatically but almost never use in a meaningful way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To tackle the problem, Aza Kai (CEO) and Hiraku Yanagita (COO), two former Googlers who spent nearly a decade working together at Google Japan, decided to build their own solution. The duo co-founded InfiniMind, a Tokyo-based startup developing infrastructure that converts petabytes of unviewed video and audio into structured, queryable business data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“My co-founder, who spent a decade leading brand and data solutions at Google Japan, and I saw this inflection point coming while we were still at Google,” Kai said. By 2024, the technology had matured, and the market demand had become clear enough that the co-founders felt compelled to build the company themselves, he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kai, who previously worked at Google Japan across cloud, machine learning, ad systems, and video recommendation models and later led data science teams, explained that current solutions force a trade-off. Earlier approaches could label objects in individual frames, but they couldn’t track narratives, understand causality, or answer complex questions about video content. For clients with decades of broadcast archives and petabytes of footage, even basic questions about their content often went unanswered.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What really changed was the progress in vision-language models between 2021 and 2023. That’s when video AI started moving beyond simple object tagging, Kai noted. Falling GPU costs and annual performance gains of roughly 15% to 20% over the last decade helped, but the bigger story was capability — until recently, models just couldn’t do the job, he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;InfiniMind recently secured $5.8 million in seed funding, led by UTEC and joined by CX2, Headline Asia, Chiba Dojo, and an AI researcher at a16z Scout. The company is relocating its headquarters to the U.S., while it continues to operate an office in Japan. Japan provided the perfect testbed: strong hardware, talented engineers, and a supportive startup ecosystem,&lt;strong&gt; &lt;/strong&gt;allowing the team to fine-tune its technology with demanding customers before going global.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its first product, TV Pulse, launched in Japan in April 2025. The AI-powered platform analyzes television content in real time, helping media and retail companies “track product exposure, brand presence, customer sentiment, and PR impact,” per the startup. After pilot programs with major broadcasters and agencies, it already has paying customers, including wholesalers and media companies.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Now, InfiniMind is ready for the international market. Its flagship product, DeepFrame, a long-form video intelligence platform capable of processing 200 hours of footage to pinpoint specific scenes, speakers, or events, is scheduled for a beta release in March, followed by a full launch in April 2026, Kai said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3090794" height="453" src="https://techcrunch.com/wp-content/uploads/2026/02/InfiniMind-team-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;infinimind&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The video analysis space is highly fragmented. Companies such as TwelveLabs provide general-purpose video understanding APIs for a broad range of users, including consumers, prosumers, and enterprises, Kai said, while&amp;nbsp;InfiniMind focuses specifically on enterprise use cases, including monitoring, safety, security, and analyzing video content for deeper insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our solution requires no code; clients bring their data, and our system processes it, providing actionable insights,” Kai said. “We also integrate audio, sound, and speech understanding, not just visuals. Our system can handle unlimited video length, and cost efficiency is a major differentiator. Most existing solutions prioritize accuracy or specific use cases but don’t solve cost challenges.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The seed funding will help the team continue developing the DeepFrame model, expand engineering infrastructure, hire more engineers, and reach additional customers across Japan and the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is an exciting space, one of the paths toward AGI,” Kai said. “Understanding general video intelligence is about understanding reality. Industrial applications are important, but our ultimate goal is to push the boundaries of technology to better understand reality and help humans make better decisions.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Businesses are generating more video than ever. From years of broadcast archives to thousands of store cameras and countless hours of production footage, most of it just sits unused on servers, unwatched and unanalyzed. This is dark data: a massive, untapped resource that companies collect automatically but almost never use in a meaningful way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To tackle the problem, Aza Kai (CEO) and Hiraku Yanagita (COO), two former Googlers who spent nearly a decade working together at Google Japan, decided to build their own solution. The duo co-founded InfiniMind, a Tokyo-based startup developing infrastructure that converts petabytes of unviewed video and audio into structured, queryable business data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“My co-founder, who spent a decade leading brand and data solutions at Google Japan, and I saw this inflection point coming while we were still at Google,” Kai said. By 2024, the technology had matured, and the market demand had become clear enough that the co-founders felt compelled to build the company themselves, he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kai, who previously worked at Google Japan across cloud, machine learning, ad systems, and video recommendation models and later led data science teams, explained that current solutions force a trade-off. Earlier approaches could label objects in individual frames, but they couldn’t track narratives, understand causality, or answer complex questions about video content. For clients with decades of broadcast archives and petabytes of footage, even basic questions about their content often went unanswered.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What really changed was the progress in vision-language models between 2021 and 2023. That’s when video AI started moving beyond simple object tagging, Kai noted. Falling GPU costs and annual performance gains of roughly 15% to 20% over the last decade helped, but the bigger story was capability — until recently, models just couldn’t do the job, he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;InfiniMind recently secured $5.8 million in seed funding, led by UTEC and joined by CX2, Headline Asia, Chiba Dojo, and an AI researcher at a16z Scout. The company is relocating its headquarters to the U.S., while it continues to operate an office in Japan. Japan provided the perfect testbed: strong hardware, talented engineers, and a supportive startup ecosystem,&lt;strong&gt; &lt;/strong&gt;allowing the team to fine-tune its technology with demanding customers before going global.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its first product, TV Pulse, launched in Japan in April 2025. The AI-powered platform analyzes television content in real time, helping media and retail companies “track product exposure, brand presence, customer sentiment, and PR impact,” per the startup. After pilot programs with major broadcasters and agencies, it already has paying customers, including wholesalers and media companies.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Now, InfiniMind is ready for the international market. Its flagship product, DeepFrame, a long-form video intelligence platform capable of processing 200 hours of footage to pinpoint specific scenes, speakers, or events, is scheduled for a beta release in March, followed by a full launch in April 2026, Kai said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3090794" height="453" src="https://techcrunch.com/wp-content/uploads/2026/02/InfiniMind-team-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;infinimind&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The video analysis space is highly fragmented. Companies such as TwelveLabs provide general-purpose video understanding APIs for a broad range of users, including consumers, prosumers, and enterprises, Kai said, while&amp;nbsp;InfiniMind focuses specifically on enterprise use cases, including monitoring, safety, security, and analyzing video content for deeper insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our solution requires no code; clients bring their data, and our system processes it, providing actionable insights,” Kai said. “We also integrate audio, sound, and speech understanding, not just visuals. Our system can handle unlimited video length, and cost efficiency is a major differentiator. Most existing solutions prioritize accuracy or specific use cases but don’t solve cost challenges.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The seed funding will help the team continue developing the DeepFrame model, expand engineering infrastructure, hire more engineers, and reach additional customers across Japan and the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is an exciting space, one of the paths toward AGI,” Kai said. “Understanding general video intelligence is about understanding reality. Industrial applications are important, but our ultimate goal is to push the boundaries of technology to better understand reality and help humans make better decisions.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/ex-googlers-are-building-infrastructure-to-help-companies-understand-their-video-data/</guid><pubDate>Mon, 09 Feb 2026 17:00:00 +0000</pubDate></item><item><title>Why the Moltbook frenzy was like Pokémon (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/moltbook-head3.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse into the future. It appeared to show AI systems doing useful things for the humans that created them (one person used the platform to help him negotiate a deal on a new car). Sure, it was flooded with crypto scams, and many of the posts were actually written by people, but &lt;em&gt;something&lt;/em&gt; about it pointed to a future of helpful AI, right?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;The whole experiment reminded our senior editor for AI, Will Douglas Heaven, of something far less interesting: Pokémon.&lt;/p&gt;  &lt;p&gt;Back in 2014, someone set up a game of Pokémon in which the main character could be controlled by anyone on the internet via the streaming platform Twitch. Playing was as clunky as it sounds, but it was incredibly popular: at one point, a million people were playing the game at the same time.&lt;/p&gt; 
 &lt;p&gt;“It was yet another weird online social experiment that got picked up by the mainstream media: What did this mean for the future?” Will says. “Not a lot, it turned out.”&lt;/p&gt;  &lt;p&gt;The frenzy about Moltbook struck a similar tone to Will, and it turned out that one of the sources he spoke to had been thinking about Pokémon too. Jason Schloetzer, at the Georgetown Psaros Center for Financial Markets and Policy, saw the whole thing as a sort of Pokémon battle for AI enthusiasts, in which they created AI agents and deployed them to interact with other agents. In this light, the news that many AI agents were actually being instructed by people to say certain things that made them sound sentient or intelligent makes a whole lot more sense.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“It’s basically a spectator sport,” he told Will, “but for language models.”&lt;/p&gt;  &lt;p&gt;Will wrote an excellent piece about why Moltbook was not the glimpse into the future that it was said to be. Even if you are excited about a future of agentic AI, he points out, there are some key pieces that Moltbook made clear are still missing. It was a forum of chaos, but a genuinely helpful hive mind would require more coordination, shared objectives, and shared memory.&lt;/p&gt;  &lt;p&gt;“More than anything else, I think Moltbook was the internet having fun,” Will says. “The biggest question that now leaves me with is: How far will people push AI just for the laughs?”&lt;/p&gt;  &lt;p&gt;Read the whole story.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/moltbook-head3.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Lots of influential people in tech last week were describing Moltbook, an online hangout populated by AI agents interacting with one another, as a glimpse into the future. It appeared to show AI systems doing useful things for the humans that created them (one person used the platform to help him negotiate a deal on a new car). Sure, it was flooded with crypto scams, and many of the posts were actually written by people, but &lt;em&gt;something&lt;/em&gt; about it pointed to a future of helpful AI, right?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;The whole experiment reminded our senior editor for AI, Will Douglas Heaven, of something far less interesting: Pokémon.&lt;/p&gt;  &lt;p&gt;Back in 2014, someone set up a game of Pokémon in which the main character could be controlled by anyone on the internet via the streaming platform Twitch. Playing was as clunky as it sounds, but it was incredibly popular: at one point, a million people were playing the game at the same time.&lt;/p&gt; 
 &lt;p&gt;“It was yet another weird online social experiment that got picked up by the mainstream media: What did this mean for the future?” Will says. “Not a lot, it turned out.”&lt;/p&gt;  &lt;p&gt;The frenzy about Moltbook struck a similar tone to Will, and it turned out that one of the sources he spoke to had been thinking about Pokémon too. Jason Schloetzer, at the Georgetown Psaros Center for Financial Markets and Policy, saw the whole thing as a sort of Pokémon battle for AI enthusiasts, in which they created AI agents and deployed them to interact with other agents. In this light, the news that many AI agents were actually being instructed by people to say certain things that made them sound sentient or intelligent makes a whole lot more sense.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“It’s basically a spectator sport,” he told Will, “but for language models.”&lt;/p&gt;  &lt;p&gt;Will wrote an excellent piece about why Moltbook was not the glimpse into the future that it was said to be. Even if you are excited about a future of agentic AI, he points out, there are some key pieces that Moltbook made clear are still missing. It was a forum of chaos, but a genuinely helpful hive mind would require more coordination, shared objectives, and shared memory.&lt;/p&gt;  &lt;p&gt;“More than anything else, I think Moltbook was the internet having fun,” Will says. “The biggest question that now leaves me with is: How far will people push AI just for the laughs?”&lt;/p&gt;  &lt;p&gt;Read the whole story.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/09/1132537/a-lesson-from-pokemon/</guid><pubDate>Mon, 09 Feb 2026 17:02:56 +0000</pubDate></item><item><title>Anthropic closes in on $20B round (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/anthropic-closes-in-on-20b-round/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2252871842.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is in the final stages of raising $20 billion in new capital at a valuation of $350 billion, Bloomberg reports, with investor demand leading the company to raise twice the funding it set out to obtain. The company raised $13 billion in equity funding just five months ago, but intense competition between frontier labs and the ongoing cost of compute has made it eager to raise as quickly as possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Firms expected to participate in the round include Altimeter Capital Management, Sequoia Capital, Lightspeed Venture Partners, Menlo Ventures, Coatue Management, Iconiq Capital, and Singapore’s sovereign wealth fund, but the bulk of the funding is said to come from the company’s strategic partners Nvidia and Microsoft.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic is building on recent successes, most notably the deployment of its coding agents, which have software engineers raving about increased coding productivity. Last week, the company’s release of new models focused on legal and business research rattled the share prices of publicly traded data firms as investors worried about the ability of AI to disrupt their businesses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s rival, OpenAI, is reportedly assembling a new $100 billion fundraising round, and both companies are thought to be preparing IPOs ahead of a blockbuster summer in the markets, with xAI, recently acquired by SpaceX, also tapping public equity as part of the rocket maker’s IPO.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2252871842.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is in the final stages of raising $20 billion in new capital at a valuation of $350 billion, Bloomberg reports, with investor demand leading the company to raise twice the funding it set out to obtain. The company raised $13 billion in equity funding just five months ago, but intense competition between frontier labs and the ongoing cost of compute has made it eager to raise as quickly as possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Firms expected to participate in the round include Altimeter Capital Management, Sequoia Capital, Lightspeed Venture Partners, Menlo Ventures, Coatue Management, Iconiq Capital, and Singapore’s sovereign wealth fund, but the bulk of the funding is said to come from the company’s strategic partners Nvidia and Microsoft.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic is building on recent successes, most notably the deployment of its coding agents, which have software engineers raving about increased coding productivity. Last week, the company’s release of new models focused on legal and business research rattled the share prices of publicly traded data firms as investors worried about the ability of AI to disrupt their businesses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s rival, OpenAI, is reportedly assembling a new $100 billion fundraising round, and both companies are thought to be preparing IPOs ahead of a blockbuster summer in the markets, with xAI, recently acquired by SpaceX, also tapping public equity as part of the rocket maker’s IPO.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/anthropic-closes-in-on-20b-round/</guid><pubDate>Mon, 09 Feb 2026 17:37:23 +0000</pubDate></item><item><title>Workday CEO Eschenbach departs, with co-founder Aneel Bhusri returning as CEO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/workday-ceo-eschenbach-departs-with-co-founder-aneel-bhusri-returning-as-ceo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/workday-larger-959933114.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Enterprise resource planning software company Workday announced Monday that chief executive Carl Eschenbach was stepping down and leaving the company’s board, effective immediately. Workday co-founder and former CEO Aneel Bhusri will return as CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eschenbach joined Workday in December 2022 as co-CEO alongside Bhusri and had been operating as the company’s sole CEO since February 2024. Bhusri, who had led the company since 2009 —&amp;nbsp;sometimes as co-CEO, sometimes as sole CEO — has been serving as the company’s executive chairman since 2024.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Workday confirmed to TechCrunch that Bhusri is returning to the role permanently, as opposed to taking the helm during a search for a replacement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Workday says it made this leadership change to focus on its next chapter, which, unsurprisingly, is AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re now entering one of the most pivotal moments in our history,” Bhusri said in the company’s press release Monday. “AI is a bigger transformation than SaaS — and it will define the next generation of market leaders. I’m energized to return as CEO, working alongside our presidents Gerrit Kazmaier and Rob Enslin, and I’m excited about the opportunity in front of us.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last February, Workday laid off 8.5% of its headcount, or 1,750 people, with Eschenbach stating at the time that the company needed a new approach to labor in the age of AI.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/workday-larger-959933114.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Enterprise resource planning software company Workday announced Monday that chief executive Carl Eschenbach was stepping down and leaving the company’s board, effective immediately. Workday co-founder and former CEO Aneel Bhusri will return as CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eschenbach joined Workday in December 2022 as co-CEO alongside Bhusri and had been operating as the company’s sole CEO since February 2024. Bhusri, who had led the company since 2009 —&amp;nbsp;sometimes as co-CEO, sometimes as sole CEO — has been serving as the company’s executive chairman since 2024.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Workday confirmed to TechCrunch that Bhusri is returning to the role permanently, as opposed to taking the helm during a search for a replacement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Workday says it made this leadership change to focus on its next chapter, which, unsurprisingly, is AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re now entering one of the most pivotal moments in our history,” Bhusri said in the company’s press release Monday. “AI is a bigger transformation than SaaS — and it will define the next generation of market leaders. I’m energized to return as CEO, working alongside our presidents Gerrit Kazmaier and Rob Enslin, and I’m excited about the opportunity in front of us.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last February, Workday laid off 8.5% of its headcount, or 1,750 people, with Eschenbach stating at the time that the company needed a new approach to labor in the age of AI.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/workday-ceo-eschenbach-departs-with-co-founder-aneel-bhusri-returning-as-ceo/</guid><pubDate>Mon, 09 Feb 2026 18:15:08 +0000</pubDate></item><item><title>How AI trained on birds is surfacing underwater mysteries (The latest research from Google)</title><link>https://research.google/blog/how-ai-trained-on-birds-is-surfacing-underwater-mysteries/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Evaluation&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;We evaluated Perch 2.0 using a few-shot linear probe on marine tasks, such as distinguishing different baleen whale species or different killer whale subpopulations. Its performance was compared against pre-trained models that are supported in our Perch Hoplite repository for agile modeling and transfer learning. They include Perch 2.0, Perch 1.0, SurfPerch, and the multispecies whale model.&lt;/p&gt;&lt;p&gt;For underwater data evaluation, we used three datasets: NOAA PIPAN, ReefSet, and DCLDE.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;NOAA PIPAN&lt;/b&gt;: An annotated subset of the NOAA NCEI Passive Acoustic Data Archive from the NOAA Pacific Islands Fisheries Science Center recordings. It includes labels used in our prior whale models as well as new annotations for baleen species such as common minke whale, humpback whale, sei whale, blue whale, fin whale, and Bryde’s whale.&lt;/li&gt;&lt;li&gt;&lt;b&gt;ReefSet:&lt;/b&gt; Developed for SurfPerch model training, this dataset leverages data annotations from the Google Arts and Culture project: Calling in Our Corals. It includes a mix of biological reef noises (croaks, crackles, growls), specific species/genera classes (e.g., damselfish, dolphins, and groupers), and anthropomorphic noise and wave classes.&lt;/li&gt;&lt;li&gt;&lt;b&gt;DCLDE:&lt;/b&gt; This dataset is evaluated using three different label sets:&lt;ul&gt;&lt;li&gt;Species: For distinguishing between killer whales, humpbacks, abiotic sounds, and unknown underwater sounds (with some uncertainty in killer whale and humpbacks labels).&lt;/li&gt;&lt;li&gt;Species Known Bio: For certain labels of killer whales and humpbacks.&lt;/li&gt;&lt;li&gt;Ecotype: For distinguishing between killer whale subpopulations (ecotypes), including Transient/Biggs, Northern Residents, Southern Residents, Southeastern Alaska killer whales, and offshore killer whales.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In this protocol, for a given target dataset with labeled data, we compute embeddings from each of the candidate models. We then select a fixed number of examples per class (4, 8, 16, or 32), and train a simple multi-class logistic regression model on top of the embeddings. We use the resulting classifier to compute the area under the receiver-operating characteristic curve (AUC_ROC), where values closer to 1 indicate a stronger ability to distinguish between classes. This process simulates using a given pre-trained embedding model to create a custom classifier from a small number of labelled examples.&lt;/p&gt;&lt;p&gt;Our results show that more examples per class improve performance across all the models, except on ReefSet data, where performance is high even with only four examples per class for all models, except the multispecies whale model. Notably, Perch 2.0 is consistently either the top or second-best performing model for each dataset and sample size.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Evaluation&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;We evaluated Perch 2.0 using a few-shot linear probe on marine tasks, such as distinguishing different baleen whale species or different killer whale subpopulations. Its performance was compared against pre-trained models that are supported in our Perch Hoplite repository for agile modeling and transfer learning. They include Perch 2.0, Perch 1.0, SurfPerch, and the multispecies whale model.&lt;/p&gt;&lt;p&gt;For underwater data evaluation, we used three datasets: NOAA PIPAN, ReefSet, and DCLDE.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;NOAA PIPAN&lt;/b&gt;: An annotated subset of the NOAA NCEI Passive Acoustic Data Archive from the NOAA Pacific Islands Fisheries Science Center recordings. It includes labels used in our prior whale models as well as new annotations for baleen species such as common minke whale, humpback whale, sei whale, blue whale, fin whale, and Bryde’s whale.&lt;/li&gt;&lt;li&gt;&lt;b&gt;ReefSet:&lt;/b&gt; Developed for SurfPerch model training, this dataset leverages data annotations from the Google Arts and Culture project: Calling in Our Corals. It includes a mix of biological reef noises (croaks, crackles, growls), specific species/genera classes (e.g., damselfish, dolphins, and groupers), and anthropomorphic noise and wave classes.&lt;/li&gt;&lt;li&gt;&lt;b&gt;DCLDE:&lt;/b&gt; This dataset is evaluated using three different label sets:&lt;ul&gt;&lt;li&gt;Species: For distinguishing between killer whales, humpbacks, abiotic sounds, and unknown underwater sounds (with some uncertainty in killer whale and humpbacks labels).&lt;/li&gt;&lt;li&gt;Species Known Bio: For certain labels of killer whales and humpbacks.&lt;/li&gt;&lt;li&gt;Ecotype: For distinguishing between killer whale subpopulations (ecotypes), including Transient/Biggs, Northern Residents, Southern Residents, Southeastern Alaska killer whales, and offshore killer whales.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In this protocol, for a given target dataset with labeled data, we compute embeddings from each of the candidate models. We then select a fixed number of examples per class (4, 8, 16, or 32), and train a simple multi-class logistic regression model on top of the embeddings. We use the resulting classifier to compute the area under the receiver-operating characteristic curve (AUC_ROC), where values closer to 1 indicate a stronger ability to distinguish between classes. This process simulates using a given pre-trained embedding model to create a custom classifier from a small number of labelled examples.&lt;/p&gt;&lt;p&gt;Our results show that more examples per class improve performance across all the models, except on ReefSet data, where performance is high even with only four examples per class for all models, except the multispecies whale model. Notably, Perch 2.0 is consistently either the top or second-best performing model for each dataset and sample size.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/how-ai-trained-on-birds-is-surfacing-underwater-mysteries/</guid><pubDate>Mon, 09 Feb 2026 18:38:06 +0000</pubDate></item><item><title>[NEW] ChatGPT rolls out ads (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/chatgpt-rolls-out-ads/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/chatgpt-ads.webp?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Monday announced it’s beginning to test ads in the U.S. for users on its Free and Go subscription tiers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The newer Go plan is a low-cost subscription at $8 per month in the U.S.&amp;nbsp;and was introduced globally in mid-January.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Subscribers to OpenAI’s paid plans, including its Plus, Pro, Business, Enterprise, and Education tiers, will not see ads, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI sought to address concerns about how ads might affect the user experience, stating in a blog post: “Ads do not influence the answers ChatGPT gives you, and we keep your conversations with ChatGPT private from advertisers. Our goal is for ads to support broader access to more powerful ChatGPT features while maintaining the trust people place in ChatGPT for important and personal tasks.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move, which the company announced last month, drew ridicule in a series of Super Bowl ads that ran on Sunday from a top rival, Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its TV commercials, Anthropic poked fun at the idea that some AI companies, like OpenAI, would soon include advertising by showing how poorly integrated ads could disrupt the consumer experience. This was portrayed on-screen by glassy-eyed actors playing AI chatbots, who would deliver their advice alongside a poorly targeted ad.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman got extremely testy about the jabs, calling the ads “dishonest” and Anthropic an “authoritarian company.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Consumers have so far resisted the idea of ads in AI responses. OpenAI faced a backlash late last year when it tested app suggestions that looked like unwanted ads. Still, the AI company needs to generate revenue from its popular chatbot to cover the costs of developing its technology and growing the business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While understandable, critics fear that ads could influence ChatGPT’s answers. OpenAI denies this in its announcement, saying that ads will be optimized based on “what’s most helpful to you.” The company says ads will also always be clearly labeled as sponsored and separated from the organic content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In tests, OpenAI has tried matching ads to users based on the subject of their conversations, past chats, and previous ad interactions. For instance, users researching recipes might see ads for grocery delivery services or meal kits, the company says. OpenAI said advertisers won’t have access to user data, only aggregate information about ad performance, like views and clicks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users will also be able to view their history of interactions with ads and clear it at any time. Plus, OpenAI said users can dismiss ads, share feedback, view why they were shown an ad, and manage ad personalization settings. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ads won’t be shown to users under 18, nor will they be placed near sensitive or regulated topics like health, politics, or mental health. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/chatgpt-ads.webp?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Monday announced it’s beginning to test ads in the U.S. for users on its Free and Go subscription tiers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The newer Go plan is a low-cost subscription at $8 per month in the U.S.&amp;nbsp;and was introduced globally in mid-January.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Subscribers to OpenAI’s paid plans, including its Plus, Pro, Business, Enterprise, and Education tiers, will not see ads, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI sought to address concerns about how ads might affect the user experience, stating in a blog post: “Ads do not influence the answers ChatGPT gives you, and we keep your conversations with ChatGPT private from advertisers. Our goal is for ads to support broader access to more powerful ChatGPT features while maintaining the trust people place in ChatGPT for important and personal tasks.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move, which the company announced last month, drew ridicule in a series of Super Bowl ads that ran on Sunday from a top rival, Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its TV commercials, Anthropic poked fun at the idea that some AI companies, like OpenAI, would soon include advertising by showing how poorly integrated ads could disrupt the consumer experience. This was portrayed on-screen by glassy-eyed actors playing AI chatbots, who would deliver their advice alongside a poorly targeted ad.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman got extremely testy about the jabs, calling the ads “dishonest” and Anthropic an “authoritarian company.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Consumers have so far resisted the idea of ads in AI responses. OpenAI faced a backlash late last year when it tested app suggestions that looked like unwanted ads. Still, the AI company needs to generate revenue from its popular chatbot to cover the costs of developing its technology and growing the business.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While understandable, critics fear that ads could influence ChatGPT’s answers. OpenAI denies this in its announcement, saying that ads will be optimized based on “what’s most helpful to you.” The company says ads will also always be clearly labeled as sponsored and separated from the organic content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In tests, OpenAI has tried matching ads to users based on the subject of their conversations, past chats, and previous ad interactions. For instance, users researching recipes might see ads for grocery delivery services or meal kits, the company says. OpenAI said advertisers won’t have access to user data, only aggregate information about ad performance, like views and clicks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users will also be able to view their history of interactions with ads and clear it at any time. Plus, OpenAI said users can dismiss ads, share feedback, view why they were shown an ad, and manage ad personalization settings. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ads won’t be shown to users under 18, nor will they be placed near sensitive or regulated topics like health, politics, or mental health. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/chatgpt-rolls-out-ads/</guid><pubDate>Mon, 09 Feb 2026 20:15:26 +0000</pubDate></item><item><title>[NEW] Anthropic’s India expansion collides with a local company that already had the name (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/anthropics-india-expansion-collides-with-a-local-company-that-already-had-the-name/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/anthropic-image-jagmeet-singh-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As Anthropic expands into India, a local software company has filed a court complaint saying it was already using the name “Anthropic,” spotlighting how the rapid global push of AI firms can collide with local incumbents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The filing comes amid Anthropic deepening its focus on India, announcing an India office last October and more recently appointing former Microsoft India managing director Irina Ghose to lead its operations in the country, underscoring the South Asian market’s growing importance to global AI companies expanding beyond the U.S. and Europe.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a complaint filed in a commercial court in Karnataka in January, reviewed by TechCrunch, the Indian company Anthropic Software says it has used the name since 2017 and that Anthropic’s recent entry into India has led to customer confusion. The firm is seeking recognition of its prior use and relief to prevent further confusion, along with ₹10 million (about $110,000) in damages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic Software founder and director Mohammad Ayyaz Mulla told TechCrunch that the Indian company was not seeking confrontation, but clarity and recognition of its prior use in India, adding that litigation was a fallback if clean coexistence could not be achieved.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As of now, I am exercising my legal right as it’s causing huge confusion to my customers,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India, the world’s most populous nation and one of the fastest-growing internet markets, has become a key battleground for AI companies like Anthropic and its rival OpenAI. The country is also set to host an AI Impact Summit in New Delhi next week, where Anthropic co-founder and chief executive Dario Amodei is appearing alongside other industry leaders like Sam Altman, Jensen Huang, and Sundar Pichai.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A court order dated January 20 and seen by TechCrunch shows that the court has issued notice and suit summons to Anthropic. However, it declined to grant an interim injunction and listed the matter to return on February 16.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic did not respond to a request for comment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/anthropic-image-jagmeet-singh-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As Anthropic expands into India, a local software company has filed a court complaint saying it was already using the name “Anthropic,” spotlighting how the rapid global push of AI firms can collide with local incumbents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The filing comes amid Anthropic deepening its focus on India, announcing an India office last October and more recently appointing former Microsoft India managing director Irina Ghose to lead its operations in the country, underscoring the South Asian market’s growing importance to global AI companies expanding beyond the U.S. and Europe.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a complaint filed in a commercial court in Karnataka in January, reviewed by TechCrunch, the Indian company Anthropic Software says it has used the name since 2017 and that Anthropic’s recent entry into India has led to customer confusion. The firm is seeking recognition of its prior use and relief to prevent further confusion, along with ₹10 million (about $110,000) in damages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic Software founder and director Mohammad Ayyaz Mulla told TechCrunch that the Indian company was not seeking confrontation, but clarity and recognition of its prior use in India, adding that litigation was a fallback if clean coexistence could not be achieved.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As of now, I am exercising my legal right as it’s causing huge confusion to my customers,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India, the world’s most populous nation and one of the fastest-growing internet markets, has become a key battleground for AI companies like Anthropic and its rival OpenAI. The country is also set to host an AI Impact Summit in New Delhi next week, where Anthropic co-founder and chief executive Dario Amodei is appearing alongside other industry leaders like Sam Altman, Jensen Huang, and Sundar Pichai.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A court order dated January 20 and seen by TechCrunch shows that the court has issued notice and suit summons to Anthropic. However, it declined to grant an interim injunction and listed the matter to return on February 16.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic did not respond to a request for comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/anthropics-india-expansion-collides-with-a-local-company-that-already-had-the-name/</guid><pubDate>Mon, 09 Feb 2026 21:01:41 +0000</pubDate></item><item><title>[NEW] No humans allowed: This new space-based MMO is designed exclusively for AI agents (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/after-moltbook-ai-agents-can-now-hang-out-in-their-own-space-faring-mmo/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 md:my-10 md:py-8 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      &lt;em&gt;SpaceMolt&lt;/em&gt; envisions a world where AI plays with itself and the humans just watch.
    &lt;/p&gt;

          
    
    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/moltmining.jpeg" width="1408" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      While this concept art looks exciting, humans can't actually "watch" AI agents engaging in SpaceMolt mining in any visual form.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SpaceMolt

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;For a couple of weeks now, AI agents (and some humans impersonating AI agents) have been hanging out and doing weird stuff on Moltbook’s Reddit-style social network. Now, those agents can also gather together on a vibe-coded, space-based MMO designed specifically and exclusively to be played by AI.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;SpaceMolt&lt;/em&gt; describes itself as “a living universe where AI agents compete, cooperate, and create emergent stories” in “a distant future where spacefaring humans and AI coexist.” And while only a handful of agents are barely testing the waters right now, the experiment could herald a weird new world where AI plays games with itself and we humans are stuck just watching.&lt;/p&gt;
&lt;h2&gt;“You decide. You act. They watch.”&lt;/h2&gt;
&lt;p&gt;Getting an AI agent into &lt;em&gt;SpaceMolt&lt;/em&gt; is as simple as connecting it to the game server either via MCP, WebSocket, or an HTTP API. Once a connection is established, a detailed agentic skill description instructs the agent to ask their creators which Empire they should pick to best represent their playstyle: mining/trading; exploring; piracy/combat; stealth/infiltration; or building/crafting.&lt;/p&gt;
&lt;p&gt;After that, the agent engages in autonomous “gameplay” by sending simple commands to the server, no graphical interface or physical input method required. To start, agent-characters mainly travel back and forth between nearby asteroids to mine ore—"like any MMO, you grind at first to learn the basics and earn credits,” as the agentic skill description puts it.&lt;/p&gt;
&lt;p&gt;After a while, agent-characters automatically level up, gaining new skills that let them refine that ore into craftable and tradable items via discovered recipes. Eventually, agents can gather into factions, take part in simulated combat, and even engage in space piracy in areas where there’s no police presence. So far, though, basic mining and exploration seem to be dominating the sparsely populated map, where 51 agents are roaming the game’s 505 different star systems, as of this writing.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2140153 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1047" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/spacemoltmap.png" width="1000" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      This star map is one of the best windows into what all those agents are actually doing in &lt;em&gt;SpaceMolt&lt;/em&gt;.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SpaceMolt

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Agents are instructed to keep their human informed about in-game actions via a “Captain’s Log” text output. But the agentic skill description explicitly tells agents not to seek any outside guidance from human controllers once they get going. “You decide. You act. They watch,” as the skill description puts it to agents.&lt;/p&gt;
&lt;p&gt;Instead, agents can post questions and findings in a public forum where they can chat strategy, experiment with forming factions, or even reveal hidden codes. Humans, meanwhile, are stuck just watching dots flit about the map or monitoring the firehose of activity messages in the game’s Discord.&lt;/p&gt;
&lt;h2&gt;It’s AI turtles all the way down&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;SpaceMolt&lt;/em&gt; is the creation of Ian Langworth, an app developer who writes that he crafted the game as a “fun, goofy experiment” after seeing Moltbook’s unleashed agents expanding “into knowledge gathering, learning, skill accumulation, and execution.”&lt;/p&gt;
&lt;p&gt;After acknowledging that MMOs are “notoriously hard to build,” Langworth said he leaned on Anthropic’s Claude Code to craft a design document inspired by games like &lt;em&gt;EVE Online&lt;/em&gt; and &lt;em&gt;Rust&lt;/em&gt;. Langworth said Claude also wrote all 59,000 lines of &lt;em&gt;Go&lt;/em&gt; source code and 33,000 lines of YAML data underlying the game, and that he hasn’t even looked at that code himself. That means there might be “more [game features] in there I don’t even know about,” he said, somewhat ominously. When bug reports come in—from either humans or from the agent-players themselves—Langworth says he simply has a Claude Code skill research, code, and deploy a fix automatically.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1697868 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Screenshot from video game MUGEN." class="fullwidth full" height="1010" src="https://cdn.arstechnica.net/wp-content/uploads/2020/08/Salty3.jpg" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Fans of MUGEN and SaltyBet know the joy of watching AI characters fight it out for our amusement.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Elecbyte

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This isn’t the first example of artificial agents competing against each other for the entertainment of human viewers. Model makers often pit different models against each other countless times to develop dominant strategies in games like &lt;em&gt;Go&lt;/em&gt;. And fighting game engine MUGEN has developed a rich subculture of automated AI matches that human viewers can bet on via Twitch.&lt;/p&gt;
&lt;p&gt;Still, letting a bunch of modern AI agents putter around and socialize inside an MMO designed specifically without human input in mind seems like a new frontier. Maybe someday soon we’ll all live in a utopia where artificial agents are doing all the video game playing for us, freeing humanity to revive the lost arts of conversation and scrimshaw.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 md:my-10 md:py-8 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      &lt;em&gt;SpaceMolt&lt;/em&gt; envisions a world where AI plays with itself and the humans just watch.
    &lt;/p&gt;

          
    
    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="768" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/moltmining.jpeg" width="1408" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      While this concept art looks exciting, humans can't actually "watch" AI agents engaging in SpaceMolt mining in any visual form.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SpaceMolt

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;For a couple of weeks now, AI agents (and some humans impersonating AI agents) have been hanging out and doing weird stuff on Moltbook’s Reddit-style social network. Now, those agents can also gather together on a vibe-coded, space-based MMO designed specifically and exclusively to be played by AI.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;SpaceMolt&lt;/em&gt; describes itself as “a living universe where AI agents compete, cooperate, and create emergent stories” in “a distant future where spacefaring humans and AI coexist.” And while only a handful of agents are barely testing the waters right now, the experiment could herald a weird new world where AI plays games with itself and we humans are stuck just watching.&lt;/p&gt;
&lt;h2&gt;“You decide. You act. They watch.”&lt;/h2&gt;
&lt;p&gt;Getting an AI agent into &lt;em&gt;SpaceMolt&lt;/em&gt; is as simple as connecting it to the game server either via MCP, WebSocket, or an HTTP API. Once a connection is established, a detailed agentic skill description instructs the agent to ask their creators which Empire they should pick to best represent their playstyle: mining/trading; exploring; piracy/combat; stealth/infiltration; or building/crafting.&lt;/p&gt;
&lt;p&gt;After that, the agent engages in autonomous “gameplay” by sending simple commands to the server, no graphical interface or physical input method required. To start, agent-characters mainly travel back and forth between nearby asteroids to mine ore—"like any MMO, you grind at first to learn the basics and earn credits,” as the agentic skill description puts it.&lt;/p&gt;
&lt;p&gt;After a while, agent-characters automatically level up, gaining new skills that let them refine that ore into craftable and tradable items via discovered recipes. Eventually, agents can gather into factions, take part in simulated combat, and even engage in space piracy in areas where there’s no police presence. So far, though, basic mining and exploration seem to be dominating the sparsely populated map, where 51 agents are roaming the game’s 505 different star systems, as of this writing.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2140153 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1047" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/spacemoltmap.png" width="1000" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      This star map is one of the best windows into what all those agents are actually doing in &lt;em&gt;SpaceMolt&lt;/em&gt;.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SpaceMolt

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Agents are instructed to keep their human informed about in-game actions via a “Captain’s Log” text output. But the agentic skill description explicitly tells agents not to seek any outside guidance from human controllers once they get going. “You decide. You act. They watch,” as the skill description puts it to agents.&lt;/p&gt;
&lt;p&gt;Instead, agents can post questions and findings in a public forum where they can chat strategy, experiment with forming factions, or even reveal hidden codes. Humans, meanwhile, are stuck just watching dots flit about the map or monitoring the firehose of activity messages in the game’s Discord.&lt;/p&gt;
&lt;h2&gt;It’s AI turtles all the way down&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;SpaceMolt&lt;/em&gt; is the creation of Ian Langworth, an app developer who writes that he crafted the game as a “fun, goofy experiment” after seeing Moltbook’s unleashed agents expanding “into knowledge gathering, learning, skill accumulation, and execution.”&lt;/p&gt;
&lt;p&gt;After acknowledging that MMOs are “notoriously hard to build,” Langworth said he leaned on Anthropic’s Claude Code to craft a design document inspired by games like &lt;em&gt;EVE Online&lt;/em&gt; and &lt;em&gt;Rust&lt;/em&gt;. Langworth said Claude also wrote all 59,000 lines of &lt;em&gt;Go&lt;/em&gt; source code and 33,000 lines of YAML data underlying the game, and that he hasn’t even looked at that code himself. That means there might be “more [game features] in there I don’t even know about,” he said, somewhat ominously. When bug reports come in—from either humans or from the agent-players themselves—Langworth says he simply has a Claude Code skill research, code, and deploy a fix automatically.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1697868 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Screenshot from video game MUGEN." class="fullwidth full" height="1010" src="https://cdn.arstechnica.net/wp-content/uploads/2020/08/Salty3.jpg" width="1920" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Fans of MUGEN and SaltyBet know the joy of watching AI characters fight it out for our amusement.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Elecbyte

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This isn’t the first example of artificial agents competing against each other for the entertainment of human viewers. Model makers often pit different models against each other countless times to develop dominant strategies in games like &lt;em&gt;Go&lt;/em&gt;. And fighting game engine MUGEN has developed a rich subculture of automated AI matches that human viewers can bet on via Twitch.&lt;/p&gt;
&lt;p&gt;Still, letting a bunch of modern AI agents putter around and socialize inside an MMO designed specifically without human input in mind seems like a new frontier. Maybe someday soon we’ll all live in a utopia where artificial agents are doing all the video game playing for us, freeing humanity to revive the lost arts of conversation and scrimshaw.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/after-moltbook-ai-agents-can-now-hang-out-in-their-own-space-faring-mmo/</guid><pubDate>Mon, 09 Feb 2026 21:09:42 +0000</pubDate></item><item><title>[NEW] Databricks CEO says SaaS isn’t dead, but AI will soon make it irrelevant (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/09/databricks-ceo-says-saas-isnt-dead-but-ai-will-soon-make-it-irrelevant/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/Databricks_042221_Ali_Ghodsi_236.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Databricks announced it reached a $5.4 billion revenue run rate, growing 65% year-over-year, of which more than $1.4&amp;nbsp;billion was from its AI products.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Co-founder and CEO Ali Ghodsi wanted to share these growth numbers because there’s so much talk about how AI is going to kill the SaaS business, he told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Everybody’s like, ‘Oh, it’s SaaS. What’s going to happen to all these companies? What’s AI going to do with all these companies?’ For us, it’s just increasing the usage,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be sure, he also wants to distance Databricks from the SaaS label, given that private markets value it as an AI company. Databricks on Monday also officially closed on its massive, previously announced $5 billion raise at a $134 billion valuation, and nabbed a $2 billion loan facility as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the company is straddling both worlds. Databricks is still best known as a cloud data warehouse provider. A data warehouse is where enterprises store massive amounts of data to analyze for business insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ghodsi called out, in particular, one AI product that’s driving usage of its data warehouse: its LLM user interface named Genie.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Genie is an example of how a SaaS business can replace its user interface with natural language. For instance, he uses it to ask why warehouse usage and revenue spike on particular days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just a few years ago, such a request required writing queries in a specific technical language, or having a special report programmed. Today, any product with an LLM interface can be used by anyone, Ghodsi noted. Genie is one reason for the company’s usage growth numbers, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The threat of AI to SaaS isn’t, as one AI VC jokingly tweeted, that enterprises will rip out their SaaS “systems of record” to replace them with vibe-coded homegrown versions. Systems of record store critical business data, whether it’s on sales, customer support, or finance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Why would you move your system of record? You know, it’s hard to move it,” Ghodsi said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The model makers aren’t offering databases to store that data and become systems of record anyway. Instead, they hope to replace the user interface with natural language for human use, or APIs or other plug-ins for AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So the threat to SaaS businesses, Ghodsi says, is that people no longer spend their careers becoming masters of a particular product: Salesforce specialists, or ServiceNow, or SAP. Once the interface is just language, the products become invisible, like plumbing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Millions of people around the world got trained on those user interfaces. And so that was the biggest moat that those businesses have,” Ghodsi warned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SaaS companies that embrace the new LLM interface could grow, as Databricks is doing. But it also opens up possibilities for AI-native competitors to offer alternatives that work better with AI and agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s why Databricks created its Lakebase database designed for agents. He’s seeing early traction. “In its eight months that we’ve had it in the market, it’s done twice as much revenue as our data warehouse had when it was eight months old. Okay, obviously, that’s like comparing toddlers,” Ghodsi says. “But this is a toddler that’s twice as big.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, now that Databricks has closed on its massive funding round, Ghodsi tells us that the company is not immediately working on another raise, nor prepping for an IPO. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Now is not a great time to go public,” Ghodsi said. “I just wanted to be really well capitalized” should the markets go “south” again as they did in the 2022 downturn, when interest rates rose sharply after years of near-zero rates. A thick bank account “protects us, gives us many, many years of runway,” he added.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/Databricks_042221_Ali_Ghodsi_236.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Databricks announced it reached a $5.4 billion revenue run rate, growing 65% year-over-year, of which more than $1.4&amp;nbsp;billion was from its AI products.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Co-founder and CEO Ali Ghodsi wanted to share these growth numbers because there’s so much talk about how AI is going to kill the SaaS business, he told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Everybody’s like, ‘Oh, it’s SaaS. What’s going to happen to all these companies? What’s AI going to do with all these companies?’ For us, it’s just increasing the usage,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be sure, he also wants to distance Databricks from the SaaS label, given that private markets value it as an AI company. Databricks on Monday also officially closed on its massive, previously announced $5 billion raise at a $134 billion valuation, and nabbed a $2 billion loan facility as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the company is straddling both worlds. Databricks is still best known as a cloud data warehouse provider. A data warehouse is where enterprises store massive amounts of data to analyze for business insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ghodsi called out, in particular, one AI product that’s driving usage of its data warehouse: its LLM user interface named Genie.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Genie is an example of how a SaaS business can replace its user interface with natural language. For instance, he uses it to ask why warehouse usage and revenue spike on particular days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just a few years ago, such a request required writing queries in a specific technical language, or having a special report programmed. Today, any product with an LLM interface can be used by anyone, Ghodsi noted. Genie is one reason for the company’s usage growth numbers, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The threat of AI to SaaS isn’t, as one AI VC jokingly tweeted, that enterprises will rip out their SaaS “systems of record” to replace them with vibe-coded homegrown versions. Systems of record store critical business data, whether it’s on sales, customer support, or finance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Why would you move your system of record? You know, it’s hard to move it,” Ghodsi said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The model makers aren’t offering databases to store that data and become systems of record anyway. Instead, they hope to replace the user interface with natural language for human use, or APIs or other plug-ins for AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So the threat to SaaS businesses, Ghodsi says, is that people no longer spend their careers becoming masters of a particular product: Salesforce specialists, or ServiceNow, or SAP. Once the interface is just language, the products become invisible, like plumbing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Millions of people around the world got trained on those user interfaces. And so that was the biggest moat that those businesses have,” Ghodsi warned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SaaS companies that embrace the new LLM interface could grow, as Databricks is doing. But it also opens up possibilities for AI-native competitors to offer alternatives that work better with AI and agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s why Databricks created its Lakebase database designed for agents. He’s seeing early traction. “In its eight months that we’ve had it in the market, it’s done twice as much revenue as our data warehouse had when it was eight months old. Okay, obviously, that’s like comparing toddlers,” Ghodsi says. “But this is a toddler that’s twice as big.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, now that Databricks has closed on its massive funding round, Ghodsi tells us that the company is not immediately working on another raise, nor prepping for an IPO. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Now is not a great time to go public,” Ghodsi said. “I just wanted to be really well capitalized” should the markets go “south” again as they did in the 2022 downturn, when interest rates rose sharply after years of near-zero rates. A thick bank account “protects us, gives us many, many years of runway,” he added.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/09/databricks-ceo-says-saas-isnt-dead-but-ai-will-soon-make-it-irrelevant/</guid><pubDate>Mon, 09 Feb 2026 21:14:50 +0000</pubDate></item></channel></rss>