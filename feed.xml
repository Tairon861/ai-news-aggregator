<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 16 Sep 2025 06:31:31 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>The 9 most sought-after startups from YC Demo Day (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/15/the-9-most-sought-after-startups-from-yc-demo-day/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/09/yc-2022-fall-1-e1662566861873.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Y Combinator hosted its Summer 2025 Demo Day last week, showcasing the latest batch of over 160 startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As with recent batches, the majority of startups presented AI-centric solutions. However, a clear evolution was evident. Instead of&amp;nbsp; “AI-powered” products, many companies are now building AI agents or the infrastructure and tools needed to develop them. For instance, this batch had a flurry of voice AI solutions and new businesses focused on helping others monetize the “AI economy” with ads and marketing tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We spoke with a handful of YC-focused&amp;nbsp; investors to learn which startups they found most interesting and which generated the highest investment demand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below are the most frequently mentioned ones:&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Stripe for AI startups&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Many AI startups use complex pricing models that often blend a flat subscription fee per seat with usage-based charges, credits, and various add-on costs. Managing complex AI pricing on Stripe is a time-consuming, manual process. That’s why Autumn developed an open-source infrastructure that simplifies Stripe integration for AI startups. The company says its technology is already used by hundreds of AI apps and 40 YC startups. Given Stripe’s dominance in payments and the explosive growth of the AI market, could a specialized billing solution for AI be the next major fintech success story?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Builds Vercel for AI agents&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Just as Vercel helps developers deploy and host startups,&lt;strong&gt; &lt;/strong&gt;Dedalus Labs claims its platform automates the infrastructure for building AI agents, cutting hours of coding down to a few clicks. The company handles complex tasks like autoscaling and load balancing, which it says makes agent deployment fast and simple.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;crowdsource rankings of vibe coded designs&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;The ability of AI to rapidly generate a huge number of designs creates a new problem: figuring out which ones are actually good. Design Arena solves this by crowdsourcing rankings of AI-generated visuals, creating a feedback loop that forces AI models to improve. Large AI labs see value in training their models to generate better designs, as some of them are already Design Arena’s customers.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Tech-enabled distributor for retailers in Southeast Asia&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Getasap Asia was founded by Raghav Arora three years ago when he was just 14 years old. Since then, the startup that uses tech to deliver supplies to corner stores, restaurants and large supermarkets in Southeast Asia in under eight hours, has earned millions in revenue. Getasap Asia closed a round from General Catalyst, according to its website, and we are hearing that the startup’s valuation was among the highest in the whole batch.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;AI engineer that fixes bugs in production&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Founded by a 20-year-old Pablo Hansen who last year earned a master’s degree in AI, Keystone is on a mission to reduce software breaks. The company’s AI finds and fixes bugs for clients like Lovable and has already turned down a seven-figure acquisition offer, Hansen said.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;AI matchmaker for female friends&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;While there isn’t a shortage of dating apps, RealRoots is tackling a different kind of loneliness. The company’s AI matchmaker, Lisa, interviews women and then organizes social experiences to connect them with compatible friends. While the AI part might be performative –&amp;nbsp; conversations with Lisa probably wouldn’t give RealRoots more insights about participants than written answers would – RealRoots may be on to something. Last month alone, the company generated $782,000 from 9,000 paying clients, its founders said.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Automates insurance claims with AI&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Solva’s AI automates the most routine tasks for insurance adjusters, from filling out complex claims to preventing improper payouts. Just ten weeks after launching, Solva has already amassed $245,000 in annual recurring revenue (ARR), a figure that has investors excited.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;counter-drone mini-missiles&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;With China reportedly amassing swarms of inexpensive drones, the U.S. military faces an urgent need for cost-effective counter-drone solutions. Perseus is developing just that: small missiles designed to shoot down drones at a fraction of the cost of existing systems. Multiple branches of the U.S. military have already invited the startup to demonstrate its solution, which could lead to hefty contracts.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does:&lt;/strong&gt; AI foreign language tutor&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Apps like Duolingo have made language learning accessible and fun, but they often lack a key component of fluency: consistent conversation. Pingo solves this problem by allowing users to speak with its AI, which acts as a native speaker. The company’s unique approach is proving incredibly popular, with founders claiming it’s growing 70% monthly and earning $250,000 in monthly revenue.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/09/yc-2022-fall-1-e1662566861873.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Y Combinator hosted its Summer 2025 Demo Day last week, showcasing the latest batch of over 160 startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As with recent batches, the majority of startups presented AI-centric solutions. However, a clear evolution was evident. Instead of&amp;nbsp; “AI-powered” products, many companies are now building AI agents or the infrastructure and tools needed to develop them. For instance, this batch had a flurry of voice AI solutions and new businesses focused on helping others monetize the “AI economy” with ads and marketing tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We spoke with a handful of YC-focused&amp;nbsp; investors to learn which startups they found most interesting and which generated the highest investment demand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below are the most frequently mentioned ones:&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Stripe for AI startups&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Many AI startups use complex pricing models that often blend a flat subscription fee per seat with usage-based charges, credits, and various add-on costs. Managing complex AI pricing on Stripe is a time-consuming, manual process. That’s why Autumn developed an open-source infrastructure that simplifies Stripe integration for AI startups. The company says its technology is already used by hundreds of AI apps and 40 YC startups. Given Stripe’s dominance in payments and the explosive growth of the AI market, could a specialized billing solution for AI be the next major fintech success story?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Builds Vercel for AI agents&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Just as Vercel helps developers deploy and host startups,&lt;strong&gt; &lt;/strong&gt;Dedalus Labs claims its platform automates the infrastructure for building AI agents, cutting hours of coding down to a few clicks. The company handles complex tasks like autoscaling and load balancing, which it says makes agent deployment fast and simple.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;crowdsource rankings of vibe coded designs&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;The ability of AI to rapidly generate a huge number of designs creates a new problem: figuring out which ones are actually good. Design Arena solves this by crowdsourcing rankings of AI-generated visuals, creating a feedback loop that forces AI models to improve. Large AI labs see value in training their models to generate better designs, as some of them are already Design Arena’s customers.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Tech-enabled distributor for retailers in Southeast Asia&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Getasap Asia was founded by Raghav Arora three years ago when he was just 14 years old. Since then, the startup that uses tech to deliver supplies to corner stores, restaurants and large supermarkets in Southeast Asia in under eight hours, has earned millions in revenue. Getasap Asia closed a round from General Catalyst, according to its website, and we are hearing that the startup’s valuation was among the highest in the whole batch.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;AI engineer that fixes bugs in production&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Founded by a 20-year-old Pablo Hansen who last year earned a master’s degree in AI, Keystone is on a mission to reduce software breaks. The company’s AI finds and fixes bugs for clients like Lovable and has already turned down a seven-figure acquisition offer, Hansen said.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;AI matchmaker for female friends&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;While there isn’t a shortage of dating apps, RealRoots is tackling a different kind of loneliness. The company’s AI matchmaker, Lisa, interviews women and then organizes social experiences to connect them with compatible friends. While the AI part might be performative –&amp;nbsp; conversations with Lisa probably wouldn’t give RealRoots more insights about participants than written answers would – RealRoots may be on to something. Last month alone, the company generated $782,000 from 9,000 paying clients, its founders said.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;Automates insurance claims with AI&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Solva’s AI automates the most routine tasks for insurance adjusters, from filling out complex claims to preventing improper payouts. Just ten weeks after launching, Solva has already amassed $245,000 in annual recurring revenue (ARR), a figure that has investors excited.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does: &lt;/strong&gt;counter-drone mini-missiles&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;With China reportedly amassing swarms of inexpensive drones, the U.S. military faces an urgent need for cost-effective counter-drone solutions. Perseus is developing just that: small missiles designed to shoot down drones at a fraction of the cost of existing systems. Multiple branches of the U.S. military have already invited the startup to demonstrate its solution, which could lead to hefty contracts.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;What it does:&lt;/strong&gt; AI foreign language tutor&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Why it’s a fave: &lt;/strong&gt;Apps like Duolingo have made language learning accessible and fun, but they often lack a key component of fluency: consistent conversation. Pingo solves this problem by allowing users to speak with its AI, which acts as a native speaker. The company’s unique approach is proving incredibly popular, with founders claiming it’s growing 70% monthly and earning $250,000 in monthly revenue.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/15/the-9-most-sought-after-startups-from-yc-demo-day/</guid><pubDate>Mon, 15 Sep 2025 20:11:51 +0000</pubDate></item><item><title>What do people actually use ChatGPT for? OpenAI provides some numbers. (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/seven-things-we-learned-from-openais-first-study-on-chatgpt-usage/</link><description>&lt;article class="double-column h-entry post-2117130 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-ai tag-chatgpt tag-demographics tag-measurement tag-openai tag-statistics tag-stats tag-users"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New study breaks down what 700 million users do across 2.6 billion daily GPT messages.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1397542920-1-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1397542920-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A live look at how OpenAI gathered its user data.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;As someone who writes about the AI industry relatively frequently for this site, there is one question that I find myself constantly asking and being asked in turn, in some form or another: What do you actually use large language models for?&lt;/p&gt;
&lt;p&gt;Today, OpenAI's Economic Research Team went a long way toward answering that question, on a population level, releasing a first-of-its-kind National Bureau of Economic Research working paper (in association with Harvard economist David Denning) detailing how people end up using ChatGPT across time and tasks. While other research has sought to estimate this kind of usage data using self-reported surveys, this is the first such paper with direct access to OpenAI's internal user data. As such, it gives us an unprecedented direct window into reliable usage stats for what is still the most popular application of LLMs by far.&lt;/p&gt;
&lt;p&gt;After digging through the dense 65-page paper, here are seven of the most interesting and/or surprising things we discovered about how people are using OpenAI today.&lt;/p&gt;
&lt;h2&gt;OpenAI is still growing at a rapid clip&lt;/h2&gt;
&lt;p&gt;We've known for a while that ChatGPT was popular, but this paper gives a direct look at just how big the LLM has been getting in recent months. Just measuring weekly active users on ChatGPT's consumer plans (i.e. Free, Plus, and Pro tiers), ChatGPT passed 100 million users in early 2024, climbed past 400 million users early this year, and currently can boast over 700 million users, or "nearly 10% of the world’s adult population," according to the company.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117133 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="623" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph1.png" width="1084" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Line goes up... and faster than ever these days.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI admits its measurements might be slightly off thanks to double-counting some logged-out users across multiple individual devices, as well as some logged-in users who maintain multiple accounts with different email addresses. And other reporting suggests only a small minority of those users are paying for the privilege of using ChatGPT just yet. Still, the vast number of people who are at least curious about trying OpenAI's LLM appears to still be on the steep upward part of its growth curve.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;All those new users are also leading to significant increases in just how many messages OpenAI processes daily, which has gone up from about 451 million in June 2024 to over 2.6 billion in June 2025 (averaged over a week near the end of the month). To give that number some context, Google announced in March that it averages 14 billion searches per day, and that's after decades as the undisputed leader in Internet search.&lt;/p&gt;
&lt;h2&gt;... but usage growth is plateauing among long-term users&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2117135 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="747" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph2.png" width="1084" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Newer users have driven almost all of the overall usage growth in ChatGPT in recent months.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;In addition to measuring overall user and usage growth, OpenAI's paper also breaks down total usage based on when its logged-in users first signed up for an account. These charts show just how much of ChatGPT's recent growth is reliant on new user acquisition, rather than older users increasing their daily usage.&lt;/p&gt;
&lt;p&gt;In terms of average daily message volume per individual long-term user, ChatGPT seems to have seen two distinct and sharp growth periods. The first runs roughly from September through December 2024, coinciding with the launch of the o1-preview and o1-mini models. Average per-user messaging on ChatGPT then largely plateaued until April, when the launch of the o3 and o4-mini models&amp;nbsp;caused another significant usage increase through June.&lt;/p&gt;
&lt;p&gt;Since June, though, per-user message rates for established ChatGPT users (those who signed up in the first quarter of 2025 or before) have been remarkably flat for three full months. The growth in overall usage during that last quarter has been entirely driven by newer users who have signed up since April, many of whom are still getting their feet wet with the LLM.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117139 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="729" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph3.png" width="1072" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Average daily usage for long-term users has stopped growing in recent months, even as new users increase their ChatGPT message rates.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;We'll see if the recent tumultuous launch of the GPT-5 model leads to another significant increase in per-user message volume averages in the coming months. If it doesn't, then we may be seeing at least a temporary ceiling on how much use established ChatGPT users get out of the service in an average day.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;ChatGPT users are younger and were more male than the general population&lt;/h2&gt;
&lt;p&gt;While young people are generally more likely to embrace new technology, it's striking just how much of ChatGPT's user base is made up of our youngest demographic cohort. A full 46 percent of users who revealed their age in OpenAI's study sample were between the ages of 18 and 25. Add in the doubtless significant number of people under 18 using ChatGPT (who weren't included in the sample at all), and a decent majority of OpenAI's users probably aren't old enough to remember the 20th century firsthand.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117140 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="492" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph4.png" width="1086" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      What started as mostly a boys' club has reached close to gender parity among ChatGPT users, based on gendered name analysis.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI also estimated the likely gender split among a large sample of ChatGPT users by using Social Security data and the World Gender Name Registry's list of strongly masculine or feminine first names. When ChatGPT launched in late 2022, this analysis found roughly 80 percent of weekly active ChatGPT users were likely male. In late 2025, that ratio has flipped to a slight (52.4 percent) majority for likely female users.&lt;/p&gt;
&lt;h2&gt;People are using it for more than work&lt;/h2&gt;
&lt;p&gt;Despite all the talk about LLMs potentially revolutionizing the workplace, a significant majority of all ChatGPT use has nothing to do with business productivity, according to OpenAI. Non-work tasks (as identified by an LLM-based classifier) grew from about 53 percent of all ChatGPT messages in June of 2024 to 72.2 percent as of June 2025, according to the study.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117142 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="776" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph5.png" width="1088" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      As time goes on, more and more ChatGPT usage is becoming non-work related.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Some of this might have to do with the exclusion of users in the Business, Enterprise, and Education subscription tiers from the data set. Still, the recent rise in non-work uses suggests that a lot of the newest ChatGPT users are doing so more for personal than for productivity reasons.&lt;/p&gt;
&lt;h2&gt;ChatGPT users need help with their writing&lt;/h2&gt;
&lt;p&gt;It's not that surprising that a lot of people use a large language model to help them with generating written words. But it's still striking the extent to which writing help is a major use of ChatGPT.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Across 1.1 million conversations dating from May 2024 to June 2025, a full 28 percent dealt with writing assistance in some form or another, OpenAI said. That rises to a whopping 42 percent for the subset of conversations tagged as work-related (by far the most popular work-related task), and a majority, 52 percent, of all work-related conversations from users with "management and business occupations."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117145 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph8.png" width="1077" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A lot of ChatGPT use is people seeking help with their writing in some form.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI is quick to point out, though, that many of these users aren't just relying on ChatGPT to generate emails or messages from whole cloth. The percent of all conversations studied involves users asking the LLM to "edit or critique" text, at 10.6 percent, vs. just 8 percent that deal with generating "personal writing or communication" from a prompt. Another 4.5 percent of all conversations deal with translating existing text to a new language, versus just 1.4 percent dealing with "writing fiction."&lt;/p&gt;
&lt;h2&gt;More people are using ChatGPT as an informational search engine&lt;/h2&gt;
&lt;p&gt;In June 2024, about 14 percent of all ChatGPT conversations were tagged as relating to "seeking information." By June 2025, that number had risen to 24.4 percent, slightly edging out writing-based prompts in the sample (which had fallen from roughly 35 percent of the 2024 sample).&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117143 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="704" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph6.png" width="1072" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A growing number of ChatGPT conversations now deal with "seeking information" as you might do with a more traditional search engine.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;While recent GPT models seem to have gotten better about citing relevant sources to back up their information, OpenAI is no closer to solving the widespread confabulation problem that makes LLMs a dodgy tool for retrieving facts. Luckily, fewer people seem interested in using ChatGPT to seek information at work; that use case makes up just 13.5 percent of work-related ChatGPT conversations, well below the 40 percent that are writing-related.&lt;/p&gt;
&lt;h2&gt;A large number of workers are using ChatGPT to make decisions&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2117144 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="211" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph7.png" width="834" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Among work-related conversations, "making decisions and solving problems" is a relatively popular use for ChatGPT.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Getting help editing an email is one thing, but asking ChatGPT to help you make a business decision is another altogether. Across work-related conversations, OpenAI says a significant 14.9 percent dealt with "making decisions and solving problems." That's second only to "documenting and recording information" for work-related ChatGPT conversations among the dozens of "generalized work activity" categories classified by O*NET.&lt;/p&gt;
&lt;p&gt;This was true across all the different occupation types OpenAI looked at, which the company suggests means people are "using ChatGPT as an advisor or research assistant, not just a technology that performs job tasks directly."&lt;/p&gt;
&lt;h2&gt;And the rest...&lt;/h2&gt;
&lt;p&gt;Some other highly touted use cases for ChatGPT that represented a surprisingly small portion of the sampled conversations across OpenAI's study:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multimedia (e.g., creating or retrieving an image): 6 percent&lt;/li&gt;
&lt;li&gt;Computer programming: 4.2 percent (though some of this use might be outsourced to the API)&lt;/li&gt;
&lt;li&gt;Creative ideation: 3.9 percent&lt;/li&gt;
&lt;li&gt;Mathematical calculation: 3 percent&lt;/li&gt;
&lt;li&gt;Relationships and personal reflection: 1.9 percent&lt;/li&gt;
&lt;li&gt;Game and roleplay: 0.4 percent&lt;/li&gt;
&lt;/ul&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #a7ffeb; background-color: #00796b;"&gt;&lt;span class="ars-avatar-letter"&gt;&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              太鶏道
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            I use it quite a bit to assist with translation, and I can't ever see myself going back to things like Google Translate.  Google Translate has almost no ability to provide context, so the answers you get back with it are often suboptimal or even wrong.  It's a night and day difference for me.  However, as with other use cases, the LLM is most advantageous when you have a grasp on that language already, and can understand what the LLM spits out.
          &lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-09-15T20:52:11+00:00"&gt;September 15, 2025 at 8:52 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2117130 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-ai tag-chatgpt tag-demographics tag-measurement tag-openai tag-statistics tag-stats tag-users"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New study breaks down what 700 million users do across 2.6 billion daily GPT messages.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1397542920-1-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1397542920-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A live look at how OpenAI gathered its user data.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;As someone who writes about the AI industry relatively frequently for this site, there is one question that I find myself constantly asking and being asked in turn, in some form or another: What do you actually use large language models for?&lt;/p&gt;
&lt;p&gt;Today, OpenAI's Economic Research Team went a long way toward answering that question, on a population level, releasing a first-of-its-kind National Bureau of Economic Research working paper (in association with Harvard economist David Denning) detailing how people end up using ChatGPT across time and tasks. While other research has sought to estimate this kind of usage data using self-reported surveys, this is the first such paper with direct access to OpenAI's internal user data. As such, it gives us an unprecedented direct window into reliable usage stats for what is still the most popular application of LLMs by far.&lt;/p&gt;
&lt;p&gt;After digging through the dense 65-page paper, here are seven of the most interesting and/or surprising things we discovered about how people are using OpenAI today.&lt;/p&gt;
&lt;h2&gt;OpenAI is still growing at a rapid clip&lt;/h2&gt;
&lt;p&gt;We've known for a while that ChatGPT was popular, but this paper gives a direct look at just how big the LLM has been getting in recent months. Just measuring weekly active users on ChatGPT's consumer plans (i.e. Free, Plus, and Pro tiers), ChatGPT passed 100 million users in early 2024, climbed past 400 million users early this year, and currently can boast over 700 million users, or "nearly 10% of the world’s adult population," according to the company.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117133 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="623" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph1.png" width="1084" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Line goes up... and faster than ever these days.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI admits its measurements might be slightly off thanks to double-counting some logged-out users across multiple individual devices, as well as some logged-in users who maintain multiple accounts with different email addresses. And other reporting suggests only a small minority of those users are paying for the privilege of using ChatGPT just yet. Still, the vast number of people who are at least curious about trying OpenAI's LLM appears to still be on the steep upward part of its growth curve.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;All those new users are also leading to significant increases in just how many messages OpenAI processes daily, which has gone up from about 451 million in June 2024 to over 2.6 billion in June 2025 (averaged over a week near the end of the month). To give that number some context, Google announced in March that it averages 14 billion searches per day, and that's after decades as the undisputed leader in Internet search.&lt;/p&gt;
&lt;h2&gt;... but usage growth is plateauing among long-term users&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2117135 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="747" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph2.png" width="1084" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Newer users have driven almost all of the overall usage growth in ChatGPT in recent months.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;In addition to measuring overall user and usage growth, OpenAI's paper also breaks down total usage based on when its logged-in users first signed up for an account. These charts show just how much of ChatGPT's recent growth is reliant on new user acquisition, rather than older users increasing their daily usage.&lt;/p&gt;
&lt;p&gt;In terms of average daily message volume per individual long-term user, ChatGPT seems to have seen two distinct and sharp growth periods. The first runs roughly from September through December 2024, coinciding with the launch of the o1-preview and o1-mini models. Average per-user messaging on ChatGPT then largely plateaued until April, when the launch of the o3 and o4-mini models&amp;nbsp;caused another significant usage increase through June.&lt;/p&gt;
&lt;p&gt;Since June, though, per-user message rates for established ChatGPT users (those who signed up in the first quarter of 2025 or before) have been remarkably flat for three full months. The growth in overall usage during that last quarter has been entirely driven by newer users who have signed up since April, many of whom are still getting their feet wet with the LLM.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117139 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="729" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph3.png" width="1072" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Average daily usage for long-term users has stopped growing in recent months, even as new users increase their ChatGPT message rates.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;We'll see if the recent tumultuous launch of the GPT-5 model leads to another significant increase in per-user message volume averages in the coming months. If it doesn't, then we may be seeing at least a temporary ceiling on how much use established ChatGPT users get out of the service in an average day.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;ChatGPT users are younger and were more male than the general population&lt;/h2&gt;
&lt;p&gt;While young people are generally more likely to embrace new technology, it's striking just how much of ChatGPT's user base is made up of our youngest demographic cohort. A full 46 percent of users who revealed their age in OpenAI's study sample were between the ages of 18 and 25. Add in the doubtless significant number of people under 18 using ChatGPT (who weren't included in the sample at all), and a decent majority of OpenAI's users probably aren't old enough to remember the 20th century firsthand.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117140 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="492" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph4.png" width="1086" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      What started as mostly a boys' club has reached close to gender parity among ChatGPT users, based on gendered name analysis.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI also estimated the likely gender split among a large sample of ChatGPT users by using Social Security data and the World Gender Name Registry's list of strongly masculine or feminine first names. When ChatGPT launched in late 2022, this analysis found roughly 80 percent of weekly active ChatGPT users were likely male. In late 2025, that ratio has flipped to a slight (52.4 percent) majority for likely female users.&lt;/p&gt;
&lt;h2&gt;People are using it for more than work&lt;/h2&gt;
&lt;p&gt;Despite all the talk about LLMs potentially revolutionizing the workplace, a significant majority of all ChatGPT use has nothing to do with business productivity, according to OpenAI. Non-work tasks (as identified by an LLM-based classifier) grew from about 53 percent of all ChatGPT messages in June of 2024 to 72.2 percent as of June 2025, according to the study.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117142 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="776" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph5.png" width="1088" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      As time goes on, more and more ChatGPT usage is becoming non-work related.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Some of this might have to do with the exclusion of users in the Business, Enterprise, and Education subscription tiers from the data set. Still, the recent rise in non-work uses suggests that a lot of the newest ChatGPT users are doing so more for personal than for productivity reasons.&lt;/p&gt;
&lt;h2&gt;ChatGPT users need help with their writing&lt;/h2&gt;
&lt;p&gt;It's not that surprising that a lot of people use a large language model to help them with generating written words. But it's still striking the extent to which writing help is a major use of ChatGPT.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Across 1.1 million conversations dating from May 2024 to June 2025, a full 28 percent dealt with writing assistance in some form or another, OpenAI said. That rises to a whopping 42 percent for the subset of conversations tagged as work-related (by far the most popular work-related task), and a majority, 52 percent, of all work-related conversations from users with "management and business occupations."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117145 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph8.png" width="1077" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A lot of ChatGPT use is people seeking help with their writing in some form.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;OpenAI is quick to point out, though, that many of these users aren't just relying on ChatGPT to generate emails or messages from whole cloth. The percent of all conversations studied involves users asking the LLM to "edit or critique" text, at 10.6 percent, vs. just 8 percent that deal with generating "personal writing or communication" from a prompt. Another 4.5 percent of all conversations deal with translating existing text to a new language, versus just 1.4 percent dealing with "writing fiction."&lt;/p&gt;
&lt;h2&gt;More people are using ChatGPT as an informational search engine&lt;/h2&gt;
&lt;p&gt;In June 2024, about 14 percent of all ChatGPT conversations were tagged as relating to "seeking information." By June 2025, that number had risen to 24.4 percent, slightly edging out writing-based prompts in the sample (which had fallen from roughly 35 percent of the 2024 sample).&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117143 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="704" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph6.png" width="1072" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A growing number of ChatGPT conversations now deal with "seeking information" as you might do with a more traditional search engine.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;While recent GPT models seem to have gotten better about citing relevant sources to back up their information, OpenAI is no closer to solving the widespread confabulation problem that makes LLMs a dodgy tool for retrieving facts. Luckily, fewer people seem interested in using ChatGPT to seek information at work; that use case makes up just 13.5 percent of work-related ChatGPT conversations, well below the 40 percent that are writing-related.&lt;/p&gt;
&lt;h2&gt;A large number of workers are using ChatGPT to make decisions&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2117144 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="211" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/gptgraph7.png" width="834" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Among work-related conversations, "making decisions and solving problems" is a relatively popular use for ChatGPT.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Getting help editing an email is one thing, but asking ChatGPT to help you make a business decision is another altogether. Across work-related conversations, OpenAI says a significant 14.9 percent dealt with "making decisions and solving problems." That's second only to "documenting and recording information" for work-related ChatGPT conversations among the dozens of "generalized work activity" categories classified by O*NET.&lt;/p&gt;
&lt;p&gt;This was true across all the different occupation types OpenAI looked at, which the company suggests means people are "using ChatGPT as an advisor or research assistant, not just a technology that performs job tasks directly."&lt;/p&gt;
&lt;h2&gt;And the rest...&lt;/h2&gt;
&lt;p&gt;Some other highly touted use cases for ChatGPT that represented a surprisingly small portion of the sampled conversations across OpenAI's study:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Multimedia (e.g., creating or retrieving an image): 6 percent&lt;/li&gt;
&lt;li&gt;Computer programming: 4.2 percent (though some of this use might be outsourced to the API)&lt;/li&gt;
&lt;li&gt;Creative ideation: 3.9 percent&lt;/li&gt;
&lt;li&gt;Mathematical calculation: 3 percent&lt;/li&gt;
&lt;li&gt;Relationships and personal reflection: 1.9 percent&lt;/li&gt;
&lt;li&gt;Game and roleplay: 0.4 percent&lt;/li&gt;
&lt;/ul&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #a7ffeb; background-color: #00796b;"&gt;&lt;span class="ars-avatar-letter"&gt;&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              太鶏道
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            I use it quite a bit to assist with translation, and I can't ever see myself going back to things like Google Translate.  Google Translate has almost no ability to provide context, so the answers you get back with it are often suboptimal or even wrong.  It's a night and day difference for me.  However, as with other use cases, the LLM is most advantageous when you have a grasp on that language already, and can understand what the LLM spits out.
          &lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-09-15T20:52:11+00:00"&gt;September 15, 2025 at 8:52 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/seven-things-we-learned-from-openais-first-study-on-chatgpt-usage/</guid><pubDate>Mon, 15 Sep 2025 20:26:34 +0000</pubDate></item><item><title>Google releases VaultGemma, its first privacy-preserving LLM (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/google-releases-vaultgemma-its-first-privacy-preserving-llm/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google Research shows that AI models can keep training data private.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="450" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma.jpg" width="800" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The companies seeking to build larger AI models have been increasingly stymied by a lack of high-quality training data. As tech firms scour the web for more data to feed their models, they could increasingly rely on potentially sensitive user data. A team at Google Research is exploring new techniques to make the resulting large language models (LLMs) less likely to "memorize" any of that content.&lt;/p&gt;
&lt;p&gt;LLMs have non-deterministic outputs, meaning you can't exactly predict what they'll say. While the output varies even for identical inputs, models do sometimes regurgitate something from their training data—if trained with personal data, the output could be a violation of user privacy. In the event copyrighted data makes it into training data (either accidentally or on purpose), its appearance in outputs can cause a different kind of headache for devs. Differential privacy can prevent such memorization by introducing calibrated noise during the training phase.&lt;/p&gt;
&lt;p&gt;Adding differential privacy to a model comes with drawbacks in terms of accuracy and compute requirements. No one has bothered to figure out the degree to which that alters the scaling laws of AI models until now. The team worked from the assumption that model performance would be primarily affected by the noise-batch ratio, which compares the volume of randomized noise to the size of the original training data.&lt;/p&gt;
&lt;p&gt;By running experiments with varying model sizes and noise-batch ratios, the team established a basic understanding of differential privacy scaling laws, which is a balance between the compute budget, privacy budget, and data budget. In short, more noise leads to lower-quality outputs unless offset with a higher compute budget (FLOPs) or data budget (tokens). The paper details the scaling laws for private LLMs, which could help developers find an ideal noise-batch ratio to make a model more private.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Building VaultGemma&lt;/h2&gt;
&lt;p&gt;This work on differential privacy has led to a new open-weight Google model called VaultGemma. The model uses differential privacy to reduce the possibility of memorization, which could change how Google builds privacy into its future AI agents. For now, though, the company's first differential privacy model is an experiment.&lt;/p&gt;
&lt;p&gt;VaultGemma is based on the Gemma 2 foundational model, which is a generation behind Google's latest open model family. The team used the scaling laws derived from its initial testing to train VaultGemma with the optimal&amp;nbsp;differential privacy. This model isn't particularly large in the grand scheme, clocking in at just 1 billion parameters. However, Google Research says VaultGemma performs similarly to non-private models of a similar size.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117184 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="VaultGemma tests" class="fullwidth full" height="547" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma4_Performance.width-1250.png" width="1250" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      VaultGemma does surprisingly well versus non-private AI models.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The team hopes this work on differential privacy scaling laws will help others efficiently allocate resources to train private AI models. This probably won't change the way the largest and most capable AI models operate—performance is everything in supersized general models. And regardless, the research suggests that differential privacy works better with smaller LLMs, like the purpose-built models that power specific AI features.&lt;/p&gt;
&lt;p&gt;You can download VaultGemma now from Hugging Face and Kaggle. Like other Gemma models, this one has open weights, but it's not quite open source. While Google will let you modify and distribute Gemma models, you must agree not to use them for nefarious purposes and to distribute a copy of the Gemma license with any and all modified versions.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google Research shows that AI models can keep training data private.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="450" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma.jpg" width="800" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The companies seeking to build larger AI models have been increasingly stymied by a lack of high-quality training data. As tech firms scour the web for more data to feed their models, they could increasingly rely on potentially sensitive user data. A team at Google Research is exploring new techniques to make the resulting large language models (LLMs) less likely to "memorize" any of that content.&lt;/p&gt;
&lt;p&gt;LLMs have non-deterministic outputs, meaning you can't exactly predict what they'll say. While the output varies even for identical inputs, models do sometimes regurgitate something from their training data—if trained with personal data, the output could be a violation of user privacy. In the event copyrighted data makes it into training data (either accidentally or on purpose), its appearance in outputs can cause a different kind of headache for devs. Differential privacy can prevent such memorization by introducing calibrated noise during the training phase.&lt;/p&gt;
&lt;p&gt;Adding differential privacy to a model comes with drawbacks in terms of accuracy and compute requirements. No one has bothered to figure out the degree to which that alters the scaling laws of AI models until now. The team worked from the assumption that model performance would be primarily affected by the noise-batch ratio, which compares the volume of randomized noise to the size of the original training data.&lt;/p&gt;
&lt;p&gt;By running experiments with varying model sizes and noise-batch ratios, the team established a basic understanding of differential privacy scaling laws, which is a balance between the compute budget, privacy budget, and data budget. In short, more noise leads to lower-quality outputs unless offset with a higher compute budget (FLOPs) or data budget (tokens). The paper details the scaling laws for private LLMs, which could help developers find an ideal noise-batch ratio to make a model more private.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Building VaultGemma&lt;/h2&gt;
&lt;p&gt;This work on differential privacy has led to a new open-weight Google model called VaultGemma. The model uses differential privacy to reduce the possibility of memorization, which could change how Google builds privacy into its future AI agents. For now, though, the company's first differential privacy model is an experiment.&lt;/p&gt;
&lt;p&gt;VaultGemma is based on the Gemma 2 foundational model, which is a generation behind Google's latest open model family. The team used the scaling laws derived from its initial testing to train VaultGemma with the optimal&amp;nbsp;differential privacy. This model isn't particularly large in the grand scheme, clocking in at just 1 billion parameters. However, Google Research says VaultGemma performs similarly to non-private models of a similar size.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2117184 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="VaultGemma tests" class="fullwidth full" height="547" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/VaultGemma4_Performance.width-1250.png" width="1250" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      VaultGemma does surprisingly well versus non-private AI models.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The team hopes this work on differential privacy scaling laws will help others efficiently allocate resources to train private AI models. This probably won't change the way the largest and most capable AI models operate—performance is everything in supersized general models. And regardless, the research suggests that differential privacy works better with smaller LLMs, like the purpose-built models that power specific AI features.&lt;/p&gt;
&lt;p&gt;You can download VaultGemma now from Hugging Face and Kaggle. Like other Gemma models, this one has open weights, but it's not quite open source. While Google will let you modify and distribute Gemma models, you must agree not to use them for nefarious purposes and to distribute a copy of the Gemma license with any and all modified versions.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/google-releases-vaultgemma-its-first-privacy-preserving-llm/</guid><pubDate>Mon, 15 Sep 2025 21:04:04 +0000</pubDate></item></channel></rss>