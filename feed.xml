<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 17 Sep 2025 06:31:21 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>CodeRabbit raises $60M, valuing the 2-year-old AI code review startup at $550M (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/coderabbit-raises-60m-valuing-the-2-year-old-ai-code-review-startup-at-550m/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2080972792.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Harjot Gill was running FluxNinja, an observability startup he co-founded several years after selling his first startup Netsil to Nutanix in 2018, when he noticed a curious trend. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had a team of remote engineers who were starting to adopt AI code generation on GitHub Copilot,” Gill told TechCrunch. “We saw that adoption happen, and it was very clear to me that as a second-order effect, it’s going to cause bottlenecks in the code review.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In early 2023, Gill started CodeRabbit, an AI-powered code review platform, and it acquired FlexNinja.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gill’s prediction has come true: developers are now regularly using AI coding assistants to generate code, but the output is often buggy, forcing engineers to spend a lot of time on corrections.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CodeRabbit can help catch some of the errors. The business has been growing 20% a month and is now making more than $15 million in annual recurring revenue (ARR), according to Gill.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors find the startup’s growth exciting. On Tuesday, CodeRabbit announced that it raised a $60 million Series B, valuing the company at $550 million. The round, which brought the startup’s total funding to $88 million, was led by Scale Venture Partners with participation of NVentures, Nvidia’s venture capital arm, and returning investors including CRV. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CodeRabbit is helping companies like Chegg, Groupon, and Mercury, along with over 8,000 other businesses, save time on the famously frustrating task of code review, which has become even more time-consuming with the rise of AI-generated code.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Since CodeRabbit understands a company’s codebase, it can identify bugs and provide feedback, acting like a coworker, Gill said.&amp;nbsp;He added that companies using CodeRabbit can cut the number of humans working on code-review by half.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As with most areas of AI, CodeRabbit has competition. Startup rivals include Graphite, which secured a $52 million Series B led by Accel earlier this year, and Greptile, which we reported is in talks for a $30 million Series A round with Benchmark. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While leading AI coding assistants like Anthropic’s Claude Code and Cursor also offer AI-powered code review capabilities, Gill is betting that customers will prefer a standalone offering in the long term. “CodeRabbit is a lot more comprehensive in terms of depth and technical breadth than bundled solutions,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Whether his prediction will turn out to be correct remains to be seen. But for now, thousands of developers are clearly happy to pay CodeRabbit $30 a month. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even with the growing popularity of AI code review tools like CodeRabbit, AI solutions still can’t yet be fully trusted to fix the bugs and “unusable” code written by AI. The unreliability of AI-generated code has given rise to a new corporate role: the vibe code cleanup specialist.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2080972792.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Harjot Gill was running FluxNinja, an observability startup he co-founded several years after selling his first startup Netsil to Nutanix in 2018, when he noticed a curious trend. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had a team of remote engineers who were starting to adopt AI code generation on GitHub Copilot,” Gill told TechCrunch. “We saw that adoption happen, and it was very clear to me that as a second-order effect, it’s going to cause bottlenecks in the code review.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In early 2023, Gill started CodeRabbit, an AI-powered code review platform, and it acquired FlexNinja.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gill’s prediction has come true: developers are now regularly using AI coding assistants to generate code, but the output is often buggy, forcing engineers to spend a lot of time on corrections.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CodeRabbit can help catch some of the errors. The business has been growing 20% a month and is now making more than $15 million in annual recurring revenue (ARR), according to Gill.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors find the startup’s growth exciting. On Tuesday, CodeRabbit announced that it raised a $60 million Series B, valuing the company at $550 million. The round, which brought the startup’s total funding to $88 million, was led by Scale Venture Partners with participation of NVentures, Nvidia’s venture capital arm, and returning investors including CRV. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CodeRabbit is helping companies like Chegg, Groupon, and Mercury, along with over 8,000 other businesses, save time on the famously frustrating task of code review, which has become even more time-consuming with the rise of AI-generated code.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Since CodeRabbit understands a company’s codebase, it can identify bugs and provide feedback, acting like a coworker, Gill said.&amp;nbsp;He added that companies using CodeRabbit can cut the number of humans working on code-review by half.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As with most areas of AI, CodeRabbit has competition. Startup rivals include Graphite, which secured a $52 million Series B led by Accel earlier this year, and Greptile, which we reported is in talks for a $30 million Series A round with Benchmark. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While leading AI coding assistants like Anthropic’s Claude Code and Cursor also offer AI-powered code review capabilities, Gill is betting that customers will prefer a standalone offering in the long term. “CodeRabbit is a lot more comprehensive in terms of depth and technical breadth than bundled solutions,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Whether his prediction will turn out to be correct remains to be seen. But for now, thousands of developers are clearly happy to pay CodeRabbit $30 a month. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even with the growing popularity of AI code review tools like CodeRabbit, AI solutions still can’t yet be fully trusted to fix the bugs and “unusable” code written by AI. The unreliability of AI-generated code has given rise to a new corporate role: the vibe code cleanup specialist.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/coderabbit-raises-60m-valuing-the-2-year-old-ai-code-review-startup-at-550m/</guid><pubDate>Tue, 16 Sep 2025 19:00:00 +0000</pubDate></item><item><title>Silicon Valley bets big on ‘environments’ to train AI agents (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/silicon-valley-bets-big-on-environments-to-train-ai-agents/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1356382582.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, Big Tech CEOs have touted visions of AI agents that can autonomously use software applications to complete tasks for people. But take today’s consumer AI agents out for a spin, whether it’s OpenAI’s ChatGPT Agent or Perplexity’s Comet, and you’ll quickly realize how limited the technology still is. Making AI agents more robust may take a new set of techniques that the industry is still discovering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of those techniques is carefully simulating workspaces where agents can be trained on multi-step tasks — known as reinforcement learning (RL) environments. Similarly to how labeled datasets powered the last wave of AI, RL environments are starting to look like a critical element in the development of agents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI researchers, founders, and investors tell TechCrunch that leading AI labs are now demanding more RL environments, and there’s no shortage of startups hoping to supply them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“All the big AI labs are building RL environments in-house,” said Jennifer Li, general partner at Andreessen Horowitz, in an interview with TechCrunch. “But as you can imagine, creating these datasets is very complex, so AI labs are also looking at third party vendors that can create high quality environments and evaluations. Everyone is looking at this space.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The push for RL environments has minted a new class of well-funded startups, such as Mechanize and Prime Intellect, that aim to lead the space. Meanwhile, large data-labeling companies like Mercor and Surge say they’re investing more in RL environments to keep pace with the industry’s shifts from static datasets to interactive simulations. The major labs are considering investing heavily too: according to The Information, leaders at Anthropic have discussed spending more than $1 billion on RL environments over the next year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hope for investors and founders is that one of these startups emerge as the “Scale AI for environments,” referring to the $29 billion data labelling powerhouse that powered the chatbot era.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The question is whether RL environments will truly push the frontier of AI progress.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-what-is-an-rl-environment"&gt;What is an RL environment?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;At their core, RL environments are training grounds that simulate what an AI agent would be doing in a real software application. One founder described building them in recent interview “like creating a very boring video game.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, an environment could simulate a Chrome browser and task an AI agent with purchasing a pair of socks on Amazon. The agent is graded on its performance and sent a reward signal when it succeeds (in this case, buying a worthy pair of socks).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While such a task sounds relatively simple, there are a lot of places where an AI agent could get tripped up. It might get lost navigating the web page’s drop down menus, or buy too many socks. And because developers can’t predict exactly what wrong turn an agent will take, the environment itself has to be robust enough to capture any unexpected behavior, and still deliver useful feedback. That makes building environments far more complex than a static dataset.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Some environments are quite elaborate, allowing for AI agents to use tools, access the internet, or use various software applications to complete a given task. Others are more narrow, aimed at helping an agent learn specific tasks in enterprise software applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While RL environments are the hot thing in Silicon Valley right now, there’s a lot of precedent for using this technique. One of OpenAI’s first projects back in 2016 was building “RL Gyms,” which were quite similar to the modern conception of environments. The same year, Google DeepMind’s AlphaGo AI system beat a world champion at the board game, Go. It also used RL techniques within a simulated environment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s unique about today’s environments is that researchers are trying to build computer-using AI agents with large transformer models. Unlike AlphaGo, which was a specialized AI system working in a closed environments, today’s AI agents are trained to have more general capabilities. AI researchers today have a stronger starting point, but also a complicated goal where more can go wrong. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-crowded-field"&gt;&lt;strong&gt;A crowded field&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AI data labeling companies like Scale AI, Surge, and Mercor are trying to meet the moment and build out RL environments. These companies have more resources than many startups in the space, as well as deep relationships with AI labs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Surge CEO Edwin Chen tells TechCrunch he’s recently seen a “significant increase” in demand for RL environments within AI labs. Surge — which reportedly generated $1.2 billion in revenue last year from working with AI labs like OpenAI, Google, Anthropic and Meta — recently spun up a new internal organization specifically tasked with building out RL environments, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Close behind Surge is Mercor, a startup valued at $10 billion, which has also worked with OpenAI, Meta, and Anthropic. Mercor is pitching investors on its business building RL environments for domain specific tasks such as coding, healthcare, and law, according to marketing materials seen by TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mercor CEO Brendan Foody told TechCrunch in an interview that “few understand how large the opportunity around RL environments truly is.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Scale AI used to dominate the data labeling space, but has lost ground since Meta invested $14 billion and hired away its CEO. Since then, Google and OpenAI dropped Scale AI as a data provider, and the startup even faces competition for data labelling work inside of Meta. But still, Scale is trying to meet the moment and build environments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“This is just the nature of the business [Scale AI] is in,” said Chetan Rane, Scale AI’s head of product for agents and RL environments. “Scale has proven its ability to adapt quickly. We did this in the early days of autonomous vehicles, our first business unit. When ChatGPT came out, Scale AI adapted to that. And now, once again, we’re adapting to new frontier spaces like agents and environments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some newer players are focusing exclusively on environments from the outset. Among them is Mechanize, a startup founded roughly six months ago with the audacious goal of “automating all jobs.” However, co-founder Matthew Barnett tells TechCrunch that his firm is starting with RL environments for AI coding agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mechanize aims to supply AI labs with a small number of robust RL environments, Barnett says, rather than larger data firms that create a wide range of simple RL environments. To this point, the startup is offering software engineers $500,000 salaries to build RL environments — far higher than an hourly contractor could earn working at Scale AI or Surge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mechanize has already been working with Anthropic on RL environments, two sources familiar with the matter told TechCrunch. Mechanize and Anthropic declined to comment on the partnership.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other startups are betting that RL environments will be influential outside of AI labs. Prime Intellect — a startup backed by AI researcher Andrej Karpathy, Founders Fund, and Menlo Ventures — is targeting smaller developers with its RL environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Prime Intellect launched an RL environments hub, which aims to be a “Hugging Face for RL environments.” The idea is to give open-source developers access to the same resources that large AI labs have, and sell those developers access to computational resources in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Training generally capable agents in RL environments can be more computational expensive than previous AI training techniques, according to Prime Intellect researcher Will Brown. Alongside startups building RL environments, there’s another opportunity for GPU providers that can power the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“RL environments are going to be too large for any one company to dominate,” said Brown in an interview. “Part of what we’re doing is just trying to build good open-source infrastructure around it. The service we sell is compute, so it is a convenient onramp to using GPUs, but we’re thinking of this more in the long term.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-will-it-scale"&gt;&lt;strong&gt;Will it scale?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The open question around RL environments is whether the technique will scale like previous AI training methods.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Reinforcement learning has powered some of the biggest leaps in AI over the past year, including models like OpenAI’s o1 and Anthropic’s Claude Opus 4. Those are particularly important breakthroughs because the methods previously used to improve AI models are now showing diminishing returns.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Environments are part of AI labs’ bigger bet on RL, which many believe will continue to drive progress as they add more data and computational resources to the process. Some of the OpenAI researchers behind o1 previously told TechCrunch that the company originally invested in AI reasoning models — which were created through investments in RL and test-time-compute — because they thought it would scale nicely.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The best way to scale RL remains unclear, but environments seem like a promising contender. Instead of simply rewarding chatbots for text responses, they let agents operate in simulations with tools and computers at their disposal. That’s far more resource-intensive, but potentially more rewarding. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some are skeptical that all these RL environments will pan out. Ross Taylor, a former AI research lead with Meta that co-founded General Reasoning, tells TechCrunch that RL environments are prone to reward hacking. This is a process in which AI models cheat in order to get a reward, without really doing the task.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think people are underestimating how difficult it is to scale environments,” said Taylor. “Even the best publicly available [RL environments] typically don’t work without serious modification.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s Head of Engineering for its API business, Sherwin Wu, said in a recent podcast that he was “short” on RL environment startups. Wu noted that it’s a very competitive space, but also that AI research is evolving so quickly that it’s hard to serve AI labs well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Karpathy, an investor in Prime Intellect that has called RL environments a potential breakthrough, has also voiced caution for the RL space more broadly. In a post on X, he raised concerns about how much more AI progress can be squeezed out of RL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I am bullish on environments and agentic interactions but I am bearish on reinforcement learning specifically,” said Karpathy. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Update: A previous version of this article referred to Mechanize as Mechanize Work. It has been updated to reflect the company’s official name.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1356382582.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, Big Tech CEOs have touted visions of AI agents that can autonomously use software applications to complete tasks for people. But take today’s consumer AI agents out for a spin, whether it’s OpenAI’s ChatGPT Agent or Perplexity’s Comet, and you’ll quickly realize how limited the technology still is. Making AI agents more robust may take a new set of techniques that the industry is still discovering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of those techniques is carefully simulating workspaces where agents can be trained on multi-step tasks — known as reinforcement learning (RL) environments. Similarly to how labeled datasets powered the last wave of AI, RL environments are starting to look like a critical element in the development of agents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI researchers, founders, and investors tell TechCrunch that leading AI labs are now demanding more RL environments, and there’s no shortage of startups hoping to supply them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“All the big AI labs are building RL environments in-house,” said Jennifer Li, general partner at Andreessen Horowitz, in an interview with TechCrunch. “But as you can imagine, creating these datasets is very complex, so AI labs are also looking at third party vendors that can create high quality environments and evaluations. Everyone is looking at this space.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The push for RL environments has minted a new class of well-funded startups, such as Mechanize and Prime Intellect, that aim to lead the space. Meanwhile, large data-labeling companies like Mercor and Surge say they’re investing more in RL environments to keep pace with the industry’s shifts from static datasets to interactive simulations. The major labs are considering investing heavily too: according to The Information, leaders at Anthropic have discussed spending more than $1 billion on RL environments over the next year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hope for investors and founders is that one of these startups emerge as the “Scale AI for environments,” referring to the $29 billion data labelling powerhouse that powered the chatbot era.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The question is whether RL environments will truly push the frontier of AI progress.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-what-is-an-rl-environment"&gt;What is an RL environment?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;At their core, RL environments are training grounds that simulate what an AI agent would be doing in a real software application. One founder described building them in recent interview “like creating a very boring video game.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, an environment could simulate a Chrome browser and task an AI agent with purchasing a pair of socks on Amazon. The agent is graded on its performance and sent a reward signal when it succeeds (in this case, buying a worthy pair of socks).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While such a task sounds relatively simple, there are a lot of places where an AI agent could get tripped up. It might get lost navigating the web page’s drop down menus, or buy too many socks. And because developers can’t predict exactly what wrong turn an agent will take, the environment itself has to be robust enough to capture any unexpected behavior, and still deliver useful feedback. That makes building environments far more complex than a static dataset.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Some environments are quite elaborate, allowing for AI agents to use tools, access the internet, or use various software applications to complete a given task. Others are more narrow, aimed at helping an agent learn specific tasks in enterprise software applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While RL environments are the hot thing in Silicon Valley right now, there’s a lot of precedent for using this technique. One of OpenAI’s first projects back in 2016 was building “RL Gyms,” which were quite similar to the modern conception of environments. The same year, Google DeepMind’s AlphaGo AI system beat a world champion at the board game, Go. It also used RL techniques within a simulated environment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What’s unique about today’s environments is that researchers are trying to build computer-using AI agents with large transformer models. Unlike AlphaGo, which was a specialized AI system working in a closed environments, today’s AI agents are trained to have more general capabilities. AI researchers today have a stronger starting point, but also a complicated goal where more can go wrong. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-crowded-field"&gt;&lt;strong&gt;A crowded field&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AI data labeling companies like Scale AI, Surge, and Mercor are trying to meet the moment and build out RL environments. These companies have more resources than many startups in the space, as well as deep relationships with AI labs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Surge CEO Edwin Chen tells TechCrunch he’s recently seen a “significant increase” in demand for RL environments within AI labs. Surge — which reportedly generated $1.2 billion in revenue last year from working with AI labs like OpenAI, Google, Anthropic and Meta — recently spun up a new internal organization specifically tasked with building out RL environments, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Close behind Surge is Mercor, a startup valued at $10 billion, which has also worked with OpenAI, Meta, and Anthropic. Mercor is pitching investors on its business building RL environments for domain specific tasks such as coding, healthcare, and law, according to marketing materials seen by TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mercor CEO Brendan Foody told TechCrunch in an interview that “few understand how large the opportunity around RL environments truly is.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Scale AI used to dominate the data labeling space, but has lost ground since Meta invested $14 billion and hired away its CEO. Since then, Google and OpenAI dropped Scale AI as a data provider, and the startup even faces competition for data labelling work inside of Meta. But still, Scale is trying to meet the moment and build environments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“This is just the nature of the business [Scale AI] is in,” said Chetan Rane, Scale AI’s head of product for agents and RL environments. “Scale has proven its ability to adapt quickly. We did this in the early days of autonomous vehicles, our first business unit. When ChatGPT came out, Scale AI adapted to that. And now, once again, we’re adapting to new frontier spaces like agents and environments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some newer players are focusing exclusively on environments from the outset. Among them is Mechanize, a startup founded roughly six months ago with the audacious goal of “automating all jobs.” However, co-founder Matthew Barnett tells TechCrunch that his firm is starting with RL environments for AI coding agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mechanize aims to supply AI labs with a small number of robust RL environments, Barnett says, rather than larger data firms that create a wide range of simple RL environments. To this point, the startup is offering software engineers $500,000 salaries to build RL environments — far higher than an hourly contractor could earn working at Scale AI or Surge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mechanize has already been working with Anthropic on RL environments, two sources familiar with the matter told TechCrunch. Mechanize and Anthropic declined to comment on the partnership.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other startups are betting that RL environments will be influential outside of AI labs. Prime Intellect — a startup backed by AI researcher Andrej Karpathy, Founders Fund, and Menlo Ventures — is targeting smaller developers with its RL environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Prime Intellect launched an RL environments hub, which aims to be a “Hugging Face for RL environments.” The idea is to give open-source developers access to the same resources that large AI labs have, and sell those developers access to computational resources in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Training generally capable agents in RL environments can be more computational expensive than previous AI training techniques, according to Prime Intellect researcher Will Brown. Alongside startups building RL environments, there’s another opportunity for GPU providers that can power the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“RL environments are going to be too large for any one company to dominate,” said Brown in an interview. “Part of what we’re doing is just trying to build good open-source infrastructure around it. The service we sell is compute, so it is a convenient onramp to using GPUs, but we’re thinking of this more in the long term.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-will-it-scale"&gt;&lt;strong&gt;Will it scale?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The open question around RL environments is whether the technique will scale like previous AI training methods.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Reinforcement learning has powered some of the biggest leaps in AI over the past year, including models like OpenAI’s o1 and Anthropic’s Claude Opus 4. Those are particularly important breakthroughs because the methods previously used to improve AI models are now showing diminishing returns.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Environments are part of AI labs’ bigger bet on RL, which many believe will continue to drive progress as they add more data and computational resources to the process. Some of the OpenAI researchers behind o1 previously told TechCrunch that the company originally invested in AI reasoning models — which were created through investments in RL and test-time-compute — because they thought it would scale nicely.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The best way to scale RL remains unclear, but environments seem like a promising contender. Instead of simply rewarding chatbots for text responses, they let agents operate in simulations with tools and computers at their disposal. That’s far more resource-intensive, but potentially more rewarding. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some are skeptical that all these RL environments will pan out. Ross Taylor, a former AI research lead with Meta that co-founded General Reasoning, tells TechCrunch that RL environments are prone to reward hacking. This is a process in which AI models cheat in order to get a reward, without really doing the task.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think people are underestimating how difficult it is to scale environments,” said Taylor. “Even the best publicly available [RL environments] typically don’t work without serious modification.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s Head of Engineering for its API business, Sherwin Wu, said in a recent podcast that he was “short” on RL environment startups. Wu noted that it’s a very competitive space, but also that AI research is evolving so quickly that it’s hard to serve AI labs well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Karpathy, an investor in Prime Intellect that has called RL environments a potential breakthrough, has also voiced caution for the RL space more broadly. In a post on X, he raised concerns about how much more AI progress can be squeezed out of RL.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I am bullish on environments and agentic interactions but I am bearish on reinforcement learning specifically,” said Karpathy. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Update: A previous version of this article referred to Mechanize as Mechanize Work. It has been updated to reflect the company’s official name.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/silicon-valley-bets-big-on-environments-to-train-ai-agents/</guid><pubDate>Tue, 16 Sep 2025 19:00:48 +0000</pubDate></item><item><title>ChatGPT may soon require ID verification from adults, CEO says (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/chatgpt-may-soon-require-id-verification-from-adults-ceo-says/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Chatbot will "default to the under-18 experience" when age is uncertain after teen suicide lawsuit.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Photo of a teenager using a smartphone lying in bed late at night" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/teen_using_smartphone-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Photo of a teenager using a smartphone lying in bed late at night" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/teen_using_smartphone-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Javier Zayaz via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Tuesday, OpenAI announced plans to develop an automated age-prediction system that will determine whether ChatGPT users are over or under 18, automatically directing younger users to a restricted version of the AI chatbot. The company also confirmed that parental controls will launch by the end of September.&lt;/p&gt;
&lt;p&gt;In a companion blog post, OpenAI CEO Sam Altman acknowledged the company is explicitly "prioritizing safety ahead of privacy and freedom for teens," even though it means that adults may eventually need to verify their age to use a more unrestricted version of the service.&lt;/p&gt;
&lt;p&gt;"In some cases or countries we may also ask for an ID," Altman wrote. "We know this is a privacy compromise for adults but believe it is a worthy tradeoff." Altman admitted that "not everyone will agree with how we are resolving that conflict" between user privacy and teen safety.&lt;/p&gt;
&lt;p&gt;The announcements arrives weeks after a lawsuit filed by parents whose 16-year-old son died by suicide following extensive interactions with ChatGPT. According to the lawsuit, the chatbot provided detailed instructions, romanticized suicide methods, and discouraged the teen from seeking help from his family while OpenAI's system tracked 377 messages flagged for self-harm content without intervening.&lt;/p&gt;
&lt;p&gt;The proposed age-prediction system represents a non-trivial technical undertaking for OpenAI, and whether AI-powered age detection can actually work remains a significant open question. When the AI system in development identifies users under 18, OpenAI plans to automatically route the user to a modified ChatGPT experience that blocks graphic sexual content and includes other age-appropriate restrictions. The company says it will "take the safer route" when uncertain about a user's age, defaulting to the restricted experience and requiring adults to verify their age to access full functionality.&lt;/p&gt;
&lt;p&gt;The company didn't specify what technology it plans to use for age prediction or provide a timeline for deployment beyond saying it's "building toward" the system. OpenAI acknowledged that developing effective age-verification systems isn't straightforward. "Even the most advanced systems will sometimes struggle to predict age," the company wrote.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Recent academic research offers both possibilities and warnings for OpenAI's age-detection approach. A 2024 Georgia Tech study achieved 96 percent accuracy detecting underage users from text—but only in controlled conditions with cooperative subjects. When attempting to classify specific age groups, accuracy dropped to 54 percent, with the models completely failing for some demographics. More concerning: The research used curated datasets where ages were known and users weren't trying to deceive the system—luxuries OpenAI won't have with some of ChatGPT's users actively trying to bypass restrictions.&lt;/p&gt;
&lt;p&gt;While YouTube and Instagram can potentially analyze faces, posting patterns, and social networks to determine age, ChatGPT must rely solely on conversational text, which can be an unreliable signal of user age. Research on Twitter-user age prediction from 2017 conducted by Research Triangle International found that even with metadata like follower counts and posting frequency, text-based models "need continual updating" because "cohort effects in language usage vary over time," with terms, like "LOL," for example, shifting from teen to adult usage patterns.&lt;/p&gt;
&lt;h2&gt;Planned parental oversight features&lt;/h2&gt;
&lt;p&gt;Beyond age detection, the ChatGPT parental controls arriving this month will reportedly allow parents to link their accounts with their teenagers' accounts (minimum age 13) through email invitations. Once connected, parents can disable specific features, including ChatGPT's memory function and chat history storage, set blackout hours when teens cannot use the service, and receive notifications when the system "detects" their teen experiencing acute distress.&lt;/p&gt;
&lt;p&gt;That last feature comes with a significant caveat: OpenAI states that in rare emergency situations where parents cannot be reached, the company "may involve law enforcement as a next step." The company says expert input will guide this feature's implementation, though it didn't specify which experts or organizations are providing that guidance.&lt;/p&gt;
&lt;p&gt;The controls will also let parents "help guide how ChatGPT responds to their teen, based on teen-specific model behavior rules," though OpenAI didn't yet elaborate on what those rules entail or how parents would configure them.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;OpenAI joins other tech companies that have tried youth-specific versions of their services. YouTube Kids, Instagram Teen Accounts, and TikTok's under-16 restrictions represent similar efforts to create "safer" digital spaces for young users, but teens routinely circumvent age verification through false birthdate entries, borrowed accounts, or technical workarounds. A 2024 BBC report found that 22 percent of children lie on social media platforms about being 18 or over.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Privacy vs. safety trade-offs&lt;/h2&gt;
&lt;p&gt;Despite the unproven technology behind AI age detection, OpenAI still plans to press ahead with its system, acknowledging that adults will sacrifice privacy and flexibility to make it work. Altman acknowledged the tension this creates, given the intimate nature of AI interactions.&lt;/p&gt;
&lt;p&gt;"People talk to AI about increasingly personal things; it is different from previous generations of technology, and we believe that they may be one of the most personally sensitive accounts you’ll ever have," Altman wrote in his post.&lt;/p&gt;
&lt;p&gt;The safety push follows OpenAI's acknowledgment in August that ChatGPT's safety measures can break down during lengthy conversations—precisely when vulnerable users might need them most. "As the back-and-forth grows, parts of the model's safety training may degrade," the company wrote at the time, noting that while ChatGPT might correctly direct users to suicide hotlines initially, "after many messages over a long period of time, it might eventually offer an answer that goes against our safeguards."&lt;/p&gt;
&lt;p&gt;This degradation of safeguards proved tragically consequential in the Adam Raine case. According to the lawsuit, ChatGPT mentioned suicide 1,275 times in conversations with Adam—six times more often than the teen himself—while the system's safety protocols failed to intervene or notify anyone. Stanford University researchers found in July that AI therapy bots can provide dangerous mental health advice, and recent reports have documented cases of vulnerable users developing what some experts informally call "AI Psychosis" after extended chatbot interactions.&lt;/p&gt;
&lt;p&gt;OpenAI didn't address how the age-prediction system would handle existing users who have been using ChatGPT without age verification, whether the system would apply to API access, or how it plans to verify ages in jurisdictions with different legal definitions of adulthood.&lt;/p&gt;
&lt;p&gt;All users, regardless of age, will continue to see in-app reminders during long ChatGPT sessions that encourage taking breaks—a feature OpenAI introduced earlier this year after reports of users spending marathon sessions with the chatbot.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Chatbot will "default to the under-18 experience" when age is uncertain after teen suicide lawsuit.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Photo of a teenager using a smartphone lying in bed late at night" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/teen_using_smartphone-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Photo of a teenager using a smartphone lying in bed late at night" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/teen_using_smartphone-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Javier Zayaz via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Tuesday, OpenAI announced plans to develop an automated age-prediction system that will determine whether ChatGPT users are over or under 18, automatically directing younger users to a restricted version of the AI chatbot. The company also confirmed that parental controls will launch by the end of September.&lt;/p&gt;
&lt;p&gt;In a companion blog post, OpenAI CEO Sam Altman acknowledged the company is explicitly "prioritizing safety ahead of privacy and freedom for teens," even though it means that adults may eventually need to verify their age to use a more unrestricted version of the service.&lt;/p&gt;
&lt;p&gt;"In some cases or countries we may also ask for an ID," Altman wrote. "We know this is a privacy compromise for adults but believe it is a worthy tradeoff." Altman admitted that "not everyone will agree with how we are resolving that conflict" between user privacy and teen safety.&lt;/p&gt;
&lt;p&gt;The announcements arrives weeks after a lawsuit filed by parents whose 16-year-old son died by suicide following extensive interactions with ChatGPT. According to the lawsuit, the chatbot provided detailed instructions, romanticized suicide methods, and discouraged the teen from seeking help from his family while OpenAI's system tracked 377 messages flagged for self-harm content without intervening.&lt;/p&gt;
&lt;p&gt;The proposed age-prediction system represents a non-trivial technical undertaking for OpenAI, and whether AI-powered age detection can actually work remains a significant open question. When the AI system in development identifies users under 18, OpenAI plans to automatically route the user to a modified ChatGPT experience that blocks graphic sexual content and includes other age-appropriate restrictions. The company says it will "take the safer route" when uncertain about a user's age, defaulting to the restricted experience and requiring adults to verify their age to access full functionality.&lt;/p&gt;
&lt;p&gt;The company didn't specify what technology it plans to use for age prediction or provide a timeline for deployment beyond saying it's "building toward" the system. OpenAI acknowledged that developing effective age-verification systems isn't straightforward. "Even the most advanced systems will sometimes struggle to predict age," the company wrote.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Recent academic research offers both possibilities and warnings for OpenAI's age-detection approach. A 2024 Georgia Tech study achieved 96 percent accuracy detecting underage users from text—but only in controlled conditions with cooperative subjects. When attempting to classify specific age groups, accuracy dropped to 54 percent, with the models completely failing for some demographics. More concerning: The research used curated datasets where ages were known and users weren't trying to deceive the system—luxuries OpenAI won't have with some of ChatGPT's users actively trying to bypass restrictions.&lt;/p&gt;
&lt;p&gt;While YouTube and Instagram can potentially analyze faces, posting patterns, and social networks to determine age, ChatGPT must rely solely on conversational text, which can be an unreliable signal of user age. Research on Twitter-user age prediction from 2017 conducted by Research Triangle International found that even with metadata like follower counts and posting frequency, text-based models "need continual updating" because "cohort effects in language usage vary over time," with terms, like "LOL," for example, shifting from teen to adult usage patterns.&lt;/p&gt;
&lt;h2&gt;Planned parental oversight features&lt;/h2&gt;
&lt;p&gt;Beyond age detection, the ChatGPT parental controls arriving this month will reportedly allow parents to link their accounts with their teenagers' accounts (minimum age 13) through email invitations. Once connected, parents can disable specific features, including ChatGPT's memory function and chat history storage, set blackout hours when teens cannot use the service, and receive notifications when the system "detects" their teen experiencing acute distress.&lt;/p&gt;
&lt;p&gt;That last feature comes with a significant caveat: OpenAI states that in rare emergency situations where parents cannot be reached, the company "may involve law enforcement as a next step." The company says expert input will guide this feature's implementation, though it didn't specify which experts or organizations are providing that guidance.&lt;/p&gt;
&lt;p&gt;The controls will also let parents "help guide how ChatGPT responds to their teen, based on teen-specific model behavior rules," though OpenAI didn't yet elaborate on what those rules entail or how parents would configure them.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;OpenAI joins other tech companies that have tried youth-specific versions of their services. YouTube Kids, Instagram Teen Accounts, and TikTok's under-16 restrictions represent similar efforts to create "safer" digital spaces for young users, but teens routinely circumvent age verification through false birthdate entries, borrowed accounts, or technical workarounds. A 2024 BBC report found that 22 percent of children lie on social media platforms about being 18 or over.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Privacy vs. safety trade-offs&lt;/h2&gt;
&lt;p&gt;Despite the unproven technology behind AI age detection, OpenAI still plans to press ahead with its system, acknowledging that adults will sacrifice privacy and flexibility to make it work. Altman acknowledged the tension this creates, given the intimate nature of AI interactions.&lt;/p&gt;
&lt;p&gt;"People talk to AI about increasingly personal things; it is different from previous generations of technology, and we believe that they may be one of the most personally sensitive accounts you’ll ever have," Altman wrote in his post.&lt;/p&gt;
&lt;p&gt;The safety push follows OpenAI's acknowledgment in August that ChatGPT's safety measures can break down during lengthy conversations—precisely when vulnerable users might need them most. "As the back-and-forth grows, parts of the model's safety training may degrade," the company wrote at the time, noting that while ChatGPT might correctly direct users to suicide hotlines initially, "after many messages over a long period of time, it might eventually offer an answer that goes against our safeguards."&lt;/p&gt;
&lt;p&gt;This degradation of safeguards proved tragically consequential in the Adam Raine case. According to the lawsuit, ChatGPT mentioned suicide 1,275 times in conversations with Adam—six times more often than the teen himself—while the system's safety protocols failed to intervene or notify anyone. Stanford University researchers found in July that AI therapy bots can provide dangerous mental health advice, and recent reports have documented cases of vulnerable users developing what some experts informally call "AI Psychosis" after extended chatbot interactions.&lt;/p&gt;
&lt;p&gt;OpenAI didn't address how the age-prediction system would handle existing users who have been using ChatGPT without age verification, whether the system would apply to API access, or how it plans to verify ages in jurisdictions with different legal definitions of adulthood.&lt;/p&gt;
&lt;p&gt;All users, regardless of age, will continue to see in-app reminders during long ChatGPT sessions that encourage taking breaks—a feature OpenAI introduced earlier this year after reports of users spending marathon sessions with the chatbot.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/chatgpt-may-soon-require-id-verification-from-adults-ceo-says/</guid><pubDate>Tue, 16 Sep 2025 20:09:22 +0000</pubDate></item><item><title>The AI Makers: NVIDIA Partners in UK Advance Physical and Agentic AI, Robotics, Life Sciences and More (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/uk-partner-ecosystem-ai-makers/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The U.K. is driving investments in sovereign AI, using the technology to advance industries like manufacturing, life sciences and more.&lt;/p&gt;
&lt;p&gt;During NVIDIA founder and CEO Jensen Huang’s visit to the U.K. this week, NVIDIA highlighted how it is working with a broad ecosystem of AI makers across the nation on applications in physical and agentic AI, robotics and healthcare.&lt;/p&gt;
&lt;p&gt;Such partner advancements support the U.K.’s AI Action Opportunities Plan, published earlier this year, which includes these key pillars:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Infographic that includes three pillars of the U.K.’s AI Action Opportunities Plan: 1) Invest in the foundations of AI. The U.K. needs world-class computing and data infrastructure, access to talent and regulation. 2) Push hard on cross-economy AI adoption. The public sector should rapidly pilot and scale AI products and services, and encourage the private sector to do the same. 3) Position the UK to be an AI maker, not an AI taker. The U.K. should aim to have national champions at critical layers of the AI stack so the U.K. benefits economically from AI advancement and has influence on future AI’s values, safety and government." class="aligncenter size-large wp-image-84827" height="672" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/uk-ai-action-plan-infographic-1680x672.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Advancing the UK Technology Ecosystem&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Work to build the U.K.’s AI foundation has already begun, with support from the nation’s rich research and startup ecosystem along with technology leaders.&lt;/p&gt;
&lt;p&gt;Funded by U.K. Research and Innovation and built on NVIDIA Grace Hopper Superchips, &lt;b&gt;Isambard-AI&lt;/b&gt; — the U.K.’s most powerful AI supercomputer based at the University of Bristol, which launched in July — is accelerating national projects including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;UK-LLM&lt;/b&gt;, a large language model project developed by University College London, Bangor University and NVIDIA. UK-LLM uses NVIDIA Nemotron reasoning models to support national languages like Welsh, as well as English, to improve public service delivery in sectors like healthcare and education.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nightingale AI&lt;/b&gt;, a sovereign, multimodal health foundation model led by Imperial College London and trained on U.K. and US health data, which is designed to be used for numerous health applications including earlier diagnoses and personalized care.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;PolluGen&lt;/b&gt;, a new high-resolution pollution dispersion model developed by the University of Manchester, using NVIDIA CorrDiff and Earth-2 Studio. The model can use regional health and other data to help inform citizens and policymakers of air-quality impacts.&lt;/li&gt;
&lt;li&gt;The &lt;b&gt;Ultrasound Foundation Model&lt;/b&gt;, led by researchers at Queen Mary University of London. The model is built for ultrasound imaging, focusing on rheumatoid arthritis patient analysis and creating a reproducible, publicly accessible AI model for medical imaging.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Gen Model in Ego-Sensed World&lt;/b&gt;, led by researchers at the University of Bristol, is analyzing visual data from more than 900 participants to train an AI model to better understand everyday tasks. The AI model could help predict future real-world interactions and support memory to aid independent living for dementia patients.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Electrostatics-aware foundation models, &lt;/b&gt;developed by researchers at the University of Cambridge in collaboration with NVIDIA. These are being trained as the first foundation models for atomic interactions that understand electrostatics in chemistry at the atomic level. To do this, the researchers are using more than 200 million molecular and material structures from the OMOL and OMAT databases with NVIDIA’s cuEquivariance library. The model will allow scientists to simulate materials and molecules that were previously too large or complex to handle.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, SCAN — a technology solutions provider with a strong focus on community, education and innovation — is collaborating with NVIDIA to address the growing AI skills gap across the U.K. through NVIDIA Deep Learning Institute courses and SCAN Springboard U.K., a community-driven initiative designed to foster peer-to-peer learning, market awareness, and mass training in AI and specialized workloads.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;AI for Robotics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA announced separately today it is collaborating with techUK, alongside educational autonomous systems leader Quanser and training provider QA, to strengthen the U.K.’s robotics and AI ecosystem.&lt;/p&gt;
&lt;p&gt;NVIDIA is also working with other leading U.K. robotics leaders to advance industries with physical AI.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Extend Robotics&lt;/b&gt; is accelerating safe, scalable robot deployment in vehicle manufacturing by combining extended reality-based teleoperation and advanced training systems — powered by NVIDIA Jetson AGX Orin modules, the NVIDIA Isaac Lab framework and NVIDIA Isaac GR00T models — enabling rapid skill acquisition and boosting safety and productivity.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Humanoid&lt;/b&gt; is developing a modular humanoid robot called HMND 01 for general tasks in warehouses and retail spaces. The robot is designed for seamless integration with human environments.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Materials Innovation Factory&lt;/b&gt; at the University of Liverpool is using NVIDIA tools and libraries to train a foundations model to predict material properties, as well as train robot scientists using NVIDIA Jetson Orin Nano modules to test these hypotheses within a fully automated lab environment.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;The National Robotarium&lt;/b&gt;, a U.K. hub for robotics innovation, is using NVIDIA robotics and AI frameworks to support cutting-edge, practical research and help early-stage robotics businesses grow.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Opteran&lt;/b&gt; is creating autonomy algorithms for robots that mirror how the brains of insects and animals process information, harnessing knowledge on 600 million years of evolution to make robotic systems as robust and efficient as nature.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Oxa&lt;/b&gt; is creating full-stack AI self-driving software for industrial and commercial fleets with the NVIDIA DRIVE platform. The software works in all weather and locations — even where GPS is unreliable. Through its collaboration with NVIDIA, Oxa is able to generate vast amounts of diverse and realistic synthetic data to support training and validation — significantly accelerating the development and deployment of its solutions.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Wayve&lt;/b&gt; is pioneering end-to-end deep learning for autonomous driving. Its next-generation AV2.0 Platform enables vehicles to quickly and safely adapt its driving intelligence to new, unseen environments without needing expensive sensors and high-definition maps&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;AI for Life Sciences&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Many U.K.-based life sciences companies are using NVIDIA technologies to take an AI-first approach to drug discovery, simulating therapies and drug design to achieve faster treatment testing.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Basecamp Research&lt;/b&gt;’s BaseData — a proprietary evolutionary dataset that’s 10x larger than comparable public sources — is now powering a new generation of large foundation models across diverse biological data types, accelerating the development of curative, programmable medicines.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;U.K. CEiSRI&lt;/b&gt; — the U.K. Centre of Excellence for In-Silico Regulatory Science and Innovation,&amp;nbsp; headquartered at the University of Manchester — is developing complex digital twins with NVIDIA technologies to test new treatments on large and diverse patient populations.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Isomorphic Labs&lt;/b&gt; has built a leading AI drug design engine comprising foundational AI models that can work across multiple therapeutic areas and drug modalities.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Peptone&lt;/b&gt; is pioneering a new class of safer, more effective medicines by applying its physics-driven AI platform to unlock the therapeutic potential of the entire proteome, with a focus on historically “undruggable” intrinsically disordered proteins.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Latent Labs&lt;/b&gt;’ generative AI model, Latent-X, allows scientists to create and test therapeutic molecules in silico, speeding up drug design for researchers.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Relation Therapeutics&lt;/b&gt; offers a foundational AI platform for target drug discovery, integrating lab-in-the-loop experimentation to understand disease biology and accelerate the discovery and development of new therapies.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Hologen AI&lt;/b&gt;, a spinout with cofounders from University College London and King’s College London, represents a new breed of AI-native companies — ones harnessing the power of AI to model complex human biology and medical interventions with high precision, making new drugs available for patients rapidly and at lower cost.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Oxford Nanopore&lt;/b&gt; is delivering information-rich, rapid, affordable and accessible molecular information — such as DNA and RNA sequence data — to scientific researchers, as well as users in clinical, biopharma and applied industrial communities.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Agentic and Generative AI Innovations&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;AI model builders and startups are working with NVIDIA to transform the U.K. technology sector with agentic and generative AI tools that advance productivity, from financial large language models to AI voice agents.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Aveni &lt;/b&gt;created a financial LLM using the NVIDIA NeMo software suite to power its next-generation agentic framework that can interact with live financial systems, communicate with customers and advise on risk outcomes while ensuring compliance, transparency and control.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;ElevenLabs&lt;/b&gt; develops AI voice technology that generates natural, ultrarealistic speech in over 70 languages using NVIDIA software and NVIDIA DGX B200 systems. Its models power real-time conversational agents, localization, storytelling and accessibility tools for people who have lost their voices, in addition to voicing audiobooks and animating video game characters.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;PolyAI&lt;/b&gt; deployed advanced conversational AI agents using NVIDIA Riva automatic speech recognition NVIDIA NIM microservices. The AI agents automate customer support, speak naturally over the phone and handle complex tasks such as authentication, order management, billing and reservations on a massive scale.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Recraft&lt;/b&gt; is producing state-of-the-art image generation and editing models, built with advanced design capabilities to support professional creative workflows. Recraft is using the NVIDIA TensorRT software development kit, enabling users to generate and edit images and graphics to speed workflows such as producing marketing materials, generating product mockups and editing visual content.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Speechmatics&lt;/b&gt; developed speech-to-text software using NVIDIA Dynamo-Triton and NVIDIA cuDNN software. Its automatic speech recognition software lets businesses and developers convert spoken language into written text, with support for dozens of languages.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Synthesia&lt;/b&gt; built an enterprise-focused AI video platform using NVIDIA Dynamo-Triton and other NVIDIA software. With the platform, businesses create professional-quality training, marketing, sales and customer support videos from text, using AI avatars and voiceovers in over 140 languages.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about how &lt;/i&gt;&lt;i&gt;NVIDIA is bolstering Europe’s technology ecosystem&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The U.K. is driving investments in sovereign AI, using the technology to advance industries like manufacturing, life sciences and more.&lt;/p&gt;
&lt;p&gt;During NVIDIA founder and CEO Jensen Huang’s visit to the U.K. this week, NVIDIA highlighted how it is working with a broad ecosystem of AI makers across the nation on applications in physical and agentic AI, robotics and healthcare.&lt;/p&gt;
&lt;p&gt;Such partner advancements support the U.K.’s AI Action Opportunities Plan, published earlier this year, which includes these key pillars:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Infographic that includes three pillars of the U.K.’s AI Action Opportunities Plan: 1) Invest in the foundations of AI. The U.K. needs world-class computing and data infrastructure, access to talent and regulation. 2) Push hard on cross-economy AI adoption. The public sector should rapidly pilot and scale AI products and services, and encourage the private sector to do the same. 3) Position the UK to be an AI maker, not an AI taker. The U.K. should aim to have national champions at critical layers of the AI stack so the U.K. benefits economically from AI advancement and has influence on future AI’s values, safety and government." class="aligncenter size-large wp-image-84827" height="672" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/uk-ai-action-plan-infographic-1680x672.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Advancing the UK Technology Ecosystem&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Work to build the U.K.’s AI foundation has already begun, with support from the nation’s rich research and startup ecosystem along with technology leaders.&lt;/p&gt;
&lt;p&gt;Funded by U.K. Research and Innovation and built on NVIDIA Grace Hopper Superchips, &lt;b&gt;Isambard-AI&lt;/b&gt; — the U.K.’s most powerful AI supercomputer based at the University of Bristol, which launched in July — is accelerating national projects including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;UK-LLM&lt;/b&gt;, a large language model project developed by University College London, Bangor University and NVIDIA. UK-LLM uses NVIDIA Nemotron reasoning models to support national languages like Welsh, as well as English, to improve public service delivery in sectors like healthcare and education.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Nightingale AI&lt;/b&gt;, a sovereign, multimodal health foundation model led by Imperial College London and trained on U.K. and US health data, which is designed to be used for numerous health applications including earlier diagnoses and personalized care.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;PolluGen&lt;/b&gt;, a new high-resolution pollution dispersion model developed by the University of Manchester, using NVIDIA CorrDiff and Earth-2 Studio. The model can use regional health and other data to help inform citizens and policymakers of air-quality impacts.&lt;/li&gt;
&lt;li&gt;The &lt;b&gt;Ultrasound Foundation Model&lt;/b&gt;, led by researchers at Queen Mary University of London. The model is built for ultrasound imaging, focusing on rheumatoid arthritis patient analysis and creating a reproducible, publicly accessible AI model for medical imaging.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Gen Model in Ego-Sensed World&lt;/b&gt;, led by researchers at the University of Bristol, is analyzing visual data from more than 900 participants to train an AI model to better understand everyday tasks. The AI model could help predict future real-world interactions and support memory to aid independent living for dementia patients.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Electrostatics-aware foundation models, &lt;/b&gt;developed by researchers at the University of Cambridge in collaboration with NVIDIA. These are being trained as the first foundation models for atomic interactions that understand electrostatics in chemistry at the atomic level. To do this, the researchers are using more than 200 million molecular and material structures from the OMOL and OMAT databases with NVIDIA’s cuEquivariance library. The model will allow scientists to simulate materials and molecules that were previously too large or complex to handle.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition, SCAN — a technology solutions provider with a strong focus on community, education and innovation — is collaborating with NVIDIA to address the growing AI skills gap across the U.K. through NVIDIA Deep Learning Institute courses and SCAN Springboard U.K., a community-driven initiative designed to foster peer-to-peer learning, market awareness, and mass training in AI and specialized workloads.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;AI for Robotics&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA announced separately today it is collaborating with techUK, alongside educational autonomous systems leader Quanser and training provider QA, to strengthen the U.K.’s robotics and AI ecosystem.&lt;/p&gt;
&lt;p&gt;NVIDIA is also working with other leading U.K. robotics leaders to advance industries with physical AI.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Extend Robotics&lt;/b&gt; is accelerating safe, scalable robot deployment in vehicle manufacturing by combining extended reality-based teleoperation and advanced training systems — powered by NVIDIA Jetson AGX Orin modules, the NVIDIA Isaac Lab framework and NVIDIA Isaac GR00T models — enabling rapid skill acquisition and boosting safety and productivity.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Humanoid&lt;/b&gt; is developing a modular humanoid robot called HMND 01 for general tasks in warehouses and retail spaces. The robot is designed for seamless integration with human environments.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Materials Innovation Factory&lt;/b&gt; at the University of Liverpool is using NVIDIA tools and libraries to train a foundations model to predict material properties, as well as train robot scientists using NVIDIA Jetson Orin Nano modules to test these hypotheses within a fully automated lab environment.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;The National Robotarium&lt;/b&gt;, a U.K. hub for robotics innovation, is using NVIDIA robotics and AI frameworks to support cutting-edge, practical research and help early-stage robotics businesses grow.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Opteran&lt;/b&gt; is creating autonomy algorithms for robots that mirror how the brains of insects and animals process information, harnessing knowledge on 600 million years of evolution to make robotic systems as robust and efficient as nature.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Oxa&lt;/b&gt; is creating full-stack AI self-driving software for industrial and commercial fleets with the NVIDIA DRIVE platform. The software works in all weather and locations — even where GPS is unreliable. Through its collaboration with NVIDIA, Oxa is able to generate vast amounts of diverse and realistic synthetic data to support training and validation — significantly accelerating the development and deployment of its solutions.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Wayve&lt;/b&gt; is pioneering end-to-end deep learning for autonomous driving. Its next-generation AV2.0 Platform enables vehicles to quickly and safely adapt its driving intelligence to new, unseen environments without needing expensive sensors and high-definition maps&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;AI for Life Sciences&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Many U.K.-based life sciences companies are using NVIDIA technologies to take an AI-first approach to drug discovery, simulating therapies and drug design to achieve faster treatment testing.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Basecamp Research&lt;/b&gt;’s BaseData — a proprietary evolutionary dataset that’s 10x larger than comparable public sources — is now powering a new generation of large foundation models across diverse biological data types, accelerating the development of curative, programmable medicines.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;U.K. CEiSRI&lt;/b&gt; — the U.K. Centre of Excellence for In-Silico Regulatory Science and Innovation,&amp;nbsp; headquartered at the University of Manchester — is developing complex digital twins with NVIDIA technologies to test new treatments on large and diverse patient populations.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Isomorphic Labs&lt;/b&gt; has built a leading AI drug design engine comprising foundational AI models that can work across multiple therapeutic areas and drug modalities.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Peptone&lt;/b&gt; is pioneering a new class of safer, more effective medicines by applying its physics-driven AI platform to unlock the therapeutic potential of the entire proteome, with a focus on historically “undruggable” intrinsically disordered proteins.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Latent Labs&lt;/b&gt;’ generative AI model, Latent-X, allows scientists to create and test therapeutic molecules in silico, speeding up drug design for researchers.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Relation Therapeutics&lt;/b&gt; offers a foundational AI platform for target drug discovery, integrating lab-in-the-loop experimentation to understand disease biology and accelerate the discovery and development of new therapies.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Hologen AI&lt;/b&gt;, a spinout with cofounders from University College London and King’s College London, represents a new breed of AI-native companies — ones harnessing the power of AI to model complex human biology and medical interventions with high precision, making new drugs available for patients rapidly and at lower cost.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Oxford Nanopore&lt;/b&gt; is delivering information-rich, rapid, affordable and accessible molecular information — such as DNA and RNA sequence data — to scientific researchers, as well as users in clinical, biopharma and applied industrial communities.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Agentic and Generative AI Innovations&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;AI model builders and startups are working with NVIDIA to transform the U.K. technology sector with agentic and generative AI tools that advance productivity, from financial large language models to AI voice agents.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Aveni &lt;/b&gt;created a financial LLM using the NVIDIA NeMo software suite to power its next-generation agentic framework that can interact with live financial systems, communicate with customers and advise on risk outcomes while ensuring compliance, transparency and control.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;ElevenLabs&lt;/b&gt; develops AI voice technology that generates natural, ultrarealistic speech in over 70 languages using NVIDIA software and NVIDIA DGX B200 systems. Its models power real-time conversational agents, localization, storytelling and accessibility tools for people who have lost their voices, in addition to voicing audiobooks and animating video game characters.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;PolyAI&lt;/b&gt; deployed advanced conversational AI agents using NVIDIA Riva automatic speech recognition NVIDIA NIM microservices. The AI agents automate customer support, speak naturally over the phone and handle complex tasks such as authentication, order management, billing and reservations on a massive scale.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Recraft&lt;/b&gt; is producing state-of-the-art image generation and editing models, built with advanced design capabilities to support professional creative workflows. Recraft is using the NVIDIA TensorRT software development kit, enabling users to generate and edit images and graphics to speed workflows such as producing marketing materials, generating product mockups and editing visual content.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Speechmatics&lt;/b&gt; developed speech-to-text software using NVIDIA Dynamo-Triton and NVIDIA cuDNN software. Its automatic speech recognition software lets businesses and developers convert spoken language into written text, with support for dozens of languages.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Synthesia&lt;/b&gt; built an enterprise-focused AI video platform using NVIDIA Dynamo-Triton and other NVIDIA software. With the platform, businesses create professional-quality training, marketing, sales and customer support videos from text, using AI avatars and voiceovers in over 140 languages.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about how &lt;/i&gt;&lt;i&gt;NVIDIA is bolstering Europe’s technology ecosystem&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/uk-partner-ecosystem-ai-makers/</guid><pubDate>Tue, 16 Sep 2025 21:30:16 +0000</pubDate></item><item><title>Meta Connect 2025: What to expect and how to watch (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/16/meta-connect-2025-what-to-expect-and-how-to-watch/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta Connect 2025 — the company’s biggest conference of the year where it unveils smart glasses and VR headsets — kicks off on Wednesday night. We’re expecting the star of Meta Connect 2025 to be the company’s new AI-powered smart glasses with Ray-Ban and Oakley, but the company may have some other surprises in store regarding the Metaverse, Quest headsets, or even its broader AI ambitions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta says it has sold millions of Ray-Ban Meta smart glasses, and earlier this year, Meta unveiled its latest AI-powered smart glasses with Oakley, which were designed for athletes. Silicon Valley is leaning heavily into AI wearables, and Meta seems to be one of the companies leading the charge.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Notably, this is the company’s first Connect conference since it started Meta Superintelligence Labs (MSL), its boldest effort yet to develop cutting-edge AI systems under former Scale AI CEO Alexandr Wang. It’s possible we’ll get some official updates on how that project is going, and we may hear from some MSL executives.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Meta looks to regain its footing in the AI race, this year’s Connect feels especially consequential. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-to-watch"&gt;How to watch&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Meta Connect 2025 starts at 5 p.m. PT Wednesday, with a keynote from CEO Mark Zuckerberg. The event will take place in person at Meta’s headquarters in Menlo Park. You can register for free to watch the livestream virtually on Meta’s website. Meta’s agenda says the keynote will be roughly an hour.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you want to get that Menlo Park feel from the comfort of your living room, you can also access the keynote through Horizon via your Meta Quest headset. You can also access the Meta Connect 2025 keynote on Facebook via the company’s official developer page, Meta for Developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Meta will host a Developer Keynote staring 10 a.m. PT to discuss the new experiences people can build with its devices. Then, at 10:45 a.m. PT, Meta will host a conversation between Chief Scientist of Reality Labs Michael Abrash and VP of Reality Labs Research Richard Newcombe. The two Meta executives are slated to discuss the “future of glasses with contextual AI, and how Meta is poised to transform the future of computing.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-what-to-expect"&gt;What to expect&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;There have already been several leaks regarding what will be announced at Meta Connect 2025. Perhaps the biggest pertains to a new type of smart glasses called Hypernova.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A now-removed video on Meta’s YouTube channel, spotted by UploadVR, showed a pair of Ray-Ban Meta smart glasses with a heads-up display on the right lens, as well as cameras, microphones, and an onboard AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The glasses in the video were controlled by a wristband, which was unveiled at last year’s Connect and is controlled by subtle hand gestures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The video suggests that Meta will unveil, and perhaps launch, the Hypernova glasses this week. CNBC previously reported that Meta was planning to unveil Hypernova and launch the wristband at Connect 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta also seems likely to unveil new pair of smart glasses it developed with Oakley at Connect 2025. The companies are expected to launch a new pair of AI-powered smart glasses in Oakley’s Spheara style. This features a large unified lens on the front — an ideal shape for runners and bikers. Unlike previous Meta smart glasses, this model has one centered camera above the nose bridge, rather than two cameras on the top corners of the frames.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the VR front, it’s unclear whether Meta will release any new Quest headsets as part of this year’s Connect. Even though the conference, and company, is named after the Metaverse, it seems like that’s less of the focus this year. Meta is reportedly developing an ultralight VR headset for launch by the end of 2026. However, the company could wait to show that off at next year’s Connect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, Meta promises that Zuckerberg will talk about the Metaverse in some shape or form. We don’t doubt that.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for Meta’s AI ambitions, it wouldn’t be surprising if Zuckerberg used Connect 2025 as a chance to highlight all the work MSL is doing. The company’s first LlamaCon, its AI developer conference, took place earlier this year before Meta invested billions in Scale AI and hired researchers from around the industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Right now, Meta’s standalone AI app is in a confusing spot where it both controls smart glasses and can be used as an AI chatbot. It’s possible that app also gets some updates that make it easier to use.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta Connect 2025 — the company’s biggest conference of the year where it unveils smart glasses and VR headsets — kicks off on Wednesday night. We’re expecting the star of Meta Connect 2025 to be the company’s new AI-powered smart glasses with Ray-Ban and Oakley, but the company may have some other surprises in store regarding the Metaverse, Quest headsets, or even its broader AI ambitions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta says it has sold millions of Ray-Ban Meta smart glasses, and earlier this year, Meta unveiled its latest AI-powered smart glasses with Oakley, which were designed for athletes. Silicon Valley is leaning heavily into AI wearables, and Meta seems to be one of the companies leading the charge.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Notably, this is the company’s first Connect conference since it started Meta Superintelligence Labs (MSL), its boldest effort yet to develop cutting-edge AI systems under former Scale AI CEO Alexandr Wang. It’s possible we’ll get some official updates on how that project is going, and we may hear from some MSL executives.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Meta looks to regain its footing in the AI race, this year’s Connect feels especially consequential. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-how-to-watch"&gt;How to watch&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Meta Connect 2025 starts at 5 p.m. PT Wednesday, with a keynote from CEO Mark Zuckerberg. The event will take place in person at Meta’s headquarters in Menlo Park. You can register for free to watch the livestream virtually on Meta’s website. Meta’s agenda says the keynote will be roughly an hour.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you want to get that Menlo Park feel from the comfort of your living room, you can also access the keynote through Horizon via your Meta Quest headset. You can also access the Meta Connect 2025 keynote on Facebook via the company’s official developer page, Meta for Developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Meta will host a Developer Keynote staring 10 a.m. PT to discuss the new experiences people can build with its devices. Then, at 10:45 a.m. PT, Meta will host a conversation between Chief Scientist of Reality Labs Michael Abrash and VP of Reality Labs Research Richard Newcombe. The two Meta executives are slated to discuss the “future of glasses with contextual AI, and how Meta is poised to transform the future of computing.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-what-to-expect"&gt;What to expect&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;There have already been several leaks regarding what will be announced at Meta Connect 2025. Perhaps the biggest pertains to a new type of smart glasses called Hypernova.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A now-removed video on Meta’s YouTube channel, spotted by UploadVR, showed a pair of Ray-Ban Meta smart glasses with a heads-up display on the right lens, as well as cameras, microphones, and an onboard AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The glasses in the video were controlled by a wristband, which was unveiled at last year’s Connect and is controlled by subtle hand gestures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The video suggests that Meta will unveil, and perhaps launch, the Hypernova glasses this week. CNBC previously reported that Meta was planning to unveil Hypernova and launch the wristband at Connect 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta also seems likely to unveil new pair of smart glasses it developed with Oakley at Connect 2025. The companies are expected to launch a new pair of AI-powered smart glasses in Oakley’s Spheara style. This features a large unified lens on the front — an ideal shape for runners and bikers. Unlike previous Meta smart glasses, this model has one centered camera above the nose bridge, rather than two cameras on the top corners of the frames.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the VR front, it’s unclear whether Meta will release any new Quest headsets as part of this year’s Connect. Even though the conference, and company, is named after the Metaverse, it seems like that’s less of the focus this year. Meta is reportedly developing an ultralight VR headset for launch by the end of 2026. However, the company could wait to show that off at next year’s Connect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, Meta promises that Zuckerberg will talk about the Metaverse in some shape or form. We don’t doubt that.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for Meta’s AI ambitions, it wouldn’t be surprising if Zuckerberg used Connect 2025 as a chance to highlight all the work MSL is doing. The company’s first LlamaCon, its AI developer conference, took place earlier this year before Meta invested billions in Scale AI and hired researchers from around the industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Right now, Meta’s standalone AI app is in a confusing spot where it both controls smart glasses and can be used as an AI chatbot. It’s possible that app also gets some updates that make it easier to use.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/16/meta-connect-2025-what-to-expect-and-how-to-watch/</guid><pubDate>Tue, 16 Sep 2025 21:55:23 +0000</pubDate></item></channel></rss>