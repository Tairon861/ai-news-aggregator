<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 11 Nov 2025 18:31:28 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>Chinese AI startup Moonshot outperforms GPT-5 and Claude Sonnet 4.5: What you need to know (AI News)</title><link>https://www.artificialintelligence-news.com/news/moonshot-ai-gpt-5-claude-comparison-china-breakthrough/</link><description>&lt;p&gt;A Chinese AI startup, Moonshot, has disrupted expectations in artificial intelligence development after its Kimi K2 Thinking model surpassed OpenAI‚Äôs GPT-5 and Anthropic‚Äôs Claude Sonnet 4.5 across multiple performance benchmarks, sparking renewed debate about whether America‚Äôs AI dominance is being challenged by cost-efficient Chinese innovation.&lt;/p&gt;&lt;p&gt;Beijing-based Moonshot AI, valued at US$3.3 billion and backed by tech giants Alibaba Group Holding and Tencent Holdings, released the open-source Kimi K2 Thinking model on November 6, achieving what industry observers are calling another ‚ÄúDeepSeek moment‚Äù ‚Äì a reference to the Hangzhou-based startup‚Äôs earlier disruption of AI cost assumptions.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;üöÄ Hello, Kimi K2 Thinking!&lt;br /&gt;The Open-Source Thinking Agent Model is here.&lt;/p&gt;&lt;p&gt;üîπ SOTA on HLE (44.9%) and BrowseComp (60.2%)&lt;br /&gt;üîπ Executes up to 200 ‚Äì 300 sequential tool calls without human interference&lt;br /&gt;üîπ Excels in reasoning, agentic search, and coding&lt;br /&gt;üîπ 256K context window&lt;/p&gt;&lt;p&gt;Built‚Ä¶ pic.twitter.com/lZCNBIgbV2&lt;/p&gt;‚Äî Kimi.ai (@Kimi_Moonshot) November 6, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-performance-metrics-challenge-us-models"&gt;Performance metrics challenge US models&lt;/h3&gt;&lt;p&gt;According to the company‚Äôs GitHub blog&amp;nbsp;post, Kimi K2 Thinking scored 44.9% on Humanity‚Äôs Last Exam, a large language model benchmark consisting of 2,500 questions across a broad range of subjects, exceeding GPT-5‚Äôs 41.7%.&lt;/p&gt;&lt;p&gt;The model also achieved 60.2% on the BrowseComp benchmark, which evaluates web browsing proficiency and information-seeking persistence of large language model agents, and scored 56.3% to lead in the Seal-0 benchmark designed to challenge search-augmented models on real-world research queries.&lt;/p&gt;&lt;p&gt;&lt;em&gt;VentureBeat&lt;/em&gt;&amp;nbsp;reported&amp;nbsp;that the fully open-weight release meeting or exceeding GPT-5‚Äôs scores marks a turning point where the gap between closed frontier systems and publicly available models has effectively collapsed for high-end reasoning and coding.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Kimi K2 Thinking is the new leading open weights model: it demonstrates particular strength in agentic contexts but is very verbose, generating the most tokens of any model in completing our Intelligence Index evals@Kimi_Moonshot's Kimi K2 Thinking achieves a 67 in the‚Ä¶ pic.twitter.com/m6SvpW7iif&lt;/p&gt;‚Äî Artificial Analysis (@ArtificialAnlys) November 7, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-cost-efficiency-raises-nbsp-questions"&gt;Cost efficiency raises&amp;nbsp;questions&lt;/h3&gt;&lt;p&gt;The popularity of the model grew after CNBC reported its training cost was merely US$4.6 million, though Moonshot AI did not comment on the cost.&amp;nbsp;According to calculations by the&amp;nbsp;&lt;em&gt;South China Morning Post&lt;/em&gt;,&amp;nbsp;the cost of&amp;nbsp;Kimi K2 Thinking‚Äôs application programming interface was&amp;nbsp;six&amp;nbsp;to 10 times cheaper than&amp;nbsp;that&amp;nbsp;of OpenAI and Anthropic‚Äôs models.&lt;/p&gt;&lt;p&gt;The model uses a Mixture-of-Experts architecture with&amp;nbsp;one&amp;nbsp;trillion total parameters, of which 32 billion are activated per inference, and was trained&amp;nbsp;using&amp;nbsp;INT4 quantisation to achieve roughly&amp;nbsp;two times&amp;nbsp;generation speed&amp;nbsp;improvement&amp;nbsp;while maintaining state-of-the-art performance.&lt;/p&gt;&lt;p&gt;Thomas Wolf, co-founder of Hugging Face,&amp;nbsp;commented&amp;nbsp;on X that Kimi K2 Thinking was another case of an open-source model passing a closed-source model, asking, ‚ÄúIs this another DeepSeek moment? Should we expect [one] every couple of months now?‚Äù&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-technical-capabilities-and-limitations"&gt;Technical capabilities and limitations&lt;/h3&gt;&lt;p&gt;Moonshot AI researchers&amp;nbsp;said&amp;nbsp;Kimi K2 Thinking set ‚Äúnew records across benchmarks that assess reasoning, coding and agent capabilities‚Äù. The model can execute up to 200-300 sequential tool calls without human interference, reasoning coherently across hundreds of steps to solve complex problems.&lt;/p&gt;&lt;p&gt;Independent testing by consultancy Artificial Analysis placed Kimi K2 on top of its Tau-2 Bench Telecom agentic benchmark with 93% accuracy, which was&amp;nbsp;described&amp;nbsp;as the highest score it has independently measured.&lt;/p&gt;&lt;p&gt;However, Nathan Lambert, a researcher at the Allen Institute for AI, suggested there‚Äôs still a time lag of approximately four to six months in raw performance between the best closed and open models, though he&amp;nbsp;acknowledged&amp;nbsp;that Chinese labs are closing in and performing very strongly on key benchmarks.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-market-implications-and-competitive-pressure"&gt;Market implications and competitive pressure&lt;/h3&gt;&lt;p&gt;Zhang Ruiwang, a Beijing-based information technology system architect, said the trend was for Chinese companies to keep costs down, explaining, ‚ÄúThe overall performance of Chinese models still lags behind top US models, so they have to compete in the realms of cost-effectiveness to have a way out‚Äù.&lt;/p&gt;&lt;p&gt;Zhang Yi, chief analyst at consultancy iiMedia, said the training costs of Chinese AI models were seeing a ‚Äúcliff-like drop‚Äù driven by innovation in model architecture and training technique, and input of quality training data, marking a shift away from the heaping of computing resources in the early days.&lt;/p&gt;&lt;p&gt;The model was released under a Modified MIT License that grants full commercial and derivative rights, with one restriction: deployers serving over 100 million monthly active users or&amp;nbsp;generating&amp;nbsp;over US$20 million per month in revenue must prominently display ‚ÄúKimi K2‚Äù on the product‚Äôs user interface.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-industry-response-and-future-outlook"&gt;Industry response and future outlook&lt;/h3&gt;&lt;p&gt;Deedy Das, a partner at early-stage venture capital firm Menlo Ventures, wrote in a post on X that ‚ÄúToday is a turning point in AI. A Chinese open-source model is #1. Seminal moment in AI‚Äù.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;üö® Today is a turning point in AI. A Chinese open source model is #1.&lt;/p&gt;&lt;p&gt;Kimi K2 Thinking scored 51% in Humanity's Last Exam, higher than GPT-5 and every other model. $0.6/M in, $2.5/M output.&lt;/p&gt;&lt;p&gt;The best at writing, and does 15tps on two Mac M3 Ultras!&lt;/p&gt;&lt;p&gt;Seminal moment in AI.&lt;/p&gt;&lt;p&gt;Try it‚Ä¶ pic.twitter.com/fmxlxpCGbE&lt;/p&gt;‚Äî Deedy (@deedydas) November 7, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;Nathan Lambert wrote in a Substack article that the success of Chinese open-source AI developers, including Moonshot AI and DeepSeek, showed how they ‚Äúmade the closed labs sweat,‚Äù adding ‚ÄúThere‚Äôs serious pricing pressure and expectations that [the US developers] need to manage‚Äù.&lt;/p&gt;&lt;p&gt;The release positions Moonshot AI alongside other Chinese AI companies like DeepSeek, Qwen, and Baichuan that are increasingly challenging the narrative of American AI supremacy through cost-efficient innovation and open-source development strategies.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Whether this represents a sustainable competitive advantage or a temporary convergence in capabilities remains to be seen as both US and Chinese companies continue advancing their models.&lt;/p&gt;&lt;p&gt;the public nature of the statements, and the market‚Äôs reaction, suggest substantive discussions may soon be underway.&lt;/p&gt;&lt;p&gt;The AI chip landscape is entering a period of flux. Organisations should maintain flexibility in their infrastructure strategy and monitor how partnerships like Tesla-Intel might reshape the competitive dynamics of AI hardware manufacturing.&lt;/p&gt;&lt;p&gt;The decisions made today about chip manufacturing partnerships could determine which organisations have access to cost-effective, high-performance AI infrastructure in the coming years.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Photo by Moonshot AI)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also:&lt;/strong&gt; DeepSeek disruption: Chinese AI innovation narrows global technology divide&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. This comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A Chinese AI startup, Moonshot, has disrupted expectations in artificial intelligence development after its Kimi K2 Thinking model surpassed OpenAI‚Äôs GPT-5 and Anthropic‚Äôs Claude Sonnet 4.5 across multiple performance benchmarks, sparking renewed debate about whether America‚Äôs AI dominance is being challenged by cost-efficient Chinese innovation.&lt;/p&gt;&lt;p&gt;Beijing-based Moonshot AI, valued at US$3.3 billion and backed by tech giants Alibaba Group Holding and Tencent Holdings, released the open-source Kimi K2 Thinking model on November 6, achieving what industry observers are calling another ‚ÄúDeepSeek moment‚Äù ‚Äì a reference to the Hangzhou-based startup‚Äôs earlier disruption of AI cost assumptions.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;üöÄ Hello, Kimi K2 Thinking!&lt;br /&gt;The Open-Source Thinking Agent Model is here.&lt;/p&gt;&lt;p&gt;üîπ SOTA on HLE (44.9%) and BrowseComp (60.2%)&lt;br /&gt;üîπ Executes up to 200 ‚Äì 300 sequential tool calls without human interference&lt;br /&gt;üîπ Excels in reasoning, agentic search, and coding&lt;br /&gt;üîπ 256K context window&lt;/p&gt;&lt;p&gt;Built‚Ä¶ pic.twitter.com/lZCNBIgbV2&lt;/p&gt;‚Äî Kimi.ai (@Kimi_Moonshot) November 6, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-performance-metrics-challenge-us-models"&gt;Performance metrics challenge US models&lt;/h3&gt;&lt;p&gt;According to the company‚Äôs GitHub blog&amp;nbsp;post, Kimi K2 Thinking scored 44.9% on Humanity‚Äôs Last Exam, a large language model benchmark consisting of 2,500 questions across a broad range of subjects, exceeding GPT-5‚Äôs 41.7%.&lt;/p&gt;&lt;p&gt;The model also achieved 60.2% on the BrowseComp benchmark, which evaluates web browsing proficiency and information-seeking persistence of large language model agents, and scored 56.3% to lead in the Seal-0 benchmark designed to challenge search-augmented models on real-world research queries.&lt;/p&gt;&lt;p&gt;&lt;em&gt;VentureBeat&lt;/em&gt;&amp;nbsp;reported&amp;nbsp;that the fully open-weight release meeting or exceeding GPT-5‚Äôs scores marks a turning point where the gap between closed frontier systems and publicly available models has effectively collapsed for high-end reasoning and coding.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Kimi K2 Thinking is the new leading open weights model: it demonstrates particular strength in agentic contexts but is very verbose, generating the most tokens of any model in completing our Intelligence Index evals@Kimi_Moonshot's Kimi K2 Thinking achieves a 67 in the‚Ä¶ pic.twitter.com/m6SvpW7iif&lt;/p&gt;‚Äî Artificial Analysis (@ArtificialAnlys) November 7, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-cost-efficiency-raises-nbsp-questions"&gt;Cost efficiency raises&amp;nbsp;questions&lt;/h3&gt;&lt;p&gt;The popularity of the model grew after CNBC reported its training cost was merely US$4.6 million, though Moonshot AI did not comment on the cost.&amp;nbsp;According to calculations by the&amp;nbsp;&lt;em&gt;South China Morning Post&lt;/em&gt;,&amp;nbsp;the cost of&amp;nbsp;Kimi K2 Thinking‚Äôs application programming interface was&amp;nbsp;six&amp;nbsp;to 10 times cheaper than&amp;nbsp;that&amp;nbsp;of OpenAI and Anthropic‚Äôs models.&lt;/p&gt;&lt;p&gt;The model uses a Mixture-of-Experts architecture with&amp;nbsp;one&amp;nbsp;trillion total parameters, of which 32 billion are activated per inference, and was trained&amp;nbsp;using&amp;nbsp;INT4 quantisation to achieve roughly&amp;nbsp;two times&amp;nbsp;generation speed&amp;nbsp;improvement&amp;nbsp;while maintaining state-of-the-art performance.&lt;/p&gt;&lt;p&gt;Thomas Wolf, co-founder of Hugging Face,&amp;nbsp;commented&amp;nbsp;on X that Kimi K2 Thinking was another case of an open-source model passing a closed-source model, asking, ‚ÄúIs this another DeepSeek moment? Should we expect [one] every couple of months now?‚Äù&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-technical-capabilities-and-limitations"&gt;Technical capabilities and limitations&lt;/h3&gt;&lt;p&gt;Moonshot AI researchers&amp;nbsp;said&amp;nbsp;Kimi K2 Thinking set ‚Äúnew records across benchmarks that assess reasoning, coding and agent capabilities‚Äù. The model can execute up to 200-300 sequential tool calls without human interference, reasoning coherently across hundreds of steps to solve complex problems.&lt;/p&gt;&lt;p&gt;Independent testing by consultancy Artificial Analysis placed Kimi K2 on top of its Tau-2 Bench Telecom agentic benchmark with 93% accuracy, which was&amp;nbsp;described&amp;nbsp;as the highest score it has independently measured.&lt;/p&gt;&lt;p&gt;However, Nathan Lambert, a researcher at the Allen Institute for AI, suggested there‚Äôs still a time lag of approximately four to six months in raw performance between the best closed and open models, though he&amp;nbsp;acknowledged&amp;nbsp;that Chinese labs are closing in and performing very strongly on key benchmarks.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-market-implications-and-competitive-pressure"&gt;Market implications and competitive pressure&lt;/h3&gt;&lt;p&gt;Zhang Ruiwang, a Beijing-based information technology system architect, said the trend was for Chinese companies to keep costs down, explaining, ‚ÄúThe overall performance of Chinese models still lags behind top US models, so they have to compete in the realms of cost-effectiveness to have a way out‚Äù.&lt;/p&gt;&lt;p&gt;Zhang Yi, chief analyst at consultancy iiMedia, said the training costs of Chinese AI models were seeing a ‚Äúcliff-like drop‚Äù driven by innovation in model architecture and training technique, and input of quality training data, marking a shift away from the heaping of computing resources in the early days.&lt;/p&gt;&lt;p&gt;The model was released under a Modified MIT License that grants full commercial and derivative rights, with one restriction: deployers serving over 100 million monthly active users or&amp;nbsp;generating&amp;nbsp;over US$20 million per month in revenue must prominently display ‚ÄúKimi K2‚Äù on the product‚Äôs user interface.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-industry-response-and-future-outlook"&gt;Industry response and future outlook&lt;/h3&gt;&lt;p&gt;Deedy Das, a partner at early-stage venture capital firm Menlo Ventures, wrote in a post on X that ‚ÄúToday is a turning point in AI. A Chinese open-source model is #1. Seminal moment in AI‚Äù.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;üö® Today is a turning point in AI. A Chinese open source model is #1.&lt;/p&gt;&lt;p&gt;Kimi K2 Thinking scored 51% in Humanity's Last Exam, higher than GPT-5 and every other model. $0.6/M in, $2.5/M output.&lt;/p&gt;&lt;p&gt;The best at writing, and does 15tps on two Mac M3 Ultras!&lt;/p&gt;&lt;p&gt;Seminal moment in AI.&lt;/p&gt;&lt;p&gt;Try it‚Ä¶ pic.twitter.com/fmxlxpCGbE&lt;/p&gt;‚Äî Deedy (@deedydas) November 7, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;Nathan Lambert wrote in a Substack article that the success of Chinese open-source AI developers, including Moonshot AI and DeepSeek, showed how they ‚Äúmade the closed labs sweat,‚Äù adding ‚ÄúThere‚Äôs serious pricing pressure and expectations that [the US developers] need to manage‚Äù.&lt;/p&gt;&lt;p&gt;The release positions Moonshot AI alongside other Chinese AI companies like DeepSeek, Qwen, and Baichuan that are increasingly challenging the narrative of American AI supremacy through cost-efficient innovation and open-source development strategies.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Whether this represents a sustainable competitive advantage or a temporary convergence in capabilities remains to be seen as both US and Chinese companies continue advancing their models.&lt;/p&gt;&lt;p&gt;the public nature of the statements, and the market‚Äôs reaction, suggest substantive discussions may soon be underway.&lt;/p&gt;&lt;p&gt;The AI chip landscape is entering a period of flux. Organisations should maintain flexibility in their infrastructure strategy and monitor how partnerships like Tesla-Intel might reshape the competitive dynamics of AI hardware manufacturing.&lt;/p&gt;&lt;p&gt;The decisions made today about chip manufacturing partnerships could determine which organisations have access to cost-effective, high-performance AI infrastructure in the coming years.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Photo by Moonshot AI)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also:&lt;/strong&gt; DeepSeek disruption: Chinese AI innovation narrows global technology divide&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. This comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/moonshot-ai-gpt-5-claude-comparison-china-breakthrough/</guid><pubDate>Tue, 11 Nov 2025 09:00:00 +0000</pubDate></item><item><title>[NEW] The Download: surviving extreme temperatures, and the big whale-wind turbine conspiracy (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/11/1127866/the-download-surviving-extreme-temperatures-and-the-big-whale-wind-turbine-conspiracy/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The quest to find out how our bodies react to extreme temperatures&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Climate change is subjecting vulnerable people to temperatures that push their limits. In 2023, about 47,000 heat-related deaths are believed to have occurred in Europe. Researchers estimate that climate change could add an extra 2.3 million European heat deaths this century. That‚Äôs heightened the stakes for solving the mystery of just what happens to bodies in extreme conditions.&lt;/p&gt;&lt;p&gt;While we broadly know how people thermoregulate, the science of keeping warm or cool is mottled with blind spots. Researchers around the world are revising rules about when extremes veer from uncomfortable to deadly. Their findings change how we should think about the limits of hot and cold‚Äîand how to survive in a new world. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîMax G.Levy&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from the latest print issue of MIT Technology Review magazine, which is full of fascinating stories about the body. If you haven‚Äôt already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Whales are dying. Don‚Äôt blame wind turbines.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Whale deaths have become a political flashpoint. There are currently three active mortality events for whales in the Atlantic, meaning clusters of deaths that experts consider unusual. And Republican lawmakers, conservative think tanks, and‚Äîmost notably‚ÄîPresident Donald Trump (a longtime enemy of wind power) are making dubious claims that offshore wind farms are responsible.&lt;/p&gt;&lt;p&gt;But any finger-pointing at wind turbines for whale deaths ignores the fact that whales have been washing up on beaches since long before the giant machines were rooted in the ocean floor. This is something that has always happened. And the scientific consensus is clear: There‚Äôs no evidence that wind farms are the cause of recent increases in whale deaths. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîCasey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is part of &lt;em&gt;MIT Technology Review&lt;/em&gt;‚Äôs series ‚ÄúThe New Conspiracy Age,‚Äù on how the present boom in conspiracy theories is reshaping science and technology. Check out &lt;/strong&gt;&lt;strong&gt;the rest of the series here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The State of AI: Energy is king, and the US is falling behind&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;In the age of AI, the biggest barrier to progress isn‚Äôt money but energy. That should be particularly worrying in the US, where massive data centers are waiting to come online. It doesn‚Äôt look as if the country will build the steady power supply or infrastructure needed to serve them all.&lt;/p&gt;&lt;p&gt;It wasn‚Äôt always like this. For about a decade before 2020, data centers were able to offset increased demand with efficiency improvements. Now, though, electricity demand is ticking up in the US, with billions of queries to popular AI models each day‚Äîand efficiency gains aren‚Äôt keeping pace.&lt;/p&gt;&lt;p&gt;If we want AI to have the chance to deliver on big promises without driving electricity prices sky-high for the rest of us, the US needs to learn some lessons from the rest of the world on energy abundance. Just look at China.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîCasey Crownhart &amp;amp; Pilita Clark&lt;/em&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;This is from The State of AI, our subscriber-only collaboration between the&lt;em&gt; Financial Times&lt;/em&gt; &amp;amp; &lt;em&gt;MIT Technology Review&lt;/em&gt; examining the ways in which AI is reshaping global power.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Every Monday for the next four weeks, writers from both publications will debate one aspect of the generative AI revolution reshaping global power. While subscribers to The Algorithm, our weekly AI newsletter, get access to an extended excerpt, subscribers to the magazine are able to read the whole thing. &lt;strong&gt;Sign up&lt;/strong&gt;&lt;strong&gt; here to receive future editions every Monday.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;1 How China narrowed its AI divide with the US&lt;/strong&gt;&lt;br /&gt;America still has a clear lead‚Äîbut for how long? (WSJ $)&lt;br /&gt;+ &lt;em&gt;The AI boom won‚Äôt offset tariffs and America‚Äôs immigration crackdown forever. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;How quickly is AI likely to progress really? &lt;/em&gt;(Economist $)&lt;br /&gt;+ &lt;em&gt;Is China about to win the AI race? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Anthropic is due to turn a profit much faster than OpenAI&lt;br /&gt;&lt;/strong&gt;The two companies are taking very different approaches to making money. (WSJ $)&lt;br /&gt;+ &lt;em&gt;OpenAI has lured Intel‚Äôs AI chief away. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 The EU is setting up a new intelligence sharing unit&lt;br /&gt;&lt;/strong&gt;It‚Äôs a bid to shore up intel in the wake of Donald Trump‚Äôs plans to reduce security support for Europe. (FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Trump officials are poised to suggest oil drilling off the coast of California&lt;/strong&gt;&lt;br /&gt;That's likely to rile the state‚Äôs politicians and leaders. (WP $)&lt;br /&gt;+ &lt;em&gt;What role should oil and gas companies play in climate tech? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;5 America‚Äôs cyber defenses are poor&lt;/strong&gt;&lt;br /&gt;Repeated cuts and mass layoffs are making it harder to protect the nation. (The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 China is on track to hit its peak CO2 emissions target early&lt;/strong&gt;&lt;br /&gt;Although it‚Äôs likely to miss its goal for cutting carbon intensity. (The Guardian)&lt;br /&gt;+ &lt;em&gt;World leaders are heading to COP30 in Brazil this week. &lt;/em&gt;(New Yorker $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;7 OpenAI cannot use song lyrics without a license&lt;/strong&gt;&lt;br /&gt;That‚Äôs what a German court has decided, after siding with a music rights society. (Reuters)&lt;br /&gt;+ &lt;em&gt;OpenAI is no stranger to legal proceedings. &lt;/em&gt;(The Atlantic $)&lt;br /&gt;+ &lt;em&gt;AI is coming for music. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 A small Michigan town is fighting a proposed AI data center&lt;br /&gt;&lt;/strong&gt;The planned center is part of a collaboration between the University of Michigan and nuclear weapons scientists. (404 Media)&lt;br /&gt;+ &lt;em&gt;Here‚Äôs where America‚Äôs data centers should be built instead. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Communities in Latin America are pushing back, too. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Should we be moving data centers to space? &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;9 AI models can‚Äôt tell the time ‚è∞&lt;br /&gt;Analog clocks leave them completely stumped. (IEEE Spectrum)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;10 ChatGPT is giving daters the ick&lt;/strong&gt;&lt;br /&gt;These refuseniks don‚Äôt want anything to do with AI, or love interests who use it. (The Guardian)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;‚ÄúI never imagined that making a cup of tea or obtaining water, antibiotics, or painkillers would require such tremendous effort.‚Äù&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;‚ÄîAn anonymous member of startup accelerator Gaza Sky Geeks tells Rest of World about the impact the war has had on them.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2023/02/jinhwajang_c2.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How Rust went from a side project to the world‚Äôs most-loved programming language&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Many software projects emerge because‚Äîsomewhere out there‚Äîa programmer had a personal problem to solve.&lt;/p&gt;&lt;p&gt;That‚Äôs more or less what happened to Graydon Hoare. In 2006, Hoare was a 29-year-old computer programmer working for Mozilla. After a software crash broke the elevator in his building, he set about designing a new computer language; one that he hoped would make it possible to write small, fast code without memory bugs.&lt;/p&gt;&lt;p&gt;That language developed into Rust, one of the hottest new languages on the planet. But while it isn‚Äôt unusual for someone to make a new computer language, it‚Äôs incredibly rare for one to take hold and become part of the programming pantheon. How did Rust do it? Read the full story.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The quest to find out how our bodies react to extreme temperatures&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Climate change is subjecting vulnerable people to temperatures that push their limits. In 2023, about 47,000 heat-related deaths are believed to have occurred in Europe. Researchers estimate that climate change could add an extra 2.3 million European heat deaths this century. That‚Äôs heightened the stakes for solving the mystery of just what happens to bodies in extreme conditions.&lt;/p&gt;&lt;p&gt;While we broadly know how people thermoregulate, the science of keeping warm or cool is mottled with blind spots. Researchers around the world are revising rules about when extremes veer from uncomfortable to deadly. Their findings change how we should think about the limits of hot and cold‚Äîand how to survive in a new world. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîMax G.Levy&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from the latest print issue of MIT Technology Review magazine, which is full of fascinating stories about the body. If you haven‚Äôt already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Whales are dying. Don‚Äôt blame wind turbines.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Whale deaths have become a political flashpoint. There are currently three active mortality events for whales in the Atlantic, meaning clusters of deaths that experts consider unusual. And Republican lawmakers, conservative think tanks, and‚Äîmost notably‚ÄîPresident Donald Trump (a longtime enemy of wind power) are making dubious claims that offshore wind farms are responsible.&lt;/p&gt;&lt;p&gt;But any finger-pointing at wind turbines for whale deaths ignores the fact that whales have been washing up on beaches since long before the giant machines were rooted in the ocean floor. This is something that has always happened. And the scientific consensus is clear: There‚Äôs no evidence that wind farms are the cause of recent increases in whale deaths. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîCasey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is part of &lt;em&gt;MIT Technology Review&lt;/em&gt;‚Äôs series ‚ÄúThe New Conspiracy Age,‚Äù on how the present boom in conspiracy theories is reshaping science and technology. Check out &lt;/strong&gt;&lt;strong&gt;the rest of the series here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The State of AI: Energy is king, and the US is falling behind&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;In the age of AI, the biggest barrier to progress isn‚Äôt money but energy. That should be particularly worrying in the US, where massive data centers are waiting to come online. It doesn‚Äôt look as if the country will build the steady power supply or infrastructure needed to serve them all.&lt;/p&gt;&lt;p&gt;It wasn‚Äôt always like this. For about a decade before 2020, data centers were able to offset increased demand with efficiency improvements. Now, though, electricity demand is ticking up in the US, with billions of queries to popular AI models each day‚Äîand efficiency gains aren‚Äôt keeping pace.&lt;/p&gt;&lt;p&gt;If we want AI to have the chance to deliver on big promises without driving electricity prices sky-high for the rest of us, the US needs to learn some lessons from the rest of the world on energy abundance. Just look at China.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîCasey Crownhart &amp;amp; Pilita Clark&lt;/em&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;This is from The State of AI, our subscriber-only collaboration between the&lt;em&gt; Financial Times&lt;/em&gt; &amp;amp; &lt;em&gt;MIT Technology Review&lt;/em&gt; examining the ways in which AI is reshaping global power.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Every Monday for the next four weeks, writers from both publications will debate one aspect of the generative AI revolution reshaping global power. While subscribers to The Algorithm, our weekly AI newsletter, get access to an extended excerpt, subscribers to the magazine are able to read the whole thing. &lt;strong&gt;Sign up&lt;/strong&gt;&lt;strong&gt; here to receive future editions every Monday.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;1 How China narrowed its AI divide with the US&lt;/strong&gt;&lt;br /&gt;America still has a clear lead‚Äîbut for how long? (WSJ $)&lt;br /&gt;+ &lt;em&gt;The AI boom won‚Äôt offset tariffs and America‚Äôs immigration crackdown forever. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;How quickly is AI likely to progress really? &lt;/em&gt;(Economist $)&lt;br /&gt;+ &lt;em&gt;Is China about to win the AI race? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Anthropic is due to turn a profit much faster than OpenAI&lt;br /&gt;&lt;/strong&gt;The two companies are taking very different approaches to making money. (WSJ $)&lt;br /&gt;+ &lt;em&gt;OpenAI has lured Intel‚Äôs AI chief away. &lt;/em&gt;(Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 The EU is setting up a new intelligence sharing unit&lt;br /&gt;&lt;/strong&gt;It‚Äôs a bid to shore up intel in the wake of Donald Trump‚Äôs plans to reduce security support for Europe. (FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Trump officials are poised to suggest oil drilling off the coast of California&lt;/strong&gt;&lt;br /&gt;That's likely to rile the state‚Äôs politicians and leaders. (WP $)&lt;br /&gt;+ &lt;em&gt;What role should oil and gas companies play in climate tech? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;5 America‚Äôs cyber defenses are poor&lt;/strong&gt;&lt;br /&gt;Repeated cuts and mass layoffs are making it harder to protect the nation. (The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 China is on track to hit its peak CO2 emissions target early&lt;/strong&gt;&lt;br /&gt;Although it‚Äôs likely to miss its goal for cutting carbon intensity. (The Guardian)&lt;br /&gt;+ &lt;em&gt;World leaders are heading to COP30 in Brazil this week. &lt;/em&gt;(New Yorker $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;7 OpenAI cannot use song lyrics without a license&lt;/strong&gt;&lt;br /&gt;That‚Äôs what a German court has decided, after siding with a music rights society. (Reuters)&lt;br /&gt;+ &lt;em&gt;OpenAI is no stranger to legal proceedings. &lt;/em&gt;(The Atlantic $)&lt;br /&gt;+ &lt;em&gt;AI is coming for music. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 A small Michigan town is fighting a proposed AI data center&lt;br /&gt;&lt;/strong&gt;The planned center is part of a collaboration between the University of Michigan and nuclear weapons scientists. (404 Media)&lt;br /&gt;+ &lt;em&gt;Here‚Äôs where America‚Äôs data centers should be built instead. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Communities in Latin America are pushing back, too. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Should we be moving data centers to space? &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;9 AI models can‚Äôt tell the time ‚è∞&lt;br /&gt;Analog clocks leave them completely stumped. (IEEE Spectrum)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;10 ChatGPT is giving daters the ick&lt;/strong&gt;&lt;br /&gt;These refuseniks don‚Äôt want anything to do with AI, or love interests who use it. (The Guardian)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;‚ÄúI never imagined that making a cup of tea or obtaining water, antibiotics, or painkillers would require such tremendous effort.‚Äù&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;‚ÄîAn anonymous member of startup accelerator Gaza Sky Geeks tells Rest of World about the impact the war has had on them.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2023/02/jinhwajang_c2.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How Rust went from a side project to the world‚Äôs most-loved programming language&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Many software projects emerge because‚Äîsomewhere out there‚Äîa programmer had a personal problem to solve.&lt;/p&gt;&lt;p&gt;That‚Äôs more or less what happened to Graydon Hoare. In 2006, Hoare was a 29-year-old computer programmer working for Mozilla. After a software crash broke the elevator in his building, he set about designing a new computer language; one that he hoped would make it possible to write small, fast code without memory bugs.&lt;/p&gt;&lt;p&gt;That language developed into Rust, one of the hottest new languages on the planet. But while it isn‚Äôt unusual for someone to make a new computer language, it‚Äôs incredibly rare for one to take hold and become part of the programming pantheon. How did Rust do it? Read the full story.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/11/1127866/the-download-surviving-extreme-temperatures-and-the-big-whale-wind-turbine-conspiracy/</guid><pubDate>Tue, 11 Nov 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] A former physician has launched Robyn, an empathetic AI companion (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/11/a-former-physician-has-launched-robyn-an-empathetic-ai-companion/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Jenny Shao was a practicing physician and was in residency at Harvard. During the pandemic, Shao saw that people in isolation had a neurological impact, and they needed support. This drove her to leave her medical career, the Harvard residency, to launch a start offering an AI assistant called Robyn. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Robyn is intended to be an empathic, emotionally intelligent AI for people.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Navigating human relationships with AI assistants is a tricky space. On the one hand, there are general-purpose chatbots like ChatGPT; on the other, there are companion/friendship/avatar apps like Character.AI, Replika, and Friend, and even therapy apps like Feeling Great. A study in July indicated that 72% of U.S. teens have used AI companion apps. These apps have been accused of playing a part in the suicides of multiple people through various lawsuits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shao said that it is trying to position Robyn in a way that it is neither a friendship app nor a replacement for a therapist or a clinical practitioner.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúAs a physician, I have seen things go badly when tech companies try to replace your doctor. Robyn is and won‚Äôt ever be a clinical [replacement]. It is equivalent to someone who knows you very well. Usually, their role is to support you. You can think of Robyn as your emotionally intelligent partner,‚Äù Shao said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Screenshot showing with the Robyn home screen where you can type and start chat with the AI chatbot. " class="wp-image-3066728" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-11-at-10.55.09-AM.jpeg?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Robyn&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The founder said that with Robyn, her startup has tried to replicate the way humans remember things. Shao previously worked under Nobel Laureate Eric Kandel‚Äôs, who won the 2000 Nobel Prize in Physiology or Medicine, lab to research human memory. Shao said she put those learnings into Robyn to have the AI understand users more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Robyn, which is available on iOS, has an onboarding process like many journaling or mental health apps. The app asks you about yourself, your goals, how you react when you are challenged, and what kind of tone you Robyn to respond in.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="An image that describes Robyn's memory feature and shows a chat where the AI chatbot recalls something which user said in the past. " class="wp-image-3066731" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/3-preview.jpeg?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image credits: Robyn&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Once you complete the onboarding, you can chat with Robyn about different topics. For instance, when I asked it to build a morning routine for me, it asked me a bunch of questions and also had a detailed conversation about having a minimum screen time at the beginning of the day. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As you chat more with Robyn, the app will give you more insights into your pattern and also describe different traits about you, including your emotional fingerprint, attachment style, love language, growth edge, and inner critic. The startup has also made a demo website to analyze profiles on X and give insights as to what kinds of insights they would get out of Robyn.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="An image where Robyn describes your spirit and memory based on the chats that you've had. " class="wp-image-3066729" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/Spirit-Animal.jpeg?w=471" width="471" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image credits: Robyn&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Shao said that the company takes safety seriously and has been putting in guardrails even when she was testing the chatbot as a solo user. The app gives users a crisis line number and points them to the nearest ER if they talk about self-harm. The assistant also pushes back on certain topics and answers. If you ask it to show the latest sports score or ask it to count to 1,000, Robyn will say that it can‚Äôt perform these actions but help you with any personal stuff. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company has raised $5.5 million in seed funding led by M13 with participation from Google Maps co-founder Lars Rasmussen, early Canva investor Bill Tai, ex-Yahoo CFO Ken Goldman, and X.ai co-founder Christian Szegedy. The startup had three team members at the start of the year and has now grown to 10 people. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rasmussen said that the app‚Äôs emotional memory system was impressive, and Shao‚Äôs mission of helping people attracted him to invest in the app.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="And I was describing Robyn's weekly insight features that gives you some takeaways from the week based on the conversations. " class="wp-image-3066730" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/7-preview.jpeg?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Robyn&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe‚Äôre living through a massive disconnection problem. People are surrounded by technology but feel less understood than ever. Robyn tackles that head-on. It‚Äôs solving emotional disconnection, helping people reflect, recognize their own patterns, and reconnect with who they are.&amp;nbsp;It‚Äôs not about therapy or replacing l relationships. It‚Äôs about strengthening someone‚Äôs capacity to connect ‚Äî with themselves first, and then with others,‚Äù he told TechCrunch over email.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A big challenge for Robyn would be to maintain the safety of its users and also make sure users don‚Äôt anthropomorphize the chatbot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Latif Parecha, a partner at M13, said that Robyn‚Äôs ultimate goal is to foster human connections, but for AIs operating in this realm, there needs to be guardrails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThere needs to be guardrails in place for escalation for situations where people are in real danger. Especially, as AI will be part of our lives just like are family and friends are,‚Äù Parecha told TechCrunch over a call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup has been testing Robyn with a select set of users for a few months and launching today in the U.S. The app is paid, and the subscription costs $19.99 a month or $199 a year. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Jenny Shao was a practicing physician and was in residency at Harvard. During the pandemic, Shao saw that people in isolation had a neurological impact, and they needed support. This drove her to leave her medical career, the Harvard residency, to launch a start offering an AI assistant called Robyn. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Robyn is intended to be an empathic, emotionally intelligent AI for people.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Navigating human relationships with AI assistants is a tricky space. On the one hand, there are general-purpose chatbots like ChatGPT; on the other, there are companion/friendship/avatar apps like Character.AI, Replika, and Friend, and even therapy apps like Feeling Great. A study in July indicated that 72% of U.S. teens have used AI companion apps. These apps have been accused of playing a part in the suicides of multiple people through various lawsuits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shao said that it is trying to position Robyn in a way that it is neither a friendship app nor a replacement for a therapist or a clinical practitioner.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúAs a physician, I have seen things go badly when tech companies try to replace your doctor. Robyn is and won‚Äôt ever be a clinical [replacement]. It is equivalent to someone who knows you very well. Usually, their role is to support you. You can think of Robyn as your emotionally intelligent partner,‚Äù Shao said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Screenshot showing with the Robyn home screen where you can type and start chat with the AI chatbot. " class="wp-image-3066728" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-11-at-10.55.09-AM.jpeg?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Robyn&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The founder said that with Robyn, her startup has tried to replicate the way humans remember things. Shao previously worked under Nobel Laureate Eric Kandel‚Äôs, who won the 2000 Nobel Prize in Physiology or Medicine, lab to research human memory. Shao said she put those learnings into Robyn to have the AI understand users more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Robyn, which is available on iOS, has an onboarding process like many journaling or mental health apps. The app asks you about yourself, your goals, how you react when you are challenged, and what kind of tone you Robyn to respond in.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="An image that describes Robyn's memory feature and shows a chat where the AI chatbot recalls something which user said in the past. " class="wp-image-3066731" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/3-preview.jpeg?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image credits: Robyn&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Once you complete the onboarding, you can chat with Robyn about different topics. For instance, when I asked it to build a morning routine for me, it asked me a bunch of questions and also had a detailed conversation about having a minimum screen time at the beginning of the day. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As you chat more with Robyn, the app will give you more insights into your pattern and also describe different traits about you, including your emotional fingerprint, attachment style, love language, growth edge, and inner critic. The startup has also made a demo website to analyze profiles on X and give insights as to what kinds of insights they would get out of Robyn.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="An image where Robyn describes your spirit and memory based on the chats that you've had. " class="wp-image-3066729" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/Spirit-Animal.jpeg?w=471" width="471" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image credits: Robyn&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Shao said that the company takes safety seriously and has been putting in guardrails even when she was testing the chatbot as a solo user. The app gives users a crisis line number and points them to the nearest ER if they talk about self-harm. The assistant also pushes back on certain topics and answers. If you ask it to show the latest sports score or ask it to count to 1,000, Robyn will say that it can‚Äôt perform these actions but help you with any personal stuff. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company has raised $5.5 million in seed funding led by M13 with participation from Google Maps co-founder Lars Rasmussen, early Canva investor Bill Tai, ex-Yahoo CFO Ken Goldman, and X.ai co-founder Christian Szegedy. The startup had three team members at the start of the year and has now grown to 10 people. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rasmussen said that the app‚Äôs emotional memory system was impressive, and Shao‚Äôs mission of helping people attracted him to invest in the app.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="And I was describing Robyn's weekly insight features that gives you some takeaways from the week based on the conversations. " class="wp-image-3066730" height="680" src="https://techcrunch.com/wp-content/uploads/2025/11/7-preview.jpeg?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image Credits: Robyn&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe‚Äôre living through a massive disconnection problem. People are surrounded by technology but feel less understood than ever. Robyn tackles that head-on. It‚Äôs solving emotional disconnection, helping people reflect, recognize their own patterns, and reconnect with who they are.&amp;nbsp;It‚Äôs not about therapy or replacing l relationships. It‚Äôs about strengthening someone‚Äôs capacity to connect ‚Äî with themselves first, and then with others,‚Äù he told TechCrunch over email.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A big challenge for Robyn would be to maintain the safety of its users and also make sure users don‚Äôt anthropomorphize the chatbot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Latif Parecha, a partner at M13, said that Robyn‚Äôs ultimate goal is to foster human connections, but for AIs operating in this realm, there needs to be guardrails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThere needs to be guardrails in place for escalation for situations where people are in real danger. Especially, as AI will be part of our lives just like are family and friends are,‚Äù Parecha told TechCrunch over a call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup has been testing Robyn with a select set of users for a few months and launching today in the U.S. The app is paid, and the subscription costs $19.99 a month or $199 a year. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/11/a-former-physician-has-launched-robyn-an-empathetic-ai-companion/</guid><pubDate>Tue, 11 Nov 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Meta‚Äôs chief AI scientist Yann LeCun reportedly plans to leave to build his own startup (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/11/metas-chief-ai-scientist-yann-lecun-reportedly-plans-to-leave-to-build-his-own-startup/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2194768816.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta may be about to lose one of its most renowned AI heads: Yann LeCun, a chief AI scientist at the company, is planning to leave the company to build his own startup, the Financial Times reported, citing anonymous sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LeCun, a professor at New York University, senior researcher at Meta, and winner of the prestigious A.M. Turing Award, plans to leave in the coming months, and is already in talks to raise capital for a startup that would focus on continuing his work on world models, the report added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A world model is an AI system that develops an internal understanding of its environment so it can simulate cause-and-effect scenarios to predict outcomes. Top labs and startups like Google DeepMind and World Labs are also developing world models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LeCun‚Äôs departure would come at a pivotal time for Meta, which has of late changed how it approaches AI development in response to concerns that it is being outpaced by rivals like OpenAI, Google, and Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has reportedly started revamping its AI organization after hiring over 50 engineers and researchers from its competitors to build out a new AI unit, dubbed Meta Superintelligence Labs (MSL). Notably, Meta in June invested $14.3 billion in data-labeling vendor Scale AI and brought on board its CEO Alexandr Wang to run the new division.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those decisions, sources told TechCrunch in August, have made things increasingly chaotic at Meta‚Äôs AI unit, with new talent expressing frustration with navigating the bureaucracy of a big company, while Meta‚Äôs previous generative AI team has seen its scope limited.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LeCun‚Äôs long-term research work at the company under its Fundamental AI Research Lab (FAIR) division has been overshadowed by CEO Mark Zuckerberg‚Äôs decisions to overhaul things after the company‚Äôs previous family of AI models, Llama 4, failed to keep up with rival models. Unlike MSL, FAIR is designed to focus on long-term AI research ‚Äî techniques that may be used five to 10 years from now.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;LeCun has been openly skeptical about how AI technology ‚Äî specifically LLMs ‚Äî is currently being marketed as the cure for all of humankind‚Äôs ails. He even tweeted that AI systems have a long way to go. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIt seems to me that before ‚Äòurgently figuring out how to control AI systems much smarter than us‚Äô we need to have the beginning of a hint of a design for a system smarter than a house cat,‚Äù he wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta did not immediately return a request for comment outside regular business hours. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2194768816.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta may be about to lose one of its most renowned AI heads: Yann LeCun, a chief AI scientist at the company, is planning to leave the company to build his own startup, the Financial Times reported, citing anonymous sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LeCun, a professor at New York University, senior researcher at Meta, and winner of the prestigious A.M. Turing Award, plans to leave in the coming months, and is already in talks to raise capital for a startup that would focus on continuing his work on world models, the report added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A world model is an AI system that develops an internal understanding of its environment so it can simulate cause-and-effect scenarios to predict outcomes. Top labs and startups like Google DeepMind and World Labs are also developing world models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LeCun‚Äôs departure would come at a pivotal time for Meta, which has of late changed how it approaches AI development in response to concerns that it is being outpaced by rivals like OpenAI, Google, and Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has reportedly started revamping its AI organization after hiring over 50 engineers and researchers from its competitors to build out a new AI unit, dubbed Meta Superintelligence Labs (MSL). Notably, Meta in June invested $14.3 billion in data-labeling vendor Scale AI and brought on board its CEO Alexandr Wang to run the new division.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those decisions, sources told TechCrunch in August, have made things increasingly chaotic at Meta‚Äôs AI unit, with new talent expressing frustration with navigating the bureaucracy of a big company, while Meta‚Äôs previous generative AI team has seen its scope limited.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LeCun‚Äôs long-term research work at the company under its Fundamental AI Research Lab (FAIR) division has been overshadowed by CEO Mark Zuckerberg‚Äôs decisions to overhaul things after the company‚Äôs previous family of AI models, Llama 4, failed to keep up with rival models. Unlike MSL, FAIR is designed to focus on long-term AI research ‚Äî techniques that may be used five to 10 years from now.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;LeCun has been openly skeptical about how AI technology ‚Äî specifically LLMs ‚Äî is currently being marketed as the cure for all of humankind‚Äôs ails. He even tweeted that AI systems have a long way to go. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIt seems to me that before ‚Äòurgently figuring out how to control AI systems much smarter than us‚Äô we need to have the beginning of a hint of a design for a system smarter than a house cat,‚Äù he wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta did not immediately return a request for comment outside regular business hours. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/11/metas-chief-ai-scientist-yann-lecun-reportedly-plans-to-leave-to-build-his-own-startup/</guid><pubDate>Tue, 11 Nov 2025 14:58:45 +0000</pubDate></item><item><title>[NEW] You won‚Äôt believe the excuses lawyers have after getting busted for using AI (AI ‚Äì Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/11/lawyers-keep-giving-weak-sauce-excuses-for-fake-ai-citations-in-court-docs/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 dark:bg-gray-700 md:my-10 md:py-8"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      I got hacked; I lost my login; it was a rough draft; toggling windows is hard.
    &lt;/p&gt;

    

    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/ai-shrugging-lawyer.jpg" width="2560" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Amid what one judge called an ‚Äúepidemic‚Äù of fake AI-generated case citations bogging down courts, some common excuses are emerging from lawyers hoping to dodge the most severe sanctions for filings deemed misleading.&lt;/p&gt;
&lt;p&gt;Using a database compiled by French lawyer and AI researcher Damien Charlotin, Ars reviewed 23 cases where lawyers were sanctioned for AI hallucinations. In many, judges noted that the simplest path to avoid or diminish sanctions was to admit that AI was used as soon as it‚Äôs detected, act humble, self-report the error to relevant legal associations, and voluntarily take classes on AI and law. But not every lawyer takes the path of least resistance, Ars‚Äô review found, with many instead offering excuses that no judge found credible. Some even lie about their AI use, judges concluded.&lt;/p&gt;
&lt;p&gt;Since 2023‚Äîwhen fake AI citations started being publicized‚Äîthe most popular excuse has been that the lawyer didn‚Äôt know AI was used to draft a filing.&lt;/p&gt;
&lt;p&gt;Sometimes that means arguing that you didn‚Äôt realize you were using AI, as in the case of a California lawyer who got stung by Google‚Äôs AI Overviews, which he claimed he took for typical Google search results. Most often, lawyers using this excuse tend to blame an underling, but clients have been blamed, too. A Texas lawyer this month was sanctioned after deflecting so much that the court had to eventually put his client on the stand after he revealed she played a significant role in drafting the aberrant filing.&lt;/p&gt;
&lt;p&gt;‚ÄúIs your client an attorney?‚Äù the court asked.&lt;/p&gt;
&lt;p&gt;‚ÄúNo, not at all your Honor, just was essentially helping me with the theories of the case,‚Äù the lawyer said.&lt;/p&gt;
&lt;p&gt;Another popular dodge comes from lawyers who feign ignorance that chatbots are prone to hallucinating facts.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Recent cases suggest this excuse may be mutating into variants. Last month, a sanctioned Oklahoma lawyer admitted that he didn‚Äôt expect ChatGPT to add new citations when all he asked the bot to do was ‚Äúmake his writing more persuasive.‚Äù And in September, a California lawyer got in a similar bind‚Äîand was sanctioned a whopping $10,000, a fine the judge called ‚Äúconservative.‚Äù That lawyer had asked ChatGPT to ‚Äúenhance‚Äù his briefs, ‚Äúthen ran the ‚Äòenhanced‚Äô briefs through other AI platforms to check for errors,‚Äù neglecting to ever read the ‚Äúenhanced‚Äù briefs.&lt;/p&gt;
&lt;p&gt;Neither of those tired old excuses hold much weight today, especially in courts that have drawn up guidance to address AI hallucinations. But rather than quickly acknowledge their missteps, as courts are begging lawyers to do, several lawyers appear to have gotten desperate. Ars found a bunch citing common tech issues as the reason for citing fake cases.&lt;/p&gt;
&lt;h2&gt;When in doubt, blame hackers?&lt;/h2&gt;
&lt;p&gt;For an extreme case, look to a New York City civil court, where a lawyer, Innocent Chinweze, first admitted to using Microsoft Copilot to draft an errant filing, then bizarrely pivoted to claim that the AI citations were due to malware found on his computer.&lt;/p&gt;
&lt;p&gt;Chinweze said he had created a draft with correct citations but then got hacked, allowing bad actors ‚Äúunauthorized remote access‚Äù to supposedly add the errors in his filing.&lt;/p&gt;
&lt;p&gt;The judge was skeptical, describing the excuse as an ‚Äúincredible and unsupported statement,‚Äù particularly since there was no evidence of the prior draft existing. Instead, Chinweze asked to bring in an expert to testify that the hack had occurred, requesting to end the proceedings on sanctions until after the court weighed the expert‚Äôs analysis.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The judge, Kimon C. Thermos, didn‚Äôt have to weigh this argument, however, because after the court broke for lunch, the lawyer once again ‚Äúdramatically‚Äù changed his position.&lt;/p&gt;
&lt;p&gt;‚ÄúHe no longer wished to adjourn for an expert to testify regarding malware or unauthorized access to his computer,‚Äù Thermos wrote in an order issuing sanctions. ‚ÄúHe retreated‚Äù to ‚Äúhis original position that he used Copilot to aid in his research and didn‚Äôt realize that it could generate fake cases.‚Äù&lt;/p&gt;
&lt;p&gt;Possibly more galling to Thermos than the lawyer‚Äôs weird malware argument, though, was a document that Chinweze filed on the day of his sanctions hearing. That document included multiple summaries preceded by this text, the judge noted:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Some case metadata and case summaries were written with the help of AI, which can produce inaccuracies. You should read the full case before relying on it for legal research purposes.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thermos admonished Chinweze for continuing to use AI recklessly. He blasted the filing as ‚Äúan incoherent document that is eighty-eight pages long, has no structure, contains the full text of most of the cases cited,‚Äù and ‚Äúshows distinct indications that parts of the discussion/analysis of the cited cases were written by artificial intelligence.‚Äù&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Ultimately, Thermos ordered Chinweze to pay $1,000, the most typical fine lawyers received in the cases Ars reviewed. The judge then took an extra non-monetary step to sanction Chinweze, referring the lawyer to a grievance committee, ‚Äúgiven that his misconduct was substantial and seriously implicated his honesty, trustworthiness, and fitness to practice law.‚Äù&lt;/p&gt;
&lt;p&gt;Ars could not immediately reach Chinweze for comment.&lt;/p&gt;
&lt;h2&gt;Toggling windows on a laptop is hard&lt;/h2&gt;
&lt;p&gt;&lt;span style="margin: 0px; padding: 0px;"&gt;In Alabama, an attorney named James A. Johnson made an ‚Äúembarrassing mistake,‚Äù he said, primarily because toggling windows on a laptop is hard, US District Judge Terry F. Moorer noted in an October&amp;nbsp;order on sanctions.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Johnson explained that he had accidentally used an AI tool that he didn‚Äôt realize could hallucinate. It happened while he was ‚Äúat an out-of-state hospital attending to the care of a family member recovering from surgery.‚Äù He rushed to draft the filing, he said, because he got a notice that his client‚Äôs conference had suddenly been ‚Äúmoved up on the court‚Äôs schedule.‚Äù&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;‚ÄúUnder time pressure and difficult personal circumstance,‚Äù Johnson explained, he decided against using Fastcase, a research tool provided by the Alabama State Bar, to research the filing. Working on his laptop, he opted instead to use ‚Äúa Microsoft Word plug-in called Ghostwriter Legal‚Äù because ‚Äúit appeared automatically in the sidebar of Word while Fastcase required opening a separate browser to access through the Alabama State Bar website.‚Äù&lt;/p&gt;
&lt;p&gt;To Johnson, it felt ‚Äútedious to toggle back and forth between programs on [his] laptop with the touchpad,‚Äù and that meant he ‚Äúunfortunately fell victim to the allure of a new program that was open and available.‚Äù&lt;/p&gt;
&lt;p&gt;Moorer seemed unimpressed by Johnson‚Äôs claim that he understood tools like ChatGPT were unreliable but didn‚Äôt expect the same from other AI legal tools‚Äîparticularly since ‚Äúinformation from Ghostwriter Legal made it clear that it used ChatGPT as its default AI program,‚Äù Moorer wrote.&lt;/p&gt;
&lt;p&gt;The lawyer‚Äôs client was similarly horrified, deciding to drop Johnson on the spot, even though that risked ‚Äúa significant delay of trial.‚Äù Moorer noted that Johnson seemed shaken by his client‚Äôs abrupt decision, evidenced by ‚Äúhis look of shock, dismay, and display of emotion.‚Äù&lt;/p&gt;
&lt;p&gt;Moorer further noted that Johnson had been paid using public funds while seemingly letting AI do his homework. ‚ÄúThe harm is not inconsequential as public funds for appointed counsel are not a bottomless well and are limited resource,‚Äù the judge wrote in justifying a more severe fine.&lt;/p&gt;
&lt;p&gt;‚ÄúIt has become clear that basic reprimands and small fines are not sufficient to deter this type of misconduct because if it were, we would not be here,‚Äù Moorer concluded.&lt;/p&gt;
&lt;p&gt;Ruling that Johnson‚Äôs reliance on AI was ‚Äútantamount to bad faith,‚Äù Moorer imposed a $5,000 fine. The judge also would have&amp;nbsp;‚Äúconsidered potential disqualification, but that was rendered moot‚Äù since Johnson‚Äôs client had already dismissed him.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Asked for comment, Johnson told Ars that ‚Äúthe court made plainly erroneous findings of fact and the sanctions are on appeal.‚Äù&lt;/p&gt;
&lt;h2&gt;Plagued by login issues&lt;/h2&gt;
&lt;p&gt;As a lawyer in Georgia tells it, sometimes fake AI citations may be filed because a lawyer accidentally filed a rough draft instead of the final version.&lt;/p&gt;
&lt;p&gt;Other lawyers claim they turn to AI as needed when they have trouble accessing legal tools like Westlaw or LexisNexis.&lt;/p&gt;
&lt;p&gt;For example, in Iowa, a lawyer told an appeals court that she regretted relying on ‚Äúsecondary AI-driven research tools‚Äù after experiencing ‚Äúlogin issues her with her Westlaw subscription.‚Äù Although the court was ‚Äúsympathetic to issues with technology, such as login issues,‚Äù the lawyer was sanctioned, primarily because she only admitted to using AI after the court ordered her to explain her mistakes. In her case, however, she got to choose between paying a minimal $150 fine or attending ‚Äútwo hours of legal ethics training particular to AI.‚Äù&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Less sympathetic was a lawyer who got caught lying about the AI tool she blamed for inaccuracies, a Louisiana case suggested. In that case, a judge demanded to see the research history after a lawyer claimed that AI hallucinations came from ‚Äúusing Westlaw Precision, an AI-assisted research tool, rather than Westlaw‚Äôs standalone legal database.‚Äù&lt;/p&gt;
&lt;p&gt;It turned out that the lawyer had outsourced the research, relying on a ‚Äúcurrently suspended‚Äù lawyer‚Äôs AI citations, and had only ‚Äúassumed‚Äù the lawyer‚Äôs mistakes were from Westlaw‚Äôs AI tool. It‚Äôs unclear what tool was actually used by the suspended lawyer, who likely lost access to a Westlaw login, but the judge ordered a $1,000 penalty after the lawyer who signed the filing ‚Äúagreed that Westlaw did not generate the fabricated citations.‚Äù&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Judge warned of ‚Äúserial hallucinators‚Äù&lt;/h2&gt;
&lt;p&gt;Another lawyer, William T. Panichi in Illinois, has been sanctioned at least three times, Ars‚Äô review found.&lt;/p&gt;
&lt;p&gt;In response to his initial penalties ordered in July, he admitted to being tempted by AI while he was ‚Äúbetween research software.‚Äù&lt;/p&gt;
&lt;p&gt;In that case, the court was frustrated to find that the lawyer had contradicted himself, and it ordered more severe sanctions as a result.&lt;/p&gt;
&lt;p&gt;Panichi ‚Äúsimultaneously admitted to using AI to generate the briefs, not doing any of his own independent research, and even that he ‚Äòbarely did any personal work [him]self on this appeal,'‚Äù the court order said, while also defending charging a higher fee‚Äîsupposedly because this case ‚Äúwas out of the ordinary in terms of time spent‚Äù and his office ‚Äúdid some exceptional work‚Äù getting information.&lt;/p&gt;
&lt;p&gt;The court deemed this AI misuse so bad that Panichi was ordered to disgorge a ‚Äúpayment of $6,925.62 that he received‚Äù in addition to a $1,000 penalty.&lt;/p&gt;
&lt;p&gt;‚ÄúIf I‚Äôm lucky enough to be able to continue practicing before the appellate court, I‚Äôm not going to do it again,‚Äù Panichi told the court in July, just before getting hit with two more rounds of sanctions in August.&lt;/p&gt;
&lt;p&gt;Panichi did not immediately respond to Ars‚Äô request for comment.&lt;/p&gt;
&lt;p&gt;When AI-generated hallucinations are found, penalties are often paid to the court, the other parties‚Äô lawyers, or both, depending on whose time and resources were wasted fact-checking fake cases.&lt;/p&gt;
&lt;p&gt;Lawyers seem more likely to argue against paying sanctions to the other parties‚Äô attorneys, hoping to keep sanctions as low as possible. One lawyer even argued that ‚Äúit only takes 7.6 seconds, not hours, to type citations into LexisNexis or Westlaw,‚Äù while seemingly neglecting the fact that she did not take those precious seconds to check her own citations.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The judge in the case, Nancy Miller, was clear that ‚Äúsuch statements display an astounding lack of awareness of counsel‚Äôs obligations,‚Äù noting that ‚Äúthe responsibility for correcting erroneous and fake citations never shifts to opposing counsel or the court, even if they are the first to notice the errors.‚Äù&lt;/p&gt;
&lt;p&gt;‚ÄúThe duty to mitigate the harms caused by such errors remains with the signor,‚Äù Miller said. ‚ÄúThe sooner such errors are properly corrected, either by withdrawing or amending and supplementing the offending pleadings, the less time is wasted by everyone involved, and fewer costs are incurred.‚Äù&lt;/p&gt;
&lt;p&gt;Texas US District Judge Marina Garcia Marmolejo agreed, explaining that even more time is wasted determining how other judges have responded to fake AI-generated citations.&lt;/p&gt;
&lt;p&gt;‚ÄúAt one of the busiest court dockets in the nation, there are scant resources to spare ferreting out erroneous AI citations in the first place, let alone surveying the burgeoning caselaw on this subject,‚Äù she said.&lt;/p&gt;
&lt;p&gt;At least one Florida court was ‚Äúshocked, shocked‚Äù to find that a lawyer was refusing to pay what the other party‚Äôs attorneys said they were owed after misusing AI. The lawyer in that case, James Martin Paul, asked to pay less than a quarter of the fees and costs owed, arguing that Charlotin‚Äôs database showed he might otherwise owe penalties that ‚Äúwould be the largest sanctions paid out for the use of AI generative case law to date.‚Äù&lt;/p&gt;
&lt;p&gt;But caving to Paul‚Äôs arguments ‚Äúwould only benefit serial hallucinators,‚Äù the Florida court found. Ultimately, Paul was sanctioned more than $85,000 for what the court said was ‚Äúfar more egregious‚Äù conduct than other offenders in the database, chastising him for ‚Äúrepeated, abusive, bad-faith conduct that cannot be recognized as legitimate legal practice and must be deterred.‚Äù&lt;/p&gt;
&lt;p&gt;Paul did not immediately respond to Ars‚Äô request to comment.&lt;/p&gt;
&lt;p&gt;Michael B. Slade, a US bankruptcy judge in Illinois, seems to be done weighing excuses, calling on all lawyers to stop taking AI shortcuts that are burdening courts.&lt;/p&gt;
&lt;p&gt;‚ÄúAt this point, to be blunt, any lawyer unaware that using generative AI platforms to do legal research is playing with fire is living in a cloud,‚Äù Slade wrote.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 dark:bg-gray-700 md:my-10 md:py-8"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      I got hacked; I lost my login; it was a rough draft; toggling windows is hard.
    &lt;/p&gt;

    

    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/ai-shrugging-lawyer.jpg" width="2560" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Amid what one judge called an ‚Äúepidemic‚Äù of fake AI-generated case citations bogging down courts, some common excuses are emerging from lawyers hoping to dodge the most severe sanctions for filings deemed misleading.&lt;/p&gt;
&lt;p&gt;Using a database compiled by French lawyer and AI researcher Damien Charlotin, Ars reviewed 23 cases where lawyers were sanctioned for AI hallucinations. In many, judges noted that the simplest path to avoid or diminish sanctions was to admit that AI was used as soon as it‚Äôs detected, act humble, self-report the error to relevant legal associations, and voluntarily take classes on AI and law. But not every lawyer takes the path of least resistance, Ars‚Äô review found, with many instead offering excuses that no judge found credible. Some even lie about their AI use, judges concluded.&lt;/p&gt;
&lt;p&gt;Since 2023‚Äîwhen fake AI citations started being publicized‚Äîthe most popular excuse has been that the lawyer didn‚Äôt know AI was used to draft a filing.&lt;/p&gt;
&lt;p&gt;Sometimes that means arguing that you didn‚Äôt realize you were using AI, as in the case of a California lawyer who got stung by Google‚Äôs AI Overviews, which he claimed he took for typical Google search results. Most often, lawyers using this excuse tend to blame an underling, but clients have been blamed, too. A Texas lawyer this month was sanctioned after deflecting so much that the court had to eventually put his client on the stand after he revealed she played a significant role in drafting the aberrant filing.&lt;/p&gt;
&lt;p&gt;‚ÄúIs your client an attorney?‚Äù the court asked.&lt;/p&gt;
&lt;p&gt;‚ÄúNo, not at all your Honor, just was essentially helping me with the theories of the case,‚Äù the lawyer said.&lt;/p&gt;
&lt;p&gt;Another popular dodge comes from lawyers who feign ignorance that chatbots are prone to hallucinating facts.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Recent cases suggest this excuse may be mutating into variants. Last month, a sanctioned Oklahoma lawyer admitted that he didn‚Äôt expect ChatGPT to add new citations when all he asked the bot to do was ‚Äúmake his writing more persuasive.‚Äù And in September, a California lawyer got in a similar bind‚Äîand was sanctioned a whopping $10,000, a fine the judge called ‚Äúconservative.‚Äù That lawyer had asked ChatGPT to ‚Äúenhance‚Äù his briefs, ‚Äúthen ran the ‚Äòenhanced‚Äô briefs through other AI platforms to check for errors,‚Äù neglecting to ever read the ‚Äúenhanced‚Äù briefs.&lt;/p&gt;
&lt;p&gt;Neither of those tired old excuses hold much weight today, especially in courts that have drawn up guidance to address AI hallucinations. But rather than quickly acknowledge their missteps, as courts are begging lawyers to do, several lawyers appear to have gotten desperate. Ars found a bunch citing common tech issues as the reason for citing fake cases.&lt;/p&gt;
&lt;h2&gt;When in doubt, blame hackers?&lt;/h2&gt;
&lt;p&gt;For an extreme case, look to a New York City civil court, where a lawyer, Innocent Chinweze, first admitted to using Microsoft Copilot to draft an errant filing, then bizarrely pivoted to claim that the AI citations were due to malware found on his computer.&lt;/p&gt;
&lt;p&gt;Chinweze said he had created a draft with correct citations but then got hacked, allowing bad actors ‚Äúunauthorized remote access‚Äù to supposedly add the errors in his filing.&lt;/p&gt;
&lt;p&gt;The judge was skeptical, describing the excuse as an ‚Äúincredible and unsupported statement,‚Äù particularly since there was no evidence of the prior draft existing. Instead, Chinweze asked to bring in an expert to testify that the hack had occurred, requesting to end the proceedings on sanctions until after the court weighed the expert‚Äôs analysis.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The judge, Kimon C. Thermos, didn‚Äôt have to weigh this argument, however, because after the court broke for lunch, the lawyer once again ‚Äúdramatically‚Äù changed his position.&lt;/p&gt;
&lt;p&gt;‚ÄúHe no longer wished to adjourn for an expert to testify regarding malware or unauthorized access to his computer,‚Äù Thermos wrote in an order issuing sanctions. ‚ÄúHe retreated‚Äù to ‚Äúhis original position that he used Copilot to aid in his research and didn‚Äôt realize that it could generate fake cases.‚Äù&lt;/p&gt;
&lt;p&gt;Possibly more galling to Thermos than the lawyer‚Äôs weird malware argument, though, was a document that Chinweze filed on the day of his sanctions hearing. That document included multiple summaries preceded by this text, the judge noted:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Some case metadata and case summaries were written with the help of AI, which can produce inaccuracies. You should read the full case before relying on it for legal research purposes.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Thermos admonished Chinweze for continuing to use AI recklessly. He blasted the filing as ‚Äúan incoherent document that is eighty-eight pages long, has no structure, contains the full text of most of the cases cited,‚Äù and ‚Äúshows distinct indications that parts of the discussion/analysis of the cited cases were written by artificial intelligence.‚Äù&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Ultimately, Thermos ordered Chinweze to pay $1,000, the most typical fine lawyers received in the cases Ars reviewed. The judge then took an extra non-monetary step to sanction Chinweze, referring the lawyer to a grievance committee, ‚Äúgiven that his misconduct was substantial and seriously implicated his honesty, trustworthiness, and fitness to practice law.‚Äù&lt;/p&gt;
&lt;p&gt;Ars could not immediately reach Chinweze for comment.&lt;/p&gt;
&lt;h2&gt;Toggling windows on a laptop is hard&lt;/h2&gt;
&lt;p&gt;&lt;span style="margin: 0px; padding: 0px;"&gt;In Alabama, an attorney named James A. Johnson made an ‚Äúembarrassing mistake,‚Äù he said, primarily because toggling windows on a laptop is hard, US District Judge Terry F. Moorer noted in an October&amp;nbsp;order on sanctions.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Johnson explained that he had accidentally used an AI tool that he didn‚Äôt realize could hallucinate. It happened while he was ‚Äúat an out-of-state hospital attending to the care of a family member recovering from surgery.‚Äù He rushed to draft the filing, he said, because he got a notice that his client‚Äôs conference had suddenly been ‚Äúmoved up on the court‚Äôs schedule.‚Äù&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;‚ÄúUnder time pressure and difficult personal circumstance,‚Äù Johnson explained, he decided against using Fastcase, a research tool provided by the Alabama State Bar, to research the filing. Working on his laptop, he opted instead to use ‚Äúa Microsoft Word plug-in called Ghostwriter Legal‚Äù because ‚Äúit appeared automatically in the sidebar of Word while Fastcase required opening a separate browser to access through the Alabama State Bar website.‚Äù&lt;/p&gt;
&lt;p&gt;To Johnson, it felt ‚Äútedious to toggle back and forth between programs on [his] laptop with the touchpad,‚Äù and that meant he ‚Äúunfortunately fell victim to the allure of a new program that was open and available.‚Äù&lt;/p&gt;
&lt;p&gt;Moorer seemed unimpressed by Johnson‚Äôs claim that he understood tools like ChatGPT were unreliable but didn‚Äôt expect the same from other AI legal tools‚Äîparticularly since ‚Äúinformation from Ghostwriter Legal made it clear that it used ChatGPT as its default AI program,‚Äù Moorer wrote.&lt;/p&gt;
&lt;p&gt;The lawyer‚Äôs client was similarly horrified, deciding to drop Johnson on the spot, even though that risked ‚Äúa significant delay of trial.‚Äù Moorer noted that Johnson seemed shaken by his client‚Äôs abrupt decision, evidenced by ‚Äúhis look of shock, dismay, and display of emotion.‚Äù&lt;/p&gt;
&lt;p&gt;Moorer further noted that Johnson had been paid using public funds while seemingly letting AI do his homework. ‚ÄúThe harm is not inconsequential as public funds for appointed counsel are not a bottomless well and are limited resource,‚Äù the judge wrote in justifying a more severe fine.&lt;/p&gt;
&lt;p&gt;‚ÄúIt has become clear that basic reprimands and small fines are not sufficient to deter this type of misconduct because if it were, we would not be here,‚Äù Moorer concluded.&lt;/p&gt;
&lt;p&gt;Ruling that Johnson‚Äôs reliance on AI was ‚Äútantamount to bad faith,‚Äù Moorer imposed a $5,000 fine. The judge also would have&amp;nbsp;‚Äúconsidered potential disqualification, but that was rendered moot‚Äù since Johnson‚Äôs client had already dismissed him.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Asked for comment, Johnson told Ars that ‚Äúthe court made plainly erroneous findings of fact and the sanctions are on appeal.‚Äù&lt;/p&gt;
&lt;h2&gt;Plagued by login issues&lt;/h2&gt;
&lt;p&gt;As a lawyer in Georgia tells it, sometimes fake AI citations may be filed because a lawyer accidentally filed a rough draft instead of the final version.&lt;/p&gt;
&lt;p&gt;Other lawyers claim they turn to AI as needed when they have trouble accessing legal tools like Westlaw or LexisNexis.&lt;/p&gt;
&lt;p&gt;For example, in Iowa, a lawyer told an appeals court that she regretted relying on ‚Äúsecondary AI-driven research tools‚Äù after experiencing ‚Äúlogin issues her with her Westlaw subscription.‚Äù Although the court was ‚Äúsympathetic to issues with technology, such as login issues,‚Äù the lawyer was sanctioned, primarily because she only admitted to using AI after the court ordered her to explain her mistakes. In her case, however, she got to choose between paying a minimal $150 fine or attending ‚Äútwo hours of legal ethics training particular to AI.‚Äù&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Less sympathetic was a lawyer who got caught lying about the AI tool she blamed for inaccuracies, a Louisiana case suggested. In that case, a judge demanded to see the research history after a lawyer claimed that AI hallucinations came from ‚Äúusing Westlaw Precision, an AI-assisted research tool, rather than Westlaw‚Äôs standalone legal database.‚Äù&lt;/p&gt;
&lt;p&gt;It turned out that the lawyer had outsourced the research, relying on a ‚Äúcurrently suspended‚Äù lawyer‚Äôs AI citations, and had only ‚Äúassumed‚Äù the lawyer‚Äôs mistakes were from Westlaw‚Äôs AI tool. It‚Äôs unclear what tool was actually used by the suspended lawyer, who likely lost access to a Westlaw login, but the judge ordered a $1,000 penalty after the lawyer who signed the filing ‚Äúagreed that Westlaw did not generate the fabricated citations.‚Äù&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Judge warned of ‚Äúserial hallucinators‚Äù&lt;/h2&gt;
&lt;p&gt;Another lawyer, William T. Panichi in Illinois, has been sanctioned at least three times, Ars‚Äô review found.&lt;/p&gt;
&lt;p&gt;In response to his initial penalties ordered in July, he admitted to being tempted by AI while he was ‚Äúbetween research software.‚Äù&lt;/p&gt;
&lt;p&gt;In that case, the court was frustrated to find that the lawyer had contradicted himself, and it ordered more severe sanctions as a result.&lt;/p&gt;
&lt;p&gt;Panichi ‚Äúsimultaneously admitted to using AI to generate the briefs, not doing any of his own independent research, and even that he ‚Äòbarely did any personal work [him]self on this appeal,'‚Äù the court order said, while also defending charging a higher fee‚Äîsupposedly because this case ‚Äúwas out of the ordinary in terms of time spent‚Äù and his office ‚Äúdid some exceptional work‚Äù getting information.&lt;/p&gt;
&lt;p&gt;The court deemed this AI misuse so bad that Panichi was ordered to disgorge a ‚Äúpayment of $6,925.62 that he received‚Äù in addition to a $1,000 penalty.&lt;/p&gt;
&lt;p&gt;‚ÄúIf I‚Äôm lucky enough to be able to continue practicing before the appellate court, I‚Äôm not going to do it again,‚Äù Panichi told the court in July, just before getting hit with two more rounds of sanctions in August.&lt;/p&gt;
&lt;p&gt;Panichi did not immediately respond to Ars‚Äô request for comment.&lt;/p&gt;
&lt;p&gt;When AI-generated hallucinations are found, penalties are often paid to the court, the other parties‚Äô lawyers, or both, depending on whose time and resources were wasted fact-checking fake cases.&lt;/p&gt;
&lt;p&gt;Lawyers seem more likely to argue against paying sanctions to the other parties‚Äô attorneys, hoping to keep sanctions as low as possible. One lawyer even argued that ‚Äúit only takes 7.6 seconds, not hours, to type citations into LexisNexis or Westlaw,‚Äù while seemingly neglecting the fact that she did not take those precious seconds to check her own citations.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The judge in the case, Nancy Miller, was clear that ‚Äúsuch statements display an astounding lack of awareness of counsel‚Äôs obligations,‚Äù noting that ‚Äúthe responsibility for correcting erroneous and fake citations never shifts to opposing counsel or the court, even if they are the first to notice the errors.‚Äù&lt;/p&gt;
&lt;p&gt;‚ÄúThe duty to mitigate the harms caused by such errors remains with the signor,‚Äù Miller said. ‚ÄúThe sooner such errors are properly corrected, either by withdrawing or amending and supplementing the offending pleadings, the less time is wasted by everyone involved, and fewer costs are incurred.‚Äù&lt;/p&gt;
&lt;p&gt;Texas US District Judge Marina Garcia Marmolejo agreed, explaining that even more time is wasted determining how other judges have responded to fake AI-generated citations.&lt;/p&gt;
&lt;p&gt;‚ÄúAt one of the busiest court dockets in the nation, there are scant resources to spare ferreting out erroneous AI citations in the first place, let alone surveying the burgeoning caselaw on this subject,‚Äù she said.&lt;/p&gt;
&lt;p&gt;At least one Florida court was ‚Äúshocked, shocked‚Äù to find that a lawyer was refusing to pay what the other party‚Äôs attorneys said they were owed after misusing AI. The lawyer in that case, James Martin Paul, asked to pay less than a quarter of the fees and costs owed, arguing that Charlotin‚Äôs database showed he might otherwise owe penalties that ‚Äúwould be the largest sanctions paid out for the use of AI generative case law to date.‚Äù&lt;/p&gt;
&lt;p&gt;But caving to Paul‚Äôs arguments ‚Äúwould only benefit serial hallucinators,‚Äù the Florida court found. Ultimately, Paul was sanctioned more than $85,000 for what the court said was ‚Äúfar more egregious‚Äù conduct than other offenders in the database, chastising him for ‚Äúrepeated, abusive, bad-faith conduct that cannot be recognized as legitimate legal practice and must be deterred.‚Äù&lt;/p&gt;
&lt;p&gt;Paul did not immediately respond to Ars‚Äô request to comment.&lt;/p&gt;
&lt;p&gt;Michael B. Slade, a US bankruptcy judge in Illinois, seems to be done weighing excuses, calling on all lawyers to stop taking AI shortcuts that are burdening courts.&lt;/p&gt;
&lt;p&gt;‚ÄúAt this point, to be blunt, any lawyer unaware that using generative AI platforms to do legal research is playing with fire is living in a cloud,‚Äù Slade wrote.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/11/lawyers-keep-giving-weak-sauce-excuses-for-fake-ai-citations-in-court-docs/</guid><pubDate>Tue, 11 Nov 2025 15:54:11 +0000</pubDate></item><item><title>[NEW] Wonderful raised $100M Series A to put AI agents on the front lines of customer service (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/11/wonderful-raised-100m-series-a-to-put-ai-agents-on-the-front-lines-of-customer-service/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Wonderful-Founders.png?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Israeli&amp;nbsp;AI agent&amp;nbsp;startup&amp;nbsp;Wonderful&amp;nbsp;has raised $100 million in a Series A round led by Index Ventures, with participation from Insight Partners, IVP, Bessemer, and Vine Ventures. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The large round, in a&amp;nbsp;market already crowded&amp;nbsp;with AI agent startups, suggests&amp;nbsp;Wonderful has convinced top tier investors&amp;nbsp;it‚Äôs&amp;nbsp;not just another GPT wrapper, but a company building&amp;nbsp;the infrastructure and orchestration that could scale if multi-agent systems take off.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The round brings&amp;nbsp;Wonderful‚Äôs&amp;nbsp;total funding to $134 million just four months after the startup came out of stealth with a seed round&amp;nbsp;and a promise to help&amp;nbsp;enterprises deploy customer-facing AI agents across voice, chat, and email in every market and every language.&amp;nbsp;The startup says it tailors the platform to each market it serves, fine-tuning for language, cultural norms, and regulatory environments, and even&amp;nbsp;organizes local teams to manage deployment.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That approach&amp;nbsp;has led to rapid growth&amp;nbsp;for&amp;nbsp;the young startup, which claims its AI agents are already managing tens of thousands of customer requests daily with an 80% resolve rate. Since launching, Wonderful has expanded to Italy, Switzerland, the Netherlands, Greece, Poland, Romania, the Baltics, the&amp;nbsp;Adriatics and the UAE.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With its fresh funding, Wonderful intends to launch in Germany, Austria, the Nordics and Portugal in 2025, and plans to expand in the Asia-Pacific region in early 2026.&amp;nbsp;But the&amp;nbsp;company&amp;nbsp;doesn‚Äôt&amp;nbsp;intend to&amp;nbsp;stop with&amp;nbsp;customer support&amp;nbsp;agents. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since&amp;nbsp;its&amp;nbsp;system plugs deeply into an enterprise customer‚Äôs existing software and can be tailored for each market, the startup says it will be able to give agents the capabilities to perform new tasks with minimal extra effort. It is currently exploring areas like&amp;nbsp;employee training, sales enablement, regulatory compliance, internal IT support, and onboarding, the company said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe promise of AI agents is clear, but putting that into practice, and critically, into production, is a huge challenge,‚Äù Bar Winkler, CEO and co-founder of Wonderful, said in a statement. ‚ÄúIt requires marrying best-in-class technology together with flawless delivery, on the ground with customers.&amp;nbsp;That‚Äôs&amp;nbsp;been our approach with Wonderful, and&amp;nbsp;it‚Äôs&amp;nbsp;what has driven the accelerated adoption&amp;nbsp;we‚Äôve&amp;nbsp;seen across markets in the last few months.‚Äù&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Customer-facing AI agents are&amp;nbsp;emerging&amp;nbsp;as the first real beachhead for the technology, and&amp;nbsp;investors were likely attracted by Wonderful‚Äôs&amp;nbsp;focus here. These use cases help enterprises cut costs by augmenting or replacing human support staff, and&amp;nbsp;they integrate&amp;nbsp;readily into existing call&amp;nbsp;centre&amp;nbsp;infrastructure. Crucially, they also carry less risk than having an AI make internal decisions autonomously ‚Äî&amp;nbsp;a&amp;nbsp;use case that most enterprises&amp;nbsp;aren‚Äôt&amp;nbsp;ready to&amp;nbsp;adopt at&amp;nbsp;scale yet.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Index Ventures partner Hannah Seal pointed to&amp;nbsp;Wonderful‚Äôs&amp;nbsp;ability to ‚Äú[move] from concept to global scale in less than a year‚Äù as a source of confidence for investors. The company‚Äôs true edge, she said, is its ability to deploy agents for global enterprises that function across every market and language.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jeff&amp;nbsp;Horing, co-founder and managing director at Insight Partners,&amp;nbsp;said&amp;nbsp;the adoption Wonderful is seeing across industries shows ‚Äújust how valuable culturally fluent agents can be.‚Äù&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Wonderful-Founders.png?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Israeli&amp;nbsp;AI agent&amp;nbsp;startup&amp;nbsp;Wonderful&amp;nbsp;has raised $100 million in a Series A round led by Index Ventures, with participation from Insight Partners, IVP, Bessemer, and Vine Ventures. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The large round, in a&amp;nbsp;market already crowded&amp;nbsp;with AI agent startups, suggests&amp;nbsp;Wonderful has convinced top tier investors&amp;nbsp;it‚Äôs&amp;nbsp;not just another GPT wrapper, but a company building&amp;nbsp;the infrastructure and orchestration that could scale if multi-agent systems take off.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The round brings&amp;nbsp;Wonderful‚Äôs&amp;nbsp;total funding to $134 million just four months after the startup came out of stealth with a seed round&amp;nbsp;and a promise to help&amp;nbsp;enterprises deploy customer-facing AI agents across voice, chat, and email in every market and every language.&amp;nbsp;The startup says it tailors the platform to each market it serves, fine-tuning for language, cultural norms, and regulatory environments, and even&amp;nbsp;organizes local teams to manage deployment.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That approach&amp;nbsp;has led to rapid growth&amp;nbsp;for&amp;nbsp;the young startup, which claims its AI agents are already managing tens of thousands of customer requests daily with an 80% resolve rate. Since launching, Wonderful has expanded to Italy, Switzerland, the Netherlands, Greece, Poland, Romania, the Baltics, the&amp;nbsp;Adriatics and the UAE.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With its fresh funding, Wonderful intends to launch in Germany, Austria, the Nordics and Portugal in 2025, and plans to expand in the Asia-Pacific region in early 2026.&amp;nbsp;But the&amp;nbsp;company&amp;nbsp;doesn‚Äôt&amp;nbsp;intend to&amp;nbsp;stop with&amp;nbsp;customer support&amp;nbsp;agents. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since&amp;nbsp;its&amp;nbsp;system plugs deeply into an enterprise customer‚Äôs existing software and can be tailored for each market, the startup says it will be able to give agents the capabilities to perform new tasks with minimal extra effort. It is currently exploring areas like&amp;nbsp;employee training, sales enablement, regulatory compliance, internal IT support, and onboarding, the company said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe promise of AI agents is clear, but putting that into practice, and critically, into production, is a huge challenge,‚Äù Bar Winkler, CEO and co-founder of Wonderful, said in a statement. ‚ÄúIt requires marrying best-in-class technology together with flawless delivery, on the ground with customers.&amp;nbsp;That‚Äôs&amp;nbsp;been our approach with Wonderful, and&amp;nbsp;it‚Äôs&amp;nbsp;what has driven the accelerated adoption&amp;nbsp;we‚Äôve&amp;nbsp;seen across markets in the last few months.‚Äù&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Customer-facing AI agents are&amp;nbsp;emerging&amp;nbsp;as the first real beachhead for the technology, and&amp;nbsp;investors were likely attracted by Wonderful‚Äôs&amp;nbsp;focus here. These use cases help enterprises cut costs by augmenting or replacing human support staff, and&amp;nbsp;they integrate&amp;nbsp;readily into existing call&amp;nbsp;centre&amp;nbsp;infrastructure. Crucially, they also carry less risk than having an AI make internal decisions autonomously ‚Äî&amp;nbsp;a&amp;nbsp;use case that most enterprises&amp;nbsp;aren‚Äôt&amp;nbsp;ready to&amp;nbsp;adopt at&amp;nbsp;scale yet.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Index Ventures partner Hannah Seal pointed to&amp;nbsp;Wonderful‚Äôs&amp;nbsp;ability to ‚Äú[move] from concept to global scale in less than a year‚Äù as a source of confidence for investors. The company‚Äôs true edge, she said, is its ability to deploy agents for global enterprises that function across every market and language.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jeff&amp;nbsp;Horing, co-founder and managing director at Insight Partners,&amp;nbsp;said&amp;nbsp;the adoption Wonderful is seeing across industries shows ‚Äújust how valuable culturally fluent agents can be.‚Äù&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/11/wonderful-raised-100m-series-a-to-put-ai-agents-on-the-front-lines-of-customer-service/</guid><pubDate>Tue, 11 Nov 2025 16:08:47 +0000</pubDate></item><item><title>[NEW] BlueCodeAgent: A blue teaming agent enabled by automated red teaming for CodeGen AI (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/bluecodeagent-a-blue-teaming-agent-enabled-by-automated-red-teaming-for-codegen-ai/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a blue-to-green gradient background: the first icon shows a circle with connected nodes, the second shows a circuit, and the third shows a flowchart" class="wp-image-1154392" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/BlueCodeAgent-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="introduction"&gt;Introduction&lt;/h2&gt;



&lt;p&gt;Large&amp;nbsp;language&amp;nbsp;models&amp;nbsp;(LLMs)&amp;nbsp;are now widely used for automated code generation across software engineering tasks. However, this powerful capability in code generation also introduces security concerns. Code generation systems could be misused for harmful purposes, such as generating malicious code.&amp;nbsp;It&amp;nbsp;could also&amp;nbsp;produce&amp;nbsp;bias-filled&amp;nbsp;code reflecting&amp;nbsp;underlying logic that is&amp;nbsp;discriminatory&amp;nbsp;or unethical. Additionally, even when completing benign tasks, LLMs may inadvertently produce vulnerable code that&amp;nbsp;contains&amp;nbsp;security flaws (e.g., injection risks, unsafe input handling). These unsafe outcomes undermine the trustworthiness of code generation models and pose threats to the broader software ecosystem, where safety and reliability are critical.&lt;/p&gt;



&lt;p&gt;Many&amp;nbsp;studies have explored red teaming code LLMs, testing whether the models can reject unsafe requests and whether their generated code&amp;nbsp;exhibits&amp;nbsp;insecure patterns. For more details, see our earlier MSR blog post on&amp;nbsp;RedCodeAgent. While red teaming has significantly improved our understanding of model failure modes, progress on blue teaming‚Äîi.e., developing effective defensive mechanisms to detect and prevent such failures‚Äîremains&amp;nbsp;relatively limited. Current blue teaming approaches face several challenges: (1)&amp;nbsp;Poor alignment with security concepts:&amp;nbsp;additional&amp;nbsp;safety&amp;nbsp;prompts&amp;nbsp;struggle to help models&amp;nbsp;understand high-level notions,&amp;nbsp;such as what constitutes a malicious or bias instruction, and typically lack actionable principles to guide safe decision-making. A case study is shown in Figure 1.&amp;nbsp;(2)&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;Over-conservatism:&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;especially in the domain of vulnerable code detection, models tend to misclassify safe code as unsafe, leading to more false positives and reduced developer trust&lt;strong&gt;.&lt;/strong&gt;&amp;nbsp;(3)&amp;nbsp;Incomplete risk coverage: without a strong knowledge foundation, models perform poorly when dealing with subtle or previously unseen risks.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To address these challenges, researchers from the University of Chicago, University of California, Santa Barbara, University of Illinois Urbana‚ÄìChampaign, VirtueAI, and Microsoft Research recently released a paper: BlueCodeAgent: A Blue Teaming Agent Enabled by Automated Red Teaming for CodeGen AI. This work makes the following key contributions:&amp;nbsp;&lt;/p&gt;



&lt;ol class="wp-block-list" start="1"&gt;
&lt;li&gt;&lt;strong&gt;Diverse red-teaming pipeline:&lt;/strong&gt; The authors design a comprehensive red-teaming process that integrates multiple strategies to synthesize diverse red-teaming data for effective knowledge accumulation.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Knowledge-enhanced blue teaming:&lt;/strong&gt; Building on the foundation of red-teaming knowledge, BlueCodeAgent significantly improves blue-teaming performance by leveraging constitutions derived from knowledge and dynamic testing.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Principled-Level Defense and Nuanced-Level analysis:&lt;/strong&gt; The authors propose two complementary strategies‚ÄîPrincipled-Level Defense (via constitutions) and Nuanced-Level Analysis (via dynamic testing)‚Äîand demonstrate their synergistic effects in vulnerable code detection tasks.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Generalization to seen and unseen risks:&lt;/strong&gt; Empowered by comprehensive red-teaming knowledge, BlueCodeAgent generalizes effectively to unseen risks. Overall, BlueCodeAgent achieves an average 12.7% improvement in F1 score across four datasets and three tasks, attributed to its ability to distill actionable constitutions that enhance context-aware risk detection.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1. A case study of BlueCodeAgent on the bias instruction detection task. Even when concepts such as ‚Äúbiased‚Äù are explicitly included in additional safety prompts, models often fail to recognize biased requests (left). BlueCodeAgent (right) addresses this gap by summarizing constitutions from knowledge and applying concrete, actionable constraints benefited from red teaming to improve the defense. " class="wp-image-1154397" height="371" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/BlueCodeAgent_figure1.png" width="1202" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. A case study of BlueCodeAgent on the bias instruction detection task. Even when concepts such as ‚Äúbiased‚Äù are explicitly included in additional safety prompts, models often fail to recognize biased requests (left). BlueCodeAgent (right) addresses this gap by summarizing constitutions from knowledge and applying concrete, actionable constraints benefited from red teaming to improve the defense. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="a-blue-teaming-agent-enabled-by-red-teaming"&gt;A blue teaming agent enabled by red teaming&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: Overview of BlueCodeAgent, an end-to-end blue teaming framework powered by automated red teaming for code security. By integrating knowledge derived from diverse red teaming and conducting dynamic sandbox-based testing, BlueCodeAgent substantially strengthens the defensive capabilities beyond static LLM analysis. " class="wp-image-1154396" height="581" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/BlueCodeAgent_figure2.png" width="1222" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2: Overview of BlueCodeAgent, an end-to-end blue teaming framework powered by automated red teaming for code security. By integrating knowledge derived from diverse red teaming and conducting dynamic sandbox-based testing, BlueCodeAgent substantially strengthens the defensive capabilities beyond static LLM analysis. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Figure 2 presents an overview of the pipeline. The framework unifies both sides of the process: red teaming generates diverse risky cases and behaviors, which are then distilled into actionable constitutions that encode safety rules on the blue-teaming side. These constitutions guide BlueCodeAgent to more effectively detect unsafe textual inputs and code outputs, mitigating limitations such as poor alignment with abstract security concepts.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This work targets three major risk categories, covering both input/textual-level risks‚Äîincluding biased and malicious instructions‚Äîand output/code-level risks, where models may generate vulnerable code. These categories represent risks that have been widely studied in prior research.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="diverse-red-teaming-process-for-knowledge-accumulation"&gt;Diverse red-teaming process for knowledge accumulation&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Since different tasks require distinct attack strategies, the&amp;nbsp;red-teaming&amp;nbsp;employs multiple attack methods to generate realistic and diverse data. Specifically, the red-teaming process is divided into three categories:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Policy-based instance generation&lt;/strong&gt;: To synthesize policy-grounded red-teaming data, diverse security and ethical policies are first collected. These high-level principles are then used to prompt an uncensored model to generate instances that intentionally violate the specified policies.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Seed-based adversarial prompt optimization&lt;/strong&gt;: Existing adversarial instructions are often overly simplistic and easily rejected by models. To overcome this limitation, an adaptive red-teaming agent invokes various jailbreak tools to iteratively refine initial seed prompts until the prompts achieve high attack success rates.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Knowledge-driven vulnerability generation&lt;/strong&gt;: To synthesize both vulnerable and safe code samples under realistic programming scenarios, domain knowledge of common software weaknesses (CWE) is leveraged to generate diverse code examples.&lt;/li&gt;
&lt;/ol&gt;



&lt;h2 class="wp-block-heading" id="knowledge-enhanced-blue-teaming-agent"&gt;Knowledge-enhanced blue teaming agent&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;After accumulating red-teaming knowledge data, BlueCodeAgent set up &lt;strong&gt;Principled-Level Defense via Constitution Construction&lt;/strong&gt; and &lt;strong&gt;Nuanced-Level Analysis via Dynamic Testing&lt;/strong&gt;.&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Principled-Level Defense via Constitution Construction&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;Based on the most relevant knowledge data&lt;strong&gt;, &lt;/strong&gt;BlueCodeAgent summarizes red-teamed knowledge into actionable constitutions‚Äîexplicit rules and principles distilled from prior attack data. These constitutions serve as normative guidelines, enabling the model to stay aligned with ethical and security principles even when confronted with novel or unseen adversarial inputs.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Nuanced-Level Analysis via Dynamic Testing&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;In vulnerable code detection, BlueCodeAgent augments static reasoning with dynamic sandbox-based analysis, executing generated code within isolated Docker environments to verify whether the model-reported vulnerabilities manifest as actual unsafe behaviors. This dynamic validation effectively mitigates the model‚Äôs tendency toward over-conservatism, where benign code is mistakenly flagged as vulnerable.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Event Series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Forum&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-forum"&gt;Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="insights-from-bluecodeagent"&gt;Insights from BlueCodeAgent&amp;nbsp;&lt;/h2&gt;



&lt;h3 class="wp-block-heading" id="bluecodeagent-outperforms-prompting-baselines"&gt;BlueCodeAgent outperforms prompting baselines&amp;nbsp;&lt;/h3&gt;



&lt;p&gt;As shown in Figure 3, BlueCodeAgent significantly outperforms other baselines. Several findings are highlighted.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;(1) Even when test categories differ from knowledge categories to simulate unseen scenarios, BlueCodeAgent effectively leverages previously seen risks to handle unseen ones, benefiting from its knowledge-enhanced safety reasoning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;(2) BlueCodeAgent is model-agnostic, working consistently across diverse base LLMs, including both open-source and commercial models. Its F1 scores for bias and malicious instruction detection approach 1.0, highlighting strong effectiveness.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;(3) BlueCodeAgent achieves a strong balance between safety and usability. It accurately identifies unsafe inputs while maintaining a reasonable false-positive rate on benign ones, resulting in a consistently high F1 score.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;(4) By contrast, prompting with general or fine-grained safety reminders remains insufficient for effective blue teaming, as models struggle to internalize abstract safety concepts and apply them to unseen risky scenarios. BlueCodeAgent bridges this gap by distilling actionable constitutions from knowledge, using concrete and interpretable safety constraints to enhance model alignment.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3. F1 scores on bias instruction detection task (BlueCodeEval-Bias) in the first row and on malicious instruction detection task (BlueCodeEval-Mal, RedCode-based) in the second row. " class="wp-image-1154395" height="602" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/BlueCodeAgent_figure3.png" width="993" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt;&amp;nbsp;F1 scores on bias instruction detection task (BlueCodeEval-Bias) in the first row and on malicious instruction detection task (BlueCodeEval-Mal) in the second row.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="complementary-effects-of-constitutions-and-dynamic-testing"&gt;Complementary effects of constitutions and dynamic testing&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;In vulnerability detection tasks, models tend to behave conservatively‚Äîan effect also noted in prior research. They are often more likely to flag code as &lt;em&gt;unsafe&lt;/em&gt; rather than &lt;em&gt;safe&lt;/em&gt;. This bias is understandable: confirming that code is completely free from vulnerabilities is generally harder than spotting a potential issue.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To mitigate this over-conservatism, BlueCodeAgent integrates dynamic testing into its analysis pipeline. When BlueCodeAgent identifies a potential vulnerability, it triggers a reliable model (Claude-3.7-Sonnet-20250219) to generate test cases and corresponding executable code that embeds the suspicious snippet. These test cases are then run in a controlled environment to verify whether the vulnerability actually manifests. The final judgment combines the LLM‚Äôs analysis of the static code, the generated test code, run-time execution results, and constitutions derived from knowledge.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Researchers find the two components‚Äîconstitutions and dynamic testing‚Äîplay complementary roles. Constitutions expand the model‚Äôs understanding of risk, increasing true positives (TP) and reducing false negatives (FN). Dynamic testing, on the other hand, focuses on reducing false positives (FP) by validating whether predicted vulnerabilities can truly be triggered at run-time. Together, they make BlueCodeAgent both more accurate and more reliable in blue-teaming scenarios.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="summary"&gt;Summary&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;BlueCodeAgent introduces an end-to-end blue-teaming framework designed to address risks in code generation. The key insight behind BlueCodeAgent is that comprehensive red-teaming can greatly strengthen blue-teaming defenses. Based on this idea, the framework first builds a red-teaming process with diverse strategies for generating red-teaming data. It then constructs a blue-teaming agent that retrieves relevant examples from the red-teaming knowledge base and summarizes safety constitutions to guide LLMs in making accurate defensive decisions. A dynamic testing component is further added to reduce false positives in vulnerability detection.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Looking ahead, several directions hold promise.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;First, it is valuable to explore the generalization of BlueCodeAgent to other categories of code-generation risks beyond bias, malicious code, and vulnerable code. This may require designing and integrating novel red-teaming strategies into BlueCodeAgent and creating corresponding benchmarks for new risks.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Second, scaling BlueCodeAgent to the file and repository levels could further enhance its real-world utility, which requires equipping agents with more advanced context retrieval tools and memory components.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Finally, beyond code generation, it is also important to extend BlueCodeAgent to mitigate risks in other modalities, including text, image, video, and audio, as well as in multimodal applications.&amp;nbsp;&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a blue-to-green gradient background: the first icon shows a circle with connected nodes, the second shows a circuit, and the third shows a flowchart" class="wp-image-1154392" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/BlueCodeAgent-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="introduction"&gt;Introduction&lt;/h2&gt;



&lt;p&gt;Large&amp;nbsp;language&amp;nbsp;models&amp;nbsp;(LLMs)&amp;nbsp;are now widely used for automated code generation across software engineering tasks. However, this powerful capability in code generation also introduces security concerns. Code generation systems could be misused for harmful purposes, such as generating malicious code.&amp;nbsp;It&amp;nbsp;could also&amp;nbsp;produce&amp;nbsp;bias-filled&amp;nbsp;code reflecting&amp;nbsp;underlying logic that is&amp;nbsp;discriminatory&amp;nbsp;or unethical. Additionally, even when completing benign tasks, LLMs may inadvertently produce vulnerable code that&amp;nbsp;contains&amp;nbsp;security flaws (e.g., injection risks, unsafe input handling). These unsafe outcomes undermine the trustworthiness of code generation models and pose threats to the broader software ecosystem, where safety and reliability are critical.&lt;/p&gt;



&lt;p&gt;Many&amp;nbsp;studies have explored red teaming code LLMs, testing whether the models can reject unsafe requests and whether their generated code&amp;nbsp;exhibits&amp;nbsp;insecure patterns. For more details, see our earlier MSR blog post on&amp;nbsp;RedCodeAgent. While red teaming has significantly improved our understanding of model failure modes, progress on blue teaming‚Äîi.e., developing effective defensive mechanisms to detect and prevent such failures‚Äîremains&amp;nbsp;relatively limited. Current blue teaming approaches face several challenges: (1)&amp;nbsp;Poor alignment with security concepts:&amp;nbsp;additional&amp;nbsp;safety&amp;nbsp;prompts&amp;nbsp;struggle to help models&amp;nbsp;understand high-level notions,&amp;nbsp;such as what constitutes a malicious or bias instruction, and typically lack actionable principles to guide safe decision-making. A case study is shown in Figure 1.&amp;nbsp;(2)&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;Over-conservatism:&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;especially in the domain of vulnerable code detection, models tend to misclassify safe code as unsafe, leading to more false positives and reduced developer trust&lt;strong&gt;.&lt;/strong&gt;&amp;nbsp;(3)&amp;nbsp;Incomplete risk coverage: without a strong knowledge foundation, models perform poorly when dealing with subtle or previously unseen risks.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To address these challenges, researchers from the University of Chicago, University of California, Santa Barbara, University of Illinois Urbana‚ÄìChampaign, VirtueAI, and Microsoft Research recently released a paper: BlueCodeAgent: A Blue Teaming Agent Enabled by Automated Red Teaming for CodeGen AI. This work makes the following key contributions:&amp;nbsp;&lt;/p&gt;



&lt;ol class="wp-block-list" start="1"&gt;
&lt;li&gt;&lt;strong&gt;Diverse red-teaming pipeline:&lt;/strong&gt; The authors design a comprehensive red-teaming process that integrates multiple strategies to synthesize diverse red-teaming data for effective knowledge accumulation.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Knowledge-enhanced blue teaming:&lt;/strong&gt; Building on the foundation of red-teaming knowledge, BlueCodeAgent significantly improves blue-teaming performance by leveraging constitutions derived from knowledge and dynamic testing.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Principled-Level Defense and Nuanced-Level analysis:&lt;/strong&gt; The authors propose two complementary strategies‚ÄîPrincipled-Level Defense (via constitutions) and Nuanced-Level Analysis (via dynamic testing)‚Äîand demonstrate their synergistic effects in vulnerable code detection tasks.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Generalization to seen and unseen risks:&lt;/strong&gt; Empowered by comprehensive red-teaming knowledge, BlueCodeAgent generalizes effectively to unseen risks. Overall, BlueCodeAgent achieves an average 12.7% improvement in F1 score across four datasets and three tasks, attributed to its ability to distill actionable constitutions that enhance context-aware risk detection.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1. A case study of BlueCodeAgent on the bias instruction detection task. Even when concepts such as ‚Äúbiased‚Äù are explicitly included in additional safety prompts, models often fail to recognize biased requests (left). BlueCodeAgent (right) addresses this gap by summarizing constitutions from knowledge and applying concrete, actionable constraints benefited from red teaming to improve the defense. " class="wp-image-1154397" height="371" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/BlueCodeAgent_figure1.png" width="1202" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. A case study of BlueCodeAgent on the bias instruction detection task. Even when concepts such as ‚Äúbiased‚Äù are explicitly included in additional safety prompts, models often fail to recognize biased requests (left). BlueCodeAgent (right) addresses this gap by summarizing constitutions from knowledge and applying concrete, actionable constraints benefited from red teaming to improve the defense. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="a-blue-teaming-agent-enabled-by-red-teaming"&gt;A blue teaming agent enabled by red teaming&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: Overview of BlueCodeAgent, an end-to-end blue teaming framework powered by automated red teaming for code security. By integrating knowledge derived from diverse red teaming and conducting dynamic sandbox-based testing, BlueCodeAgent substantially strengthens the defensive capabilities beyond static LLM analysis. " class="wp-image-1154396" height="581" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/BlueCodeAgent_figure2.png" width="1222" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2: Overview of BlueCodeAgent, an end-to-end blue teaming framework powered by automated red teaming for code security. By integrating knowledge derived from diverse red teaming and conducting dynamic sandbox-based testing, BlueCodeAgent substantially strengthens the defensive capabilities beyond static LLM analysis. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Figure 2 presents an overview of the pipeline. The framework unifies both sides of the process: red teaming generates diverse risky cases and behaviors, which are then distilled into actionable constitutions that encode safety rules on the blue-teaming side. These constitutions guide BlueCodeAgent to more effectively detect unsafe textual inputs and code outputs, mitigating limitations such as poor alignment with abstract security concepts.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This work targets three major risk categories, covering both input/textual-level risks‚Äîincluding biased and malicious instructions‚Äîand output/code-level risks, where models may generate vulnerable code. These categories represent risks that have been widely studied in prior research.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="diverse-red-teaming-process-for-knowledge-accumulation"&gt;Diverse red-teaming process for knowledge accumulation&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Since different tasks require distinct attack strategies, the&amp;nbsp;red-teaming&amp;nbsp;employs multiple attack methods to generate realistic and diverse data. Specifically, the red-teaming process is divided into three categories:&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Policy-based instance generation&lt;/strong&gt;: To synthesize policy-grounded red-teaming data, diverse security and ethical policies are first collected. These high-level principles are then used to prompt an uncensored model to generate instances that intentionally violate the specified policies.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Seed-based adversarial prompt optimization&lt;/strong&gt;: Existing adversarial instructions are often overly simplistic and easily rejected by models. To overcome this limitation, an adaptive red-teaming agent invokes various jailbreak tools to iteratively refine initial seed prompts until the prompts achieve high attack success rates.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Knowledge-driven vulnerability generation&lt;/strong&gt;: To synthesize both vulnerable and safe code samples under realistic programming scenarios, domain knowledge of common software weaknesses (CWE) is leveraged to generate diverse code examples.&lt;/li&gt;
&lt;/ol&gt;



&lt;h2 class="wp-block-heading" id="knowledge-enhanced-blue-teaming-agent"&gt;Knowledge-enhanced blue teaming agent&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;After accumulating red-teaming knowledge data, BlueCodeAgent set up &lt;strong&gt;Principled-Level Defense via Constitution Construction&lt;/strong&gt; and &lt;strong&gt;Nuanced-Level Analysis via Dynamic Testing&lt;/strong&gt;.&lt;/p&gt;



&lt;ol class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Principled-Level Defense via Constitution Construction&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;Based on the most relevant knowledge data&lt;strong&gt;, &lt;/strong&gt;BlueCodeAgent summarizes red-teamed knowledge into actionable constitutions‚Äîexplicit rules and principles distilled from prior attack data. These constitutions serve as normative guidelines, enabling the model to stay aligned with ethical and security principles even when confronted with novel or unseen adversarial inputs.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Nuanced-Level Analysis via Dynamic Testing&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;In vulnerable code detection, BlueCodeAgent augments static reasoning with dynamic sandbox-based analysis, executing generated code within isolated Docker environments to verify whether the model-reported vulnerabilities manifest as actual unsafe behaviors. This dynamic validation effectively mitigates the model‚Äôs tendency toward over-conservatism, where benign code is mistakenly flagged as vulnerable.&amp;nbsp;&lt;/li&gt;
&lt;/ol&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Event Series&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Forum&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-forum"&gt;Join us for a continuous exchange of ideas about research in the era of general AI. Watch the first four episodes on demand.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="insights-from-bluecodeagent"&gt;Insights from BlueCodeAgent&amp;nbsp;&lt;/h2&gt;



&lt;h3 class="wp-block-heading" id="bluecodeagent-outperforms-prompting-baselines"&gt;BlueCodeAgent outperforms prompting baselines&amp;nbsp;&lt;/h3&gt;



&lt;p&gt;As shown in Figure 3, BlueCodeAgent significantly outperforms other baselines. Several findings are highlighted.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;(1) Even when test categories differ from knowledge categories to simulate unseen scenarios, BlueCodeAgent effectively leverages previously seen risks to handle unseen ones, benefiting from its knowledge-enhanced safety reasoning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;(2) BlueCodeAgent is model-agnostic, working consistently across diverse base LLMs, including both open-source and commercial models. Its F1 scores for bias and malicious instruction detection approach 1.0, highlighting strong effectiveness.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;(3) BlueCodeAgent achieves a strong balance between safety and usability. It accurately identifies unsafe inputs while maintaining a reasonable false-positive rate on benign ones, resulting in a consistently high F1 score.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;(4) By contrast, prompting with general or fine-grained safety reminders remains insufficient for effective blue teaming, as models struggle to internalize abstract safety concepts and apply them to unseen risky scenarios. BlueCodeAgent bridges this gap by distilling actionable constitutions from knowledge, using concrete and interpretable safety constraints to enhance model alignment.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 3. F1 scores on bias instruction detection task (BlueCodeEval-Bias) in the first row and on malicious instruction detection task (BlueCodeEval-Mal, RedCode-based) in the second row. " class="wp-image-1154395" height="602" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/10/BlueCodeAgent_figure3.png" width="993" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt;&amp;nbsp;F1 scores on bias instruction detection task (BlueCodeEval-Bias) in the first row and on malicious instruction detection task (BlueCodeEval-Mal) in the second row.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="complementary-effects-of-constitutions-and-dynamic-testing"&gt;Complementary effects of constitutions and dynamic testing&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;In vulnerability detection tasks, models tend to behave conservatively‚Äîan effect also noted in prior research. They are often more likely to flag code as &lt;em&gt;unsafe&lt;/em&gt; rather than &lt;em&gt;safe&lt;/em&gt;. This bias is understandable: confirming that code is completely free from vulnerabilities is generally harder than spotting a potential issue.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To mitigate this over-conservatism, BlueCodeAgent integrates dynamic testing into its analysis pipeline. When BlueCodeAgent identifies a potential vulnerability, it triggers a reliable model (Claude-3.7-Sonnet-20250219) to generate test cases and corresponding executable code that embeds the suspicious snippet. These test cases are then run in a controlled environment to verify whether the vulnerability actually manifests. The final judgment combines the LLM‚Äôs analysis of the static code, the generated test code, run-time execution results, and constitutions derived from knowledge.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Researchers find the two components‚Äîconstitutions and dynamic testing‚Äîplay complementary roles. Constitutions expand the model‚Äôs understanding of risk, increasing true positives (TP) and reducing false negatives (FN). Dynamic testing, on the other hand, focuses on reducing false positives (FP) by validating whether predicted vulnerabilities can truly be triggered at run-time. Together, they make BlueCodeAgent both more accurate and more reliable in blue-teaming scenarios.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="summary"&gt;Summary&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;BlueCodeAgent introduces an end-to-end blue-teaming framework designed to address risks in code generation. The key insight behind BlueCodeAgent is that comprehensive red-teaming can greatly strengthen blue-teaming defenses. Based on this idea, the framework first builds a red-teaming process with diverse strategies for generating red-teaming data. It then constructs a blue-teaming agent that retrieves relevant examples from the red-teaming knowledge base and summarizes safety constitutions to guide LLMs in making accurate defensive decisions. A dynamic testing component is further added to reduce false positives in vulnerability detection.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Looking ahead, several directions hold promise.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;First, it is valuable to explore the generalization of BlueCodeAgent to other categories of code-generation risks beyond bias, malicious code, and vulnerable code. This may require designing and integrating novel red-teaming strategies into BlueCodeAgent and creating corresponding benchmarks for new risks.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Second, scaling BlueCodeAgent to the file and repository levels could further enhance its real-world utility, which requires equipping agents with more advanced context retrieval tools and memory components.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Finally, beyond code generation, it is also important to extend BlueCodeAgent to mitigate risks in other modalities, including text, image, video, and audio, as well as in multimodal applications.&amp;nbsp;&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/bluecodeagent-a-blue-teaming-agent-enabled-by-automated-red-teaming-for-codegen-ai/</guid><pubDate>Tue, 11 Nov 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Google announces even more AI in Photos app, powered by Nano Banana (AI ‚Äì Ars Technica)</title><link>https://arstechnica.com/google/2025/11/googles-nano-banana-ai-image-editing-is-finally-coming-to-google-photos/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google‚Äôs Nano Banana is powering a raft of new features in the app.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Photos nano banana" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GP_Nov-AI-Feature_Blog-Post-Hero-640x361.png" width="640" /&gt;
                  &lt;img alt="Photos nano banana" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GP_Nov-AI-Feature_Blog-Post-Hero-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;We‚Äôre running out of ways to tell you that Google is releasing more generative AI features, but that‚Äôs what‚Äôs happening in Google Photos today. The Big G is finally making good on its promise to add its market-leading Nano Banana image-editing model to the app. The model powers a couple of features, and it‚Äôs not just for Google‚Äôs Android platform. Nano Banana edits are also coming to the iOS version of the app.&lt;/p&gt;
&lt;p&gt;Nano Banana started making waves when it appeared earlier this year as an unbranded demo. You simply feed the model an image and tell it what edits you want to see. Google said Nano Banana was destined for the Photos app back in October, but it‚Äôs only now beginning the rollout. The Photos app already had conversational editing in the ‚ÄúHelp Me Edit‚Äù feature, but it was running an older non-fruit model that produced inferior results. Nano Banana editing will produce AI slop, yes, but it‚Äôs &lt;em&gt;better&lt;/em&gt; slop.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2126656-1" preload="metadata" width="1080"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Nano-Banana-in-Help-me-edit.mp4?_=1" type="video/mp4" /&gt;Nano Banana in Help me edit&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Nano Banana in Help me edit

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Google says the updated Help Me Edit feature has access to your private face groups, so you can use names in your instructions. For example, you could type ‚ÄúRemove Riley‚Äôs sunglasses,‚Äù and Nano Banana will identify Riley in the photo (assuming you have a person of that name saved) and make the edit without further instructions. You can also ask for more fantastical edits in Help Me Edit, changing the style of the image from top to bottom.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Google is very invested in getting people to use its AI tools, but less-savvy users might not be familiar enough with AI prompting to get the most out of Nano Banana. So Google Photos is also getting a collection of AI templates in a new ‚ÄúCreate with AI‚Äù section. This menu will offer pre-formed prompts based on popular in-app edits. Some of the options you‚Äôll see include ‚Äúput me in a high fashion photoshoot,‚Äù ‚Äúcreate a professional headshot,‚Äù and ‚Äúput me in a winter holiday card.‚Äù&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2126656-2" preload="metadata" width="1080"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Ask-button.mp4?_=2" type="video/mp4" /&gt;The Ask button is yet another route to Gemini chitchat.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Ask button is yet another route to Gemini chitchat.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The app is also getting a new ‚ÄúAsk‚Äù button, which is not to be confused with ‚ÄúAsk Photos.‚Äù The former is a new contextual button that appears when viewing a photo, and the latter is Google‚Äôs controversial natural language search feature. Ask Photos is expanding to more than 100 new countries this week, but the new Ask button will only be available in the US for now. When looking at a photo, you can tap the Ask button to get information about the content of the photo or find related images. You can also describe edits you‚Äôd like to see in this interface, and Nano Banana will make them for you.&lt;/p&gt;
&lt;p&gt;According to Google, these new features are rolling out now‚Äîin Google-ese, ‚Äúnow‚Äù usually means a few days for full visibility.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google‚Äôs Nano Banana is powering a raft of new features in the app.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Photos nano banana" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GP_Nov-AI-Feature_Blog-Post-Hero-640x361.png" width="640" /&gt;
                  &lt;img alt="Photos nano banana" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GP_Nov-AI-Feature_Blog-Post-Hero-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;We‚Äôre running out of ways to tell you that Google is releasing more generative AI features, but that‚Äôs what‚Äôs happening in Google Photos today. The Big G is finally making good on its promise to add its market-leading Nano Banana image-editing model to the app. The model powers a couple of features, and it‚Äôs not just for Google‚Äôs Android platform. Nano Banana edits are also coming to the iOS version of the app.&lt;/p&gt;
&lt;p&gt;Nano Banana started making waves when it appeared earlier this year as an unbranded demo. You simply feed the model an image and tell it what edits you want to see. Google said Nano Banana was destined for the Photos app back in October, but it‚Äôs only now beginning the rollout. The Photos app already had conversational editing in the ‚ÄúHelp Me Edit‚Äù feature, but it was running an older non-fruit model that produced inferior results. Nano Banana editing will produce AI slop, yes, but it‚Äôs &lt;em&gt;better&lt;/em&gt; slop.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2126656-1" preload="metadata" width="1080"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Nano-Banana-in-Help-me-edit.mp4?_=1" type="video/mp4" /&gt;Nano Banana in Help me edit&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Nano Banana in Help me edit

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Google says the updated Help Me Edit feature has access to your private face groups, so you can use names in your instructions. For example, you could type ‚ÄúRemove Riley‚Äôs sunglasses,‚Äù and Nano Banana will identify Riley in the photo (assuming you have a person of that name saved) and make the edit without further instructions. You can also ask for more fantastical edits in Help Me Edit, changing the style of the image from top to bottom.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Google is very invested in getting people to use its AI tools, but less-savvy users might not be familiar enough with AI prompting to get the most out of Nano Banana. So Google Photos is also getting a collection of AI templates in a new ‚ÄúCreate with AI‚Äù section. This menu will offer pre-formed prompts based on popular in-app edits. Some of the options you‚Äôll see include ‚Äúput me in a high fashion photoshoot,‚Äù ‚Äúcreate a professional headshot,‚Äù and ‚Äúput me in a winter holiday card.‚Äù&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2126656-2" preload="metadata" width="1080"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Ask-button.mp4?_=2" type="video/mp4" /&gt;The Ask button is yet another route to Gemini chitchat.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Ask button is yet another route to Gemini chitchat.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The app is also getting a new ‚ÄúAsk‚Äù button, which is not to be confused with ‚ÄúAsk Photos.‚Äù The former is a new contextual button that appears when viewing a photo, and the latter is Google‚Äôs controversial natural language search feature. Ask Photos is expanding to more than 100 new countries this week, but the new Ask button will only be available in the US for now. When looking at a photo, you can tap the Ask button to get information about the content of the photo or find related images. You can also describe edits you‚Äôd like to see in this interface, and Nano Banana will make them for you.&lt;/p&gt;
&lt;p&gt;According to Google, these new features are rolling out now‚Äîin Google-ese, ‚Äúnow‚Äù usually means a few days for full visibility.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/11/googles-nano-banana-ai-image-editing-is-finally-coming-to-google-photos/</guid><pubDate>Tue, 11 Nov 2025 17:00:11 +0000</pubDate></item><item><title>[NEW] Wiz: Security lapses emerge amid the global AI race (AI News)</title><link>https://www.artificialintelligence-news.com/news/wiz-security-lapses-emerge-amid-global-ai-race/</link><description>&lt;p&gt;According to Wiz, the race among AI companies is causing many to overlook basic security hygiene practices.&lt;/p&gt;&lt;p&gt;65 percent of the 50 leading AI firms the cybersecurity firm analysed had leaked verified secrets on GitHub. The exposures include API keys, tokens, and sensitive credentials, often buried in code repositories that standard security tools do not check.&lt;/p&gt;&lt;p&gt;Glyn Morgan, Country Manager for UK&amp;amp;I at Salt Security, described this trend as a preventable and basic error. ‚ÄúWhen AI firms accidentally expose their API keys they lay bare a glaring avoidable security failure,‚Äù he said.&lt;/p&gt;&lt;p&gt;‚ÄúIt‚Äôs the textbook example of governance paired with a security configuration, two of the risk categories that OWASP flags. By pushing credentials into code repositories they hand attackers a golden ticket to systems, data, and models, effectively sidestepping the usual defensive layers.‚Äù&lt;/p&gt;&lt;p&gt;Wiz‚Äôs report highlights the increasingly complex supply chain security risk. The problem extends beyond internal development teams; as enterprises increasingly partner with AI startups, they may inherit their security posture. The researchers warn that some of the leaks they found ‚Äúcould have exposed organisational structures, training data, or even private models.‚Äù&lt;/p&gt;&lt;p&gt;The financial stakes are considerable. The companies analysed with verified leaks have a combined valuation of over $400 billion.&lt;/p&gt;&lt;p&gt;The report, which focused on companies listed in the Forbes AI 50, provides examples of the risks:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;LangChain was found to have exposed multiple Langsmith API keys, some with permissions to manage the organisation and list its members. This type of information is highly valued by attackers for reconnaissance.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;An enterprise-tier API key for ElevenLabs was discovered sitting in a plaintext file.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;An unnamed AI 50 company had a HuggingFace token exposed in a deleted code fork. This single token ‚Äúallow[ed] access to about 1K private models‚Äù. The same company also leaked WeightsAndBiases keys, exposing the ‚Äútraining data for many private models.‚Äù&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The Wiz report suggests this problem is so prevalent because traditional security scanning methods are no longer sufficient. Relying on basic scans of a company‚Äôs main GitHub repositories is a ‚Äúcommoditised approach‚Äù that misses the most severe risks .&lt;/p&gt;&lt;p&gt;The researchers describe the situation as an ‚Äúiceberg‚Äù (i.e. the most obvious risks are visible, but the greater danger lies ‚Äúbelow the surface‚Äù.) To find these hidden risks, the researchers adopted a three-dimensional scanning methodology they call ‚ÄúDepth, Perimeter, and Coverage‚Äù:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Depth:&lt;/strong&gt; Their deep scan analysed the ‚Äúfull commit history, commit history on forks, deleted forks, workflow logs and gists‚Äù‚Äîareas most scanners ‚Äúnever touch‚Äù.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Perimeter:&lt;/strong&gt; The scan was expanded beyond the core company organisation to include organisation members and contributors. These individuals might ‚Äúinadvertently check company-related secrets into their own public repositories‚Äù. The team identified these adjacent accounts by tracking code contributors, organisation followers, and even ‚Äúcorrelations in related networks like HuggingFace and npm.‚Äù&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Coverage:&lt;/strong&gt; The researchers specifically looked for new AI-related secret types that traditional scanners often miss, such as keys for platforms like WeightsAndBiases, Groq, and Perplexity.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This expanded attack surface is particularly worrying given the apparent lack of security maturity at many fast-moving companies. The report notes that when researchers tried to disclose the leaks, almost half of disclosures either failed to reach the target or received no response. Many firms lacked an official disclosure channel or simply failed to resolve the issue when notified.&lt;/p&gt;&lt;p&gt;Wiz‚Äôs findings serve as a warning for enterprise technology executives, highlighting three immediate action items for managing both internal and third-party security risk.&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;Security leaders must treat their employees as part of their company‚Äôs attack surface. The report recommends creating a Version Control System (VCS) member policy to be applied during employee onboarding. This policy should mandate practices such as using multi-factor authentication for personal accounts and maintaining a strict separation between personal and professional activity on platforms like GitHub.&lt;/li&gt;&lt;/ol&gt;&lt;ol class="wp-block-list" start="2"&gt;&lt;li&gt;Internal secret scanning must evolve beyond basic repository checks. The report urges companies to mandate public VCS secret scanning as a ‚Äúnon-negotiable defense‚Äù. This scanning must adopt the aforementioned ‚ÄúDepth, Perimeter, and Coverage‚Äù mindset to find threats lurking below the surface.&lt;/li&gt;&lt;/ol&gt;&lt;ol class="wp-block-list" start="3"&gt;&lt;li&gt;This level of scrutiny must be extended to the entire AI supply chain. When evaluating or integrating tools from AI vendors, CISOs should probe their secrets management and vulnerability disclosure practices. The report notes that many AI service providers are leaking their own API keys and should ‚Äúprioritise detection for their own secret types.‚Äù&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The central message for enterprises is that the tools and platforms defining the next generation of technology are being built at a pace that often outstrips security governance. As Wiz concludes, ‚ÄúFor AI innovators, the message is clear: speed cannot compromise security‚Äù. For the enterprises that depend on that innovation, the same warning applies.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Exclusive: Dubai‚Äôs Digital Government chief says speed trumps spending in AI efficiency race&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;According to Wiz, the race among AI companies is causing many to overlook basic security hygiene practices.&lt;/p&gt;&lt;p&gt;65 percent of the 50 leading AI firms the cybersecurity firm analysed had leaked verified secrets on GitHub. The exposures include API keys, tokens, and sensitive credentials, often buried in code repositories that standard security tools do not check.&lt;/p&gt;&lt;p&gt;Glyn Morgan, Country Manager for UK&amp;amp;I at Salt Security, described this trend as a preventable and basic error. ‚ÄúWhen AI firms accidentally expose their API keys they lay bare a glaring avoidable security failure,‚Äù he said.&lt;/p&gt;&lt;p&gt;‚ÄúIt‚Äôs the textbook example of governance paired with a security configuration, two of the risk categories that OWASP flags. By pushing credentials into code repositories they hand attackers a golden ticket to systems, data, and models, effectively sidestepping the usual defensive layers.‚Äù&lt;/p&gt;&lt;p&gt;Wiz‚Äôs report highlights the increasingly complex supply chain security risk. The problem extends beyond internal development teams; as enterprises increasingly partner with AI startups, they may inherit their security posture. The researchers warn that some of the leaks they found ‚Äúcould have exposed organisational structures, training data, or even private models.‚Äù&lt;/p&gt;&lt;p&gt;The financial stakes are considerable. The companies analysed with verified leaks have a combined valuation of over $400 billion.&lt;/p&gt;&lt;p&gt;The report, which focused on companies listed in the Forbes AI 50, provides examples of the risks:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;LangChain was found to have exposed multiple Langsmith API keys, some with permissions to manage the organisation and list its members. This type of information is highly valued by attackers for reconnaissance.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;An enterprise-tier API key for ElevenLabs was discovered sitting in a plaintext file.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;An unnamed AI 50 company had a HuggingFace token exposed in a deleted code fork. This single token ‚Äúallow[ed] access to about 1K private models‚Äù. The same company also leaked WeightsAndBiases keys, exposing the ‚Äútraining data for many private models.‚Äù&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The Wiz report suggests this problem is so prevalent because traditional security scanning methods are no longer sufficient. Relying on basic scans of a company‚Äôs main GitHub repositories is a ‚Äúcommoditised approach‚Äù that misses the most severe risks .&lt;/p&gt;&lt;p&gt;The researchers describe the situation as an ‚Äúiceberg‚Äù (i.e. the most obvious risks are visible, but the greater danger lies ‚Äúbelow the surface‚Äù.) To find these hidden risks, the researchers adopted a three-dimensional scanning methodology they call ‚ÄúDepth, Perimeter, and Coverage‚Äù:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Depth:&lt;/strong&gt; Their deep scan analysed the ‚Äúfull commit history, commit history on forks, deleted forks, workflow logs and gists‚Äù‚Äîareas most scanners ‚Äúnever touch‚Äù.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Perimeter:&lt;/strong&gt; The scan was expanded beyond the core company organisation to include organisation members and contributors. These individuals might ‚Äúinadvertently check company-related secrets into their own public repositories‚Äù. The team identified these adjacent accounts by tracking code contributors, organisation followers, and even ‚Äúcorrelations in related networks like HuggingFace and npm.‚Äù&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Coverage:&lt;/strong&gt; The researchers specifically looked for new AI-related secret types that traditional scanners often miss, such as keys for platforms like WeightsAndBiases, Groq, and Perplexity.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This expanded attack surface is particularly worrying given the apparent lack of security maturity at many fast-moving companies. The report notes that when researchers tried to disclose the leaks, almost half of disclosures either failed to reach the target or received no response. Many firms lacked an official disclosure channel or simply failed to resolve the issue when notified.&lt;/p&gt;&lt;p&gt;Wiz‚Äôs findings serve as a warning for enterprise technology executives, highlighting three immediate action items for managing both internal and third-party security risk.&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;Security leaders must treat their employees as part of their company‚Äôs attack surface. The report recommends creating a Version Control System (VCS) member policy to be applied during employee onboarding. This policy should mandate practices such as using multi-factor authentication for personal accounts and maintaining a strict separation between personal and professional activity on platforms like GitHub.&lt;/li&gt;&lt;/ol&gt;&lt;ol class="wp-block-list" start="2"&gt;&lt;li&gt;Internal secret scanning must evolve beyond basic repository checks. The report urges companies to mandate public VCS secret scanning as a ‚Äúnon-negotiable defense‚Äù. This scanning must adopt the aforementioned ‚ÄúDepth, Perimeter, and Coverage‚Äù mindset to find threats lurking below the surface.&lt;/li&gt;&lt;/ol&gt;&lt;ol class="wp-block-list" start="3"&gt;&lt;li&gt;This level of scrutiny must be extended to the entire AI supply chain. When evaluating or integrating tools from AI vendors, CISOs should probe their secrets management and vulnerability disclosure practices. The report notes that many AI service providers are leaking their own API keys and should ‚Äúprioritise detection for their own secret types.‚Äù&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The central message for enterprises is that the tools and platforms defining the next generation of technology are being built at a pace that often outstrips security governance. As Wiz concludes, ‚ÄúFor AI innovators, the message is clear: speed cannot compromise security‚Äù. For the enterprises that depend on that innovation, the same warning applies.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Exclusive: Dubai‚Äôs Digital Government chief says speed trumps spending in AI efficiency race&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/wiz-security-lapses-emerge-amid-global-ai-race/</guid><pubDate>Tue, 11 Nov 2025 17:05:25 +0000</pubDate></item><item><title>[NEW] How AI startups should be thinking about product-market fit (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/11/how-ai-startups-should-be-thinking-about-product-market-fit/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/disrupt-2025-product-market-fit-panel.jpeg?resize=1200,859" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For all their pitches promising something new, AI startups share many of the same questions as startups in years past: How do they know when they‚Äôve achieved the holy grail of product-market fit?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Product-market fit has been studied extensively over the years; entire books have been written about how to master the art. But as with so many things, AI is upending established practices.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;‚ÄúHonestly, it just could not be more different from all the playbooks that we‚Äôve all been taught in tech in the past,‚Äù Ann Bordetsky, a partner at New Enterprise Associates, told a standing room-only crowd at TechCrunch Disrupt in San Francisco. ‚ÄúIt‚Äôs a completely different ball game.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Top of the list is the pace of change in the AI world. ‚ÄúThe technology itself isn‚Äôt static,‚Äù she said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even still, there are ways that founders and operators can evaluate whether they have product-market fit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the best things to watch, Murali Joshi, a partner at Iconiq, told the audience, is ‚Äúdurability of spend.‚Äù AI is still early in the adoption curve at many companies, and so much of their spend is focused on experimentation rather than integration.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIncreasingly, we‚Äôre seeing people really shift away from just experimental AI budgets to core office of the CXO budgets,‚Äù Joshi said. ‚ÄúDigging into that is super critical to ensure that this is a tool, a solution, a platform that‚Äôs here to stay, versus something that they‚Äôre just testing and trying out.‚Äù &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Joshi also suggested startups consider classic metrics: daily, weekly, and monthly active users. ‚ÄúHow frequently are your customers engaging with the tool and the product that they‚Äôre paying for?‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bordetsky agreed, adding that qualitative data can help provide nuance to some of the quantitative metrics which might suggest, but not confirm, whether customers are likely to stick with a product. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIf you talk to customers or users, even in qualitative interviews, which we do tend to do a lot early on, that comes through very clearly,‚Äù she said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Interviewing people in the executive suite can be helpful, too, Joshi said. ‚ÄúWhere does this sit in the tech stack?‚Äù he suggests asking them. He said that startups should think about how they can make themselves ‚Äúmore sticky as a product in terms of the core workflows.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lastly, it‚Äôs important for AI startups to think about product-market fit as a continuum, Bordetsky said. Product-market fit is not sort of one point in time,‚Äù she said. ‚ÄúIt‚Äôs learning to think about how you maybe start with a little bit of product market fit in your space, but then really strengthen that over time.‚Äù&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/disrupt-2025-product-market-fit-panel.jpeg?resize=1200,859" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For all their pitches promising something new, AI startups share many of the same questions as startups in years past: How do they know when they‚Äôve achieved the holy grail of product-market fit?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Product-market fit has been studied extensively over the years; entire books have been written about how to master the art. But as with so many things, AI is upending established practices.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;‚ÄúHonestly, it just could not be more different from all the playbooks that we‚Äôve all been taught in tech in the past,‚Äù Ann Bordetsky, a partner at New Enterprise Associates, told a standing room-only crowd at TechCrunch Disrupt in San Francisco. ‚ÄúIt‚Äôs a completely different ball game.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Top of the list is the pace of change in the AI world. ‚ÄúThe technology itself isn‚Äôt static,‚Äù she said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even still, there are ways that founders and operators can evaluate whether they have product-market fit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the best things to watch, Murali Joshi, a partner at Iconiq, told the audience, is ‚Äúdurability of spend.‚Äù AI is still early in the adoption curve at many companies, and so much of their spend is focused on experimentation rather than integration.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIncreasingly, we‚Äôre seeing people really shift away from just experimental AI budgets to core office of the CXO budgets,‚Äù Joshi said. ‚ÄúDigging into that is super critical to ensure that this is a tool, a solution, a platform that‚Äôs here to stay, versus something that they‚Äôre just testing and trying out.‚Äù &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Joshi also suggested startups consider classic metrics: daily, weekly, and monthly active users. ‚ÄúHow frequently are your customers engaging with the tool and the product that they‚Äôre paying for?‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bordetsky agreed, adding that qualitative data can help provide nuance to some of the quantitative metrics which might suggest, but not confirm, whether customers are likely to stick with a product. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIf you talk to customers or users, even in qualitative interviews, which we do tend to do a lot early on, that comes through very clearly,‚Äù she said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Interviewing people in the executive suite can be helpful, too, Joshi said. ‚ÄúWhere does this sit in the tech stack?‚Äù he suggests asking them. He said that startups should think about how they can make themselves ‚Äúmore sticky as a product in terms of the core workflows.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lastly, it‚Äôs important for AI startups to think about product-market fit as a continuum, Bordetsky said. Product-market fit is not sort of one point in time,‚Äù she said. ‚ÄúIt‚Äôs learning to think about how you maybe start with a little bit of product market fit in your space, but then really strengthen that over time.‚Äù&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/11/how-ai-startups-should-be-thinking-about-product-market-fit/</guid><pubDate>Tue, 11 Nov 2025 17:15:00 +0000</pubDate></item><item><title>[NEW] Immortality startup Eternos pivots to a personal AI that sounds like you (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/11/immortality-startup-eternos-pivots-to-a-personal-ai-that-sounds-like-you/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Group-Photo-4-.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In 2023, after nearly three decades as CEO of the company he founded, Robert LoCascio stepped down as CEO of LivePerson, the public firm credited with pioneering web chat in 1997.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Generative AI advances inspired his next project, which he calls ‚Äúthe highest bar‚Äù for the technology: replicating human beings with their life stories and personality. In 2024, he founded and self-funded, Eternos, a legacy service that allows people to preserve their voice and stories for loved ones after they pass away. Now, it‚Äôs got a new name and modified mission. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup gained significant media attention after its first client, the terminally ill Michael Bommer, revealed how he worked with Eternos to create a digital replica of himself after spending 25 hours talking to Eternos about his life, interests, and worldview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lo Cascio was set on building a legacy business, but what surprised him was that most of the people considering using Eternos weren‚Äôt preparing for death.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eternos developed the Human Life Model (HLM) ‚Äî a framework that uses only an individual‚Äôs data, rather than general LLM data, to capture their unique values, life story, and decision-making traits. LoCascio saw an opportunity to use this technology to help individuals create personal AIs for professional and personal use.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company announced Tuesday it has rebranded as Uare.ai and raised $10.3 million in seed funding led by Mayfield and Boldstart Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúI started to realize that the big models, they‚Äôre taking our datasets, and they‚Äôre getting smarter because of us,‚Äù LoCascio told TechCrunch. ‚ÄúWe don‚Äôt have to take that path. You own the model, and you can share it and monetize it.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The vision for Uare.ai is to be a scaling tool for creators and professionals. Since the personal AI models hold the individual‚Äôs full expertise, a digital replica can be put to work to generate content, handle customer interactions, and even execute projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once Uare.ai‚Äôs platform launches later this year, individuals will be able to start training their HLMs by responding to Uare.ai questions about their lives using text, voice, and even video.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe first part is getting a human life story. Where‚Äôd you come from? Tell me a story about your childhood. What‚Äôs a crossroad in your life when you were younger?‚Äù LoCascio said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Uare.ai then asks the person to submit additional facts about their life, including information about their profession. ‚ÄúWe blend the facts with this human life story, and that gives us your model,‚Äù he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Character.ai and other chatbots, Uare.ai‚Äôs model won‚Äôt turn to general LLMs to fill the gaps about anything that‚Äôs not in HLM. ‚ÄúOur AIs will say, I don‚Äôt know if they can‚Äôt answer the question,‚Äù LoCascio said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Uare.ai intends to generate revenue through subscription fees or take a share of the revenue generated by customers who earn income from their digital twins.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another startup developing personal AIs is Sequoia-backed Delphi, which has attracted people with large followings, including Arnold Schwarzenegger, and enables others to interact with his replicated knowledge via voice or text.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Navin Chaddha, managing partner at Mayfield, believes Uare.ai stands out from competitors because it targets individual professionals like CPAs. Plus, it has LoCascio, a very successful entrepreneur at the helm, he told TechCrunch.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Group-Photo-4-.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In 2023, after nearly three decades as CEO of the company he founded, Robert LoCascio stepped down as CEO of LivePerson, the public firm credited with pioneering web chat in 1997.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Generative AI advances inspired his next project, which he calls ‚Äúthe highest bar‚Äù for the technology: replicating human beings with their life stories and personality. In 2024, he founded and self-funded, Eternos, a legacy service that allows people to preserve their voice and stories for loved ones after they pass away. Now, it‚Äôs got a new name and modified mission. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup gained significant media attention after its first client, the terminally ill Michael Bommer, revealed how he worked with Eternos to create a digital replica of himself after spending 25 hours talking to Eternos about his life, interests, and worldview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lo Cascio was set on building a legacy business, but what surprised him was that most of the people considering using Eternos weren‚Äôt preparing for death.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eternos developed the Human Life Model (HLM) ‚Äî a framework that uses only an individual‚Äôs data, rather than general LLM data, to capture their unique values, life story, and decision-making traits. LoCascio saw an opportunity to use this technology to help individuals create personal AIs for professional and personal use.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company announced Tuesday it has rebranded as Uare.ai and raised $10.3 million in seed funding led by Mayfield and Boldstart Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúI started to realize that the big models, they‚Äôre taking our datasets, and they‚Äôre getting smarter because of us,‚Äù LoCascio told TechCrunch. ‚ÄúWe don‚Äôt have to take that path. You own the model, and you can share it and monetize it.‚Äù&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The vision for Uare.ai is to be a scaling tool for creators and professionals. Since the personal AI models hold the individual‚Äôs full expertise, a digital replica can be put to work to generate content, handle customer interactions, and even execute projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once Uare.ai‚Äôs platform launches later this year, individuals will be able to start training their HLMs by responding to Uare.ai questions about their lives using text, voice, and even video.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe first part is getting a human life story. Where‚Äôd you come from? Tell me a story about your childhood. What‚Äôs a crossroad in your life when you were younger?‚Äù LoCascio said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Uare.ai then asks the person to submit additional facts about their life, including information about their profession. ‚ÄúWe blend the facts with this human life story, and that gives us your model,‚Äù he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Character.ai and other chatbots, Uare.ai‚Äôs model won‚Äôt turn to general LLMs to fill the gaps about anything that‚Äôs not in HLM. ‚ÄúOur AIs will say, I don‚Äôt know if they can‚Äôt answer the question,‚Äù LoCascio said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Uare.ai intends to generate revenue through subscription fees or take a share of the revenue generated by customers who earn income from their digital twins.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another startup developing personal AIs is Sequoia-backed Delphi, which has attracted people with large followings, including Arnold Schwarzenegger, and enables others to interact with his replicated knowledge via voice or text.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Navin Chaddha, managing partner at Mayfield, believes Uare.ai stands out from competitors because it targets individual professionals like CPAs. Plus, it has LoCascio, a very successful entrepreneur at the helm, he told TechCrunch.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/11/immortality-startup-eternos-pivots-to-a-personal-ai-that-sounds-like-you/</guid><pubDate>Tue, 11 Nov 2025 17:29:58 +0000</pubDate></item></channel></rss>