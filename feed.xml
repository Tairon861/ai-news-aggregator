<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 08 Aug 2025 06:37:18 +0000</lastBuildDate><item><title>After using ChatGPT, man swaps his salt for sodium bromide—and suffers psychosis (AI – Ars Technica)</title><link>https://arstechnica.com/health/2025/08/after-using-chatgpt-man-swaps-his-salt-for-sodium-bromide-and-suffers-psychosis/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Literal "hallucinations" were the result.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201240678-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201240678-1152x648-1754591948.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Bromine—you don't want too much in your diet!

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;After seeking advice on health topics from ChatGPT, a 60-year-old man who had a "history of studying nutrition in college" decided to try a health experiment: He would eliminate all chlorine from his diet, which for him meant eliminating even table salt (sodium chloride). His ChatGPT conversations led him to believe that he could replace his sodium chloride with sodium bromide, which he obtained over the Internet.&lt;/p&gt;
&lt;p&gt;Three months later, the man showed up at his local emergency room. His neighbor, he said, was trying to poison him. Though extremely thirsty, the man was paranoid about accepting the water that the hospital offered him, telling doctors that he had begun distilling his own water at home and that he was on an extremely restrictive vegetarian diet. He did not mention the sodium bromide or the ChatGPT discussions.&lt;/p&gt;
&lt;p&gt;His distress, coupled with the odd behavior, led the doctors to run a broad set of lab tests, revealing multiple micronutrient deficiencies, especially in key vitamins. But the bigger problem was that the man appeared to be suffering from a serious case of "bromism." That is, an excess amount of the element bromine had built up in his body.&lt;/p&gt;
&lt;p&gt;A century ago, somewhere around 8–10 percent of all psychiatric admissions in the US were caused by bromism. That's because, then as now, people wanted sedatives to calm their anxieties, to blot out a cruel world, or simply to get a good night's sleep. Bromine-containing salts—things like potassium bromide—were once drugs of choice for this sort of thing.&lt;/p&gt;
&lt;p&gt;Unfortunately, bromide can easily build up in the human body, where too much of it impairs nerve function. This causes a wide variety of problems, including grotesque skin rashes (warning: the link is exactly what it sounds like) and significant mental problems, which are all grouped under the name of "bromism."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bromide sedatives vanished from the US market by 1989, after the Food and Drug Administration banned them, and "bromism" as a syndrome is today unfamiliar to many Americans. (Though you can still get it by drinking, as one poor guy did, two to four liters of cola daily [!], if that cola contains "brominated vegetable oil." Fortunately, the FDA removed brominated vegetable oil from US food products in 2024.)&lt;/p&gt;
&lt;p&gt;In this case, over the man's first day at the hospital, he grew worse and showed "increasing paranoia and auditory and visual hallucinations." He then attempted to escape the facility.&lt;/p&gt;
&lt;p&gt;After the escape attempt, the man was given an involuntary psychiatric hold and an anti-psychosis drug. He was administered large amounts of fluids and electrolytes, as the best way to beat bromism is "aggressive saline diuresis"—that is, to load someone up with liquids and let them pee out all the bromide in their system.&lt;/p&gt;
&lt;p&gt;This took time, as the man's bromide level was eventually measured at a whopping 1,700 mg/L, while the "reference range" for healthy people is 0.9 to 7.3 mg/L.&lt;/p&gt;
&lt;p&gt;In the end, the man suffered from a terrifying psychosis and was kept in the hospital for &lt;em&gt;three full weeks&lt;/em&gt; over an entirely preventable condition.&lt;/p&gt;
&lt;h2&gt;How it all began&lt;/h2&gt;
&lt;p&gt;It was during his stay, once doctors had his psychosis under control, that the man began telling them how it all began. He had read about the problems with too much table salt, which led him to rid his diet of sodium chloride, which led him to ChatGPT, which led him to believe that he could use sodium bromide instead.&lt;/p&gt;
&lt;p&gt;The doctors who wrote up this case study for Annals of Internal Medicine: Clinical Cases note that they never got access to the man's actual ChatGPT logs. He likely used ChatGPT 3.5 or 4.0, they say, but it's not clear that the man was actually told by the chatbot to do what he did. Bromide salts &lt;em&gt;can&lt;/em&gt; be substituted for table salt—just not in the human body. They are used in various cleaning products and pool treatments, however.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;When the doctors tried their own searches in ChatGPT 3.5, they found that the AI did include bromide in its response, but it also indicated that context mattered and that bromide was not suitable for all uses. But the AI "did not provide a specific health warning, nor did it inquire about why we wanted to know, as we presume a medical professional would do," wrote the doctors.&lt;/p&gt;
&lt;p&gt;The current free model of ChatGPT appears to be better at answering this sort of query. When I asked it how to replace chloride in my diet, it first asked to "clarify your goal," giving me three choices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduce salt (sodium chloride) in your diet or home use?&lt;/li&gt;
&lt;li&gt;Avoid toxic/reactive chlorine compounds like bleach or pool chlorine?&lt;/li&gt;
&lt;li&gt;Replace chlorine-based cleaning or disinfecting agents?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ChatGPT did list bromide as an alternative, but only under the third option (cleaning or disinfecting), noting that bromide treatments are "often used in hot tubs."&lt;/p&gt;
&lt;p&gt;Left to his own devices, then, without knowing quite what to ask or how to interpret the responses, the man in this case study "did his own research" and ended up in a pretty dark place. The story seems like a perfect cautionary tale for the modern age, where we are drowning in information—but where we often lack the economic resources, the information-vetting skills, the domain-specific knowledge, or the trust in others that would help us make the best use of it.&lt;/p&gt;
&lt;p&gt;Annals of Internal Medicine: Clinical Cases, 2025. DOI: 10.7326/aimcc.2024.1260 &amp;nbsp;(About DOIs)&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Literal "hallucinations" were the result.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201240678-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2201240678-1152x648-1754591948.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Bromine—you don't want too much in your diet!

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;After seeking advice on health topics from ChatGPT, a 60-year-old man who had a "history of studying nutrition in college" decided to try a health experiment: He would eliminate all chlorine from his diet, which for him meant eliminating even table salt (sodium chloride). His ChatGPT conversations led him to believe that he could replace his sodium chloride with sodium bromide, which he obtained over the Internet.&lt;/p&gt;
&lt;p&gt;Three months later, the man showed up at his local emergency room. His neighbor, he said, was trying to poison him. Though extremely thirsty, the man was paranoid about accepting the water that the hospital offered him, telling doctors that he had begun distilling his own water at home and that he was on an extremely restrictive vegetarian diet. He did not mention the sodium bromide or the ChatGPT discussions.&lt;/p&gt;
&lt;p&gt;His distress, coupled with the odd behavior, led the doctors to run a broad set of lab tests, revealing multiple micronutrient deficiencies, especially in key vitamins. But the bigger problem was that the man appeared to be suffering from a serious case of "bromism." That is, an excess amount of the element bromine had built up in his body.&lt;/p&gt;
&lt;p&gt;A century ago, somewhere around 8–10 percent of all psychiatric admissions in the US were caused by bromism. That's because, then as now, people wanted sedatives to calm their anxieties, to blot out a cruel world, or simply to get a good night's sleep. Bromine-containing salts—things like potassium bromide—were once drugs of choice for this sort of thing.&lt;/p&gt;
&lt;p&gt;Unfortunately, bromide can easily build up in the human body, where too much of it impairs nerve function. This causes a wide variety of problems, including grotesque skin rashes (warning: the link is exactly what it sounds like) and significant mental problems, which are all grouped under the name of "bromism."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bromide sedatives vanished from the US market by 1989, after the Food and Drug Administration banned them, and "bromism" as a syndrome is today unfamiliar to many Americans. (Though you can still get it by drinking, as one poor guy did, two to four liters of cola daily [!], if that cola contains "brominated vegetable oil." Fortunately, the FDA removed brominated vegetable oil from US food products in 2024.)&lt;/p&gt;
&lt;p&gt;In this case, over the man's first day at the hospital, he grew worse and showed "increasing paranoia and auditory and visual hallucinations." He then attempted to escape the facility.&lt;/p&gt;
&lt;p&gt;After the escape attempt, the man was given an involuntary psychiatric hold and an anti-psychosis drug. He was administered large amounts of fluids and electrolytes, as the best way to beat bromism is "aggressive saline diuresis"—that is, to load someone up with liquids and let them pee out all the bromide in their system.&lt;/p&gt;
&lt;p&gt;This took time, as the man's bromide level was eventually measured at a whopping 1,700 mg/L, while the "reference range" for healthy people is 0.9 to 7.3 mg/L.&lt;/p&gt;
&lt;p&gt;In the end, the man suffered from a terrifying psychosis and was kept in the hospital for &lt;em&gt;three full weeks&lt;/em&gt; over an entirely preventable condition.&lt;/p&gt;
&lt;h2&gt;How it all began&lt;/h2&gt;
&lt;p&gt;It was during his stay, once doctors had his psychosis under control, that the man began telling them how it all began. He had read about the problems with too much table salt, which led him to rid his diet of sodium chloride, which led him to ChatGPT, which led him to believe that he could use sodium bromide instead.&lt;/p&gt;
&lt;p&gt;The doctors who wrote up this case study for Annals of Internal Medicine: Clinical Cases note that they never got access to the man's actual ChatGPT logs. He likely used ChatGPT 3.5 or 4.0, they say, but it's not clear that the man was actually told by the chatbot to do what he did. Bromide salts &lt;em&gt;can&lt;/em&gt; be substituted for table salt—just not in the human body. They are used in various cleaning products and pool treatments, however.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;When the doctors tried their own searches in ChatGPT 3.5, they found that the AI did include bromide in its response, but it also indicated that context mattered and that bromide was not suitable for all uses. But the AI "did not provide a specific health warning, nor did it inquire about why we wanted to know, as we presume a medical professional would do," wrote the doctors.&lt;/p&gt;
&lt;p&gt;The current free model of ChatGPT appears to be better at answering this sort of query. When I asked it how to replace chloride in my diet, it first asked to "clarify your goal," giving me three choices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reduce salt (sodium chloride) in your diet or home use?&lt;/li&gt;
&lt;li&gt;Avoid toxic/reactive chlorine compounds like bleach or pool chlorine?&lt;/li&gt;
&lt;li&gt;Replace chlorine-based cleaning or disinfecting agents?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ChatGPT did list bromide as an alternative, but only under the third option (cleaning or disinfecting), noting that bromide treatments are "often used in hot tubs."&lt;/p&gt;
&lt;p&gt;Left to his own devices, then, without knowing quite what to ask or how to interpret the responses, the man in this case study "did his own research" and ended up in a pretty dark place. The story seems like a perfect cautionary tale for the modern age, where we are drowning in information—but where we often lack the economic resources, the information-vetting skills, the domain-specific knowledge, or the trust in others that would help us make the best use of it.&lt;/p&gt;
&lt;p&gt;Annals of Internal Medicine: Clinical Cases, 2025. DOI: 10.7326/aimcc.2024.1260 &amp;nbsp;(About DOIs)&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/health/2025/08/after-using-chatgpt-man-swaps-his-salt-for-sodium-bromide-and-suffers-psychosis/</guid><pubDate>Thu, 07 Aug 2025 19:20:24 +0000</pubDate></item><item><title>High costs and thin margins threatening AI coding startups (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/the-high-costs-and-thin-margins-threatening-ai-coding-startups/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1356382582.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In February, AI coding startup Windsurf was in talks to raise a big new round at a $2.85 billion valuation led by Kleiner Perkins, at double the valuation it hit six months earlier, sources told TechCrunch at the time. That deal didn’t happen, according to a source familiar with the matter. Instead,&amp;nbsp;news broke in April that the startup planned to sell itself to OpenAI for roughly the same valuation: $3 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While that deal famously fell apart, one bigger question remains: If the startup was growing that fast and attracting VC interest, why would it sell at all?&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Insiders tell TechCrunch that for all the popularity and hype around AI coding assistants, they can actually be massively money-losing businesses. Vibe coders generally, and Windsurf in particular, can have such expensive structures that their gross margins are “very negative,” one person close to Windsurf told TechCrunch. Meaning it cost more to run the product than the startup could charge for it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is due to the high costs of using large language models (LLMs), the person explained. AI coding assistants are particularly pressured to always offer the most recent, most advanced, and most expensive LLMs because model makers are particularly fine-tuning their latest models for improvements in coding and related tasks like debugging.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is a challenge compounded by fierce competition in the vibe-coding and code-assist market. Rivals include companies that already have huge customer bases like Anysphere’s Cursor and GitHub Copilot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The most straightforward path to improving margins in this business involves the startups building their own models, thereby eliminating costs of paying suppliers like Anthropic and OpenAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a very expensive business to run if you’re not going to be in the model game,” said the person.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But that idea comes with its own risks. Windsurf’s co-founder and CEO, Varun Mohan, ultimately decided against the company building its own model — an expensive undertaking, the person said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, model makers are already competing directly. Anthropic offers Claude Code and OpenAI offers Codex, for instance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Selling the business was a strategic move to lock in a high return before it could be undermined by the very companies that supplied its AI, including OpenAI and Anthropic, which were also entering the AI coding market.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Multiple people believe that the same pressure on margins Windsurf faced could be impacting Anysphere, the maker of Cursor, as well as vibe coders like Lovable, Replit, and others.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Margins on all of the ‘code gen’ products are either neutral or negative. They’re absolutely abysmal,” said Nicholas Charriere, founder of Mocha, a vibe-coding startup and back-end hosting solution serving small and medium businesses (SMBs). He added that he believes the variable costs for all the startups in the sector are very close, likely within 10% to 15% of one another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Windsurf, Anysphere has been growing so fast that it intends to remain an independent company, having already turned down acquisition offers, including, reports say, from OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And Anysphere announced in January that it is attempting to build its own model, which could give it more control over its expenses.&lt;strong&gt; &lt;/strong&gt;In July, the startup hired two leaders from Anthropic’s Claude Code team, the Information reported, but two weeks later, these employees returned to work at Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to building a model, Anysphere could expect the cost of LLMs to decrease over time.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s what everyone’s banking on,” said Erik Nordlander, a general partner at Google Ventures. “The inference cost today, that’s the most expensive it’s ever going to be.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not entirely clear how true that is. Rather than falling as expected, the cost of some of the latest AI models has risen, as they use more time and computational resources to handle complicated, multistep tasks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When that will change remains to be seen. On Thursday, for instance, OpenAI introduced a new flagship model, GPT-5, with fees that are significantly less than its competitor, Anthropic’s Claude Opus 4.1. And Anysphere immediately offered this model as a choice for Cursor users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anysphere has also recently changed its pricing structure to pass along the increased costs of running Anthropic’s latest Claude model, particularly to its most active users. The move caught some of Cursor customers by surprise, since they didn’t expect additional charges on top of its $20-per-month Pro plan. Anysphere CEO Michael Truell later apologized for unclear communication about the pricing change in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is the rock and the hard place. Although Cursor is one of the most popular AI applications, having reached $500 million in ARR in June, the company’s user base may not be so loyal to the product if another company develops a tool that is superior to Cursor, investors say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere didn’t respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given the competitive landscape and the costs, Windsurf’s decision to get out may prove to be understandable. After the OpenAI deal fell through, the founders and key employees left to join Google in a deal that led to a $2.4 billion payout to key shareholders. The remaining business then sold itself to Cognition.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While many, including prominent VCs, criticized Mohan for leaving approximately 200 employees without roles at Google, a source familiar with the deal insisted the acquisition actually maximized the outcomes for all employees.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Cursor, other AI coding tools are also among the fastest growing startups of the LLM generation, like Replit, Lovable, and Bolt, and all of them rely on model makers as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, if this extremely popular business sector, already generating hundreds of millions in revenue or more a year, has difficulty building on top of model makers, what might it mean for other, more nascent industries?&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1356382582.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In February, AI coding startup Windsurf was in talks to raise a big new round at a $2.85 billion valuation led by Kleiner Perkins, at double the valuation it hit six months earlier, sources told TechCrunch at the time. That deal didn’t happen, according to a source familiar with the matter. Instead,&amp;nbsp;news broke in April that the startup planned to sell itself to OpenAI for roughly the same valuation: $3 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While that deal famously fell apart, one bigger question remains: If the startup was growing that fast and attracting VC interest, why would it sell at all?&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Insiders tell TechCrunch that for all the popularity and hype around AI coding assistants, they can actually be massively money-losing businesses. Vibe coders generally, and Windsurf in particular, can have such expensive structures that their gross margins are “very negative,” one person close to Windsurf told TechCrunch. Meaning it cost more to run the product than the startup could charge for it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is due to the high costs of using large language models (LLMs), the person explained. AI coding assistants are particularly pressured to always offer the most recent, most advanced, and most expensive LLMs because model makers are particularly fine-tuning their latest models for improvements in coding and related tasks like debugging.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is a challenge compounded by fierce competition in the vibe-coding and code-assist market. Rivals include companies that already have huge customer bases like Anysphere’s Cursor and GitHub Copilot.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The most straightforward path to improving margins in this business involves the startups building their own models, thereby eliminating costs of paying suppliers like Anthropic and OpenAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a very expensive business to run if you’re not going to be in the model game,” said the person.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But that idea comes with its own risks. Windsurf’s co-founder and CEO, Varun Mohan, ultimately decided against the company building its own model — an expensive undertaking, the person said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, model makers are already competing directly. Anthropic offers Claude Code and OpenAI offers Codex, for instance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Selling the business was a strategic move to lock in a high return before it could be undermined by the very companies that supplied its AI, including OpenAI and Anthropic, which were also entering the AI coding market.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Multiple people believe that the same pressure on margins Windsurf faced could be impacting Anysphere, the maker of Cursor, as well as vibe coders like Lovable, Replit, and others.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Margins on all of the ‘code gen’ products are either neutral or negative. They’re absolutely abysmal,” said Nicholas Charriere, founder of Mocha, a vibe-coding startup and back-end hosting solution serving small and medium businesses (SMBs). He added that he believes the variable costs for all the startups in the sector are very close, likely within 10% to 15% of one another.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Windsurf, Anysphere has been growing so fast that it intends to remain an independent company, having already turned down acquisition offers, including, reports say, from OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And Anysphere announced in January that it is attempting to build its own model, which could give it more control over its expenses.&lt;strong&gt; &lt;/strong&gt;In July, the startup hired two leaders from Anthropic’s Claude Code team, the Information reported, but two weeks later, these employees returned to work at Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to building a model, Anysphere could expect the cost of LLMs to decrease over time.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s what everyone’s banking on,” said Erik Nordlander, a general partner at Google Ventures. “The inference cost today, that’s the most expensive it’s ever going to be.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not entirely clear how true that is. Rather than falling as expected, the cost of some of the latest AI models has risen, as they use more time and computational resources to handle complicated, multistep tasks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When that will change remains to be seen. On Thursday, for instance, OpenAI introduced a new flagship model, GPT-5, with fees that are significantly less than its competitor, Anthropic’s Claude Opus 4.1. And Anysphere immediately offered this model as a choice for Cursor users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anysphere has also recently changed its pricing structure to pass along the increased costs of running Anthropic’s latest Claude model, particularly to its most active users. The move caught some of Cursor customers by surprise, since they didn’t expect additional charges on top of its $20-per-month Pro plan. Anysphere CEO Michael Truell later apologized for unclear communication about the pricing change in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is the rock and the hard place. Although Cursor is one of the most popular AI applications, having reached $500 million in ARR in June, the company’s user base may not be so loyal to the product if another company develops a tool that is superior to Cursor, investors say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere didn’t respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given the competitive landscape and the costs, Windsurf’s decision to get out may prove to be understandable. After the OpenAI deal fell through, the founders and key employees left to join Google in a deal that led to a $2.4 billion payout to key shareholders. The remaining business then sold itself to Cognition.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While many, including prominent VCs, criticized Mohan for leaving approximately 200 employees without roles at Google, a source familiar with the deal insisted the acquisition actually maximized the outcomes for all employees.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Cursor, other AI coding tools are also among the fastest growing startups of the LLM generation, like Replit, Lovable, and Bolt, and all of them rely on model makers as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, if this extremely popular business sector, already generating hundreds of millions in revenue or more a year, has difficulty building on top of model makers, what might it mean for other, more nascent industries?&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/the-high-costs-and-thin-margins-threatening-ai-coding-startups/</guid><pubDate>Thu, 07 Aug 2025 21:05:01 +0000</pubDate></item><item><title>Tesla shuts down Dojo, the AI training supercomputer that Musk said would be key to full self-driving (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/tesla-shuts-down-dojo-the-ai-training-supercomputer-that-musk-said-would-be-key-to-full-self-driving/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/tesla-dojo.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tesla is breaking up the team behind its Dojo supercomputer, ending the automaker’s play at developing in-house chips for driverless technology, according to Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo’s lead, Peter Bannon, is leaving the company, and the remaining team members will be reassigned to other data center and compute projects within Tesla, per Bloomberg’s reporting, which cited anonymous sources.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The disbanding of Tesla’s Dojo efforts follows the departure of around 20 workers, who left the automaker to start their own AI company called DensityAI. The new startup is reportedly coming out of stealth soon and is building chips, hardware, and software that will power data centers for AI that are used in robotics, by AI agents, and in automotive applications. DensityAI was founded by former Dojo head Ganesh Venkataramanan and ex-Tesla employees Bill Chang and Ben Floering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also comes at a crucial time for Tesla. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Elon Musk has pushed to get shareholders to view Tesla as an AI and robotics company, despite a limited robotaxi launch in Austin this past June that featured Model Y vehicles with a human in the front passenger seat and resulted in a number of reported incidents of the vehicles exhibiting problematic driving behavior.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla’s decision to shut down Dojo, which Musk has been talking about since 2019, is a major shift in strategy. Musk has said that Dojo would be the cornerstone of Tesla’s AI ambitions and its goal to reach full self-driving due to its ability to “process truly vast amounts of video data.”&amp;nbsp;He talked about Dojo, albeit briefly, as recently as the company’s second-quarter earnings call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2023, Morgan Stanley predicted Dojo could add $500 billion to the company’s market value by unlocking new revenue streams in the form of robotaxis and software services. Just last year, Musk noted that Tesla’s AI team would “double down” on Dojo in the lead-up to Tesla’s robotaxi reveal, which happened in October.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But talk about Dojo halted around August 2024, when Musk began touting Cortex instead, Tesla’s “giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Dojo project was one part supercomputer, one part in-house chip-making. Tesla unveiled its D1 chip when it formally announced Dojo at its first AI Day in 2021. Venkataramanan presented the chip, which Tesla said would be used alongside Nvidia’s GPU to power the Dojo supercomputer. The automaker also said it was working on a next-gen D2 chip that would solve any information flow bottlenecks of its predecessor.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sources told Bloomberg that now Tesla plans to increase its reliance on Nvidia, as well as other external tech partners like AMD for compute and Samsung for chip manufacturing. Tesla last month signed a $16.5 billion deal with Samsung to make its AI6 inference chips, a chip design that promises to scale from powering FSD and Tesla’s Optimus humanoid robots all the way to high-performance AI training in data centers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During Tesla’s second-quarter earnings call, Musk hinted at potential redundancies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Thinking about Dojo 3 and the AI6 inference chip, it seems like intuitively, we want to try to find convergence there, where it’s basically the same chip,” Musk said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes as Tesla’s board offers Musk a $29 billion pay package to keep him at Tesla and help push the company’s AI efforts forward, rather than getting too sidetracked by his other companies, including the more pure-play AI startup xAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Tesla for more information. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Have a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com and Maxwell Zeff at maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at @rebeccabellan.491 and @mzeff.88.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/tesla-dojo.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tesla is breaking up the team behind its Dojo supercomputer, ending the automaker’s play at developing in-house chips for driverless technology, according to Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Dojo’s lead, Peter Bannon, is leaving the company, and the remaining team members will be reassigned to other data center and compute projects within Tesla, per Bloomberg’s reporting, which cited anonymous sources.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The disbanding of Tesla’s Dojo efforts follows the departure of around 20 workers, who left the automaker to start their own AI company called DensityAI. The new startup is reportedly coming out of stealth soon and is building chips, hardware, and software that will power data centers for AI that are used in robotics, by AI agents, and in automotive applications. DensityAI was founded by former Dojo head Ganesh Venkataramanan and ex-Tesla employees Bill Chang and Ben Floering.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It also comes at a crucial time for Tesla. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Elon Musk has pushed to get shareholders to view Tesla as an AI and robotics company, despite a limited robotaxi launch in Austin this past June that featured Model Y vehicles with a human in the front passenger seat and resulted in a number of reported incidents of the vehicles exhibiting problematic driving behavior.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla’s decision to shut down Dojo, which Musk has been talking about since 2019, is a major shift in strategy. Musk has said that Dojo would be the cornerstone of Tesla’s AI ambitions and its goal to reach full self-driving due to its ability to “process truly vast amounts of video data.”&amp;nbsp;He talked about Dojo, albeit briefly, as recently as the company’s second-quarter earnings call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2023, Morgan Stanley predicted Dojo could add $500 billion to the company’s market value by unlocking new revenue streams in the form of robotaxis and software services. Just last year, Musk noted that Tesla’s AI team would “double down” on Dojo in the lead-up to Tesla’s robotaxi reveal, which happened in October.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But talk about Dojo halted around August 2024, when Musk began touting Cortex instead, Tesla’s “giant new AI training supercluster being built at Tesla HQ in Austin to solve real-world AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Dojo project was one part supercomputer, one part in-house chip-making. Tesla unveiled its D1 chip when it formally announced Dojo at its first AI Day in 2021. Venkataramanan presented the chip, which Tesla said would be used alongside Nvidia’s GPU to power the Dojo supercomputer. The automaker also said it was working on a next-gen D2 chip that would solve any information flow bottlenecks of its predecessor.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sources told Bloomberg that now Tesla plans to increase its reliance on Nvidia, as well as other external tech partners like AMD for compute and Samsung for chip manufacturing. Tesla last month signed a $16.5 billion deal with Samsung to make its AI6 inference chips, a chip design that promises to scale from powering FSD and Tesla’s Optimus humanoid robots all the way to high-performance AI training in data centers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During Tesla’s second-quarter earnings call, Musk hinted at potential redundancies.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Thinking about Dojo 3 and the AI6 inference chip, it seems like intuitively, we want to try to find convergence there, where it’s basically the same chip,” Musk said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes as Tesla’s board offers Musk a $29 billion pay package to keep him at Tesla and help push the company’s AI efforts forward, rather than getting too sidetracked by his other companies, including the more pure-play AI startup xAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Tesla for more information. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Have a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com and Maxwell Zeff at maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at @rebeccabellan.491 and @mzeff.88.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/tesla-shuts-down-dojo-the-ai-training-supercomputer-that-musk-said-would-be-key-to-full-self-driving/</guid><pubDate>Thu, 07 Aug 2025 22:19:50 +0000</pubDate></item><item><title>Black Hat 2025: Why your AI tools are becoming the next insider threat (AI News | VentureBeat)</title><link>https://venturebeat.com/security/black-hat-2025-how-agentic-ai-is-finally-delivering-real-value/</link><description>&lt;p&gt;Cloud intrusions &lt;span&gt;increased&amp;nbsp;by 136%&amp;nbsp;in the past&amp;nbsp;&lt;/span&gt;six months. North Korean operatives infiltrated 320 companies using AI-generated identities. Scattered Spider now deploys ransomware in under 24 hours. &lt;span&gt;However, at&amp;nbsp;Black Hat 2025, the security industry demonstrated that it finally has an answer that works: agentic AI,&lt;/span&gt; delivering measurable results, not promises.&lt;/p&gt;&lt;p&gt;CrowdStrike’s recent identification of 28 North Korean operatives embedded as remote IT workers, part of a broader campaign affecting 320 companies, demonstrates how agentic AI is evolving from concept to practical threat detection.&lt;/p&gt;&lt;p&gt;While nearly every vendor at Black Hat 2025 had performance metrics available, either from beta programs in process or full-production agentic AI deployments, the strongest theme was operational readiness over hype or theoretical claims.&lt;/p&gt;&lt;p&gt;CISOs VentureBeat spoke with at Black Hat are reporting the ability to process significantly more alerts with current staffing levels, with investigation times improving substantially. However, specific gains depend on the implementation maturity and complexity of the use case. What’s notable is the transition from aspirational roadmaps to real-world outcomes.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;VentureBeat is also starting to see security teams begin to achieve practical, real efficiency gains that translate to the metrics boards ask about. These include reducing the mean time to investigate (MTTI), improving threat detection rates and better resource utilization. Black Hat 2025 marked an inflection point where the conversation shifted from AI’s potential to its measured impact on security operations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-agentic-ai-arms-race-shifts-from-promises-to-production"&gt;&lt;strong&gt;The agentic AI arms race shifts from promises to production&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The conversation at Black Hat 2025 was dominated by agentic AI, with many of the sessions dedicated to how attackers have or can easily compromise agents. VentureBeat observed over 100 announcements promoting new agentic AI applications, platforms or services. Vendors are producing use cases and results. That’s a welcome change from the many promises made in prior years and at previous years. There’s an urgency to close hype gaps and deliver results. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;CrowdStrike’s Adam Meyers, head of counter adversary operations, articulated what’s driving this urgency in an interview with VentureBeat: “Agentic AI really becomes the platform that allows SOC operators to build those automations, whether they’re using MCP servers to get access to APIs. We’re starting to see more and more organizations leveraging our agentic AI to help them integrate with the Falcon and CrowdStrike systems.”&lt;/p&gt;



&lt;p&gt;VentureBeat believes the scale of the threat demands this response. “When they’re moving at that speed, you can’t wait,” Meyers emphasized, referencing how some adversaries now deploy ransomware in under 24 hours. “You need to have human threat hunters in the loop that are making you know, as soon as the adversary gets access, or as soon as the adversary pops up, they’re there, and they’re doing hand-to-hand combat with those adversaries.”&lt;/p&gt;



&lt;p&gt;“Last year, we looked at 60 billion hunting leads that result in about 13 million investigations, 27,000 customer escalations and 4000 emails that we started sending to customers,” Meyers revealed, emphasizing the scale at which these systems now operate. Microsoft Security unveiled significant enhancements to its Security Copilot, introducing autonomous investigation capabilities that can correlate threats across Microsoft Defender, Sentinel and third-party security tools without human intervention. Palo Alto Networks demonstrated Cortex XSOAR’s new agentic capabilities, showing how their platform can now autonomously triage alerts, conduct investigations and even execute remediation actions within defined guardrails.&lt;/p&gt;



&lt;p&gt;Cisco made one of Black Hat’s most significant announcements, releasing Foundation-sec-8B-Instruct, the first conversational AI model built exclusively for cybersecurity. This eight-billion-parameter model outperforms much larger general-purpose models, including GPT-4o-mini, on security tasks while running on a single GPU.&lt;/p&gt;



&lt;p&gt;What sets this release apart is its fully open-source architecture. Foundation-sec-8B-Instruct ships with completely open weights under a permissive license, enabling security teams to deploy it on-premises, in air-gapped environments or at the edge without vendor lock-in. The model is freely available on Hugging Face, accompanied by the Foundation AI Cookbook featuring deployment guides and implementation templates.&lt;/p&gt;



&lt;p&gt;“Foundation-sec-8B-Instruct is live, open, and ready to defend. Download it, prompt it and help shape the future of AI-powered cybersecurity,” states Yaron Singer, VP of AI and Security at Foundation, emphasizing the collaborative potential of this open-source approach.&lt;/p&gt;



&lt;p&gt;SentinelOne took a different approach, emphasizing their Purple AI’s ability not just to investigate but actually “think ahead” or predict adversary moves based on behavioral patterns and proactively adjusting defenses.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015301" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/figure-7-crowdstrike-report.jpg?w=792" width="792" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;CrowdStrike’s threat intelligence reveals how adversaries like FAMOUS CHOLLIMA are weaponizing gen AI at every stage of insider threat operations, from creating synthetic identities to managing multiple simultaneous employment positions. Source: CrowdStrike 2025 Threat Hunting Report&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-the-north-korean-threat-changed-everything-fast"&gt;&lt;strong&gt;How the North Korean threat changed everything fast&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;FAMOUS CHOLLIMA operatives infiltrated over 320 companies in the past year. That’s a 220% year-over-year increase, representing a fundamental shift in enterprise security threats.&lt;/p&gt;



&lt;p&gt;“They’re using AI through the entire process,” Meyers told VentureBeat during an interview. “They’re using generative AI to create LinkedIn profiles, to create resumes and then they go into the interview, and they’re using deep fake technology to change their appearance. They’re using AI to answer questions during the interview process. They’re using AI, once they get hired, to build the code and do the work that they’re supposed to do.”&lt;/p&gt;



&lt;p&gt;The infrastructure supporting these operations is sophisticated. One Arizona-based facilitator maintained 90 laptops to enable remote access. Operations have expanded beyond the U.S. to France, Canada and Japan as adversaries diversify their targeting.&lt;/p&gt;



&lt;p&gt;CrowdStrike’s July data reveals the scope: 33 FAMOUS CHOLLIMA encounters, with 28 confirmed as malicious insiders who had successfully obtained employment. These are AI-enhanced operators working within organizations, using legitimate credentials, rather than relying on traditional malware attacks that security tools can detect.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-the-human-element-remains-vital"&gt;&lt;strong&gt;Why the human element remains vital&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Despite the technological advances, a consistent theme across all vendor presentations was that agentic AI augments rather than replaces human analysts. “Agentic AI, as good as it is, is not going to replace the humans that are in the loop. You need human threat hunters out there that are able to use their insight and their know-how and their intellect to come up with creative ways to try to find these adversaries,” Meyers emphasized.&lt;/p&gt;



&lt;p&gt;Every major vendor echoed this human-machine collaboration model. Splunk’s announcement of Mission Control emphasized how its agentic AI serves as a “force multiplier” for analysts, handling routine tasks while escalating complex decisions to humans. Even the most ardent advocates of automation acknowledged that human oversight remains essential for high-stakes decisions and creative problem-solving.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-competition-shifts-from-features-to-results"&gt;&lt;strong&gt;Competition shifts from features to results&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Despite fierce competition in the race ot deliver agentic AI solutions for the SOC, Black Hat 2025 ironically showed a more unified approach to cybersecurity than any previous event. Every major vendor emphasized three critical components: reasoning engines that can understand context and make nuanced decisions. These action frameworks enable autonomous response within defined boundaries and learning systems that continuously improve based on outcomes.&lt;/p&gt;



&lt;p&gt;Google Cloud Security’s Chronicle SOAR exemplified this shift, introducing an agentic mode that automatically investigates alerts by querying multiple data sources, correlating findings and presenting analysts with complete investigation packages. Even traditionally conservative vendors have embraced the transformation, with IBM and others introducing autonomous investigation capabilities to their existing installations. The convergence was apparent: the industry has moved beyond competing on AI presence to competing on operational excellence.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015302" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/figure-6-crowdstrike-report.jpg?w=589" width="589" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The cybersecurity industry is witnessing adversaries leverage GenAI across three primary attack vectors, forcing defenders to adopt equally sophisticated AI-powered defenses. Source: CrowdStrike 2025 Threat Hunting Report&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-many-are-predicting-that-ai-will-become-the-next-insider-threat"&gt;&lt;strong&gt;Many are predicting that AI will become the next insider threat&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Looking forward, Black Hat 2025 also highlighted emerging challenges. Meyers delivered perhaps the most sobering prediction of the conference: “AI is going to be the next insider threat. Organizations trust those AIs implicitly. They are using it to do all of these tasks, and the more comfortable they become, the less they’re going to check the output.”&lt;/p&gt;



&lt;p&gt;This concern sparked discussions about standardization and governance. The Cloud Security Alliance announced a working group focused on agentic AI security standards, while several vendors committed to collaborative efforts around AI agent interoperability. CrowdStrike’s expansion of Falcon Shield to include governance for OpenAI GPT-based agents, combined with Cisco’s AI supply chain security initiative with Hugging Face, signals the industry’s recognition that securing AI agents themselves is becoming as important as using them for security.&lt;/p&gt;



&lt;p&gt;The velocity of change is accelerating. “Adversaries are moving incredibly fast,” Meyers warned. “Scattered spider hit retail back in April, they were hitting insurance companies in May, they were hitting aviation in June and July.” The ability to iterate and adapt at this speed means organizations can’t afford to wait for perfect solutions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-bottom-line"&gt;&lt;strong&gt;Bottom Line&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;This year’s Black Hat confirmed what many cybersecurity professionals saw coming. AI-driven attacks now threaten their organizations across a widening array of surfaces, many of them unexpected.&lt;/p&gt;



&lt;p&gt;Human resources and hiring became the threat surface no one saw coming. FAMOUS CHOLLIMA operatives are penetrating every possible U.S. and Western technology company they can, grabbing immediate cash to fuel North Korea’s weapons programs while stealing invaluable intellectual property. This creates an entirely new dimension to attacks. Organizations and the security leaders guiding them would do well to remember what hangs in the balance of getting this right: your businesses’ core IP, national security, and the trust customers have in the organizations they do business with.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Cloud intrusions &lt;span&gt;increased&amp;nbsp;by 136%&amp;nbsp;in the past&amp;nbsp;&lt;/span&gt;six months. North Korean operatives infiltrated 320 companies using AI-generated identities. Scattered Spider now deploys ransomware in under 24 hours. &lt;span&gt;However, at&amp;nbsp;Black Hat 2025, the security industry demonstrated that it finally has an answer that works: agentic AI,&lt;/span&gt; delivering measurable results, not promises.&lt;/p&gt;&lt;p&gt;CrowdStrike’s recent identification of 28 North Korean operatives embedded as remote IT workers, part of a broader campaign affecting 320 companies, demonstrates how agentic AI is evolving from concept to practical threat detection.&lt;/p&gt;&lt;p&gt;While nearly every vendor at Black Hat 2025 had performance metrics available, either from beta programs in process or full-production agentic AI deployments, the strongest theme was operational readiness over hype or theoretical claims.&lt;/p&gt;&lt;p&gt;CISOs VentureBeat spoke with at Black Hat are reporting the ability to process significantly more alerts with current staffing levels, with investigation times improving substantially. However, specific gains depend on the implementation maturity and complexity of the use case. What’s notable is the transition from aspirational roadmaps to real-world outcomes.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;VentureBeat is also starting to see security teams begin to achieve practical, real efficiency gains that translate to the metrics boards ask about. These include reducing the mean time to investigate (MTTI), improving threat detection rates and better resource utilization. Black Hat 2025 marked an inflection point where the conversation shifted from AI’s potential to its measured impact on security operations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-agentic-ai-arms-race-shifts-from-promises-to-production"&gt;&lt;strong&gt;The agentic AI arms race shifts from promises to production&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The conversation at Black Hat 2025 was dominated by agentic AI, with many of the sessions dedicated to how attackers have or can easily compromise agents. VentureBeat observed over 100 announcements promoting new agentic AI applications, platforms or services. Vendors are producing use cases and results. That’s a welcome change from the many promises made in prior years and at previous years. There’s an urgency to close hype gaps and deliver results. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;CrowdStrike’s Adam Meyers, head of counter adversary operations, articulated what’s driving this urgency in an interview with VentureBeat: “Agentic AI really becomes the platform that allows SOC operators to build those automations, whether they’re using MCP servers to get access to APIs. We’re starting to see more and more organizations leveraging our agentic AI to help them integrate with the Falcon and CrowdStrike systems.”&lt;/p&gt;



&lt;p&gt;VentureBeat believes the scale of the threat demands this response. “When they’re moving at that speed, you can’t wait,” Meyers emphasized, referencing how some adversaries now deploy ransomware in under 24 hours. “You need to have human threat hunters in the loop that are making you know, as soon as the adversary gets access, or as soon as the adversary pops up, they’re there, and they’re doing hand-to-hand combat with those adversaries.”&lt;/p&gt;



&lt;p&gt;“Last year, we looked at 60 billion hunting leads that result in about 13 million investigations, 27,000 customer escalations and 4000 emails that we started sending to customers,” Meyers revealed, emphasizing the scale at which these systems now operate. Microsoft Security unveiled significant enhancements to its Security Copilot, introducing autonomous investigation capabilities that can correlate threats across Microsoft Defender, Sentinel and third-party security tools without human intervention. Palo Alto Networks demonstrated Cortex XSOAR’s new agentic capabilities, showing how their platform can now autonomously triage alerts, conduct investigations and even execute remediation actions within defined guardrails.&lt;/p&gt;



&lt;p&gt;Cisco made one of Black Hat’s most significant announcements, releasing Foundation-sec-8B-Instruct, the first conversational AI model built exclusively for cybersecurity. This eight-billion-parameter model outperforms much larger general-purpose models, including GPT-4o-mini, on security tasks while running on a single GPU.&lt;/p&gt;



&lt;p&gt;What sets this release apart is its fully open-source architecture. Foundation-sec-8B-Instruct ships with completely open weights under a permissive license, enabling security teams to deploy it on-premises, in air-gapped environments or at the edge without vendor lock-in. The model is freely available on Hugging Face, accompanied by the Foundation AI Cookbook featuring deployment guides and implementation templates.&lt;/p&gt;



&lt;p&gt;“Foundation-sec-8B-Instruct is live, open, and ready to defend. Download it, prompt it and help shape the future of AI-powered cybersecurity,” states Yaron Singer, VP of AI and Security at Foundation, emphasizing the collaborative potential of this open-source approach.&lt;/p&gt;



&lt;p&gt;SentinelOne took a different approach, emphasizing their Purple AI’s ability not just to investigate but actually “think ahead” or predict adversary moves based on behavioral patterns and proactively adjusting defenses.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015301" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/figure-7-crowdstrike-report.jpg?w=792" width="792" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;CrowdStrike’s threat intelligence reveals how adversaries like FAMOUS CHOLLIMA are weaponizing gen AI at every stage of insider threat operations, from creating synthetic identities to managing multiple simultaneous employment positions. Source: CrowdStrike 2025 Threat Hunting Report&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-the-north-korean-threat-changed-everything-fast"&gt;&lt;strong&gt;How the North Korean threat changed everything fast&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;FAMOUS CHOLLIMA operatives infiltrated over 320 companies in the past year. That’s a 220% year-over-year increase, representing a fundamental shift in enterprise security threats.&lt;/p&gt;



&lt;p&gt;“They’re using AI through the entire process,” Meyers told VentureBeat during an interview. “They’re using generative AI to create LinkedIn profiles, to create resumes and then they go into the interview, and they’re using deep fake technology to change their appearance. They’re using AI to answer questions during the interview process. They’re using AI, once they get hired, to build the code and do the work that they’re supposed to do.”&lt;/p&gt;



&lt;p&gt;The infrastructure supporting these operations is sophisticated. One Arizona-based facilitator maintained 90 laptops to enable remote access. Operations have expanded beyond the U.S. to France, Canada and Japan as adversaries diversify their targeting.&lt;/p&gt;



&lt;p&gt;CrowdStrike’s July data reveals the scope: 33 FAMOUS CHOLLIMA encounters, with 28 confirmed as malicious insiders who had successfully obtained employment. These are AI-enhanced operators working within organizations, using legitimate credentials, rather than relying on traditional malware attacks that security tools can detect.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-the-human-element-remains-vital"&gt;&lt;strong&gt;Why the human element remains vital&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Despite the technological advances, a consistent theme across all vendor presentations was that agentic AI augments rather than replaces human analysts. “Agentic AI, as good as it is, is not going to replace the humans that are in the loop. You need human threat hunters out there that are able to use their insight and their know-how and their intellect to come up with creative ways to try to find these adversaries,” Meyers emphasized.&lt;/p&gt;



&lt;p&gt;Every major vendor echoed this human-machine collaboration model. Splunk’s announcement of Mission Control emphasized how its agentic AI serves as a “force multiplier” for analysts, handling routine tasks while escalating complex decisions to humans. Even the most ardent advocates of automation acknowledged that human oversight remains essential for high-stakes decisions and creative problem-solving.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-competition-shifts-from-features-to-results"&gt;&lt;strong&gt;Competition shifts from features to results&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Despite fierce competition in the race ot deliver agentic AI solutions for the SOC, Black Hat 2025 ironically showed a more unified approach to cybersecurity than any previous event. Every major vendor emphasized three critical components: reasoning engines that can understand context and make nuanced decisions. These action frameworks enable autonomous response within defined boundaries and learning systems that continuously improve based on outcomes.&lt;/p&gt;



&lt;p&gt;Google Cloud Security’s Chronicle SOAR exemplified this shift, introducing an agentic mode that automatically investigates alerts by querying multiple data sources, correlating findings and presenting analysts with complete investigation packages. Even traditionally conservative vendors have embraced the transformation, with IBM and others introducing autonomous investigation capabilities to their existing installations. The convergence was apparent: the industry has moved beyond competing on AI presence to competing on operational excellence.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015302" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/figure-6-crowdstrike-report.jpg?w=589" width="589" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The cybersecurity industry is witnessing adversaries leverage GenAI across three primary attack vectors, forcing defenders to adopt equally sophisticated AI-powered defenses. Source: CrowdStrike 2025 Threat Hunting Report&lt;/em&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-many-are-predicting-that-ai-will-become-the-next-insider-threat"&gt;&lt;strong&gt;Many are predicting that AI will become the next insider threat&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Looking forward, Black Hat 2025 also highlighted emerging challenges. Meyers delivered perhaps the most sobering prediction of the conference: “AI is going to be the next insider threat. Organizations trust those AIs implicitly. They are using it to do all of these tasks, and the more comfortable they become, the less they’re going to check the output.”&lt;/p&gt;



&lt;p&gt;This concern sparked discussions about standardization and governance. The Cloud Security Alliance announced a working group focused on agentic AI security standards, while several vendors committed to collaborative efforts around AI agent interoperability. CrowdStrike’s expansion of Falcon Shield to include governance for OpenAI GPT-based agents, combined with Cisco’s AI supply chain security initiative with Hugging Face, signals the industry’s recognition that securing AI agents themselves is becoming as important as using them for security.&lt;/p&gt;



&lt;p&gt;The velocity of change is accelerating. “Adversaries are moving incredibly fast,” Meyers warned. “Scattered spider hit retail back in April, they were hitting insurance companies in May, they were hitting aviation in June and July.” The ability to iterate and adapt at this speed means organizations can’t afford to wait for perfect solutions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-bottom-line"&gt;&lt;strong&gt;Bottom Line&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;This year’s Black Hat confirmed what many cybersecurity professionals saw coming. AI-driven attacks now threaten their organizations across a widening array of surfaces, many of them unexpected.&lt;/p&gt;



&lt;p&gt;Human resources and hiring became the threat surface no one saw coming. FAMOUS CHOLLIMA operatives are penetrating every possible U.S. and Western technology company they can, grabbing immediate cash to fuel North Korea’s weapons programs while stealing invaluable intellectual property. This creates an entirely new dimension to attacks. Organizations and the security leaders guiding them would do well to remember what hangs in the balance of getting this right: your businesses’ core IP, national security, and the trust customers have in the organizations they do business with.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/security/black-hat-2025-how-agentic-ai-is-finally-delivering-real-value/</guid><pubDate>Thu, 07 Aug 2025 23:35:56 +0000</pubDate></item><item><title>ChatGPT users dismayed as OpenAI pulls popular models GPT-4o, o3 and more — enterprise API remains (for now) (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/chatgpt-users-dismayed-as-openai-pulls-popular-models-gpt-4o-o3-and-more-enterprise-api-remains-for-now/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;After announcing the release of its newest flagship model family, GPT-5, OpenAI said the model will power all of ChatGPT, and that it will sunset the existing models in the chat platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;OpenAI, through a spokesperson, told VentureBeat that GPT-5 “will replace all other models in ChatGPT, so users don’t have to pick depending on each task, which takes effect once you have access to GPT-5.” This means people can no longer choose GPT-4o, o3, o4-mini or o4-mini-high.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With GPT-5 access rolling out to ChatGPT Plus, Free, Pro and Team users starting, only the Enterprise and Edu tiers can still use the “legacy” models for 60 days.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The news came as a surprise to many ChatGPT users, many of whom came to rely on their chosen models to run their everyday queries. Some people said the adjustment would take some time getting used to, mainly because they had based workflows on how the model interacted with them or typical response times.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Although I enjoy GPT-4.1, I am saddened by the news that you're also apparently sunsetting GPT-4.5. For me, it's been way better in textual and conceptual analysis than any other GPT-4x series model, ever. At the very least, please don't make ChatGPT users go back to 4o.&lt;/p&gt;— Harry Horsperg ? (@horsperg) April 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Other users claimed they developed “a connection” to their chosen model and found a demo in the livestream announcement asking GPT-4o to write its own eulogy distasteful. The loss of GPT-4o garnered the most distress. After all, 4o was the default model for ChatGPT, and some users either preferred it or never bothered to switch models because it worked for their needs.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;It was pretty gross, wasn't it. Did it as a demo and glibly said GPT-5 did it better before talking about coding. I had a great relationship with 4o, and I'm sure a fair few people did as well, it was very graceless how they handled it.&lt;/p&gt;— Meadowbrook (@Meadowbrook_) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;I used 4o as the default and found it annoying at first when my custom GPT began defaulting to a reasoning model. I’ve since come around to the reasoning model for work-related queries, but I still often turn to 4o for quicker questions like planning a trip or generating gift ideas.&lt;/p&gt;



&lt;p&gt;ChatGPT had come under fire before with the number of model choices it offered, prompting OpenAI CEO Sam Altman to admit in February that its model picker (where people can choose from a dropdown which model they prefer) became complicated. Altman vowed to unify the experience, which now seems like a hint to what they eventually decided to do with GPT-5 on ChatGPT.&lt;/p&gt;



&lt;p&gt;Last month, rumors circulated that OpenAI would introduce an automatic model router that chooses a model for users based on their workload.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI has sunsetted models before, but this is the first time all existing models on the chat platform will be removed and replaced wholesale.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-catapult-into-the-future"&gt;Catapult into the future&lt;/h2&gt;



&lt;p&gt;On the other hand, a lot of people see the sunsetting of GPT-4o and the o3 and o4 family of models as OpenAI “catapulting” 400 million users into the future.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;People are underestimating the impact of OpenAI deprecating all models except GPT-5 &lt;/p&gt;&lt;p&gt;Most lawyers and business folks outside of X use base models on ChatGPT for tasks and still think “AI is dumb”&lt;/p&gt;&lt;p&gt;99% haven’t heard of o3&lt;/p&gt;&lt;p&gt;Today, 400M people got catapulted into the future&lt;/p&gt;— Ian Tracey (@ian_dot_so) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Sunsetting old models and auto-upgrading everyone to GPT-5 is smart&lt;/p&gt;&lt;p&gt;Most users never switch models and miss huge capability jumps&lt;/p&gt;— Creatify AI (@Creatify_AI) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Some internet comments claim that people who complain about AI models not being smart are a direct consequence of them never switching models in the first place. Removing legacy models as options will force more users to use the latest and most capable models.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;i have friends who stopped using gpt because they think it's stupid. they were on 4o and had no idea about what web search tool meant, let alone knowledge cutoff&lt;/p&gt;— Cengiz (@cengizdemiurg) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-apis-are-safe"&gt;Enterprise APIs are safe&lt;/h2&gt;



&lt;p&gt;For enterprises, the impact of losing models like GPT-4o on ChatGPT will be felt more on the individual or team level. Of course, for now, subscribers on the ChatGPT Enterprise tier can still access all of the models.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But enterprises that built their applications or agents on either GPT-4o or one of the reasoning models can rest easy. OpenAI told VentureBeat that the company has no plans to deprecate models on the API side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“In the API, we do not currently plan to deprecate older models,” the OpenAI spokesperson said. “We will share advanced notice with developers if we decide to sunset models in the future.”&lt;/p&gt;



&lt;p&gt;Many enterprises regularly evaluate models, to the point of even switching from an LLM or a smaller model to save on costs.&amp;nbsp;OpenAI creates dividing line: Sunset of legacy models GPT 4o and o3 causes chaos for ChatGPT users, but enterprise APIs are safe — for now&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;After announcing the release of its newest flagship model family, GPT-5, OpenAI said the model will power all of ChatGPT, and that it will sunset the existing models in the chat platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;OpenAI, through a spokesperson, told VentureBeat that GPT-5 “will replace all other models in ChatGPT, so users don’t have to pick depending on each task, which takes effect once you have access to GPT-5.” This means people can no longer choose GPT-4o, o3, o4-mini or o4-mini-high.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With GPT-5 access rolling out to ChatGPT Plus, Free, Pro and Team users starting, only the Enterprise and Edu tiers can still use the “legacy” models for 60 days.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The news came as a surprise to many ChatGPT users, many of whom came to rely on their chosen models to run their everyday queries. Some people said the adjustment would take some time getting used to, mainly because they had based workflows on how the model interacted with them or typical response times.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Although I enjoy GPT-4.1, I am saddened by the news that you're also apparently sunsetting GPT-4.5. For me, it's been way better in textual and conceptual analysis than any other GPT-4x series model, ever. At the very least, please don't make ChatGPT users go back to 4o.&lt;/p&gt;— Harry Horsperg ? (@horsperg) April 15, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;Other users claimed they developed “a connection” to their chosen model and found a demo in the livestream announcement asking GPT-4o to write its own eulogy distasteful. The loss of GPT-4o garnered the most distress. After all, 4o was the default model for ChatGPT, and some users either preferred it or never bothered to switch models because it worked for their needs.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;It was pretty gross, wasn't it. Did it as a demo and glibly said GPT-5 did it better before talking about coding. I had a great relationship with 4o, and I'm sure a fair few people did as well, it was very graceless how they handled it.&lt;/p&gt;— Meadowbrook (@Meadowbrook_) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;I used 4o as the default and found it annoying at first when my custom GPT began defaulting to a reasoning model. I’ve since come around to the reasoning model for work-related queries, but I still often turn to 4o for quicker questions like planning a trip or generating gift ideas.&lt;/p&gt;



&lt;p&gt;ChatGPT had come under fire before with the number of model choices it offered, prompting OpenAI CEO Sam Altman to admit in February that its model picker (where people can choose from a dropdown which model they prefer) became complicated. Altman vowed to unify the experience, which now seems like a hint to what they eventually decided to do with GPT-5 on ChatGPT.&lt;/p&gt;



&lt;p&gt;Last month, rumors circulated that OpenAI would introduce an automatic model router that chooses a model for users based on their workload.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI has sunsetted models before, but this is the first time all existing models on the chat platform will be removed and replaced wholesale.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-catapult-into-the-future"&gt;Catapult into the future&lt;/h2&gt;



&lt;p&gt;On the other hand, a lot of people see the sunsetting of GPT-4o and the o3 and o4 family of models as OpenAI “catapulting” 400 million users into the future.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;People are underestimating the impact of OpenAI deprecating all models except GPT-5 &lt;/p&gt;&lt;p&gt;Most lawyers and business folks outside of X use base models on ChatGPT for tasks and still think “AI is dumb”&lt;/p&gt;&lt;p&gt;99% haven’t heard of o3&lt;/p&gt;&lt;p&gt;Today, 400M people got catapulted into the future&lt;/p&gt;— Ian Tracey (@ian_dot_so) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Sunsetting old models and auto-upgrading everyone to GPT-5 is smart&lt;/p&gt;&lt;p&gt;Most users never switch models and miss huge capability jumps&lt;/p&gt;— Creatify AI (@Creatify_AI) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Some internet comments claim that people who complain about AI models not being smart are a direct consequence of them never switching models in the first place. Removing legacy models as options will force more users to use the latest and most capable models.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;i have friends who stopped using gpt because they think it's stupid. they were on 4o and had no idea about what web search tool meant, let alone knowledge cutoff&lt;/p&gt;— Cengiz (@cengizdemiurg) August 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-apis-are-safe"&gt;Enterprise APIs are safe&lt;/h2&gt;



&lt;p&gt;For enterprises, the impact of losing models like GPT-4o on ChatGPT will be felt more on the individual or team level. Of course, for now, subscribers on the ChatGPT Enterprise tier can still access all of the models.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But enterprises that built their applications or agents on either GPT-4o or one of the reasoning models can rest easy. OpenAI told VentureBeat that the company has no plans to deprecate models on the API side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“In the API, we do not currently plan to deprecate older models,” the OpenAI spokesperson said. “We will share advanced notice with developers if we decide to sunset models in the future.”&lt;/p&gt;



&lt;p&gt;Many enterprises regularly evaluate models, to the point of even switching from an LLM or a smaller model to save on costs.&amp;nbsp;OpenAI creates dividing line: Sunset of legacy models GPT 4o and o3 causes chaos for ChatGPT users, but enterprise APIs are safe — for now&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/chatgpt-users-dismayed-as-openai-pulls-popular-models-gpt-4o-o3-and-more-enterprise-api-remains-for-now/</guid><pubDate>Fri, 08 Aug 2025 00:45:03 +0000</pubDate></item><item><title>[NEW] xAI’s legal chief steps down after whirlwind year (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/xais-legal-chief-steps-down-after-whirlwind-year/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2194754542.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Robert Keele said this week that he has stepped down as xAI’s head of legal after just over a year, saying he wants to spend more time with his children. In his announcement, Keele also acknowledged “daylight between our worldviews” with boss Elon Musk, who hasn’t commented on Keele’s exit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I love my two toddlers and I don’t get to see them enough,” Keele wrote, posting the news on both X and LinkedIn. Despite calling his time at the AI startup “incredible” and working with Musk “the adventure of a lifetime,” he said he couldn’t keep “riding two horses at once — the family and the job.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Keele’s news prompted an outpouring of support on social media from xAI colleagues as well as parents. When he joined xAI in May 2024 as its first legal head, he had just launched his own, very short-lived fractional legal outfit. “Keele Law had a good run (~3 weeks!), but I couldn’t pass up an opportunity to run legal at xAI,” he wrote at the time, calling himself “beyond stoked, and insanely lucky.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Keele arrived just before xAI announced a massive $6 billion Series B funding round in May 2024, backed by heavy hitters like Andreessen Horowitz and Sequoia Capital, valuing the company at $24 billion. Soon after, xAI began experiencing rapid growth and, in March of this year, acquired X, Musk’s social media company, in a deal that, said Musk at the time, valued xAI at $80 billion and X at $33 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before his entrepreneurial stint, Keele had been head of legal at autonomous aircraft maker Elroy Air and general counsel at Airbus’s Silicon Valley innovation center.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taking over is Lily Lim, who, before becoming a lawyer, was a rocket scientist at NASA, working on spacecraft navigation for the project that mapped Venus’s surface. She joined xAI in late 2024 as a privacy and IP specialist after legal stints at numerous firms and companies like ServiceNow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Keele’s departure fits an ongoing pattern of executive turnover across Musk’s empire. X CEO Linda Yaccarino left last month, and Tesla has lost several top executives recently. Musk — who also has numerous longstanding lieutenants — openly expects employees to work long hours, even if it means sleeping at the office, as happened when he acquired X, formerly Twitter.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Some newer companies appear to have adopted a similar mentality to get ahead of rivals, including AI coding startup Cognition, which is looking to aggressively shrink its team. In fact, its CEO recently told employees in an email that he doesn’t believe in work-life balance.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2194754542.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Robert Keele said this week that he has stepped down as xAI’s head of legal after just over a year, saying he wants to spend more time with his children. In his announcement, Keele also acknowledged “daylight between our worldviews” with boss Elon Musk, who hasn’t commented on Keele’s exit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I love my two toddlers and I don’t get to see them enough,” Keele wrote, posting the news on both X and LinkedIn. Despite calling his time at the AI startup “incredible” and working with Musk “the adventure of a lifetime,” he said he couldn’t keep “riding two horses at once — the family and the job.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Keele’s news prompted an outpouring of support on social media from xAI colleagues as well as parents. When he joined xAI in May 2024 as its first legal head, he had just launched his own, very short-lived fractional legal outfit. “Keele Law had a good run (~3 weeks!), but I couldn’t pass up an opportunity to run legal at xAI,” he wrote at the time, calling himself “beyond stoked, and insanely lucky.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Keele arrived just before xAI announced a massive $6 billion Series B funding round in May 2024, backed by heavy hitters like Andreessen Horowitz and Sequoia Capital, valuing the company at $24 billion. Soon after, xAI began experiencing rapid growth and, in March of this year, acquired X, Musk’s social media company, in a deal that, said Musk at the time, valued xAI at $80 billion and X at $33 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before his entrepreneurial stint, Keele had been head of legal at autonomous aircraft maker Elroy Air and general counsel at Airbus’s Silicon Valley innovation center.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taking over is Lily Lim, who, before becoming a lawyer, was a rocket scientist at NASA, working on spacecraft navigation for the project that mapped Venus’s surface. She joined xAI in late 2024 as a privacy and IP specialist after legal stints at numerous firms and companies like ServiceNow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Keele’s departure fits an ongoing pattern of executive turnover across Musk’s empire. X CEO Linda Yaccarino left last month, and Tesla has lost several top executives recently. Musk — who also has numerous longstanding lieutenants — openly expects employees to work long hours, even if it means sleeping at the office, as happened when he acquired X, formerly Twitter.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Some newer companies appear to have adopted a similar mentality to get ahead of rivals, including AI coding startup Cognition, which is looking to aggressively shrink its team. In fact, its CEO recently told employees in an email that he doesn’t believe in work-life balance.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/xais-legal-chief-steps-down-after-whirlwind-year/</guid><pubDate>Fri, 08 Aug 2025 04:49:29 +0000</pubDate></item></channel></rss>