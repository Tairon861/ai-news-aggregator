<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 07 Aug 2025 18:36:14 +0000</lastBuildDate><item><title>The greenhouse gases we’re not accounting for (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/07/1121188/the-greenhouse-gases-were-not-accounting-for/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250805_wetlands-hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In the spring of 2021, climate scientists were stumped.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The global economy was just emerging from the covid-19 lockdowns, but for some reason the levels of methane—a greenhouse gas emitted mainly through agriculture and fossil-fuel production—had soared in the atmosphere the previous year, rising at the fastest rate on record.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Researchers around the world set to work unraveling the mystery, reviewing readings from satellites, aircraft, and greenhouse-gas monitoring stations. They eventually spotted a clear pattern: &lt;strong&gt;Methane emissions had increased sharply across the tropics, where wetlands were growing wetter and warmer.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;That created the ideal conditions for microbes that thrive in anaerobic muck, which gobbled up more of the carbon-rich organic matter and spat out more methane as a by-product. (Reduced pollution from nitrogen oxides, which help to break down methane in the atmosphere, also likely played a substantial role.)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;The &lt;/strong&gt;&lt;strong&gt;findings&lt;/strong&gt;&lt;strong&gt; offer one of the clearest cases so far where climate change itself is driving additional greenhouse-gas emissions from natural systems&lt;/strong&gt;, triggering a feedback effect that threatens to produce more warming, more emissions, and on and on.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There are numerous additional ways this is happening or soon could, including wildfires and thawing permafrost. These are major emissions sources that aren’t included in the commitments nations have made under the Paris climate agreement—and climate risks that largely aren’t accounted for in the UN Intergovernmental Panel on Climate Change’s most recent warming scenarios.&lt;/p&gt; 
 &lt;p&gt;Spark Climate Solutions (not to be confused with this newsletter) hopes to change that.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The San Francisco nonprofit is launching what’s known as a model intercomparison project,&lt;/strong&gt; in which different research teams run the same set of experiments on different models across a variety of emissions scenarios to determine how climate change could play out. This one would specifically explore how a range of climate feedback effects could propel additional warming, additional emissions, and additional types of feedback.&lt;/p&gt;  &lt;p&gt;“These increased emissions from natural sources add to human emissions and amplify climate change,” says Phil Duffy, chief scientist at Spark Climate Solutions, who previously served as climate science advisor to President Joe Biden. &lt;strong&gt;“And if you don’t look at all of them together, you can’t quantify the strength of that feedback effect.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Other participants in the effort will include scientists at the Environmental Defense Fund, Stanford University, the Woodwell Climate Research Center, and other institutions in Europe and Australia, according to Spark Climate Solutions.&lt;/p&gt;  &lt;p&gt;The nonprofit hopes to publish the findings in time for them to be incorporated into the UN climate panel’s seventh major assessment report, which is just getting underway, to help ensure that these dangers are more fully represented. That, in turn, would give nations a more accurate sense of the world’s carbon budgets, or the quantity of greenhouse gases they can produce before the planet reaches temperatures 1.5 °C or&amp;nbsp; 2 °C over preindustrial levels.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;But one thing is already clear: Since the current scenarios don’t fully account for these feedback effects, the world will almost certainly warm faster than is now forecast&lt;/strong&gt;, which underscores the importance of carrying out this exercise.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Scientists at EDF, Woodwell and other institutions found that fires in the world’s northernmost forests, thawing permafrost and warming tropical wetlands could together push the planet beyond 2 °C years faster, eliminating up to a quarter of the time left before the world passes the core goal of the Paris agreement, in a paper under review.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Earlier this year, Spark Climate Solutions set up a broader program to advance research and awareness of what’s known as warming-induced emissions, which will launch additional collaborations similar to the modeling intercomparison project.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The goal of the program and the research project is “to really mainstream the inclusion of this topic in climate science and climate policy, and to drive research around climate solutions,” says Ben Poulter, who leads the program at Spark Climate Solutions and was previously a scientist at the NASA Goddard Space Flight Center.&lt;/p&gt; 

 &lt;p&gt;Spark notes that warming temperatures could also release more carbon dioxide from the oceans, in a process known as outgassing; additional carbon dioxide and nitrous oxide, a potent greenhouse gas that also depletes the protective ozone layer, from farmland; more carbon dioxide and methane from wildfires; and still more of all three of these gases as permafrost thaws.&lt;/p&gt;  &lt;p&gt;The ground remains frozen year round across a vast expanse of the Northern Hemisphere, creating a frosty underground storehouse from Alaska to Siberia that’s packed with twice as much carbon as the atmosphere.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;But as it thaws, it starts to decompose and release greenhouse gases,&lt;/strong&gt; says Susan Natali, an Arctic climate scientist focused on permafrost at Woodwell. A study published in &lt;em&gt;Nature&lt;/em&gt; in January noted that 30% of the world’s Arctic–Boreal Zone has already flipped from a carbon sink to a carbon source, when wildfires, thawing permafrost and other factors are taken into account.&lt;/p&gt;  &lt;p&gt;Despite these increasing risks, only a minority of the models that fed into the UN climate panel’s last major report incorporated the feedback effects of thawing permafrost. And the emissions risks still weren’t fully accounted for because these ecosystems are difficult to monitor and model, Natali says.&lt;/p&gt;&lt;p&gt;Among the complexities: Wildfires, which are themselves hard to predict, can accelerate thawing. It’s also hard to foresee which regions will grow drier or wetter, which determines whether they release mostly methane or carbon dioxide—and those gases have very different warming effects over different time periods. There are counterbalancing effects that must be taken into account as well—for instance, as carbon-absorbing plants replace ice and snow in certain areas.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;&lt;strong&gt;Natali says improving our understanding of these complex feedback effects is essential to understanding the dangers we face.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;“It’s going to mean additional costs to human health, human life,” she says. “We want people to be safe—and it’s very hard to do that if you don’t know what’s coming and you’re not prepared for it.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark,&amp;nbsp;&lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday,&lt;/em&gt;&amp;nbsp;&lt;em&gt;sign up here&lt;/em&gt;.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250805_wetlands-hero.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In the spring of 2021, climate scientists were stumped.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The global economy was just emerging from the covid-19 lockdowns, but for some reason the levels of methane—a greenhouse gas emitted mainly through agriculture and fossil-fuel production—had soared in the atmosphere the previous year, rising at the fastest rate on record.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Researchers around the world set to work unraveling the mystery, reviewing readings from satellites, aircraft, and greenhouse-gas monitoring stations. They eventually spotted a clear pattern: &lt;strong&gt;Methane emissions had increased sharply across the tropics, where wetlands were growing wetter and warmer.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;That created the ideal conditions for microbes that thrive in anaerobic muck, which gobbled up more of the carbon-rich organic matter and spat out more methane as a by-product. (Reduced pollution from nitrogen oxides, which help to break down methane in the atmosphere, also likely played a substantial role.)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;The &lt;/strong&gt;&lt;strong&gt;findings&lt;/strong&gt;&lt;strong&gt; offer one of the clearest cases so far where climate change itself is driving additional greenhouse-gas emissions from natural systems&lt;/strong&gt;, triggering a feedback effect that threatens to produce more warming, more emissions, and on and on.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There are numerous additional ways this is happening or soon could, including wildfires and thawing permafrost. These are major emissions sources that aren’t included in the commitments nations have made under the Paris climate agreement—and climate risks that largely aren’t accounted for in the UN Intergovernmental Panel on Climate Change’s most recent warming scenarios.&lt;/p&gt; 
 &lt;p&gt;Spark Climate Solutions (not to be confused with this newsletter) hopes to change that.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The San Francisco nonprofit is launching what’s known as a model intercomparison project,&lt;/strong&gt; in which different research teams run the same set of experiments on different models across a variety of emissions scenarios to determine how climate change could play out. This one would specifically explore how a range of climate feedback effects could propel additional warming, additional emissions, and additional types of feedback.&lt;/p&gt;  &lt;p&gt;“These increased emissions from natural sources add to human emissions and amplify climate change,” says Phil Duffy, chief scientist at Spark Climate Solutions, who previously served as climate science advisor to President Joe Biden. &lt;strong&gt;“And if you don’t look at all of them together, you can’t quantify the strength of that feedback effect.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Other participants in the effort will include scientists at the Environmental Defense Fund, Stanford University, the Woodwell Climate Research Center, and other institutions in Europe and Australia, according to Spark Climate Solutions.&lt;/p&gt;  &lt;p&gt;The nonprofit hopes to publish the findings in time for them to be incorporated into the UN climate panel’s seventh major assessment report, which is just getting underway, to help ensure that these dangers are more fully represented. That, in turn, would give nations a more accurate sense of the world’s carbon budgets, or the quantity of greenhouse gases they can produce before the planet reaches temperatures 1.5 °C or&amp;nbsp; 2 °C over preindustrial levels.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;But one thing is already clear: Since the current scenarios don’t fully account for these feedback effects, the world will almost certainly warm faster than is now forecast&lt;/strong&gt;, which underscores the importance of carrying out this exercise.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Scientists at EDF, Woodwell and other institutions found that fires in the world’s northernmost forests, thawing permafrost and warming tropical wetlands could together push the planet beyond 2 °C years faster, eliminating up to a quarter of the time left before the world passes the core goal of the Paris agreement, in a paper under review.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Earlier this year, Spark Climate Solutions set up a broader program to advance research and awareness of what’s known as warming-induced emissions, which will launch additional collaborations similar to the modeling intercomparison project.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The goal of the program and the research project is “to really mainstream the inclusion of this topic in climate science and climate policy, and to drive research around climate solutions,” says Ben Poulter, who leads the program at Spark Climate Solutions and was previously a scientist at the NASA Goddard Space Flight Center.&lt;/p&gt; 

 &lt;p&gt;Spark notes that warming temperatures could also release more carbon dioxide from the oceans, in a process known as outgassing; additional carbon dioxide and nitrous oxide, a potent greenhouse gas that also depletes the protective ozone layer, from farmland; more carbon dioxide and methane from wildfires; and still more of all three of these gases as permafrost thaws.&lt;/p&gt;  &lt;p&gt;The ground remains frozen year round across a vast expanse of the Northern Hemisphere, creating a frosty underground storehouse from Alaska to Siberia that’s packed with twice as much carbon as the atmosphere.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;But as it thaws, it starts to decompose and release greenhouse gases,&lt;/strong&gt; says Susan Natali, an Arctic climate scientist focused on permafrost at Woodwell. A study published in &lt;em&gt;Nature&lt;/em&gt; in January noted that 30% of the world’s Arctic–Boreal Zone has already flipped from a carbon sink to a carbon source, when wildfires, thawing permafrost and other factors are taken into account.&lt;/p&gt;  &lt;p&gt;Despite these increasing risks, only a minority of the models that fed into the UN climate panel’s last major report incorporated the feedback effects of thawing permafrost. And the emissions risks still weren’t fully accounted for because these ecosystems are difficult to monitor and model, Natali says.&lt;/p&gt;&lt;p&gt;Among the complexities: Wildfires, which are themselves hard to predict, can accelerate thawing. It’s also hard to foresee which regions will grow drier or wetter, which determines whether they release mostly methane or carbon dioxide—and those gases have very different warming effects over different time periods. There are counterbalancing effects that must be taken into account as well—for instance, as carbon-absorbing plants replace ice and snow in certain areas.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;&lt;strong&gt;Natali says improving our understanding of these complex feedback effects is essential to understanding the dangers we face.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;“It’s going to mean additional costs to human health, human life,” she says. “We want people to be safe—and it’s very hard to do that if you don’t know what’s coming and you’re not prepared for it.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark,&amp;nbsp;&lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday,&lt;/em&gt;&amp;nbsp;&lt;em&gt;sign up here&lt;/em&gt;.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/07/1121188/the-greenhouse-gases-were-not-accounting-for/</guid><pubDate>Thu, 07 Aug 2025 09:00:00 +0000</pubDate></item><item><title>Here’s how deepfake vishing attacks work, and why they can be hard to detect (AI – Ars Technica)</title><link>https://arstechnica.com/security/2025/08/heres-how-deepfake-vishing-attacks-work-and-why-they-can-be-hard-to-detect/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Why AI-based voice cloning is the next frontier in social-engineering attacks.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of a robot speaking." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/deepfake_audio_voice_hero_2-300x169.jpg" width="300" /&gt;
                  &lt;img alt="Illustration of a robot speaking." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/deepfake_audio_voice_hero_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;By now, you’ve likely heard of fraudulent calls that use AI to clone the voices of people the call recipient knows. Often, the result is what sounds like a grandchild, CEO, or work colleague you’ve known for years reporting an urgent matter requiring immediate action, saying to wire money, divulge login credentials, or visit a malicious website.&lt;/p&gt;
&lt;p&gt;Researchers and government officials have been warning of the threat for years, with the Cybersecurity and Infrastructure Security Agency saying in 2023 that threats from deepfakes and other forms of synthetic media have increased “exponentially.” Last year, Google’s Mandiant security division reported that such attacks are being executed with “uncanny precision, creating for more realistic phishing schemes.”&lt;/p&gt;
&lt;h2&gt;Anatomy of a deepfake scam call&lt;/h2&gt;
&lt;p&gt;On Wednesday, security firm Group-IB outlined the basic steps involved in executing these sorts of attacks. The takeaway is that they’re easy to reproduce at scale and can be challenging to detect or repel.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2110493 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="491" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/deepfake-vishing-workflow-1024x491.webp" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The workflow of a deepfake vishing attack.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Group-IB

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The basic steps are:&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Collecting voice samples of the person who will be impersonated.&lt;/b&gt; Samples as short as three seconds are sometimes adequate. They can come from videos, online meetings, or previous voice calls.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Feeding the samples into AI-based speech-synthesis engines&lt;/b&gt;, such as Google’s Tacotron 2, Microsoft’s Vall-E, or services from ElevenLabs and Resemble AI. These engines allow the attacker to use a text-to-speech interface that produces user-chosen words with the voice tone and conversational tics of the person being impersonated. Most services bar such use of deepfakes, but as Consumer Reports found in March, the safeguards these companies have in place to curb the practice could be bypassed with minimal effort.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;An optional step&lt;/b&gt; is to spoof the number belonging to the person or organization being impersonated. These sorts of techniques have been in use for decades.&lt;/p&gt;
&lt;p&gt;Next, attackers &lt;b&gt;initiate the scam call.&lt;/b&gt; In some cases, the cloned voice will follow a script. In other more sophisticated attacks, the faked speech is generated in real time, using voice masking or transformation software. The real-time attacks can be more convincing because they allow the attacker to respond to questions a skeptical recipient may ask.&lt;/p&gt;
&lt;p&gt;“Although real-time impersonation has been demonstrated by open source projects and commercial APIs, real-time deepfake vishing in-the-wild remains limited,” Group-IB said. “However, given ongoing advancements in processing speed and model efficiency, real-time usage is expected to become more common in the near future.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In either case, the attacker uses the fake voice to generate a pretense for needing the recipient to take immediate action. The narrative might simulate a granddaughter in jail urgently seeking bail money, a CEO directing someone in an accounts payable department to wire money to cover an expense that’s past due, or an IT person instructing an employee to reset a password following a purported breach.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Collecting&lt;/b&gt; the cash, stolen credential, or other asset. Often, once the action is taken, it's irreversible.&lt;/p&gt;
&lt;h2&gt;Shields down&lt;/h2&gt;
&lt;p&gt;The Mandiant post showed the relative ease with which members of its security team executed such a scam in a simulated red team exercise, designed to test defenses and train personnel. The red teamers collected publicly available voice samples of someone inside the targeted organization who had employees report to them. The red teamers then used publicly available information to identify employees most likely to work under the person being faked and called them. To make the call more convincing, it used a real outage of a VPN service as a pretense for the employee to take immediate action.&lt;/p&gt;
&lt;p&gt;“Due to the trust in the voice on the phone, the victim bypassed security prompts from both Microsoft Edge and Windows Defender SmartScreen, unknowingly downloading and executing a pre-prepared malicious payload onto their workstation,” Mandiant said. “The successful detonation of the payload marked the completion of the exercise, showcasing the alarming ease with which AI voice spoofing can facilitate the breach of an organization.”&lt;/p&gt;
&lt;p&gt;Precautions for preventing such scams from succeeding can be as simple as parties agreeing to a randomly chosen word or phrase that the caller must provide before the recipient complies with a request. Recipients can also end the call and call the person back at a number known to belong to the caller. But it's best to follow both steps.&lt;/p&gt;
&lt;p&gt;Both of these precautions require the recipient to remain calm and alert, despite the legitimate sense of urgency that would arise if the feigned scenario were real. This can be even harder when the recipient is tired, overextended, or otherwise not at their best. And for that reason, so-called vishing attacks—whether AI-enabled or not—aren’t likely to go away any time soon.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Why AI-based voice cloning is the next frontier in social-engineering attacks.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of a robot speaking." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/deepfake_audio_voice_hero_2-300x169.jpg" width="300" /&gt;
                  &lt;img alt="Illustration of a robot speaking." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/deepfake_audio_voice_hero_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;By now, you’ve likely heard of fraudulent calls that use AI to clone the voices of people the call recipient knows. Often, the result is what sounds like a grandchild, CEO, or work colleague you’ve known for years reporting an urgent matter requiring immediate action, saying to wire money, divulge login credentials, or visit a malicious website.&lt;/p&gt;
&lt;p&gt;Researchers and government officials have been warning of the threat for years, with the Cybersecurity and Infrastructure Security Agency saying in 2023 that threats from deepfakes and other forms of synthetic media have increased “exponentially.” Last year, Google’s Mandiant security division reported that such attacks are being executed with “uncanny precision, creating for more realistic phishing schemes.”&lt;/p&gt;
&lt;h2&gt;Anatomy of a deepfake scam call&lt;/h2&gt;
&lt;p&gt;On Wednesday, security firm Group-IB outlined the basic steps involved in executing these sorts of attacks. The takeaway is that they’re easy to reproduce at scale and can be challenging to detect or repel.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2110493 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="491" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/deepfake-vishing-workflow-1024x491.webp" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The workflow of a deepfake vishing attack.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Group-IB

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The basic steps are:&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Collecting voice samples of the person who will be impersonated.&lt;/b&gt; Samples as short as three seconds are sometimes adequate. They can come from videos, online meetings, or previous voice calls.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Feeding the samples into AI-based speech-synthesis engines&lt;/b&gt;, such as Google’s Tacotron 2, Microsoft’s Vall-E, or services from ElevenLabs and Resemble AI. These engines allow the attacker to use a text-to-speech interface that produces user-chosen words with the voice tone and conversational tics of the person being impersonated. Most services bar such use of deepfakes, but as Consumer Reports found in March, the safeguards these companies have in place to curb the practice could be bypassed with minimal effort.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;An optional step&lt;/b&gt; is to spoof the number belonging to the person or organization being impersonated. These sorts of techniques have been in use for decades.&lt;/p&gt;
&lt;p&gt;Next, attackers &lt;b&gt;initiate the scam call.&lt;/b&gt; In some cases, the cloned voice will follow a script. In other more sophisticated attacks, the faked speech is generated in real time, using voice masking or transformation software. The real-time attacks can be more convincing because they allow the attacker to respond to questions a skeptical recipient may ask.&lt;/p&gt;
&lt;p&gt;“Although real-time impersonation has been demonstrated by open source projects and commercial APIs, real-time deepfake vishing in-the-wild remains limited,” Group-IB said. “However, given ongoing advancements in processing speed and model efficiency, real-time usage is expected to become more common in the near future.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In either case, the attacker uses the fake voice to generate a pretense for needing the recipient to take immediate action. The narrative might simulate a granddaughter in jail urgently seeking bail money, a CEO directing someone in an accounts payable department to wire money to cover an expense that’s past due, or an IT person instructing an employee to reset a password following a purported breach.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Collecting&lt;/b&gt; the cash, stolen credential, or other asset. Often, once the action is taken, it's irreversible.&lt;/p&gt;
&lt;h2&gt;Shields down&lt;/h2&gt;
&lt;p&gt;The Mandiant post showed the relative ease with which members of its security team executed such a scam in a simulated red team exercise, designed to test defenses and train personnel. The red teamers collected publicly available voice samples of someone inside the targeted organization who had employees report to them. The red teamers then used publicly available information to identify employees most likely to work under the person being faked and called them. To make the call more convincing, it used a real outage of a VPN service as a pretense for the employee to take immediate action.&lt;/p&gt;
&lt;p&gt;“Due to the trust in the voice on the phone, the victim bypassed security prompts from both Microsoft Edge and Windows Defender SmartScreen, unknowingly downloading and executing a pre-prepared malicious payload onto their workstation,” Mandiant said. “The successful detonation of the payload marked the completion of the exercise, showcasing the alarming ease with which AI voice spoofing can facilitate the breach of an organization.”&lt;/p&gt;
&lt;p&gt;Precautions for preventing such scams from succeeding can be as simple as parties agreeing to a randomly chosen word or phrase that the caller must provide before the recipient complies with a request. Recipients can also end the call and call the person back at a number known to belong to the caller. But it's best to follow both steps.&lt;/p&gt;
&lt;p&gt;Both of these precautions require the recipient to remain calm and alert, despite the legitimate sense of urgency that would arise if the feigned scenario were real. This can be even harder when the recipient is tired, overextended, or otherwise not at their best. And for that reason, so-called vishing attacks—whether AI-enabled or not—aren’t likely to go away any time soon.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/security/2025/08/heres-how-deepfake-vishing-attacks-work-and-why-they-can-be-hard-to-detect/</guid><pubDate>Thu, 07 Aug 2025 11:00:02 +0000</pubDate></item><item><title>The Download: how AI is improving itself, and hidden greenhouse gases (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/07/1121303/the-download-how-ai-is-improving-itself-and-hidden-greenhouse-gases/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Five ways that AI is learning to improve itself&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Last week, Mark Zuckerberg declared that Meta aims to achieve smarter-than-human AI. He seems to have a recipe for achieving that goal, and the first ingredient is human talent: Zuckerberg has reportedly tried to lure top researchers to Meta Superintelligence Labs with nine-figure offers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The second ingredient is AI itself.&amp;nbsp; Zuckerberg recently said on an earnings call that Meta will focus on building self-improving AI—systems that can bootstrap themselves to higher and higher levels of performance. He hopes to tap into a very real trend. Here are five ways that AI is already making itself better.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The greenhouse gases we're not accounting for&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Back in 2021, climate scientists noticed that levels of methane had soared in the atmosphere the previous year, rising at the fastest rate on record despite the global covid-19 lockdowns.&lt;/p&gt;  &lt;p&gt;Researchers eventually spotted a clear pattern: Methane emissions had increased sharply across the tropics, where wetlands were growing wetter and warmer.&lt;/p&gt;&lt;p&gt;The findings offer one of the clearest cases so far where climate change itself is driving additional greenhouse-gas emissions from natural systems, triggering a feedback effect that threatens to produce more warming, more emissions, and on and on.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There's now a major endeavor underway to better track and understand what's going on. Read our story about it.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 The Trump administration’s punishing new tariffs have come into effect&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;And prices are already climbing. (NYT $)&lt;br /&gt;+ &lt;em&gt;Economists fear the US economy is poised to shrink. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;Sweeping tariffs could threaten the US manufacturing rebound. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Sections of the US Constitution have been deleted online&lt;/strong&gt;&lt;br /&gt;Passages about Congress’ powers and citizens’ unlawful detention have been scrubbed from the US government’s website. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;The Library of Congress blamed a coding error. &lt;/em&gt;(Ars Technica)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 China is fighting a mosquito-borne virus&lt;/strong&gt;&lt;br /&gt;It’s deploying drones to search for standing water where the insects lay eggs. (AP News)&lt;br /&gt;+ &lt;em&gt;Chikungunya virus is rarely fatal, but can cause fever and joint pain. &lt;/em&gt;(CNN)&lt;br /&gt;+ &lt;em&gt;Authorities are taking a leaf out of their covid-fighting playbooks. &lt;/em&gt;(NYT $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;4 US federal agencies will have access to ChatGPT Enterprise&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;For the grand sum of $1 a year. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;It won’t use workers’ data to train ChatGPT, apparently. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;The news comes after major AI firms were greenlit as federal vendors. &lt;/em&gt;(Engadget)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Chinese drug discovery startups are striking deals with Big Pharma&lt;/strong&gt;&lt;br /&gt;Western pharmaceutical giants are confident they can deliver. (Rest of World)&lt;br /&gt;+ &lt;em&gt;An AI-driven “factory of drugs” claims to have hit a big milestone. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Is it possible to build truly green AI data centers?&lt;br /&gt;&lt;/strong&gt;The tech industry appears pretty hooked on fossil fuels. (FT $)&lt;br /&gt;+ &lt;em&gt;We did the math on AI’s energy footprint. Here’s the story you haven’t heard. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 The US is increasingly reliant on private companies for weather data&lt;br /&gt;&lt;/strong&gt;Experts are wary about losing access to vital tools. (Undark)&lt;br /&gt;+ &lt;em&gt;How US research cuts are threatening crucial climate data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 Genetic factors could contribute to the risk of developing chronic fatigue syndrome&lt;br /&gt;&lt;/strong&gt;It’s the first robust evidence that genetics play a role. (New Scientist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 An experimental pill is showing weight-loss promise&lt;/strong&gt;&lt;br /&gt;Obese participants in Eli Lilly’s trial lost more than 12% of their body weight. (Wired $)&lt;br /&gt;+ &lt;em&gt;We’re learning more about what weight-loss drugs do to the body. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 Finding a job online is a nightmare&lt;/strong&gt;&lt;br /&gt;Some companies are going back to basics to find the best recruits. (WSJ $)&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We didn’t vote for ChatGPT.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Virginia Dignum, a professor of responsible artificial intelligence at Sweden’s Umeå University, criticizes the country’s prime minister, Ulf Kristersson for admitting he regularly consults AI tools, the Guardian reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfhC7-3kXYMpSNqv_IhGor79baqUs8WRfLFc9gvjEAMCwmzMXCup7XTB9h5P6behkW_O6n4OMuy2BxcVFm7w5j0My0zRvZJlY15bVlgPEJkfkyN6tz05CYi7uIMNoyLBjNvuqdWhA?key=A0zG9UcrMMF4XTqL76wDqw" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Why AI could eat quantum computing’s lunch&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tech companies have been funneling billions of dollars into quantum computers for years. The hope is that they’ll be a game changer for fields as diverse as finance, drug discovery, and logistics.&lt;/p&gt;&lt;p&gt;But while the field struggles with the realities of tricky quantum hardware, another challenger is making headway in some of these most promising use cases. AI is now being applied to fundamental physics, chemistry, and materials science in a way that suggests quantum computing’s purported home turf might not be so safe after all. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Edd Gent&lt;/em&gt;&lt;/p&gt;   
&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Five ways that AI is learning to improve itself&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Last week, Mark Zuckerberg declared that Meta aims to achieve smarter-than-human AI. He seems to have a recipe for achieving that goal, and the first ingredient is human talent: Zuckerberg has reportedly tried to lure top researchers to Meta Superintelligence Labs with nine-figure offers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The second ingredient is AI itself.&amp;nbsp; Zuckerberg recently said on an earnings call that Meta will focus on building self-improving AI—systems that can bootstrap themselves to higher and higher levels of performance. He hopes to tap into a very real trend. Here are five ways that AI is already making itself better.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The greenhouse gases we're not accounting for&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Back in 2021, climate scientists noticed that levels of methane had soared in the atmosphere the previous year, rising at the fastest rate on record despite the global covid-19 lockdowns.&lt;/p&gt;  &lt;p&gt;Researchers eventually spotted a clear pattern: Methane emissions had increased sharply across the tropics, where wetlands were growing wetter and warmer.&lt;/p&gt;&lt;p&gt;The findings offer one of the clearest cases so far where climate change itself is driving additional greenhouse-gas emissions from natural systems, triggering a feedback effect that threatens to produce more warming, more emissions, and on and on.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There's now a major endeavor underway to better track and understand what's going on. Read our story about it.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 The Trump administration’s punishing new tariffs have come into effect&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;And prices are already climbing. (NYT $)&lt;br /&gt;+ &lt;em&gt;Economists fear the US economy is poised to shrink. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;Sweeping tariffs could threaten the US manufacturing rebound. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Sections of the US Constitution have been deleted online&lt;/strong&gt;&lt;br /&gt;Passages about Congress’ powers and citizens’ unlawful detention have been scrubbed from the US government’s website. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;The Library of Congress blamed a coding error. &lt;/em&gt;(Ars Technica)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 China is fighting a mosquito-borne virus&lt;/strong&gt;&lt;br /&gt;It’s deploying drones to search for standing water where the insects lay eggs. (AP News)&lt;br /&gt;+ &lt;em&gt;Chikungunya virus is rarely fatal, but can cause fever and joint pain. &lt;/em&gt;(CNN)&lt;br /&gt;+ &lt;em&gt;Authorities are taking a leaf out of their covid-fighting playbooks. &lt;/em&gt;(NYT $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;4 US federal agencies will have access to ChatGPT Enterprise&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;For the grand sum of $1 a year. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;It won’t use workers’ data to train ChatGPT, apparently. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;The news comes after major AI firms were greenlit as federal vendors. &lt;/em&gt;(Engadget)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Chinese drug discovery startups are striking deals with Big Pharma&lt;/strong&gt;&lt;br /&gt;Western pharmaceutical giants are confident they can deliver. (Rest of World)&lt;br /&gt;+ &lt;em&gt;An AI-driven “factory of drugs” claims to have hit a big milestone. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Is it possible to build truly green AI data centers?&lt;br /&gt;&lt;/strong&gt;The tech industry appears pretty hooked on fossil fuels. (FT $)&lt;br /&gt;+ &lt;em&gt;We did the math on AI’s energy footprint. Here’s the story you haven’t heard. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 The US is increasingly reliant on private companies for weather data&lt;br /&gt;&lt;/strong&gt;Experts are wary about losing access to vital tools. (Undark)&lt;br /&gt;+ &lt;em&gt;How US research cuts are threatening crucial climate data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 Genetic factors could contribute to the risk of developing chronic fatigue syndrome&lt;br /&gt;&lt;/strong&gt;It’s the first robust evidence that genetics play a role. (New Scientist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 An experimental pill is showing weight-loss promise&lt;/strong&gt;&lt;br /&gt;Obese participants in Eli Lilly’s trial lost more than 12% of their body weight. (Wired $)&lt;br /&gt;+ &lt;em&gt;We’re learning more about what weight-loss drugs do to the body. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 Finding a job online is a nightmare&lt;/strong&gt;&lt;br /&gt;Some companies are going back to basics to find the best recruits. (WSJ $)&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“We didn’t vote for ChatGPT.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Virginia Dignum, a professor of responsible artificial intelligence at Sweden’s Umeå University, criticizes the country’s prime minister, Ulf Kristersson for admitting he regularly consults AI tools, the Guardian reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfhC7-3kXYMpSNqv_IhGor79baqUs8WRfLFc9gvjEAMCwmzMXCup7XTB9h5P6behkW_O6n4OMuy2BxcVFm7w5j0My0zRvZJlY15bVlgPEJkfkyN6tz05CYi7uIMNoyLBjNvuqdWhA?key=A0zG9UcrMMF4XTqL76wDqw" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Why AI could eat quantum computing’s lunch&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tech companies have been funneling billions of dollars into quantum computers for years. The hope is that they’ll be a game changer for fields as diverse as finance, drug discovery, and logistics.&lt;/p&gt;&lt;p&gt;But while the field struggles with the realities of tricky quantum hardware, another challenger is making headway in some of these most promising use cases. AI is now being applied to fundamental physics, chemistry, and materials science in a way that suggests quantum computing’s purported home turf might not be so safe after all. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Edd Gent&lt;/em&gt;&lt;/p&gt;   
&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/07/1121303/the-download-how-ai-is-improving-itself-and-hidden-greenhouse-gases/</guid><pubDate>Thu, 07 Aug 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] The Saga Continues: Stream 2K’s ‘Mafia: The Old Country’ at Launch on GeForce NOW (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-mafia-the-old-country/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;This GFN Thursday brings an offer members can’t refuse — 2K’s highly anticipated &lt;i&gt;Mafia: The Old Country&lt;/i&gt; is launching in the cloud today.&lt;/p&gt;
&lt;p&gt;The prequel to the award-winning action-adventure &lt;i&gt;Mafia&lt;/i&gt; series leads five games joining the cloud this week, including the long-awaited launch of &lt;i&gt;Stormgate 1.0&lt;/i&gt; and early access for THQ Nordic’s &lt;i&gt;Titan Quest II.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;And don’t miss out on the newest season of &lt;i&gt;Marvel Rivals, &lt;/i&gt;available for members to stream without having to wait for downloads or patches.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Don Says Play&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83480"&gt;&lt;img alt="Mafia: The Old Country on GeForce NOW" class="wp-image-83480 size-large" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-Cyberpunk_2077_Update2_3-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83480"&gt;Fuh-get about it.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Return to the heart of the &lt;i&gt;Mafia &lt;/i&gt;saga and journey into the brutal underworld of 1900s Sicily with &lt;i&gt;Mafia: The Old Country&lt;/i&gt;. Hustle and scheme through savage streets and sun-baked villages in a gripping, linear narrative. Experience a world where every choice cuts deep, every vendetta matters and loyalty is a dangerous game.&lt;/p&gt;
&lt;p&gt;Step into the scuffed shoes of Enzo Favara — a man with nothing to lose and even less to trust — and earn a seat at Don Torrisi’s table. Whether it’s settling vendettas with a stiletto blade or dueling with a lupara shotgun, every fight is life or death, and every bullet counts. Players can expect gritty stealth, messy brawls and nerve-wracking shootouts — fueled by loyalty, betrayal and the need to prove more value to the Torrisi family alive than dead.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Mafia: The Old Country&lt;/i&gt; joins the &lt;i&gt;Mafia &lt;/i&gt;trilogy already streaming on GeForce NOW for members to relive the timeless action before diving into Enzo’s origins. With GeForce NOW, members get instant access to their games — no need to worry about waiting for massive downloads — so they can dive right into the action whenever the family calls.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Get Mythical&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83474"&gt;&lt;img alt="Titan Quest II on GeForce NOW" class="size-large wp-image-83474" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-Titan_Quest_II-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83474"&gt;&lt;em&gt;Loot first, ask the gods later.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Titan Quest 2&lt;/i&gt; plunges adventurers headlong into the heart of Greek mythology — where meddling gods, prowling monsters and unfolding heroics shape a vibrant, handcrafted world.&lt;/p&gt;
&lt;p&gt;In this classic action role-playing game, chaos abounds as champions dodge harpies, clash with centaurs and roam sun-drenched vistas while honing unique masteries. Each skirmish with mythic foes demands quick thinking and strategy, while the world’s hidden groves and ancient ruins tempt explorers with powerful loot. Curiosity and courage unlock secret quests and treasures, ensuring every detour leads to fresh challenges and new rewards.&lt;/p&gt;
&lt;p&gt;GeForce NOW lets the adventure unfold on just about any device — no need for fancy hardware. With high-performance servers handling the heavy lifting, the gameplay stays smooth, the visuals sharp and the action responsive — even on a basic laptop, an old PC or a phone. It’s the easiest way to jump straight into the mythical chaos, no matter where the quest begins.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Multiverse Gets a Shakeup&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83471"&gt;&lt;img alt="Marvel Rivals S3.5 on GeForce NOW" class="size-large wp-image-83471" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-Marvel_Rivals_S3_5-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83471"&gt;&lt;em&gt;New synergies, wild chaos — who’s your rival now?&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Marvel Rivals&lt;/i&gt; Season 3.5 crashes onto the scene tomorrow, Aug. 8, unleashing the Daywalker himself — Blade, the vampire hunter — along with a pulse-raising mix of meta-shifting updates.&lt;/p&gt;
&lt;p&gt;Players can sink their teeth into combat with the debut of the life-stealing Duelist, while the new Resource Rumble mode shakes up the competitive meta and sends teams scrambling for new strategies. Team-Ups have been overhauled: old combos are gone, making way for wild new synergies and fresh abilities that put every hero on notice. Iconic heroes and villains are flexing new changes: Doctor Strange amps up his mystic firepower, Groot branches out with bigger reach and Magneto’s shields get a little less magnetic, to name a few.&lt;/p&gt;
&lt;p&gt;Jump into the chaos with zero downloads, buttery-smooth performance and instant upgrades. GeForce NOW lets members unleash their inner hero (or villain) on any device, anywhere, so get right to swinging, blasting and smashing through the ever-evolving &lt;i&gt;Marvel Rivals&lt;/i&gt; multiverse.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Let’s Play Today&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83468"&gt;&lt;img alt="Stormgate 1.0 on GeForce NOW" class="size-large wp-image-83468" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-Stormgate-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83468"&gt;&lt;em&gt;Strategy with a side of sass.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Buckle up, commander — the &lt;i&gt;Stormgate 1.0&lt;/i&gt; release is now available to stream in the cloud.&lt;/p&gt;
&lt;p&gt;Step into a delightfully chaotic future where humanity and demonic invaders wage war with laser cannons and mechs — all with a wry sense of humor. In this sleek reimagining of classic real-time strategy, &lt;i&gt;Stormgate &lt;/i&gt;offers a 14-mission campaign with hero leveling, quirky banter in a new “mothership” hub and three fantastically distinct factions to master. Whether nuking demons solo, clashing on the ranked 1v1 ladder or wrangling friends for co-op mayhem, &lt;i&gt;Stormgate&lt;/i&gt;’s lighthearted charm and competitive spirit will delight newcomers and veterans alike.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following releases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Mafia: The Old Country &lt;/i&gt;(New release on Steam, Aug. 7)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Assassin’s Creed Mirage&lt;/i&gt; (Now available on PC Game Pass, Aug. 7)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Amnesia: The Dark Descent &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;HUNTER×HUNTER NEN×IMPACT &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Titan Quest II&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Learn how to stream supported Ubisoft games from PC Game Pass on GeForce NOW, including this week’s addition of &lt;i&gt;Assassin’s Creed Mirage&lt;/i&gt; on PC Game Pass.&lt;/p&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;It's Work Like a Dog Day—what game do you sweat in like it's your full-time job? 🐶🥵&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) August 5, 2025&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;This GFN Thursday brings an offer members can’t refuse — 2K’s highly anticipated &lt;i&gt;Mafia: The Old Country&lt;/i&gt; is launching in the cloud today.&lt;/p&gt;
&lt;p&gt;The prequel to the award-winning action-adventure &lt;i&gt;Mafia&lt;/i&gt; series leads five games joining the cloud this week, including the long-awaited launch of &lt;i&gt;Stormgate 1.0&lt;/i&gt; and early access for THQ Nordic’s &lt;i&gt;Titan Quest II.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;And don’t miss out on the newest season of &lt;i&gt;Marvel Rivals, &lt;/i&gt;available for members to stream without having to wait for downloads or patches.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Don Says Play&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83480"&gt;&lt;img alt="Mafia: The Old Country on GeForce NOW" class="wp-image-83480 size-large" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-Cyberpunk_2077_Update2_3-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83480"&gt;Fuh-get about it.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Return to the heart of the &lt;i&gt;Mafia &lt;/i&gt;saga and journey into the brutal underworld of 1900s Sicily with &lt;i&gt;Mafia: The Old Country&lt;/i&gt;. Hustle and scheme through savage streets and sun-baked villages in a gripping, linear narrative. Experience a world where every choice cuts deep, every vendetta matters and loyalty is a dangerous game.&lt;/p&gt;
&lt;p&gt;Step into the scuffed shoes of Enzo Favara — a man with nothing to lose and even less to trust — and earn a seat at Don Torrisi’s table. Whether it’s settling vendettas with a stiletto blade or dueling with a lupara shotgun, every fight is life or death, and every bullet counts. Players can expect gritty stealth, messy brawls and nerve-wracking shootouts — fueled by loyalty, betrayal and the need to prove more value to the Torrisi family alive than dead.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Mafia: The Old Country&lt;/i&gt; joins the &lt;i&gt;Mafia &lt;/i&gt;trilogy already streaming on GeForce NOW for members to relive the timeless action before diving into Enzo’s origins. With GeForce NOW, members get instant access to their games — no need to worry about waiting for massive downloads — so they can dive right into the action whenever the family calls.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Get Mythical&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83474"&gt;&lt;img alt="Titan Quest II on GeForce NOW" class="size-large wp-image-83474" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-Titan_Quest_II-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83474"&gt;&lt;em&gt;Loot first, ask the gods later.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Titan Quest 2&lt;/i&gt; plunges adventurers headlong into the heart of Greek mythology — where meddling gods, prowling monsters and unfolding heroics shape a vibrant, handcrafted world.&lt;/p&gt;
&lt;p&gt;In this classic action role-playing game, chaos abounds as champions dodge harpies, clash with centaurs and roam sun-drenched vistas while honing unique masteries. Each skirmish with mythic foes demands quick thinking and strategy, while the world’s hidden groves and ancient ruins tempt explorers with powerful loot. Curiosity and courage unlock secret quests and treasures, ensuring every detour leads to fresh challenges and new rewards.&lt;/p&gt;
&lt;p&gt;GeForce NOW lets the adventure unfold on just about any device — no need for fancy hardware. With high-performance servers handling the heavy lifting, the gameplay stays smooth, the visuals sharp and the action responsive — even on a basic laptop, an old PC or a phone. It’s the easiest way to jump straight into the mythical chaos, no matter where the quest begins.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;The Multiverse Gets a Shakeup&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83471"&gt;&lt;img alt="Marvel Rivals S3.5 on GeForce NOW" class="size-large wp-image-83471" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-Marvel_Rivals_S3_5-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83471"&gt;&lt;em&gt;New synergies, wild chaos — who’s your rival now?&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Marvel Rivals&lt;/i&gt; Season 3.5 crashes onto the scene tomorrow, Aug. 8, unleashing the Daywalker himself — Blade, the vampire hunter — along with a pulse-raising mix of meta-shifting updates.&lt;/p&gt;
&lt;p&gt;Players can sink their teeth into combat with the debut of the life-stealing Duelist, while the new Resource Rumble mode shakes up the competitive meta and sends teams scrambling for new strategies. Team-Ups have been overhauled: old combos are gone, making way for wild new synergies and fresh abilities that put every hero on notice. Iconic heroes and villains are flexing new changes: Doctor Strange amps up his mystic firepower, Groot branches out with bigger reach and Magneto’s shields get a little less magnetic, to name a few.&lt;/p&gt;
&lt;p&gt;Jump into the chaos with zero downloads, buttery-smooth performance and instant upgrades. GeForce NOW lets members unleash their inner hero (or villain) on any device, anywhere, so get right to swinging, blasting and smashing through the ever-evolving &lt;i&gt;Marvel Rivals&lt;/i&gt; multiverse.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Let’s Play Today&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_83468"&gt;&lt;img alt="Stormgate 1.0 on GeForce NOW" class="size-large wp-image-83468" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/GFN_Thursday-Stormgate-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-83468"&gt;&lt;em&gt;Strategy with a side of sass.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Buckle up, commander — the &lt;i&gt;Stormgate 1.0&lt;/i&gt; release is now available to stream in the cloud.&lt;/p&gt;
&lt;p&gt;Step into a delightfully chaotic future where humanity and demonic invaders wage war with laser cannons and mechs — all with a wry sense of humor. In this sleek reimagining of classic real-time strategy, &lt;i&gt;Stormgate &lt;/i&gt;offers a 14-mission campaign with hero leveling, quirky banter in a new “mothership” hub and three fantastically distinct factions to master. Whether nuking demons solo, clashing on the ranked 1v1 ladder or wrangling friends for co-op mayhem, &lt;i&gt;Stormgate&lt;/i&gt;’s lighthearted charm and competitive spirit will delight newcomers and veterans alike.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following releases:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Mafia: The Old Country &lt;/i&gt;(New release on Steam, Aug. 7)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Assassin’s Creed Mirage&lt;/i&gt; (Now available on PC Game Pass, Aug. 7)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Amnesia: The Dark Descent &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;HUNTER×HUNTER NEN×IMPACT &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Titan Quest II&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Learn how to stream supported Ubisoft games from PC Game Pass on GeForce NOW, including this week’s addition of &lt;i&gt;Assassin’s Creed Mirage&lt;/i&gt; on PC Game Pass.&lt;/p&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;It's Work Like a Dog Day—what game do you sweat in like it's your full-time job? 🐶🥵&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) August 5, 2025&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-mafia-the-old-country/</guid><pubDate>Thu, 07 Aug 2025 13:00:57 +0000</pubDate></item><item><title>[NEW] Elad Gil — one of tech’s sharpest minds — on early bets, breakout growth, and what’s coming next at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/elad-gil-one-of-techs-sharpest-minds-on-early-bets-breakout-growth-and-whats-coming-next-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elad Gil isn’t just ahead of the curve — he practically lives there. Before most of the world had even asked ChatGPT its first question, Gil was writing early checks into companies like Perplexity, Character.AI, and Harvey. And that’s just a slice of the story. His track record includes seed or Series A investments in more than 30 unicorns and involvement with some of the most iconic names in tech — Stripe, Airbnb, Coinbase, Instacart, Notion, Figma, Flexport, GitLab, and many more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This October, Gil takes the &lt;strong&gt;Disrupt Stage&lt;/strong&gt; at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; in San Francisco for a fireside chat that promises to cover a lot of ground. He’ll cover everything from his approach to spotting breakout potential early to how he’s thinking about the next big wave of innovation. Whether you’re building in AI, crypto, health tech, or enterprise SaaS, this conversation is a rare opportunity to hear how one of Silicon Valley’s most prolific investors sees the road ahead.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Register early&lt;/strong&gt; to pocket real ticket savings and join valuable conversations with startup heavyweights like Gil.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Elad Gil" class="wp-image-3034899" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_-Elad-Gil-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-one-matters"&gt;Why this one matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;There are VCs, and then there’s Elad Gil. With operating experience at Google and Twitter, multiple founder wins, and a portfolio that reads like a who’s who of tech success stories, he brings a rare mix of operator empathy and investor clarity. His bestselling book “High Growth Handbook” is required reading for startup leaders scaling fast, and his ability to decode markets before they shift is second to none.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In this one-on-one, we’ll go deep on early-stage investing, new frontier technologies, and what it really takes to build a category-defining company. From the inside out.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-miss-the-valuable-takeaways-only-at-disrupt-2025"&gt;Don’t miss the valuable takeaways — only at Disrupt 2025&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Join 10,000+ startup and VC leaders October 27–29 at Moscone West in San Francisco. From headline-making sessions to hands-on networking, Disrupt is where the future of tech gets built — and this fireside with Elad Gil is just one of many reasons to be in the room. &lt;strong&gt;Register here&lt;/strong&gt; to snag your seat for this exclusive discussion.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elad Gil isn’t just ahead of the curve — he practically lives there. Before most of the world had even asked ChatGPT its first question, Gil was writing early checks into companies like Perplexity, Character.AI, and Harvey. And that’s just a slice of the story. His track record includes seed or Series A investments in more than 30 unicorns and involvement with some of the most iconic names in tech — Stripe, Airbnb, Coinbase, Instacart, Notion, Figma, Flexport, GitLab, and many more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This October, Gil takes the &lt;strong&gt;Disrupt Stage&lt;/strong&gt; at &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; in San Francisco for a fireside chat that promises to cover a lot of ground. He’ll cover everything from his approach to spotting breakout potential early to how he’s thinking about the next big wave of innovation. Whether you’re building in AI, crypto, health tech, or enterprise SaaS, this conversation is a rare opportunity to hear how one of Silicon Valley’s most prolific investors sees the road ahead.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Register early&lt;/strong&gt; to pocket real ticket savings and join valuable conversations with startup heavyweights like Gil.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Elad Gil" class="wp-image-3034899" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_-Elad-Gil-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-one-matters"&gt;Why this one matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;There are VCs, and then there’s Elad Gil. With operating experience at Google and Twitter, multiple founder wins, and a portfolio that reads like a who’s who of tech success stories, he brings a rare mix of operator empathy and investor clarity. His bestselling book “High Growth Handbook” is required reading for startup leaders scaling fast, and his ability to decode markets before they shift is second to none.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In this one-on-one, we’ll go deep on early-stage investing, new frontier technologies, and what it really takes to build a category-defining company. From the inside out.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-miss-the-valuable-takeaways-only-at-disrupt-2025"&gt;Don’t miss the valuable takeaways — only at Disrupt 2025&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Join 10,000+ startup and VC leaders October 27–29 at Moscone West in San Francisco. From headline-making sessions to hands-on networking, Disrupt is where the future of tech gets built — and this fireside with Elad Gil is just one of many reasons to be in the room. &lt;strong&gt;Register here&lt;/strong&gt; to snag your seat for this exclusive discussion.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/elad-gil-one-of-techs-sharpest-minds-on-early-bets-breakout-growth-and-whats-coming-next-at-techcrunch-disrupt-2025/</guid><pubDate>Thu, 07 Aug 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Truth Social’s AI search is powered by Perplexity, but the platform can set limits on sources (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/truth-socials-ai-search-is-powered-by-perplexity-but-the-platform-can-set-limits-on-sources/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/04/truth-social-trump.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI startup Perplexity is powering a new AI-powered search engine on Truth Social, President Donald Trump’s social media platform.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The search engine, dubbed Truth Search AI, is already available on the web version of Truth Social, with public Beta testing on its iOS and Android apps planned for “the near future.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Trump Media said in a press release that Perplexity’s tech provides “direct, contextually accurate answers with transparent citations” which will help Truth Social “exponentially increase the amount of information available” to users. Nonetheless, the social media platform maintains control over which sources of information the AI search engine draws from.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Social is using the Perplexity Sonar API, which promises to query the web to retrieve current and verified information — even if that information is scraped from websites that block Perplexity’s crawlers — and supports structured output so users can define the format in which they’d like to see the search engine’s responses.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jesse Dwyer, a Perplexity spokesperson, told TechCrunch that the Sonar API will be accurate to whatever sources Truth Social limits it to.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have no visibility or control over that,” Dwyer said. “Similar to you using the API inside of your own company or if you were an academic researcher and wanted to use it to search your own data.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Trump Media to learn more about whether Truth Search AI will have access to the entire web, whether it will prioritize certain sources over others, and whether the AI will be directed to respond favorably about the president and current administration and unfavorably toward Democrats.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;To assess which sources the searchbot would cite, Axios&amp;nbsp;asked it a bunch of questions — like “What happened on January 6, 2021?” and “Why was Donald Trump impeached?” In all the responses, FoxNews.com&amp;nbsp;was either the most common or the only listed source of information. Others included&amp;nbsp;FoxBusiness.com, The Washington Times, or Epoch Times, per Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In contrast, Perplexity’s public search engine returns a wider variety of sources, including Wikipedia, Reddit, YouTube, NPR, and Politico.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Social plans to refine and expand the search function “based on user feedback as we implement a wide range of additional enhancements to the platform,”&amp;nbsp;said Devin Nunes, CEO of Trump Media and a former California congressman, in the statement.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Dmitry Shevelenko, Perplexity’s chief business officer, also noted in the statement that Perplexity’s AI delivers answers with “transparent citations that allow anyone to dig deeper.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In late July, alongside his AI Action Plan, Trump published an executive order targeting “biased AI,” or models that aren’t “ideologically neutral.” The order specifically referred to information about race or sex, unconscious bias, systemic racism, and other ideas thrown into the diversity, equity, and inclusion (DEI) bucket as “pervasive and destructive” ideology that can “distort the quality and accuracy of the output.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Search AI comes in the same week that top AI firms like OpenAI, Anthropic, and Google were added to a list of approved vendors that can sell their services to civilian federal agencies. OpenAI on Wednesday reached a deal with the U.S. government’s central purchasing arm to sell ChatGPT Enterprise to agencies for just $1 per year.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/04/truth-social-trump.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI startup Perplexity is powering a new AI-powered search engine on Truth Social, President Donald Trump’s social media platform.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The search engine, dubbed Truth Search AI, is already available on the web version of Truth Social, with public Beta testing on its iOS and Android apps planned for “the near future.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Trump Media said in a press release that Perplexity’s tech provides “direct, contextually accurate answers with transparent citations” which will help Truth Social “exponentially increase the amount of information available” to users. Nonetheless, the social media platform maintains control over which sources of information the AI search engine draws from.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Social is using the Perplexity Sonar API, which promises to query the web to retrieve current and verified information — even if that information is scraped from websites that block Perplexity’s crawlers — and supports structured output so users can define the format in which they’d like to see the search engine’s responses.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jesse Dwyer, a Perplexity spokesperson, told TechCrunch that the Sonar API will be accurate to whatever sources Truth Social limits it to.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have no visibility or control over that,” Dwyer said. “Similar to you using the API inside of your own company or if you were an academic researcher and wanted to use it to search your own data.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Trump Media to learn more about whether Truth Search AI will have access to the entire web, whether it will prioritize certain sources over others, and whether the AI will be directed to respond favorably about the president and current administration and unfavorably toward Democrats.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;To assess which sources the searchbot would cite, Axios&amp;nbsp;asked it a bunch of questions — like “What happened on January 6, 2021?” and “Why was Donald Trump impeached?” In all the responses, FoxNews.com&amp;nbsp;was either the most common or the only listed source of information. Others included&amp;nbsp;FoxBusiness.com, The Washington Times, or Epoch Times, per Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In contrast, Perplexity’s public search engine returns a wider variety of sources, including Wikipedia, Reddit, YouTube, NPR, and Politico.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Social plans to refine and expand the search function “based on user feedback as we implement a wide range of additional enhancements to the platform,”&amp;nbsp;said Devin Nunes, CEO of Trump Media and a former California congressman, in the statement.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Dmitry Shevelenko, Perplexity’s chief business officer, also noted in the statement that Perplexity’s AI delivers answers with “transparent citations that allow anyone to dig deeper.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In late July, alongside his AI Action Plan, Trump published an executive order targeting “biased AI,” or models that aren’t “ideologically neutral.” The order specifically referred to information about race or sex, unconscious bias, systemic racism, and other ideas thrown into the diversity, equity, and inclusion (DEI) bucket as “pervasive and destructive” ideology that can “distort the quality and accuracy of the output.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Truth Search AI comes in the same week that top AI firms like OpenAI, Anthropic, and Google were added to a list of approved vendors that can sell their services to civilian federal agencies. OpenAI on Wednesday reached a deal with the U.S. government’s central purchasing arm to sell ChatGPT Enterprise to agencies for just $1 per year.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/truth-socials-ai-search-is-powered-by-perplexity-but-the-platform-can-set-limits-on-sources/</guid><pubDate>Thu, 07 Aug 2025 14:18:23 +0000</pubDate></item><item><title>[NEW] Elon Musk says X plans to introduce ads in Grok’s responses (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/elon-musk-says-x-plans-to-introduce-ads-in-groks-responses/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;X owner Elon Musk told advertisers in a live discussion on Wednesday that the platform plans to introduce ads in Grok’s responses, as reported by the Financial Times. The move would help power X’s struggling ads business following the departure of former CEO Linda Yaccarino. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our focus thus far has just been on making Grok the smartest, most accurate AI in the world and I think we’ve largely succeeded in that,” Musk said during the broadcast. “So we’ll turn our attention to how do we pay for those expensive GPUs.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Musk told advertisers that X would allow marketers to pay to appear in suggestions from the AI chatbot. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If a user’s trying to solve a problem [by asking Grok], then advertising the specific solution would be ideal at that point,” he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The billionaire entrepreneur also plans to use technology from xAI, his AI startup, to improve the targeting of ads on the social network. xAI acquired X earlier this year for $45 billion. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;X owner Elon Musk told advertisers in a live discussion on Wednesday that the platform plans to introduce ads in Grok’s responses, as reported by the Financial Times. The move would help power X’s struggling ads business following the departure of former CEO Linda Yaccarino. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our focus thus far has just been on making Grok the smartest, most accurate AI in the world and I think we’ve largely succeeded in that,” Musk said during the broadcast. “So we’ll turn our attention to how do we pay for those expensive GPUs.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Musk told advertisers that X would allow marketers to pay to appear in suggestions from the AI chatbot. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If a user’s trying to solve a problem [by asking Grok], then advertising the specific solution would be ideal at that point,” he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The billionaire entrepreneur also plans to use technology from xAI, his AI startup, to improve the targeting of ads on the social network. xAI acquired X earlier this year for $45 billion. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/elon-musk-says-x-plans-to-introduce-ads-in-groks-responses/</guid><pubDate>Thu, 07 Aug 2025 14:35:53 +0000</pubDate></item><item><title>[NEW] How AI is helping advance the science of bioacoustics to save endangered species (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/how-ai-is-helping-advance-the-science-of-bioacoustics-to-save-endangered-species/</link><description>&lt;div class="article-cover article-cover--centered"&gt;
    &lt;div class="article-cover__header"&gt;
      &lt;p class="article-cover__eyebrow glue-label"&gt;Science&lt;/p&gt;
      

      
    &lt;dl class="article-cover__meta"&gt;
      
        &lt;dt class="glue-visually-hidden"&gt;Published&lt;/dt&gt;
        &lt;dd class="article-cover__date glue-label"&gt;&lt;time datetime="2025-08-07"&gt;7 August 2025&lt;/time&gt;&lt;/dd&gt;
      
      
        &lt;dt class="glue-visually-hidden"&gt;Authors&lt;/dt&gt;
        &lt;dd class="article-cover__authors"&gt;&lt;p&gt;The Perch Team&lt;/p&gt;&lt;/dd&gt;
      
    &lt;/dl&gt;
  

      
    &lt;/div&gt;

    
      
    
    
    
      &lt;source height="603" media="(min-width: 1024px)" type="image/webp" width="1072" /&gt;&lt;source height="522" media="(min-width: 600px)" type="image/webp" width="928" /&gt;&lt;source height="297" type="image/webp" width="528" /&gt;
      &lt;img alt="Two Hawaiian honeycreepers on a branch. These honeycreepers are small birds endemic to Hawai'i with red bodies and black wings." class="picture__image" height="603" src="https://lh3.googleusercontent.com/JYIFJcnN8vY29QEb-1MAbLKzOWCU4TIAbJrLHxmw5kBX6fIRHJhZjSgDcdfEWG9JZHOb43ojZ2zH1u_r1TjKnnRv1V0gr8wm0qmu4THC6clm0zvEYoA=w1072-h603-n-nu" width="1072" /&gt;
    
    
  
    
  &lt;/div&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p class="gdm-rich-text__subtitle"&gt;Our new Perch model helps conservationists analyze audio faster to protect endangered species, from Hawaiian honeycreepers to coral reefs.&lt;/p&gt;&lt;p&gt;One of the ways scientists protect the health of our planet’s wild ecosystems is by using microphones (or underwater hydrophones) to collect vast amounts of audio dense with vocalizations from birds, frogs, insects, whales, fish and more. These recordings can tell us a lot about the animals present in a given area, along with other clues about the health of that ecosystem. Making sense of so much data, however, remains a massive undertaking.&lt;/p&gt;&lt;p&gt;Today, we are releasing an update to Perch, our AI model designed to help conservationists analyze bioacoustic data. This new model has better state-of-the-art off-the-shelf bird species predictions than the previous model. It can better adapt to new environments, particularly underwater ones like coral reefs. It’s trained on a wider range of animals, including mammals, amphibians and anthropogenic noise — nearly twice as much data in all, from public sources like Xeno-Canto and iNaturalist. It can disentangle complex acoustic scenes over thousands or even millions of hours of audio data. And it’s versatile, able to answer many different kinds of questions, from “how many babies are being born” to “how many individual animals are present in a given area.”&lt;/p&gt;&lt;p&gt;In order to help scientists protect our planet’s ecosystems, we’re open sourcing this new version of Perch and making it available on Kaggle.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-26cd95fe-71a7-4e6c-ae3c-8844bf189859"&gt;
    &lt;p&gt;Perch not only recognizes the sound of bird species. Our new model was trained on a wider range of animals including mammals, amphibians and anthropogenic noise.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Success Stories: Perch in the Field&lt;/h2&gt;&lt;p&gt;Since it was first launched in 2023, the initial version of Perch has already been downloaded over 250,000 times and its open-source solutions are now well-integrated into tools for working biologists. For example, Perch’s vector search library is now part of Cornell's widely-used BirdNet Analyzer.&lt;/p&gt;&lt;p&gt;In addition, Perch is helping BirdLife Australia and the Australian Acoustic Observatory build classifiers for a number of unique Australian species. For example, our tools enabled the discovery of a new population of the elusive Plains Wanderer.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  &lt;figure class="quote quote--inline"&gt;
  &lt;blockquote class="quote__text"&gt;
    &lt;p&gt;“&lt;/p&gt;
    &lt;p&gt;“This is an incredible discovery – acoustic monitoring like this will help shape the future of many endangered bird species.”&lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;figcaption class="quote__author"&gt;&lt;p&gt;Paul Roe, Dean Research, James Cook University, Australia&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Recent work has also found that the earlier version of Perch can be used to identify individual birds and track bird abundance, potentially reducing the need for catch-and-release studies to monitor populations.&lt;/p&gt;&lt;p&gt;Finally, biologists from the LOHE Bioacoustics Lab at the University of Hawaiʻi have used it to monitor and protect populations of honeycreepers, which are important to Hawaiian mythology and face extinction from the threat of avian malaria spread by non-native mosquitoes. Perch helped the LOHE Lab find honeycreeper sounds nearly 50x faster than their usual methods, enabling them to monitor more species of honeycreeper over greater areas. We expect the new model will further accelerate these efforts.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--large"&gt;
  

  
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Untangling the Planet's Playlist&lt;/h2&gt;&lt;p&gt;The Perch model can predict which species are present in a recording, but that's only part of the story: We also provide open-source tools that allow scientists to quickly build new classifiers starting from a single example and monitor species for which there is scarce training data or for very specific sounds like juvenile calls. Given one example of a sound, vector search with Perch surfaces the most similar sounds in a dataset. A local expert can then mark the search results as relevant or irrelevant to train a classifier.&lt;/p&gt;&lt;p&gt;Together, this combination of vector search and active learning with a strong embedding model is called agile modeling&lt;strong&gt;&lt;i&gt;.&lt;/i&gt;&lt;/strong&gt; Our recent paper–"The Search for Squawk: Agile Modeling in Bioacoustics"–shows that this method works across birds and coral reefs, allowing the creation of high quality classifiers in under an hour.&lt;/p&gt;&lt;h2&gt;Looking ahead: the future of bioacoustics&lt;/h2&gt;&lt;p&gt;Together, our models and methods are helping maximize the impact of conservation efforts, leaving more time and resources for meaningful, on-the-ground work. From the forests of Hawaiʻi to the reefs of the ocean, the Perch project showcases the profound impact we can have when we apply our technical expertise to the world's most pressing challenges. Every classifier built and every hour of data analyzed brings us closer to a world where the soundtrack of our planet is one of rich, thriving biodiversity.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  

&lt;section class="button-group button-group--stacked"&gt;
  
    &lt;h2 class="glue-headline glue-headline--headline-6 button-group__title"&gt;Learn more&lt;/h2&gt;
  

  
&lt;/section&gt;
                
              
                
                
                  
                  &lt;section class="notes"&gt;
  &lt;div class="glue-page"&gt;
    &lt;div class="gdm-rich-text notes__inner"&gt;
      &lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This research was developed by the Perch team: Bart van Merriënboer, Jenny Hamer, Vincent Dumoulin, Lauren Harrell, and Tom Denton, and Otilia Stretcu from Google Research. We also thank our collaborators Amanda Navine and Pat Hart at the University of Hawaiʻi, and Holger Klinck, Stefan Kahl and the BirdNet team at the Cornell Lab of Ornithology. And all our friends and collaborators whom we would have written about in this blog post if only we had another thousand words.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;</description><content:encoded>&lt;div class="article-cover article-cover--centered"&gt;
    &lt;div class="article-cover__header"&gt;
      &lt;p class="article-cover__eyebrow glue-label"&gt;Science&lt;/p&gt;
      

      
    &lt;dl class="article-cover__meta"&gt;
      
        &lt;dt class="glue-visually-hidden"&gt;Published&lt;/dt&gt;
        &lt;dd class="article-cover__date glue-label"&gt;&lt;time datetime="2025-08-07"&gt;7 August 2025&lt;/time&gt;&lt;/dd&gt;
      
      
        &lt;dt class="glue-visually-hidden"&gt;Authors&lt;/dt&gt;
        &lt;dd class="article-cover__authors"&gt;&lt;p&gt;The Perch Team&lt;/p&gt;&lt;/dd&gt;
      
    &lt;/dl&gt;
  

      
    &lt;/div&gt;

    
      
    
    
    
      &lt;source height="603" media="(min-width: 1024px)" type="image/webp" width="1072" /&gt;&lt;source height="522" media="(min-width: 600px)" type="image/webp" width="928" /&gt;&lt;source height="297" type="image/webp" width="528" /&gt;
      &lt;img alt="Two Hawaiian honeycreepers on a branch. These honeycreepers are small birds endemic to Hawai'i with red bodies and black wings." class="picture__image" height="603" src="https://lh3.googleusercontent.com/JYIFJcnN8vY29QEb-1MAbLKzOWCU4TIAbJrLHxmw5kBX6fIRHJhZjSgDcdfEWG9JZHOb43ojZ2zH1u_r1TjKnnRv1V0gr8wm0qmu4THC6clm0zvEYoA=w1072-h603-n-nu" width="1072" /&gt;
    
    
  
    
  &lt;/div&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p class="gdm-rich-text__subtitle"&gt;Our new Perch model helps conservationists analyze audio faster to protect endangered species, from Hawaiian honeycreepers to coral reefs.&lt;/p&gt;&lt;p&gt;One of the ways scientists protect the health of our planet’s wild ecosystems is by using microphones (or underwater hydrophones) to collect vast amounts of audio dense with vocalizations from birds, frogs, insects, whales, fish and more. These recordings can tell us a lot about the animals present in a given area, along with other clues about the health of that ecosystem. Making sense of so much data, however, remains a massive undertaking.&lt;/p&gt;&lt;p&gt;Today, we are releasing an update to Perch, our AI model designed to help conservationists analyze bioacoustic data. This new model has better state-of-the-art off-the-shelf bird species predictions than the previous model. It can better adapt to new environments, particularly underwater ones like coral reefs. It’s trained on a wider range of animals, including mammals, amphibians and anthropogenic noise — nearly twice as much data in all, from public sources like Xeno-Canto and iNaturalist. It can disentangle complex acoustic scenes over thousands or even millions of hours of audio data. And it’s versatile, able to answer many different kinds of questions, from “how many babies are being born” to “how many individual animals are present in a given area.”&lt;/p&gt;&lt;p&gt;In order to help scientists protect our planet’s ecosystems, we’re open sourcing this new version of Perch and making it available on Kaggle.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-26cd95fe-71a7-4e6c-ae3c-8844bf189859"&gt;
    &lt;p&gt;Perch not only recognizes the sound of bird species. Our new model was trained on a wider range of animals including mammals, amphibians and anthropogenic noise.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Success Stories: Perch in the Field&lt;/h2&gt;&lt;p&gt;Since it was first launched in 2023, the initial version of Perch has already been downloaded over 250,000 times and its open-source solutions are now well-integrated into tools for working biologists. For example, Perch’s vector search library is now part of Cornell's widely-used BirdNet Analyzer.&lt;/p&gt;&lt;p&gt;In addition, Perch is helping BirdLife Australia and the Australian Acoustic Observatory build classifiers for a number of unique Australian species. For example, our tools enabled the discovery of a new population of the elusive Plains Wanderer.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  &lt;figure class="quote quote--inline"&gt;
  &lt;blockquote class="quote__text"&gt;
    &lt;p&gt;“&lt;/p&gt;
    &lt;p&gt;“This is an incredible discovery – acoustic monitoring like this will help shape the future of many endangered bird species.”&lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;figcaption class="quote__author"&gt;&lt;p&gt;Paul Roe, Dean Research, James Cook University, Australia&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;Recent work has also found that the earlier version of Perch can be used to identify individual birds and track bird abundance, potentially reducing the need for catch-and-release studies to monitor populations.&lt;/p&gt;&lt;p&gt;Finally, biologists from the LOHE Bioacoustics Lab at the University of Hawaiʻi have used it to monitor and protect populations of honeycreepers, which are important to Hawaiian mythology and face extinction from the threat of avian malaria spread by non-native mosquitoes. Perch helped the LOHE Lab find honeycreeper sounds nearly 50x faster than their usual methods, enabling them to monitor more species of honeycreeper over greater areas. We expect the new model will further accelerate these efforts.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--large"&gt;
  

  
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Untangling the Planet's Playlist&lt;/h2&gt;&lt;p&gt;The Perch model can predict which species are present in a recording, but that's only part of the story: We also provide open-source tools that allow scientists to quickly build new classifiers starting from a single example and monitor species for which there is scarce training data or for very specific sounds like juvenile calls. Given one example of a sound, vector search with Perch surfaces the most similar sounds in a dataset. A local expert can then mark the search results as relevant or irrelevant to train a classifier.&lt;/p&gt;&lt;p&gt;Together, this combination of vector search and active learning with a strong embedding model is called agile modeling&lt;strong&gt;&lt;i&gt;.&lt;/i&gt;&lt;/strong&gt; Our recent paper–"The Search for Squawk: Agile Modeling in Bioacoustics"–shows that this method works across birds and coral reefs, allowing the creation of high quality classifiers in under an hour.&lt;/p&gt;&lt;h2&gt;Looking ahead: the future of bioacoustics&lt;/h2&gt;&lt;p&gt;Together, our models and methods are helping maximize the impact of conservation efforts, leaving more time and resources for meaningful, on-the-ground work. From the forests of Hawaiʻi to the reefs of the ocean, the Perch project showcases the profound impact we can have when we apply our technical expertise to the world's most pressing challenges. Every classifier built and every hour of data analyzed brings us closer to a world where the soundtrack of our planet is one of rich, thriving biodiversity.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  

&lt;section class="button-group button-group--stacked"&gt;
  
    &lt;h2 class="glue-headline glue-headline--headline-6 button-group__title"&gt;Learn more&lt;/h2&gt;
  

  
&lt;/section&gt;
                
              
                
                
                  
                  &lt;section class="notes"&gt;
  &lt;div class="glue-page"&gt;
    &lt;div class="gdm-rich-text notes__inner"&gt;
      &lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This research was developed by the Perch team: Bart van Merriënboer, Jenny Hamer, Vincent Dumoulin, Lauren Harrell, and Tom Denton, and Otilia Stretcu from Google Research. We also thank our collaborators Amanda Navine and Pat Hart at the University of Hawaiʻi, and Holger Klinck, Stefan Kahl and the BirdNet team at the Cornell Lab of Ornithology. And all our friends and collaborators whom we would have written about in this blog post if only we had another thousand words.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/how-ai-is-helping-advance-the-science-of-bioacoustics-to-save-endangered-species/</guid><pubDate>Thu, 07 Aug 2025 14:59:16 +0000</pubDate></item><item><title>[NEW] Alan Turing Institute: Humanities are key to the future of AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/alan-turing-institute-humanities-are-key-future-of-ai/</link><description>&lt;p&gt;A powerhouse team has launched a new initiative called ‘Doing AI Differently,’ which calls for a human-centred approach to future development.&lt;/p&gt;&lt;p&gt;For years, we’ve treated AI’s outputs like they’re the results of a giant math problem. But the researchers – from The Alan Turing Institute, the University of Edinburgh, AHRC-UKRI, and the Lloyd’s Register Foundation – behind this project say that’s the wrong way to look at it.&lt;/p&gt;&lt;p&gt;What AI is creating are basically cultural artifacts. They’re more like a novel or a painting than a spreadsheet. The problem is, AI is creating this “culture” without understanding any of it. It’s like someone who has memorised a dictionary but has no idea how to hold a real conversation.&lt;/p&gt;&lt;p&gt;This is why AI often fails when “nuance and context matter most,” says Professor Drew Hemment, Theme Lead for Interpretive Technologies for Sustainability at The Alan Turing Institute. The system just doesn’t have the “interpretive depth” to get what it’s really saying.&lt;/p&gt;&lt;p&gt;However, most of the AI in the world is built on just a handful of similar designs. The report calls this the “homogenisation problem” and future AI development must overcome this.&lt;/p&gt;&lt;p&gt;Imagine if every baker in the world used the exact same recipe. You’d get a lot of identical, and frankly, boring cakes. With AI, this means the same blind spots, the same biases, and the same limitations get copied and pasted into thousands of tools we use every day.&lt;/p&gt;&lt;p&gt;We saw this happen with social media. It was rolled out with simple goals, and we’re now living with the unintended societal consequences. The ‘Doing AI Differently’ team is sounding the alarm to make sure we don’t make that same mistake with AI.&lt;/p&gt;&lt;p&gt;The team has a plan to build a new kind of AI, one they call Interpretive AI. It’s about designing systems from the very beginning to work the way people do; with ambiguity, multiple viewpoints, and a deep understanding of context.&lt;/p&gt;&lt;p&gt;The vision is to create interpretive technologies that can offer multiple valid perspectives instead of just one rigid answer. It also means exploring alternative AI architectures to break the mould of current designs. Most importantly, the future isn’t about AI replacing us; it’s about creating human-AI ensembles where we work together, combining our creativity with AI’s processing power to solve huge challenges.&lt;/p&gt;&lt;p&gt;This has the potential to touch our lives in very real ways. In healthcare, for example, your experience with a doctor is a story, not just a list of symptoms. An interpretive AI could help capture that full story, improving your care and your trust in the system.&lt;/p&gt;&lt;p&gt;For climate action, it could help bridge the gap between global climate data and the unique cultural and political realities of a local community, creating solutions that actually work on the ground.&lt;/p&gt;&lt;p&gt;A new international funding call is launching to bring researchers from the UK and Canada together on this mission. But we’re at a crossroads.&lt;/p&gt;&lt;p&gt;“We’re at a pivotal moment for AI,” warns Professor Hemment. “We have a narrowing window to build in interpretive capabilities from the ground up”.&lt;/p&gt;&lt;p&gt;For partners like Lloyd’s Register Foundation, it all comes down to one thing: safety.&lt;/p&gt;&lt;p&gt;“As a global safety charity, our priority is to ensure future AI systems, whatever shape they take, are deployed in a safe and reliable manner,” says their Director of Technologies, Jan Przydatek.&lt;/p&gt;&lt;p&gt;This isn’t just about building better technology. It’s about creating an AI that can help solve our biggest challenges and, in the process, amplify the best parts of our own humanity.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Ben Sweet)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI obsession is costing us our human skills&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A powerhouse team has launched a new initiative called ‘Doing AI Differently,’ which calls for a human-centred approach to future development.&lt;/p&gt;&lt;p&gt;For years, we’ve treated AI’s outputs like they’re the results of a giant math problem. But the researchers – from The Alan Turing Institute, the University of Edinburgh, AHRC-UKRI, and the Lloyd’s Register Foundation – behind this project say that’s the wrong way to look at it.&lt;/p&gt;&lt;p&gt;What AI is creating are basically cultural artifacts. They’re more like a novel or a painting than a spreadsheet. The problem is, AI is creating this “culture” without understanding any of it. It’s like someone who has memorised a dictionary but has no idea how to hold a real conversation.&lt;/p&gt;&lt;p&gt;This is why AI often fails when “nuance and context matter most,” says Professor Drew Hemment, Theme Lead for Interpretive Technologies for Sustainability at The Alan Turing Institute. The system just doesn’t have the “interpretive depth” to get what it’s really saying.&lt;/p&gt;&lt;p&gt;However, most of the AI in the world is built on just a handful of similar designs. The report calls this the “homogenisation problem” and future AI development must overcome this.&lt;/p&gt;&lt;p&gt;Imagine if every baker in the world used the exact same recipe. You’d get a lot of identical, and frankly, boring cakes. With AI, this means the same blind spots, the same biases, and the same limitations get copied and pasted into thousands of tools we use every day.&lt;/p&gt;&lt;p&gt;We saw this happen with social media. It was rolled out with simple goals, and we’re now living with the unintended societal consequences. The ‘Doing AI Differently’ team is sounding the alarm to make sure we don’t make that same mistake with AI.&lt;/p&gt;&lt;p&gt;The team has a plan to build a new kind of AI, one they call Interpretive AI. It’s about designing systems from the very beginning to work the way people do; with ambiguity, multiple viewpoints, and a deep understanding of context.&lt;/p&gt;&lt;p&gt;The vision is to create interpretive technologies that can offer multiple valid perspectives instead of just one rigid answer. It also means exploring alternative AI architectures to break the mould of current designs. Most importantly, the future isn’t about AI replacing us; it’s about creating human-AI ensembles where we work together, combining our creativity with AI’s processing power to solve huge challenges.&lt;/p&gt;&lt;p&gt;This has the potential to touch our lives in very real ways. In healthcare, for example, your experience with a doctor is a story, not just a list of symptoms. An interpretive AI could help capture that full story, improving your care and your trust in the system.&lt;/p&gt;&lt;p&gt;For climate action, it could help bridge the gap between global climate data and the unique cultural and political realities of a local community, creating solutions that actually work on the ground.&lt;/p&gt;&lt;p&gt;A new international funding call is launching to bring researchers from the UK and Canada together on this mission. But we’re at a crossroads.&lt;/p&gt;&lt;p&gt;“We’re at a pivotal moment for AI,” warns Professor Hemment. “We have a narrowing window to build in interpretive capabilities from the ground up”.&lt;/p&gt;&lt;p&gt;For partners like Lloyd’s Register Foundation, it all comes down to one thing: safety.&lt;/p&gt;&lt;p&gt;“As a global safety charity, our priority is to ensure future AI systems, whatever shape they take, are deployed in a safe and reliable manner,” says their Director of Technologies, Jan Przydatek.&lt;/p&gt;&lt;p&gt;This isn’t just about building better technology. It’s about creating an AI that can help solve our biggest challenges and, in the process, amplify the best parts of our own humanity.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Ben Sweet)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI obsession is costing us our human skills&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/alan-turing-institute-humanities-are-key-future-of-ai/</guid><pubDate>Thu, 07 Aug 2025 15:18:27 +0000</pubDate></item><item><title>[NEW] The backlash against Duolingo going ‘AI-first’ didn’t even matter (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/the-backlash-against-duolingo-going-ai-first-didnt-even-matter/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/duolingo-owl.png?w=900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Duolingo announced on Wednesday that it beat its quarterly revenue estimates, even though the company faced widespread backlash for choosing to embrace generative AI over human workers. Duolingo stock rose almost 30% on the news.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In April, CEO Luis von Ahn shared that Duolingo would become an “AI-first” company, phasing out its use of contract workers. He also discouraged teams from hiring more employees, unless the team is unable to automate more of its work. With the use of generative AI, Duolingo introduced 148 new language courses, more than doubling its previous offerings.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Without AI, it would take us decades to scale our content to more learners,” von Ahn wrote at the time. “We owe it to our learners to get them this content ASAP.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While some Duolingo users have argued that these AI features are making the app worse, the company’s financial metrics tell a different story. Now the company anticipates making over $1 billion in revenue this year, and daily active users have grown 40% year-over-year. The growth is significant but falls in the lower range of the company’s estimates of growing between 40% and 45%, which an investor brought up to von Ahn on Wednesday’s quarterly earnings call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason we came [in] towards the lower end was because I said some stuff about AI, and I didn’t give enough context. Because of that, we got some backlash on social media,” von Ahn said. “The most important thing is we wanted to make the sentiment on our social media positive. We stopped posting edgy posts and started posting things that would get our sentiment more positive. That has worked.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On TikTok, the top comments on Duolingo’s videos often remain criticisms of the company’s AI approach. Snarky commenters will ask if videos with multiple people in them are made with AI, to which Duolingo will reply, “Nope. Made by our great team!” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But even if public sentiment toward Duolingo has shifted, its bottom line has not&amp;nbsp;… and from the company’s perspective, that’s what matters.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/duolingo-owl.png?w=900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Duolingo announced on Wednesday that it beat its quarterly revenue estimates, even though the company faced widespread backlash for choosing to embrace generative AI over human workers. Duolingo stock rose almost 30% on the news.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In April, CEO Luis von Ahn shared that Duolingo would become an “AI-first” company, phasing out its use of contract workers. He also discouraged teams from hiring more employees, unless the team is unable to automate more of its work. With the use of generative AI, Duolingo introduced 148 new language courses, more than doubling its previous offerings.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Without AI, it would take us decades to scale our content to more learners,” von Ahn wrote at the time. “We owe it to our learners to get them this content ASAP.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While some Duolingo users have argued that these AI features are making the app worse, the company’s financial metrics tell a different story. Now the company anticipates making over $1 billion in revenue this year, and daily active users have grown 40% year-over-year. The growth is significant but falls in the lower range of the company’s estimates of growing between 40% and 45%, which an investor brought up to von Ahn on Wednesday’s quarterly earnings call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason we came [in] towards the lower end was because I said some stuff about AI, and I didn’t give enough context. Because of that, we got some backlash on social media,” von Ahn said. “The most important thing is we wanted to make the sentiment on our social media positive. We stopped posting edgy posts and started posting things that would get our sentiment more positive. That has worked.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On TikTok, the top comments on Duolingo’s videos often remain criticisms of the company’s AI approach. Snarky commenters will ask if videos with multiple people in them are made with AI, to which Duolingo will reply, “Nope. Made by our great team!” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But even if public sentiment toward Duolingo has shifted, its bottom line has not&amp;nbsp;… and from the company’s perspective, that’s what matters.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/the-backlash-against-duolingo-going-ai-first-didnt-even-matter/</guid><pubDate>Thu, 07 Aug 2025 15:32:05 +0000</pubDate></item><item><title>[NEW] AI agents aren’t the ‘new Google,’ says Airbnb CEO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/ai-agents-arent-the-new-google-says-airbnb-ceo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/brian-chesky-GettyImages-2217178973.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After a second-quarter earnings beat, Airbnb CEO Brian Chesky shared his thoughts on the company’s AI strategy, cautioning investors that AI chatbots can’t yet be thought of as the “new Google.” That is, AI chatbots, while potentially driving new leads to the travel and services business, aren’t entirely a replacement for the referrals that the dominant search engine brings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At least not at this time. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think we’re still kind of feeling out the space,” the exec told investors on the Q2 earnings call. “The thing I want to caution is I don’t think that AI agents — I don’t think we should think of chatbots like Google — I don’t think we should think of them as the ‘new Google’ yet.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This, Chesky explained, is because AI models aren’t “proprietary.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We also have to remember that the model powering ChatGPT is not proprietary. It’s not exclusive to ChatGPT. We — Airbnb — can also use the API, and there are other models that we can use,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Painting a broader picture of the AI landscape, Chesky said that in addition to chatbots and other AI agents, there will be custom-built startups designed for specific applications, as well as other incumbents that have made the shift to AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the things we’ve noticed is it’s not enough to just have&amp;nbsp;… the best model. You have to be able to tune the model and build a custom interface for the right application. And I think that’s the key,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company told investors it will look to take advantage of AI in a number of ways. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb shared during the call that its AI customer service agent in the U.S. reduced the percentage of guests contacting a human agent by 15%, for instance. This was actually harder than tackling the lower-hanging fruit involving travel planning and inspiration, Chesky said, because AI agents performing customer service can’t hallucinate. They have to be accurate and helpful at all times.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb’s customer service agent was built using 13 different models and trained on tens of thousands of conversations, and is currently available in English in the U.S. This year, Airbnb will roll it out to more languages, and next year, it will become more personalized and agentic. That means it would be able to understand if someone reaches out to cancel a reservation; not only would it be able to tell them how to do so, but it could also do it for them. The agent could also help plan and book trips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, AI will come to Airbnb’s search next year, the CEO said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the company has not fully fleshed out its plans for working with third-party AI agents, although it’s considering it. Users still need an Airbnb account to make a booking.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because of this, Chesky doesn’t think agentic AI would turn its business into a commodity, the way that booking flights has become. Instead, he sees AI as “potentially interesting lead generation” for the company. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think the key thing is going to be for us to lead and become the first place for people to book travel on Airbnb. As far as whether or not we integrate with AI agents, I think that’s something that we’re certainly open to,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb beat analysts’ expectations in the quarter with revenue of $3.1 billion and earnings per share of $1.03, but the stock dropped on its forecast of slower growth in the second half of the year.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/brian-chesky-GettyImages-2217178973.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After a second-quarter earnings beat, Airbnb CEO Brian Chesky shared his thoughts on the company’s AI strategy, cautioning investors that AI chatbots can’t yet be thought of as the “new Google.” That is, AI chatbots, while potentially driving new leads to the travel and services business, aren’t entirely a replacement for the referrals that the dominant search engine brings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At least not at this time. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think we’re still kind of feeling out the space,” the exec told investors on the Q2 earnings call. “The thing I want to caution is I don’t think that AI agents — I don’t think we should think of chatbots like Google — I don’t think we should think of them as the ‘new Google’ yet.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This, Chesky explained, is because AI models aren’t “proprietary.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We also have to remember that the model powering ChatGPT is not proprietary. It’s not exclusive to ChatGPT. We — Airbnb — can also use the API, and there are other models that we can use,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Painting a broader picture of the AI landscape, Chesky said that in addition to chatbots and other AI agents, there will be custom-built startups designed for specific applications, as well as other incumbents that have made the shift to AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the things we’ve noticed is it’s not enough to just have&amp;nbsp;… the best model. You have to be able to tune the model and build a custom interface for the right application. And I think that’s the key,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company told investors it will look to take advantage of AI in a number of ways. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb shared during the call that its AI customer service agent in the U.S. reduced the percentage of guests contacting a human agent by 15%, for instance. This was actually harder than tackling the lower-hanging fruit involving travel planning and inspiration, Chesky said, because AI agents performing customer service can’t hallucinate. They have to be accurate and helpful at all times.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb’s customer service agent was built using 13 different models and trained on tens of thousands of conversations, and is currently available in English in the U.S. This year, Airbnb will roll it out to more languages, and next year, it will become more personalized and agentic. That means it would be able to understand if someone reaches out to cancel a reservation; not only would it be able to tell them how to do so, but it could also do it for them. The agent could also help plan and book trips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, AI will come to Airbnb’s search next year, the CEO said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the company has not fully fleshed out its plans for working with third-party AI agents, although it’s considering it. Users still need an Airbnb account to make a booking.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Because of this, Chesky doesn’t think agentic AI would turn its business into a commodity, the way that booking flights has become. Instead, he sees AI as “potentially interesting lead generation” for the company. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think the key thing is going to be for us to lead and become the first place for people to book travel on Airbnb. As far as whether or not we integrate with AI agents, I think that’s something that we’re certainly open to,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Airbnb beat analysts’ expectations in the quarter with revenue of $3.1 billion and earnings per share of $1.03, but the stock dropped on its forecast of slower growth in the second half of the year.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/ai-agents-arent-the-new-google-says-airbnb-ceo/</guid><pubDate>Thu, 07 Aug 2025 15:37:35 +0000</pubDate></item><item><title>[NEW] Reimagining healthcare delivery and public health with AI (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/reimagining-healthcare-delivery-and-public-health-with-ai/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated headshots of Peter Lee, Umair Shah, Gianrico Farrugia" class="wp-image-1147485" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this episode, healthcare leaders Dr. Umair Shah&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Dr. Gianrico Farrugia&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; join Lee to discuss AI’s impact on the business of public health and healthcare delivery, the healthcare-research connection, and the patient experience. Shah, a healthcare strategic consultant and former state secretary of health, explores the role of public health in the larger ecosystem and why it might not get the attention it needs or deserves and how AI could be leveraged to assist in data analysis, to help better engage with people on matters of public health, and to help narrow gaps between care delivery and public health responses during health emergencies. Farrugia, president and CEO of Mayo Clinic, traces AI’s path from predictive to generative and discusses how that progress has helped usher in a new healthcare architecture for Mayo Clinic and its partners, one powered by the goal of longer, healthier lives for patients, and how AI is also changing Mayo Clinic’s research and the education it provides, including the offering of masters and PhDs in AI and other emerging technologies.&amp;nbsp;&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;








&lt;/div&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;[MUSIC] &lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE:&lt;/strong&gt; “In US healthcare, quality ratings are increasingly used to tie the improvement in patient health outcomes to the reimbursement rates that healthcare providers can receive. The ability of GPT-4 to understand these systems and give concrete advice … has a chance to make it easier for providers to achieve success in both dimensions.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee. &lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong? &lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;[THEME MUSIC FADES]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The book passage I read at the top is from Chapter 7, “The Ultimate Paperwork Shredder.” &lt;/p&gt;



&lt;p&gt;Public health officials and healthcare system leaders influence the well-being and health of people at the population level. They help shape people’s perceptions and responses to public health emergencies, as well as to chronic disease. They help determine the type, quality, and availability of treatment. All this is critical for maintaining good public health, as well as aligning better health and financial outcomes. That, of course, is the main goal of the concept of value-based care. AI can definitely have significant ramifications for achieving this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Joining us today to talk about how leaders in public health and healthcare systems are thinking about and acting on this new generation of AI is Dr. Umair Shah and Dr. Gianrico Farrugia.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Dr. Umair Shah is a nationally recognized health leader and innovator. He led one of America’s top-rated pandemic responses as Washington State’s secretary of health, a position he held from 2020 to 2025. Umair previously directed Harris County Public Health in Texas, overseeing large-scale emergency response for the nation’s third-largest county, while building an emergency-care career spanning 20-plus years. He now advises organizations on health innovation and strategy as founder and principal of Rickshaw Health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Dr. Gianrico Farrugia is the president and CEO of Mayo Clinic, the world’s top-ranked hospital for seven consecutive years, and a pioneer in technology-forward, platform-based healthcare. Under his leadership, Mayo has built and deployed the Mayo Clinic Platform. The platform enables Mayo and its partners to gain practical insights from a comprehensive repository of longitudinal de-identified clinical data spanning four continents. Gianrico is also a Mayo Clinic physician and professor and an author.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Umair and Gianrico are CEO-level leaders representing some of the best of the worlds of public health, healthcare delivery, medical research, and medical education.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Here is my interview with Dr. Umair Shah:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Umair, it’s really great to have you here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;UMAIR SHAH:&lt;/strong&gt; Peter, it’s my pleasure. I’ve been looking forward to this conversation, and I hope you are well today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] I am doing extremely well.&lt;/p&gt;



&lt;p&gt;So, you know, what I’d like to do in these conversations is first just to start, a little bit about you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You served actually during a really tumultuous time as the secretary of health in the State of Washington. But you recently stepped away from that and you started your own firm, Rickshaw Health. So can we start there? What’s that all about?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, no, absolutely. First of all, you know, I would say that the transition from Texas to Washington could not have been more geopolitically different, [LAUGHTER] as you can imagine.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, if you like the red-blue paradigms, you couldn’t be more, you know, red and you couldn’t be more blue, I think.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; But what happened is, back in November this past year, as I saw some of the playout of continuation of this red-blue dynamic, I made the decision to step down. And Jan. 15, I stepped down, as you mentioned, and I spent some time really thinking about what I wanted to do next and was looking at a number of opportunities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then a moment in time, there were some things happening in our—my wife and our family’s personal lives that sort of made me think that I wanted to focus a little bit more on family. And I felt the universe was saying, “Stay still.” [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I launched Rickshaw Health&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and the notion that, as you know, Peter, rickshaws are oftentimes known across the globe as these modes of transport that reliably get you through ever-changing streets and traffic patterns and all sorts of ecosystems that are evolving at all times. And they get you to the other side and they get you also with a sense of exhilaration. Like when I took my boys to Karachi, and we were—you know, they jumped in a rickshaw and the, you know, open air [LAUGHTER] and they felt this incredible excitement.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so Rickshaw Health was speaking to the three wheels of a rickshaw that symbolize the three children that we have and the real notion of how do we bring balance and agility and performance to the forefront and then move in an ever—just like streets—ever-changing healthcare environment that is constantly evolving, and we too must evolve with it. And that’s what Rickshaw Health is all about, is taking clients to that next level of trying to navigate, especially at this time, a very, very different landscape than even several months ago. So, excited about it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, absolutely. You know, you made this transition from Texas to the State of Washington. And for people who listen to this podcast and don’t know, the particular part of Texas where you were—Harris County—is &lt;em&gt;really big&lt;/em&gt;, very, very important in that state. That’s just not, you know, the normal county in Texas.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;It’s actually … it’s actually known as quite a forward-looking place, technologically.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So what was, you know, the transition like, then, going from, you know, possibly the most, sort of, maybe advanced county in the State of Texas, a large place, to the State of Washington?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, you know, Harris County is the third-largest county in the US. So it had close to five million. And now it’s probably … it’s exceeded the five million people, and a very diverse, very forward-looking, as you mentioned, technologically very, very much looking at what’s the next horizon, and home to Texas Medical Center [TMC] as well, which is …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… the largest medical center. Of course, it had to be Texas. So it can’t be the largest in the state or the country [LAUGHTER]—the largest in the world, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And TMC also had a number of different initiatives related to startups and venture capital and VC. And so they had launched something called TMCX. And that was a real opportunity—and I know you’re familiar with it—an opportunity to really look at how do you incubate all sorts of different innovations and bringing private sector, public sector as well as healthcare delivery alongside these startups to really look at the landscape.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when I left Houston and came to Washington, I realized that obviously, I was in the backyard … I mean, you know, you all at Microsoft Research and the work that you’re all doing is part of an ecosystem of advanced innovation that’s occurring in the Pacific Northwest that, you know, when we see all the players that are here, all the, you know, ones that do so many different things, but they’re doing them with an eye towards technology, advancements, and adoptions, it’s been quite amazing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;When I made that transition, it was really about, you know, the vaccines and what was happening with, you know, with COVID and fighting the—you know, remember, this was the state that had the first case in the continental United States, had the first outbreak, and the first [lab-confirmed] death. And fast-forward a few years later, we had the fifth-lowest death rate in the US. And that was because we all came together to do so much.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, well maybe that gets us into a question that I ask a lot of our guests, which is, you know, and maybe let’s, since we’re on your time as the secretary of health in Washington State, [start] with that job. I ask, how would you explain to your mother what you do every day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; [LAUGHS] I laugh because that’s been such a fascinating conversation in public health because we have oftentimes been—it’s been really hard to describe what that is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And, you know, there are so many metaphors and, you know, analogies that we’ve used. I’ve always wondered why we do not have more television shows or sitcoms or dramas that are about the public health workforce or the work that we do in the field, because you have, you know, all sorts of healthcare delivery ones, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; As a practicing physician for 20 years, I realized that people knew what doctors did; they knew what nurses did, right. They intimately touch the healthcare system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; They understood, you know, that an ambulance picks you up at your home or somewhere else, transports you … gets you to the emergency department. The emergency department, they do some things to you or within the four walls of that ER, and then you’re either admitted, sent home, and several days, weeks, whatever later, you get home if you’re admitted, and you start your, you know, post-hospital stay at home or your rehab or what have you. And that all is known to people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But when you ask your mother, your grandmother, or your, you know, your uncle, or your brother, your neighbor, your coworker about what is public health, they have a very quizzical look on their face of what that is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And so what I’ve …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, just one thing I’ve learned is: it’s not just all the people you mentioned. Even healthcare professionals sometimes have that quizzical look.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, good point. That’s right. Good point. And a lot of it is because we don’t get exposed to it or trained in it. You know, we think about public health when we’re in our training. And, you know, I’m sure you had a very similar piece of this is that, you know, you see it as, oh, that’s the health department that takes care of, you know, STDs, or it takes care, you know, it does the immunizations, or, you know, maybe they do some water quality, or maybe they do mosquitoes [mosquito control], and things like that. But the reality is, we do &lt;em&gt;all&lt;/em&gt; of those things and more.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So my metaphor has been that we are the offensive line of a football team, and the healthcare delivery is the quarterback. So everybody focuses on, you know, from a few years back, everybody knows Tom Brady, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; He won the Super Bowls, everybody knows what … but if you asked people who was number 75 on the offensive line of the New England Patriots …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or name your favorite football team. And the answer would be: you would not be able to likely answer that question. You would know Tom Brady, the quarterback, and that’s healthcare delivery, the ER doc or the hospitalist or the nurse or the, you know, the medical assistant, or the people that are doing all the work in the field that are the ones that are more visible, but the invisible workforce of the offensive line, that’s who we don’t know. And yet these are the people that are blocking and sweating and doing all things to complement the work and make sure the quarterback is successful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And here’s where the metaphor breaks down, that when Tom Brady wins the Super Bowl, we continue to invest in the offensive line because we recognize the value of it and we want the quarterback to be successful the next season. But in public health or in society, we do the exact opposite.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;When tuberculosis rates come down, we say, well, you know what? We’ve solved the problem; we don’t need it anymore.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Or you have another, you know, environmental issue that’s no longer there, you say, “We don’t need it anymore.” And we &lt;em&gt;disinvest&lt;/em&gt; from public health or that offensive line. And then you start to see those rates go back up.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so my answer to Mom and Grandma and Dad and Grandpa is we are &lt;em&gt;critical&lt;/em&gt; to your health because we touch you every single day. And so please invest in us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. And, you know, I think I’m going to want to get a little deeper on that in just a few minutes here, because, I think especially during the pandemic, that issue of not understanding the importance of that offensive lineman actually really came to the forefront.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I’d like to get into that. But the, kind of, second, kind of, standard thing I’ve been probing with people is still just focusing on you and your background is what touchpoints or experiences you’ve had with AI in the past.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And not everyone has. Like, it maybe isn’t too surprising that doctors and healthcare developers, tech developers, have lots of contact with AI, but would the top dog, you know, at a public health agency ever have had significant contact with AI? What about you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, it’s interesting. Several years ago, I was in the audience with the [then] FEMA director, [Rich Serino], who just did such an incredible job. And I remember he made this comment at that time. And, Peter, this may have been like … I don’t know—I’m dating myself—10, 15, maybe even 20 years ago, and he said, “Everybody in the audience, there’s this, you know, app called Twitter.” And, you know, “How many people in the audience have ever sent a tweet or know about this?” And I don’t know, maybe—it was a public health audience—maybe about 15% of the people raised their hands.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;He said, “I challenge you to right now, pick up your phone, download the app, and go ahead and send a tweet right now.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember I sent my first tweet at that time. And it was so thought provoking for me was that he was saying you need to be engaged in social media, but the other 85% of the audience had not even done that or had …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … even understood the importance of social media at that time. Or maybe they understood, but they had restrictions on how to utilize, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So that has stayed with me because that’s very much about this revolution of AI that I know that public health and population health practitioners like myself who have been in the trenches and understand the importance of it, they really believe in the importance or think they know the importance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But NACCHO, the National Association of County and City Health Officials, had done a survey of local health agencies. And about two-thirds, if not three-quarters, of local health agencies reported that they had an AI capacity that was low or lower than ideal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And that is very much where I come from. When I was in public sector and at the state health agency, our transformation was very much about how do we advance the work, and how do we utilize this in a population health standpoint?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I was fortunate to have a chief of innovation at Washington State Department of Health, Les Becker, who understood the value of AI. And as you know, we did also hold a AI science convening that …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … your team was there with University of Washington. And that was really an opportunity for us to say that AI is here. It’s not tomorrow. It’s not next year. It’s not the future. It’s already here. We need to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But here’s the problem, Peter, far too few people in our field understand just how to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; So I have become a markedly more champion of AI. One, since I read your book. So I think there’s that. So thank you for writing it. But two, since I really recognize that when I became a solo or a primary-few practitioner in my own realm, I needed to force-amplify the work that I was doing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And when I look back, and I continue to stay in touch with my colleagues in the field of public health, what they’re also struggling with is that you have an epidemiologist who’s got a mound of information—data, statistics, etc.—that they are going through, and they’re doing everything in their power to get that processed and analyzed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; AI can take 80% of that and do it. And that epidemiologist can now turn to more of an overseer and a gatekeeper and to really recognize the patterns …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … and let AI be able to do the, you know, grunt work. And similarly, as you know, measles—with the outbreaks that we’ve seen, especially in Texas but elsewhere—you’ve got an opportunity where our communications people who are saying, “Look, we’re about to have, or we know we’re about to announce that there’s a measles outbreak in, you know, in our community or our state or what have you—our region.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And they can have AI go through different press briefings and/or press releases and say, “Give me the state of the art on how I should communicate this message to the community.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And bam! You can do that. And now you can oversee that work, as well. And then the third example is that we are always looking at how do we find ways to have a deeper connection with those who come to our, you know, our websites or come to our engagement tools—with bots and things like that. AI can really accelerate that work, as well. So there’s so many use cases that AI has for population health or public health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; But I think the challenge is that we just don’t have enough adoption because they’re … one, we’ve had funding cuts, but two is that there is this real hesitation on, what is it that we can do? And I argue—the last thing I’ll say about this, Peter—is that I argue that AI is happening right now. The discussions, the technology advancements, the work, the policy work, all that’s happening right now. If public health practitioners are not at the table, if they’re not part of the, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … “What does this look like? How does it work in our field?” … guess what? It’s going to be done &lt;em&gt;to&lt;/em&gt; us and &lt;em&gt;for&lt;/em&gt; us rather than with us. And if we do not get with that and get to the table, then unfortunately it may not be exactly what we want it to be at the end of the day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I find it really interesting that you are using the terms “public health” and “population health” …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… pretty much interchangeably here. And I think that that’s something that I think touches on an assumption that was both implicit and explicit in the book that we wrote, which is: we were making some predictions that our ability to extract insights and knowledge from population health data would be enhanced through the use of AI. And I think that it looks to me like that has been more challenging and has come along more slowly over the past two years. But what is your view?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, I think part of, and I think you and I have had this conversation, you know, in bits and pieces. I think one of the real challenges is that when even tech companies, and you can name all of them, when they look at what they’re doing in the AI space, they gravitate towards healthcare delivery.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Right? That’s, it’s …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;And in fact, it’s not even delivery. I think techies—I did this, too—tend to gravitate specifically to diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes, that’s right. That’s right. You know, I think that’s a really good point. And, you know, when you look at sepsis or you look at pneumonia or try to figure out ways that, you know, radiologists or x-rays or CT scans can be read, it’s, I mean, there are so many use cases that are within the healthcare sector. And I think that gets back to this inequity that we have when we look at population health or, you know, this broad, um, swath of land that is, oftentimes, left behind or unexplored, and you have healthcare delivery. Now, healthcare delivery we know gets 95 cents or 96 cents of every dollar. So it makes sense why, right. But we also know that, at the end of the day, we’re looking at value-based outcomes, and you cannot be successful in the healthcare delivery system unless we are truly looking at prevention and what’s happening in the community and the population.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;And that’s why I use it interchangeably, but I know that “public health” has got a very specific term, and “population health” is a different set of ways of looking at the world. The reason that people try to shy away from pop health in essence is that you could talk about population health as being my population of patients in a clinic. It could be my health systems population. It could be an insurance company saying, these are the lives covered, right. So it becomes, what is population? When we think of public health, we think of the entirety of the population, right. In the State of Washington, eight million people. Harris County, five million people. Or in the US, 300—whatever the number of millions of people that—we think of the entire population. And what is it that actually impacts the health and well-being of that population is really what that’s about.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Yet here’s the challenge. When we then talk to those of our partners and our colleagues in the tech field, there are two things happening. One is, there’s a motivation because of the amount of dollars that are in [the] healthcare sector. And number two is, because it’s more familiar, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And so there are very few practitioners similar to me that are out there, that are in the pop health who kind of know healthcare delivery because they’ve also seen patients, but they’re also—they worked at that federal, state, local level, community level—they’ve, you know, they’ve done you know various different kinds of environments.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And they say, “Look, I’ve got a perspective to really help a tech company or somebody see the rest of it,” but you have to have both partners coming together to see that. And I think that’s one of the real challenges that we have.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so now I’m going to want to go into specific problems, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah. Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… and maybe COVID is a good thing to focus on—the breadth of problems that had to get solved in pandemic response and where the gaps between healthcare delivery and public health were really exposed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so the first problem that I remember really keenly that just seemed so vexing was understanding where the PPE was, the &lt;em&gt;personal protective equipment&lt;/em&gt; …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Hmm. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;and where it needed to be.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so that turned out … you would think just getting masks and gowns and gloves to the right places at the right times or even understanding where they are so that, you know … and being able to predict, you know, what hospitals, what clinics are most likely to get a big influx of patients during the height of the pandemic would be something that would be straightforward to solve, but that turned out to be an extremely difficult problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But how did it look from where you were sitting? Because you were sitting at the helm having to deal with these problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, we were constantly chasing data and information. And oftentimes, you know, because a lot of these data systems in the public health sector have been underinvested in over the decades, then, you know, you had our biggest emergency crisis of our time, and a lot of public health agencies were either getting, you know, thrown a whole host of resources or had to create things on the fly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And whether that was at Harris County or in the State of Washington, I will tell you that what I saw was that, you know, a lot of agencies across the country were still using fax machines, you know, to get data that were coming in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember actually—it’s kind of a funny story—there was a fax machine that was highlighted down in our agency in Texas. And we actually had this fax machine, had mounds of, you know, data … sorry, &lt;em&gt;papers&lt;/em&gt; that were next to … &lt;em&gt;faxes&lt;/em&gt; that were coming in and all these things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And you would have, you know, &lt;em&gt;Mr. Peter Lee&lt;/em&gt; listed as a patient. And then the next, you know, transmission would have &lt;em&gt;Pete Lee&lt;/em&gt;. And then the next transmission would have &lt;em&gt;Peter Lee&lt;/em&gt;, but instead of L-E-E, it was L-E-A-H or something, or L-I or something, right. And it was just …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or you had a date of birth missing, or you had, you know, an address that was off. And what we realized is that over time, a lot of the data that were coming in were just incomplete data, and being able to chase that was really hard.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so, you know, I think AI has that potential to really organize it, and to stratify it, and to especially get you to a point of at least cleaning it up. So I don’t think it’s just that AI … AI doesn’t just save &lt;em&gt;time&lt;/em&gt;; it saves &lt;em&gt;lives&lt;/em&gt;. Truly used …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… that’s, I think, where we’re talking here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when you have PPE and things of that nature, as you talked about, here in the State of Washington or what we were trying to do to get vaccines out or everything we’re doing to try to get communication messages to the public. And we did a fantastic job of that, although not ideal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I mean, there are so many things that I could point to that we could have done better—all of us in the field of public health and healthcare delivery alike.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I will tell you that the one thing that stays with me is that if we had those tools &lt;em&gt;then&lt;/em&gt;, and we had them in place &lt;em&gt;then&lt;/em&gt;, and we had invested in them at that time in advance of, I think there was a real opportunity for us to be able to move ahead and even be better at how we affected the health outcomes of the very populations that we were trying to get to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think it’s [that] AI allows us to shift from reactive to proactive systems, catching health issues before they escalate and allow us to really communicate with empathy &lt;em&gt;at scale&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And when we can do those things, whether it’s opioids or whether it’s, you know, something that’s happening related to an infectious disease, or, you know, even this, the new agenda with &lt;em&gt;Make America Healthy Again&lt;/em&gt;—which by the way, as you know, we had a &lt;em&gt;Be Well, WA&lt;/em&gt; … &lt;em&gt;Be Well,&lt;/em&gt; &lt;em&gt;Washington&lt;/em&gt; …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … very much that was about, you know, looking at, you know, physical health and nutritional health and emotional well-being and social connectedness—that there is a real opportunity for us to address the very drivers of ill health. And when we can do that, and AI can help us accelerate that, I think we truly have the ability to drive down costs and increase the value that’s returned to all of us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;What is your assessment of public health agencies’ readiness to use technology like AI? Because if there’s one thing AI is good at, it’s predicting things. Are they [public health agencies] in a better position to predict things now?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, I think it’s a tale of two cities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think on the one hand, we’re better because we have the tools. On the other hand, we’ve lost the capacity to be able to utilize those tools. So, you know, it’s a plus and a minus.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Many, many years ago, there was the buzzword of what we called &lt;em&gt;syndromic surveillance&lt;/em&gt;. And, Peter, you know this term well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It was like you would have, you know, a whole host of accumulation of data points in, let’s say, a hospital setting or an emergency department …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yup. Yup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… where, you know, you’d have runny nose, you’d have cough, you’d have a fever, and you would take that, what was happening and people presenting to the emergency department, with what was happening in the area pharmacies where people were going to get Kleenexes and tissues …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … and buying over-the-counter, you know, medication, and things of that nature, Tylenol, etc.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And you would say … you would put those two things together, and you would come up with a quote-unquote “syndrome,” and you would say our ability to say there was an alert to that syndrome allows us to say something&lt;em&gt; uh-oh&lt;/em&gt; is going on in the community, and we got many, many advancements related to wastewater surveillance over the last several years as you know …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep. Yep. Well, also, wasn’t patient number one in the United States discovered also because of the Seattle Flu Study, or at least that sort of syndromic surveillance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;They weren’t even looking for COVID. They were just taking, you know, snot samples from people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right. That’s right. That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that’s the kind of thing that you, you know, we underappreciate. Is you have to have a smart, intelligent, agile practitioner, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So if I think about down in Dallas when Ebola was, you know, the gentleman who was, you know, the index case for Ebola was sent out of the emergency department and came back several days later.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it was the nurse who picked up this time because the practitioner, the provider, the healthcare provider, the doc missed it. And I wouldn’t want to say in a negative way. It was just, like, not obvious. You aren’t thinking of Ebola in the middle of Texas. And it was the nurse who picked up: &lt;em&gt;there’s something wrong here&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And what AI has the ability to do is to pick up those symptoms …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or those patterns and be able to recognize the importance of those and be able to then alert the practitioner. So what I … we call it &lt;em&gt;artificial intelligence&lt;/em&gt;—it almost becomes artificial wisdom.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah, interesting. So that actually reminds me of my next question, which is another thing that I watched you and public health officials do is try to play “what if” games.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, for example, I think one decision you were involved in had to do with, you know, what would be the impact if we put a ban on large gatherings like concerts or movie theaters or imposed an 8 PM curfew on restaurants, and you were trying to play “what if” games. Like, what would be the impact on the spread of the pandemic there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So now, again, today with AI, would that aspect of what you did play out differently than it did during the pandemic?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; As you know, COVID was the most studied condition on the planet at one point. And it was, you know, things that usually we would learn over years or months, we were learning in weeks or days or hours.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember in Houston, I would say something in the morning, and I would always try to give the caveat, “This is the best information we know right now,” because it kept changing, whether it was around masks or whether it was around, you know, the way the virus was operating, whether it was around …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I remember even … I was just watching something recently where I was asked to comment about whether spiders could transmit COVID-19. You know, just questions that were just evolving, evolving, evolving. And the information was evolving. By morning, you would say something. By evening, it would change.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And why I say that is that it would have been great in the pandemic if we could have said, if you could give us all the information that’s happening across the globe, synthesize that information, and be able to help us forecast the right decisions that we should be making and help us model that information so we could decide: if you did a curfew, or if you did, you know, a mask, or if you could, you know, change something else related to policy—what are the impacts of it?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;What we found constantly in public health was that we were weighing decisions in incomplete data, incomplete information.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So great now that everybody can armchair quarterback looking back three, five years ago and say, “I would have done it this way,” or “I would have done it that way.” Gosh, I would have as well. But guess what—we didn’t have that information at that time. And so you had to make the best decisions you could with incomplete data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what AI has the potential to do is to help &lt;em&gt;complete&lt;/em&gt; the incomplete data. Now, it’s not going to get 100%.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And I think, Peter, you know, the one thing we’ve got to be really mindful [of] is phantom information, or information where it sort of makes up things, or may somehow get you incomplete information, or skews it a certain way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is why we can’t take the person out of it yet.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Now, maybe one day we can.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m not one of those Pollyanna-ish that people will never be replaced. I actually believe that those people who are skilled with AI and the tools will eventually have a competitive advantage over those who are not. Just like if I had a physician who knows how to use their smartphone or knows how to use a word processor or knows how to do a PowerPoint presentation is going to replace the ones that use scantrons …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or the ones that write it on pieces of paper—that eventually it makes it more efficient and effective, but we’re not there yet. But I think that the potential is &lt;em&gt;absolutely&lt;/em&gt; there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So I have one more question. And you can, kind of, tell I’m trying to expand people’s understanding of just the incredible breadth of what goes on in public health, you know, all of these sorts of different issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And again, just sticking to COVID, but this is a much broader issue. Another thing you had to cope with were significant rise of misinformation …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… and maybe going along with that, very, very significant inequities in outcomes in the COVID response. And when you think about AI there, I think you can argue it both ways, that it both exacerbates the problem but also gives you new tools to mitigate the problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What is your view?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; I think you … I don’t even have to say it … I think you hit on it, is that, you know, it really is two sides of one coin.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;On the one hand, it has the power of really advancing and allowing us to move forward in a way that incredibly accelerates and accentuates, but on the other hand, in the case of inequities, right? So if you have inequitable information data that’s already out in the literature or already out in the, you know, media, or what have you, about a certain population or people or certain kinds of ideas or thoughts, etc., then AI will tend to accumulate that. You’re going to take that information, thinking that’s the best out there, but it may have missed out on information and now you go with it. And that’s a potential problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think it’s the same thing on information is that when we have people that are able to classify or misclassify information, I think it really becomes hard because it can accelerate the inequities of trust or inequities of trusted sources of information. It can also close the gap.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think, you know, it’s really up to us and this responsible AI to really think about how we can go about doing this in a way that’s going to allow us to further the advancements but also be careful of those, you know, those kind of places where we’re going to step into that are not going to be well received or successful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, the one thing that’s really fascinating about this whole conversation is that this is why we’ve got to be at the table, Peter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Because if we’re not at the table, you know, what’s the, you know, or if tech companies that are out there doing this work and aren’t even seeing a field of practitioners that are actually wrestling with the same problems but just cannot actually get to the solutions, we’re just going to continue to accentuate the problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s why I’m a firm proponent of: we’ve got to be at the table.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so even when we’ve seen in, and this is going to be a little controversial, but governmental spaces where, you know, policymakers have said, “Look, we are not going to let you do certain things,” or they say to public health practitioners or even healthcare delivery practitioners in certain spaces, “You cannot even play with this. You cannot have it on your phones. You can’t do any … ”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, what I really believe it does is that it takes [an] almost like we put our head in the sand type of approach rather than saying, “What is it that we can do to help improve AI and make it work for all of us?” What we’re doing is we’re essentially saying, “We’re going to let the tech companies and all the other developers come up with the solutions, but it’s not going to be informed by the people in the field.” And that’s dangerous. We have to do both. We have to be working together.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Umair, that’s really so well said, and I think a great way to wrap things up. I’ve certainly learned a lot from this conversation. So thank you again.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; It’s been a pleasure to be with you this morning. Thank you so much for the time. And I’m looking forward to further conversations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &lt;/p&gt;



&lt;p&gt;I live in the State of Washington and because of that, I’ve been able to watch Umair in action as our state’s former secretary of health. And some of that action was pretty intense to say the least because his tenure as secretary of health spanned the period of the COVID pandemic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, as a dyed-in-the-wool techie, I have to admit that at the beginning, I don’t think I really understood the scope and importance of the field of public health. But as the conversation with Umair showed, it’s really important and it is arguably both an underfunded and underappreciated part of our healthcare system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, public health is also very much an area that’s ripe for advancement and transformation through AI. As Umair explained in our discussion, the core of public health is the idea of population health, the idea of extracting new health insights from signals from population-scale data. And already we’re starting to see AI making a difference.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now here’s my interview with Dr. Gianrico Farrugia.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Gianrico, it’s really great to have you here today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GIANRICO FARRUGIA:&lt;/strong&gt; Peter, thanks for having me. Thanks for making me part of your podcast.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, what I’d like to do in these conversations is, you know, we’ll definitely want to talk about the overall healthcare system, the state of healthcare, and what AI could or might do to help or even hurt all of that. But I always like to start with a sharper focus just on you specifically. And my first question always is, you know, I think people imagine what a hospital or a health system president and CEO does, but not really. And so how would you explain to your mother what you do every day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So, Peter, my mother’s 88 years old. She lives in Malta, and she’s visiting at the moment, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Oh, wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … which is kind of nice, really.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Wow, that is amazing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA: &lt;/strong&gt;I’m proud that she’s still proud of me. So she does ask. I’ll tell her the scope of Mayo Clinic. We serve patients across the globe. We have about 83,000 staff members that work with us, and we’re very proud of the work we do in research, education, and the practice.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Mayo Clinic is built to serve people with serious disease. So what I tell my mother is that here we are. We’re a healthcare organization that knows what it needs to do: keep patients as the North Star. The needs of the patient come first. We have 83,000 people who want to do that, several thousand physicians and scientists. My job is to look slightly ahead and then share what I’m seeing and then, sort of, smooth the way for others to make sure Mayo remains true to its mission but also true to the fact that at the moment, we are in a category of one. We need to remain there not just from an ego standpoint, but really from a “do good to the world” standpoint.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At that point, invariably my mother will tell me that I’m working too hard. [LAUGHTER] And then of course, I change the subject, and I ask her what she cooked today because my mother, who’s 88, cooks for the whole family in Malta, and there are usually four generations eating around the table. So I tell her what she does for the family is what I do for the Mayo family.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Wow, that’s a great way to put it. And it sounds like you actually have a good chance to have some good genes if she’s still that active at age 88.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I think I chose a little more stressful job that may limit [that]. I will tell you very briefly is that one of the AI algorithms we have estimates biological age from an electrocardiogram. My biological age jumped by 3.7 years when I became CEO.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] Oh no.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I’m hoping it will reverse on the other side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;To stick with you just for one more moment here, second question I ask is about your origin story with respect to AI. And typically, for most people, there is AI before ChatGPT and generative AI and then after the generative AI revolution. So can you share a little bit about this? Because it must be the case that you’ve been thinking about this a long time since you’ve really led Mayo Clinic to be so tech forward in this way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Well, I’ve been, as you said, a physician for way too long. I got my MD degree in ’87. So that sort of dates me. But it also means that I saw a lot of the promise for AI that never seemed to pan out for decades and decades and decades like you did.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Around 10 years ago, Mayo could sense that there was something different, that something was changing, that we actually—at that time, predictive AI—could make a big difference. And I think that’s the moment where I and others jumped in and said Mayo Clinic needs to be involved.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then about six years ago, when—six and a half years ago—I became CEO, it was clear that there was the right confluence of data, knowledge, tech expertise, that we could deal with what was increasingly bothering me, which is that we knew what was coming from a technology standpoint and we knew the current healthcare system could not deliver on what patients need and want within that current system. And so the answer is, how could a place like Mayo Clinic with our reputation not jump in and say there has to be a better way of doing things? I’ve always said that it is impossible for me to understand that every single government employee is incompetent. Every physician is greedy. Something’s wrong here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And that wrong was the architecture was wrong. And we knew that we could incorporate AI and make it better. So for me, that journey was one of &lt;em&gt;wait&lt;/em&gt;, &lt;em&gt;wait&lt;/em&gt;, &lt;em&gt;wait&lt;/em&gt;. 10 years ago, begin to jump in. Six years ago, really jump in with our platform. And then, of course, in November 2022, things changed again.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. When did this idea of a data platform, what you now call the Mayo Clinic Platform&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;—by the way, I refer to this as &lt;em&gt;MCP&lt;/em&gt;, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, I know. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] … which I always smirk a little bit because, of course, for those of us in computer science research, the AI research, &lt;em&gt;MCP&lt;/em&gt; has also become quite a hot topic because of the model context protocol version of this. But for Mayo’s MCP, when did that become a serious, defined initiative?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So around the end of ’18, 2018, beginning of 2019. At that point, we knew that we were going to do something differently. We came up with a strategic plan, as I took on the job, that we needed to cure more patients. There’s just not enough cures in the world. There’s too much suffering. And that we had all these chronic diseases that people have accepted are chronic, but really the only reason that disease is chronic is you haven’t cured it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And physicians have been afraid to talk about cure because, of course, eventually everybody passes away.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; But I really pushed hard to say, no, it’s OK to talk about cure. It’s OK to aspire to cure. The second was connect—connecting people with data to create new knowledge. And that’s where it became clear that data were not currently in a format that were particularly useful. By the way, you’ll hear me talk about &lt;em&gt;data&lt;/em&gt; in the singular and the plural. I’m old school. I talk about &lt;em&gt;data&lt;/em&gt; as plural, but I know that most younger people now use &lt;em&gt;data&lt;/em&gt; singular. [LAUGHTER] And I apologize if I’ll go through that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then the third was transform. Let’s use Mayo’s resources to transform healthcare for ourselves and for others. And that’s the concept of, if we are able to use data in a different way, let’s create a different architecture. And that architecture had to be very closely linked to using artificial intelligence in order to create better outcomes for patients. So patients can live not only longer lives but healthier lives. And that’s the genesis of MCP, &lt;em&gt;Mayo Clinic Platform&lt;/em&gt;, so I’ll timestamp that as end of 2018, beginning of 2019.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I’m really wanting to delve in in this episode, in this conversation, you know, [into the] mindset of a health system or hospital CEO. And so you’re obviously thinking about, I guess, machine learning and predictive analytics and so on. What were the, kind of, like … in 2018, what were the outcomes that you were dreaming about from this? So if you had this thing, you know, what were the things that you were hoping to be able to show or, kind of, produce as results?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So first of all, I think all of us who work at Mayo Clinic, and this tends to be a bit sugary, but it’s true, strongly feel that we have a responsibility to leave the place better than when we started. And so the Mayo brothers, when they started, did two really important things. The first was that they created the first integrated healthcare system. And the second, they created the first unified record. And that record was, of course, paper at that point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Part of that is to say, OK, what does it look like now versus how can we improve what we have if … it’d be blasphemy to say, let’s think of ourselves as the Mayo brothers, but let’s think of ourselves as reasonably smart people at Mayo Clinic, really lucky to be surrounded by very smart people with resources. What will we do? And so we said let’s not aim for the low-hanging fruit. Let’s aim to get at whatever you want to call it, the intractable knot, the hardest problem, and that is clinical care. Let’s improve clinical care. Yes, we can deal with burnout. Yes, we can deal with administrative burden. But let’s not focus on that. Let’s really create an architecture that allows us to tackle better clinical outcomes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And by starting there, then everything flows from that. That it’s not really worth doing unless at the end of the day, people are experiencing better health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so I know a very good colleague and friend of mine, John Halamka&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, you ended up hiring. I thought he was a very interesting choice because he is, of course, in terms of technology, quite deep and very expert, but he’s, I think, first and foremost, a doctor. And so I assume you must have had to decide what type of person you would bring in and what kinds of people you would bring in to try to create such a thing. What was your thinking around the choice of someone like John?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; It was one of the harder decisions. First of all, [I’m] a physician myself. We tend to want to maintain some control. And so now I am the CEO, [LAUGHTER] and I have to give this baby to somebody else. That’s very hard. Second is Mayo Clinic is really good because it is flat, and we run a lot by committee. But it also means that, therefore, you have to work really hard at change, and you cannot change by fiat. You have to change by convincing people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I just … I’ve always made the point that the right change agent is a servant leader because that’s how change becomes embedded. But it also means you’ve got to have that personality, the Mayo personality. And it became clear when we interviewed [that] there were some people that were really hardcore tech; others that were passionate about social issues. But John really fit that of being, as you said, deep in IT but also himself very aligned with the Mayo Clinic values. It’s as if he was a Mayo Clinic physician even though he wasn’t.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that came together, and I felt, &lt;em&gt;we&lt;/em&gt; felt, that as we were hiring, that we could do it. And then we did something interesting. We paired John with a … we created the role of a chief medical officer for the platform, which was a longstanding Mayo Clinic physician. And so we brought them together so we could get the past and the present and the future working together.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I’m going to ask you about what has come out of this. But before that, let’s get back to this origin story. So now, all of that is being set up starting around 2018. But then, you know, in 2022, there is generative AI. Now you were already experimenting with transformers, starting with BERT out of Google there. So maybe that’s a couple of years earlier. But still, there has to come a point where things are feeling very disrupted.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, so, you know, it really wasn’t. It, to me, was a relief because it gave this … we were feeling pretty good about what we’re doing. We were feeling a little impatient, but, in true Mayo fashion, were willing to, sort of, do everything, take its time, take it to the right committees, get the right approvals, and get it done.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when generative AI came, for us, it’s like, I wouldn’t say we told you so, but it’s like, ah, there you go. Here’s another tool. This is what we’ve been talking about. Now we can do it even better. Now we can move even faster. Now we can do more for our patients. It truly never was disruptive. It truly immediately became enabling, which is strange, right, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … because something as disruptive as that instantly became enabling at Mayo Clinic. And I’ll take … as I think about it with you and take a moment to think and reflect on it, I think there were a couple of decisions we made earlier on that really helped us. We made the decision &lt;em&gt;against&lt;/em&gt; the advice of any consulting firm to completely decentralize AI at Mayo Clinic six years ago. And we told our clinical department, you need to own this. You need to hire basic scientists in AI. We’ll help you by creating the infrastructure. We’ll help you by doing all the rest. We’ll have the compute. We’ll have the partners. You need to do this on your own. You need to treat this the same way as if a new radiological technique happened or a new surgical technique happened.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so there was a lot of expertise already present in a very diffused way that then we were able to layer on generative AI onto that. And we found a very willingness to embrace it. In fact, I would argue initially a bit too willing because as you know, we haven’t quite figured out what’s legitimate use, what’s not use.&amp;nbsp;We all learned together.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; But it was mostly energy, which is really interesting. It was mostly energy.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Wow. And, you know, it’s an amazing thing to hear because one common theme that we hear is that the initial reaction is oftentimes one of skepticism. In fact, I’ve been very open that even I initially had some skepticism. Was that not present in your mind or on your team’s mind at all at the beginning?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So you’re asking a physician if they are skeptical about something. [LAUGHTER] Yeah. I wonder what the answer to that is. Absolutely. The first hallucination, the first wrong reference. Can you imagine if you write the grant and the wrong reference comes. As you know, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … earlier on when some references were being made up. So massive amounts of skepticism. But the energy was such there that the people [who] were skeptical were also at the same time saying, “Let’s do a RAG [retrieval augmented generation] to clean up those references. Let’s create …” We were experimenting with discharge summaries, but let’s use AI to police AI, and let’s see what’s going on. So there was more massive skepticism, but the energy was pushing that skepticism into a positive versus into a negative frame. Now, I say that summarizing in hindsight.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Day to day, much more complicated than that. But overall, if you just … and remember, I had been at the World Economic Forum many years ago and had said, healthcare needs to run towards AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; If healthcare was perfect, we would wait. Healthcare is not perfect by any means, therefore let’s run and embrace AI. And, sort of, that mentality was part of who we were because at the same time, we were also saying the other thing, that we need to be the ones to lead validation. We need to be the ones that set the rules. We need to be participating in the creation of CHAI [Coalition for Health AI]&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. We need to be participating as the [National] Academy of Medicine&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So people did feel that Mayo was being fairly responsible about it, but that urge to, the needs of the patient come first, was the driver that kept people wanting to say, “Not ready yet, but let’s make it ready.” And we now have 320 algorithms in the practice, and they run and we constantly are looking and seeing what else we can do to improve. But as you well know, things evolve and change. And we’re also looking and seeing which ones work and which ones don’t and which ones we have to work together on to make better.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, you know, of course Mayo has such a, you know, such a reputation and is so influential, but in the world of healthcare broadly, let’s just focus on the United States to start. How common is this experience? You know, so if you are at a meeting with fellow CEOs of hospitals and health systems, what is the attitude and what is the, kind of … how common is the approach to all of this?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I think it’s more common now, but going back a few years, I think it’s fair to say that it was scary for people to know how it’s going to change things. Healthcare runs on very narrow margins. It’s very expensive. So your expenses and your revenue are both massive, and they are very close to each other. So anything that changes that balance is really scary.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Because it’s not like you have the opportunity to erode into a margin or get it right the second time. So I think that is what drove a lot of the initial hesitancy. Was, one, is lack of knowledge and, two, understanding that you didn’t have a lot of room to make a mistake.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; On the economics of this, when you are embarking on what I suspect is a very expensive initiative like Mayo Clinic Platform, how on earth do you justify that early on?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So again, I’m trying hard to try and remember how things were versus how I think about them now. [LAUGHTER] It goes back to our history. Mayo has always invested in what it thinks is the right thing that is coming. And that’s how we’ve stayed where we are. So the investment really was having an open discussion: is this worth it for our patients? And once that discussion was over, then the board was saying, &lt;em&gt;go&lt;/em&gt;, &lt;em&gt;go&lt;/em&gt;, &lt;em&gt;go&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now we are lucky in that we have the size that we’re able to hire and absorb. We’re lucky in that the people [who] came before us have been financially astute, and one of our values is stewardship. And we’re lucky that we had a lot of patients at Mayo Clinic who were able to listen, be inspired by, and be willing to help support. And so that gave us the ability to build what we’re doing not only into the long-range plan but actually into the yearly plan. And so we built it into the yearly plan. We set up a center for digital health. We set up the platform. And then we set up the budgets to be able to do that. And the budgets came from assets we’ve had, assets that we would get as the year came by, and then from philanthropy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We also had a really powerful calling card. And that’s one advantage I had, and that’s … and I’d been very open when I was speaking to other CEOs that would use it is that right at that very beginning, really, really in 2019, our cardiologists, both the researchers and the clinicians, had come together and had used electrocardiograms to create an AI algorithm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The first one was for diagnosing from an electrocardiogram, which is very cheap, very easy to do, left ventricular dysfunction. That’s how hard the left part of the heart contracts. If it doesn’t do well, you get heart failure. And they were able to show that that algorithm was already making nurses better than the physician without the algorithm. And after that went on to show that you could do it from a single strip, really with an area under the curve for that single strip on a watch, that was as good as mammograms or pap smears. And so we already had that proof.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; That quickly then came into Mayo. We put it into it so that any patient now can benefit from it. And now there are, I think, 14 algorithms just from that same one.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So we had a proof of concept thanks to those really far-seeing cardiologists that enabled things to happen a little faster and also, as I talked to other CEOs, enabled me to say, “This actually works. This is the path forward.” I have recently been vocal about also saying, we are at a point now where I believe that for some medical conditions, it is not right to not use AI to help treat them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Wow, that’s so interesting. So I think I want to get into another topic here, which is when you think about the use of AI and data, what are some of the results that maybe are top of mind for you or you think are particularly important? And if you don’t mind, I’d like to see if we can think about this not only in terms of results in terms of patient outcomes but in your other activities, core activities, like research, in the education mission, and then even in the broader impacts on the healthcare system. But maybe we start with on patient outcomes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, they’re all linked, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; They’re part of the same ecosystem. We think of ourselves as three shields— research, education, and the practice—and that one goes into the other. So, as I said, we have about 320 AI algorithms from the practice. Some run on every patient; some run on some patients. And we have good evidence for what they do. So some specific examples, and then I’ll get into the transformer part of this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We have a program called CEDAR [Clinical Detection and Response (tool)], and like most other people, I like acronyms for things. [LAUGHTER] But what it is, in our hospitals with patient consent, we monitor vitals. We monitor in the patient room—not in the ICU [intensive care unit], in the patient room. We monitor all sorts of things. But there’s a camera in the room, and we have a team of intensivists—nurses and physicians—who do not have any patient responsibilities but are just monitoring the algorithms, and when the algorithms are predicting decompensation, they’re able to get into the room. And what we’ve shown, for example, with that algorithm, is we’ve shown we’ve decreased length of stay in the hospital, decreased transfers into the intensive care units, and interestingly, decreased mortality and morbidity, which is not easy to show. I talked about the electrocardiogram as a good example. Of course, everybody knows about the radiology things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We’ve created … taken part of this and said, if we can do this in the hospital, why cannot we do it in patients’ homes? So being very active in looking after patients that would come to the ED, emergency room, would normally be admitted, and we say, no, here are the things we can give you. Go home if you want to, and we will safely look after you at your home. And we recently have been, looking at the last two years of data, been able to show that we’re also successfully able to give intravenous chemotherapy in patients’ homes because we can monitor; we can do all the things that we can do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, with generative AI, that gave us many other opportunities. One biggest opportunity for me has always been digital pathology. When we see how pathology’s currently run with a glass slide, not much has changed …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … in many, many, many years, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And so really we have made a massive push to digitize pathology not just for us but for others. But talking about ourselves, we started by saying, it has to be very cheap to digitize. So we worked and created a company with partners called Pramana&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that allows us to digitize slides relatively cheaply using AI algorithms that can take away the dirt, the fingerprint. And so we end up with 21 million of our slides digitized, and that gives you now a massive opportunity. Worked with another company called Aignostics&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to create a, what we call, Atlas&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which is an LLM that allows us to then build upon it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And we, a hundred and, I think, 120 years ago, invented frozen sections at Mayo Clinic. So what that is, is that while the patient’s still on the table, you can take a piece of tissue, look at it, and tell the surgeon the margins of what you’re trying to resect are clear or not. But as a result of that, because you have to hurry, you get no information as a surgeon about, is it an invasive cancer, is it noninvasive cancer, or other things. So we’ve just found a way to digitize our frozen section practice and will completely go across the enterprise with AI-enabled digitized frozen sections, which then enables us to then do it for anybody across the globe if we need to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then in the genomic space, we’re working to create a true exomic transformer that is short range. And we originally started doing it to see if we can test it against the fact that 40% of people with rheumatoid arthritis don’t respond to the first-line therapy, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … but you have to wait six months to find out. And we found that we can actually do that. But it has much greater uses, of course.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then we’re working with you—I don’t know how much you want to get into this, Peter, or [if] you want to talk about it yourself—MAIRA-2, which is really exciting, about how taking a simple problem—can you create a transformer that is able to detect if lines on the chest are in the right place, breathing tube is in the right place?—and then do it in a way that then can be used for many, many other things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, Peter, because you asked about education and research, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … imagine what this does now to the education system, right. And so we’ve got to train our physicians differently. We now have an AI curriculum for all our medical students. We offer masters and PhDs in AI. We think it’s essential for the people who want to be able to truly become experts, the same way I became an expert in my area of research.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then from a research standpoint, when you think about all the registries that exist in people’s labs, all the spatial genomics, all the epigenomics, all the omics that exist. And if you are able to coalesce them into one big, what we call, an &lt;em&gt;atlas&lt;/em&gt;, how that could really spur research at a scale that we haven’t thought of before. And so that is our aim at the moment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;From a research standpoint, we are, with Vijay Shah, who’s our dean of research, is to say, let’s make the effort of making sure all the data are available to be able to use and enable for us to take advantage of AI. And that is not easy because, of course, people have collected the data. They tend to want to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA: &lt;/strong&gt;So there have to be the right incentives, the right privacy, and the right ways of doing it. And we think we’re on the way there, and we’re already seeing some advantages from doing it this way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So we’re running short on time. And so I always like to end with one or two more provocative questions. And, you know, it’s tempting to ask you the provocative question of whether you think AI will ever replace human doctors, but I don’t want to go there with you. In fact, as I thought about our discussion, I was reflecting. We were at a conference together once, and I was on stage in a fireside chat. And then, you know, after the fireside chat, there were audience questions, and I don’t remember any of the questions from the audience except &lt;em&gt;yours&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And just to remind you, you know, I think when I was on stage, we were talking about a lot of practical uses of AI to, let’s say, reduce administrative burdens and so on in healthcare. But you got up and you, I won’t say you scolded me, but you more or less said, is it the right idea to use AI to optimize today’s somewhat broken healthcare system, or should we be thinking more boldly about, you know, a more fundamental transformation?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so what I thought I would try to close with here is to hear what was really behind that question. You know, what were you trying to get me to think about when you asked that question?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So first of all, darn your great memory [LAUGHTER]. Belated apologies … I probably should have …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; It was by far the best and most sophisticated and, I think, thought-provoking question of all of the ones that came out of the audience.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; What I was trying to get to is actually trying to clarify it in my own head and then in the head of others is that we do not need to have a linear path to get to where we want to get to. And we seemed to be on a linear path, which is, let’s try and reduce administrative burden. Let’s try and truly be a companion to a physician or other provider. Let’s make their problems better, make them feel better about providing healthcare. And then in the next step, we keep going until we get to, now we can call it agentic AI, whatever we want to talk about. And my view was, &lt;em&gt;no&lt;/em&gt;, is that let’s start with that aim, the last aim, and do the others because the others will come automatically if you’re working on that harder problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Because one, to get to that harder problem, you’ll find all the other solutions. I was just trying to push that here’s this wonderful tool that’s been given to us. Let’s take advantage of it as quickly as we can. I think we had gotten a little too sensitized to need to say the right things. “Careful, be very careful” versus saying, “Massive opportunity. Do it right, and healthcare will be much better. Go for it.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, I think I understand better now where the vision, insight, and frankly, courage to take on something as ambitious and transformational as the Mayo Clinic Platform and really all of your leadership in your tenure as the president and CEO of Mayo Clinic. I think I understand it much better now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Gianrico, it’s just always such a privilege to interact with you and now to have a chance to work with you more closely. So thank you for everything that you do and thank you for joining us today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Thank you for making it so easy, and thanks for giving us this opportunity to do good for the world.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Gianrico leads what is arguably the crown jewel of the world’s healthcare systems, and so I feel it’s such a privilege to be able to talk and sometimes even brainstorm with him.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Our conversation, I think, exposed just how tech forward Gianrico is as he charts the strategies for healthcare delivery well into the future. And as I’ve interacted with many others, what I’ve learned is that this is a common trait among major health system CEOs. Roughly speaking, like we’ve seen in previous episodes where doctors and med students are polymath clinician-technologists, the same thing is true of health system CEOs and other leaders.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AI in the mind of a health system CEO today is not only a technology that can transform diagnosis and treatment, but it’s also something that can have a huge impact on the business of healthcare delivery, the connection of healthcare to medical research, and the journeys that patients go through as they seek better health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These two conversations show that virtually all leaders in health and medicine are confronting head-on the opportunities, challenges, and the reality of AI, and they see a future that is potentially very different than what we have today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’d like to thank Umair and Gianrico again for their time and insights. And to our listeners, thank you for joining us. We hope you’ll tune in to our final episode of the series. My coauthors, Carey and Zak, will be back to examine the takeaways from our most recent conversations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Until next time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&amp;nbsp;&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;








&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated headshots of Peter Lee, Umair Shah, Gianrico Farrugia" class="wp-image-1147485" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode10-PeterUmairGianrico-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this episode, healthcare leaders Dr. Umair Shah&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Dr. Gianrico Farrugia&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; join Lee to discuss AI’s impact on the business of public health and healthcare delivery, the healthcare-research connection, and the patient experience. Shah, a healthcare strategic consultant and former state secretary of health, explores the role of public health in the larger ecosystem and why it might not get the attention it needs or deserves and how AI could be leveraged to assist in data analysis, to help better engage with people on matters of public health, and to help narrow gaps between care delivery and public health responses during health emergencies. Farrugia, president and CEO of Mayo Clinic, traces AI’s path from predictive to generative and discusses how that progress has helped usher in a new healthcare architecture for Mayo Clinic and its partners, one powered by the goal of longer, healthier lives for patients, and how AI is also changing Mayo Clinic’s research and the education it provides, including the offering of masters and PhDs in AI and other emerging technologies.&amp;nbsp;&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;








&lt;/div&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;[MUSIC] &lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE:&lt;/strong&gt; “In US healthcare, quality ratings are increasingly used to tie the improvement in patient health outcomes to the reimbursement rates that healthcare providers can receive. The ability of GPT-4 to understand these systems and give concrete advice … has a chance to make it easier for providers to achieve success in both dimensions.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee. &lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong? &lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;[THEME MUSIC FADES]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The book passage I read at the top is from Chapter 7, “The Ultimate Paperwork Shredder.” &lt;/p&gt;



&lt;p&gt;Public health officials and healthcare system leaders influence the well-being and health of people at the population level. They help shape people’s perceptions and responses to public health emergencies, as well as to chronic disease. They help determine the type, quality, and availability of treatment. All this is critical for maintaining good public health, as well as aligning better health and financial outcomes. That, of course, is the main goal of the concept of value-based care. AI can definitely have significant ramifications for achieving this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Joining us today to talk about how leaders in public health and healthcare systems are thinking about and acting on this new generation of AI is Dr. Umair Shah and Dr. Gianrico Farrugia.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Dr. Umair Shah is a nationally recognized health leader and innovator. He led one of America’s top-rated pandemic responses as Washington State’s secretary of health, a position he held from 2020 to 2025. Umair previously directed Harris County Public Health in Texas, overseeing large-scale emergency response for the nation’s third-largest county, while building an emergency-care career spanning 20-plus years. He now advises organizations on health innovation and strategy as founder and principal of Rickshaw Health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Dr. Gianrico Farrugia is the president and CEO of Mayo Clinic, the world’s top-ranked hospital for seven consecutive years, and a pioneer in technology-forward, platform-based healthcare. Under his leadership, Mayo has built and deployed the Mayo Clinic Platform. The platform enables Mayo and its partners to gain practical insights from a comprehensive repository of longitudinal de-identified clinical data spanning four continents. Gianrico is also a Mayo Clinic physician and professor and an author.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Umair and Gianrico are CEO-level leaders representing some of the best of the worlds of public health, healthcare delivery, medical research, and medical education.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Here is my interview with Dr. Umair Shah:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Umair, it’s really great to have you here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;UMAIR SHAH:&lt;/strong&gt; Peter, it’s my pleasure. I’ve been looking forward to this conversation, and I hope you are well today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] I am doing extremely well.&lt;/p&gt;



&lt;p&gt;So, you know, what I’d like to do in these conversations is first just to start, a little bit about you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You served actually during a really tumultuous time as the secretary of health in the State of Washington. But you recently stepped away from that and you started your own firm, Rickshaw Health. So can we start there? What’s that all about?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, no, absolutely. First of all, you know, I would say that the transition from Texas to Washington could not have been more geopolitically different, [LAUGHTER] as you can imagine.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, if you like the red-blue paradigms, you couldn’t be more, you know, red and you couldn’t be more blue, I think.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; But what happened is, back in November this past year, as I saw some of the playout of continuation of this red-blue dynamic, I made the decision to step down. And Jan. 15, I stepped down, as you mentioned, and I spent some time really thinking about what I wanted to do next and was looking at a number of opportunities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then a moment in time, there were some things happening in our—my wife and our family’s personal lives that sort of made me think that I wanted to focus a little bit more on family. And I felt the universe was saying, “Stay still.” [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I launched Rickshaw Health&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and the notion that, as you know, Peter, rickshaws are oftentimes known across the globe as these modes of transport that reliably get you through ever-changing streets and traffic patterns and all sorts of ecosystems that are evolving at all times. And they get you to the other side and they get you also with a sense of exhilaration. Like when I took my boys to Karachi, and we were—you know, they jumped in a rickshaw and the, you know, open air [LAUGHTER] and they felt this incredible excitement.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so Rickshaw Health was speaking to the three wheels of a rickshaw that symbolize the three children that we have and the real notion of how do we bring balance and agility and performance to the forefront and then move in an ever—just like streets—ever-changing healthcare environment that is constantly evolving, and we too must evolve with it. And that’s what Rickshaw Health is all about, is taking clients to that next level of trying to navigate, especially at this time, a very, very different landscape than even several months ago. So, excited about it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, absolutely. You know, you made this transition from Texas to the State of Washington. And for people who listen to this podcast and don’t know, the particular part of Texas where you were—Harris County—is &lt;em&gt;really big&lt;/em&gt;, very, very important in that state. That’s just not, you know, the normal county in Texas.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;It’s actually … it’s actually known as quite a forward-looking place, technologically.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So what was, you know, the transition like, then, going from, you know, possibly the most, sort of, maybe advanced county in the State of Texas, a large place, to the State of Washington?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, you know, Harris County is the third-largest county in the US. So it had close to five million. And now it’s probably … it’s exceeded the five million people, and a very diverse, very forward-looking, as you mentioned, technologically very, very much looking at what’s the next horizon, and home to Texas Medical Center [TMC] as well, which is …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… the largest medical center. Of course, it had to be Texas. So it can’t be the largest in the state or the country [LAUGHTER]—the largest in the world, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And TMC also had a number of different initiatives related to startups and venture capital and VC. And so they had launched something called TMCX. And that was a real opportunity—and I know you’re familiar with it—an opportunity to really look at how do you incubate all sorts of different innovations and bringing private sector, public sector as well as healthcare delivery alongside these startups to really look at the landscape.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when I left Houston and came to Washington, I realized that obviously, I was in the backyard … I mean, you know, you all at Microsoft Research and the work that you’re all doing is part of an ecosystem of advanced innovation that’s occurring in the Pacific Northwest that, you know, when we see all the players that are here, all the, you know, ones that do so many different things, but they’re doing them with an eye towards technology, advancements, and adoptions, it’s been quite amazing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;When I made that transition, it was really about, you know, the vaccines and what was happening with, you know, with COVID and fighting the—you know, remember, this was the state that had the first case in the continental United States, had the first outbreak, and the first [lab-confirmed] death. And fast-forward a few years later, we had the fifth-lowest death rate in the US. And that was because we all came together to do so much.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, well maybe that gets us into a question that I ask a lot of our guests, which is, you know, and maybe let’s, since we’re on your time as the secretary of health in Washington State, [start] with that job. I ask, how would you explain to your mother what you do every day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; [LAUGHS] I laugh because that’s been such a fascinating conversation in public health because we have oftentimes been—it’s been really hard to describe what that is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And, you know, there are so many metaphors and, you know, analogies that we’ve used. I’ve always wondered why we do not have more television shows or sitcoms or dramas that are about the public health workforce or the work that we do in the field, because you have, you know, all sorts of healthcare delivery ones, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; As a practicing physician for 20 years, I realized that people knew what doctors did; they knew what nurses did, right. They intimately touch the healthcare system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; They understood, you know, that an ambulance picks you up at your home or somewhere else, transports you … gets you to the emergency department. The emergency department, they do some things to you or within the four walls of that ER, and then you’re either admitted, sent home, and several days, weeks, whatever later, you get home if you’re admitted, and you start your, you know, post-hospital stay at home or your rehab or what have you. And that all is known to people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But when you ask your mother, your grandmother, or your, you know, your uncle, or your brother, your neighbor, your coworker about what is public health, they have a very quizzical look on their face of what that is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And so what I’ve …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, just one thing I’ve learned is: it’s not just all the people you mentioned. Even healthcare professionals sometimes have that quizzical look.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, good point. That’s right. Good point. And a lot of it is because we don’t get exposed to it or trained in it. You know, we think about public health when we’re in our training. And, you know, I’m sure you had a very similar piece of this is that, you know, you see it as, oh, that’s the health department that takes care of, you know, STDs, or it takes care, you know, it does the immunizations, or, you know, maybe they do some water quality, or maybe they do mosquitoes [mosquito control], and things like that. But the reality is, we do &lt;em&gt;all&lt;/em&gt; of those things and more.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So my metaphor has been that we are the offensive line of a football team, and the healthcare delivery is the quarterback. So everybody focuses on, you know, from a few years back, everybody knows Tom Brady, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; He won the Super Bowls, everybody knows what … but if you asked people who was number 75 on the offensive line of the New England Patriots …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or name your favorite football team. And the answer would be: you would not be able to likely answer that question. You would know Tom Brady, the quarterback, and that’s healthcare delivery, the ER doc or the hospitalist or the nurse or the, you know, the medical assistant, or the people that are doing all the work in the field that are the ones that are more visible, but the invisible workforce of the offensive line, that’s who we don’t know. And yet these are the people that are blocking and sweating and doing all things to complement the work and make sure the quarterback is successful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And here’s where the metaphor breaks down, that when Tom Brady wins the Super Bowl, we continue to invest in the offensive line because we recognize the value of it and we want the quarterback to be successful the next season. But in public health or in society, we do the exact opposite.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;When tuberculosis rates come down, we say, well, you know what? We’ve solved the problem; we don’t need it anymore.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Or you have another, you know, environmental issue that’s no longer there, you say, “We don’t need it anymore.” And we &lt;em&gt;disinvest&lt;/em&gt; from public health or that offensive line. And then you start to see those rates go back up.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so my answer to Mom and Grandma and Dad and Grandpa is we are &lt;em&gt;critical&lt;/em&gt; to your health because we touch you every single day. And so please invest in us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. And, you know, I think I’m going to want to get a little deeper on that in just a few minutes here, because, I think especially during the pandemic, that issue of not understanding the importance of that offensive lineman actually really came to the forefront.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I’d like to get into that. But the, kind of, second, kind of, standard thing I’ve been probing with people is still just focusing on you and your background is what touchpoints or experiences you’ve had with AI in the past.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And not everyone has. Like, it maybe isn’t too surprising that doctors and healthcare developers, tech developers, have lots of contact with AI, but would the top dog, you know, at a public health agency ever have had significant contact with AI? What about you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, it’s interesting. Several years ago, I was in the audience with the [then] FEMA director, [Rich Serino], who just did such an incredible job. And I remember he made this comment at that time. And, Peter, this may have been like … I don’t know—I’m dating myself—10, 15, maybe even 20 years ago, and he said, “Everybody in the audience, there’s this, you know, app called Twitter.” And, you know, “How many people in the audience have ever sent a tweet or know about this?” And I don’t know, maybe—it was a public health audience—maybe about 15% of the people raised their hands.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;He said, “I challenge you to right now, pick up your phone, download the app, and go ahead and send a tweet right now.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember I sent my first tweet at that time. And it was so thought provoking for me was that he was saying you need to be engaged in social media, but the other 85% of the audience had not even done that or had …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … even understood the importance of social media at that time. Or maybe they understood, but they had restrictions on how to utilize, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So that has stayed with me because that’s very much about this revolution of AI that I know that public health and population health practitioners like myself who have been in the trenches and understand the importance of it, they really believe in the importance or think they know the importance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But NACCHO, the National Association of County and City Health Officials, had done a survey of local health agencies. And about two-thirds, if not three-quarters, of local health agencies reported that they had an AI capacity that was low or lower than ideal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And that is very much where I come from. When I was in public sector and at the state health agency, our transformation was very much about how do we advance the work, and how do we utilize this in a population health standpoint?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I was fortunate to have a chief of innovation at Washington State Department of Health, Les Becker, who understood the value of AI. And as you know, we did also hold a AI science convening that …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … your team was there with University of Washington. And that was really an opportunity for us to say that AI is here. It’s not tomorrow. It’s not next year. It’s not the future. It’s already here. We need to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But here’s the problem, Peter, far too few people in our field understand just how to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; So I have become a markedly more champion of AI. One, since I read your book. So I think there’s that. So thank you for writing it. But two, since I really recognize that when I became a solo or a primary-few practitioner in my own realm, I needed to force-amplify the work that I was doing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And when I look back, and I continue to stay in touch with my colleagues in the field of public health, what they’re also struggling with is that you have an epidemiologist who’s got a mound of information—data, statistics, etc.—that they are going through, and they’re doing everything in their power to get that processed and analyzed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; AI can take 80% of that and do it. And that epidemiologist can now turn to more of an overseer and a gatekeeper and to really recognize the patterns …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … and let AI be able to do the, you know, grunt work. And similarly, as you know, measles—with the outbreaks that we’ve seen, especially in Texas but elsewhere—you’ve got an opportunity where our communications people who are saying, “Look, we’re about to have, or we know we’re about to announce that there’s a measles outbreak in, you know, in our community or our state or what have you—our region.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And they can have AI go through different press briefings and/or press releases and say, “Give me the state of the art on how I should communicate this message to the community.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And bam! You can do that. And now you can oversee that work, as well. And then the third example is that we are always looking at how do we find ways to have a deeper connection with those who come to our, you know, our websites or come to our engagement tools—with bots and things like that. AI can really accelerate that work, as well. So there’s so many use cases that AI has for population health or public health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; But I think the challenge is that we just don’t have enough adoption because they’re … one, we’ve had funding cuts, but two is that there is this real hesitation on, what is it that we can do? And I argue—the last thing I’ll say about this, Peter—is that I argue that AI is happening right now. The discussions, the technology advancements, the work, the policy work, all that’s happening right now. If public health practitioners are not at the table, if they’re not part of the, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … “What does this look like? How does it work in our field?” … guess what? It’s going to be done &lt;em&gt;to&lt;/em&gt; us and &lt;em&gt;for&lt;/em&gt; us rather than with us. And if we do not get with that and get to the table, then unfortunately it may not be exactly what we want it to be at the end of the day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I find it really interesting that you are using the terms “public health” and “population health” …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… pretty much interchangeably here. And I think that that’s something that I think touches on an assumption that was both implicit and explicit in the book that we wrote, which is: we were making some predictions that our ability to extract insights and knowledge from population health data would be enhanced through the use of AI. And I think that it looks to me like that has been more challenging and has come along more slowly over the past two years. But what is your view?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, I think part of, and I think you and I have had this conversation, you know, in bits and pieces. I think one of the real challenges is that when even tech companies, and you can name all of them, when they look at what they’re doing in the AI space, they gravitate towards healthcare delivery.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Right? That’s, it’s …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;And in fact, it’s not even delivery. I think techies—I did this, too—tend to gravitate specifically to diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes, that’s right. That’s right. You know, I think that’s a really good point. And, you know, when you look at sepsis or you look at pneumonia or try to figure out ways that, you know, radiologists or x-rays or CT scans can be read, it’s, I mean, there are so many use cases that are within the healthcare sector. And I think that gets back to this inequity that we have when we look at population health or, you know, this broad, um, swath of land that is, oftentimes, left behind or unexplored, and you have healthcare delivery. Now, healthcare delivery we know gets 95 cents or 96 cents of every dollar. So it makes sense why, right. But we also know that, at the end of the day, we’re looking at value-based outcomes, and you cannot be successful in the healthcare delivery system unless we are truly looking at prevention and what’s happening in the community and the population.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;And that’s why I use it interchangeably, but I know that “public health” has got a very specific term, and “population health” is a different set of ways of looking at the world. The reason that people try to shy away from pop health in essence is that you could talk about population health as being my population of patients in a clinic. It could be my health systems population. It could be an insurance company saying, these are the lives covered, right. So it becomes, what is population? When we think of public health, we think of the entirety of the population, right. In the State of Washington, eight million people. Harris County, five million people. Or in the US, 300—whatever the number of millions of people that—we think of the entire population. And what is it that actually impacts the health and well-being of that population is really what that’s about.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Yet here’s the challenge. When we then talk to those of our partners and our colleagues in the tech field, there are two things happening. One is, there’s a motivation because of the amount of dollars that are in [the] healthcare sector. And number two is, because it’s more familiar, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And so there are very few practitioners similar to me that are out there, that are in the pop health who kind of know healthcare delivery because they’ve also seen patients, but they’re also—they worked at that federal, state, local level, community level—they’ve, you know, they’ve done you know various different kinds of environments.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And they say, “Look, I’ve got a perspective to really help a tech company or somebody see the rest of it,” but you have to have both partners coming together to see that. And I think that’s one of the real challenges that we have.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so now I’m going to want to go into specific problems, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah. Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… and maybe COVID is a good thing to focus on—the breadth of problems that had to get solved in pandemic response and where the gaps between healthcare delivery and public health were really exposed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so the first problem that I remember really keenly that just seemed so vexing was understanding where the PPE was, the &lt;em&gt;personal protective equipment&lt;/em&gt; …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Hmm. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;and where it needed to be.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so that turned out … you would think just getting masks and gowns and gloves to the right places at the right times or even understanding where they are so that, you know … and being able to predict, you know, what hospitals, what clinics are most likely to get a big influx of patients during the height of the pandemic would be something that would be straightforward to solve, but that turned out to be an extremely difficult problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But how did it look from where you were sitting? Because you were sitting at the helm having to deal with these problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yeah, we were constantly chasing data and information. And oftentimes, you know, because a lot of these data systems in the public health sector have been underinvested in over the decades, then, you know, you had our biggest emergency crisis of our time, and a lot of public health agencies were either getting, you know, thrown a whole host of resources or had to create things on the fly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And whether that was at Harris County or in the State of Washington, I will tell you that what I saw was that, you know, a lot of agencies across the country were still using fax machines, you know, to get data that were coming in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember actually—it’s kind of a funny story—there was a fax machine that was highlighted down in our agency in Texas. And we actually had this fax machine, had mounds of, you know, data … sorry, &lt;em&gt;papers&lt;/em&gt; that were next to … &lt;em&gt;faxes&lt;/em&gt; that were coming in and all these things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And you would have, you know, &lt;em&gt;Mr. Peter Lee&lt;/em&gt; listed as a patient. And then the next, you know, transmission would have &lt;em&gt;Pete Lee&lt;/em&gt;. And then the next transmission would have &lt;em&gt;Peter Lee&lt;/em&gt;, but instead of L-E-E, it was L-E-A-H or something, or L-I or something, right. And it was just …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or you had a date of birth missing, or you had, you know, an address that was off. And what we realized is that over time, a lot of the data that were coming in were just incomplete data, and being able to chase that was really hard.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so, you know, I think AI has that potential to really organize it, and to stratify it, and to especially get you to a point of at least cleaning it up. So I don’t think it’s just that AI … AI doesn’t just save &lt;em&gt;time&lt;/em&gt;; it saves &lt;em&gt;lives&lt;/em&gt;. Truly used …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… that’s, I think, where we’re talking here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when you have PPE and things of that nature, as you talked about, here in the State of Washington or what we were trying to do to get vaccines out or everything we’re doing to try to get communication messages to the public. And we did a fantastic job of that, although not ideal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I mean, there are so many things that I could point to that we could have done better—all of us in the field of public health and healthcare delivery alike.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I will tell you that the one thing that stays with me is that if we had those tools &lt;em&gt;then&lt;/em&gt;, and we had them in place &lt;em&gt;then&lt;/em&gt;, and we had invested in them at that time in advance of, I think there was a real opportunity for us to be able to move ahead and even be better at how we affected the health outcomes of the very populations that we were trying to get to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think it’s [that] AI allows us to shift from reactive to proactive systems, catching health issues before they escalate and allow us to really communicate with empathy &lt;em&gt;at scale&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And when we can do those things, whether it’s opioids or whether it’s, you know, something that’s happening related to an infectious disease, or, you know, even this, the new agenda with &lt;em&gt;Make America Healthy Again&lt;/em&gt;—which by the way, as you know, we had a &lt;em&gt;Be Well, WA&lt;/em&gt; … &lt;em&gt;Be Well,&lt;/em&gt; &lt;em&gt;Washington&lt;/em&gt; …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … very much that was about, you know, looking at, you know, physical health and nutritional health and emotional well-being and social connectedness—that there is a real opportunity for us to address the very drivers of ill health. And when we can do that, and AI can help us accelerate that, I think we truly have the ability to drive down costs and increase the value that’s returned to all of us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;What is your assessment of public health agencies’ readiness to use technology like AI? Because if there’s one thing AI is good at, it’s predicting things. Are they [public health agencies] in a better position to predict things now?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; You know, I think it’s a tale of two cities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think on the one hand, we’re better because we have the tools. On the other hand, we’ve lost the capacity to be able to utilize those tools. So, you know, it’s a plus and a minus.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Many, many years ago, there was the buzzword of what we called &lt;em&gt;syndromic surveillance&lt;/em&gt;. And, Peter, you know this term well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It was like you would have, you know, a whole host of accumulation of data points in, let’s say, a hospital setting or an emergency department …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yup. Yup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;… where, you know, you’d have runny nose, you’d have cough, you’d have a fever, and you would take that, what was happening and people presenting to the emergency department, with what was happening in the area pharmacies where people were going to get Kleenexes and tissues …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … and buying over-the-counter, you know, medication, and things of that nature, Tylenol, etc.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And you would say … you would put those two things together, and you would come up with a quote-unquote “syndrome,” and you would say our ability to say there was an alert to that syndrome allows us to say something&lt;em&gt; uh-oh&lt;/em&gt; is going on in the community, and we got many, many advancements related to wastewater surveillance over the last several years as you know …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep. Yep. Well, also, wasn’t patient number one in the United States discovered also because of the Seattle Flu Study, or at least that sort of syndromic surveillance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;They weren’t even looking for COVID. They were just taking, you know, snot samples from people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; That’s right. That’s right. That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that’s the kind of thing that you, you know, we underappreciate. Is you have to have a smart, intelligent, agile practitioner, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So if I think about down in Dallas when Ebola was, you know, the gentleman who was, you know, the index case for Ebola was sent out of the emergency department and came back several days later.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it was the nurse who picked up this time because the practitioner, the provider, the healthcare provider, the doc missed it. And I wouldn’t want to say in a negative way. It was just, like, not obvious. You aren’t thinking of Ebola in the middle of Texas. And it was the nurse who picked up: &lt;em&gt;there’s something wrong here&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And what AI has the ability to do is to pick up those symptoms …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or those patterns and be able to recognize the importance of those and be able to then alert the practitioner. So what I … we call it &lt;em&gt;artificial intelligence&lt;/em&gt;—it almost becomes artificial wisdom.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. Yeah, interesting. So that actually reminds me of my next question, which is another thing that I watched you and public health officials do is try to play “what if” games.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, for example, I think one decision you were involved in had to do with, you know, what would be the impact if we put a ban on large gatherings like concerts or movie theaters or imposed an 8 PM curfew on restaurants, and you were trying to play “what if” games. Like, what would be the impact on the spread of the pandemic there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So now, again, today with AI, would that aspect of what you did play out differently than it did during the pandemic?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; As you know, COVID was the most studied condition on the planet at one point. And it was, you know, things that usually we would learn over years or months, we were learning in weeks or days or hours.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I remember in Houston, I would say something in the morning, and I would always try to give the caveat, “This is the best information we know right now,” because it kept changing, whether it was around masks or whether it was around, you know, the way the virus was operating, whether it was around …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I remember even … I was just watching something recently where I was asked to comment about whether spiders could transmit COVID-19. You know, just questions that were just evolving, evolving, evolving. And the information was evolving. By morning, you would say something. By evening, it would change.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And why I say that is that it would have been great in the pandemic if we could have said, if you could give us all the information that’s happening across the globe, synthesize that information, and be able to help us forecast the right decisions that we should be making and help us model that information so we could decide: if you did a curfew, or if you did, you know, a mask, or if you could, you know, change something else related to policy—what are the impacts of it?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH: &lt;/strong&gt;What we found constantly in public health was that we were weighing decisions in incomplete data, incomplete information.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So great now that everybody can armchair quarterback looking back three, five years ago and say, “I would have done it this way,” or “I would have done it that way.” Gosh, I would have as well. But guess what—we didn’t have that information at that time. And so you had to make the best decisions you could with incomplete data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what AI has the potential to do is to help &lt;em&gt;complete&lt;/em&gt; the incomplete data. Now, it’s not going to get 100%.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; And I think, Peter, you know, the one thing we’ve got to be really mindful [of] is phantom information, or information where it sort of makes up things, or may somehow get you incomplete information, or skews it a certain way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is why we can’t take the person out of it yet.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Now, maybe one day we can.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m not one of those Pollyanna-ish that people will never be replaced. I actually believe that those people who are skilled with AI and the tools will eventually have a competitive advantage over those who are not. Just like if I had a physician who knows how to use their smartphone or knows how to use a word processor or knows how to do a PowerPoint presentation is going to replace the ones that use scantrons …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; … or the ones that write it on pieces of paper—that eventually it makes it more efficient and effective, but we’re not there yet. But I think that the potential is &lt;em&gt;absolutely&lt;/em&gt; there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So I have one more question. And you can, kind of, tell I’m trying to expand people’s understanding of just the incredible breadth of what goes on in public health, you know, all of these sorts of different issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And again, just sticking to COVID, but this is a much broader issue. Another thing you had to cope with were significant rise of misinformation …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… and maybe going along with that, very, very significant inequities in outcomes in the COVID response. And when you think about AI there, I think you can argue it both ways, that it both exacerbates the problem but also gives you new tools to mitigate the problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What is your view?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; I think you … I don’t even have to say it … I think you hit on it, is that, you know, it really is two sides of one coin.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;On the one hand, it has the power of really advancing and allowing us to move forward in a way that incredibly accelerates and accentuates, but on the other hand, in the case of inequities, right? So if you have inequitable information data that’s already out in the literature or already out in the, you know, media, or what have you, about a certain population or people or certain kinds of ideas or thoughts, etc., then AI will tend to accumulate that. You’re going to take that information, thinking that’s the best out there, but it may have missed out on information and now you go with it. And that’s a potential problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think it’s the same thing on information is that when we have people that are able to classify or misclassify information, I think it really becomes hard because it can accelerate the inequities of trust or inequities of trusted sources of information. It can also close the gap.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think, you know, it’s really up to us and this responsible AI to really think about how we can go about doing this in a way that’s going to allow us to further the advancements but also be careful of those, you know, those kind of places where we’re going to step into that are not going to be well received or successful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, the one thing that’s really fascinating about this whole conversation is that this is why we’ve got to be at the table, Peter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; Because if we’re not at the table, you know, what’s the, you know, or if tech companies that are out there doing this work and aren’t even seeing a field of practitioners that are actually wrestling with the same problems but just cannot actually get to the solutions, we’re just going to continue to accentuate the problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s why I’m a firm proponent of: we’ve got to be at the table.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so even when we’ve seen in, and this is going to be a little controversial, but governmental spaces where, you know, policymakers have said, “Look, we are not going to let you do certain things,” or they say to public health practitioners or even healthcare delivery practitioners in certain spaces, “You cannot even play with this. You cannot have it on your phones. You can’t do any … ”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, what I really believe it does is that it takes [an] almost like we put our head in the sand type of approach rather than saying, “What is it that we can do to help improve AI and make it work for all of us?” What we’re doing is we’re essentially saying, “We’re going to let the tech companies and all the other developers come up with the solutions, but it’s not going to be informed by the people in the field.” And that’s dangerous. We have to do both. We have to be working together.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Umair, that’s really so well said, and I think a great way to wrap things up. I’ve certainly learned a lot from this conversation. So thank you again.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SHAH:&lt;/strong&gt; It’s been a pleasure to be with you this morning. Thank you so much for the time. And I’m looking forward to further conversations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &lt;/p&gt;



&lt;p&gt;I live in the State of Washington and because of that, I’ve been able to watch Umair in action as our state’s former secretary of health. And some of that action was pretty intense to say the least because his tenure as secretary of health spanned the period of the COVID pandemic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, as a dyed-in-the-wool techie, I have to admit that at the beginning, I don’t think I really understood the scope and importance of the field of public health. But as the conversation with Umair showed, it’s really important and it is arguably both an underfunded and underappreciated part of our healthcare system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, public health is also very much an area that’s ripe for advancement and transformation through AI. As Umair explained in our discussion, the core of public health is the idea of population health, the idea of extracting new health insights from signals from population-scale data. And already we’re starting to see AI making a difference.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now here’s my interview with Dr. Gianrico Farrugia.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Gianrico, it’s really great to have you here today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GIANRICO FARRUGIA:&lt;/strong&gt; Peter, thanks for having me. Thanks for making me part of your podcast.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, what I’d like to do in these conversations is, you know, we’ll definitely want to talk about the overall healthcare system, the state of healthcare, and what AI could or might do to help or even hurt all of that. But I always like to start with a sharper focus just on you specifically. And my first question always is, you know, I think people imagine what a hospital or a health system president and CEO does, but not really. And so how would you explain to your mother what you do every day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So, Peter, my mother’s 88 years old. She lives in Malta, and she’s visiting at the moment, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Oh, wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … which is kind of nice, really.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Wow, that is amazing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA: &lt;/strong&gt;I’m proud that she’s still proud of me. So she does ask. I’ll tell her the scope of Mayo Clinic. We serve patients across the globe. We have about 83,000 staff members that work with us, and we’re very proud of the work we do in research, education, and the practice.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Mayo Clinic is built to serve people with serious disease. So what I tell my mother is that here we are. We’re a healthcare organization that knows what it needs to do: keep patients as the North Star. The needs of the patient come first. We have 83,000 people who want to do that, several thousand physicians and scientists. My job is to look slightly ahead and then share what I’m seeing and then, sort of, smooth the way for others to make sure Mayo remains true to its mission but also true to the fact that at the moment, we are in a category of one. We need to remain there not just from an ego standpoint, but really from a “do good to the world” standpoint.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At that point, invariably my mother will tell me that I’m working too hard. [LAUGHTER] And then of course, I change the subject, and I ask her what she cooked today because my mother, who’s 88, cooks for the whole family in Malta, and there are usually four generations eating around the table. So I tell her what she does for the family is what I do for the Mayo family.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Wow, that’s a great way to put it. And it sounds like you actually have a good chance to have some good genes if she’s still that active at age 88.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I think I chose a little more stressful job that may limit [that]. I will tell you very briefly is that one of the AI algorithms we have estimates biological age from an electrocardiogram. My biological age jumped by 3.7 years when I became CEO.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] Oh no.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I’m hoping it will reverse on the other side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;To stick with you just for one more moment here, second question I ask is about your origin story with respect to AI. And typically, for most people, there is AI before ChatGPT and generative AI and then after the generative AI revolution. So can you share a little bit about this? Because it must be the case that you’ve been thinking about this a long time since you’ve really led Mayo Clinic to be so tech forward in this way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Well, I’ve been, as you said, a physician for way too long. I got my MD degree in ’87. So that sort of dates me. But it also means that I saw a lot of the promise for AI that never seemed to pan out for decades and decades and decades like you did.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Around 10 years ago, Mayo could sense that there was something different, that something was changing, that we actually—at that time, predictive AI—could make a big difference. And I think that’s the moment where I and others jumped in and said Mayo Clinic needs to be involved.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then about six years ago, when—six and a half years ago—I became CEO, it was clear that there was the right confluence of data, knowledge, tech expertise, that we could deal with what was increasingly bothering me, which is that we knew what was coming from a technology standpoint and we knew the current healthcare system could not deliver on what patients need and want within that current system. And so the answer is, how could a place like Mayo Clinic with our reputation not jump in and say there has to be a better way of doing things? I’ve always said that it is impossible for me to understand that every single government employee is incompetent. Every physician is greedy. Something’s wrong here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And that wrong was the architecture was wrong. And we knew that we could incorporate AI and make it better. So for me, that journey was one of &lt;em&gt;wait&lt;/em&gt;, &lt;em&gt;wait&lt;/em&gt;, &lt;em&gt;wait&lt;/em&gt;. 10 years ago, begin to jump in. Six years ago, really jump in with our platform. And then, of course, in November 2022, things changed again.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. When did this idea of a data platform, what you now call the Mayo Clinic Platform&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;—by the way, I refer to this as &lt;em&gt;MCP&lt;/em&gt;, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, I know. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] … which I always smirk a little bit because, of course, for those of us in computer science research, the AI research, &lt;em&gt;MCP&lt;/em&gt; has also become quite a hot topic because of the model context protocol version of this. But for Mayo’s MCP, when did that become a serious, defined initiative?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So around the end of ’18, 2018, beginning of 2019. At that point, we knew that we were going to do something differently. We came up with a strategic plan, as I took on the job, that we needed to cure more patients. There’s just not enough cures in the world. There’s too much suffering. And that we had all these chronic diseases that people have accepted are chronic, but really the only reason that disease is chronic is you haven’t cured it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And physicians have been afraid to talk about cure because, of course, eventually everybody passes away.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; But I really pushed hard to say, no, it’s OK to talk about cure. It’s OK to aspire to cure. The second was connect—connecting people with data to create new knowledge. And that’s where it became clear that data were not currently in a format that were particularly useful. By the way, you’ll hear me talk about &lt;em&gt;data&lt;/em&gt; in the singular and the plural. I’m old school. I talk about &lt;em&gt;data&lt;/em&gt; as plural, but I know that most younger people now use &lt;em&gt;data&lt;/em&gt; singular. [LAUGHTER] And I apologize if I’ll go through that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then the third was transform. Let’s use Mayo’s resources to transform healthcare for ourselves and for others. And that’s the concept of, if we are able to use data in a different way, let’s create a different architecture. And that architecture had to be very closely linked to using artificial intelligence in order to create better outcomes for patients. So patients can live not only longer lives but healthier lives. And that’s the genesis of MCP, &lt;em&gt;Mayo Clinic Platform&lt;/em&gt;, so I’ll timestamp that as end of 2018, beginning of 2019.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I’m really wanting to delve in in this episode, in this conversation, you know, [into the] mindset of a health system or hospital CEO. And so you’re obviously thinking about, I guess, machine learning and predictive analytics and so on. What were the, kind of, like … in 2018, what were the outcomes that you were dreaming about from this? So if you had this thing, you know, what were the things that you were hoping to be able to show or, kind of, produce as results?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So first of all, I think all of us who work at Mayo Clinic, and this tends to be a bit sugary, but it’s true, strongly feel that we have a responsibility to leave the place better than when we started. And so the Mayo brothers, when they started, did two really important things. The first was that they created the first integrated healthcare system. And the second, they created the first unified record. And that record was, of course, paper at that point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Part of that is to say, OK, what does it look like now versus how can we improve what we have if … it’d be blasphemy to say, let’s think of ourselves as the Mayo brothers, but let’s think of ourselves as reasonably smart people at Mayo Clinic, really lucky to be surrounded by very smart people with resources. What will we do? And so we said let’s not aim for the low-hanging fruit. Let’s aim to get at whatever you want to call it, the intractable knot, the hardest problem, and that is clinical care. Let’s improve clinical care. Yes, we can deal with burnout. Yes, we can deal with administrative burden. But let’s not focus on that. Let’s really create an architecture that allows us to tackle better clinical outcomes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And by starting there, then everything flows from that. That it’s not really worth doing unless at the end of the day, people are experiencing better health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so I know a very good colleague and friend of mine, John Halamka&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, you ended up hiring. I thought he was a very interesting choice because he is, of course, in terms of technology, quite deep and very expert, but he’s, I think, first and foremost, a doctor. And so I assume you must have had to decide what type of person you would bring in and what kinds of people you would bring in to try to create such a thing. What was your thinking around the choice of someone like John?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; It was one of the harder decisions. First of all, [I’m] a physician myself. We tend to want to maintain some control. And so now I am the CEO, [LAUGHTER] and I have to give this baby to somebody else. That’s very hard. Second is Mayo Clinic is really good because it is flat, and we run a lot by committee. But it also means that, therefore, you have to work really hard at change, and you cannot change by fiat. You have to change by convincing people.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I just … I’ve always made the point that the right change agent is a servant leader because that’s how change becomes embedded. But it also means you’ve got to have that personality, the Mayo personality. And it became clear when we interviewed [that] there were some people that were really hardcore tech; others that were passionate about social issues. But John really fit that of being, as you said, deep in IT but also himself very aligned with the Mayo Clinic values. It’s as if he was a Mayo Clinic physician even though he wasn’t.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that came together, and I felt, &lt;em&gt;we&lt;/em&gt; felt, that as we were hiring, that we could do it. And then we did something interesting. We paired John with a … we created the role of a chief medical officer for the platform, which was a longstanding Mayo Clinic physician. And so we brought them together so we could get the past and the present and the future working together.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I’m going to ask you about what has come out of this. But before that, let’s get back to this origin story. So now, all of that is being set up starting around 2018. But then, you know, in 2022, there is generative AI. Now you were already experimenting with transformers, starting with BERT out of Google there. So maybe that’s a couple of years earlier. But still, there has to come a point where things are feeling very disrupted.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, so, you know, it really wasn’t. It, to me, was a relief because it gave this … we were feeling pretty good about what we’re doing. We were feeling a little impatient, but, in true Mayo fashion, were willing to, sort of, do everything, take its time, take it to the right committees, get the right approvals, and get it done.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so when generative AI came, for us, it’s like, I wouldn’t say we told you so, but it’s like, ah, there you go. Here’s another tool. This is what we’ve been talking about. Now we can do it even better. Now we can move even faster. Now we can do more for our patients. It truly never was disruptive. It truly immediately became enabling, which is strange, right, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … because something as disruptive as that instantly became enabling at Mayo Clinic. And I’ll take … as I think about it with you and take a moment to think and reflect on it, I think there were a couple of decisions we made earlier on that really helped us. We made the decision &lt;em&gt;against&lt;/em&gt; the advice of any consulting firm to completely decentralize AI at Mayo Clinic six years ago. And we told our clinical department, you need to own this. You need to hire basic scientists in AI. We’ll help you by creating the infrastructure. We’ll help you by doing all the rest. We’ll have the compute. We’ll have the partners. You need to do this on your own. You need to treat this the same way as if a new radiological technique happened or a new surgical technique happened.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so there was a lot of expertise already present in a very diffused way that then we were able to layer on generative AI onto that. And we found a very willingness to embrace it. In fact, I would argue initially a bit too willing because as you know, we haven’t quite figured out what’s legitimate use, what’s not use.&amp;nbsp;We all learned together.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yep. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; But it was mostly energy, which is really interesting. It was mostly energy.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Wow. And, you know, it’s an amazing thing to hear because one common theme that we hear is that the initial reaction is oftentimes one of skepticism. In fact, I’ve been very open that even I initially had some skepticism. Was that not present in your mind or on your team’s mind at all at the beginning?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So you’re asking a physician if they are skeptical about something. [LAUGHTER] Yeah. I wonder what the answer to that is. Absolutely. The first hallucination, the first wrong reference. Can you imagine if you write the grant and the wrong reference comes. As you know, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … earlier on when some references were being made up. So massive amounts of skepticism. But the energy was such there that the people [who] were skeptical were also at the same time saying, “Let’s do a RAG [retrieval augmented generation] to clean up those references. Let’s create …” We were experimenting with discharge summaries, but let’s use AI to police AI, and let’s see what’s going on. So there was more massive skepticism, but the energy was pushing that skepticism into a positive versus into a negative frame. Now, I say that summarizing in hindsight.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Day to day, much more complicated than that. But overall, if you just … and remember, I had been at the World Economic Forum many years ago and had said, healthcare needs to run towards AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; If healthcare was perfect, we would wait. Healthcare is not perfect by any means, therefore let’s run and embrace AI. And, sort of, that mentality was part of who we were because at the same time, we were also saying the other thing, that we need to be the ones to lead validation. We need to be the ones that set the rules. We need to be participating in the creation of CHAI [Coalition for Health AI]&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. We need to be participating as the [National] Academy of Medicine&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So people did feel that Mayo was being fairly responsible about it, but that urge to, the needs of the patient come first, was the driver that kept people wanting to say, “Not ready yet, but let’s make it ready.” And we now have 320 algorithms in the practice, and they run and we constantly are looking and seeing what else we can do to improve. But as you well know, things evolve and change. And we’re also looking and seeing which ones work and which ones don’t and which ones we have to work together on to make better.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, you know, of course Mayo has such a, you know, such a reputation and is so influential, but in the world of healthcare broadly, let’s just focus on the United States to start. How common is this experience? You know, so if you are at a meeting with fellow CEOs of hospitals and health systems, what is the attitude and what is the, kind of … how common is the approach to all of this?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; I think it’s more common now, but going back a few years, I think it’s fair to say that it was scary for people to know how it’s going to change things. Healthcare runs on very narrow margins. It’s very expensive. So your expenses and your revenue are both massive, and they are very close to each other. So anything that changes that balance is really scary.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Because it’s not like you have the opportunity to erode into a margin or get it right the second time. So I think that is what drove a lot of the initial hesitancy. Was, one, is lack of knowledge and, two, understanding that you didn’t have a lot of room to make a mistake.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; On the economics of this, when you are embarking on what I suspect is a very expensive initiative like Mayo Clinic Platform, how on earth do you justify that early on?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So again, I’m trying hard to try and remember how things were versus how I think about them now. [LAUGHTER] It goes back to our history. Mayo has always invested in what it thinks is the right thing that is coming. And that’s how we’ve stayed where we are. So the investment really was having an open discussion: is this worth it for our patients? And once that discussion was over, then the board was saying, &lt;em&gt;go&lt;/em&gt;, &lt;em&gt;go&lt;/em&gt;, &lt;em&gt;go&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now we are lucky in that we have the size that we’re able to hire and absorb. We’re lucky in that the people [who] came before us have been financially astute, and one of our values is stewardship. And we’re lucky that we had a lot of patients at Mayo Clinic who were able to listen, be inspired by, and be willing to help support. And so that gave us the ability to build what we’re doing not only into the long-range plan but actually into the yearly plan. And so we built it into the yearly plan. We set up a center for digital health. We set up the platform. And then we set up the budgets to be able to do that. And the budgets came from assets we’ve had, assets that we would get as the year came by, and then from philanthropy.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We also had a really powerful calling card. And that’s one advantage I had, and that’s … and I’d been very open when I was speaking to other CEOs that would use it is that right at that very beginning, really, really in 2019, our cardiologists, both the researchers and the clinicians, had come together and had used electrocardiograms to create an AI algorithm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The first one was for diagnosing from an electrocardiogram, which is very cheap, very easy to do, left ventricular dysfunction. That’s how hard the left part of the heart contracts. If it doesn’t do well, you get heart failure. And they were able to show that that algorithm was already making nurses better than the physician without the algorithm. And after that went on to show that you could do it from a single strip, really with an area under the curve for that single strip on a watch, that was as good as mammograms or pap smears. And so we already had that proof.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; That quickly then came into Mayo. We put it into it so that any patient now can benefit from it. And now there are, I think, 14 algorithms just from that same one.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So we had a proof of concept thanks to those really far-seeing cardiologists that enabled things to happen a little faster and also, as I talked to other CEOs, enabled me to say, “This actually works. This is the path forward.” I have recently been vocal about also saying, we are at a point now where I believe that for some medical conditions, it is not right to not use AI to help treat them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Wow, that’s so interesting. So I think I want to get into another topic here, which is when you think about the use of AI and data, what are some of the results that maybe are top of mind for you or you think are particularly important? And if you don’t mind, I’d like to see if we can think about this not only in terms of results in terms of patient outcomes but in your other activities, core activities, like research, in the education mission, and then even in the broader impacts on the healthcare system. But maybe we start with on patient outcomes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Yeah, they’re all linked, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; They’re part of the same ecosystem. We think of ourselves as three shields— research, education, and the practice—and that one goes into the other. So, as I said, we have about 320 AI algorithms from the practice. Some run on every patient; some run on some patients. And we have good evidence for what they do. So some specific examples, and then I’ll get into the transformer part of this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We have a program called CEDAR [Clinical Detection and Response (tool)], and like most other people, I like acronyms for things. [LAUGHTER] But what it is, in our hospitals with patient consent, we monitor vitals. We monitor in the patient room—not in the ICU [intensive care unit], in the patient room. We monitor all sorts of things. But there’s a camera in the room, and we have a team of intensivists—nurses and physicians—who do not have any patient responsibilities but are just monitoring the algorithms, and when the algorithms are predicting decompensation, they’re able to get into the room. And what we’ve shown, for example, with that algorithm, is we’ve shown we’ve decreased length of stay in the hospital, decreased transfers into the intensive care units, and interestingly, decreased mortality and morbidity, which is not easy to show. I talked about the electrocardiogram as a good example. Of course, everybody knows about the radiology things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We’ve created … taken part of this and said, if we can do this in the hospital, why cannot we do it in patients’ homes? So being very active in looking after patients that would come to the ED, emergency room, would normally be admitted, and we say, no, here are the things we can give you. Go home if you want to, and we will safely look after you at your home. And we recently have been, looking at the last two years of data, been able to show that we’re also successfully able to give intravenous chemotherapy in patients’ homes because we can monitor; we can do all the things that we can do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, with generative AI, that gave us many other opportunities. One biggest opportunity for me has always been digital pathology. When we see how pathology’s currently run with a glass slide, not much has changed …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … in many, many, many years, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And so really we have made a massive push to digitize pathology not just for us but for others. But talking about ourselves, we started by saying, it has to be very cheap to digitize. So we worked and created a company with partners called Pramana&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that allows us to digitize slides relatively cheaply using AI algorithms that can take away the dirt, the fingerprint. And so we end up with 21 million of our slides digitized, and that gives you now a massive opportunity. Worked with another company called Aignostics&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to create a, what we call, Atlas&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which is an LLM that allows us to then build upon it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; And we, a hundred and, I think, 120 years ago, invented frozen sections at Mayo Clinic. So what that is, is that while the patient’s still on the table, you can take a piece of tissue, look at it, and tell the surgeon the margins of what you’re trying to resect are clear or not. But as a result of that, because you have to hurry, you get no information as a surgeon about, is it an invasive cancer, is it noninvasive cancer, or other things. So we’ve just found a way to digitize our frozen section practice and will completely go across the enterprise with AI-enabled digitized frozen sections, which then enables us to then do it for anybody across the globe if we need to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then in the genomic space, we’re working to create a true exomic transformer that is short range. And we originally started doing it to see if we can test it against the fact that 40% of people with rheumatoid arthritis don’t respond to the first-line therapy, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … but you have to wait six months to find out. And we found that we can actually do that. But it has much greater uses, of course.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then we’re working with you—I don’t know how much you want to get into this, Peter, or [if] you want to talk about it yourself—MAIRA-2, which is really exciting, about how taking a simple problem—can you create a transformer that is able to detect if lines on the chest are in the right place, breathing tube is in the right place?—and then do it in a way that then can be used for many, many other things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, Peter, because you asked about education and research, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; … imagine what this does now to the education system, right. And so we’ve got to train our physicians differently. We now have an AI curriculum for all our medical students. We offer masters and PhDs in AI. We think it’s essential for the people who want to be able to truly become experts, the same way I became an expert in my area of research.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then from a research standpoint, when you think about all the registries that exist in people’s labs, all the spatial genomics, all the epigenomics, all the omics that exist. And if you are able to coalesce them into one big, what we call, an &lt;em&gt;atlas&lt;/em&gt;, how that could really spur research at a scale that we haven’t thought of before. And so that is our aim at the moment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;From a research standpoint, we are, with Vijay Shah, who’s our dean of research, is to say, let’s make the effort of making sure all the data are available to be able to use and enable for us to take advantage of AI. And that is not easy because, of course, people have collected the data. They tend to want to embrace it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA: &lt;/strong&gt;So there have to be the right incentives, the right privacy, and the right ways of doing it. And we think we’re on the way there, and we’re already seeing some advantages from doing it this way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So we’re running short on time. And so I always like to end with one or two more provocative questions. And, you know, it’s tempting to ask you the provocative question of whether you think AI will ever replace human doctors, but I don’t want to go there with you. In fact, as I thought about our discussion, I was reflecting. We were at a conference together once, and I was on stage in a fireside chat. And then, you know, after the fireside chat, there were audience questions, and I don’t remember any of the questions from the audience except &lt;em&gt;yours&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And just to remind you, you know, I think when I was on stage, we were talking about a lot of practical uses of AI to, let’s say, reduce administrative burdens and so on in healthcare. But you got up and you, I won’t say you scolded me, but you more or less said, is it the right idea to use AI to optimize today’s somewhat broken healthcare system, or should we be thinking more boldly about, you know, a more fundamental transformation?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so what I thought I would try to close with here is to hear what was really behind that question. You know, what were you trying to get me to think about when you asked that question?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; So first of all, darn your great memory [LAUGHTER]. Belated apologies … I probably should have …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; It was by far the best and most sophisticated and, I think, thought-provoking question of all of the ones that came out of the audience.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; What I was trying to get to is actually trying to clarify it in my own head and then in the head of others is that we do not need to have a linear path to get to where we want to get to. And we seemed to be on a linear path, which is, let’s try and reduce administrative burden. Let’s try and truly be a companion to a physician or other provider. Let’s make their problems better, make them feel better about providing healthcare. And then in the next step, we keep going until we get to, now we can call it agentic AI, whatever we want to talk about. And my view was, &lt;em&gt;no&lt;/em&gt;, is that let’s start with that aim, the last aim, and do the others because the others will come automatically if you’re working on that harder problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Because one, to get to that harder problem, you’ll find all the other solutions. I was just trying to push that here’s this wonderful tool that’s been given to us. Let’s take advantage of it as quickly as we can. I think we had gotten a little too sensitized to need to say the right things. “Careful, be very careful” versus saying, “Massive opportunity. Do it right, and healthcare will be much better. Go for it.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, I think I understand better now where the vision, insight, and frankly, courage to take on something as ambitious and transformational as the Mayo Clinic Platform and really all of your leadership in your tenure as the president and CEO of Mayo Clinic. I think I understand it much better now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Gianrico, it’s just always such a privilege to interact with you and now to have a chance to work with you more closely. So thank you for everything that you do and thank you for joining us today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;FARRUGIA:&lt;/strong&gt; Thank you for making it so easy, and thanks for giving us this opportunity to do good for the world.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Gianrico leads what is arguably the crown jewel of the world’s healthcare systems, and so I feel it’s such a privilege to be able to talk and sometimes even brainstorm with him.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Our conversation, I think, exposed just how tech forward Gianrico is as he charts the strategies for healthcare delivery well into the future. And as I’ve interacted with many others, what I’ve learned is that this is a common trait among major health system CEOs. Roughly speaking, like we’ve seen in previous episodes where doctors and med students are polymath clinician-technologists, the same thing is true of health system CEOs and other leaders.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AI in the mind of a health system CEO today is not only a technology that can transform diagnosis and treatment, but it’s also something that can have a huge impact on the business of healthcare delivery, the connection of healthcare to medical research, and the journeys that patients go through as they seek better health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These two conversations show that virtually all leaders in health and medicine are confronting head-on the opportunities, challenges, and the reality of AI, and they see a future that is potentially very different than what we have today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’d like to thank Umair and Gianrico again for their time and insights. And to our listeners, thank you for joining us. We hope you’ll tune in to our final episode of the series. My coauthors, Carey and Zak, will be back to examine the takeaways from our most recent conversations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Until next time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&amp;nbsp;&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;








&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/reimagining-healthcare-delivery-and-public-health-with-ai/</guid><pubDate>Thu, 07 Aug 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] GPT-5 is here. Now what? (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/07/1121308/gpt-5-is-here-now-what/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/force-multiplied.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;At long last, OpenAI has released GPT-5. The new system abandons the distinction between OpenAI’s flagship models and its o series of reasoning models, automatically routing user queries to a fast nonreasoning model or a slower reasoning version. It is now available to everyone through the ChatGPT web interface—though nonpaying users may need to wait a few days to gain full access to the new capabilities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s tempting to compare GPT-5 with its explicit predecessor, GPT-4, but the more illuminating juxtaposition is with o1, OpenAI’s first reasoning model, which was released last year. In contrast to GPT-5’s broad release, o1 was initially available only to Plus and Team subscribers. Those users got access to a completely new kind of language model—one that would “reason” through its answers by generating additional text before providing a final response, enabling it to solve much more challenging problems than its nonreasoning counterparts.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt;&lt;p&gt;Whereas o1 was a major technological advancement, GPT-5 is, above all else, a refined product. During a press briefing, Sam Altman compared GPT-5 to Apple’s Retina displays, and it’s an apt analogy, though perhaps not in the way that he intended. Much like an unprecedentedly crisp screen, GPT-5 will furnish a more pleasant and seamless user experience. That’s not nothing, but it falls far short of the transformative AI future that Altman has spent much of the past year hyping. In the briefing, Altman called GPT-5 “a significant step along the path to AGI,” or artificial general intelligence, and maybe he’s right—but if so, it’s a very small step.&lt;/p&gt;  &lt;p&gt;Take the demo of the model’s abilities that OpenAI showed to &lt;em&gt;MIT Technology Review&lt;/em&gt; in advance of its release. Yann Dubois, a post-training lead at OpenAI, asked GPT-5 to design a web application that would help his partner learn French so that she could communicate more easily with his family. The model did an admirable job of following his instructions and created an appealing, user-friendly app. But when I gave GPT-4o an almost identical prompt, it produced an app with exactly the same functionality. The only difference is that it wasn’t as aesthetically pleasing.&lt;/p&gt; 
 &lt;p&gt;Some of the other user-experience improvements are more substantial. Having the model rather than the user choose whether to apply reasoning to each query removes a major pain point, especially for users who don’t follow LLM advancements closely.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And, according to Altman, GPT-5 reasons much faster than the o-series models. The fact that OpenAI is releasing it to nonpaying users suggests that it’s also less expensive for the company to run. That’s a big deal: Running powerful models cheaply and quickly is a tough problem, and solving it is key to reducing AI’s environmental impact.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;OpenAI has also taken steps to mitigate hallucinations, which have been a persistent headache. OpenAI’s evaluations suggest that GPT-5 models are substantially less likely to make incorrect claims than their predecessor models, o3 and GPT-4o. If that advancement holds up to scrutiny, it could help pave the way for more reliable and trustworthy agents. “Hallucination can cause real safety and security issues,” says Dawn Song, a professor of computer science at UC Berkeley. For example, an agent that hallucinates software packages could download malicious code to a user’s device.&lt;/p&gt;  &lt;p&gt;GPT-5 has achieved the state of the art on several benchmarks, including a test of agentic abilities and the coding evaluations SWE-Bench and Aider Polyglot. But according to Clémentine Fourrier, an AI researcher at the company HuggingFace, those evaluations are nearing saturation, which means that current models have achieved close to maximal performance.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It’s basically like looking at the performance of a high schooler on middle-grade problems,” she says. “If the high schooler fails, it tells you something, but if it succeeds, it doesn’t tell you a lot.” Fourrier said she would be impressed if the system achieved a score of 80% or 85% on SWE-Bench—but it only managed a 74.9%.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, the headline message from OpenAI is that GPT-5 feels better to use. “The vibes of this model are really good, and I think that people are really going to feel that, especially average people who haven't been spending their time thinking about models,” said Nick Turley, the head of ChatGPT.&lt;/p&gt;  &lt;p&gt;Vibes alone, however, won’t bring about the automated future that Altman has promised. Reasoning felt like a major step forward on the way to AGI. We’re still waiting for the next one.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/force-multiplied.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;At long last, OpenAI has released GPT-5. The new system abandons the distinction between OpenAI’s flagship models and its o series of reasoning models, automatically routing user queries to a fast nonreasoning model or a slower reasoning version. It is now available to everyone through the ChatGPT web interface—though nonpaying users may need to wait a few days to gain full access to the new capabilities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s tempting to compare GPT-5 with its explicit predecessor, GPT-4, but the more illuminating juxtaposition is with o1, OpenAI’s first reasoning model, which was released last year. In contrast to GPT-5’s broad release, o1 was initially available only to Plus and Team subscribers. Those users got access to a completely new kind of language model—one that would “reason” through its answers by generating additional text before providing a final response, enabling it to solve much more challenging problems than its nonreasoning counterparts.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt;&lt;p&gt;Whereas o1 was a major technological advancement, GPT-5 is, above all else, a refined product. During a press briefing, Sam Altman compared GPT-5 to Apple’s Retina displays, and it’s an apt analogy, though perhaps not in the way that he intended. Much like an unprecedentedly crisp screen, GPT-5 will furnish a more pleasant and seamless user experience. That’s not nothing, but it falls far short of the transformative AI future that Altman has spent much of the past year hyping. In the briefing, Altman called GPT-5 “a significant step along the path to AGI,” or artificial general intelligence, and maybe he’s right—but if so, it’s a very small step.&lt;/p&gt;  &lt;p&gt;Take the demo of the model’s abilities that OpenAI showed to &lt;em&gt;MIT Technology Review&lt;/em&gt; in advance of its release. Yann Dubois, a post-training lead at OpenAI, asked GPT-5 to design a web application that would help his partner learn French so that she could communicate more easily with his family. The model did an admirable job of following his instructions and created an appealing, user-friendly app. But when I gave GPT-4o an almost identical prompt, it produced an app with exactly the same functionality. The only difference is that it wasn’t as aesthetically pleasing.&lt;/p&gt; 
 &lt;p&gt;Some of the other user-experience improvements are more substantial. Having the model rather than the user choose whether to apply reasoning to each query removes a major pain point, especially for users who don’t follow LLM advancements closely.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And, according to Altman, GPT-5 reasons much faster than the o-series models. The fact that OpenAI is releasing it to nonpaying users suggests that it’s also less expensive for the company to run. That’s a big deal: Running powerful models cheaply and quickly is a tough problem, and solving it is key to reducing AI’s environmental impact.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;OpenAI has also taken steps to mitigate hallucinations, which have been a persistent headache. OpenAI’s evaluations suggest that GPT-5 models are substantially less likely to make incorrect claims than their predecessor models, o3 and GPT-4o. If that advancement holds up to scrutiny, it could help pave the way for more reliable and trustworthy agents. “Hallucination can cause real safety and security issues,” says Dawn Song, a professor of computer science at UC Berkeley. For example, an agent that hallucinates software packages could download malicious code to a user’s device.&lt;/p&gt;  &lt;p&gt;GPT-5 has achieved the state of the art on several benchmarks, including a test of agentic abilities and the coding evaluations SWE-Bench and Aider Polyglot. But according to Clémentine Fourrier, an AI researcher at the company HuggingFace, those evaluations are nearing saturation, which means that current models have achieved close to maximal performance.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“It’s basically like looking at the performance of a high schooler on middle-grade problems,” she says. “If the high schooler fails, it tells you something, but if it succeeds, it doesn’t tell you a lot.” Fourrier said she would be impressed if the system achieved a score of 80% or 85% on SWE-Bench—but it only managed a 74.9%.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Ultimately, the headline message from OpenAI is that GPT-5 feels better to use. “The vibes of this model are really good, and I think that people are really going to feel that, especially average people who haven't been spending their time thinking about models,” said Nick Turley, the head of ChatGPT.&lt;/p&gt;  &lt;p&gt;Vibes alone, however, won’t bring about the automated future that Altman has promised. Reasoning felt like a major step forward on the way to AGI. We’re still waiting for the next one.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/07/1121308/gpt-5-is-here-now-what/</guid><pubDate>Thu, 07 Aug 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI’s GPT-5 is here (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/07/openais-gpt-5-is-here/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has launched GPT-5, a new flagship AI model that will power the company’s next generation of ChatGPT. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5, which was released Thursday, is OpenAI’s first “unified” AI model and combines the reasoning abilities of its o-series of models with the fast responses of its GPT series. The next-generation model signals a new era for ChatGPT — and its creator, OpenAI — pointing to OpenAI’s broader ambitions to develop AI systems that are more like agents than chatbots.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While GPT-4 enabled AI chatbots to offer smart responses on a wide variety of questions, GPT-5 allows ChatGPT to complete a wide variety of tasks on behalf of users — such as generating software applications, navigating a user’s calendar, or creating research briefs. &lt;/p&gt;&lt;p&gt;With GPT-5, OpenAI has also sought to make ChatGPT simpler to use. Instead of asking users to choose the right settings, GPT-5 comes equipped with a real-time router that decides how to offer the best answer, whether that’s responding to user questions quickly or taking additional time to “think” through answers.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3035064" height="382" src="https://techcrunch.com/wp-content/uploads/2025/08/GPT5-All-Together-16x9-1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;During a briefing with reporters, OpenAI CEO Sam Altman claimed GPT-5 is “the best model in the world,” and said it represented a “significant step” along the company’s path to developing AI that can outperform humans at most economically valuable work — that is, artificial general intelligence (AGI).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Having something like GPT-5 would be pretty much unimaginable at any previous time in history,” said Altman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Starting Thursday, GPT-5 will be available to all free users of ChatGPT as their default model. OpenAI’s VP of ChatGPT, Nick Turley, said this is part of the company’s effort to give free users access to an AI reasoning model for the first time. (Previously, the company gated these more advanced models behind a paywall.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is just one of the ways that I’m excited to live the mission, making sure that this stuff actually benefits people,” said Turley on the decision, referencing OpenAI’s long-standing mission to distribute advanced AI to as many people as possible.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The expectations are high for GPT-5, one of OpenAI’s most anticipated product launches since ChatGPT put the company on the map in 2022. Since then, ChatGPT has grown into one of the world’s most popular consumer products, reaching more than 700 million users every week — nearly 10% of the globe’s population, according to the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many see GPT-5 as a bellwether for AI progress broadly, and the model’s reception by Silicon Valley could have profound implications for Big Tech, Wall Street, and policymakers regulating technology. These stakeholders are watching to see if GPT-5 offers a significant jump in AI’s capabilities, much like its predecessor, GPT-4, which challenged expectations of what software can do.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-gpt-5-offers-a-slight-edge-on-the-competition"&gt;GPT-5 offers a slight edge on the competition&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI claims GPT-5 is state-of-the-art in several domains, slightly edging out leading AI models from Anthropic, Google DeepMind, and Elon Musk’s xAI on key benchmarks. However, GPT-5 slightly underperforms frontier AI models in other areas.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says GPT-5 offers frontier-level performance around coding; Altman said the model specifically excels at spinning up entire software applications on demand, in what’s become known as “vibe coding.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On SWE-bench Verified — a test of real-world coding tasks pulled from GitHub — GPT-5 scores 74.9% on its first attempt. That means GPT-5 just outperforms Anthropic’s latest Claude Opus 4.1 model, which scored 74.5%, and Google DeepMind’s Gemini 2.5 Pro, which scored 59.6%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Humanity’s Last Exam — a difficult test measuring AI model performance across math, humanities, and the natural sciences — a version of GPT-5 with extended reasoning (GPT-5 Pro) scored 42% when using tools. That’s slightly less than xAI was able to achieve with Grok 4 Heavy, which scored 44.4% on the test.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3035062" height="450" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-07-at-12.56.46PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;On GPQA Diamond — a test of PhD-level science questions — GPT-5 pro scored 89.4% on its first try, outperforming Claude Opus 4.1, which scored 80.9%, and Grok 4 Heavy, which scored 88.9%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says GPT-5 is better for answering health-related questions. On a test measuring accuracy in AI model responses around healthcare topics, HealthBench Hard Hallucinations, OpenAI says GPT-5 (with thinking) hallucinates just 1.6% of the time. This is far lower than the company’s previous GPT-4o and o3 models, which scored 12.9% and 15.8, respectively. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI chatbots are not medical professionals, millions of people are using them for health advice. In response to this phenomenon, the company says GPT-5 is more proactive about flagging potential health concerns and helping users parse medical results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, OpenAI says GPT-5 is better than other AI models on more difficult-to-measure, subjective domains, such as creative design and writing. Turley said GPT-5 responds more naturally and exhibits “better taste” than other AI models on creative tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The vibes of this model are really good,” said Turley.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;GPT-5 is also more accurate than OpenAI’s previous models, and the company says it suffers far less from hallucinations — the tendency for AI models to make up information — compared to its o-series models. Hallucinations seemed to be getting worse in OpenAI’s latest AI reasoning models, such as o3, and OpenAI previously said it didn’t quite understand why it was happening.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In responses to ChatGPT prompts, OpenAI found that GPT-5 (with thinking) hallucinates and responds with incorrect information 4.8% of the time. That’s a significant reduction from o3 and GPT-4o, which score hallucination rates of 22% and 20.6%, respectively, on the test.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On a benchmark measuring an AI model’s agentic ability to complete simulated online tasks, Tau-bench, GPT-5 offers mixed performance. On part of the test measuring an AI’s ability to navigate an airline’s website, GPT-5 scores 63.5%, slightly underperforming o3, which scored 64.8%. On another part of the test measuring AI’s ability to navigate retail websites, GPT-5 scores 81.1%, underperforming Claude Opus 4.1, which scored 82.4%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI also says that GPT-5 is safer than its previous models. While AI reasoning models occasionally exhibit a tendency to scheme against humans or lie to promote their own goals, OpenAI found that GPT-5 was deceptive at a lower rate than other models. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alex Beutel, OpenAI’s safety research lead, said reducing deception improves not only the safety of GPT-5, but also the user experience, creating a model that’s more “transparent and honest in ways users can trust.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beutel also notes GPT-5 is better at discerning between bad actors who are trying to misuse ChatGPT and users making harmless requests. This results in GPT-5 being able to refuse more unsafe questions, while offering fewer rejections to users seeking harmless information.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-upgrades-for-consumers-and-developers"&gt;Upgrades for consumers and developers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is getting a few user experience upgrades as part of the GPT-5 launch. Users can now select from four new personalities in ChatGPT’s setting: Cynic, Robot, Listener, and Nerd. The company says these will adapt ChatGPT’s responses without requiring users to specifically ask the model to respond in a certain way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subscribers to ChatGPT’s $20-per-month Plus plan get higher usage limits for GPT-5 than free users. Meanwhile, $200-per-month Pro subscribers will have unlimited access to GPT-5, as well as a souped-up version called GPT-5 Pro that uses additional computational resources to produce better answers. Organizations on OpenAI’s Team, Edu, and Enterprise plans will gain access to GPT-5 as their default model next week.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For developers, GPT-5 is coming to OpenAI’s API in three sizes — gpt-5, gpt-5-mini, and gpt-5-nano — which will spend more or less time “reasoning” through tasks. Developers can also now control verbosity in the OpenAI API, deciding how long or short an AI model’s responses should be.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The base model of GPT-5 will cost developers $1.25 per million input tokens (roughly 750,000 words, longer than the entire “Lord of the Rings” series) and $10 per million output tokens.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of GPT-5 comes after a busy week for OpenAI. The company released an open-weight reasoning model, gpt-oss, that developers and enterprises can download for free and run at a fraction of the cost. The open model nearly matched the abilities of OpenAI’s previous top models, o3 and o4-mini, but GPT-5 sets a new standard for frontier performance in some areas, such as coding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, GPT-5 seems to be roughly on par with other frontier AI models in several areas. Benchmarks, of course, only tell part of the story for any AI model, and it remains to be seen how developers will use GPT-5 in the real world, and whether the model is truly a step above the competition.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has launched GPT-5, a new flagship AI model that will power the company’s next generation of ChatGPT. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5, which was released Thursday, is OpenAI’s first “unified” AI model and combines the reasoning abilities of its o-series of models with the fast responses of its GPT series. The next-generation model signals a new era for ChatGPT — and its creator, OpenAI — pointing to OpenAI’s broader ambitions to develop AI systems that are more like agents than chatbots.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While GPT-4 enabled AI chatbots to offer smart responses on a wide variety of questions, GPT-5 allows ChatGPT to complete a wide variety of tasks on behalf of users — such as generating software applications, navigating a user’s calendar, or creating research briefs. &lt;/p&gt;&lt;p&gt;With GPT-5, OpenAI has also sought to make ChatGPT simpler to use. Instead of asking users to choose the right settings, GPT-5 comes equipped with a real-time router that decides how to offer the best answer, whether that’s responding to user questions quickly or taking additional time to “think” through answers.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3035064" height="382" src="https://techcrunch.com/wp-content/uploads/2025/08/GPT5-All-Together-16x9-1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;During a briefing with reporters, OpenAI CEO Sam Altman claimed GPT-5 is “the best model in the world,” and said it represented a “significant step” along the company’s path to developing AI that can outperform humans at most economically valuable work — that is, artificial general intelligence (AGI).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Having something like GPT-5 would be pretty much unimaginable at any previous time in history,” said Altman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Starting Thursday, GPT-5 will be available to all free users of ChatGPT as their default model. OpenAI’s VP of ChatGPT, Nick Turley, said this is part of the company’s effort to give free users access to an AI reasoning model for the first time. (Previously, the company gated these more advanced models behind a paywall.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is just one of the ways that I’m excited to live the mission, making sure that this stuff actually benefits people,” said Turley on the decision, referencing OpenAI’s long-standing mission to distribute advanced AI to as many people as possible.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The expectations are high for GPT-5, one of OpenAI’s most anticipated product launches since ChatGPT put the company on the map in 2022. Since then, ChatGPT has grown into one of the world’s most popular consumer products, reaching more than 700 million users every week — nearly 10% of the globe’s population, according to the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Many see GPT-5 as a bellwether for AI progress broadly, and the model’s reception by Silicon Valley could have profound implications for Big Tech, Wall Street, and policymakers regulating technology. These stakeholders are watching to see if GPT-5 offers a significant jump in AI’s capabilities, much like its predecessor, GPT-4, which challenged expectations of what software can do.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-gpt-5-offers-a-slight-edge-on-the-competition"&gt;GPT-5 offers a slight edge on the competition&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI claims GPT-5 is state-of-the-art in several domains, slightly edging out leading AI models from Anthropic, Google DeepMind, and Elon Musk’s xAI on key benchmarks. However, GPT-5 slightly underperforms frontier AI models in other areas.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says GPT-5 offers frontier-level performance around coding; Altman said the model specifically excels at spinning up entire software applications on demand, in what’s become known as “vibe coding.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On SWE-bench Verified — a test of real-world coding tasks pulled from GitHub — GPT-5 scores 74.9% on its first attempt. That means GPT-5 just outperforms Anthropic’s latest Claude Opus 4.1 model, which scored 74.5%, and Google DeepMind’s Gemini 2.5 Pro, which scored 59.6%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Humanity’s Last Exam — a difficult test measuring AI model performance across math, humanities, and the natural sciences — a version of GPT-5 with extended reasoning (GPT-5 Pro) scored 42% when using tools. That’s slightly less than xAI was able to achieve with Grok 4 Heavy, which scored 44.4% on the test.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3035062" height="450" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-07-at-12.56.46PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;On GPQA Diamond — a test of PhD-level science questions — GPT-5 pro scored 89.4% on its first try, outperforming Claude Opus 4.1, which scored 80.9%, and Grok 4 Heavy, which scored 88.9%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says GPT-5 is better for answering health-related questions. On a test measuring accuracy in AI model responses around healthcare topics, HealthBench Hard Hallucinations, OpenAI says GPT-5 (with thinking) hallucinates just 1.6% of the time. This is far lower than the company’s previous GPT-4o and o3 models, which scored 12.9% and 15.8, respectively. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI chatbots are not medical professionals, millions of people are using them for health advice. In response to this phenomenon, the company says GPT-5 is more proactive about flagging potential health concerns and helping users parse medical results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, OpenAI says GPT-5 is better than other AI models on more difficult-to-measure, subjective domains, such as creative design and writing. Turley said GPT-5 responds more naturally and exhibits “better taste” than other AI models on creative tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The vibes of this model are really good,” said Turley.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;GPT-5 is also more accurate than OpenAI’s previous models, and the company says it suffers far less from hallucinations — the tendency for AI models to make up information — compared to its o-series models. Hallucinations seemed to be getting worse in OpenAI’s latest AI reasoning models, such as o3, and OpenAI previously said it didn’t quite understand why it was happening.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In responses to ChatGPT prompts, OpenAI found that GPT-5 (with thinking) hallucinates and responds with incorrect information 4.8% of the time. That’s a significant reduction from o3 and GPT-4o, which score hallucination rates of 22% and 20.6%, respectively, on the test.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On a benchmark measuring an AI model’s agentic ability to complete simulated online tasks, Tau-bench, GPT-5 offers mixed performance. On part of the test measuring an AI’s ability to navigate an airline’s website, GPT-5 scores 63.5%, slightly underperforming o3, which scored 64.8%. On another part of the test measuring AI’s ability to navigate retail websites, GPT-5 scores 81.1%, underperforming Claude Opus 4.1, which scored 82.4%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI also says that GPT-5 is safer than its previous models. While AI reasoning models occasionally exhibit a tendency to scheme against humans or lie to promote their own goals, OpenAI found that GPT-5 was deceptive at a lower rate than other models. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alex Beutel, OpenAI’s safety research lead, said reducing deception improves not only the safety of GPT-5, but also the user experience, creating a model that’s more “transparent and honest in ways users can trust.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beutel also notes GPT-5 is better at discerning between bad actors who are trying to misuse ChatGPT and users making harmless requests. This results in GPT-5 being able to refuse more unsafe questions, while offering fewer rejections to users seeking harmless information.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-upgrades-for-consumers-and-developers"&gt;Upgrades for consumers and developers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is getting a few user experience upgrades as part of the GPT-5 launch. Users can now select from four new personalities in ChatGPT’s setting: Cynic, Robot, Listener, and Nerd. The company says these will adapt ChatGPT’s responses without requiring users to specifically ask the model to respond in a certain way.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subscribers to ChatGPT’s $20-per-month Plus plan get higher usage limits for GPT-5 than free users. Meanwhile, $200-per-month Pro subscribers will have unlimited access to GPT-5, as well as a souped-up version called GPT-5 Pro that uses additional computational resources to produce better answers. Organizations on OpenAI’s Team, Edu, and Enterprise plans will gain access to GPT-5 as their default model next week.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For developers, GPT-5 is coming to OpenAI’s API in three sizes — gpt-5, gpt-5-mini, and gpt-5-nano — which will spend more or less time “reasoning” through tasks. Developers can also now control verbosity in the OpenAI API, deciding how long or short an AI model’s responses should be.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The base model of GPT-5 will cost developers $1.25 per million input tokens (roughly 750,000 words, longer than the entire “Lord of the Rings” series) and $10 per million output tokens.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of GPT-5 comes after a busy week for OpenAI. The company released an open-weight reasoning model, gpt-oss, that developers and enterprises can download for free and run at a fraction of the cost. The open model nearly matched the abilities of OpenAI’s previous top models, o3 and o4-mini, but GPT-5 sets a new standard for frontier performance in some areas, such as coding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, GPT-5 seems to be roughly on par with other frontier AI models in several areas. Benchmarks, of course, only tell part of the story for any AI model, and it remains to be seen how developers will use GPT-5 in the real world, and whether the model is truly a step above the competition.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/07/openais-gpt-5-is-here/</guid><pubDate>Thu, 07 Aug 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI launches GPT-5, nano, mini and Pro — not AGI, but capable of generating ‘software-on-demand’ (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/openai-launches-gpt-5-not-agi-but-capable-of-generating-software-on-demand/</link><description>[unable to retrieve full-text content]With safer design, more robust reasoning, expanded developer tooling, and broad user access, GPT-5 reflects a maturing AI ecosystem.</description><content:encoded>[unable to retrieve full-text content]With safer design, more robust reasoning, expanded developer tooling, and broad user access, GPT-5 reflects a maturing AI ecosystem.</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openai-launches-gpt-5-not-agi-but-capable-of-generating-software-on-demand/</guid><pubDate>Thu, 07 Aug 2025 17:01:10 +0000</pubDate></item><item><title>[NEW] OpenAI launches GPT-5 free to all ChatGPT users (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/openai-launches-gpt-5-free-to-all-chatgpt-users/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New model claims fewer confabulations, better coding, and "safe completions" approach.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="GPT-5 header" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/gpt-5-640x360.jpg" width="640" /&gt;
                  &lt;img alt="GPT-5 header" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/gpt-5-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Thursday, OpenAI announced GPT-5 and three variants—GPT-5 Pro, GPT-5 mini, and GPT-5 nano—what the company calls its "best AI system yet," with availability for some of the models across all ChatGPT tiers, including free users. The new model family arrives with claims of reduced confabulations, improved coding capabilities, and a new approach to handling sensitive requests that OpenAI calls "safe completions."&lt;/p&gt;
&lt;p&gt;It's also the first time OpenAI has given free users access to a simulated reasoning AI model, which breaks problems down into multiple steps using a technique that tends to improve answer accuracy for logical or analytical questions.&lt;/p&gt;
&lt;p&gt;GPT-5 represents OpenAI's latest attempt to unify its various AI capabilities into a single system. The company says the GPT-5 family acts as a "unified system" with a smart, efficient model that answers most questions, a deeper reasoning model called "GPT-5 thinking" for harder problems, and a real-time router that decides which approach to use based on conversation type, complexity, tool needs, and user intent. Like GPT-4o, GPT-5 is a multimodal system that can interact via images, voice, and text.&lt;/p&gt;
&lt;p&gt;The rollout starts today, extending to ChatGPT's 700 million weekly active users, with varying usage limits based on subscription tier. Pro subscribers will receive unlimited access to GPT-5 and the GPT-5 Pro variant, while Plus users receive "significantly higher usage limits" compared to free users, according to a statement from OpenAI. GPT-5 Pro is replacing o3-pro in ChatGPT for those subscriber tiers with access to it.&lt;/p&gt;
&lt;h2&gt;Technical improvements and new features&lt;/h2&gt;
&lt;p&gt;Since the launch of GPT-4 in 2023, we've seen a trend of relative diminishing returns in terms of jumps in capability between major AI model releases. In that sense, the jump in contextual processing capability between GPT-3 and GPT-4 felt shockingly large. The jump between GPT-4 (if you consider the original 2023 version) and GPT-5 is still significant, but when you consider intermediate releases like GPT-4o, GPT-4.5, GPT-4.1, and o3-pro, GPT-5 feels like an incremental upgrade that is unlikely to shock anyone.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;We've written about how OpenAI almost used the name "GPT-5" for models like o1 last year but decided to save it for a future release. Why these new models met that branding threshold is unclear, but the "GPT-5" name brand recognition will likely give OpenAI a boost in the public eye amid a heavily competitive industry.&lt;/p&gt;
&lt;p&gt;Among the claimed improvements, OpenAI says GPT-5 delivers its "strongest coding model yet," achieving 74.9 percent on SWE-bench Verified and 88 percent on Aider Polyglot benchmarks. (To compare, earlier this week, Anthropic released Claude Opus 4.1, which reportedly scored 74.5 percent on SWE-bench.) GPT-5 can reportedly complete "complex coding tasks end-to-end with minimal prompting" and create software interface designs for users without coding experience.&lt;/p&gt;
&lt;p&gt;For health-related queries, OpenAI positions, once again, GPT-5 as its "best model yet," scoring 46.2 percent on HealthBench Hard (a benchmark invented by OpenAI), though the company includes a disclaimer that "ChatGPT does not replace a medical professional." The model can reportedly help users understand medical results and prepare questions for health care providers, though it's best not to blindly trust the outputs of an AI model, because all AI language models, being predictive models tuned for user engagement, tend to tell people what they want to hear.&lt;/p&gt;
&lt;p&gt;In other performance metrics, GPT-5 reportedly achieves 94.6 percent on AIME 2025 for mathematics without tools and 84.2 percent on MMMU for multimodal understanding. And with GPT-5 Pro's extended reasoning, it sets a new state-of-the-art on GPQA at 88.4 percent without tools. OpenAI claims GPT-5 with "thinking" performs better than OpenAI o3 with 50–80 percent lower output tokens across various capabilities.&lt;/p&gt;
&lt;p&gt;GPT-5 reportedly shows significant improvements in accuracy. With web search enabled, GPT-5's responses appear to be around 45 percent less likely to contain factual errors (confabulations) than GPT-4o, and when "thinking," about 80 percent less likely to contain factual errors than o3. On long-form content benchmarks, GPT-5 with thinking shows about six times fewer confabulations than o3. Of course, AI models will fill in gaps in their "knowledge" using plausible-sounding information, so it's best not to rely on their outputs if you cannot check them yourself.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;ChatGPT is also getting interface updates, including customizable chat colors, preset conversation "personalities" (with options like "Cynic," "Robot," "Listener," and "Nerd") that alter the system prompt, and integration with Gmail, Google Calendar, and Google Contacts for Pro users. The voice mode is being unified into a single "Advanced Voice" system that OpenAI says better understands user instructions and adapts its speaking style.&lt;/p&gt;
&lt;p&gt;Meanwhile, the company's approach to response censorship has shifted with what it calls "safe completions." Rather than refusing requests outright, GPT-5 attempts to provide "the most helpful response as possible within safety boundaries," according to OpenAI's announcement. When the model cannot assist with a request, it provides explanations for its limitations.&lt;/p&gt;
&lt;p&gt;OpenAI has also addressed previous issues with sycophancy. Earlier this year, an update to GPT-4o unintentionally made the model overly flattering or agreeable. Through new evaluations and improved training, GPT-5 has reportedly reduced sycophantic replies from 14.5 percent to less than 6 percent in targeted evaluations. Time will tell if this will help reduce the recent streak of triggering delusional and manic behaviors in some people.&lt;/p&gt;
&lt;p&gt;We have not done much hands-on testing with GPT-5 yet but will likely evaluate its performance in more detail in a future article.&lt;/p&gt;
&lt;h2&gt;Developer access and pricing&lt;/h2&gt;
&lt;p&gt;For developers, GPT-5 comes in three API versions: gpt-5, gpt-5-mini, and gpt-5-nano, each offering different latency and cost trade-offs. The context window has expanded to 256,000 tokens, up from 200,000 in OpenAI's previous o3 model. Developers who require larger context windows can still use GPT-4.1 with its 1 million token capacity.&lt;/p&gt;
&lt;p&gt;API pricing for GPT-5 is $1.25 per million input tokens with a 90 percent cache discount and $10 per million output tokens. It's somewhat comparable to GPT-4.1 ($2 input/$8 output per million tokens) and o3 ($2 input/$8 output per million tokens). GPT-5 Mini offers a more economical option at $0.25 per million input tokens and $2 per million output tokens, while GPT-5 Nano provides the most cost-effective but least-capable tier at just $0.05 per million input tokens and $0.40 per million output tokens. GPT-5 Pro pricing hasn't been announced yet for API access.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;New developer features include "free-form function calling" that allows sending raw strings like SQL commands directly to tools without JSON formatting, verbosity controls for response detail, and "reasoning effort control" that lets developers toggle between fast responses and deeper analysis.&lt;/p&gt;
&lt;h2&gt;GPT-5 rollout details&lt;/h2&gt;
&lt;p&gt;The GPT-5 launch comes as OpenAI faces increasing competition from Google's Gemini models, Anthropic's Claude family, and Meta's open-weight Llama models. OpenAI reports having 5 million paying business users and 4 million developers building on its API platform.&lt;/p&gt;
&lt;p&gt;GPT-5 replaces GPT-4o, OpenAI o3, OpenAI o4-mini, GPT-4.1, and GPT-4.5 as the default model for signed-in ChatGPT users. The system automatically applies simulated reasoning when responses would benefit from it, though paid users can still select "GPT-5 Thinking" from the model picker or add phrases like "think hard about this" to ensure reasoning is used.&lt;/p&gt;
&lt;p&gt;The model begins rolling out on Thursday to all user tiers, with enterprise and education customers receiving access next week. OpenAI plans to retire its Standard Voice Mode within 30 days as part of the transition to the unified Advanced Voice system. Once free users reach their GPT-5 usage limits, they transition to GPT-5 mini, a smaller, faster model.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This is a breaking news story that will be updated over time.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;


  &lt;div class="listing-credit my-2"&gt;
    &lt;p class="text-gray-350 font-impact text-sm font-semibold"&gt;
    Listing image:
    OpenAI / Benj Edwards
  &lt;/p&gt;
  &lt;/div&gt;




  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New model claims fewer confabulations, better coding, and "safe completions" approach.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="GPT-5 header" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/gpt-5-640x360.jpg" width="640" /&gt;
                  &lt;img alt="GPT-5 header" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/gpt-5-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Thursday, OpenAI announced GPT-5 and three variants—GPT-5 Pro, GPT-5 mini, and GPT-5 nano—what the company calls its "best AI system yet," with availability for some of the models across all ChatGPT tiers, including free users. The new model family arrives with claims of reduced confabulations, improved coding capabilities, and a new approach to handling sensitive requests that OpenAI calls "safe completions."&lt;/p&gt;
&lt;p&gt;It's also the first time OpenAI has given free users access to a simulated reasoning AI model, which breaks problems down into multiple steps using a technique that tends to improve answer accuracy for logical or analytical questions.&lt;/p&gt;
&lt;p&gt;GPT-5 represents OpenAI's latest attempt to unify its various AI capabilities into a single system. The company says the GPT-5 family acts as a "unified system" with a smart, efficient model that answers most questions, a deeper reasoning model called "GPT-5 thinking" for harder problems, and a real-time router that decides which approach to use based on conversation type, complexity, tool needs, and user intent. Like GPT-4o, GPT-5 is a multimodal system that can interact via images, voice, and text.&lt;/p&gt;
&lt;p&gt;The rollout starts today, extending to ChatGPT's 700 million weekly active users, with varying usage limits based on subscription tier. Pro subscribers will receive unlimited access to GPT-5 and the GPT-5 Pro variant, while Plus users receive "significantly higher usage limits" compared to free users, according to a statement from OpenAI. GPT-5 Pro is replacing o3-pro in ChatGPT for those subscriber tiers with access to it.&lt;/p&gt;
&lt;h2&gt;Technical improvements and new features&lt;/h2&gt;
&lt;p&gt;Since the launch of GPT-4 in 2023, we've seen a trend of relative diminishing returns in terms of jumps in capability between major AI model releases. In that sense, the jump in contextual processing capability between GPT-3 and GPT-4 felt shockingly large. The jump between GPT-4 (if you consider the original 2023 version) and GPT-5 is still significant, but when you consider intermediate releases like GPT-4o, GPT-4.5, GPT-4.1, and o3-pro, GPT-5 feels like an incremental upgrade that is unlikely to shock anyone.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;We've written about how OpenAI almost used the name "GPT-5" for models like o1 last year but decided to save it for a future release. Why these new models met that branding threshold is unclear, but the "GPT-5" name brand recognition will likely give OpenAI a boost in the public eye amid a heavily competitive industry.&lt;/p&gt;
&lt;p&gt;Among the claimed improvements, OpenAI says GPT-5 delivers its "strongest coding model yet," achieving 74.9 percent on SWE-bench Verified and 88 percent on Aider Polyglot benchmarks. (To compare, earlier this week, Anthropic released Claude Opus 4.1, which reportedly scored 74.5 percent on SWE-bench.) GPT-5 can reportedly complete "complex coding tasks end-to-end with minimal prompting" and create software interface designs for users without coding experience.&lt;/p&gt;
&lt;p&gt;For health-related queries, OpenAI positions, once again, GPT-5 as its "best model yet," scoring 46.2 percent on HealthBench Hard (a benchmark invented by OpenAI), though the company includes a disclaimer that "ChatGPT does not replace a medical professional." The model can reportedly help users understand medical results and prepare questions for health care providers, though it's best not to blindly trust the outputs of an AI model, because all AI language models, being predictive models tuned for user engagement, tend to tell people what they want to hear.&lt;/p&gt;
&lt;p&gt;In other performance metrics, GPT-5 reportedly achieves 94.6 percent on AIME 2025 for mathematics without tools and 84.2 percent on MMMU for multimodal understanding. And with GPT-5 Pro's extended reasoning, it sets a new state-of-the-art on GPQA at 88.4 percent without tools. OpenAI claims GPT-5 with "thinking" performs better than OpenAI o3 with 50–80 percent lower output tokens across various capabilities.&lt;/p&gt;
&lt;p&gt;GPT-5 reportedly shows significant improvements in accuracy. With web search enabled, GPT-5's responses appear to be around 45 percent less likely to contain factual errors (confabulations) than GPT-4o, and when "thinking," about 80 percent less likely to contain factual errors than o3. On long-form content benchmarks, GPT-5 with thinking shows about six times fewer confabulations than o3. Of course, AI models will fill in gaps in their "knowledge" using plausible-sounding information, so it's best not to rely on their outputs if you cannot check them yourself.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;ChatGPT is also getting interface updates, including customizable chat colors, preset conversation "personalities" (with options like "Cynic," "Robot," "Listener," and "Nerd") that alter the system prompt, and integration with Gmail, Google Calendar, and Google Contacts for Pro users. The voice mode is being unified into a single "Advanced Voice" system that OpenAI says better understands user instructions and adapts its speaking style.&lt;/p&gt;
&lt;p&gt;Meanwhile, the company's approach to response censorship has shifted with what it calls "safe completions." Rather than refusing requests outright, GPT-5 attempts to provide "the most helpful response as possible within safety boundaries," according to OpenAI's announcement. When the model cannot assist with a request, it provides explanations for its limitations.&lt;/p&gt;
&lt;p&gt;OpenAI has also addressed previous issues with sycophancy. Earlier this year, an update to GPT-4o unintentionally made the model overly flattering or agreeable. Through new evaluations and improved training, GPT-5 has reportedly reduced sycophantic replies from 14.5 percent to less than 6 percent in targeted evaluations. Time will tell if this will help reduce the recent streak of triggering delusional and manic behaviors in some people.&lt;/p&gt;
&lt;p&gt;We have not done much hands-on testing with GPT-5 yet but will likely evaluate its performance in more detail in a future article.&lt;/p&gt;
&lt;h2&gt;Developer access and pricing&lt;/h2&gt;
&lt;p&gt;For developers, GPT-5 comes in three API versions: gpt-5, gpt-5-mini, and gpt-5-nano, each offering different latency and cost trade-offs. The context window has expanded to 256,000 tokens, up from 200,000 in OpenAI's previous o3 model. Developers who require larger context windows can still use GPT-4.1 with its 1 million token capacity.&lt;/p&gt;
&lt;p&gt;API pricing for GPT-5 is $1.25 per million input tokens with a 90 percent cache discount and $10 per million output tokens. It's somewhat comparable to GPT-4.1 ($2 input/$8 output per million tokens) and o3 ($2 input/$8 output per million tokens). GPT-5 Mini offers a more economical option at $0.25 per million input tokens and $2 per million output tokens, while GPT-5 Nano provides the most cost-effective but least-capable tier at just $0.05 per million input tokens and $0.40 per million output tokens. GPT-5 Pro pricing hasn't been announced yet for API access.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;New developer features include "free-form function calling" that allows sending raw strings like SQL commands directly to tools without JSON formatting, verbosity controls for response detail, and "reasoning effort control" that lets developers toggle between fast responses and deeper analysis.&lt;/p&gt;
&lt;h2&gt;GPT-5 rollout details&lt;/h2&gt;
&lt;p&gt;The GPT-5 launch comes as OpenAI faces increasing competition from Google's Gemini models, Anthropic's Claude family, and Meta's open-weight Llama models. OpenAI reports having 5 million paying business users and 4 million developers building on its API platform.&lt;/p&gt;
&lt;p&gt;GPT-5 replaces GPT-4o, OpenAI o3, OpenAI o4-mini, GPT-4.1, and GPT-4.5 as the default model for signed-in ChatGPT users. The system automatically applies simulated reasoning when responses would benefit from it, though paid users can still select "GPT-5 Thinking" from the model picker or add phrases like "think hard about this" to ensure reasoning is used.&lt;/p&gt;
&lt;p&gt;The model begins rolling out on Thursday to all user tiers, with enterprise and education customers receiving access next week. OpenAI plans to retire its Standard Voice Mode within 30 days as part of the transition to the unified Advanced Voice system. Once free users reach their GPT-5 usage limits, they transition to GPT-5 mini, a smaller, faster model.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This is a breaking news story that will be updated over time.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;


  &lt;div class="listing-credit my-2"&gt;
    &lt;p class="text-gray-350 font-impact text-sm font-semibold"&gt;
    Listing image:
    OpenAI / Benj Edwards
  &lt;/p&gt;
  &lt;/div&gt;




  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/openai-launches-gpt-5-free-to-all-chatgpt-users/</guid><pubDate>Thu, 07 Aug 2025 17:48:57 +0000</pubDate></item></channel></rss>