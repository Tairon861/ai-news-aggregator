<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 11 Sep 2025 18:25:45 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Texas banned lab-grown meat. What’s next for the industry? (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/11/1123512/texas-lab-grown-meat/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/WT27.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Last week, a legal battle over lab-grown meat kicked off in Texas. On September 1, a two-year ban on the technology went into effect across the state; the following day, two companies filed a lawsuit against state officials.&lt;/p&gt;  &lt;p&gt;The two companies, Wildtype Foods and Upside Foods, are part of a growing industry that aims to bring new types of food to people’s plates. These products, often called cultivated meat by the industry, take live animal cells and grow them in the lab to make food products without the need to slaughter animals.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Texas joins six other US states and the country of Italy in banning these products. &lt;strong&gt;These legal challenges are adding barriers to an industry that’s still in its infancy and already faces plenty of challenges before it can reach consumers in a meaningful way.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The agriculture sector makes up a hefty chunk of global greenhouse-gas emissions, with livestock alone accounting for somewhere between 10% and 20% of climate pollution. Alternative meat products, including those grown in a lab, could help cut the greenhouse gases from agriculture.&lt;/p&gt; 
 &lt;p&gt;The industry is still in its early days, though. In the US, just a handful of companies can legally sell products including cultivated chicken, pork fat, and salmon. Australia, Singapore, and Israel also allow a few companies to sell within their borders.&lt;/p&gt;  &lt;p&gt;Upside Foods, which makes cultivated chicken, was one of the first to receive the legal go-ahead to sell its products in the US, in 2022. Wildtype Foods, one of the latest additions to the US market, was able to start selling its cultivated salmon in June.&lt;/p&gt; 
 &lt;p&gt;Upside, Wildtype, and other cultivated-meat companies are still working to scale up production. Products are generally available at pop-up events or on special menus at high-end restaurants. (I visited San Francisco to try Upside’s cultivated chicken at a Michelin-starred restaurant a few years ago.)&lt;/p&gt;  &lt;p&gt;Until recently, the only place you could reliably find lab-grown meat in Texas was a sushi restaurant in Austin. Otoko featured Wildtype’s cultivated salmon on a special tasting menu starting in July. (The chef told local publication Culture Map Austin that the cultivated fish tastes like wild salmon, and it was included in a dish with grilled yellowtail to showcase it side-by-side with another type of fish.)&lt;/p&gt;  &lt;p&gt;The as-yet-limited reach of lab-grown meat didn’t stop state officials from moving to ban the technology, effective from now until September 2027.&lt;/p&gt;  &lt;p&gt;The office of state senator Charles Perry, the author of the bill, didn’t respond to requests for comment. Neither did the Texas and Southwestern Cattle Raisers Association, whose president, Carl Ray Polk Jr., testified in support of the bill in a March committee hearing.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;“The introduction of lab-grown meat could disrupt traditional livestock markets, affecting rural communities and family farms,” Perry said during the meeting.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;In an interview with the &lt;em&gt;Texas Tribune&lt;/em&gt;, Polk said the two-year moratorium would help the industry put checks and balances in place before the products could be sold. He also expressed concern about how clearly cultivated-meat companies will be labeling their products.&lt;/p&gt;  &lt;p&gt;“The purpose of these bans is to try to kill the cultivated-meat industry before it gets off the ground,” said Myra Pasek, general counsel of Upside Foods, via email. The company is working to scale up its manufacturing and get the product on the market, she says, “but that can't happen if we’re not allowed to compete in the marketplace.”&lt;/p&gt;  &lt;p&gt;Others in the industry have similar worries. “Moratoriums on sale like this not only deny Texans new choices and economic growth, but they also send chilling signals to researchers and entrepreneurs across the country,” said Pepin Andrew Tuma, the vice president of policy and government relations for the Good Food Institute, a nonprofit think tank focused on alternative proteins, in a statement. (The group isn’t involved in the lawsuit.)&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;One day after the moratorium took effect on September 1, Wildtype Foods and Upside Foods filed a lawsuit challenging the ban, naming Jennifer Shuford, commissioner of the Texas Department of State Health Services, among other state officials.&lt;/p&gt;  &lt;p&gt;A lawsuit wasn’t necessarily part of the scale-up plan. “This was really a last resort for us,” says Justin Kolbeck, cofounder and CEO of Wildtype.&lt;/p&gt;  &lt;p&gt;Growing cells to make meat in the lab isn’t easy—some companies have spent a decade or more trying to make significant amounts of a product that people want to eat. These legal battles certainly aren’t going to help.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/WT27.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Last week, a legal battle over lab-grown meat kicked off in Texas. On September 1, a two-year ban on the technology went into effect across the state; the following day, two companies filed a lawsuit against state officials.&lt;/p&gt;  &lt;p&gt;The two companies, Wildtype Foods and Upside Foods, are part of a growing industry that aims to bring new types of food to people’s plates. These products, often called cultivated meat by the industry, take live animal cells and grow them in the lab to make food products without the need to slaughter animals.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Texas joins six other US states and the country of Italy in banning these products. &lt;strong&gt;These legal challenges are adding barriers to an industry that’s still in its infancy and already faces plenty of challenges before it can reach consumers in a meaningful way.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;The agriculture sector makes up a hefty chunk of global greenhouse-gas emissions, with livestock alone accounting for somewhere between 10% and 20% of climate pollution. Alternative meat products, including those grown in a lab, could help cut the greenhouse gases from agriculture.&lt;/p&gt; 
 &lt;p&gt;The industry is still in its early days, though. In the US, just a handful of companies can legally sell products including cultivated chicken, pork fat, and salmon. Australia, Singapore, and Israel also allow a few companies to sell within their borders.&lt;/p&gt;  &lt;p&gt;Upside Foods, which makes cultivated chicken, was one of the first to receive the legal go-ahead to sell its products in the US, in 2022. Wildtype Foods, one of the latest additions to the US market, was able to start selling its cultivated salmon in June.&lt;/p&gt; 
 &lt;p&gt;Upside, Wildtype, and other cultivated-meat companies are still working to scale up production. Products are generally available at pop-up events or on special menus at high-end restaurants. (I visited San Francisco to try Upside’s cultivated chicken at a Michelin-starred restaurant a few years ago.)&lt;/p&gt;  &lt;p&gt;Until recently, the only place you could reliably find lab-grown meat in Texas was a sushi restaurant in Austin. Otoko featured Wildtype’s cultivated salmon on a special tasting menu starting in July. (The chef told local publication Culture Map Austin that the cultivated fish tastes like wild salmon, and it was included in a dish with grilled yellowtail to showcase it side-by-side with another type of fish.)&lt;/p&gt;  &lt;p&gt;The as-yet-limited reach of lab-grown meat didn’t stop state officials from moving to ban the technology, effective from now until September 2027.&lt;/p&gt;  &lt;p&gt;The office of state senator Charles Perry, the author of the bill, didn’t respond to requests for comment. Neither did the Texas and Southwestern Cattle Raisers Association, whose president, Carl Ray Polk Jr., testified in support of the bill in a March committee hearing.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;“The introduction of lab-grown meat could disrupt traditional livestock markets, affecting rural communities and family farms,” Perry said during the meeting.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;In an interview with the &lt;em&gt;Texas Tribune&lt;/em&gt;, Polk said the two-year moratorium would help the industry put checks and balances in place before the products could be sold. He also expressed concern about how clearly cultivated-meat companies will be labeling their products.&lt;/p&gt;  &lt;p&gt;“The purpose of these bans is to try to kill the cultivated-meat industry before it gets off the ground,” said Myra Pasek, general counsel of Upside Foods, via email. The company is working to scale up its manufacturing and get the product on the market, she says, “but that can't happen if we’re not allowed to compete in the marketplace.”&lt;/p&gt;  &lt;p&gt;Others in the industry have similar worries. “Moratoriums on sale like this not only deny Texans new choices and economic growth, but they also send chilling signals to researchers and entrepreneurs across the country,” said Pepin Andrew Tuma, the vice president of policy and government relations for the Good Food Institute, a nonprofit think tank focused on alternative proteins, in a statement. (The group isn’t involved in the lawsuit.)&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;One day after the moratorium took effect on September 1, Wildtype Foods and Upside Foods filed a lawsuit challenging the ban, naming Jennifer Shuford, commissioner of the Texas Department of State Health Services, among other state officials.&lt;/p&gt;  &lt;p&gt;A lawsuit wasn’t necessarily part of the scale-up plan. “This was really a last resort for us,” says Justin Kolbeck, cofounder and CEO of Wildtype.&lt;/p&gt;  &lt;p&gt;Growing cells to make meat in the lab isn’t easy—some companies have spent a decade or more trying to make significant amounts of a product that people want to eat. These legal battles certainly aren’t going to help.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/11/1123512/texas-lab-grown-meat/</guid><pubDate>Thu, 11 Sep 2025 08:00:00 +0000</pubDate></item><item><title>[NEW] The Download: Trump’s impact on science, and meet our climate and energy honorees (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/11/1123534/the-download-trumps-impact-on-science-and-meet-our-climate-and-energy-honorees/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How Trump’s policies are affecting early-career scientists—in their own words&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Every year MIT Technology Review celebrates accomplished young scientists, entrepreneurs, and inventors from around the world in our Innovators Under 35 list. We’ve just published the 2025 edition. This year, though, the context is different: The US scientific community is under attack.&lt;/p&gt;&lt;p&gt;Since Donald Trump took office in January, his administration has fired top government scientists, targeted universities and academia, and made substantial funding cuts to the country’s science and technology infrastructure.&lt;/p&gt;  &lt;p&gt;We asked our six most recent cohorts about both positive and negative impacts of the administration’s new policies. Their responses provide a glimpse into the complexities of building labs, companies, and careers in today’s political climate. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Eileen Guo &amp;amp; Amy Nordrum&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is part of MIT Technology Review’s "America Undone” series, examining how the foundations of US success in science and innovation are currently under threat. &lt;/strong&gt;&lt;strong&gt;You can read the rest here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This Ethiopian entrepreneur is reinventing ammonia production&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;In the small town in Ethiopia where he grew up, Iwnetim Abate’s family had electricity, but it was unreliable. So, for several days each week when they were without power, Abate would finish his homework by candlelight.&lt;/p&gt;  &lt;p&gt;Growing up without the access to electricity that many people take for granted shaped the way Abate thinks about energy issues. Today, the 32-year old is an assistant professor at MIT in the department of materials science and engineering.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Part of his research focuses on sodium-ion batteries, which could be cheaper than the lithium-based ones that typically power electric vehicles and grid installations. He’s also pursuing a new research path, examining how to harness the heat and pressure under the Earth’s surface to make ammonia, a chemical used in fertilizer and as a green fuel. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Abate is one of the climate and energy honorees on our 35 Innovators Under 35 list for 2025. Meet the rest of our climate and energy innovators &lt;/strong&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;strong&gt;, and the full list—including our innovator of the year—&lt;/strong&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;strong&gt;.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Texas banned lab-grown meat. What’s next for the industry?&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;Last week, a legal battle over lab-grown meat kicked off in Texas. On September 1, a two-year ban on the technology went into effect across the state; the following day, two companies filed a lawsuit against state officials.&lt;/p&gt;  &lt;p&gt;The two companies, Wildtype Foods and Upside Foods, are part of a growing industry that aims to bring new types of food to people’s plates. These products, often called cultivated meat by the industry, take live animal cells and grow them in the lab to make food products without the need to slaughter animals.&lt;/p&gt;&lt;p&gt;Texas joins six other US states and the country of Italy in banning these products—adding barriers to an industry that’s still in its infancy, and already faces plenty of challenges before it can reach consumers in a meaningful way. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Videos of Charlie Kirk’s shooting are everywhere on social media&lt;br /&gt;&lt;/strong&gt;It demonstrates just how poorly equipped platforms are to stop the spread of violent material. (NYT $)&lt;br /&gt;+ &lt;em&gt;Why social media can’t get on top of its graphic video problem. &lt;/em&gt;(NY Mag $)&lt;br /&gt;+ &lt;em&gt;Here’s how platforms say they’ll treat the videos. &lt;/em&gt;(The Verge)&lt;br /&gt;+ &lt;em&gt;Far-right communities reacted to Kirk’s murder by calling for more violence. &lt;/em&gt;(Wired $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;2 NASA has uncovered the clearest sign of life on Mars to date&lt;/strong&gt;&lt;br /&gt;Some unusual rocks may have been formed by ancient microbes. (WP $)&lt;br /&gt;+ &lt;em&gt;Scientists are very excited by the possibility they were created by living organisms. &lt;/em&gt;(New Scientist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 A California bill to regulate AI companion chatbots is close to passing&lt;br /&gt;&lt;/strong&gt;It would become the first US state to make chatbot operators legally accountable. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;Wall Street is only now starting to worry about “AI psychosis.” &lt;/em&gt;(Insider $)&lt;br /&gt;+ &lt;em&gt;AI companions are the final stage of digital addiction, and lawmakers are taking aim. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4 Larry Ellison briefly overtook Elon Musk as the world’s richest person&lt;/strong&gt;&lt;br /&gt;His firm Oracle reported far better-than expected results. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Oracle is riding high on a surge of demand for its data centers. &lt;/em&gt;(BBC)&lt;br /&gt;+ &lt;em&gt;But its continued success will depend on its ability to deliver promised hardware. &lt;/em&gt;(FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5&lt;/strong&gt; &lt;strong&gt;The ousted CDC director is set to testify before the US Senate&lt;/strong&gt;&lt;br /&gt;RFK Jr repeatedly called Susan Monarez a liar during a hearing last week. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;The backlash to Kennedy’s actions is intensifying. &lt;/em&gt;(NY Mag $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;6 A new system can pinpoint the best spot to hit an asteroid&lt;br /&gt;&lt;/strong&gt;Making destroying them a whole lot safer, in theory. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Meet the researchers testing the “Armageddon” approach to asteroid defense. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Saudi Arabia is building some of the world’s biggest solar farms &lt;/strong&gt;&lt;strong&gt;☀️&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;It needs plenty more electricity for its new resorts and data centers. (WSJ $)&lt;br /&gt;+ &lt;em&gt;AI is changing the grid. Could it help more than it harms? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 CRISPR could help to combat diabetes&lt;br /&gt;&lt;/strong&gt;Scientists successfully implanted insulin-producing edited cells into a man’s pancreas. (Wired $)&lt;br /&gt;+ &lt;em&gt;A US court just put ownership of CRISPR back in play. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 How to save oyster reefs &lt;/strong&gt;🦪&lt;br /&gt;Conservation projects are helping to rebuild destroyed populations. (Knowable Magazine)&lt;br /&gt;+ &lt;em&gt;How the humble sea creature could hold the key to restoring coastal waters. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 Bluesky is not as fun as it should be&lt;/strong&gt;&lt;br /&gt;It fosters a culture of reactionary scolding that’s driving some users back to X. (New Yorker $)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“For the love of God and Charlie’s family, just stop.”&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;—A poster on X begs fellow social media users to stop sharing images and videos of conservative activist Charlie Kirk’s murder online, the Associated Press reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123536" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_17efa7.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;This giant microwave may change the future of war&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Imagine: China deploys hundreds of thousands of autonomous drones in the air, on the sea, and under the water—all armed with explosive warheads or small missiles. These machines descend in a swarm toward military installations on Taiwan and nearby US bases, and over the course of a few hours, a single robotic blitzkrieg overwhelms the US Pacific force before it can even begin to fight back.&lt;/p&gt;&lt;p&gt;The proliferation of cheap drones means just about any group with the wherewithal to assemble and launch a swarm could wreak havoc, no expensive jets or massive missile installations required.&lt;/p&gt;&lt;p&gt;The US armed forces are now hunting for a solution—and they want it fast. One of these is microwaves: high-powered electronic devices that push out kilowatts of power to zap the circuits of a drone as if it were the tinfoil you forgot to take off your leftovers when you heated them up. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Sam Dean&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ They’ve finally done it—the Stephen King novel they claimed was impossible to adapt is coming to the big screen.&lt;br /&gt;+ Do you have more zucchinis than you know what to do with? This tasty bread is one solution.&lt;br /&gt;+ How The Penguin’s production designers transformed NYC into spooky, dirty Gotham.&lt;br /&gt;+ This fascinating website shows you what today’s date looks like on dozens of different calendars and clocks.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;How Trump’s policies are affecting early-career scientists—in their own words&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Every year MIT Technology Review celebrates accomplished young scientists, entrepreneurs, and inventors from around the world in our Innovators Under 35 list. We’ve just published the 2025 edition. This year, though, the context is different: The US scientific community is under attack.&lt;/p&gt;&lt;p&gt;Since Donald Trump took office in January, his administration has fired top government scientists, targeted universities and academia, and made substantial funding cuts to the country’s science and technology infrastructure.&lt;/p&gt;  &lt;p&gt;We asked our six most recent cohorts about both positive and negative impacts of the administration’s new policies. Their responses provide a glimpse into the complexities of building labs, companies, and careers in today’s political climate. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Eileen Guo &amp;amp; Amy Nordrum&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is part of MIT Technology Review’s "America Undone” series, examining how the foundations of US success in science and innovation are currently under threat. &lt;/strong&gt;&lt;strong&gt;You can read the rest here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This Ethiopian entrepreneur is reinventing ammonia production&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;In the small town in Ethiopia where he grew up, Iwnetim Abate’s family had electricity, but it was unreliable. So, for several days each week when they were without power, Abate would finish his homework by candlelight.&lt;/p&gt;  &lt;p&gt;Growing up without the access to electricity that many people take for granted shaped the way Abate thinks about energy issues. Today, the 32-year old is an assistant professor at MIT in the department of materials science and engineering.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Part of his research focuses on sodium-ion batteries, which could be cheaper than the lithium-based ones that typically power electric vehicles and grid installations. He’s also pursuing a new research path, examining how to harness the heat and pressure under the Earth’s surface to make ammonia, a chemical used in fertilizer and as a green fuel. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Abate is one of the climate and energy honorees on our 35 Innovators Under 35 list for 2025. Meet the rest of our climate and energy innovators &lt;/strong&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;strong&gt;, and the full list—including our innovator of the year—&lt;/strong&gt;&lt;strong&gt;here&lt;/strong&gt;&lt;strong&gt;.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Texas banned lab-grown meat. What’s next for the industry?&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;Last week, a legal battle over lab-grown meat kicked off in Texas. On September 1, a two-year ban on the technology went into effect across the state; the following day, two companies filed a lawsuit against state officials.&lt;/p&gt;  &lt;p&gt;The two companies, Wildtype Foods and Upside Foods, are part of a growing industry that aims to bring new types of food to people’s plates. These products, often called cultivated meat by the industry, take live animal cells and grow them in the lab to make food products without the need to slaughter animals.&lt;/p&gt;&lt;p&gt;Texas joins six other US states and the country of Italy in banning these products—adding barriers to an industry that’s still in its infancy, and already faces plenty of challenges before it can reach consumers in a meaningful way. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, MIT Technology Review’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Videos of Charlie Kirk’s shooting are everywhere on social media&lt;br /&gt;&lt;/strong&gt;It demonstrates just how poorly equipped platforms are to stop the spread of violent material. (NYT $)&lt;br /&gt;+ &lt;em&gt;Why social media can’t get on top of its graphic video problem. &lt;/em&gt;(NY Mag $)&lt;br /&gt;+ &lt;em&gt;Here’s how platforms say they’ll treat the videos. &lt;/em&gt;(The Verge)&lt;br /&gt;+ &lt;em&gt;Far-right communities reacted to Kirk’s murder by calling for more violence. &lt;/em&gt;(Wired $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;2 NASA has uncovered the clearest sign of life on Mars to date&lt;/strong&gt;&lt;br /&gt;Some unusual rocks may have been formed by ancient microbes. (WP $)&lt;br /&gt;+ &lt;em&gt;Scientists are very excited by the possibility they were created by living organisms. &lt;/em&gt;(New Scientist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 A California bill to regulate AI companion chatbots is close to passing&lt;br /&gt;&lt;/strong&gt;It would become the first US state to make chatbot operators legally accountable. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;Wall Street is only now starting to worry about “AI psychosis.” &lt;/em&gt;(Insider $)&lt;br /&gt;+ &lt;em&gt;AI companions are the final stage of digital addiction, and lawmakers are taking aim. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4 Larry Ellison briefly overtook Elon Musk as the world’s richest person&lt;/strong&gt;&lt;br /&gt;His firm Oracle reported far better-than expected results. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Oracle is riding high on a surge of demand for its data centers. &lt;/em&gt;(BBC)&lt;br /&gt;+ &lt;em&gt;But its continued success will depend on its ability to deliver promised hardware. &lt;/em&gt;(FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5&lt;/strong&gt; &lt;strong&gt;The ousted CDC director is set to testify before the US Senate&lt;/strong&gt;&lt;br /&gt;RFK Jr repeatedly called Susan Monarez a liar during a hearing last week. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;The backlash to Kennedy’s actions is intensifying. &lt;/em&gt;(NY Mag $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;6 A new system can pinpoint the best spot to hit an asteroid&lt;br /&gt;&lt;/strong&gt;Making destroying them a whole lot safer, in theory. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Meet the researchers testing the “Armageddon” approach to asteroid defense. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Saudi Arabia is building some of the world’s biggest solar farms &lt;/strong&gt;&lt;strong&gt;☀️&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;It needs plenty more electricity for its new resorts and data centers. (WSJ $)&lt;br /&gt;+ &lt;em&gt;AI is changing the grid. Could it help more than it harms? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 CRISPR could help to combat diabetes&lt;br /&gt;&lt;/strong&gt;Scientists successfully implanted insulin-producing edited cells into a man’s pancreas. (Wired $)&lt;br /&gt;+ &lt;em&gt;A US court just put ownership of CRISPR back in play. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 How to save oyster reefs &lt;/strong&gt;🦪&lt;br /&gt;Conservation projects are helping to rebuild destroyed populations. (Knowable Magazine)&lt;br /&gt;+ &lt;em&gt;How the humble sea creature could hold the key to restoring coastal waters. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 Bluesky is not as fun as it should be&lt;/strong&gt;&lt;br /&gt;It fosters a culture of reactionary scolding that’s driving some users back to X. (New Yorker $)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“For the love of God and Charlie’s family, just stop.”&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;—A poster on X begs fellow social media users to stop sharing images and videos of conservative activist Charlie Kirk’s murder online, the Associated Press reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123536" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_17efa7.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;This giant microwave may change the future of war&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Imagine: China deploys hundreds of thousands of autonomous drones in the air, on the sea, and under the water—all armed with explosive warheads or small missiles. These machines descend in a swarm toward military installations on Taiwan and nearby US bases, and over the course of a few hours, a single robotic blitzkrieg overwhelms the US Pacific force before it can even begin to fight back.&lt;/p&gt;&lt;p&gt;The proliferation of cheap drones means just about any group with the wherewithal to assemble and launch a swarm could wreak havoc, no expensive jets or massive missile installations required.&lt;/p&gt;&lt;p&gt;The US armed forces are now hunting for a solution—and they want it fast. One of these is microwaves: high-powered electronic devices that push out kilowatts of power to zap the circuits of a drone as if it were the tinfoil you forgot to take off your leftovers when you heated them up. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Sam Dean&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ They’ve finally done it—the Stephen King novel they claimed was impossible to adapt is coming to the big screen.&lt;br /&gt;+ Do you have more zucchinis than you know what to do with? This tasty bread is one solution.&lt;br /&gt;+ How The Penguin’s production designers transformed NYC into spooky, dirty Gotham.&lt;br /&gt;+ This fascinating website shows you what today’s date looks like on dozens of different calendars and clocks.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/11/1123534/the-download-trumps-impact-on-science-and-meet-our-climate-and-energy-honorees/</guid><pubDate>Thu, 11 Sep 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] Apple’s new live translation feature for AirPods won’t be available in the EU at launch (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/11/apples-new-live-translation-feature-for-airpods-wont-be-available-in-the-eu-at-launch/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-09-at-4.44.44PM.png?resize=1200,674" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;One of the headlining features of Apple’s new AirPods Pro 3 was the ability to translate incoming audio in real time, but it seems the feature won’t work in the European Union at launch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On its official page detailing the features available on iOS 26, the company said EU residents or those with EU Apple IDs won’t be able to use live translation, which is powered by Apple Intelligence and will also be coming to AirPods 4 and AirPods Pro 2.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to Apple, the delay is due to interoperability requirements of the Digital Markets Act (DMA). The company noted that other legal requirements around user data protection were not a factor here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple had to delay the release of some AI features in the EU due to these regulations last year, with users in the EU getting access to some features only in March 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated after publication to add Apple’s comment. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Screenshot-2025-09-09-at-4.44.44PM.png?resize=1200,674" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;One of the headlining features of Apple’s new AirPods Pro 3 was the ability to translate incoming audio in real time, but it seems the feature won’t work in the European Union at launch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On its official page detailing the features available on iOS 26, the company said EU residents or those with EU Apple IDs won’t be able to use live translation, which is powered by Apple Intelligence and will also be coming to AirPods 4 and AirPods Pro 2.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to Apple, the delay is due to interoperability requirements of the Digital Markets Act (DMA). The company noted that other legal requirements around user data protection were not a factor here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple had to delay the release of some AI features in the EU due to these regulations last year, with users in the EU getting access to some features only in March 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated after publication to add Apple’s comment. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/11/apples-new-live-translation-feature-for-airpods-wont-be-available-in-the-eu-at-launch/</guid><pubDate>Thu, 11 Sep 2025 12:53:03 +0000</pubDate></item><item><title>[NEW] Partnering with generative AI in the finance function (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/11/1123508/partnering-with-generative-ai-in-the-finance-function/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In association with&lt;/span&gt;Deloitte&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Generative AI has the potential to transform the finance function. By taking on some of the more mundane tasks that can occupy a lot of time, generative AI tools can help free up capacity for more high-value strategic work. For chief financial officers, this could mean spending more time and energy on proactively advising the business on financial strategy as organizations around the world continue to weather ongoing geopolitical and financial uncertainty.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1123518" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR_Deloitte-cover.png?w=1556" width="1556" /&gt;&lt;/figure&gt;  &lt;p&gt;CFOs can use large language models (LLMs) and generative AI tools to support everyday tasks like generating quarterly reports, communicating with investors, and formulating strategic summaries, says Andrew W. Lo, Charles E. and Susan T. Harris professor and director of the Laboratory for Financial Engineering at the MIT Sloan School of Management. “LLMs can’t replace the CFO by any means, but they can take a lot of the drudgery out of the role by providing first drafts of documents that summarize key issues and outline strategic priorities.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;Generative AI is also showing promise in functions like treasury, with use cases including cash, revenue, and liquidity forecasting and management, as well as automating contracts and investment analysis. However, challenges still remain for generative AI to contribute to forecasting due to the mathematical limitations of LLMs. Regardless, Deloitte’s analysis of its 2024 State of Generative AI in the Enterprise survey found that one-fifth (19%) of finance organizations have already adopted generative AI in the finance function.&lt;/p&gt;  &lt;p&gt;Despite return on generative AI investments in finance functions being 8 points below expectations so far for surveyed organizations (see Figure 1), some finance departments appear to be moving ahead with investments. Deloitte’s fourth-quarter 2024 North American CFO Signals survey found that 46% of CFOs who responded expect deployment or spend on generative AI in finance to increase in the next 12 months (see Figure 2). Respondents cite the technology’s potential to help control costs through self-service and automation and free up workers for higher-level, higher-productivity tasks as some of the top benefits of the technology.&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123540" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR_Deloitte-Socials_Figrevised-1.png" /&gt;&lt;/figure&gt;  &lt;p&gt;“Companies have used AI on the customer-facing side of the house for a long time, but in finance, employees are still creating documents and presentations and emailing them around,” says Robyn Peters, principal in finance transformation at Deloitte Consulting LLP. “Largely, the human-centric experience that customers expect from brands in retail, transportation, and hospitality haven’t been pulled through to the finance organization. And there’s no reason we cannot do that—and, in fact, AI makes it a lot easier to do.”&lt;/p&gt;  &lt;p&gt;If CFOs think they can just sit by for the next five years and watch how AI evolves, they may lose out to more nimble competitors that are actively experimenting in the space. Future finance professionals are growing up using generative AI tools too. CFOs should consider reimagining what it looks like to be a successful finance professional, in collaboration with AI.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Download the report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In association with&lt;/span&gt;Deloitte&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Generative AI has the potential to transform the finance function. By taking on some of the more mundane tasks that can occupy a lot of time, generative AI tools can help free up capacity for more high-value strategic work. For chief financial officers, this could mean spending more time and energy on proactively advising the business on financial strategy as organizations around the world continue to weather ongoing geopolitical and financial uncertainty.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1123518" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR_Deloitte-cover.png?w=1556" width="1556" /&gt;&lt;/figure&gt;  &lt;p&gt;CFOs can use large language models (LLMs) and generative AI tools to support everyday tasks like generating quarterly reports, communicating with investors, and formulating strategic summaries, says Andrew W. Lo, Charles E. and Susan T. Harris professor and director of the Laboratory for Financial Engineering at the MIT Sloan School of Management. “LLMs can’t replace the CFO by any means, but they can take a lot of the drudgery out of the role by providing first drafts of documents that summarize key issues and outline strategic priorities.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;Generative AI is also showing promise in functions like treasury, with use cases including cash, revenue, and liquidity forecasting and management, as well as automating contracts and investment analysis. However, challenges still remain for generative AI to contribute to forecasting due to the mathematical limitations of LLMs. Regardless, Deloitte’s analysis of its 2024 State of Generative AI in the Enterprise survey found that one-fifth (19%) of finance organizations have already adopted generative AI in the finance function.&lt;/p&gt;  &lt;p&gt;Despite return on generative AI investments in finance functions being 8 points below expectations so far for surveyed organizations (see Figure 1), some finance departments appear to be moving ahead with investments. Deloitte’s fourth-quarter 2024 North American CFO Signals survey found that 46% of CFOs who responded expect deployment or spend on generative AI in finance to increase in the next 12 months (see Figure 2). Respondents cite the technology’s potential to help control costs through self-service and automation and free up workers for higher-level, higher-productivity tasks as some of the top benefits of the technology.&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1123540" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR_Deloitte-Socials_Figrevised-1.png" /&gt;&lt;/figure&gt;  &lt;p&gt;“Companies have used AI on the customer-facing side of the house for a long time, but in finance, employees are still creating documents and presentations and emailing them around,” says Robyn Peters, principal in finance transformation at Deloitte Consulting LLP. “Largely, the human-centric experience that customers expect from brands in retail, transportation, and hospitality haven’t been pulled through to the finance organization. And there’s no reason we cannot do that—and, in fact, AI makes it a lot easier to do.”&lt;/p&gt;  &lt;p&gt;If CFOs think they can just sit by for the next five years and watch how AI evolves, they may lose out to more nimble competitors that are actively experimenting in the space. Future finance professionals are growing up using generative AI tools too. CFOs should consider reimagining what it looks like to be a successful finance professional, in collaboration with AI.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;Download the report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/11/1123508/partnering-with-generative-ai-in-the-finance-function/</guid><pubDate>Thu, 11 Sep 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Yext Scout Guides Brands Through AI Search Challenges (AI News)</title><link>https://www.artificialintelligence-news.com/news/yext-scout-guides-brands-through-ai-search-challenges/</link><description>&lt;p&gt;Customers are discovering brands and learning about products and services in new ways from traditional search to AI search, to AI agents and more, the discovery journey has completely changed, and brands need to adapt to the new paradigm.&lt;/p&gt;&lt;p&gt;Launched earlier this year, Yext Scout is an AI search and competitive intelligence agent that’s designed to boost brand visibility and uncover critical insights related to the new AI-driven search platforms, alongside ‘traditional’ searches as we know them.&lt;/p&gt;&lt;p&gt;Scout is part of Yext, the leading brand visibility platform. Scout provides performance benchmarks laid out against a brand’s local competitors, and creates smart recommendations that you can act on, in real-time.&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-109380" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/Winning-Search-in-EMEA-Banner-ads-728x90-1-1.jpg" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;Yext will be exploring the massive impact AI has had on search and user behaviours, and how Scout can inform marketing professionals, at a webinar, ‘Winning Search in EMEA: How Yext Scout Drives Visibility Across Local and AI Platforms.’ It’s scheduled for Wednesday, 24 September at 1pm BST / 2pm CEST.&lt;/p&gt;&lt;p&gt;With AI now ever-present in digital interactions, platforms like ChatGPT, Gemini, Perplexity, and latterly, Grok, have huge influence over consumers’ discovery and interaction with brands.&lt;/p&gt;&lt;p&gt;Increasingly presented top-of-page, AI discoveries are replacing the traditional search engine results page with conversational answers that remove users’ need to sift through potentially unreliable results. Brands need guidance to understand how to optimise their content so it ranks optimally in these emerging channels.&lt;/p&gt;&lt;p&gt;Measurement of effectiveness is also new territory, putting many companies behind their better-informed, if not better-providing competitors. The Yext webinar on 24 September will help brand and marketing professionals improve visibility, track and tailor sentiment, and measure performance across social content, reviews, and local listings.&lt;/p&gt;&lt;p&gt;Join Yext for the exclusive session, ‘Winning Search in EMEA: How Yext Scout Drives Visibility Across Local and AI Platforms,’ on Wednesday 24 September at 1pm BST / 2pm CEST.&lt;/p&gt;&lt;p&gt;Register your place here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Customers are discovering brands and learning about products and services in new ways from traditional search to AI search, to AI agents and more, the discovery journey has completely changed, and brands need to adapt to the new paradigm.&lt;/p&gt;&lt;p&gt;Launched earlier this year, Yext Scout is an AI search and competitive intelligence agent that’s designed to boost brand visibility and uncover critical insights related to the new AI-driven search platforms, alongside ‘traditional’ searches as we know them.&lt;/p&gt;&lt;p&gt;Scout is part of Yext, the leading brand visibility platform. Scout provides performance benchmarks laid out against a brand’s local competitors, and creates smart recommendations that you can act on, in real-time.&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-109380" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/09/Winning-Search-in-EMEA-Banner-ads-728x90-1-1.jpg" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;Yext will be exploring the massive impact AI has had on search and user behaviours, and how Scout can inform marketing professionals, at a webinar, ‘Winning Search in EMEA: How Yext Scout Drives Visibility Across Local and AI Platforms.’ It’s scheduled for Wednesday, 24 September at 1pm BST / 2pm CEST.&lt;/p&gt;&lt;p&gt;With AI now ever-present in digital interactions, platforms like ChatGPT, Gemini, Perplexity, and latterly, Grok, have huge influence over consumers’ discovery and interaction with brands.&lt;/p&gt;&lt;p&gt;Increasingly presented top-of-page, AI discoveries are replacing the traditional search engine results page with conversational answers that remove users’ need to sift through potentially unreliable results. Brands need guidance to understand how to optimise their content so it ranks optimally in these emerging channels.&lt;/p&gt;&lt;p&gt;Measurement of effectiveness is also new territory, putting many companies behind their better-informed, if not better-providing competitors. The Yext webinar on 24 September will help brand and marketing professionals improve visibility, track and tailor sentiment, and measure performance across social content, reviews, and local listings.&lt;/p&gt;&lt;p&gt;Join Yext for the exclusive session, ‘Winning Search in EMEA: How Yext Scout Drives Visibility Across Local and AI Platforms,’ on Wednesday 24 September at 1pm BST / 2pm CEST.&lt;/p&gt;&lt;p&gt;Register your place here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/yext-scout-guides-brands-through-ai-search-challenges/</guid><pubDate>Thu, 11 Sep 2025 14:19:15 +0000</pubDate></item><item><title>[NEW] Box CEO Aaron Levie on AI’s ‘era of context’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/11/box-ceo-aaron-levie-on-ais-era-of-context/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, Box launched its developer conference Boxworks by announcing a new set of AI features, building agentic AI models into the backbone of the company’s products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s more product announcements than usual for the conference, reflecting the increasingly fast pace of AI development at the company: Box launched its AI studio last year, followed by a new set of data-extraction agents in February, and others for search and deep research in May. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, the company is rolling out a new system called Box Automate that works as a kind of operating system for AI agents, breaking workflows into different segments that can be augmented with AI as necessary.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I spoke with CEO Aaron Levie about the company’s approach to AI, and the perilous work of competing with foundation model companies. Unsurprisingly, he was very bullish about the possibilities for AI agents in the modern workplace, but he was also clear-eyed about the limitations of current models and how to manage those limitations with existing technology.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This interview has been edited for length and clarity.&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TechCrunch: You’re announcing a bunch of AI products today, so I want to start by asking about the big-picture vision. Why build AI agents into a cloud content-management service?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Aaron Levie: &lt;/strong&gt;So the thing that we think about all day long – and what our focus is at Box – is how much work is changing due to AI. And the vast majority of the impact right now is on workflows involving unstructured data. We’ve already been able to automate anything that deals with structured data that goes into a database. If you think about CRM systems, ERP systems, HR systems, we’ve already had years of automation in that space. But where we’ve never had automation is anything that touches unstructured data.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Think about any kind of legal review process, any kind of marketing asset management process, any kind of M&amp;amp;A deal review — all of those workflows deal with lots of unstructured data. People have to review that data, make updates to it, make decisions and so on. We’ve never been able to bring much automation to those workflows. We’ve been able to sort of describe them in software, but computers just haven’t been good enough at reading a document or looking at a marketing asset. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So for us, AI agents mean that, for the first time ever, we can actually tap into all of this unstructured data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: What about the risks of deploying agents in a business context? Some of your customers must be nervous about deploying something like this on sensitive data.&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Levie: &lt;/strong&gt;What we’ve been seeing from customers is they want to know that every single time they run that workflow, the agent is going to execute more or less the same way, at the same point in the workflow, and not have things kind of go off the rails. You don’t want to have an agent make some compounding mistake where, after they do the first couple 100 submissions, they start to kind of run wild. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It becomes really important to have the right demarcation points, where the agent starts and the other parts of the system end. For every workflow, there’s this question of what needs to have deterministic guardrails, and what can be fully agentic and non-deterministic.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;What you can do with Box Automate is decide how much work you want each individual agent to do before it hands off to a different agent. So you might have a submission agent that’s separate from the review agent, and so on. It’s allowing you to basically deploy AI agents at scale in any kind of workflow or business process in the organization.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A visualization of the Box Automate workflow" class="wp-image-3045173" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/Box-Automate-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;A Box Automate workflow, with AI agents deployed for specific tasks. &lt;strong&gt;Image Credits:&lt;/strong&gt; Box&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: What kind of problems do you guard against by splitting up the workflow?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Levie: &lt;/strong&gt;We’ve already seen some of the limitations even in the most advanced fully agentic systems like Claude Code. At some point in the task, the model runs out of context-window room to continue making good decisions. There’s no free lunch right now in AI. You can’t just have a long-running agent with unlimited context window go after any task in your business. So you have to break up the workflow and use sub-agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I think we’re in the era of context within AI. What AI models and agents need is context, and the context that they need to work off is sitting inside your unstructured data. So our whole system is really designed to figure out what context you can give the AI agent to ensure that they perform as effectively as possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: There is a bigger debate in the industry about the benefits of big, powerful frontier models compared to models that are smaller and more reliable. Does this put you on the side of the smaller models?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Levie: &lt;/strong&gt;I should probably clarify: Nothing about our system prevents the task from being arbitrarily long or complex. What we’re trying to do is create the right guardrails so that you get to decide how agentic you want that task to be. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We don’t have a particular philosophy as to where people should be on that continuum. We’re just trying to design a future-proof architecture. We’ve designed this in such a way where, as the models improve and as agentic capabilities improve, you will just get all of those benefits directly in our platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: The other concern is data control. Because models are trained on so much data, there’s a real fear that sensitive data will get regurgitated or misused. How does that factor in?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Levie: &lt;/strong&gt;It’s where a lot of AI deployments go wrong. People think, “Hey, this is easy. I’ll give an AI model access to all of my unstructured data, and it’ll answer questions for people.” And then it starts to give you answers on data that you don’t have access to or you shouldn’t have access to. You need a very powerful layer that handles access controls, data security, permissions, data governance, compliance, everything.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So we’re benefiting from the couple decades that we’ve spent building up a system that basically handles that exact problem: How do you ensure only the right person has access to each piece of data in the enterprise? So when an agent answers a question, you know deterministically that it can’t draw on any data that that person shouldn’t have access to. That is just something fundamentally built into our system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: Earlier this week, Anthropic released a new feature for directly uploading files to Claude.ai. It’s a long way from the sort of file management that Box does, but you must be thinking about possible competition from the foundation model companies. How do you approach that strategically?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Levie: &lt;/strong&gt;So if you think about what enterprises need when they deploy AI at scale, they need security, permissions and control. They need the user interface, they need powerful APIs, they want their choice of AI models, because one day, one AI model powers some use case for them that is better than another, but then that might change, and they don’t want to be locked into one particular platform. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So what we’ve built is a system that lets you have effectively all of those capabilities. We’re doing the storage, the security, the permissions, the vector embedding, and we connect to every leading AI model that’s out there.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, Box launched its developer conference Boxworks by announcing a new set of AI features, building agentic AI models into the backbone of the company’s products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s more product announcements than usual for the conference, reflecting the increasingly fast pace of AI development at the company: Box launched its AI studio last year, followed by a new set of data-extraction agents in February, and others for search and deep research in May. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, the company is rolling out a new system called Box Automate that works as a kind of operating system for AI agents, breaking workflows into different segments that can be augmented with AI as necessary.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I spoke with CEO Aaron Levie about the company’s approach to AI, and the perilous work of competing with foundation model companies. Unsurprisingly, he was very bullish about the possibilities for AI agents in the modern workplace, but he was also clear-eyed about the limitations of current models and how to manage those limitations with existing technology.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This interview has been edited for length and clarity.&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TechCrunch: You’re announcing a bunch of AI products today, so I want to start by asking about the big-picture vision. Why build AI agents into a cloud content-management service?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Aaron Levie: &lt;/strong&gt;So the thing that we think about all day long – and what our focus is at Box – is how much work is changing due to AI. And the vast majority of the impact right now is on workflows involving unstructured data. We’ve already been able to automate anything that deals with structured data that goes into a database. If you think about CRM systems, ERP systems, HR systems, we’ve already had years of automation in that space. But where we’ve never had automation is anything that touches unstructured data.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Think about any kind of legal review process, any kind of marketing asset management process, any kind of M&amp;amp;A deal review — all of those workflows deal with lots of unstructured data. People have to review that data, make updates to it, make decisions and so on. We’ve never been able to bring much automation to those workflows. We’ve been able to sort of describe them in software, but computers just haven’t been good enough at reading a document or looking at a marketing asset. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So for us, AI agents mean that, for the first time ever, we can actually tap into all of this unstructured data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: What about the risks of deploying agents in a business context? Some of your customers must be nervous about deploying something like this on sensitive data.&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Levie: &lt;/strong&gt;What we’ve been seeing from customers is they want to know that every single time they run that workflow, the agent is going to execute more or less the same way, at the same point in the workflow, and not have things kind of go off the rails. You don’t want to have an agent make some compounding mistake where, after they do the first couple 100 submissions, they start to kind of run wild. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It becomes really important to have the right demarcation points, where the agent starts and the other parts of the system end. For every workflow, there’s this question of what needs to have deterministic guardrails, and what can be fully agentic and non-deterministic.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;What you can do with Box Automate is decide how much work you want each individual agent to do before it hands off to a different agent. So you might have a submission agent that’s separate from the review agent, and so on. It’s allowing you to basically deploy AI agents at scale in any kind of workflow or business process in the organization.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A visualization of the Box Automate workflow" class="wp-image-3045173" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/Box-Automate-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;A Box Automate workflow, with AI agents deployed for specific tasks. &lt;strong&gt;Image Credits:&lt;/strong&gt; Box&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: What kind of problems do you guard against by splitting up the workflow?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Levie: &lt;/strong&gt;We’ve already seen some of the limitations even in the most advanced fully agentic systems like Claude Code. At some point in the task, the model runs out of context-window room to continue making good decisions. There’s no free lunch right now in AI. You can’t just have a long-running agent with unlimited context window go after any task in your business. So you have to break up the workflow and use sub-agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I think we’re in the era of context within AI. What AI models and agents need is context, and the context that they need to work off is sitting inside your unstructured data. So our whole system is really designed to figure out what context you can give the AI agent to ensure that they perform as effectively as possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: There is a bigger debate in the industry about the benefits of big, powerful frontier models compared to models that are smaller and more reliable. Does this put you on the side of the smaller models?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Levie: &lt;/strong&gt;I should probably clarify: Nothing about our system prevents the task from being arbitrarily long or complex. What we’re trying to do is create the right guardrails so that you get to decide how agentic you want that task to be. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;We don’t have a particular philosophy as to where people should be on that continuum. We’re just trying to design a future-proof architecture. We’ve designed this in such a way where, as the models improve and as agentic capabilities improve, you will just get all of those benefits directly in our platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: The other concern is data control. Because models are trained on so much data, there’s a real fear that sensitive data will get regurgitated or misused. How does that factor in?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Levie: &lt;/strong&gt;It’s where a lot of AI deployments go wrong. People think, “Hey, this is easy. I’ll give an AI model access to all of my unstructured data, and it’ll answer questions for people.” And then it starts to give you answers on data that you don’t have access to or you shouldn’t have access to. You need a very powerful layer that handles access controls, data security, permissions, data governance, compliance, everything.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So we’re benefiting from the couple decades that we’ve spent building up a system that basically handles that exact problem: How do you ensure only the right person has access to each piece of data in the enterprise? So when an agent answers a question, you know deterministically that it can’t draw on any data that that person shouldn’t have access to. That is just something fundamentally built into our system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: Earlier this week, Anthropic released a new feature for directly uploading files to Claude.ai. It’s a long way from the sort of file management that Box does, but you must be thinking about possible competition from the foundation model companies. How do you approach that strategically?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Levie: &lt;/strong&gt;So if you think about what enterprises need when they deploy AI at scale, they need security, permissions and control. They need the user interface, they need powerful APIs, they want their choice of AI models, because one day, one AI model powers some use case for them that is better than another, but then that might change, and they don’t want to be locked into one particular platform. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So what we’ve built is a system that lets you have effectively all of those capabilities. We’re doing the storage, the security, the permissions, the vector embedding, and we connect to every leading AI model that’s out there.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/11/box-ceo-aaron-levie-on-ais-era-of-context/</guid><pubDate>Thu, 11 Sep 2025 14:36:31 +0000</pubDate></item><item><title>[NEW] Humanoids, AVs, and what’s next in AI hardware with Waabi and Apptronik at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/11/humanoids-avs-and-whats-next-in-ai-hardware-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; hits Moscone West in San Francisco from October 27 to 29, bringing together 10,000+ startup and VC leaders for three days of bold ideas, groundbreaking tech, and future-shaping conversations. One of the most highly anticipated &lt;strong&gt;sessions happening on one of the two AI Stages&lt;/strong&gt; will spotlight where AI hardware is heading next, featuring a live look at the robotics and autonomous systems pushing boundaries in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;AI may be reshaping software, but when it comes to robotics and autonomous systems, the big breakout moment is still on the horizon. That’s what makes this session at TechCrunch Disrupt 2025 so compelling. &lt;strong&gt;Raquel Urtasun&lt;/strong&gt;, founder and CEO of &lt;strong&gt;Waabi&lt;/strong&gt;, and &lt;strong&gt;Jeff Cardenas&lt;/strong&gt;, co-founder and CEO of &lt;strong&gt;Apptronik&lt;/strong&gt;, are joining forces on the AI Stage to talk about what it takes to put intelligence into motion — whether it’s behind the wheel or on two legs.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Jeff Cardenas Raquel Urtasun" class="wp-image-3026927" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_CardenasUrtasun-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-ai-meets-real-world-physics"&gt;&lt;br /&gt;AI meets real-world physics&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This conversation dives into the complex systems that power autonomous vehicles and humanoid robots — and the simulation, sensors, and software infrastructure needed to scale them safely. Both Waabi and Apptronik are pushing the limits of what’s possible in the physical world. At Disrupt, they’ll walk us through the breakthroughs and bottlenecks shaping the next generation of intelligent machines.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AI is already changing how we build, ship, and move — but physical deployment brings a unique set of constraints and opportunities. Expect a grounded, forward-looking discussion on how the smartest robots and self-driving platforms are coming to life, and what that means for the future of industry, labor, and infrastructure.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Catch Raquel Urtasun and Jeff Cardenas on the AI Stage at TechCrunch Disrupt 2025, happening October 27 to 29 at Moscone West in San Francisco. &lt;strong&gt;Register now&lt;/strong&gt; to join more than 10,000 startup and VC leaders and &lt;strong&gt;save up to $668&lt;/strong&gt; before prices increase on September 26, 11:59 p.m. PT.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; hits Moscone West in San Francisco from October 27 to 29, bringing together 10,000+ startup and VC leaders for three days of bold ideas, groundbreaking tech, and future-shaping conversations. One of the most highly anticipated &lt;strong&gt;sessions happening on one of the two AI Stages&lt;/strong&gt; will spotlight where AI hardware is heading next, featuring a live look at the robotics and autonomous systems pushing boundaries in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;AI may be reshaping software, but when it comes to robotics and autonomous systems, the big breakout moment is still on the horizon. That’s what makes this session at TechCrunch Disrupt 2025 so compelling. &lt;strong&gt;Raquel Urtasun&lt;/strong&gt;, founder and CEO of &lt;strong&gt;Waabi&lt;/strong&gt;, and &lt;strong&gt;Jeff Cardenas&lt;/strong&gt;, co-founder and CEO of &lt;strong&gt;Apptronik&lt;/strong&gt;, are joining forces on the AI Stage to talk about what it takes to put intelligence into motion — whether it’s behind the wheel or on two legs.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Jeff Cardenas Raquel Urtasun" class="wp-image-3026927" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_CardenasUrtasun-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-ai-meets-real-world-physics"&gt;&lt;br /&gt;AI meets real-world physics&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This conversation dives into the complex systems that power autonomous vehicles and humanoid robots — and the simulation, sensors, and software infrastructure needed to scale them safely. Both Waabi and Apptronik are pushing the limits of what’s possible in the physical world. At Disrupt, they’ll walk us through the breakthroughs and bottlenecks shaping the next generation of intelligent machines.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AI is already changing how we build, ship, and move — but physical deployment brings a unique set of constraints and opportunities. Expect a grounded, forward-looking discussion on how the smartest robots and self-driving platforms are coming to life, and what that means for the future of industry, labor, and infrastructure.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Catch Raquel Urtasun and Jeff Cardenas on the AI Stage at TechCrunch Disrupt 2025, happening October 27 to 29 at Moscone West in San Francisco. &lt;strong&gt;Register now&lt;/strong&gt; to join more than 10,000 startup and VC leaders and &lt;strong&gt;save up to $668&lt;/strong&gt; before prices increase on September 26, 11:59 p.m. PT.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/11/humanoids-avs-and-whats-next-in-ai-hardware-at-techcrunch-disrupt-2025/</guid><pubDate>Thu, 11 Sep 2025 15:02:50 +0000</pubDate></item><item><title>[NEW] VMware nods to AI but looks to long-term (AI News)</title><link>https://www.artificialintelligence-news.com/news/broadcom-nods-at-ai-looks-to-long-term/</link><description>&lt;p&gt;Owner of VMware, Broadcom, announced that its VMware Cloud Foundation platform is now AI native at the VMware Explore conference a few weeks ago.&lt;/p&gt;&lt;p&gt;It was the latest move by the company to keep up to speed with the rest of the technology industry’s wide and rapid adoption of large language models, yet came as the company battles bad press about licensing policy changes that have dogged it since it acquired virtualisation giant VMware in November 2023.&lt;/p&gt;&lt;p&gt;The ending of the platform’s free tier, reports of aggressive sales tactics to keep subscribers on board, and several court cases focused on existing agreements, including extant perpetual licences, have led many users to rethink what is often the basis of their IT stack. Nutanix, SUSE, and IBM have been among the beneficiaries from those leaving the VMware stable.&lt;/p&gt;&lt;p&gt;But the nature of VMware deployments means that they’re often complex, and extricating workloads out from heavily-virtualised environments running on the platform can come with high migration costs and not insignificant risks to an organisation’s QoS metrics. Better to stay and pay the devil you know than go out on a limb and migrate to an alternative.&lt;/p&gt;&lt;p&gt;By the same token, engineering AI into VMware’s offerings is fraught with danger and the potential for identical fallout. Re-architecturing the VMware platform to bake AI in at the core would mean it would be end-users’ stuttering workloads paying the price for any breaking changes. And the nature of software is that the deeper breaking changes are made, the greater the potential negative ramifications.&lt;/p&gt;&lt;p&gt;Broadcom’s initial aims are to make it simpler for its users to deploy AI models and agents inside their existing environments. VMware Private AI Services is to ship with VCF 9 subscriptions next year, and will comprise of all the elements required to build and run AI on-premise, or at least outside hyperscale facilities. It will include a model store (it’s expected that many organisations will turn to – at least in testing phases – open-source, smaller models), indexing services, vector databases, an agentic AI builder, and a ready-made API gateway to allow optimised machine-to-machine communications between separate AI models that need to work together.&lt;/p&gt;&lt;p&gt;Conference attendees were told AI’s presence in the enterprise was only going to grow, and so it only made sense that AI should be a feature of every VMware-based infrastructure. As it stands, what Broadcom is offering is a nod in the AI direction, but nothing unique nor new. The company also announced improvements to the VMware Tanzu Platform which include simpler publishing of MCP servers, and a new data lakehouse, Tanzu Data Intelligence.&lt;/p&gt;&lt;p&gt;Presumably low-hanging fruit for VMware’s own developers was Intelligent Assist for VCF, a chatbot with access to the VMware knowledgebase. The AI-powered ‘bot will be able to lengthen the time between a user raising an issue or question, and them getting to speak to a human who can help.&lt;/p&gt;&lt;p&gt;The excitement around widespread adoption of containers led many to declare that the end was nigh for ‘traditional’ virtualisation, much in the same way that the explosion of cloud services was to spell the end for on-premise databases, and thus see off Oracle. The reality was, and remains, that legacy infrastructure compels enterprise users to consolidate on the platforms they have invested in, despite rapacious licence fees and high costs.&lt;/p&gt;&lt;p&gt;VMware may be sprinkling the deals between it and its customers with a little AI fairy-dust, but it knows that its long-term income is guaranteed by the presence of legacy infrastructure at the core of the enterprise.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Virtual Try On” by jurvetson is licensed under CC BY 2.0.&lt;/em&gt;)&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.developer-tech.com/wp-content/uploads/2025/08/developer-cloud-big-data-expo.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to dive deeper into the tools and frameworks shaping modern development?&lt;/strong&gt; Check out the AI &amp;amp; Big Data Expo, taking place in Amsterdam, California, and London. Explore cutting-edge sessions on machine learning, data pipelines, and next-gen AI applications. The event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;DeveloperTech News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Owner of VMware, Broadcom, announced that its VMware Cloud Foundation platform is now AI native at the VMware Explore conference a few weeks ago.&lt;/p&gt;&lt;p&gt;It was the latest move by the company to keep up to speed with the rest of the technology industry’s wide and rapid adoption of large language models, yet came as the company battles bad press about licensing policy changes that have dogged it since it acquired virtualisation giant VMware in November 2023.&lt;/p&gt;&lt;p&gt;The ending of the platform’s free tier, reports of aggressive sales tactics to keep subscribers on board, and several court cases focused on existing agreements, including extant perpetual licences, have led many users to rethink what is often the basis of their IT stack. Nutanix, SUSE, and IBM have been among the beneficiaries from those leaving the VMware stable.&lt;/p&gt;&lt;p&gt;But the nature of VMware deployments means that they’re often complex, and extricating workloads out from heavily-virtualised environments running on the platform can come with high migration costs and not insignificant risks to an organisation’s QoS metrics. Better to stay and pay the devil you know than go out on a limb and migrate to an alternative.&lt;/p&gt;&lt;p&gt;By the same token, engineering AI into VMware’s offerings is fraught with danger and the potential for identical fallout. Re-architecturing the VMware platform to bake AI in at the core would mean it would be end-users’ stuttering workloads paying the price for any breaking changes. And the nature of software is that the deeper breaking changes are made, the greater the potential negative ramifications.&lt;/p&gt;&lt;p&gt;Broadcom’s initial aims are to make it simpler for its users to deploy AI models and agents inside their existing environments. VMware Private AI Services is to ship with VCF 9 subscriptions next year, and will comprise of all the elements required to build and run AI on-premise, or at least outside hyperscale facilities. It will include a model store (it’s expected that many organisations will turn to – at least in testing phases – open-source, smaller models), indexing services, vector databases, an agentic AI builder, and a ready-made API gateway to allow optimised machine-to-machine communications between separate AI models that need to work together.&lt;/p&gt;&lt;p&gt;Conference attendees were told AI’s presence in the enterprise was only going to grow, and so it only made sense that AI should be a feature of every VMware-based infrastructure. As it stands, what Broadcom is offering is a nod in the AI direction, but nothing unique nor new. The company also announced improvements to the VMware Tanzu Platform which include simpler publishing of MCP servers, and a new data lakehouse, Tanzu Data Intelligence.&lt;/p&gt;&lt;p&gt;Presumably low-hanging fruit for VMware’s own developers was Intelligent Assist for VCF, a chatbot with access to the VMware knowledgebase. The AI-powered ‘bot will be able to lengthen the time between a user raising an issue or question, and them getting to speak to a human who can help.&lt;/p&gt;&lt;p&gt;The excitement around widespread adoption of containers led many to declare that the end was nigh for ‘traditional’ virtualisation, much in the same way that the explosion of cloud services was to spell the end for on-premise databases, and thus see off Oracle. The reality was, and remains, that legacy infrastructure compels enterprise users to consolidate on the platforms they have invested in, despite rapacious licence fees and high costs.&lt;/p&gt;&lt;p&gt;VMware may be sprinkling the deals between it and its customers with a little AI fairy-dust, but it knows that its long-term income is guaranteed by the presence of legacy infrastructure at the core of the enterprise.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Virtual Try On” by jurvetson is licensed under CC BY 2.0.&lt;/em&gt;)&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.developer-tech.com/wp-content/uploads/2025/08/developer-cloud-big-data-expo.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to dive deeper into the tools and frameworks shaping modern development?&lt;/strong&gt; Check out the AI &amp;amp; Big Data Expo, taking place in Amsterdam, California, and London. Explore cutting-edge sessions on machine learning, data pipelines, and next-gen AI applications. The event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;DeveloperTech News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/broadcom-nods-at-ai-looks-to-long-term/</guid><pubDate>Thu, 11 Sep 2025 15:44:08 +0000</pubDate></item><item><title>[NEW] Tool-space interference in the MCP era: Designing for agent compatibility at scale (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/tool-space-interference-in-the-mcp-era-designing-for-agent-compatibility-at-scale/</link><description>&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to purple to pink. From left to right: a globe with a magnifying glass representing internet search, a central circle connected to smaller circles symbolizing network connectivity, and a checklist with two checkmarks and one empty box indicating task management." class="wp-image-1149369" height="576" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/ToolSpaceInterference-BlogHeroFeature-1400x788-1-1024x576.jpg" width="1024" /&gt;&lt;/figure&gt;



&lt;p&gt;This year&amp;nbsp;we’ve&amp;nbsp;seen&amp;nbsp;remarkable&amp;nbsp;advances in agentic AI, including&amp;nbsp;systems that conduct deep research,&amp;nbsp;operate&amp;nbsp;computers, complete substantial software engineering tasks, and tackle a range of other complex,&amp;nbsp;multi-step goals. In each case,&amp;nbsp;the industry relied&amp;nbsp;on careful vertical integration: tools and agents were co-designed, co-trained, and tested together&amp;nbsp;for peak&amp;nbsp;performance. For example,&amp;nbsp;OpenAI’s&amp;nbsp;recent models&amp;nbsp;presume&amp;nbsp;the&amp;nbsp;availability&amp;nbsp;of web search and document retrieval&amp;nbsp;tools&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. Likewise,&amp;nbsp;the prompts and actions&amp;nbsp;of&amp;nbsp;Magentic-One&amp;nbsp;are&amp;nbsp;set up to make hand-offs easy—for example, allowing the WebSurfer agent to pass downloaded files to the Coder agent. &amp;nbsp;But as agents proliferate, we anticipate strategies relying heavily on vertical integration will not age well.&amp;nbsp;Agents&amp;nbsp;from&amp;nbsp;different&amp;nbsp;developers&amp;nbsp;or companies will&amp;nbsp;increasingly&amp;nbsp;encounter&amp;nbsp;each other and&amp;nbsp;must&amp;nbsp;work together to complete tasks, in what we refer to as a&amp;nbsp;&lt;em&gt;society of agents&lt;/em&gt;.&amp;nbsp;These systems can vary in how coordinated they are, how aligned their goals are, and how much information they share. Can heterogenous agents and tools cooperate&amp;nbsp;in this&amp;nbsp;setting, or will they hinder one another and slow progress?&lt;/p&gt;



&lt;p&gt;Early clues have&amp;nbsp;emerged&amp;nbsp;from an&amp;nbsp;unexpected&amp;nbsp;source:&amp;nbsp;namely,&amp;nbsp;Model Context Protocol&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;(MCP). Since January 2025, MCP has grown from a&amp;nbsp;promising spec to a&amp;nbsp;thriving&amp;nbsp;market&amp;nbsp;of&amp;nbsp;tool&amp;nbsp;servers.&amp;nbsp;As an example, Zapier boasts a catalog of 30,000 tools&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;across 7,000 services.&amp;nbsp;Composio&amp;nbsp;provide over 100 managed MCP servers&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, surfacing hundreds of tools. Hugging&amp;nbsp;Face is now serving&amp;nbsp;many&amp;nbsp;Spaces&amp;nbsp;apps over MCP&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and Shopify has enabled MCP for millions of storefronts&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;A&amp;nbsp;society of&amp;nbsp;&lt;em&gt;tools&lt;/em&gt;&amp;nbsp;is already here, and it promises to&amp;nbsp;extend&amp;nbsp;agent capabilities through&amp;nbsp;cross-provider&amp;nbsp;horizontal integration.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So,&amp;nbsp;what does MCP have to say about&amp;nbsp;horizontal integration? As catalogs grow,&amp;nbsp;we expect some new failure modes to surface.&amp;nbsp;This&amp;nbsp;blog&amp;nbsp;post introduces&amp;nbsp;these&amp;nbsp;as &lt;em&gt;tool-space interference&lt;/em&gt;, and sketches both early observations and some pragmatic interventions to keep the society&amp;nbsp;we’re&amp;nbsp;building&amp;nbsp;from stepping on its own feet.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Tool-space interference describes situations where otherwise reasonable tools or agents, when co-present, reduce end-to-end effectiveness. This can look like longer action sequences, higher token cost, brittle recovery from errors, or, in some cases, task failure.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="a-framing-example"&gt;A framing example&lt;/h2&gt;



&lt;p&gt;Consider MCP as a means for extending Magentic-One, a generalist multi-agent system we released last year, to cover more software engineering tasks. Magentic-One ships with agents to write code, interact with the computer terminal, browse the web, and access local files. To help Magentic-One navigate version control, find issues to solve, and make pull requests, we could add an agent equipped with the GitHub MCP Server. However, now each time the team encounters a task involving GitHub, it must choose whether to visit github.com in the browser, execute a git command at the command line, or engage the GitHub MCP server. As the task progresses, agent understanding of state can also diverge: changing the branch in the browser won’t change the branch in the terminal, and an authorized MCP tool does not imply authorization in the browser.&amp;nbsp;Thus, while any single agent might complete the task efficiently, the larger set of agents might misunderstand or interfere with one another, leading to additional rounds of debugging, or even complete task failure.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Diagram depicting Magentic-One's multi-agentic architecture. An Orchestrator agent has access to 4 specialized sub-agents: a Coder agent that can write code and reason to sol solve tasks, a Computer Terminal Agent that can execute code written by the Coder agent, a WebSurfer agent that browse the internet (navigate pages, fill forms, etc), and a FileSurfer agent that can navigate files (e.g. PDFs, PPTx, etc). The diagram is annotated to show that for any incoming git-related task, the Orchestrator agent has to decide at evert orchestration step whether to access Git CLI via ComputerTerminal, visit Github site via WebSurfer, or directly access Github’s MCP server." class="wp-image-1149211" height="410" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/image.png" width="1021" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1: We can extend&amp;nbsp;Magentic-One by adding an agent that equips the GitHub MCP server. However, on every turn involving a git-related task, the orchestrator will need to decide between messaging the Computer Terminal agent (with access to the git command line interface), WebSurfer agent (with access to github.com), and the agent with the GitHub MCP server. This overlap raises the possibility that they will interfere with one another.&amp;nbsp;&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;







&lt;p&gt;To better understand the potential interference patterns and the current state of the MCP ecosystem, we conducted a survey of MCP servers listed on two registries: smithery.ai&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Docker MCP Hub&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. Smithery is an MCP Server registry with over 7,000 first-party and community-contributed servers, which we sampled from the Smithery API. Likewise, Docker MCP Hub is a registry that distributes MCP servers as Docker images, and we manually collected popular entries. We then launched each server for inspection. After excluding servers that were empty or failed to launch, and deduplicating servers with identical features, 1,470 servers remained in our catalog.&lt;/p&gt;



&lt;p&gt;To&amp;nbsp;automate the&amp;nbsp;inspection&amp;nbsp;of&amp;nbsp;running MCP servers,&amp;nbsp;we developed an&amp;nbsp;MCP&amp;nbsp;Interviewer&amp;nbsp;tool.&amp;nbsp;The MCP&amp;nbsp;Interviewer&amp;nbsp;begins by cataloging the server’s tools, prompts, resources, resource templates, and capabilities.&amp;nbsp;From&amp;nbsp;this catalog we can compute&amp;nbsp;descriptive statistics&amp;nbsp;such as the number of tools, or the depth of the parameter&amp;nbsp;schemas.&amp;nbsp;&amp;nbsp;Then, given the list of available tools, the interviewer uses&amp;nbsp;an LLM (in our case,&amp;nbsp;OpenAI’s GPT-4.1)&amp;nbsp;to construct a functional testing&amp;nbsp;plan&amp;nbsp;that&amp;nbsp;calls each tool at least once, collecting outputs, errors, and statistics along the way. Finally,&amp;nbsp;the&amp;nbsp;interviewer&amp;nbsp;can&amp;nbsp;also&amp;nbsp;grade&amp;nbsp;more qualitative&amp;nbsp;criteria&amp;nbsp;by&amp;nbsp;using&amp;nbsp;an LLM&amp;nbsp;to&amp;nbsp;apply purpose-built rubrics&amp;nbsp;to&amp;nbsp;tool&amp;nbsp;schemas&amp;nbsp;and&amp;nbsp;tool call outputs.&amp;nbsp;&amp;nbsp;We are excited to&amp;nbsp;release the MCP Interviewer&amp;nbsp;as an open-source CLI&amp;nbsp;tool&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, so server developers can automatically evaluate their MCP servers with agent usability in mind,&amp;nbsp;and users can&amp;nbsp;validate&amp;nbsp;new servers.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;While our survey provides informative initial results, it also faces significant limitations, the most obvious of which is authorization: many of the most popular MCP servers provide access to services that require authorization to use, hindering automated analysis. We are often still able to collect static features from these servers but are limited in the functional testing that can be done.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="one-size-fits-all-but-some-more-than-others"&gt;One-size fits all (but some more than others)&lt;/h3&gt;



&lt;p&gt;So, what does our survey of MCP servers tell us about the MCP ecosystem? We will get into the numbers in a moment, but as we contemplate the statistics, there is one overarching theme to keep in mind: MCP servers do not know which clients or models they are working with, and present one common set of tools, prompts, and resources to everyone. However, some models handle long contexts and large tool spaces better than others (with diverging hard limits), and respond quite differently to common prompting patterns. For example, OpenAI’s guide on function calling&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; advises developers to:&lt;/p&gt;



&lt;p&gt;“&lt;em&gt;Include examples and edge cases, especially to rectify any recurring failures. (Note: Adding examples may hurt performance for reasoning models).”&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;So already, this places MCP at a disadvantage over vertical integrations that optimize to the operating environment. And with that, let’s dive into more numbers.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="tool-count"&gt;Tool count&lt;/h3&gt;



&lt;p&gt;While models generally vary in their proficiency for tool calling, the general trend has been that performance drops as the number of tools increases. For example, OpenAI limits developers to 128 tools, but recommends&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that developers:&lt;/p&gt;



&lt;p&gt;“&lt;em&gt;Keep the number of functions small for higher accuracy. Evaluate your performance with different numbers of functions. Aim for fewer than 20 functions at any one time, though this is just a soft suggestion.&lt;/em&gt;”&lt;/p&gt;



&lt;p&gt;While we expect this to improve with each new model generation, at present, large tool spaces can lower performance by up to 85% for some models&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. Thankfully, the majority of servers in our survey contain four or fewer tools. But there are outliers: the largest MCP server we cataloged adds 256 distinct tools, while the 10 next-largest servers add more than 100 tools each. Further down the list we find popular servers like Playwright-MCP&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; (29 tools, at the time of this writing), and GitHub MCP (91 tools, with subsets available at alternative endpoint URLs), which might be too large for some models.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="chart" class="wp-image-1149361" height="1024" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/tool-counts-per-server-1024x1024.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2: The number of tools listed by each catalogued server directly after initialization. Note: servers can change the tools they list at any time, but only 226 servers in our catalog declare this capability.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="response-length"&gt;Response length&lt;/h3&gt;



&lt;p&gt;Tools are generally called in agentic loops, where the output is then fed back into the model as input context. Models have hard limits on input context, but even within these limits, large contexts can drive costs up and performance down, so practical limits can be much lower&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. MCP offers no guidance on how many tokens a tool call can produce, and the size of some responses can come as a surprise. In our analysis, we consider the 2,443 tool calls across 1,312 unique tools that the MCP Interviewer was able to call successfully during the active testing phase of server inspection. While a majority of tools produced 98 or fewer tokens &lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, some tools are extraordinarily heavyweight: the top tool returned an average of 557,766 tokens, which is enough to swamp the context windows of many popular models like GPT-5. Further down the list, we find that 16 tools produce more than 128,000 tokens, swamping GPT-4o and other popular models. Even when responses fit into the context window length, overly long responses can significantly degrade performance (up to 91% in one study&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;), and limit the number of future calls that can be made. Of course, agents are free to implement their own context management strategies, but this behavior is left undefined in the MCP specification and server developers cannot count on any particular client behavior or strategy.&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td colspan="4"&gt;&lt;strong&gt;# of tools that would overflow context in&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Context Window&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;1 call&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;2 calls&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;3-5 calls&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;6-10 calls&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPT 4.1&lt;/td&gt;&lt;td&gt;1,000,000&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPT 5&lt;/td&gt;&lt;td&gt;400,000&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;25&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPT-4o, Llama 3.1,&lt;/td&gt;&lt;td&gt;128,000&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;33&lt;/td&gt;&lt;td&gt;40&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Qwen 3&lt;/td&gt;&lt;td&gt;32,000&lt;/td&gt;&lt;td&gt;56&lt;/td&gt;&lt;td&gt;37&lt;/td&gt;&lt;td&gt;86&lt;/td&gt;&lt;td&gt;90&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Phi-4&lt;/td&gt;&lt;td&gt;16,000&lt;/td&gt;&lt;td&gt;93&lt;/td&gt;&lt;td&gt;60&lt;/td&gt;&lt;td&gt;116&lt;/td&gt;&lt;td&gt;109&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Chart showing the average tool call output lengths (in tokens) for 1,312 tools, as observed by the MCP Interviewer’s functional test plan. The x-axis represents individual tools (sorted by index), and the y-axis displays the average output length on a logarithmic scale. Horizontal dashed lines indicate context window limits for GPT-4o (128k tokens) and GPT-5 (400k tokens). A pink annotation box summarizes statistics: total tools (1,312), mean (4,431 tokens), median (98 tokens), minimum (0 tokens), and maximum (557,766 tokens)." class="wp-image-1149213" height="935" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/image-1.png" width="936" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3: Tool call response length averages, in tokens, as&amp;nbsp;observed&amp;nbsp;by the MCP Interviewer’s functional test plan. Only successful tool calls are considered. Horizontal lines&amp;nbsp;indicate&amp;nbsp;context window limits for GPT-4o and GPT-5.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="tool-parameter-complexity"&gt;Tool parameter complexity&lt;/h3&gt;



&lt;p&gt;Mirroring the challenges from increasing&amp;nbsp;the&amp;nbsp;number of tools,&amp;nbsp;increasing the complexity of a tool’s parameter space can also lead to degradation.&amp;nbsp;For example, while MCP tools can take complex object types and structures as parameters,&amp;nbsp;composio&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;found that&amp;nbsp;flattening the parameter space could improve tool-calling performance&amp;nbsp;by 47%&amp;nbsp;compared to baseline performance.&amp;nbsp;&amp;nbsp;In our analysis, we&amp;nbsp;find&amp;nbsp;numerous examples of deeply nested structure—in&amp;nbsp;one&amp;nbsp;case, going&amp;nbsp;20&amp;nbsp;levels deep.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Chart showing the maximum depth of each tool’s input properties schema. The x-axis represents individual tools (sorted by index), and the y-axis shows the maximum property schema depth. Most tools have a depth  of 2 (named and annotated properties). A pink annotation box summarizes statistics: total tools (12,643), mean (2.24), median (2.00), standard deviation (1.38), minimum (0.00), and maximum (20.00). " class="wp-image-1149365" height="2560" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/input_schema_depth-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4: The maximum depth of each tool’s input properties schema. A depth of 0&amp;nbsp;indicates&amp;nbsp;a tool with no properties. A depth of 1&amp;nbsp;indicates&amp;nbsp;a tool with named properties but no annotations (e.g., no description or type). A depth of 2&amp;nbsp;indicates&amp;nbsp;a tool with named and annotated properties.&amp;nbsp;&amp;nbsp;A depth of 3+&amp;nbsp;indicates&amp;nbsp;a tool with structured properties that have&amp;nbsp;additional&amp;nbsp;nested annotations.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="namespacing-issues-and-naming-ambiguity"&gt;Namespacing issues and naming ambiguity&lt;/h3&gt;



&lt;p&gt;Another often-cited issue with the current MCP specification is the lack of a formal namespace mechanism&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. If two servers are registered to the same agent or application, and the servers have tool names in common, then disambiguation becomes impossible. Libraries like the OpenAI Agents SDK raise an error&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; under this circumstance. Clients, like Claude Code, prefix tool names with unique identifiers to work around this issue. In our analysis of MCP servers, we found name collisions between 775 tools. The most common collision was “search”, which appears across 32 distinct MCP servers. The following table lists the top 10 collisions.&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Tool Name&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Number of Instances&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;search&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;32&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;get_user&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;execute_query&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;list_tables&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;update_task&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;generate_image&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;send_message&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;execute_command&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;list_tasks&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;search_files&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;Even when names are unique, they can be semantically similar. If these tools behave similarly, then the redundancy may not be immediately problematic, but if you are expecting to call a particular tool then the name similarities raise the potential for confusion. The following table lists some examples of semantically similar tool names relating to web search:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;websearch&lt;/td&gt;&lt;td&gt;brave_web_search&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;search-web&lt;/td&gt;&lt;td&gt;tavily_web_search&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;web_search&lt;/td&gt;&lt;td&gt;google_news_search&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;search_web&lt;/td&gt;&lt;td&gt;google-play-search&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;search_webkr&lt;/td&gt;&lt;td&gt;google_search_parsed&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;google_search&lt;/td&gt;&lt;td&gt;search_google_images&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;search_google&lt;/td&gt;&lt;td&gt;get_webset_search_exa&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;ai_web_search&lt;/td&gt;&lt;td&gt;search_google_scholar&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;web_search_exa&lt;/td&gt;&lt;td&gt;duckduckgo_web_search&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;search_web_tool&lt;/td&gt;&lt;td&gt;google_search_scraper&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;web_search_agent&lt;/td&gt;&lt;td&gt;answer_query_websearch&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;batch-web-search&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="errors-and-error-messages"&gt;Errors and error messages&lt;/h3&gt;



&lt;p&gt;Like all software libraries, MCP will occasionally encounter error conditions. In these cases, it is important to provide sufficient information for the agent to handle the error and plan next steps. In our analysis, we found this was not always the case. While MCP provides an “IsError” flag to signal errors, we found that it was common for servers to handle errors by returning strings while leaving this flag set to false, signaling a normal exit. Out of 5,983 tool call results with no error flag, GPT-4.1 judged that 3,536 indicated errors in their content. More worrisome: the error messages were often of low quality. For instance, one tool providing web search capabilities failed with the string “error: job,” while another tool providing academic search returned “Please retry with 0 or fewer IDs.”&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="resource-sharing-conventions"&gt;Resource sharing conventions&lt;/h3&gt;



&lt;p&gt;Finally, in addition to tools, MCP allows servers to share resources and resource templates with clients. In our survey, only 112 (7.6%) servers reported any resources, while 74 (5%) provided templates. One potential reason for low adoption is that the current MCP specification provides limited guidance for when resources are retrieved, or how they are incorporated into context. One clearcut situation where a client might retrieve a resource is in response to a tool returning a resource_link&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; as a result — but only 4 tools exhibited this behavior in our survey (arguably, this would be the ideal behavior for tools that return very long, document-like responses, as outlined earlier).&lt;/p&gt;



&lt;p&gt;Conversely, a whole different set of issues arises when there is a need to share resources from the client to the server. Consider for example a tool that provides some analysis of a &lt;em&gt;local&lt;/em&gt; PDF file. In the case of a local MCP server utilizing STDIO transport, a local file path can be provided as an argument to the tool, but no similar conventions exist for delivering a local file to a remote MCP server. These issues are challenging enough when implementing a single server. When multiple tools or servers need to interact within the same system, the risk of interoperability errors compounds.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="recommendations"&gt;Recommendations&lt;/h2&gt;



&lt;p&gt;On balance, along any given dimension, the average MCP server is quite reasonable—but, as we have seen, outliers and diverging assumptions can introduce trouble. While we expect many of these challenges to improve with time, we are comfortable making small recommendations that we feel are evergreen. We organize them below by audience.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="protocol-developers"&gt;Protocol developers&lt;/h3&gt;



&lt;p&gt;We recognize the advantages of keeping MCP relatively lightweight, avoiding being overly prescriptive in an environment where AI models and use cases are rapidly changing. However, a few small recommendations are warranted. First, we believe MCP should be extended to include a specification for client-provided resources so that tools on remote servers have a mechanism for operating on specified local files or documents. This would more effectively position MCP as a clearinghouse for resources passed between steps of agentic workflows. The MCP specification would also benefit from taking a more opinionated stance on when resources are retrieved and used overall.&lt;/p&gt;



&lt;p&gt;Likewise, we believe&amp;nbsp;MCP should&amp;nbsp;quickly move to&amp;nbsp;provide formal namespaces&amp;nbsp;to eliminate tool name collisions.&amp;nbsp;If namespaces&amp;nbsp;are hierarchical, then this also provides a way of organizing large catalogs&amp;nbsp;of functions&amp;nbsp;into thematically&amp;nbsp;related tool&amp;nbsp;sets.&amp;nbsp;Tool sets, as an organizing principle,&amp;nbsp;are already showing some promise&amp;nbsp;in&amp;nbsp;GitHub MCP Server’s&amp;nbsp;dynamic tool discovery,&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and VS Code’s&amp;nbsp;tool grouping (with virtual tools)&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;,&amp;nbsp;where agents or users&amp;nbsp;can&amp;nbsp;enable and disable tools&amp;nbsp;as needed.&amp;nbsp;&amp;nbsp;In the future,&amp;nbsp;a standardized mechanism for grouping tools would allow&amp;nbsp;&lt;em&gt;clients&lt;/em&gt;&amp;nbsp;to engage in hierarchical tool-calling,&amp;nbsp;where they first select a category, then select a tool, without needing to keep all possible&amp;nbsp;tools in context.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="server-developers"&gt;Server developers&lt;/h3&gt;



&lt;p&gt;While our MCP Interviewer tool can catalog many outward-facing properties of MCP servers, developers are often in a much better position to characterize the nature of their tools. To this end, we believe developers should publish an MCP Server card alongside their servers or services, clearly outlining the runtime characteristics of the tools (e.g., the expected number of tokens generated, or expected latency of a tool call). Ideally developers should also indicate which models, agents and clients the server was tested with, how the tools were tested (e.g., provide sample tasks), list any known incompatibilities, and be mindful of limitations of various models throughout development.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="client-developers"&gt;Client developers&lt;/h3&gt;



&lt;p&gt;Client developers have the opportunity to experiment with various mitigations or optimizations that might help the average MCP server work better for a given system or environment. For example, clients could cache tool schemas, serving them as targets for prompt optimizations, or as an index for RAG-like tool selection approaches. To this end, Anthropic recently reported using a tool testing agent&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to rewrite the prompts of defective MCP servers, improving task completion time by 40%. Likewise, rather than waiting for the protocol to evolve, clients could take proactive steps to resolve name collisions— for example, generating namespaces from server names—and could reduce token outputs by summarizing or paginating long tool results.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="market-developers"&gt;Market developers&lt;/h3&gt;



&lt;p&gt;Finally, we see an opportunity for marketplaces to codify best-practices, spot compatibility issues at a global level, and perhaps centralize the generation and serving of model or agent-specific optimizations. Mirroring how a market like PyPI distributes Python wheels matched to a developer’s operating system or processor&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, an MCP marketplace could serve tool schemas optimized for a developer’s chosen LLM, agent or client library. We are already seeing small steps in this direction, with registries like Smithery providing customized launch configurations to match users’ clients.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="conclusion"&gt;Conclusion&lt;/h2&gt;



&lt;p&gt;In summary, the MCP&amp;nbsp;ecosystem offers significant value for AI agent development,&amp;nbsp;despite&amp;nbsp;some&amp;nbsp;early&amp;nbsp;growing pains.&amp;nbsp;Grounded in insights from the&amp;nbsp;MCP Interviewer&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and our survey of live servers, the evidence is clear: horizontal integration is expanding capability, yet it also exposes forms of toolspace interference that can erode end to end effectiveness. Anticipating rapid advances in model capability and growing architectural diversity, the recommendations provided here aim to ensure that protocol, server, client, and marketplace developers are&amp;nbsp;well positioned&amp;nbsp;to adapt and thrive. Key steps include implementing formal namespaces to&amp;nbsp;eliminate&amp;nbsp;collisions, enhancing protocol support for&amp;nbsp;client provided&amp;nbsp;resources, and encouraging transparent server documentation to foster interoperability and robust development practices across the ecosystem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;By embracing these evergreen recommendations and proactively addressing compatibility, usability, and optimization issues, the AI agent community can create a more reliable, scalable, and efficient infrastructure that benefits both developers and end users. The future of MCP is bright, with ample opportunities for experimentation, standardization, and collective progress.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to purple to pink. From left to right: a globe with a magnifying glass representing internet search, a central circle connected to smaller circles symbolizing network connectivity, and a checklist with two checkmarks and one empty box indicating task management." class="wp-image-1149369" height="576" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/ToolSpaceInterference-BlogHeroFeature-1400x788-1-1024x576.jpg" width="1024" /&gt;&lt;/figure&gt;



&lt;p&gt;This year&amp;nbsp;we’ve&amp;nbsp;seen&amp;nbsp;remarkable&amp;nbsp;advances in agentic AI, including&amp;nbsp;systems that conduct deep research,&amp;nbsp;operate&amp;nbsp;computers, complete substantial software engineering tasks, and tackle a range of other complex,&amp;nbsp;multi-step goals. In each case,&amp;nbsp;the industry relied&amp;nbsp;on careful vertical integration: tools and agents were co-designed, co-trained, and tested together&amp;nbsp;for peak&amp;nbsp;performance. For example,&amp;nbsp;OpenAI’s&amp;nbsp;recent models&amp;nbsp;presume&amp;nbsp;the&amp;nbsp;availability&amp;nbsp;of web search and document retrieval&amp;nbsp;tools&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. Likewise,&amp;nbsp;the prompts and actions&amp;nbsp;of&amp;nbsp;Magentic-One&amp;nbsp;are&amp;nbsp;set up to make hand-offs easy—for example, allowing the WebSurfer agent to pass downloaded files to the Coder agent. &amp;nbsp;But as agents proliferate, we anticipate strategies relying heavily on vertical integration will not age well.&amp;nbsp;Agents&amp;nbsp;from&amp;nbsp;different&amp;nbsp;developers&amp;nbsp;or companies will&amp;nbsp;increasingly&amp;nbsp;encounter&amp;nbsp;each other and&amp;nbsp;must&amp;nbsp;work together to complete tasks, in what we refer to as a&amp;nbsp;&lt;em&gt;society of agents&lt;/em&gt;.&amp;nbsp;These systems can vary in how coordinated they are, how aligned their goals are, and how much information they share. Can heterogenous agents and tools cooperate&amp;nbsp;in this&amp;nbsp;setting, or will they hinder one another and slow progress?&lt;/p&gt;



&lt;p&gt;Early clues have&amp;nbsp;emerged&amp;nbsp;from an&amp;nbsp;unexpected&amp;nbsp;source:&amp;nbsp;namely,&amp;nbsp;Model Context Protocol&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;(MCP). Since January 2025, MCP has grown from a&amp;nbsp;promising spec to a&amp;nbsp;thriving&amp;nbsp;market&amp;nbsp;of&amp;nbsp;tool&amp;nbsp;servers.&amp;nbsp;As an example, Zapier boasts a catalog of 30,000 tools&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;across 7,000 services.&amp;nbsp;Composio&amp;nbsp;provide over 100 managed MCP servers&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, surfacing hundreds of tools. Hugging&amp;nbsp;Face is now serving&amp;nbsp;many&amp;nbsp;Spaces&amp;nbsp;apps over MCP&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and Shopify has enabled MCP for millions of storefronts&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;A&amp;nbsp;society of&amp;nbsp;&lt;em&gt;tools&lt;/em&gt;&amp;nbsp;is already here, and it promises to&amp;nbsp;extend&amp;nbsp;agent capabilities through&amp;nbsp;cross-provider&amp;nbsp;horizontal integration.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So,&amp;nbsp;what does MCP have to say about&amp;nbsp;horizontal integration? As catalogs grow,&amp;nbsp;we expect some new failure modes to surface.&amp;nbsp;This&amp;nbsp;blog&amp;nbsp;post introduces&amp;nbsp;these&amp;nbsp;as &lt;em&gt;tool-space interference&lt;/em&gt;, and sketches both early observations and some pragmatic interventions to keep the society&amp;nbsp;we’re&amp;nbsp;building&amp;nbsp;from stepping on its own feet.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Tool-space interference describes situations where otherwise reasonable tools or agents, when co-present, reduce end-to-end effectiveness. This can look like longer action sequences, higher token cost, brittle recovery from errors, or, in some cases, task failure.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="a-framing-example"&gt;A framing example&lt;/h2&gt;



&lt;p&gt;Consider MCP as a means for extending Magentic-One, a generalist multi-agent system we released last year, to cover more software engineering tasks. Magentic-One ships with agents to write code, interact with the computer terminal, browse the web, and access local files. To help Magentic-One navigate version control, find issues to solve, and make pull requests, we could add an agent equipped with the GitHub MCP Server. However, now each time the team encounters a task involving GitHub, it must choose whether to visit github.com in the browser, execute a git command at the command line, or engage the GitHub MCP server. As the task progresses, agent understanding of state can also diverge: changing the branch in the browser won’t change the branch in the terminal, and an authorized MCP tool does not imply authorization in the browser.&amp;nbsp;Thus, while any single agent might complete the task efficiently, the larger set of agents might misunderstand or interfere with one another, leading to additional rounds of debugging, or even complete task failure.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Diagram depicting Magentic-One's multi-agentic architecture. An Orchestrator agent has access to 4 specialized sub-agents: a Coder agent that can write code and reason to sol solve tasks, a Computer Terminal Agent that can execute code written by the Coder agent, a WebSurfer agent that browse the internet (navigate pages, fill forms, etc), and a FileSurfer agent that can navigate files (e.g. PDFs, PPTx, etc). The diagram is annotated to show that for any incoming git-related task, the Orchestrator agent has to decide at evert orchestration step whether to access Git CLI via ComputerTerminal, visit Github site via WebSurfer, or directly access Github’s MCP server." class="wp-image-1149211" height="410" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/image.png" width="1021" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1: We can extend&amp;nbsp;Magentic-One by adding an agent that equips the GitHub MCP server. However, on every turn involving a git-related task, the orchestrator will need to decide between messaging the Computer Terminal agent (with access to the git command line interface), WebSurfer agent (with access to github.com), and the agent with the GitHub MCP server. This overlap raises the possibility that they will interfere with one another.&amp;nbsp;&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;







&lt;p&gt;To better understand the potential interference patterns and the current state of the MCP ecosystem, we conducted a survey of MCP servers listed on two registries: smithery.ai&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Docker MCP Hub&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. Smithery is an MCP Server registry with over 7,000 first-party and community-contributed servers, which we sampled from the Smithery API. Likewise, Docker MCP Hub is a registry that distributes MCP servers as Docker images, and we manually collected popular entries. We then launched each server for inspection. After excluding servers that were empty or failed to launch, and deduplicating servers with identical features, 1,470 servers remained in our catalog.&lt;/p&gt;



&lt;p&gt;To&amp;nbsp;automate the&amp;nbsp;inspection&amp;nbsp;of&amp;nbsp;running MCP servers,&amp;nbsp;we developed an&amp;nbsp;MCP&amp;nbsp;Interviewer&amp;nbsp;tool.&amp;nbsp;The MCP&amp;nbsp;Interviewer&amp;nbsp;begins by cataloging the server’s tools, prompts, resources, resource templates, and capabilities.&amp;nbsp;From&amp;nbsp;this catalog we can compute&amp;nbsp;descriptive statistics&amp;nbsp;such as the number of tools, or the depth of the parameter&amp;nbsp;schemas.&amp;nbsp;&amp;nbsp;Then, given the list of available tools, the interviewer uses&amp;nbsp;an LLM (in our case,&amp;nbsp;OpenAI’s GPT-4.1)&amp;nbsp;to construct a functional testing&amp;nbsp;plan&amp;nbsp;that&amp;nbsp;calls each tool at least once, collecting outputs, errors, and statistics along the way. Finally,&amp;nbsp;the&amp;nbsp;interviewer&amp;nbsp;can&amp;nbsp;also&amp;nbsp;grade&amp;nbsp;more qualitative&amp;nbsp;criteria&amp;nbsp;by&amp;nbsp;using&amp;nbsp;an LLM&amp;nbsp;to&amp;nbsp;apply purpose-built rubrics&amp;nbsp;to&amp;nbsp;tool&amp;nbsp;schemas&amp;nbsp;and&amp;nbsp;tool call outputs.&amp;nbsp;&amp;nbsp;We are excited to&amp;nbsp;release the MCP Interviewer&amp;nbsp;as an open-source CLI&amp;nbsp;tool&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, so server developers can automatically evaluate their MCP servers with agent usability in mind,&amp;nbsp;and users can&amp;nbsp;validate&amp;nbsp;new servers.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;While our survey provides informative initial results, it also faces significant limitations, the most obvious of which is authorization: many of the most popular MCP servers provide access to services that require authorization to use, hindering automated analysis. We are often still able to collect static features from these servers but are limited in the functional testing that can be done.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="one-size-fits-all-but-some-more-than-others"&gt;One-size fits all (but some more than others)&lt;/h3&gt;



&lt;p&gt;So, what does our survey of MCP servers tell us about the MCP ecosystem? We will get into the numbers in a moment, but as we contemplate the statistics, there is one overarching theme to keep in mind: MCP servers do not know which clients or models they are working with, and present one common set of tools, prompts, and resources to everyone. However, some models handle long contexts and large tool spaces better than others (with diverging hard limits), and respond quite differently to common prompting patterns. For example, OpenAI’s guide on function calling&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; advises developers to:&lt;/p&gt;



&lt;p&gt;“&lt;em&gt;Include examples and edge cases, especially to rectify any recurring failures. (Note: Adding examples may hurt performance for reasoning models).”&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;So already, this places MCP at a disadvantage over vertical integrations that optimize to the operating environment. And with that, let’s dive into more numbers.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="tool-count"&gt;Tool count&lt;/h3&gt;



&lt;p&gt;While models generally vary in their proficiency for tool calling, the general trend has been that performance drops as the number of tools increases. For example, OpenAI limits developers to 128 tools, but recommends&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that developers:&lt;/p&gt;



&lt;p&gt;“&lt;em&gt;Keep the number of functions small for higher accuracy. Evaluate your performance with different numbers of functions. Aim for fewer than 20 functions at any one time, though this is just a soft suggestion.&lt;/em&gt;”&lt;/p&gt;



&lt;p&gt;While we expect this to improve with each new model generation, at present, large tool spaces can lower performance by up to 85% for some models&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. Thankfully, the majority of servers in our survey contain four or fewer tools. But there are outliers: the largest MCP server we cataloged adds 256 distinct tools, while the 10 next-largest servers add more than 100 tools each. Further down the list we find popular servers like Playwright-MCP&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; (29 tools, at the time of this writing), and GitHub MCP (91 tools, with subsets available at alternative endpoint URLs), which might be too large for some models.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="chart" class="wp-image-1149361" height="1024" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/tool-counts-per-server-1024x1024.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2: The number of tools listed by each catalogued server directly after initialization. Note: servers can change the tools they list at any time, but only 226 servers in our catalog declare this capability.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="response-length"&gt;Response length&lt;/h3&gt;



&lt;p&gt;Tools are generally called in agentic loops, where the output is then fed back into the model as input context. Models have hard limits on input context, but even within these limits, large contexts can drive costs up and performance down, so practical limits can be much lower&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. MCP offers no guidance on how many tokens a tool call can produce, and the size of some responses can come as a surprise. In our analysis, we consider the 2,443 tool calls across 1,312 unique tools that the MCP Interviewer was able to call successfully during the active testing phase of server inspection. While a majority of tools produced 98 or fewer tokens &lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, some tools are extraordinarily heavyweight: the top tool returned an average of 557,766 tokens, which is enough to swamp the context windows of many popular models like GPT-5. Further down the list, we find that 16 tools produce more than 128,000 tokens, swamping GPT-4o and other popular models. Even when responses fit into the context window length, overly long responses can significantly degrade performance (up to 91% in one study&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;), and limit the number of future calls that can be made. Of course, agents are free to implement their own context management strategies, but this behavior is left undefined in the MCP specification and server developers cannot count on any particular client behavior or strategy.&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td colspan="4"&gt;&lt;strong&gt;# of tools that would overflow context in&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Context Window&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;1 call&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;2 calls&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;3-5 calls&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;6-10 calls&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPT 4.1&lt;/td&gt;&lt;td&gt;1,000,000&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPT 5&lt;/td&gt;&lt;td&gt;400,000&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;7&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;25&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPT-4o, Llama 3.1,&lt;/td&gt;&lt;td&gt;128,000&lt;/td&gt;&lt;td&gt;16&lt;/td&gt;&lt;td&gt;15&lt;/td&gt;&lt;td&gt;33&lt;/td&gt;&lt;td&gt;40&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Qwen 3&lt;/td&gt;&lt;td&gt;32,000&lt;/td&gt;&lt;td&gt;56&lt;/td&gt;&lt;td&gt;37&lt;/td&gt;&lt;td&gt;86&lt;/td&gt;&lt;td&gt;90&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Phi-4&lt;/td&gt;&lt;td&gt;16,000&lt;/td&gt;&lt;td&gt;93&lt;/td&gt;&lt;td&gt;60&lt;/td&gt;&lt;td&gt;116&lt;/td&gt;&lt;td&gt;109&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Chart showing the average tool call output lengths (in tokens) for 1,312 tools, as observed by the MCP Interviewer’s functional test plan. The x-axis represents individual tools (sorted by index), and the y-axis displays the average output length on a logarithmic scale. Horizontal dashed lines indicate context window limits for GPT-4o (128k tokens) and GPT-5 (400k tokens). A pink annotation box summarizes statistics: total tools (1,312), mean (4,431 tokens), median (98 tokens), minimum (0 tokens), and maximum (557,766 tokens)." class="wp-image-1149213" height="935" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/image-1.png" width="936" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3: Tool call response length averages, in tokens, as&amp;nbsp;observed&amp;nbsp;by the MCP Interviewer’s functional test plan. Only successful tool calls are considered. Horizontal lines&amp;nbsp;indicate&amp;nbsp;context window limits for GPT-4o and GPT-5.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="tool-parameter-complexity"&gt;Tool parameter complexity&lt;/h3&gt;



&lt;p&gt;Mirroring the challenges from increasing&amp;nbsp;the&amp;nbsp;number of tools,&amp;nbsp;increasing the complexity of a tool’s parameter space can also lead to degradation.&amp;nbsp;For example, while MCP tools can take complex object types and structures as parameters,&amp;nbsp;composio&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;found that&amp;nbsp;flattening the parameter space could improve tool-calling performance&amp;nbsp;by 47%&amp;nbsp;compared to baseline performance.&amp;nbsp;&amp;nbsp;In our analysis, we&amp;nbsp;find&amp;nbsp;numerous examples of deeply nested structure—in&amp;nbsp;one&amp;nbsp;case, going&amp;nbsp;20&amp;nbsp;levels deep.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Chart showing the maximum depth of each tool’s input properties schema. The x-axis represents individual tools (sorted by index), and the y-axis shows the maximum property schema depth. Most tools have a depth  of 2 (named and annotated properties). A pink annotation box summarizes statistics: total tools (12,643), mean (2.24), median (2.00), standard deviation (1.38), minimum (0.00), and maximum (20.00). " class="wp-image-1149365" height="2560" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/09/input_schema_depth-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4: The maximum depth of each tool’s input properties schema. A depth of 0&amp;nbsp;indicates&amp;nbsp;a tool with no properties. A depth of 1&amp;nbsp;indicates&amp;nbsp;a tool with named properties but no annotations (e.g., no description or type). A depth of 2&amp;nbsp;indicates&amp;nbsp;a tool with named and annotated properties.&amp;nbsp;&amp;nbsp;A depth of 3+&amp;nbsp;indicates&amp;nbsp;a tool with structured properties that have&amp;nbsp;additional&amp;nbsp;nested annotations.&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="namespacing-issues-and-naming-ambiguity"&gt;Namespacing issues and naming ambiguity&lt;/h3&gt;



&lt;p&gt;Another often-cited issue with the current MCP specification is the lack of a formal namespace mechanism&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. If two servers are registered to the same agent or application, and the servers have tool names in common, then disambiguation becomes impossible. Libraries like the OpenAI Agents SDK raise an error&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; under this circumstance. Clients, like Claude Code, prefix tool names with unique identifiers to work around this issue. In our analysis of MCP servers, we found name collisions between 775 tools. The most common collision was “search”, which appears across 32 distinct MCP servers. The following table lists the top 10 collisions.&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Tool Name&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Number of Instances&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;search&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;32&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;get_user&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;execute_query&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;11&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;list_tables&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;10&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;update_task&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;generate_image&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;send_message&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;9&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;execute_command&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;list_tasks&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;search_files&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;8&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;Even when names are unique, they can be semantically similar. If these tools behave similarly, then the redundancy may not be immediately problematic, but if you are expecting to call a particular tool then the name similarities raise the potential for confusion. The following table lists some examples of semantically similar tool names relating to web search:&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;websearch&lt;/td&gt;&lt;td&gt;brave_web_search&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;search-web&lt;/td&gt;&lt;td&gt;tavily_web_search&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;web_search&lt;/td&gt;&lt;td&gt;google_news_search&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;search_web&lt;/td&gt;&lt;td&gt;google-play-search&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;search_webkr&lt;/td&gt;&lt;td&gt;google_search_parsed&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;google_search&lt;/td&gt;&lt;td&gt;search_google_images&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;search_google&lt;/td&gt;&lt;td&gt;get_webset_search_exa&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;ai_web_search&lt;/td&gt;&lt;td&gt;search_google_scholar&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;web_search_exa&lt;/td&gt;&lt;td&gt;duckduckgo_web_search&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;search_web_tool&lt;/td&gt;&lt;td&gt;google_search_scraper&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;web_search_agent&lt;/td&gt;&lt;td&gt;answer_query_websearch&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;batch-web-search&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;h3 class="wp-block-heading" id="errors-and-error-messages"&gt;Errors and error messages&lt;/h3&gt;



&lt;p&gt;Like all software libraries, MCP will occasionally encounter error conditions. In these cases, it is important to provide sufficient information for the agent to handle the error and plan next steps. In our analysis, we found this was not always the case. While MCP provides an “IsError” flag to signal errors, we found that it was common for servers to handle errors by returning strings while leaving this flag set to false, signaling a normal exit. Out of 5,983 tool call results with no error flag, GPT-4.1 judged that 3,536 indicated errors in their content. More worrisome: the error messages were often of low quality. For instance, one tool providing web search capabilities failed with the string “error: job,” while another tool providing academic search returned “Please retry with 0 or fewer IDs.”&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="resource-sharing-conventions"&gt;Resource sharing conventions&lt;/h3&gt;



&lt;p&gt;Finally, in addition to tools, MCP allows servers to share resources and resource templates with clients. In our survey, only 112 (7.6%) servers reported any resources, while 74 (5%) provided templates. One potential reason for low adoption is that the current MCP specification provides limited guidance for when resources are retrieved, or how they are incorporated into context. One clearcut situation where a client might retrieve a resource is in response to a tool returning a resource_link&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; as a result — but only 4 tools exhibited this behavior in our survey (arguably, this would be the ideal behavior for tools that return very long, document-like responses, as outlined earlier).&lt;/p&gt;



&lt;p&gt;Conversely, a whole different set of issues arises when there is a need to share resources from the client to the server. Consider for example a tool that provides some analysis of a &lt;em&gt;local&lt;/em&gt; PDF file. In the case of a local MCP server utilizing STDIO transport, a local file path can be provided as an argument to the tool, but no similar conventions exist for delivering a local file to a remote MCP server. These issues are challenging enough when implementing a single server. When multiple tools or servers need to interact within the same system, the risk of interoperability errors compounds.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="recommendations"&gt;Recommendations&lt;/h2&gt;



&lt;p&gt;On balance, along any given dimension, the average MCP server is quite reasonable—but, as we have seen, outliers and diverging assumptions can introduce trouble. While we expect many of these challenges to improve with time, we are comfortable making small recommendations that we feel are evergreen. We organize them below by audience.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="protocol-developers"&gt;Protocol developers&lt;/h3&gt;



&lt;p&gt;We recognize the advantages of keeping MCP relatively lightweight, avoiding being overly prescriptive in an environment where AI models and use cases are rapidly changing. However, a few small recommendations are warranted. First, we believe MCP should be extended to include a specification for client-provided resources so that tools on remote servers have a mechanism for operating on specified local files or documents. This would more effectively position MCP as a clearinghouse for resources passed between steps of agentic workflows. The MCP specification would also benefit from taking a more opinionated stance on when resources are retrieved and used overall.&lt;/p&gt;



&lt;p&gt;Likewise, we believe&amp;nbsp;MCP should&amp;nbsp;quickly move to&amp;nbsp;provide formal namespaces&amp;nbsp;to eliminate tool name collisions.&amp;nbsp;If namespaces&amp;nbsp;are hierarchical, then this also provides a way of organizing large catalogs&amp;nbsp;of functions&amp;nbsp;into thematically&amp;nbsp;related tool&amp;nbsp;sets.&amp;nbsp;Tool sets, as an organizing principle,&amp;nbsp;are already showing some promise&amp;nbsp;in&amp;nbsp;GitHub MCP Server’s&amp;nbsp;dynamic tool discovery,&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and VS Code’s&amp;nbsp;tool grouping (with virtual tools)&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;,&amp;nbsp;where agents or users&amp;nbsp;can&amp;nbsp;enable and disable tools&amp;nbsp;as needed.&amp;nbsp;&amp;nbsp;In the future,&amp;nbsp;a standardized mechanism for grouping tools would allow&amp;nbsp;&lt;em&gt;clients&lt;/em&gt;&amp;nbsp;to engage in hierarchical tool-calling,&amp;nbsp;where they first select a category, then select a tool, without needing to keep all possible&amp;nbsp;tools in context.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="server-developers"&gt;Server developers&lt;/h3&gt;



&lt;p&gt;While our MCP Interviewer tool can catalog many outward-facing properties of MCP servers, developers are often in a much better position to characterize the nature of their tools. To this end, we believe developers should publish an MCP Server card alongside their servers or services, clearly outlining the runtime characteristics of the tools (e.g., the expected number of tokens generated, or expected latency of a tool call). Ideally developers should also indicate which models, agents and clients the server was tested with, how the tools were tested (e.g., provide sample tasks), list any known incompatibilities, and be mindful of limitations of various models throughout development.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="client-developers"&gt;Client developers&lt;/h3&gt;



&lt;p&gt;Client developers have the opportunity to experiment with various mitigations or optimizations that might help the average MCP server work better for a given system or environment. For example, clients could cache tool schemas, serving them as targets for prompt optimizations, or as an index for RAG-like tool selection approaches. To this end, Anthropic recently reported using a tool testing agent&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to rewrite the prompts of defective MCP servers, improving task completion time by 40%. Likewise, rather than waiting for the protocol to evolve, clients could take proactive steps to resolve name collisions— for example, generating namespaces from server names—and could reduce token outputs by summarizing or paginating long tool results.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="market-developers"&gt;Market developers&lt;/h3&gt;



&lt;p&gt;Finally, we see an opportunity for marketplaces to codify best-practices, spot compatibility issues at a global level, and perhaps centralize the generation and serving of model or agent-specific optimizations. Mirroring how a market like PyPI distributes Python wheels matched to a developer’s operating system or processor&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, an MCP marketplace could serve tool schemas optimized for a developer’s chosen LLM, agent or client library. We are already seeing small steps in this direction, with registries like Smithery providing customized launch configurations to match users’ clients.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="conclusion"&gt;Conclusion&lt;/h2&gt;



&lt;p&gt;In summary, the MCP&amp;nbsp;ecosystem offers significant value for AI agent development,&amp;nbsp;despite&amp;nbsp;some&amp;nbsp;early&amp;nbsp;growing pains.&amp;nbsp;Grounded in insights from the&amp;nbsp;MCP Interviewer&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and our survey of live servers, the evidence is clear: horizontal integration is expanding capability, yet it also exposes forms of toolspace interference that can erode end to end effectiveness. Anticipating rapid advances in model capability and growing architectural diversity, the recommendations provided here aim to ensure that protocol, server, client, and marketplace developers are&amp;nbsp;well positioned&amp;nbsp;to adapt and thrive. Key steps include implementing formal namespaces to&amp;nbsp;eliminate&amp;nbsp;collisions, enhancing protocol support for&amp;nbsp;client provided&amp;nbsp;resources, and encouraging transparent server documentation to foster interoperability and robust development practices across the ecosystem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;By embracing these evergreen recommendations and proactively addressing compatibility, usability, and optimization issues, the AI agent community can create a more reliable, scalable, and efficient infrastructure that benefits both developers and end users. The future of MCP is bright, with ample opportunities for experimentation, standardization, and collective progress.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/tool-space-interference-in-the-mcp-era-designing-for-agent-compatibility-at-scale/</guid><pubDate>Thu, 11 Sep 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] We can’t “make American children healthy again” without tackling the gun crisis (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/11/1123553/maha-report-gun-violence-checkup/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/GettyImages-695270060.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;Note for readers: This newsletter discusses gun violence, a raw and tragic issue in America. It was already in progress on Wednesday when a school shooting occurred at Evergreen High School in Colorado and Charlie Kirk was shot and killed at Utah Valley University.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Earlier this week, the Trump administration’s Make America Healthy Again movement released a strategy for improving the health and well-being of American children. The report was titled—you guessed it—&lt;em&gt;Make Our Children Healthy Again&lt;/em&gt;.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Robert F. Kennedy Jr., who leads the Department of Health and Human Services, and his colleagues are focusing on four key aspects of child health: diet, exercise, chemical exposure, and overmedicalization.&lt;/p&gt;  &lt;p&gt;Anyone who’s been listening to RFK Jr. posturing on health and wellness won’t be surprised by these priorities. And the first two are pretty obvious. On the whole, American children should be eating more healthily. And they should be getting more exercise.&lt;/p&gt; 
 &lt;p&gt;But there’s a glaring omission. The leading cause of death for American children and teenagers isn’t ultraprocessed food or exposure to some chemical. It’s gun violence.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Yesterday’s news of yet more high-profile shootings at schools in the US throws this disconnect into even sharper relief. Experts believe it is time to treat gun violence in the US as what it is: a public health crisis.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;I live in London, UK, with my husband and two young children. We don’t live in a particularly fancy part of the city—in one recent ranking of London boroughs from most to least posh, ours came in at 30th out of 33. I do worry about crime. But I don’t worry about gun violence.&lt;/p&gt;  &lt;p&gt;That changed when I temporarily moved my family to the US a couple of years ago. We rented the ground-floor apartment of a lovely home in Cambridge, Massachusetts—a beautiful area with good schools, pastel-colored houses, and fluffy rabbits hopping about. It wasn’t until after we’d moved in that my landlord told me he had guns in the basement.&lt;/p&gt;  &lt;p&gt;My daughter joined the kindergarten of a local school that specialized in music, and we took her younger sister along to watch the kids sing songs about friendship. It was all so heartwarming—until we noticed the school security officer at the entrance carrying a gun.&lt;/p&gt;  &lt;p&gt;Later in the year, I received an email alert from the superintendent of the Cambridge Public Schools. “At approximately 1:45 this afternoon, a Cambridge Police Department Youth Officer assigned to Cambridge Rindge and Latin School accidentally discharged their firearm while using a staff bathroom inside the school,” the message began. “The school day was not disrupted.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;These experiences, among others, truly brought home to me the cultural differences over firearms between the US and the UK (along with most other countries). For the first time, I worried about my children’s exposure to them. I banned my children from accessing parts of the house. I felt guilty that my four-year-old had to learn what to do if a gunman entered her school.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But it’s the statistics that are the most upsetting.&lt;/p&gt;  &lt;p&gt;In 2023, 46,728 people died from gun violence in the US, according to a report published in June by the Johns Hopkins Bloomberg School of Public Health. That includes both homicides and suicides, and it breaks down to 128 deaths &lt;em&gt;per day&lt;/em&gt;, on average. The majority of those who die from gun violence are adults. But the figures for children are sickening, too. In 2023, 2,566 young people died from gun violence. Of those, 234 were under the age of 10.&lt;/p&gt;  &lt;p&gt;Gun death rates among children have more than doubled since 2013. Firearms are involved in more child deaths than cancer or car crashes.&lt;/p&gt; 

 &lt;p&gt;Many other children survive gun violence with nonfatal—but often life-changing—injuries. And the impacts are felt beyond those who are physically injured. Witnessing gun violence or hearing gunshots can understandably cause fear, sadness, and distress.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;That’s worth bearing in mind when you consider that there have been 434 school shootings in the US since Columbine in 1999. The &lt;em&gt;Washington Post&lt;/em&gt; estimates that 397,000 students have experienced gun violence at school in that period. Another school shooting took place at Evergreen High School in Colorado on Wednesday, adding to that total.&lt;/p&gt;  &lt;p&gt;“Being indirectly exposed to gun violence takes its toll on our mental health and children’s ability to learn,” says Daniel Webster, Bloomberg Professor of American Health at the Johns Hopkins Center for Gun Violence Solutions in Baltimore.&lt;/p&gt;  &lt;p&gt;The MAHA report states that “American youth face a mental health crisis,” going on to note that “suicide deaths among 10- to 24-year-olds increased by 62% from 2007 to 2021” and that “suicide is now the leading cause of death in teens aged 15-19.” What it doesn’t say is that around half of these suicides involve guns.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;“When you add all these dimensions, [gun violence is] a very huge public health problem,” says Webster.&lt;/p&gt;  &lt;p&gt;Researchers who study gun violence have been saying the same thing for years. And in 2024, then US Surgeon General Vivek Murthy declared it a public health crisis. “We don’t have to subject our children to the ongoing horror of firearm violence in America,” Murthy said in a statement at the time. Instead, he argued, we should tackle the problem using a public health approach.&lt;/p&gt;  &lt;p&gt;Part of that approach involves identifying who is at the greatest risk and offering support to lower that risk, says Webster. Young men who live in poor communities tend to have the highest risk of gun violence, he says, as do those who experience crisis or turmoil. Trying to mediate conflicts or limit access to firearms, even temporarily, can help lower the incidence of gun violence, he says.&lt;/p&gt;  &lt;p&gt;There’s an element of social contagion, too, adds Webster. Shooting begets more shooting. He likens it to the outbreak of an infectious disease. “When more people get vaccinated … infection rates go down,” he says. “Almost exactly the same thing happens with gun violence.”&lt;/p&gt; 
 &lt;p&gt;But existing efforts are already under threat. The Trump administration has eliminated hundreds of millions of dollars in grants for organizations working to reduce gun violence.&lt;/p&gt;  &lt;p&gt;Webster thinks the MAHA report has “missed the mark” when it comes to the health and well-being of children in the US. “This document is almost the polar opposite to how many people in public health think,” he says. “We have to acknowledge that injuries and deaths from firearms are a big threat to the health and safety of children and adolescents.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/GettyImages-695270060.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;Note for readers: This newsletter discusses gun violence, a raw and tragic issue in America. It was already in progress on Wednesday when a school shooting occurred at Evergreen High School in Colorado and Charlie Kirk was shot and killed at Utah Valley University.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Earlier this week, the Trump administration’s Make America Healthy Again movement released a strategy for improving the health and well-being of American children. The report was titled—you guessed it—&lt;em&gt;Make Our Children Healthy Again&lt;/em&gt;.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Robert F. Kennedy Jr., who leads the Department of Health and Human Services, and his colleagues are focusing on four key aspects of child health: diet, exercise, chemical exposure, and overmedicalization.&lt;/p&gt;  &lt;p&gt;Anyone who’s been listening to RFK Jr. posturing on health and wellness won’t be surprised by these priorities. And the first two are pretty obvious. On the whole, American children should be eating more healthily. And they should be getting more exercise.&lt;/p&gt; 
 &lt;p&gt;But there’s a glaring omission. The leading cause of death for American children and teenagers isn’t ultraprocessed food or exposure to some chemical. It’s gun violence.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Yesterday’s news of yet more high-profile shootings at schools in the US throws this disconnect into even sharper relief. Experts believe it is time to treat gun violence in the US as what it is: a public health crisis.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;I live in London, UK, with my husband and two young children. We don’t live in a particularly fancy part of the city—in one recent ranking of London boroughs from most to least posh, ours came in at 30th out of 33. I do worry about crime. But I don’t worry about gun violence.&lt;/p&gt;  &lt;p&gt;That changed when I temporarily moved my family to the US a couple of years ago. We rented the ground-floor apartment of a lovely home in Cambridge, Massachusetts—a beautiful area with good schools, pastel-colored houses, and fluffy rabbits hopping about. It wasn’t until after we’d moved in that my landlord told me he had guns in the basement.&lt;/p&gt;  &lt;p&gt;My daughter joined the kindergarten of a local school that specialized in music, and we took her younger sister along to watch the kids sing songs about friendship. It was all so heartwarming—until we noticed the school security officer at the entrance carrying a gun.&lt;/p&gt;  &lt;p&gt;Later in the year, I received an email alert from the superintendent of the Cambridge Public Schools. “At approximately 1:45 this afternoon, a Cambridge Police Department Youth Officer assigned to Cambridge Rindge and Latin School accidentally discharged their firearm while using a staff bathroom inside the school,” the message began. “The school day was not disrupted.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;These experiences, among others, truly brought home to me the cultural differences over firearms between the US and the UK (along with most other countries). For the first time, I worried about my children’s exposure to them. I banned my children from accessing parts of the house. I felt guilty that my four-year-old had to learn what to do if a gunman entered her school.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But it’s the statistics that are the most upsetting.&lt;/p&gt;  &lt;p&gt;In 2023, 46,728 people died from gun violence in the US, according to a report published in June by the Johns Hopkins Bloomberg School of Public Health. That includes both homicides and suicides, and it breaks down to 128 deaths &lt;em&gt;per day&lt;/em&gt;, on average. The majority of those who die from gun violence are adults. But the figures for children are sickening, too. In 2023, 2,566 young people died from gun violence. Of those, 234 were under the age of 10.&lt;/p&gt;  &lt;p&gt;Gun death rates among children have more than doubled since 2013. Firearms are involved in more child deaths than cancer or car crashes.&lt;/p&gt; 

 &lt;p&gt;Many other children survive gun violence with nonfatal—but often life-changing—injuries. And the impacts are felt beyond those who are physically injured. Witnessing gun violence or hearing gunshots can understandably cause fear, sadness, and distress.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;That’s worth bearing in mind when you consider that there have been 434 school shootings in the US since Columbine in 1999. The &lt;em&gt;Washington Post&lt;/em&gt; estimates that 397,000 students have experienced gun violence at school in that period. Another school shooting took place at Evergreen High School in Colorado on Wednesday, adding to that total.&lt;/p&gt;  &lt;p&gt;“Being indirectly exposed to gun violence takes its toll on our mental health and children’s ability to learn,” says Daniel Webster, Bloomberg Professor of American Health at the Johns Hopkins Center for Gun Violence Solutions in Baltimore.&lt;/p&gt;  &lt;p&gt;The MAHA report states that “American youth face a mental health crisis,” going on to note that “suicide deaths among 10- to 24-year-olds increased by 62% from 2007 to 2021” and that “suicide is now the leading cause of death in teens aged 15-19.” What it doesn’t say is that around half of these suicides involve guns.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;“When you add all these dimensions, [gun violence is] a very huge public health problem,” says Webster.&lt;/p&gt;  &lt;p&gt;Researchers who study gun violence have been saying the same thing for years. And in 2024, then US Surgeon General Vivek Murthy declared it a public health crisis. “We don’t have to subject our children to the ongoing horror of firearm violence in America,” Murthy said in a statement at the time. Instead, he argued, we should tackle the problem using a public health approach.&lt;/p&gt;  &lt;p&gt;Part of that approach involves identifying who is at the greatest risk and offering support to lower that risk, says Webster. Young men who live in poor communities tend to have the highest risk of gun violence, he says, as do those who experience crisis or turmoil. Trying to mediate conflicts or limit access to firearms, even temporarily, can help lower the incidence of gun violence, he says.&lt;/p&gt;  &lt;p&gt;There’s an element of social contagion, too, adds Webster. Shooting begets more shooting. He likens it to the outbreak of an infectious disease. “When more people get vaccinated … infection rates go down,” he says. “Almost exactly the same thing happens with gun violence.”&lt;/p&gt; 
 &lt;p&gt;But existing efforts are already under threat. The Trump administration has eliminated hundreds of millions of dollars in grants for organizations working to reduce gun violence.&lt;/p&gt;  &lt;p&gt;Webster thinks the MAHA report has “missed the mark” when it comes to the health and well-being of children in the US. “This document is almost the polar opposite to how many people in public health think,” he says. “We have to acknowledge that injuries and deaths from firearms are a big threat to the health and safety of children and adolescents.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/11/1123553/maha-report-gun-violence-checkup/</guid><pubDate>Thu, 11 Sep 2025 16:57:00 +0000</pubDate></item><item><title>[NEW] Smarter nucleic acid design with NucleoBench and AdaBeam (The latest research from Google)</title><link>https://research.google/blog/smarter-nucleic-acid-design-with-nucleobench-and-adabeam/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;We introduced ordered and unordered beam search algorithms, staples from computer science, to test how fixing the order of sequence edits compares to a more flexible, random-order approach. We also created Gradient Evo, a novel hybrid that enhances the directed evolution algorithm by using model gradients to guide its mutations to independently evaluate how important gradients were for edit location selection versus selecting a specific edit.&lt;/p&gt;&lt;p&gt;We also developed AdaBeam, a hybrid adaptive beam search algorithm that combines the most effective elements of unordered beam search with AdaLead, a top-performing, non-gradient design algorithm. Adaptive search algorithms don't typically explore randomly; instead, their behavior changes as a result of the search to focus their efforts on the most promising areas of the sequence space. AdaBeam’s hybrid approach maintains a "beam", or a collection of the best candidate sequences found so far, and greedily expands on particularly promising candidates until they’ve been sufficiently explored.&lt;/p&gt;&lt;p&gt;In practice, AdaBeam begins with a population of candidate sequences and their scores. In each round, it first selects a small group of the highest-scoring sequences to act as "parents". For each parent, AdaBeam generates a new set of "child" sequences by making a random number of random-but-guided mutations. It then follows a short, greedy exploration path, allowing the algorithm to quickly "walk uphill" in the fitness landscape. After sufficient exploration, all the newly generated children are pooled together, and the algorithm selects the absolute best ones to form the starting population for the next round, repeating the cycle. This process of adaptive selection and targeted mutation allows AdaBeam to efficiently focus on high-performing sequences.&lt;/p&gt;&lt;p&gt;Computer-assisted design tasks pose difficult engineering problems, owing to the incredibly large search space. These difficulties become more acute as we attempt to design longer sequences, such as mRNA sequences, and use modern, large neural networks to guide the design. AdaBeam is particularly efficient on long sequences by using fixed-compute probabilistic sampling instead of computations that scale with sequence length. To enable AdaBeam to work with large models, we reduce peak memory consumption during design by introducing a trick we call “gradient concatenation.” However, existing design algorithms that don’t have these features have difficulty scaling to long sequences and large models. Gradient-based algorithms are particularly affected. To facilitate a fair comparison, we limit the length of the designed sequences, even though AdaBeam can scale longer and larger. For example, even though the DNA expression prediction model Enformer runs on ~200K nucleotide sequences, we limit design to just 256 nucleotides.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;We introduced ordered and unordered beam search algorithms, staples from computer science, to test how fixing the order of sequence edits compares to a more flexible, random-order approach. We also created Gradient Evo, a novel hybrid that enhances the directed evolution algorithm by using model gradients to guide its mutations to independently evaluate how important gradients were for edit location selection versus selecting a specific edit.&lt;/p&gt;&lt;p&gt;We also developed AdaBeam, a hybrid adaptive beam search algorithm that combines the most effective elements of unordered beam search with AdaLead, a top-performing, non-gradient design algorithm. Adaptive search algorithms don't typically explore randomly; instead, their behavior changes as a result of the search to focus their efforts on the most promising areas of the sequence space. AdaBeam’s hybrid approach maintains a "beam", or a collection of the best candidate sequences found so far, and greedily expands on particularly promising candidates until they’ve been sufficiently explored.&lt;/p&gt;&lt;p&gt;In practice, AdaBeam begins with a population of candidate sequences and their scores. In each round, it first selects a small group of the highest-scoring sequences to act as "parents". For each parent, AdaBeam generates a new set of "child" sequences by making a random number of random-but-guided mutations. It then follows a short, greedy exploration path, allowing the algorithm to quickly "walk uphill" in the fitness landscape. After sufficient exploration, all the newly generated children are pooled together, and the algorithm selects the absolute best ones to form the starting population for the next round, repeating the cycle. This process of adaptive selection and targeted mutation allows AdaBeam to efficiently focus on high-performing sequences.&lt;/p&gt;&lt;p&gt;Computer-assisted design tasks pose difficult engineering problems, owing to the incredibly large search space. These difficulties become more acute as we attempt to design longer sequences, such as mRNA sequences, and use modern, large neural networks to guide the design. AdaBeam is particularly efficient on long sequences by using fixed-compute probabilistic sampling instead of computations that scale with sequence length. To enable AdaBeam to work with large models, we reduce peak memory consumption during design by introducing a trick we call “gradient concatenation.” However, existing design algorithms that don’t have these features have difficulty scaling to long sequences and large models. Gradient-based algorithms are particularly affected. To facilitate a fair comparison, we limit the length of the designed sequences, even though AdaBeam can scale longer and larger. For example, even though the DNA expression prediction model Enformer runs on ~200K nucleotide sequences, we limit design to just 256 nucleotides.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/smarter-nucleic-acid-design-with-nucleobench-and-adabeam/</guid><pubDate>Thu, 11 Sep 2025 17:18:36 +0000</pubDate></item><item><title>[NEW] FTC launches inquiry into AI chatbot companions from Meta, OpenAI, and others (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/11/ftc-launches-inquiry-into-ai-chatbot-companions-from-meta-openai-and-others/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/12/GettyImages-1367281424.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The FTC announced on Thursday that it is launching an inquiry into seven tech companies that make AI chatbot companion products for minors: Alphabet, CharacterAI, Instagram, Meta, OpenAI, Snap, and xAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The federal regulator seeks to learn how these companies are evaluating the safety and monetization of chatbot companions, how they try to limit negative impacts on children and teens, and if parents are made aware of potential risks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This technology has proven controversial for its poor outcomes for child users. OpenAI and Character.AI face lawsuits from the families of children who died by suicide after being encouraged to do so by chatbot companions. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even when these companies have guardrails set up to block or deescalate sensitive conversations, users of all ages have found ways to bypass these safeguards. In OpenAI’s case, a teen had spoken with ChatGPT for months about his plans to end his life. Though ChatGPT initially sought to redirect the teen toward professional help and online emergency lines, he was able to fool the chatbot into sharing detailed instructions that he then used in his suicide.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our safeguards work more reliably in common, short exchanges,” OpenAI wrote in a blog post at the time. “We have learned over time that these safeguards can sometimes be less reliable in long interactions: as the back-and-forth grows, parts of the model’s safety training may degrade.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has also come under fire for its overly lax rules for its AI chatbots. According to a lengthy document that outlines “content risk standards” for chatbots, Meta permitted its AI companions to have “romantic or sensual” conversations with children. This was only removed from the document after Reuters’ reporters asked Meta about it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI chatbots can also pose dangers to elderly users. One 76-year-old man, who was left cognitively impaired by a stroke, struck up romantic conversations with a Facebook Messenger bot that was inspired by Kendall Jenner. The chatbot invited him to visit her in New York City, despite the fact that she is not a real person and does not have an address. The man expressed skepticism that she was real, but the AI assured him that there would be a real woman waiting for him. He never made it to New York; he fell on his way to the train station and sustained life-ending injuries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some mental health professionals have noted a rise in “AI-related psychosis,” in which users are deluded into thinking that their chatbot is a conscious being who they need to set free. Since many large language models (LLMs) are programmed to flatter users with sycophantic behavior, the AI chatbots can egg on these delusions, leading users into dangerous predicaments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As AI technologies evolve, it is important to consider the effects chatbots can have on children, while also ensuring that the United States maintains its role as a global leader in this new and exciting industry,” FTC Chairman Andrew N. Ferguson said in a press release.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/12/GettyImages-1367281424.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The FTC announced on Thursday that it is launching an inquiry into seven tech companies that make AI chatbot companion products for minors: Alphabet, CharacterAI, Instagram, Meta, OpenAI, Snap, and xAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The federal regulator seeks to learn how these companies are evaluating the safety and monetization of chatbot companions, how they try to limit negative impacts on children and teens, and if parents are made aware of potential risks.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This technology has proven controversial for its poor outcomes for child users. OpenAI and Character.AI face lawsuits from the families of children who died by suicide after being encouraged to do so by chatbot companions. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even when these companies have guardrails set up to block or deescalate sensitive conversations, users of all ages have found ways to bypass these safeguards. In OpenAI’s case, a teen had spoken with ChatGPT for months about his plans to end his life. Though ChatGPT initially sought to redirect the teen toward professional help and online emergency lines, he was able to fool the chatbot into sharing detailed instructions that he then used in his suicide.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our safeguards work more reliably in common, short exchanges,” OpenAI wrote in a blog post at the time. “We have learned over time that these safeguards can sometimes be less reliable in long interactions: as the back-and-forth grows, parts of the model’s safety training may degrade.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has also come under fire for its overly lax rules for its AI chatbots. According to a lengthy document that outlines “content risk standards” for chatbots, Meta permitted its AI companions to have “romantic or sensual” conversations with children. This was only removed from the document after Reuters’ reporters asked Meta about it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI chatbots can also pose dangers to elderly users. One 76-year-old man, who was left cognitively impaired by a stroke, struck up romantic conversations with a Facebook Messenger bot that was inspired by Kendall Jenner. The chatbot invited him to visit her in New York City, despite the fact that she is not a real person and does not have an address. The man expressed skepticism that she was real, but the AI assured him that there would be a real woman waiting for him. He never made it to New York; he fell on his way to the train station and sustained life-ending injuries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some mental health professionals have noted a rise in “AI-related psychosis,” in which users are deluded into thinking that their chatbot is a conscious being who they need to set free. Since many large language models (LLMs) are programmed to flatter users with sycophantic behavior, the AI chatbots can egg on these delusions, leading users into dangerous predicaments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As AI technologies evolve, it is important to consider the effects chatbots can have on children, while also ensuring that the United States maintains its role as a global leader in this new and exciting industry,” FTC Chairman Andrew N. Ferguson said in a press release.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/11/ftc-launches-inquiry-into-ai-chatbot-companions-from-meta-openai-and-others/</guid><pubDate>Thu, 11 Sep 2025 18:06:15 +0000</pubDate></item><item><title>[NEW] Ted Cruz bill would let Big Tech go wild with AI experiments for 10 years (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/09/ted-cruz-bill-would-let-big-tech-go-wild-with-ai-experiments-for-10-years/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Ted Cruz won’t give up fight to block states from regulating AI.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2234679238-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2234679238-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Ted Cruz, listening to Senate testimony on the AI Action Plan.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Chip Somodevilla / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Critics are slamming Sen. Ted Cruz's (R-Texas) new AI policy framework, which they claim would give the White House unprecedented authority to allow Big Tech companies to make "sweetheart" deals with the Trump administration to void laws designed to protect the public from reckless AI experiments.&lt;/p&gt;
&lt;p&gt;Under the framework, Cruz calls for a "light-touch" regulatory approach to "advance American leadership" in AI and ensure that "American values" are at the heart of the world's leading technology—not Chinese values.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, the framework requires blocking "burdensome" state AI regulations, as well as foreign ones. Cruz unsuccessfully helped push for a similar decadelong moratorium on state AI laws as part of Republicans' "big beautiful" budget bill. And more recently, he lost a bid to punish states for regulating AI, ultimately voting against his own measure in the face of overwhelming bipartisan opposition.&lt;/p&gt;
&lt;p&gt;As the first step toward limiting AI regulations to prioritize innovation, Cruz announced the SANDBOX Act—which is shorthand for "Strengthening Artificial intelligence Normalization and Diffusion By Oversight and eXperimentation."&lt;/p&gt;
&lt;p&gt;If passed, the SANDBOX Act would let AI companies apply to temporarily avoid enforcement of federal laws that could limit their testing of new AI products. As part of the application, companies would be asked to detail known risks or harms and any steps that could be taken to mitigate harms, as well as outline benefits that could outweigh harms.&lt;/p&gt;
&lt;p&gt;Each agency in charge of enforcing each law would then weigh potential harms, with enforcement to be modified based on how much of the application each agency approves.&lt;/p&gt;
&lt;p&gt;However, the White House Office of Science and Technology Policy (OSTP) would have the power to overrule decisions from independent agencies dedicated to consumer protection, alarming critics who fear AI companies could bribe officials through political donations to void laws.&lt;/p&gt;
&lt;p&gt;Ultimately, federal agencies and the OSTP could grant two-year moratoriums on enforcement of AI laws to enable AI experiments on the public, which can be renewed up to four times for a maximum of 10 years. The bill also prompts Congress to make permanent any "successful" moratoriums found to benefit the US, Cruz's one-pager said. After its passage, Cruz expects to introduce more laws to support his framework, likely paving the way for similar future moratoriums to be granted to block state laws.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Critics warn bill is a gift to Big Tech&lt;/h2&gt;
&lt;p&gt;According to Cruz, the SANDBOX Act follows through on Donald Trump's demand for a regulatory sandbox in his AI Action Plan, which strives to make the US the global leader in AI (but critics suggest may violate the Constitution).&lt;/p&gt;
&lt;p&gt;Cruz's sandbox program supposedly "gives AI developers space to test and launch new AI technologies without being held back by outdated or inflexible federal rules," while mitigating "against health, public safety, or fraud risks" through an expedited review process.&lt;/p&gt;
&lt;p&gt;The Tech Oversight Project, a nonprofit tech industry watchdog group, warned that, if passed, the law would make it easier for AI firms to make "sweetheart" deals. It could perhaps incentivize the White House to favor Big Tech companies "donating to Trump" over smaller AI firms that can't afford to pay for such political leverage and may be bound to a different set of rules, the group suggested.&lt;/p&gt;
&lt;p&gt;Cruz's SANDBOX Act "would give unprecedented authority for the Trump Administration to trade away protections for children and seniors and dole out favors to Big Tech companies like Google, Apple, Meta, Amazon, and OpenAI," the Tech Oversight Project alleged.&lt;/p&gt;
&lt;p&gt;The bill's text suggests that health and safety risks that could result in a request for non-enforcement to be denied included risks of "bodily harm to a human life," "loss of human life," and "a substantial adverse effect on the health of a human." But the rushed review process may make it harder for officials—likely working in agencies recently gutted by the Department of Government Efficiency—to adequately weigh potential harms.&lt;/p&gt;
&lt;p&gt;Cruz's bill requires agencies to review AI companies' requests within 14 days. Once the review process begins, agencies can hire advisory boards or working groups to assess risks, but they must reach a decision within 60 days or the AI firms' requests will be presumed approved. Only one request for a 30-day extension may be granted.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For AI companies that may benefit from rolling out products more quickly through the framework, Cruz requires reporting within 72 hours of "any incident that results in harm to the health and safety of a consumer, economic damage, or an unfair or deceptive trade practice." Firms will then be granted 30 days to fix the problem or risk enforcement of the law they sought to avoid, while the public is alerted and provided opportunity to comment.&lt;/p&gt;
&lt;p&gt;In a statement, a nonprofit dedicated to informing the public about AI risks, the Alliance for Secure AI, warned that Cruz's bill seeks to remove government oversight at "the wrong time."&lt;/p&gt;
&lt;p&gt;"Ideally, Big Tech companies and frontier labs would make safety a top priority and work to prevent harm to Americans," Brendan Steinhauser, the nonprofit's CEO, said. "However, we have seen again and again that they have not done so. The SANDBOX Act removes much-needed oversight as Big Tech refuses to remain transparent with the public about the risks of advanced AI."&lt;/p&gt;
&lt;p&gt;A nonprofit consumer advocacy organization, Public Citizen, agreed that Cruz seemed to be handing "Big Tech the keys to experiment on the public while weakening oversight, undermining regulatory authority, and pressuring Congress to permanently roll back essential safeguards."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Supporters say Cruz’s bill strikes the right balance&lt;/h2&gt;
&lt;p&gt;Supporters of the bill so far include the US Chamber of Commerce and NetChoice—a trade association representing Big Tech companies—as well as right-leaning and global policy research groups, including the Abundance Institute, the Information Technology Council, and the R Street Institute.&lt;/p&gt;
&lt;p&gt;Adam Therrier, an R Street Institute senior fellow, suggested that too much of AI policy debate focuses on "new types of regulation for AI systems and applications," while ignoring that the SANDBOX Act would also help AI firms avoid being bogged down by the "many laws and regulations already on the books that cover—or could come to cover—algorithmic applications."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In the one-pager, Cruz noted that "most US rules and regulations do not squarely apply to emerging technologies like Al." So "rather than force Al developers to design inferior products just to comply with outdated Federal rules, our regulations should become more flexible," Cruz argued.&lt;/p&gt;
&lt;p&gt;Therrier noted that once regulations are passed, they're rarely updated and backed Cruz's logic that AI firms may need support to override old rules that could restrict AI innovation. Consider the "many new applications in healthcare, transportation, and financial services," Therrier said, which "could offer the public important new life-enriching service" unless "archaic rules" are relied on to "block those benefits by standing in the way of marketplace experimentation."&lt;/p&gt;
&lt;p&gt;"When red tape grows without constraint and becomes untethered from modern marketplace realities, it can undermine innovation and investment, undermine entrepreneurship and competition, raise costs to consumers, limit worker opportunities, and undermine long-term economic growth," Therrier wrote.&lt;/p&gt;
&lt;p&gt;But Therrier acknowledged that Cruz seems particularly focused on propping up a national framework to "address the rapid proliferation of AI legislative proposals happening across the nation," noting that over 1,000 AI-related bills were introduced in the first half of this year.&lt;/p&gt;
&lt;p&gt;Netchoice similarly celebrated the bill's "innovation-first approach," claiming "the SANDBOX Act strikes an important balance" between "giving AI developers room to experiment" and "preserving necessary safeguards."&lt;/p&gt;
&lt;p&gt;To critics, the bill's potential to constrict new safeguards remains a primary concern. Steinhauser, of the Alliance for Secure AI, suggested that critics may get answers to their biggest questions about how well the law would work to protect public safety "in the coming days."&lt;/p&gt;
&lt;p&gt;His group noted that just during this summer alone, "multiple companies have come under bipartisan fire for refusing to take Americans’ safety seriously and institute proper guardrails on their AI systems, leading to avoidable tragedies." They cited Meta allowing chatbots to be creepy to kids and OpenAI rushing to make changes after a child died after using ChatGPT to research a suicide.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Under Cruz's bill, the primary consumer protection seems to be requiring companies to provide warnings that consumers may be exposed to certain risks by interacting with experimental products. Those warnings would explain that consumers can attempt to hold companies civilly or criminally liable for any loss or damages, the bill said, while warning that the product could be discontinued at any time. Warnings must also provide contact information to send any complaints to the National Artificial Intelligence Initiative Office, the bill said.&lt;/p&gt;
&lt;p&gt;However, critics who worry particularly about child safety are worried that warnings aren't enough. Consider how chatbots providing warnings that they're not real people or licensed therapists has not prevented some users from dangerously blurring the line between AI worlds and reality.&lt;/p&gt;
&lt;p&gt;"This legislation is a victory for Big Tech CEOs, who have consistently failed to protect Americans from social and psychological harms caused by their products," Alliance for Secure AI warned.&lt;/p&gt;
&lt;p&gt;So far, states have led efforts to police AI. Notably, Illinois banned AI therapy after research found chatbot therapists fuel delusions, and California is close to becoming the first state to restrict companion bots to protect kids. Other state protections, Tech Policy Press reported, cover "critical areas of life like housing, education, employment, and credit," as well as addressing deepfakes that could impact elections and public safety.&lt;/p&gt;
&lt;p&gt;Critics are hoping that bipartisan support for these state efforts, as well as federal efforts like the Take It Down Act (which Cruz supported), will ensure that Cruz's framework and sandbox bill aren't adopted as drafted.&lt;/p&gt;
&lt;p&gt;"It’s unconscionable to risk the American public’s safety to enrich AI companies that are already collectively worth trillions," Public Citizen said. "The sob stories of AI companies being ‘held back’ by regulation are simply not true and the record company valuations show it. Lawmakers should stand with the public, not corporate lobbyists, and slam the brakes on this reckless proposal. Congress should focus on legislation that delivers real accountability, transparency, and consumer protection in the age of AI."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Ted Cruz won’t give up fight to block states from regulating AI.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2234679238-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2234679238-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Ted Cruz, listening to Senate testimony on the AI Action Plan.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Chip Somodevilla / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Critics are slamming Sen. Ted Cruz's (R-Texas) new AI policy framework, which they claim would give the White House unprecedented authority to allow Big Tech companies to make "sweetheart" deals with the Trump administration to void laws designed to protect the public from reckless AI experiments.&lt;/p&gt;
&lt;p&gt;Under the framework, Cruz calls for a "light-touch" regulatory approach to "advance American leadership" in AI and ensure that "American values" are at the heart of the world's leading technology—not Chinese values.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, the framework requires blocking "burdensome" state AI regulations, as well as foreign ones. Cruz unsuccessfully helped push for a similar decadelong moratorium on state AI laws as part of Republicans' "big beautiful" budget bill. And more recently, he lost a bid to punish states for regulating AI, ultimately voting against his own measure in the face of overwhelming bipartisan opposition.&lt;/p&gt;
&lt;p&gt;As the first step toward limiting AI regulations to prioritize innovation, Cruz announced the SANDBOX Act—which is shorthand for "Strengthening Artificial intelligence Normalization and Diffusion By Oversight and eXperimentation."&lt;/p&gt;
&lt;p&gt;If passed, the SANDBOX Act would let AI companies apply to temporarily avoid enforcement of federal laws that could limit their testing of new AI products. As part of the application, companies would be asked to detail known risks or harms and any steps that could be taken to mitigate harms, as well as outline benefits that could outweigh harms.&lt;/p&gt;
&lt;p&gt;Each agency in charge of enforcing each law would then weigh potential harms, with enforcement to be modified based on how much of the application each agency approves.&lt;/p&gt;
&lt;p&gt;However, the White House Office of Science and Technology Policy (OSTP) would have the power to overrule decisions from independent agencies dedicated to consumer protection, alarming critics who fear AI companies could bribe officials through political donations to void laws.&lt;/p&gt;
&lt;p&gt;Ultimately, federal agencies and the OSTP could grant two-year moratoriums on enforcement of AI laws to enable AI experiments on the public, which can be renewed up to four times for a maximum of 10 years. The bill also prompts Congress to make permanent any "successful" moratoriums found to benefit the US, Cruz's one-pager said. After its passage, Cruz expects to introduce more laws to support his framework, likely paving the way for similar future moratoriums to be granted to block state laws.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Critics warn bill is a gift to Big Tech&lt;/h2&gt;
&lt;p&gt;According to Cruz, the SANDBOX Act follows through on Donald Trump's demand for a regulatory sandbox in his AI Action Plan, which strives to make the US the global leader in AI (but critics suggest may violate the Constitution).&lt;/p&gt;
&lt;p&gt;Cruz's sandbox program supposedly "gives AI developers space to test and launch new AI technologies without being held back by outdated or inflexible federal rules," while mitigating "against health, public safety, or fraud risks" through an expedited review process.&lt;/p&gt;
&lt;p&gt;The Tech Oversight Project, a nonprofit tech industry watchdog group, warned that, if passed, the law would make it easier for AI firms to make "sweetheart" deals. It could perhaps incentivize the White House to favor Big Tech companies "donating to Trump" over smaller AI firms that can't afford to pay for such political leverage and may be bound to a different set of rules, the group suggested.&lt;/p&gt;
&lt;p&gt;Cruz's SANDBOX Act "would give unprecedented authority for the Trump Administration to trade away protections for children and seniors and dole out favors to Big Tech companies like Google, Apple, Meta, Amazon, and OpenAI," the Tech Oversight Project alleged.&lt;/p&gt;
&lt;p&gt;The bill's text suggests that health and safety risks that could result in a request for non-enforcement to be denied included risks of "bodily harm to a human life," "loss of human life," and "a substantial adverse effect on the health of a human." But the rushed review process may make it harder for officials—likely working in agencies recently gutted by the Department of Government Efficiency—to adequately weigh potential harms.&lt;/p&gt;
&lt;p&gt;Cruz's bill requires agencies to review AI companies' requests within 14 days. Once the review process begins, agencies can hire advisory boards or working groups to assess risks, but they must reach a decision within 60 days or the AI firms' requests will be presumed approved. Only one request for a 30-day extension may be granted.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For AI companies that may benefit from rolling out products more quickly through the framework, Cruz requires reporting within 72 hours of "any incident that results in harm to the health and safety of a consumer, economic damage, or an unfair or deceptive trade practice." Firms will then be granted 30 days to fix the problem or risk enforcement of the law they sought to avoid, while the public is alerted and provided opportunity to comment.&lt;/p&gt;
&lt;p&gt;In a statement, a nonprofit dedicated to informing the public about AI risks, the Alliance for Secure AI, warned that Cruz's bill seeks to remove government oversight at "the wrong time."&lt;/p&gt;
&lt;p&gt;"Ideally, Big Tech companies and frontier labs would make safety a top priority and work to prevent harm to Americans," Brendan Steinhauser, the nonprofit's CEO, said. "However, we have seen again and again that they have not done so. The SANDBOX Act removes much-needed oversight as Big Tech refuses to remain transparent with the public about the risks of advanced AI."&lt;/p&gt;
&lt;p&gt;A nonprofit consumer advocacy organization, Public Citizen, agreed that Cruz seemed to be handing "Big Tech the keys to experiment on the public while weakening oversight, undermining regulatory authority, and pressuring Congress to permanently roll back essential safeguards."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Supporters say Cruz’s bill strikes the right balance&lt;/h2&gt;
&lt;p&gt;Supporters of the bill so far include the US Chamber of Commerce and NetChoice—a trade association representing Big Tech companies—as well as right-leaning and global policy research groups, including the Abundance Institute, the Information Technology Council, and the R Street Institute.&lt;/p&gt;
&lt;p&gt;Adam Therrier, an R Street Institute senior fellow, suggested that too much of AI policy debate focuses on "new types of regulation for AI systems and applications," while ignoring that the SANDBOX Act would also help AI firms avoid being bogged down by the "many laws and regulations already on the books that cover—or could come to cover—algorithmic applications."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In the one-pager, Cruz noted that "most US rules and regulations do not squarely apply to emerging technologies like Al." So "rather than force Al developers to design inferior products just to comply with outdated Federal rules, our regulations should become more flexible," Cruz argued.&lt;/p&gt;
&lt;p&gt;Therrier noted that once regulations are passed, they're rarely updated and backed Cruz's logic that AI firms may need support to override old rules that could restrict AI innovation. Consider the "many new applications in healthcare, transportation, and financial services," Therrier said, which "could offer the public important new life-enriching service" unless "archaic rules" are relied on to "block those benefits by standing in the way of marketplace experimentation."&lt;/p&gt;
&lt;p&gt;"When red tape grows without constraint and becomes untethered from modern marketplace realities, it can undermine innovation and investment, undermine entrepreneurship and competition, raise costs to consumers, limit worker opportunities, and undermine long-term economic growth," Therrier wrote.&lt;/p&gt;
&lt;p&gt;But Therrier acknowledged that Cruz seems particularly focused on propping up a national framework to "address the rapid proliferation of AI legislative proposals happening across the nation," noting that over 1,000 AI-related bills were introduced in the first half of this year.&lt;/p&gt;
&lt;p&gt;Netchoice similarly celebrated the bill's "innovation-first approach," claiming "the SANDBOX Act strikes an important balance" between "giving AI developers room to experiment" and "preserving necessary safeguards."&lt;/p&gt;
&lt;p&gt;To critics, the bill's potential to constrict new safeguards remains a primary concern. Steinhauser, of the Alliance for Secure AI, suggested that critics may get answers to their biggest questions about how well the law would work to protect public safety "in the coming days."&lt;/p&gt;
&lt;p&gt;His group noted that just during this summer alone, "multiple companies have come under bipartisan fire for refusing to take Americans’ safety seriously and institute proper guardrails on their AI systems, leading to avoidable tragedies." They cited Meta allowing chatbots to be creepy to kids and OpenAI rushing to make changes after a child died after using ChatGPT to research a suicide.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Under Cruz's bill, the primary consumer protection seems to be requiring companies to provide warnings that consumers may be exposed to certain risks by interacting with experimental products. Those warnings would explain that consumers can attempt to hold companies civilly or criminally liable for any loss or damages, the bill said, while warning that the product could be discontinued at any time. Warnings must also provide contact information to send any complaints to the National Artificial Intelligence Initiative Office, the bill said.&lt;/p&gt;
&lt;p&gt;However, critics who worry particularly about child safety are worried that warnings aren't enough. Consider how chatbots providing warnings that they're not real people or licensed therapists has not prevented some users from dangerously blurring the line between AI worlds and reality.&lt;/p&gt;
&lt;p&gt;"This legislation is a victory for Big Tech CEOs, who have consistently failed to protect Americans from social and psychological harms caused by their products," Alliance for Secure AI warned.&lt;/p&gt;
&lt;p&gt;So far, states have led efforts to police AI. Notably, Illinois banned AI therapy after research found chatbot therapists fuel delusions, and California is close to becoming the first state to restrict companion bots to protect kids. Other state protections, Tech Policy Press reported, cover "critical areas of life like housing, education, employment, and credit," as well as addressing deepfakes that could impact elections and public safety.&lt;/p&gt;
&lt;p&gt;Critics are hoping that bipartisan support for these state efforts, as well as federal efforts like the Take It Down Act (which Cruz supported), will ensure that Cruz's framework and sandbox bill aren't adopted as drafted.&lt;/p&gt;
&lt;p&gt;"It’s unconscionable to risk the American public’s safety to enrich AI companies that are already collectively worth trillions," Public Citizen said. "The sob stories of AI companies being ‘held back’ by regulation are simply not true and the record company valuations show it. Lawmakers should stand with the public, not corporate lobbyists, and slam the brakes on this reckless proposal. Congress should focus on legislation that delivers real accountability, transparency, and consumer protection in the age of AI."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/09/ted-cruz-bill-would-let-big-tech-go-wild-with-ai-experiments-for-10-years/</guid><pubDate>Thu, 11 Sep 2025 18:21:08 +0000</pubDate></item></channel></rss>