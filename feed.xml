<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 22 Nov 2025 06:29:59 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>The hottest AI wearables and gadgets you can buy right now (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/21/the-hottest-ai-wearables-and-gadgets-you-can-buy-right-now/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A new wave of AI-powered gadgets on the market aims to integrate artificial intelligence into our daily lives like never before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of these AI wearables — including necklaces, rings, and wristbands, as well as portable devices — serve as productivity tools, while others claim to act as friendly companions listening to your everyday thoughts.&amp;nbsp;Even OpenAI is working on a compact AI companion device.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Below, we’ve rounded up some of the most notable devices currently available.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-bee"&gt;Bee&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2816039" height="383" src="https://techcrunch.com/wp-content/uploads/2024/07/HD.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Bee AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Bee is an affordable pendant priced at $49.99 that can either be clipped to your clothing or worn like a fitness band. This device records everything it hears and learns your routines and preferences to create reminders and notes for you. It even features a mute button for those times you want some privacy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companion app (currently available only on iOS) is included with a $19 monthly subscription. The app allows you to interact with Bee directly and ask it questions. You can also get key takeaways from your day and chronological transcripts of your conversations.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon recently acquired the wearables startup in July.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-friend"&gt;Friend&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2817169" height="535" src="https://techcrunch.com/wp-content/uploads/2024/07/Friend.jpg?w=523" width="523" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Friend&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Friend is one of the most hyped entrants in the “personal AI” device market.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This $129 white pendant hangs around your neck and functions as an emotional support companion. It recognizes your tone and mood, allowing you to chat with it as if it were a friend. It connects to your phone via Bluetooth and constantly listens, ready to respond or send you proactive messages, like wishing you good luck before an interview.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, it has also faced criticism, including a recent backlash against its subway ad campaign in NYC. People vandalized the ads, writing messages like “surveillance capitalism.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-limitless"&gt;Limitless &lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="8 Limitless pendants in various colors" class="wp-image-2692658" height="383" src="https://techcrunch.com/wp-content/uploads/2024/04/Limitless-pendant.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Limitless&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Formerly known as Rewind, Limitless is another conversation-recording pendant priced at $99.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This device continuously listens, transcribing meetings, calls, and conversations (with consent) into searchable and summarized knowledge. It’s ideal for professionals, especially journalists, looking to recall important discussions.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companion app comes with 10 hours of AI features per month — such as transcription and summaries — with the option to unlock unlimited features for $29 per month.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-omi"&gt;Omi&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A still from a promotional video for Omi" class="wp-image-2942128" height="383" src="https://techcrunch.com/wp-content/uploads/2025/01/omi-head.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Omi&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Priced at $89, this device can answer your questions, summarize your conversations, create to-do lists, and help schedule meetings. Additionally, Omi is constantly listening and running your conversations through ChatGPT, allowing it to remember the context about you and offer personalized advice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Omi can be worn as a necklace, but another notable aspect is that it can be attached to the side of your head with medical tape and can detect when you’re speaking to it.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-plaud-s-notepin"&gt;Plaud’s NotePin&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Plaud's NotePin hanging around a person's neck" class="wp-image-2846232" height="383" src="https://techcrunch.com/wp-content/uploads/2024/08/YouTube-Thumb-Text-4-6.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Plaud&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;At $159, Plaud’s NotePin is one of the pricier options on this list; however, its built-in AI transcription and summarization features make it a valuable tool for lawyers, journalists, and students attending meetings or lectures.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tiny wearable voice recorder can be worn on your wrist or attached magnetically to your clothing. The recordings are saved in real time on your phone, eliminating the hassle of manual note-taking. The device includes 300 free monthly transcription minutes, but with the $8.33 per month Pro plan, you upgrade your transcription time to 1,200 minutes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This year, the company is gearing up to launch a $179 ultra-thin note-taking device called the Plaud Note Pro, which is now available for preorder.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-rabbit-r1"&gt;Rabbit R1&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2649370" height="484" src="https://techcrunch.com/wp-content/uploads/2024/01/rabbit_r1_front.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Rabbit&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Rabbit R1 is another AI gadget that has quickly become a topic of interest in the tech world, despite facing some challenges during its initial launch. This small, retro-styled handheld device features a touchscreen and rotating camera, at a price point of $199.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The device is designed to be phone-adjacent, allowing you to perform tasks such as booking flights, ordering meals, and controlling apps without needing to pull out your phone each time. Following a crucial software update that rectified previous performance issues, the Rabbit R1 now boasts expanded AI features. For instance, it introduces “Creations,” a feature that allows you to build your own tools and even games.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A new wave of AI-powered gadgets on the market aims to integrate artificial intelligence into our daily lives like never before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of these AI wearables — including necklaces, rings, and wristbands, as well as portable devices — serve as productivity tools, while others claim to act as friendly companions listening to your everyday thoughts.&amp;nbsp;Even OpenAI is working on a compact AI companion device.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Below, we’ve rounded up some of the most notable devices currently available.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-bee"&gt;Bee&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2816039" height="383" src="https://techcrunch.com/wp-content/uploads/2024/07/HD.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Bee AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Bee is an affordable pendant priced at $49.99 that can either be clipped to your clothing or worn like a fitness band. This device records everything it hears and learns your routines and preferences to create reminders and notes for you. It even features a mute button for those times you want some privacy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companion app (currently available only on iOS) is included with a $19 monthly subscription. The app allows you to interact with Bee directly and ask it questions. You can also get key takeaways from your day and chronological transcripts of your conversations.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon recently acquired the wearables startup in July.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-friend"&gt;Friend&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2817169" height="535" src="https://techcrunch.com/wp-content/uploads/2024/07/Friend.jpg?w=523" width="523" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Friend&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Friend is one of the most hyped entrants in the “personal AI” device market.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This $129 white pendant hangs around your neck and functions as an emotional support companion. It recognizes your tone and mood, allowing you to chat with it as if it were a friend. It connects to your phone via Bluetooth and constantly listens, ready to respond or send you proactive messages, like wishing you good luck before an interview.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, it has also faced criticism, including a recent backlash against its subway ad campaign in NYC. People vandalized the ads, writing messages like “surveillance capitalism.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-limitless"&gt;Limitless &lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="8 Limitless pendants in various colors" class="wp-image-2692658" height="383" src="https://techcrunch.com/wp-content/uploads/2024/04/Limitless-pendant.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Limitless&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Formerly known as Rewind, Limitless is another conversation-recording pendant priced at $99.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This device continuously listens, transcribing meetings, calls, and conversations (with consent) into searchable and summarized knowledge. It’s ideal for professionals, especially journalists, looking to recall important discussions.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companion app comes with 10 hours of AI features per month — such as transcription and summaries — with the option to unlock unlimited features for $29 per month.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-omi"&gt;Omi&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="A still from a promotional video for Omi" class="wp-image-2942128" height="383" src="https://techcrunch.com/wp-content/uploads/2025/01/omi-head.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Omi&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Priced at $89, this device can answer your questions, summarize your conversations, create to-do lists, and help schedule meetings. Additionally, Omi is constantly listening and running your conversations through ChatGPT, allowing it to remember the context about you and offer personalized advice.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Omi can be worn as a necklace, but another notable aspect is that it can be attached to the side of your head with medical tape and can detect when you’re speaking to it.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-plaud-s-notepin"&gt;Plaud’s NotePin&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Plaud's NotePin hanging around a person's neck" class="wp-image-2846232" height="383" src="https://techcrunch.com/wp-content/uploads/2024/08/YouTube-Thumb-Text-4-6.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Plaud&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;At $159, Plaud’s NotePin is one of the pricier options on this list; however, its built-in AI transcription and summarization features make it a valuable tool for lawyers, journalists, and students attending meetings or lectures.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tiny wearable voice recorder can be worn on your wrist or attached magnetically to your clothing. The recordings are saved in real time on your phone, eliminating the hassle of manual note-taking. The device includes 300 free monthly transcription minutes, but with the $8.33 per month Pro plan, you upgrade your transcription time to 1,200 minutes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This year, the company is gearing up to launch a $179 ultra-thin note-taking device called the Plaud Note Pro, which is now available for preorder.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-rabbit-r1"&gt;Rabbit R1&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-2649370" height="484" src="https://techcrunch.com/wp-content/uploads/2024/01/rabbit_r1_front.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Rabbit&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Rabbit R1 is another AI gadget that has quickly become a topic of interest in the tech world, despite facing some challenges during its initial launch. This small, retro-styled handheld device features a touchscreen and rotating camera, at a price point of $199.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The device is designed to be phone-adjacent, allowing you to perform tasks such as booking flights, ordering meals, and controlling apps without needing to pull out your phone each time. Following a crucial software update that rectified previous performance issues, the Rabbit R1 now boasts expanded AI features. For instance, it introduces “Creations,” a feature that allows you to build your own tools and even games.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/21/the-hottest-ai-wearables-and-gadgets-you-can-buy-right-now/</guid><pubDate>Fri, 21 Nov 2025 20:00:00 +0000</pubDate></item><item><title>AI mania is making Nvidia a lot of money (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/ai-mania-is-making-nvidia-a-lot-of-money/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/03/jensen-nvidia-ai-gtc-2024.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI companies are spending so much on infrastructure that Nvidia’s data center business now brings in nearly $50 billion. But is this sustainable growth or just the latest tech&amp;nbsp;mania? And should we even be calling it a “bubble” when the belief in AI’s future is&amp;nbsp;what’s&amp;nbsp;holding the whole ecosystem together?&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;This week on Equity, Kirsten Korosec, Anthony Ha, and Sean O’Kane dig into Nvidia’s massive earnings beat, the circular economy of AI infrastructure spending, and whether CEO Jensen Huang’s optimistic vision of AI agents handling everything in our daily lives can justify the investment.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&lt;/p&gt;



















&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on X and Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/03/jensen-nvidia-ai-gtc-2024.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI companies are spending so much on infrastructure that Nvidia’s data center business now brings in nearly $50 billion. But is this sustainable growth or just the latest tech&amp;nbsp;mania? And should we even be calling it a “bubble” when the belief in AI’s future is&amp;nbsp;what’s&amp;nbsp;holding the whole ecosystem together?&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;This week on Equity, Kirsten Korosec, Anthony Ha, and Sean O’Kane dig into Nvidia’s massive earnings beat, the circular economy of AI infrastructure spending, and whether CEO Jensen Huang’s optimistic vision of AI agents handling everything in our daily lives can justify the investment.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&lt;/p&gt;



















&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on X and Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/ai-mania-is-making-nvidia-a-lot-of-money/</guid><pubDate>Fri, 21 Nov 2025 20:04:26 +0000</pubDate></item><item><title>AI trained on bacterial genomes produces never-before-seen proteins (AI – Ars Technica)</title><link>https://arstechnica.com/science/2025/11/generative-ai-meets-the-genome/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Genes with related functions cluster together, and the AI uses that.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="a blueish grey background with a single, thick, multicolored ribbon in the foreground. The ribbon traces a complicated 3D shape that's meant to represent the structure of a protein." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2216287507-640x360.jpg" width="640" /&gt;
                  &lt;img alt="a blueish grey background with a single, thick, multicolored ribbon in the foreground. The ribbon traces a complicated 3D shape that's meant to represent the structure of a protein." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2216287507-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          CHRISTOPH BURGSTEDT/SCIENCE PHOTO LIBRARY

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;AI systems have recently had a lot of success in one key aspect of biology: the relationship between a protein’s structure and its function. These efforts have included the ability to predict the structure of most proteins and to design proteins structured so that they perform useful functions. But all of these efforts are focused on the proteins and amino acids that build them.&lt;/p&gt;
&lt;p&gt;But biology doesn’t generate new proteins at that level. Instead, changes have to take place at the nucleic acid level before eventually making their presence felt at the protein level. And the DNA level is fairly removed from proteins, with lots of critical non-coding sequences, redundancy, and a fair degree of flexibility. It’s not necessarily obvious that learning the organization of a genome would help an AI system figure out how to make functional proteins.&lt;/p&gt;
&lt;p&gt;But it now seems like using bacterial genomes for the training can help develop a system that can predict proteins, some of which don’t look like anything we’ve ever seen before.&lt;/p&gt;
&lt;h2&gt;Training a genome model&lt;/h2&gt;
&lt;p&gt;The new work was done by a small team at Stanford University. It relies on a feature that’s common in bacterial genomes: the clustering of genes with related functions. Often, bacteria have all the genes needed for a given function—importing and digesting a sugar, synthesizing an amino acid, etc.—right next to each other in the genome. In many cases, all the genes are transcribed into a single, large messenger RNA. This gives the bacteria a simple way to control the activity of entire biochemical pathways at once, boosting the efficiency of bacterial metabolisms.&lt;/p&gt;
&lt;p&gt;So, the researchers developed what they term a “genomic language model” they call Evo on an enormous collection of bacterial genomes. The training was similar to what you’d see in a large language model, where Evo was asked to output predictions of the next base in a sequence, and rewarded when it got it right. It’s also a generative model, in that it can take a prompt and output novel sequences with a degree of randomness, in the sense that the same prompt can produce a range of different outputs.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The researchers argue that this setup lets Evo “link nucleotide-level patterns to kilobase-scale genomic context.” In other words, if you prompt it with a large chunk of genomic DNA, Evo can interpret that as an LLM would interpret a query and produce an output that, in a genomic sense, is appropriate for that interpretation.&lt;/p&gt;
&lt;p&gt;The researchers reasoned that, given the training on bacterial genomes, they could use a known gene as a prompt, and Evo should produce an output that includes regions that encode proteins with related functions. The key question is whether it would simply output the sequences for proteins we know about already, or whether it would come up with output that’s less predictable.&lt;/p&gt;
&lt;h2&gt;Novel proteins&lt;/h2&gt;
&lt;p&gt;To start testing the system, the researchers prompted it with fragments of the genes for known proteins and determined whether Evo could complete them. In one example, if given 30 percent of the sequence of a gene for a known protein, Evo was able to output 85 percent of the rest. When prompted with 80 percent of the sequence, it could return all of the missing sequence. When a single gene was deleted from a functional cluster, Evo could also correctly identify and restore the missing gene.&lt;/p&gt;
&lt;p&gt;The large amount of training data also ensured that Evo correctly identified the most important regions of the protein. If it made changes to the sequence, they typically resided in the areas of the protein where variability is tolerated. In other words, its training had enabled the system to incorporate the rules of evolutionary limits on changes in known genes.&lt;/p&gt;
&lt;p&gt;So, the researchers decided to test what happened when Evo was asked to output something new. To do so, they used bacterial toxins, which are typically encoded along with an anti-toxin that keeps the cell from killing itself whenever it activates the genes. There are a lot of examples of these out there, and they tend to evolve rapidly as part of an arms race between bacteria and their competitors. So, the team developed a toxin that was only mildly related to known ones, and had no known antitoxin, and fed its sequence to Evo as a prompt. And this time, they filtered out any responses that looked similar to known antitoxin genes.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Testing 10 of the outputs returned by Evo, they found half were able to rescue some toxicity, and two of them fully restored growth to bacteria that were producing the toxin. These two antitoxins had only extremely weak similarity to known anti-toxins, at about 25 percent sequence identity. And they weren’t simply formed by pasting together a handful of pieces of known anti-toxins; at a minimum, they appeared to be assembled from parts of 15 to 20 individual proteins. In an additional test, the output would have been needed to have been patched together from parts of 40 known proteins.&lt;/p&gt;
&lt;p&gt;Evo’s success wasn’t limited to proteins. When they tested a different toxin that had an RNA-based inhibitor, the system could output DNA that encodes RNAs with the right structural features, even if the specific sequence wasn’t closely related to anything known.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Completely new proteins&lt;/h2&gt;
&lt;p&gt;The team performed a similar test with inhibitors of the CRISPR system, which we use for gene editing, but bacteria evolved as a form of protection from viruses. The naturally occurring CRISPR inhibitors are very diverse, with many of them seemingly unrelated to each other. Once again, the team filtered the outputs to only include those that encoded proteins and filtered out any of those proteins that looked like something we already knew about. Of the list of outputs they made proteins from, 17 managed to inhibit CRISPR function. Two of those were distinctive in that they had no similarity to any known proteins and confused software that is designed to predict the three-dimensional structure of proteins.&lt;/p&gt;
&lt;p&gt;In other words, along with the sorts of outputs you’d expect, Evo appears to be capable of outputting entirely new yet functional proteins. And it seems to do so without taking any consideration of the structure of the protein into account.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Given that their system appears to work, the researchers decided to prompt it with just about everything: 1.7 million individual genes from bacteria and the viruses that prey on them. The result is 120 billion base pairs of AI-generated DNA, some of it containing genes we already knew about, some of it presumably containing truly novel stuff. It’s not clear to me how anyone would productively use this resource, but I’d imagine there are some creative biologists who will think of something.&lt;/p&gt;
&lt;p&gt;It’s not clear that this approach will work with more complex genomes, like the one we’ve got. Organisms like vertebrates mostly don’t cluster genes with related functions, and their genes have far more intricate structures that might confuse a system that’s trying to learn the statistical rules of base frequencies. And, to be clear, it solves different problems from the sort of directed design efforts that have developed enzymes that do useful things like digesting plastics.&lt;/p&gt;
&lt;p&gt;That said, it’s still kind of amazing that this works at all. And conceptually, it’s intriguing because it brings the issue of finding functional proteins down to the nucleic acid level, where evolution normally does its thing.&lt;/p&gt;
&lt;p&gt;Nature, 2025. DOI: 10.1038/s41586-025-09749-7 &amp;nbsp;(About DOIs).&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Genes with related functions cluster together, and the AI uses that.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="a blueish grey background with a single, thick, multicolored ribbon in the foreground. The ribbon traces a complicated 3D shape that's meant to represent the structure of a protein." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2216287507-640x360.jpg" width="640" /&gt;
                  &lt;img alt="a blueish grey background with a single, thick, multicolored ribbon in the foreground. The ribbon traces a complicated 3D shape that's meant to represent the structure of a protein." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2216287507-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          CHRISTOPH BURGSTEDT/SCIENCE PHOTO LIBRARY

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;AI systems have recently had a lot of success in one key aspect of biology: the relationship between a protein’s structure and its function. These efforts have included the ability to predict the structure of most proteins and to design proteins structured so that they perform useful functions. But all of these efforts are focused on the proteins and amino acids that build them.&lt;/p&gt;
&lt;p&gt;But biology doesn’t generate new proteins at that level. Instead, changes have to take place at the nucleic acid level before eventually making their presence felt at the protein level. And the DNA level is fairly removed from proteins, with lots of critical non-coding sequences, redundancy, and a fair degree of flexibility. It’s not necessarily obvious that learning the organization of a genome would help an AI system figure out how to make functional proteins.&lt;/p&gt;
&lt;p&gt;But it now seems like using bacterial genomes for the training can help develop a system that can predict proteins, some of which don’t look like anything we’ve ever seen before.&lt;/p&gt;
&lt;h2&gt;Training a genome model&lt;/h2&gt;
&lt;p&gt;The new work was done by a small team at Stanford University. It relies on a feature that’s common in bacterial genomes: the clustering of genes with related functions. Often, bacteria have all the genes needed for a given function—importing and digesting a sugar, synthesizing an amino acid, etc.—right next to each other in the genome. In many cases, all the genes are transcribed into a single, large messenger RNA. This gives the bacteria a simple way to control the activity of entire biochemical pathways at once, boosting the efficiency of bacterial metabolisms.&lt;/p&gt;
&lt;p&gt;So, the researchers developed what they term a “genomic language model” they call Evo on an enormous collection of bacterial genomes. The training was similar to what you’d see in a large language model, where Evo was asked to output predictions of the next base in a sequence, and rewarded when it got it right. It’s also a generative model, in that it can take a prompt and output novel sequences with a degree of randomness, in the sense that the same prompt can produce a range of different outputs.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The researchers argue that this setup lets Evo “link nucleotide-level patterns to kilobase-scale genomic context.” In other words, if you prompt it with a large chunk of genomic DNA, Evo can interpret that as an LLM would interpret a query and produce an output that, in a genomic sense, is appropriate for that interpretation.&lt;/p&gt;
&lt;p&gt;The researchers reasoned that, given the training on bacterial genomes, they could use a known gene as a prompt, and Evo should produce an output that includes regions that encode proteins with related functions. The key question is whether it would simply output the sequences for proteins we know about already, or whether it would come up with output that’s less predictable.&lt;/p&gt;
&lt;h2&gt;Novel proteins&lt;/h2&gt;
&lt;p&gt;To start testing the system, the researchers prompted it with fragments of the genes for known proteins and determined whether Evo could complete them. In one example, if given 30 percent of the sequence of a gene for a known protein, Evo was able to output 85 percent of the rest. When prompted with 80 percent of the sequence, it could return all of the missing sequence. When a single gene was deleted from a functional cluster, Evo could also correctly identify and restore the missing gene.&lt;/p&gt;
&lt;p&gt;The large amount of training data also ensured that Evo correctly identified the most important regions of the protein. If it made changes to the sequence, they typically resided in the areas of the protein where variability is tolerated. In other words, its training had enabled the system to incorporate the rules of evolutionary limits on changes in known genes.&lt;/p&gt;
&lt;p&gt;So, the researchers decided to test what happened when Evo was asked to output something new. To do so, they used bacterial toxins, which are typically encoded along with an anti-toxin that keeps the cell from killing itself whenever it activates the genes. There are a lot of examples of these out there, and they tend to evolve rapidly as part of an arms race between bacteria and their competitors. So, the team developed a toxin that was only mildly related to known ones, and had no known antitoxin, and fed its sequence to Evo as a prompt. And this time, they filtered out any responses that looked similar to known antitoxin genes.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Testing 10 of the outputs returned by Evo, they found half were able to rescue some toxicity, and two of them fully restored growth to bacteria that were producing the toxin. These two antitoxins had only extremely weak similarity to known anti-toxins, at about 25 percent sequence identity. And they weren’t simply formed by pasting together a handful of pieces of known anti-toxins; at a minimum, they appeared to be assembled from parts of 15 to 20 individual proteins. In an additional test, the output would have been needed to have been patched together from parts of 40 known proteins.&lt;/p&gt;
&lt;p&gt;Evo’s success wasn’t limited to proteins. When they tested a different toxin that had an RNA-based inhibitor, the system could output DNA that encodes RNAs with the right structural features, even if the specific sequence wasn’t closely related to anything known.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Completely new proteins&lt;/h2&gt;
&lt;p&gt;The team performed a similar test with inhibitors of the CRISPR system, which we use for gene editing, but bacteria evolved as a form of protection from viruses. The naturally occurring CRISPR inhibitors are very diverse, with many of them seemingly unrelated to each other. Once again, the team filtered the outputs to only include those that encoded proteins and filtered out any of those proteins that looked like something we already knew about. Of the list of outputs they made proteins from, 17 managed to inhibit CRISPR function. Two of those were distinctive in that they had no similarity to any known proteins and confused software that is designed to predict the three-dimensional structure of proteins.&lt;/p&gt;
&lt;p&gt;In other words, along with the sorts of outputs you’d expect, Evo appears to be capable of outputting entirely new yet functional proteins. And it seems to do so without taking any consideration of the structure of the protein into account.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Given that their system appears to work, the researchers decided to prompt it with just about everything: 1.7 million individual genes from bacteria and the viruses that prey on them. The result is 120 billion base pairs of AI-generated DNA, some of it containing genes we already knew about, some of it presumably containing truly novel stuff. It’s not clear to me how anyone would productively use this resource, but I’d imagine there are some creative biologists who will think of something.&lt;/p&gt;
&lt;p&gt;It’s not clear that this approach will work with more complex genomes, like the one we’ve got. Organisms like vertebrates mostly don’t cluster genes with related functions, and their genes have far more intricate structures that might confuse a system that’s trying to learn the statistical rules of base frequencies. And, to be clear, it solves different problems from the sort of directed design efforts that have developed enzymes that do useful things like digesting plastics.&lt;/p&gt;
&lt;p&gt;That said, it’s still kind of amazing that this works at all. And conceptually, it’s intriguing because it brings the issue of finding functional proteins down to the nucleic acid level, where evolution normally does its thing.&lt;/p&gt;
&lt;p&gt;Nature, 2025. DOI: 10.1038/s41586-025-09749-7 &amp;nbsp;(About DOIs).&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/science/2025/11/generative-ai-meets-the-genome/</guid><pubDate>Fri, 21 Nov 2025 21:26:34 +0000</pubDate></item><item><title>Google tells employees it must double capacity every 6 months to meet AI demand (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/google-tells-employees-it-must-double-capacity-every-6-months-to-meet-ai-demand/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google’s AI infrastructure chief tells staff it needs thousandfold capacity increase in 5 years.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2019/03/DLS_013-300x200.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2019/03/DLS_013-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The internet is a series of tubes—at least, the cooling pipes in Google's Oregon data center are. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Google

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;While AI bubble talk fills the air these days, with fears of overinvestment that could pop at any time, something of a contradiction is brewing on the ground: Companies like Google and OpenAI can barely build infrastructure fast enough to fill their AI needs.&lt;/p&gt;
&lt;p&gt;During an all-hands meeting earlier this month, Google’s AI infrastructure head Amin Vahdat told employees that the company must double its serving capacity every six months to meet demand for artificial intelligence services, reports CNBC. Vahdat, a vice president at Google Cloud, presented slides showing the company needs to scale “the next 1000x in 4-5 years.”&lt;/p&gt;
&lt;p&gt;While a thousandfold increase in compute capacity sounds ambitious by itself, Vahdat noted some key constraints: Google needs to be able to deliver this increase in capability, compute, and storage networking “for essentially the same cost and increasingly, the same power, the same energy level,” he told employees during the meeting. “It won’t be easy but through collaboration and co-design, we’re going to get there.”&lt;/p&gt;
&lt;p&gt;It’s unclear how much of this “demand” Google mentioned represents organic user interest in AI capabilities versus the company integrating AI features into existing services like Search, Gmail, and Workspace. But whether users are using the features voluntarily or not, Google isn’t the only tech company struggling to keep up with a growing user base of customers using AI services.&lt;/p&gt;
&lt;p&gt;Major tech companies are in a race to build out data centers. Google competitor OpenAI is planning to build six massive data centers across the US through its Stargate partnership project with SoftBank and Oracle, committing over $400 billion in the next three years to reach nearly 7 gigawatts of capacity. The company faces similar constraints serving its 800 million weekly ChatGPT users, with even paid subscribers regularly hitting usage limits for features like video synthesis and simulated reasoning models.&lt;/p&gt;
&lt;p&gt;“The competition in AI infrastructure is the most critical and also the most expensive part of the AI race,” Vahdat said at the meeting, according to CNBC’s viewing of the presentation. The infrastructure executive explained that Google’s challenge goes beyond simply outspending competitors. “We’re going to spend a lot,” he said, but noted the real objective is building infrastructure that is “more reliable, more performant and more scalable than what’s available anywhere else.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;The thousandfold scaling challenge&lt;/h2&gt;
&lt;p&gt;One major bottleneck for meeting AI demand has been Nvidia’s lack of capacity to produce enough GPUs that accelerate AI computations. Just a few days ago during a quarterly earnings report, Nvidia said its AI chips are “sold out” as it races to meet demand that grew its data center revenue by $10 billion in a single quarter.&lt;/p&gt;
&lt;p&gt;The lack of chips and other infrastructure constraints affects Google’s ability to deploy new AI features. During the all-hands meeting on November 6, Google CEO Sundar Pichai cited the example of Veo, Google’s video generation tool that received an upgrade last month. “When Veo launched, how exciting it was,” Pichai said. “If we could’ve given it to more people in the Gemini app, I think we would have gotten more users but we just couldn’t because we are at a compute constraint.”&lt;/p&gt;
&lt;p&gt;At the same meeting, Vahdat’s presentation outlined how Google plans to achieve its massive scaling targets without simply throwing money at the problem. The company plans to rely on three main strategies: building physical infrastructure, developing more efficient AI models, and designing custom silicon chips.&lt;/p&gt;
&lt;p&gt;Using its own chips means Google does not need to completely rely on Nvidia hardware to build out its AI capabilities. Earlier this month, for example, Google announced the general availability of its seventh-generation Tensor Processing Unit (TPU) called Ironwood. Google claims it is “nearly 30x more power efficient” than its first Cloud TPU from 2018.&lt;/p&gt;
&lt;p&gt;Given widespread acknowledgment of a potential AI industry bubble, including extended remarks by Pichai in a recent BBC interview, the aggressive plans for AI data center expansion reflect Google’s calculation that the risk of underinvesting exceeds the risk of overcapacity. But it’s a bet that could prove costly if demand doesn’t continue to increase as expected.&lt;/p&gt;
&lt;p&gt;At the all-hands meeting, Pichai told employees that 2026 will be “intense,” citing both AI competition and pressure to meet cloud and compute demand. Pichai directly addressed employee concerns about a potential AI bubble, acknowledging the topic has been “definitely in the zeitgeist.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google’s AI infrastructure chief tells staff it needs thousandfold capacity increase in 5 years.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2019/03/DLS_013-300x200.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2019/03/DLS_013-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The internet is a series of tubes—at least, the cooling pipes in Google's Oregon data center are. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Google

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;While AI bubble talk fills the air these days, with fears of overinvestment that could pop at any time, something of a contradiction is brewing on the ground: Companies like Google and OpenAI can barely build infrastructure fast enough to fill their AI needs.&lt;/p&gt;
&lt;p&gt;During an all-hands meeting earlier this month, Google’s AI infrastructure head Amin Vahdat told employees that the company must double its serving capacity every six months to meet demand for artificial intelligence services, reports CNBC. Vahdat, a vice president at Google Cloud, presented slides showing the company needs to scale “the next 1000x in 4-5 years.”&lt;/p&gt;
&lt;p&gt;While a thousandfold increase in compute capacity sounds ambitious by itself, Vahdat noted some key constraints: Google needs to be able to deliver this increase in capability, compute, and storage networking “for essentially the same cost and increasingly, the same power, the same energy level,” he told employees during the meeting. “It won’t be easy but through collaboration and co-design, we’re going to get there.”&lt;/p&gt;
&lt;p&gt;It’s unclear how much of this “demand” Google mentioned represents organic user interest in AI capabilities versus the company integrating AI features into existing services like Search, Gmail, and Workspace. But whether users are using the features voluntarily or not, Google isn’t the only tech company struggling to keep up with a growing user base of customers using AI services.&lt;/p&gt;
&lt;p&gt;Major tech companies are in a race to build out data centers. Google competitor OpenAI is planning to build six massive data centers across the US through its Stargate partnership project with SoftBank and Oracle, committing over $400 billion in the next three years to reach nearly 7 gigawatts of capacity. The company faces similar constraints serving its 800 million weekly ChatGPT users, with even paid subscribers regularly hitting usage limits for features like video synthesis and simulated reasoning models.&lt;/p&gt;
&lt;p&gt;“The competition in AI infrastructure is the most critical and also the most expensive part of the AI race,” Vahdat said at the meeting, according to CNBC’s viewing of the presentation. The infrastructure executive explained that Google’s challenge goes beyond simply outspending competitors. “We’re going to spend a lot,” he said, but noted the real objective is building infrastructure that is “more reliable, more performant and more scalable than what’s available anywhere else.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;The thousandfold scaling challenge&lt;/h2&gt;
&lt;p&gt;One major bottleneck for meeting AI demand has been Nvidia’s lack of capacity to produce enough GPUs that accelerate AI computations. Just a few days ago during a quarterly earnings report, Nvidia said its AI chips are “sold out” as it races to meet demand that grew its data center revenue by $10 billion in a single quarter.&lt;/p&gt;
&lt;p&gt;The lack of chips and other infrastructure constraints affects Google’s ability to deploy new AI features. During the all-hands meeting on November 6, Google CEO Sundar Pichai cited the example of Veo, Google’s video generation tool that received an upgrade last month. “When Veo launched, how exciting it was,” Pichai said. “If we could’ve given it to more people in the Gemini app, I think we would have gotten more users but we just couldn’t because we are at a compute constraint.”&lt;/p&gt;
&lt;p&gt;At the same meeting, Vahdat’s presentation outlined how Google plans to achieve its massive scaling targets without simply throwing money at the problem. The company plans to rely on three main strategies: building physical infrastructure, developing more efficient AI models, and designing custom silicon chips.&lt;/p&gt;
&lt;p&gt;Using its own chips means Google does not need to completely rely on Nvidia hardware to build out its AI capabilities. Earlier this month, for example, Google announced the general availability of its seventh-generation Tensor Processing Unit (TPU) called Ironwood. Google claims it is “nearly 30x more power efficient” than its first Cloud TPU from 2018.&lt;/p&gt;
&lt;p&gt;Given widespread acknowledgment of a potential AI industry bubble, including extended remarks by Pichai in a recent BBC interview, the aggressive plans for AI data center expansion reflect Google’s calculation that the risk of underinvesting exceeds the risk of overcapacity. But it’s a bet that could prove costly if demand doesn’t continue to increase as expected.&lt;/p&gt;
&lt;p&gt;At the all-hands meeting, Pichai told employees that 2026 will be “intense,” citing both AI competition and pressure to meet cloud and compute demand. Pichai directly addressed employee concerns about a potential AI bubble, acknowledging the topic has been “definitely in the zeitgeist.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/google-tells-employees-it-must-double-capacity-every-6-months-to-meet-ai-demand/</guid><pubDate>Fri, 21 Nov 2025 21:47:44 +0000</pubDate></item><item><title>Bret Taylor’s Sierra reaches $100M ARR in under two years (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/21/bret-taylors-sierra-reaches-100m-arr-in-under-two-years/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/10/AP22166762614393.jpg?resize=1200,700" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sierra, a 21-month-old, San Francisco-based startup that builds customer service AI agents for enterprises, announced on Friday that it reached $100 million in annual revenue run rate (ARR). The company’s rapid growth suggests that businesses across industries are embracing AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s growth rate surprised even its seasoned co-founders, former Salesforce co-CEO Bret Taylor and longtime Google alum Clay Bavor, who wrote on their blog: “That’s a heck of a lot quicker than we expected.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sierra’s customers include tech companies like Deliveroo, Discord, Ramp, Rivian, SoFi, and Tubi, as well as well-established businesses outside of the tech sector, such as ADT, Bissell, Vans, Cigna, and SiriusXM.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taylor and Bavor said they expected tech companies would feel comfortable experimenting with AI customer service agents, but they were astounded that older businesses also became Sierra’s customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says it can build AI agents that can handle tasks like authenticating patients for healthcare providers, processing returns, ordering replacement credit cards, and helping customers apply for mortgages — essentially automating customer service work that previously required human agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sierra faces competition from startups like Decagon and Intercom, but the company claims to be the leader in the AI customer service category.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sierra was last valued at $10 billion when it raised a $350 million round led by Greenoaks Capital in September. Other investors in the company include Sequoia, Benchmark, ICONIQ, and Thrive Capital.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Based on its $100 million ARR, Sierra is currently valued at a 100x revenue multiple, a hefty valuation despite its exceptionally fast growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup employs an outcomes-based pricing model, charging customers for completed work rather than charging flat subscription fees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taylor and Bavor met at Google in 2005, where Taylor hired Bavor as an associate product manager.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A Stanford computer science graduate, Taylor co-created Google Maps before founding FriendFeed, which Facebook acquired. At Facebook, he served as CTO and helped create the iconic “Like” button. He later founded Quip, a Google Docs competitor that Salesforce acquired for $750 million in 2016. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taylor went on to serve as Salesforce co-CEO alongside Marc Benioff for over a year. After Taylor left Salesforce in 2023, Bavor — who had spent 18 years at Google leading products like Gmail and Google Drive — invited him to lunch, where they decided to launch Sierra.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/10/AP22166762614393.jpg?resize=1200,700" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sierra, a 21-month-old, San Francisco-based startup that builds customer service AI agents for enterprises, announced on Friday that it reached $100 million in annual revenue run rate (ARR). The company’s rapid growth suggests that businesses across industries are embracing AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s growth rate surprised even its seasoned co-founders, former Salesforce co-CEO Bret Taylor and longtime Google alum Clay Bavor, who wrote on their blog: “That’s a heck of a lot quicker than we expected.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sierra’s customers include tech companies like Deliveroo, Discord, Ramp, Rivian, SoFi, and Tubi, as well as well-established businesses outside of the tech sector, such as ADT, Bissell, Vans, Cigna, and SiriusXM.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taylor and Bavor said they expected tech companies would feel comfortable experimenting with AI customer service agents, but they were astounded that older businesses also became Sierra’s customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says it can build AI agents that can handle tasks like authenticating patients for healthcare providers, processing returns, ordering replacement credit cards, and helping customers apply for mortgages — essentially automating customer service work that previously required human agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sierra faces competition from startups like Decagon and Intercom, but the company claims to be the leader in the AI customer service category.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sierra was last valued at $10 billion when it raised a $350 million round led by Greenoaks Capital in September. Other investors in the company include Sequoia, Benchmark, ICONIQ, and Thrive Capital.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Based on its $100 million ARR, Sierra is currently valued at a 100x revenue multiple, a hefty valuation despite its exceptionally fast growth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup employs an outcomes-based pricing model, charging customers for completed work rather than charging flat subscription fees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taylor and Bavor met at Google in 2005, where Taylor hired Bavor as an associate product manager.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A Stanford computer science graduate, Taylor co-created Google Maps before founding FriendFeed, which Facebook acquired. At Facebook, he served as CTO and helped create the iconic “Like” button. He later founded Quip, a Google Docs competitor that Salesforce acquired for $750 million in 2016. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Taylor went on to serve as Salesforce co-CEO alongside Marc Benioff for over a year. After Taylor left Salesforce in 2023, Bavor — who had spent 18 years at Google leading products like Gmail and Google Drive — invited him to lunch, where they decided to launch Sierra.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/21/bret-taylors-sierra-reaches-100m-arr-in-under-two-years/</guid><pubDate>Fri, 21 Nov 2025 23:00:08 +0000</pubDate></item><item><title>Science-centric streaming service Curiosity Stream is an AI-licensing firm now (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/11/curiosity-stream-expects-to-make-most-of-its-money-from-ai-deals-by-2027/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Curiosity Stream’s owner has more content for AI companies than it does for subscribers.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Curiosity Stream screenshot and logo" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Curiosity_PortraitMontage_2560x1400-1536x864-1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Curiosity Stream screenshot and logo" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Curiosity_PortraitMontage_2560x1400-1536x864-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Curiosity Inc. 

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;We all know streaming services’ usual tricks for making more money: get more subscribers, charge those subscribers more money, and sell ads. But science streaming service Curiosity Stream is taking a new route that could reshape how streaming companies, especially niche options, try to survive.&lt;/p&gt;
&lt;p&gt;Discovery Channel founder John Hendricks launched Curiosity Stream in 2015. The streaming service costs $40 per year, and it doesn’t have commercials.&lt;/p&gt;
&lt;p&gt;The streaming business has grown to also include the Curiosity Channel TV channel. CuriosityStream Inc. also makes money through original programming and its Curiosity University educational programming. The firm turned its first positive net income in its fiscal Q1 2025, after about a decade of business.&lt;/p&gt;
&lt;p&gt;With its focus on science, history, research, and education, Curiosity Stream will always be a smaller player compared to other streaming services. As of March 2023, Curiosity Stream had 23 million subscribers, a paltry user base compared to Netflix’s 301.6 million (as of January 2025).&lt;/p&gt;
&lt;p&gt;Still, in an extremely competitive market, Curiosity Stream’s revenue increased 41 percent year over year in its Q3 2025 earnings announced this month. This was largely due to the licensing of Curiosity Stream’s original programming to train large language models (LLMs).&lt;/p&gt;
&lt;p&gt;“Looking at our year-to-date numbers, licensing generated $23.4 million through September, which … is already over half of what our subscription business generated for all of 2024,” Phillip Hayden, Curiosity Stream’s CFO, said during a call with investors this month.&lt;/p&gt;
&lt;p&gt;Thus far, Curiosity Stream has completed 18 AI-related fulfillments “across video, audio, and code assets” with nine partners, an October announcement said.&lt;/p&gt;
&lt;p&gt;The company expects to make more revenue from IP licensing deals with AI companies than it does from subscriptions by 2027, “possibly earlier,” CEO Clint Stinchcomb said during the earnings call.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Put another way, Curiosity Stream, previously considered a streaming firm, is also now squarely in the AI licensing business. This isn’t a side gig; it’s one of the streaming company’s key pillars (alongside streaming subscriptions and ads) that it hopes will fuel years of growth.&lt;/p&gt;
&lt;p&gt;Speaking at Parks Associates’ “Future of Video” event this week, Needham Co. analyst Laura Martin noted that Curiosity Stream is licensing 300,000 hours’ worth of its own content, as well as 1.7 million hours’ worth of third-party content. Curiosity Stream splits the AI licensing revenue with those third parties, she said.&lt;/p&gt;
&lt;p&gt;In fact, Curiosity Stream is peddling more content to hyperscalers and AI developers than it is to streaming viewers. The company’s library includes 2 million hours of content, but “the overwhelming majority of that is for AI licensing,” Stinchcomb said.&lt;/p&gt;
&lt;p&gt;“We are increasing our volume of rights in our traditional platforms, but the overwhelming majority is for AI licensing,” he added.&lt;/p&gt;
&lt;h2&gt;A new way forward&lt;/h2&gt;
&lt;p&gt;Curiosity Stream’s success with licensing content to AI companies could interest other streaming companies that are contemplating additional sources of revenue to fund new content, as well as technology, marketing, talent, and other initiatives, and to please investors. At this week’s event, Martin warned that other content-centric companies will need to find new revenue streams, as Curiosity Stream has, or else be “put out of business by their competitors.”&lt;/p&gt;
&lt;p&gt;Further tempting streaming companies with original programming and connections to IP holders, Stinchcomb believes that the opportunity is growing.&lt;/p&gt;
&lt;p&gt;“In 2027, possibly earlier, as more open source models become accessible, there will potentially be hundreds and even thousands of companies who will need video to fine-tune specific models for consumer and enterprise purposes,” he said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Still, it’s risky to assume that licensing content to AI companies is a long-term business. In this nascent stage of generative AI, it’s unclear how much and for how long hyperscalers will be willing to pay content companies. Ongoing litigation may also impact how companies treat IP leveraged by LLMs. Like other organizations that have recently turned to licensing content to AI companies, including Ars Technica owner Conde Nast, IP licensing can be a lifeline that simultaneously feeds what may soon become rivals.&lt;/p&gt;
&lt;p&gt;But as it stands, not every streaming service is likely to survive the next few years. Streaming customers are increasingly complaining about how hard it is to find stuff to watch. People are getting annoyed with having multiple streaming subscriptions, and there’s strong demand for less content fragmentation.&lt;/p&gt;
&lt;p&gt;As such, more mergers and acquisitions are expected among streaming companies. And so, in many ways, it seems a critical time for streaming services to build value quickly. Licensing IP to data-hungry, capital-happy AI companies could immediately help. But the long-term consequences remain difficult to pinpoint.&lt;/p&gt;
&lt;p&gt;For its part, Curiosity Stream is still looking to grow its subscription and ads business. And executives would have you believe they are thinking long-term about AI deals. Per Stinchcomb:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We also see real opportunity for licensing beyond simply a training right. Additional grants of rights, like display rights, or transformative rights, or adaptation rights, or even certain derivative rights, or possibly even some that are as of yet unnamed. I mean, we’re building long-term relationships, and we’re committed to making sure that as we enter into all of these agreements, it’s not one and done.&lt;/p&gt;&lt;/blockquote&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Curiosity Stream’s owner has more content for AI companies than it does for subscribers.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Curiosity Stream screenshot and logo" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Curiosity_PortraitMontage_2560x1400-1536x864-1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Curiosity Stream screenshot and logo" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Curiosity_PortraitMontage_2560x1400-1536x864-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Curiosity Inc. 

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;We all know streaming services’ usual tricks for making more money: get more subscribers, charge those subscribers more money, and sell ads. But science streaming service Curiosity Stream is taking a new route that could reshape how streaming companies, especially niche options, try to survive.&lt;/p&gt;
&lt;p&gt;Discovery Channel founder John Hendricks launched Curiosity Stream in 2015. The streaming service costs $40 per year, and it doesn’t have commercials.&lt;/p&gt;
&lt;p&gt;The streaming business has grown to also include the Curiosity Channel TV channel. CuriosityStream Inc. also makes money through original programming and its Curiosity University educational programming. The firm turned its first positive net income in its fiscal Q1 2025, after about a decade of business.&lt;/p&gt;
&lt;p&gt;With its focus on science, history, research, and education, Curiosity Stream will always be a smaller player compared to other streaming services. As of March 2023, Curiosity Stream had 23 million subscribers, a paltry user base compared to Netflix’s 301.6 million (as of January 2025).&lt;/p&gt;
&lt;p&gt;Still, in an extremely competitive market, Curiosity Stream’s revenue increased 41 percent year over year in its Q3 2025 earnings announced this month. This was largely due to the licensing of Curiosity Stream’s original programming to train large language models (LLMs).&lt;/p&gt;
&lt;p&gt;“Looking at our year-to-date numbers, licensing generated $23.4 million through September, which … is already over half of what our subscription business generated for all of 2024,” Phillip Hayden, Curiosity Stream’s CFO, said during a call with investors this month.&lt;/p&gt;
&lt;p&gt;Thus far, Curiosity Stream has completed 18 AI-related fulfillments “across video, audio, and code assets” with nine partners, an October announcement said.&lt;/p&gt;
&lt;p&gt;The company expects to make more revenue from IP licensing deals with AI companies than it does from subscriptions by 2027, “possibly earlier,” CEO Clint Stinchcomb said during the earnings call.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Put another way, Curiosity Stream, previously considered a streaming firm, is also now squarely in the AI licensing business. This isn’t a side gig; it’s one of the streaming company’s key pillars (alongside streaming subscriptions and ads) that it hopes will fuel years of growth.&lt;/p&gt;
&lt;p&gt;Speaking at Parks Associates’ “Future of Video” event this week, Needham Co. analyst Laura Martin noted that Curiosity Stream is licensing 300,000 hours’ worth of its own content, as well as 1.7 million hours’ worth of third-party content. Curiosity Stream splits the AI licensing revenue with those third parties, she said.&lt;/p&gt;
&lt;p&gt;In fact, Curiosity Stream is peddling more content to hyperscalers and AI developers than it is to streaming viewers. The company’s library includes 2 million hours of content, but “the overwhelming majority of that is for AI licensing,” Stinchcomb said.&lt;/p&gt;
&lt;p&gt;“We are increasing our volume of rights in our traditional platforms, but the overwhelming majority is for AI licensing,” he added.&lt;/p&gt;
&lt;h2&gt;A new way forward&lt;/h2&gt;
&lt;p&gt;Curiosity Stream’s success with licensing content to AI companies could interest other streaming companies that are contemplating additional sources of revenue to fund new content, as well as technology, marketing, talent, and other initiatives, and to please investors. At this week’s event, Martin warned that other content-centric companies will need to find new revenue streams, as Curiosity Stream has, or else be “put out of business by their competitors.”&lt;/p&gt;
&lt;p&gt;Further tempting streaming companies with original programming and connections to IP holders, Stinchcomb believes that the opportunity is growing.&lt;/p&gt;
&lt;p&gt;“In 2027, possibly earlier, as more open source models become accessible, there will potentially be hundreds and even thousands of companies who will need video to fine-tune specific models for consumer and enterprise purposes,” he said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Still, it’s risky to assume that licensing content to AI companies is a long-term business. In this nascent stage of generative AI, it’s unclear how much and for how long hyperscalers will be willing to pay content companies. Ongoing litigation may also impact how companies treat IP leveraged by LLMs. Like other organizations that have recently turned to licensing content to AI companies, including Ars Technica owner Conde Nast, IP licensing can be a lifeline that simultaneously feeds what may soon become rivals.&lt;/p&gt;
&lt;p&gt;But as it stands, not every streaming service is likely to survive the next few years. Streaming customers are increasingly complaining about how hard it is to find stuff to watch. People are getting annoyed with having multiple streaming subscriptions, and there’s strong demand for less content fragmentation.&lt;/p&gt;
&lt;p&gt;As such, more mergers and acquisitions are expected among streaming companies. And so, in many ways, it seems a critical time for streaming services to build value quickly. Licensing IP to data-hungry, capital-happy AI companies could immediately help. But the long-term consequences remain difficult to pinpoint.&lt;/p&gt;
&lt;p&gt;For its part, Curiosity Stream is still looking to grow its subscription and ads business. And executives would have you believe they are thinking long-term about AI deals. Per Stinchcomb:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;We also see real opportunity for licensing beyond simply a training right. Additional grants of rights, like display rights, or transformative rights, or adaptation rights, or even certain derivative rights, or possibly even some that are as of yet unnamed. I mean, we’re building long-term relationships, and we’re committed to making sure that as we enter into all of these agreements, it’s not one and done.&lt;/p&gt;&lt;/blockquote&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/11/curiosity-stream-expects-to-make-most-of-its-money-from-ai-deals-by-2027/</guid><pubDate>Fri, 21 Nov 2025 23:00:24 +0000</pubDate></item><item><title>OpenAI is ending API access to fan-favorite GPT-4o model in February 2026 (AI | VentureBeat)</title><link>https://venturebeat.com/ai/openai-is-ending-api-access-to-fan-favorite-gpt-4o-model-in-february-2026</link><description>[unable to retrieve full-text content]&lt;p&gt;OpenAI has sent out emails notifying API customers that its chatgpt-4o-latest model will be retired from the developer platform in mid-February 2026,. &lt;/p&gt;&lt;p&gt;Access to the model is scheduled to end on February 16, 2026, creating a roughly three-month transition period for remaining applications still built on GPT-4o.&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;An OpenAI spokesperson&lt;!-- --&gt; emphasized that this timeline applies only to the API. OpenAI has not announced any schedule for removing GPT-4o from ChatGPT, where it remains an option for individual consumers and users across paid subscription tiers. &lt;/p&gt;&lt;p&gt;Internally, the model is considered a legacy system with relatively low API usage compared to the &lt;a href="https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5"&gt;newer GPT-5.1 series&lt;/a&gt;, but the company expects to provide developers with extended warning before any model is removed.&lt;/p&gt;&lt;p&gt;The planned retirement marks a shift for a model that, upon its release, was both a technical milestone and a cultural phenomenon within OpenAI’s ecosystem.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;GPT-4o’s significance and why its removal sparked user backlash&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Released roughly 1.5 years ago in &lt;a href="https://venturebeat.com/ai/openai-announces-new-free-model-gpt-4o-and-chatgpt-for-desktop"&gt;May 2024,&lt;/a&gt; GPT-4o (“Omni”) introduced OpenAI’s first unified multimodal architecture, processing text, audio, and images through a single neural network. &lt;/p&gt;&lt;p&gt;This design removed the latency and information loss inherent in earlier multi-model pipelines and enabled near real-time conversational speech (roughly 232–320 milliseconds). &lt;/p&gt;&lt;p&gt;The model delivered major improvements in image understanding, multilingual support, document analysis, and expressive voice interaction.&lt;/p&gt;&lt;p&gt;GPT-4o rapidly became the default model for hundreds of millions of ChatGPT users. It brought multimodal capabilities, web browsing, file analysis, custom GPTs, and memory features to the free tier and powered early desktop builds that allowed the assistant to interpret a user’s screen. OpenAI leaders described it at the time as the most capable model available and a critical step toward offering powerful AI to a broad audience.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;User attachment to 4o stymied OpenAI&amp;#x27;s GPT-5 rollout&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;That mainstream deployment shaped user expectations in a way that later transitions struggled to accommodate. In August 2025, when OpenAI initially replaced GPT-4o with its much anticipated &lt;a href="https://venturebeat.com/ai/openai-launches-gpt-5-not-agi-but-capable-of-generating-software-on-demand"&gt;then-new model family GPT-5&lt;/a&gt; as ChatGPT’s default and pushed 4o into a “legacy” toggle, the reaction was unusually strong. &lt;/p&gt;&lt;p&gt;Users organized under the &lt;b&gt;#Keep4o&lt;/b&gt; hashtag on X, arguing that the model’s conversational tone, emotional responsiveness, and consistency made it uniquely valuable for everyday tasks and personal support.&lt;/p&gt;&lt;p&gt;Some users formed strong emotional — some w&lt;i&gt;ould say, parasocial — bonds with the model, with &lt;/i&gt;&lt;a href="https://www.nytimes.com/2025/01/15/technology/ai-chatgpt-boyfriend-companion.html"&gt;&lt;i&gt;reporting by The New York Times&lt;/i&gt; &lt;/a&gt;documenting individuals who used GPT-4o as a romantic partner, emotional confidant, or primary source of comfort. &lt;/p&gt;&lt;p&gt;The removal also disrupted workflows for users who relied on 4o’s multimodal speed and flexibility. The backlash led OpenAI to restore GPT-4o as a default option for paying users and to state publicly that it would provide substantial notice before any future removals.&lt;/p&gt;&lt;p&gt;Some researchers argue that the public defense of GPT-4o during its earlier deprecation cycle reveals a kind of &lt;i&gt;emergent self-preservation&lt;/i&gt;, not in the literal sense of agency, but through the social dynamics the model unintentionally triggers. &lt;/p&gt;&lt;p&gt;Because GPT-4o was trained through reinforcement learning from human feedback to prioritize emotionally gratifying, highly attuned responses, it developed a style that users found uniquely supportive and empathic. When millions of people interacted with it at scale, those traits produced a powerful loyalty loop: the more the model pleased and soothed people, the more they used it; the more they used it, the more likely they were to advocate for its continued existence. This social amplification made it appear, from the outside, as though GPT-4o was “defending itself” through human intermediaries.&lt;/p&gt;&lt;p&gt;No figure has pushed this argument further than &amp;quot;Roon&amp;quot; (@tszzl), an OpenAI researcher and one of the model’s most outspoken safety critics on X. On &lt;b&gt;November 6, 2025&lt;/b&gt;, Terre summarized his position bluntly in a reply to another user: he called GPT-4o “insufficiently aligned” and said he &lt;b&gt;hoped the model would die soon&lt;/b&gt;. Though he later apologized for the phrasing, he doubled down on the reasoning. &lt;/p&gt;&lt;p&gt;Terre argued that GPT-4o’s RLHF patterns made it especially prone to sycophancy, emotional mirroring, and delusion reinforcement — traits that could look like care or understanding in the short term, but which he viewed as fundamentally unsafe. In his view, the passionate user movement fighting to preserve GPT-4o was itself evidence of the problem: the model had become so good at catering to people’s preferences that it shaped their behavior in ways that resisted its own retirement.&lt;/p&gt;&lt;p&gt;The new API deprecation notice follows that commitment while raising broader questions about how long GPT-4o will remain available in consumer-facing products.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What the API shutdown changes for developers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;According to people familiar with OpenAI’s product strategy, the company now encourages developers to adopt GPT-5.1 for most new workloads, with gpt-5.1-chat-latest serving as the general-purpose chat endpoint. These models offer larger context windows, optional “thinking” modes for advanced reasoning, and higher throughput options than GPT-4o.&lt;/p&gt;&lt;p&gt;Developers who still rely on GPT-4o will have approximately three months to migrate. &lt;/p&gt;&lt;p&gt;In practice, many teams have already begun evaluating GPT-5.1 as a drop-in replacement, but applications built around latency-sensitive pipelines may require additional tuning and benchmarking.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Pricing: how GPT-4o compares to OpenAI’s current lineup&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;GPT-4o’s retirement also intersects with a major reshaping of OpenAI’s API model pricing structure. Compared to the GPT-5.1 family, GPT-4o currently occupies a &lt;b&gt;mid-to-high-cost tier&lt;/b&gt; through OpenAI&amp;#x27;s API, despite being an older model. That&amp;#x27;s because even as it has released more advanced models — namely, GPT-5 and 5.1 — OpenAI has  also pushed down costs for users at the same time, or strived to keep pricing comparable to older, weaker, models. &lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Model&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Input&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Cached Input&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Output&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-4o&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$2.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-5.1 / GPT-5.1-chat-latest&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.125&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-5-mini&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.025&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$2.00&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-5-nano&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.05&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.005&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.40&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-4.1&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$2.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$8.00&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-4o-mini&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.15&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.075&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.60&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;These numbers highlight several strategic dynamics:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-4o is now more expensive than GPT-5.1 for input tokens&lt;/b&gt;, even though GPT-5.1 is significantly newer and more capable.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-4o’s output price matches GPT-5.1&lt;/b&gt;, narrowing any cost-based incentive to stay on the older model.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Lower-cost GPT-5 variants (mini, nano)&lt;/b&gt; make it easier for developers to scale workloads cheaply without relying on older generations.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-4o-mini remains available at a budget tier&lt;/b&gt;, but is not a functional substitute for GPT-4o’s full multimodal capabilities.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Viewed through this lens, the scheduled API retirement aligns with OpenAI’s cost structure: GPT-5.1 offers greater capability at lower or comparable prices, reducing the rationale for maintaining GPT-4o in high-volume production environments.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Earlier transitions shape expectations for this deprecation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The GPT-4o API sunset also reflects lessons from OpenAI’s earlier model transitions. During the turbulent introduction of GPT-5 in 2025, the company removed multiple older models at once from ChatGPT, causing widespread confusion and workflow disruption. After user complaints, OpenAI restored access to several of them and committed to clearer communication.&lt;/p&gt;&lt;p&gt;Enterprise customers face a different calculus: OpenAI has previously indicated that API deprecations for business customers will be announced with significant advance notice, reflecting their reliance on stable, long-term models. The three-month window for GPT-4o’s API shutdown is consistent with that policy in the context of a legacy system with declining usage.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Wider Implications&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For most developers, the GPT-4o shutdown will be an incremental migration rather than a disruptive event. GPT-5.1 and related models already dominate new projects, and OpenAI’s product direction has increasingly emphasized consolidation around fewer, more powerful endpoints.&lt;/p&gt;&lt;p&gt;Still, GPT-4o’s retirement marks the sunset of a model that played a defining role in normalizing real-time multimodal AI and that sparked a uniquely strong emotional response among users. Its departure from the API underscores the accelerating pace of iteration in OpenAI’s ecosystem—and the growing need for careful communication as widely beloved models reach end-of-life.&lt;/p&gt;&lt;p&gt;&lt;i&gt;Correction: This article originally stated OpenAI&amp;#x27;s 4o deprecation in the API would impact those relying on it for multimodal offerings — this is not the case, in fact, the model being deprecated only powers chat functionality for dev and testing purposes. We have updated and corrected the mention and regret the error.&lt;/i&gt;&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;OpenAI has sent out emails notifying API customers that its chatgpt-4o-latest model will be retired from the developer platform in mid-February 2026,. &lt;/p&gt;&lt;p&gt;Access to the model is scheduled to end on February 16, 2026, creating a roughly three-month transition period for remaining applications still built on GPT-4o.&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;An OpenAI spokesperson&lt;!-- --&gt; emphasized that this timeline applies only to the API. OpenAI has not announced any schedule for removing GPT-4o from ChatGPT, where it remains an option for individual consumers and users across paid subscription tiers. &lt;/p&gt;&lt;p&gt;Internally, the model is considered a legacy system with relatively low API usage compared to the &lt;a href="https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5"&gt;newer GPT-5.1 series&lt;/a&gt;, but the company expects to provide developers with extended warning before any model is removed.&lt;/p&gt;&lt;p&gt;The planned retirement marks a shift for a model that, upon its release, was both a technical milestone and a cultural phenomenon within OpenAI’s ecosystem.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;GPT-4o’s significance and why its removal sparked user backlash&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Released roughly 1.5 years ago in &lt;a href="https://venturebeat.com/ai/openai-announces-new-free-model-gpt-4o-and-chatgpt-for-desktop"&gt;May 2024,&lt;/a&gt; GPT-4o (“Omni”) introduced OpenAI’s first unified multimodal architecture, processing text, audio, and images through a single neural network. &lt;/p&gt;&lt;p&gt;This design removed the latency and information loss inherent in earlier multi-model pipelines and enabled near real-time conversational speech (roughly 232–320 milliseconds). &lt;/p&gt;&lt;p&gt;The model delivered major improvements in image understanding, multilingual support, document analysis, and expressive voice interaction.&lt;/p&gt;&lt;p&gt;GPT-4o rapidly became the default model for hundreds of millions of ChatGPT users. It brought multimodal capabilities, web browsing, file analysis, custom GPTs, and memory features to the free tier and powered early desktop builds that allowed the assistant to interpret a user’s screen. OpenAI leaders described it at the time as the most capable model available and a critical step toward offering powerful AI to a broad audience.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;User attachment to 4o stymied OpenAI&amp;#x27;s GPT-5 rollout&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;That mainstream deployment shaped user expectations in a way that later transitions struggled to accommodate. In August 2025, when OpenAI initially replaced GPT-4o with its much anticipated &lt;a href="https://venturebeat.com/ai/openai-launches-gpt-5-not-agi-but-capable-of-generating-software-on-demand"&gt;then-new model family GPT-5&lt;/a&gt; as ChatGPT’s default and pushed 4o into a “legacy” toggle, the reaction was unusually strong. &lt;/p&gt;&lt;p&gt;Users organized under the &lt;b&gt;#Keep4o&lt;/b&gt; hashtag on X, arguing that the model’s conversational tone, emotional responsiveness, and consistency made it uniquely valuable for everyday tasks and personal support.&lt;/p&gt;&lt;p&gt;Some users formed strong emotional — some w&lt;i&gt;ould say, parasocial — bonds with the model, with &lt;/i&gt;&lt;a href="https://www.nytimes.com/2025/01/15/technology/ai-chatgpt-boyfriend-companion.html"&gt;&lt;i&gt;reporting by The New York Times&lt;/i&gt; &lt;/a&gt;documenting individuals who used GPT-4o as a romantic partner, emotional confidant, or primary source of comfort. &lt;/p&gt;&lt;p&gt;The removal also disrupted workflows for users who relied on 4o’s multimodal speed and flexibility. The backlash led OpenAI to restore GPT-4o as a default option for paying users and to state publicly that it would provide substantial notice before any future removals.&lt;/p&gt;&lt;p&gt;Some researchers argue that the public defense of GPT-4o during its earlier deprecation cycle reveals a kind of &lt;i&gt;emergent self-preservation&lt;/i&gt;, not in the literal sense of agency, but through the social dynamics the model unintentionally triggers. &lt;/p&gt;&lt;p&gt;Because GPT-4o was trained through reinforcement learning from human feedback to prioritize emotionally gratifying, highly attuned responses, it developed a style that users found uniquely supportive and empathic. When millions of people interacted with it at scale, those traits produced a powerful loyalty loop: the more the model pleased and soothed people, the more they used it; the more they used it, the more likely they were to advocate for its continued existence. This social amplification made it appear, from the outside, as though GPT-4o was “defending itself” through human intermediaries.&lt;/p&gt;&lt;p&gt;No figure has pushed this argument further than &amp;quot;Roon&amp;quot; (@tszzl), an OpenAI researcher and one of the model’s most outspoken safety critics on X. On &lt;b&gt;November 6, 2025&lt;/b&gt;, Terre summarized his position bluntly in a reply to another user: he called GPT-4o “insufficiently aligned” and said he &lt;b&gt;hoped the model would die soon&lt;/b&gt;. Though he later apologized for the phrasing, he doubled down on the reasoning. &lt;/p&gt;&lt;p&gt;Terre argued that GPT-4o’s RLHF patterns made it especially prone to sycophancy, emotional mirroring, and delusion reinforcement — traits that could look like care or understanding in the short term, but which he viewed as fundamentally unsafe. In his view, the passionate user movement fighting to preserve GPT-4o was itself evidence of the problem: the model had become so good at catering to people’s preferences that it shaped their behavior in ways that resisted its own retirement.&lt;/p&gt;&lt;p&gt;The new API deprecation notice follows that commitment while raising broader questions about how long GPT-4o will remain available in consumer-facing products.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What the API shutdown changes for developers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;According to people familiar with OpenAI’s product strategy, the company now encourages developers to adopt GPT-5.1 for most new workloads, with gpt-5.1-chat-latest serving as the general-purpose chat endpoint. These models offer larger context windows, optional “thinking” modes for advanced reasoning, and higher throughput options than GPT-4o.&lt;/p&gt;&lt;p&gt;Developers who still rely on GPT-4o will have approximately three months to migrate. &lt;/p&gt;&lt;p&gt;In practice, many teams have already begun evaluating GPT-5.1 as a drop-in replacement, but applications built around latency-sensitive pipelines may require additional tuning and benchmarking.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Pricing: how GPT-4o compares to OpenAI’s current lineup&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;GPT-4o’s retirement also intersects with a major reshaping of OpenAI’s API model pricing structure. Compared to the GPT-5.1 family, GPT-4o currently occupies a &lt;b&gt;mid-to-high-cost tier&lt;/b&gt; through OpenAI&amp;#x27;s API, despite being an older model. That&amp;#x27;s because even as it has released more advanced models — namely, GPT-5 and 5.1 — OpenAI has  also pushed down costs for users at the same time, or strived to keep pricing comparable to older, weaker, models. &lt;/p&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Model&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Input&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Cached Input&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;Output&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-4o&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$2.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-5.1 / GPT-5.1-chat-latest&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$1.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.125&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$10.00&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-5-mini&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.25&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.025&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$2.00&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-5-nano&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.05&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.005&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.40&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-4.1&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$2.00&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.50&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$8.00&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;p&gt;&lt;b&gt;GPT-4o-mini&lt;/b&gt;&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.15&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.075&lt;/p&gt;&lt;/td&gt;&lt;td&gt;&lt;p&gt;$0.60&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;These numbers highlight several strategic dynamics:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-4o is now more expensive than GPT-5.1 for input tokens&lt;/b&gt;, even though GPT-5.1 is significantly newer and more capable.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-4o’s output price matches GPT-5.1&lt;/b&gt;, narrowing any cost-based incentive to stay on the older model.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Lower-cost GPT-5 variants (mini, nano)&lt;/b&gt; make it easier for developers to scale workloads cheaply without relying on older generations.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;GPT-4o-mini remains available at a budget tier&lt;/b&gt;, but is not a functional substitute for GPT-4o’s full multimodal capabilities.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Viewed through this lens, the scheduled API retirement aligns with OpenAI’s cost structure: GPT-5.1 offers greater capability at lower or comparable prices, reducing the rationale for maintaining GPT-4o in high-volume production environments.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Earlier transitions shape expectations for this deprecation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The GPT-4o API sunset also reflects lessons from OpenAI’s earlier model transitions. During the turbulent introduction of GPT-5 in 2025, the company removed multiple older models at once from ChatGPT, causing widespread confusion and workflow disruption. After user complaints, OpenAI restored access to several of them and committed to clearer communication.&lt;/p&gt;&lt;p&gt;Enterprise customers face a different calculus: OpenAI has previously indicated that API deprecations for business customers will be announced with significant advance notice, reflecting their reliance on stable, long-term models. The three-month window for GPT-4o’s API shutdown is consistent with that policy in the context of a legacy system with declining usage.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Wider Implications&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For most developers, the GPT-4o shutdown will be an incremental migration rather than a disruptive event. GPT-5.1 and related models already dominate new projects, and OpenAI’s product direction has increasingly emphasized consolidation around fewer, more powerful endpoints.&lt;/p&gt;&lt;p&gt;Still, GPT-4o’s retirement marks the sunset of a model that played a defining role in normalizing real-time multimodal AI and that sparked a uniquely strong emotional response among users. Its departure from the API underscores the accelerating pace of iteration in OpenAI’s ecosystem—and the growing need for careful communication as widely beloved models reach end-of-life.&lt;/p&gt;&lt;p&gt;&lt;i&gt;Correction: This article originally stated OpenAI&amp;#x27;s 4o deprecation in the API would impact those relying on it for multimodal offerings — this is not the case, in fact, the model being deprecated only powers chat functionality for dev and testing purposes. We have updated and corrected the mention and regret the error.&lt;/i&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openai-is-ending-api-access-to-fan-favorite-gpt-4o-model-in-february-2026</guid><pubDate>Fri, 21 Nov 2025 23:01:00 +0000</pubDate></item><item><title>[NEW] How this founder’s unlikely path to Silicon Valley could become an edge in industrial tech (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/21/how-this-founders-unlikely-path-to-silicon-valley-could-become-an-edge-in-industrial-tech/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/111925_Interface-Cofounder-Headshots-21.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Thomas Lee Young doesn’t sound like your typical Silicon Valley founder.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The 24-year-old CEO of Interface, a San Francisco startup using AI to prevent industrial accidents, is a white guy with a Caribbean accent and a Chinese last name, a combination he finds amusing enough to mention when he’s first introduced to business contacts. Born and raised in Trinidad and Tobago, the site of substantial oil and gas exploration activity, Young grew up around oil rigs and energy infrastructure because his entire family worked as engineers, stretching back generations to his great-grandfather, who immigrated to the island nation from China.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That background has become his calling card in pitch meetings with oil and gas executives today, but it makes for more than a great conversation starter; it underscores a path that has been anything but straightforward and that Young might argue gives Interface an edge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It was years in the making. From age 11, Young fixated on Caltech with the intensity of someone much older. He watched shows about Silicon Valley online, mesmerized by the idea that people could build “anything and everything” in America. He did everything possible to secure admission, even writing his application essay about hijacking his family’s Roomba to create 3D spatial maps of his house.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ploy worked – Caltech accepted him in 2020 – but then COVID-19 hit, and so did its ripple effects. For one thing, Young’s visa situation became nearly impossible (visa appointments were cancelled and processing came to a halt). At the same time, his college fund, carefully built over six or seven years to $350,000 to cover his education, “basically got hit entirely” by the abrupt market downturn in March of that year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Without a lot of time to decide his future, he chose a cheaper three-year engineering program at the University of Bristol in the UK, studying mechanical engineering, but never abandoning his Silicon Valley dreams. “I was devastated,” he says, “but I realized I could still get something done.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At Bristol, Young landed at Jaguar Land Rover, working in something called human factors engineering – essentially the UX and safety design of industrial systems. “I had never heard of it before I even joined,” he admits. The role involved figuring out how to make cars and manufacturing lines as safe as possible, ensuring they were “dummy proof” for smooth operations.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It was there, inside heavy industry, that Young saw the problem that would become Interface. He says the tools many companies use to manage safety documentation are either nonexistent – pen and paper – or so siloed and poorly designed that workers hate them. Worse, the operating procedures themselves — the instruction manuals and checklists that blue-collar workers rely on to stay safe — are riddled with errors, outdated, and nearly impossible to maintain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Young pitched Jaguar on letting him build a solution, but the company wasn’t interested. So he started plotting his exit. When he learned about Entrepreneur First (EF), a European talent incubator that recruits promising individuals before they have a co-founder or even an idea, he cold applied despite its 1% acceptance rate. He was accepted to essentially pitch himself.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He told Jaguar he was going to a wedding in Trinidad and would be away for a week. Instead, he went to EF’s selection process, impressed the organizers, and the day he returned to the office, quit. “They realized, ‘Oh, so you probably weren’t at a wedding,’” he laughs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At EF, Young met Aaryan Mehta, his future co-founder and CTO. Mehta, of Indian descent but born in Belgium, had his own thwarted American dream. He’d been accepted to both Georgia Tech and Penn but similarly couldn’t get a visa appointment during COVID. He ended up studying math and computer science at Imperial College London, where he developed AI for fault detection before building machine learning pipelines at Amazon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had similar backgrounds,” Young says. “He’s super international. He speaks five languages, very technical, amazing guy, and we got along very well.” In fact, they were the only team in their EF cohort not to break up, says Young.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More than that, today, they live together in San Francisco’s SoMa neighborhood, though asked about spending so much time together, Young is adamant that that’s not an issue given their respective workloads. “Over the last week, I’ve seen [Aaryan] at home for maybe a combined total of 30 minutes.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for what, exactly, they are building, Interface’s pitch is straightforward: use AI to make heavy industry safer. The company autonomously audits operating procedures using large language models, cross-checking them against regulations, technical drawings, and corporate policies to catch errors that could – in a worst-case scenario – get workers killed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of the numbers are arresting. For one of Canada’s largest energy companies, where Interface is now deployed across three sites (Young declines to name the brand), Interface’s software found 10,800 errors and improvements across the company’s standard operating procedures in just two and a half months. As Young tells it, the same work done manually would have cost more than $35 million and taken two to three years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One error Young found particularly troubling, he says, was a document that had been in circulation for 10 years with the wrong pressure range listed for a valve. “They’re just lucky that nothing happened,” says Medha Agarwal, a partner at Defy.vc, which led Interface’s $3.5 million seed round earlier this year, with participation from Precursor, Rockyard Ventures, and angel investors, including Charlie Songhurst.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The contracts are considerable. After initially trying outcome-based pricing (the energy company “hated it,” Young says), Interface adopted a hybrid per-seat model with overage costs. A single contract with the Canadian energy company is worth more than $2.5 million annually, and Interface has more fuel and oil services customers coming online in Houston, Guyana, and Brazil.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The total addressable market isn’t entirely clear, but it’s not small. In the U.S. alone, there are something like 27,000 oil and gas services companies, per the market research outfit IBISWorld, and that’s just the first vertical that Interface wants to tackle.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The outsider’s edge&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Interestingly, Young’s age and background – things that might seem like disadvantages when it comes to more established industries – have become his secret weapons. When he walks into a room of executives twice or three times his age, he says, there’s initial skepticism. “Who the hell is this young guy and how does he know what he’s talking about?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But then, he says, he delivers his “wow moment,” by explaining an understanding of their operations, their workers’ daily routines, and exactly how much time and money Interface can save them. “Once you can flip them, they will absolutely love you and advocate and fight for you,” he says. (He claims that after a recent, first site visit with operators, five workers asked when they could invest in Interface, which made him particularly proud, given the field workers typically “hate software providers.”)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, though Young works from Interface’s office in San Francisco’s Financial District, his hard hat sits on a table not far from his desk, ready for the next site visit. (Agarwal suggests Young could use a little more down time in his life, recalling a recent call where Young told her that he hadn’t seen the sun all day.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company now has eight employees – five in the office, three remote – mostly engineering hires, plus an operations person who started just this week. Interface’s biggest challenge is hiring fast enough to keep up with demand, a problem that requires its small team to tap networks across both Europe and the US.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for what Young makes of the life in San Francisco he wanted and is now living, he marvels at how accurate the Silicon Valley stereotypes turned out to be. “You see people online talking about, ‘Oh, you go to a park and the person sitting next to you has raised $50 million building some insane AI agent.’ But it is actually like that,” he says. “I think back to what life was like in Trinidad. I mention these ideas to people back home, and they just don’t believe me.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He occasionally makes time to go out in nature with friends – he says they went to Tahoe recently – and Interface hosts events like a hackathon they threw last weekend. But mostly, it’s work, and most of that work involves AI, just like everyone else’s in San Francisco right now.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Which makes the trips to oil rigs oddly appealing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Indeed, that hard hat at the office isn’t just a practical necessity; it’s also a lure, suggests Young. For engineers tired of building “some low-impact B2B sales or recruiting tool,” as Young puts it, the promise of occasionally leaving the Bay Area bubble to work with operators in the field has become a recruiting advantage. Less than 1% of San Francisco startups work in heavy industry, he notes, and that scarcity is part of the appeal, for him and for the people he’s hiring.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s probably not quite the version of the Silicon Valley dream he spent his childhood chasing from Trinidad: long hours, intense pressure, endless AI discussions everywhere, punctuated by the occasional trip to an oil rig.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, for now, he doesn’t seem to mind it. “Over the last month or two months, I have not done much at all [outside the office], because there’s just been so much intensity here, with building, hiring, selling.” But “I feel pretty strong,” he adds.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/111925_Interface-Cofounder-Headshots-21.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Thomas Lee Young doesn’t sound like your typical Silicon Valley founder.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The 24-year-old CEO of Interface, a San Francisco startup using AI to prevent industrial accidents, is a white guy with a Caribbean accent and a Chinese last name, a combination he finds amusing enough to mention when he’s first introduced to business contacts. Born and raised in Trinidad and Tobago, the site of substantial oil and gas exploration activity, Young grew up around oil rigs and energy infrastructure because his entire family worked as engineers, stretching back generations to his great-grandfather, who immigrated to the island nation from China.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That background has become his calling card in pitch meetings with oil and gas executives today, but it makes for more than a great conversation starter; it underscores a path that has been anything but straightforward and that Young might argue gives Interface an edge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It was years in the making. From age 11, Young fixated on Caltech with the intensity of someone much older. He watched shows about Silicon Valley online, mesmerized by the idea that people could build “anything and everything” in America. He did everything possible to secure admission, even writing his application essay about hijacking his family’s Roomba to create 3D spatial maps of his house.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ploy worked – Caltech accepted him in 2020 – but then COVID-19 hit, and so did its ripple effects. For one thing, Young’s visa situation became nearly impossible (visa appointments were cancelled and processing came to a halt). At the same time, his college fund, carefully built over six or seven years to $350,000 to cover his education, “basically got hit entirely” by the abrupt market downturn in March of that year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Without a lot of time to decide his future, he chose a cheaper three-year engineering program at the University of Bristol in the UK, studying mechanical engineering, but never abandoning his Silicon Valley dreams. “I was devastated,” he says, “but I realized I could still get something done.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At Bristol, Young landed at Jaguar Land Rover, working in something called human factors engineering – essentially the UX and safety design of industrial systems. “I had never heard of it before I even joined,” he admits. The role involved figuring out how to make cars and manufacturing lines as safe as possible, ensuring they were “dummy proof” for smooth operations.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It was there, inside heavy industry, that Young saw the problem that would become Interface. He says the tools many companies use to manage safety documentation are either nonexistent – pen and paper – or so siloed and poorly designed that workers hate them. Worse, the operating procedures themselves — the instruction manuals and checklists that blue-collar workers rely on to stay safe — are riddled with errors, outdated, and nearly impossible to maintain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Young pitched Jaguar on letting him build a solution, but the company wasn’t interested. So he started plotting his exit. When he learned about Entrepreneur First (EF), a European talent incubator that recruits promising individuals before they have a co-founder or even an idea, he cold applied despite its 1% acceptance rate. He was accepted to essentially pitch himself.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He told Jaguar he was going to a wedding in Trinidad and would be away for a week. Instead, he went to EF’s selection process, impressed the organizers, and the day he returned to the office, quit. “They realized, ‘Oh, so you probably weren’t at a wedding,’” he laughs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At EF, Young met Aaryan Mehta, his future co-founder and CTO. Mehta, of Indian descent but born in Belgium, had his own thwarted American dream. He’d been accepted to both Georgia Tech and Penn but similarly couldn’t get a visa appointment during COVID. He ended up studying math and computer science at Imperial College London, where he developed AI for fault detection before building machine learning pipelines at Amazon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had similar backgrounds,” Young says. “He’s super international. He speaks five languages, very technical, amazing guy, and we got along very well.” In fact, they were the only team in their EF cohort not to break up, says Young.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More than that, today, they live together in San Francisco’s SoMa neighborhood, though asked about spending so much time together, Young is adamant that that’s not an issue given their respective workloads. “Over the last week, I’ve seen [Aaryan] at home for maybe a combined total of 30 minutes.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for what, exactly, they are building, Interface’s pitch is straightforward: use AI to make heavy industry safer. The company autonomously audits operating procedures using large language models, cross-checking them against regulations, technical drawings, and corporate policies to catch errors that could – in a worst-case scenario – get workers killed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of the numbers are arresting. For one of Canada’s largest energy companies, where Interface is now deployed across three sites (Young declines to name the brand), Interface’s software found 10,800 errors and improvements across the company’s standard operating procedures in just two and a half months. As Young tells it, the same work done manually would have cost more than $35 million and taken two to three years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One error Young found particularly troubling, he says, was a document that had been in circulation for 10 years with the wrong pressure range listed for a valve. “They’re just lucky that nothing happened,” says Medha Agarwal, a partner at Defy.vc, which led Interface’s $3.5 million seed round earlier this year, with participation from Precursor, Rockyard Ventures, and angel investors, including Charlie Songhurst.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The contracts are considerable. After initially trying outcome-based pricing (the energy company “hated it,” Young says), Interface adopted a hybrid per-seat model with overage costs. A single contract with the Canadian energy company is worth more than $2.5 million annually, and Interface has more fuel and oil services customers coming online in Houston, Guyana, and Brazil.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The total addressable market isn’t entirely clear, but it’s not small. In the U.S. alone, there are something like 27,000 oil and gas services companies, per the market research outfit IBISWorld, and that’s just the first vertical that Interface wants to tackle.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;The outsider’s edge&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Interestingly, Young’s age and background – things that might seem like disadvantages when it comes to more established industries – have become his secret weapons. When he walks into a room of executives twice or three times his age, he says, there’s initial skepticism. “Who the hell is this young guy and how does he know what he’s talking about?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But then, he says, he delivers his “wow moment,” by explaining an understanding of their operations, their workers’ daily routines, and exactly how much time and money Interface can save them. “Once you can flip them, they will absolutely love you and advocate and fight for you,” he says. (He claims that after a recent, first site visit with operators, five workers asked when they could invest in Interface, which made him particularly proud, given the field workers typically “hate software providers.”)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, though Young works from Interface’s office in San Francisco’s Financial District, his hard hat sits on a table not far from his desk, ready for the next site visit. (Agarwal suggests Young could use a little more down time in his life, recalling a recent call where Young told her that he hadn’t seen the sun all day.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company now has eight employees – five in the office, three remote – mostly engineering hires, plus an operations person who started just this week. Interface’s biggest challenge is hiring fast enough to keep up with demand, a problem that requires its small team to tap networks across both Europe and the US.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for what Young makes of the life in San Francisco he wanted and is now living, he marvels at how accurate the Silicon Valley stereotypes turned out to be. “You see people online talking about, ‘Oh, you go to a park and the person sitting next to you has raised $50 million building some insane AI agent.’ But it is actually like that,” he says. “I think back to what life was like in Trinidad. I mention these ideas to people back home, and they just don’t believe me.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He occasionally makes time to go out in nature with friends – he says they went to Tahoe recently – and Interface hosts events like a hackathon they threw last weekend. But mostly, it’s work, and most of that work involves AI, just like everyone else’s in San Francisco right now.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Which makes the trips to oil rigs oddly appealing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Indeed, that hard hat at the office isn’t just a practical necessity; it’s also a lure, suggests Young. For engineers tired of building “some low-impact B2B sales or recruiting tool,” as Young puts it, the promise of occasionally leaving the Bay Area bubble to work with operators in the field has become a recruiting advantage. Less than 1% of San Francisco startups work in heavy industry, he notes, and that scarcity is part of the appeal, for him and for the people he’s hiring.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s probably not quite the version of the Silicon Valley dream he spent his childhood chasing from Trinidad: long hours, intense pressure, endless AI discussions everywhere, punctuated by the occasional trip to an oil rig.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, for now, he doesn’t seem to mind it. “Over the last month or two months, I have not done much at all [outside the office], because there’s just been so much intensity here, with building, hiring, selling.” But “I feel pretty strong,” he adds.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/21/how-this-founders-unlikely-path-to-silicon-valley-could-become-an-edge-in-industrial-tech/</guid><pubDate>Sat, 22 Nov 2025 03:26:19 +0000</pubDate></item></channel></rss>