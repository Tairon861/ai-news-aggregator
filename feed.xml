<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 04 Aug 2025 02:08:12 +0000</lastBuildDate><item><title>Why the AI era is forcing a redesign of the entire compute backbone (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/why-the-ai-era-is-forcing-a-redesign-of-the-entire-compute-backbone/</link><description>&lt;p&gt;The past few decades have seen almost unimaginable advances in compute performance and efficiency, enabled by Moore’s Law and underpinned by scale-out commodity hardware and loosely coupled software. This architecture has delivered online services to billions globally and put virtually all of human knowledge at our fingertips.&lt;/p&gt;&lt;p&gt;But the next computing revolution will demand much more. Fulfilling the promise of AI requires a step-change in capabilities far exceeding the advancements of the internet era. To achieve this, we as an industry must revisit some of the foundations that drove the previous transformation and innovate collectively to rethink the entire technology stack. Let’s explore the forces driving this upheaval and lay out what this architecture must look like.&lt;/p&gt;&lt;p&gt;For decades, the dominant trend in computing has been the democratization of compute through scale-out architectures built on nearly identical, commodity servers. This uniformity allowed for flexible workload placement and efficient resource utilization. The demands of gen AI, heavily reliant on predictable mathematical operations on massive datasets, are reversing this trend.&amp;nbsp;&lt;/p&gt;&lt;p&gt;We are now witnessing a decisive shift towards specialized hardware — including ASICs, GPUs, and tensor processing units (TPUs) — that deliver orders of magnitude improvements in performance per dollar and per watt compared to general-purpose CPUs. This proliferation of domain-specific compute units, optimized for narrower tasks, will be critical to driving the continued rapid advances in AI.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-beyond-ethernet-the-rise-of-specialized-interconnects"&gt;Beyond ethernet: The rise of specialized interconnects&lt;/h2&gt;



&lt;p&gt;These specialized systems will often require “all-to-all” communication, with terabit-per-second bandwidth and nanosecond latencies that approach local memory speeds. Today’s networks, largely based on commodity Ethernet switches and TCP/IP protocols, are ill-equipped to handle these extreme demands.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As a result, to scale gen AI workloads across vast clusters of specialized accelerators, we are seeing the rise of specialized interconnects, such as ICI for TPUs and NVLink for GPUs. These purpose-built networks prioritize direct memory-to-memory transfers and use dedicated hardware to speed information sharing among processors, effectively bypassing the overhead of traditional, layered networking stacks.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This move towards tightly integrated, compute-centric networking will be essential to overcoming communication bottlenecks and scaling the next generation of AI efficiently.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-breaking-the-memory-wall"&gt;Breaking the memory wall&lt;/h2&gt;



&lt;p&gt;For decades, the performance gains in computation have outpaced the growth in memory bandwidth. While techniques like caching and stacked SRAM have partially mitigated this, the data-intensive nature of AI is only exacerbating the problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The insatiable need to feed increasingly powerful compute units has led to high bandwidth memory (HBM), which stacks DRAM directly on the processor package to boost bandwidth and reduce latency. However, even HBM faces fundamental limitations: The physical chip perimeter restricts total dataflow, and moving massive datasets at terabit speeds creates significant energy constraints.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These limitations highlight the critical need for higher-bandwidth connectivity and underscore the urgency for breakthroughs in processing and memory architecture. Without these innovations, our powerful compute resources will sit idle waiting for data, dramatically limiting efficiency and scale.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-server-farms-to-high-density-systems"&gt;From server farms to high-density systems&lt;/h2&gt;



&lt;p&gt;Today’s advanced machine learning (ML) models often rely on carefully orchestrated calculations across tens to hundreds of thousands of identical compute elements, consuming immense power. This tight coupling and fine-grained synchronization at the microsecond level imposes new demands. Unlike systems that embrace heterogeneity, ML computations require homogeneous elements; mixing generations would bottleneck faster units. Communication pathways must also be pre-planned and highly efficient, since delays in a single element can stall an entire process.&lt;/p&gt;



&lt;p&gt;These extreme demands for coordination and power are driving the need for unprecedented compute density. Minimizing the physical distance between processors becomes essential to reduce latency and power consumption, paving the way for a new class of ultra-dense AI systems.&lt;/p&gt;



&lt;p&gt;This drive for extreme density and tightly coordinated computation fundamentally alters the optimal design for infrastructure, demanding a radical rethinking of physical layouts and dynamic power management to prevent performance bottlenecks and maximize efficiency.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-new-approach-to-fault-tolerance"&gt;A new approach to fault tolerance&lt;/h2&gt;



&lt;p&gt;Traditional fault tolerance relies on redundancy among loosely connected systems to achieve high uptime. ML computing demands a different approach.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;First, the sheer scale of computation makes over-provisioning too costly. Second, model training is a tightly synchronized process, where a single failure can cascade to thousands of processors. Finally, advanced ML hardware often pushes to the boundary of current technology, potentially leading to higher failure rates.&lt;/p&gt;



&lt;p&gt;Instead, the emerging strategy involves frequent checkpointing — saving computation state — coupled with real-time monitoring, rapid allocation of spare resources and quick restarts. The underlying hardware and network design must enable swift failure detection and seamless component replacement to maintain performance.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-more-sustainable-approach-to-power"&gt;A more sustainable approach to power&lt;/h2&gt;



&lt;p&gt;Today and looking forward, access to power is a key bottleneck for scaling AI compute. While traditional system design focuses on maximum performance per chip, we must shift to an end-to-end design focused on delivered, at-scale performance per watt. This approach is vital because it considers all system components — compute, network, memory, power delivery, cooling and fault tolerance — working together seamlessly to sustain performance. Optimizing components in isolation severely limits overall system efficiency.&lt;/p&gt;



&lt;p&gt;As we push for greater performance, individual chips require more power, often exceeding the cooling capacity of traditional air-cooled data centers. This necessitates a shift towards more energy-intensive, but ultimately more efficient, liquid cooling solutions, and a fundamental redesign of data center cooling infrastructure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Beyond cooling, conventional redundant power sources, like dual utility feeds and diesel generators, create substantial financial costs and slow capacity delivery. Instead, we must combine diverse power sources and storage at multi-gigawatt scale, managed by real-time microgrid controllers. By leveraging AI workload flexibility and geographic distribution, we can deliver more capability without expensive backup systems needed only a few hours per year.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This evolving power model enables real-time response to power availability — from shutting down computations during shortages to advanced techniques like frequency scaling for workloads that can tolerate reduced performance. All of this requires real-time telemetry and actuation at levels not currently available.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-security-and-privacy-baked-in-not-bolted-on"&gt;Security and privacy: Baked in, not bolted on&lt;/h2&gt;



&lt;p&gt;A critical lesson from the internet era is that security and privacy cannot be effectively bolted onto an existing architecture. Threats from bad actors will only grow more sophisticated, requiring protections for user data and proprietary intellectual property to be built into the fabric of the ML infrastructure. One important observation is that AI will, in the end, enhance attacker capabilities. This, in turn, means that we must ensure that AI simultaneously supercharges our defenses.&lt;/p&gt;



&lt;p&gt;This includes end-to-end data encryption, robust data lineage tracking with verifiable access logs, hardware-enforced security boundaries to protect sensitive computations and sophisticated key management systems. Integrating these safeguards from the ground up will be essential for protecting users and maintaining their trust. Real-time monitoring of what will likely be petabits/sec of telemetry and logging will be key to identifying and neutralizing needle-in-the-haystack attack vectors, including those coming from insider threats.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-speed-as-a-strategic-imperative"&gt;Speed as a strategic imperative&lt;/h2&gt;



&lt;p&gt;The rhythm of hardware upgrades has shifted dramatically. Unlike the incremental rack-by-rack evolution of traditional infrastructure, deploying ML supercomputers requires a fundamentally different approach. This is because ML compute does not easily run on heterogeneous deployments; the compute code, algorithms and compiler must be specifically tuned to each new hardware generation to fully leverage its capabilities. The rate of innovation is also unprecedented, often delivering a factor of two or more in performance year over year from new hardware.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Therefore, instead of incremental upgrades, a massive and simultaneous rollout of homogeneous hardware, often across entire data centers, is now required. With annual hardware refreshes delivering integer-factor performance improvements, the ability to rapidly stand up these colossal AI engines is paramount.&lt;/p&gt;



&lt;p&gt;The goal must be to compress timelines from design to fully operational 100,000-plus chip deployments, enabling efficiency improvements while supporting algorithmic breakthroughs. This necessitates radical acceleration and automation of every stage, demanding a manufacturing-like model for these infrastructures. From architecture to monitoring and repair, every step must be streamlined and automated to leverage each hardware generation at unprecedented scale.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-meeting-the-moment-a-collective-effort-for-next-gen-ai-infrastructure"&gt;Meeting the moment: A collective effort for next-gen AI infrastructure&lt;/h2&gt;



&lt;p&gt;The rise of gen AI marks not just an evolution, but a revolution that requires a radical reimagining of our computing infrastructure. The challenges ahead — in specialized hardware, interconnected networks and sustainable operations — are significant, but so too is the transformative potential of the AI it will enable.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It is easy to see that our resulting compute infrastructure will be unrecognizable in the few years ahead, meaning that we cannot simply improve on the blueprints we have already designed. Instead, we must collectively, from research to industry, embark on an effort to re-examine the requirements of AI compute from first principles, building a new blueprint for the underlying global infrastructure. This in turn will result in fundamentally new capabilities, from medicine to education to business, at unprecedented scale and efficiency.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Amin Vahdat is VP and GM for machine learning, systems and cloud AI at Google Cloud. &lt;/em&gt;&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;The past few decades have seen almost unimaginable advances in compute performance and efficiency, enabled by Moore’s Law and underpinned by scale-out commodity hardware and loosely coupled software. This architecture has delivered online services to billions globally and put virtually all of human knowledge at our fingertips.&lt;/p&gt;&lt;p&gt;But the next computing revolution will demand much more. Fulfilling the promise of AI requires a step-change in capabilities far exceeding the advancements of the internet era. To achieve this, we as an industry must revisit some of the foundations that drove the previous transformation and innovate collectively to rethink the entire technology stack. Let’s explore the forces driving this upheaval and lay out what this architecture must look like.&lt;/p&gt;&lt;p&gt;For decades, the dominant trend in computing has been the democratization of compute through scale-out architectures built on nearly identical, commodity servers. This uniformity allowed for flexible workload placement and efficient resource utilization. The demands of gen AI, heavily reliant on predictable mathematical operations on massive datasets, are reversing this trend.&amp;nbsp;&lt;/p&gt;&lt;p&gt;We are now witnessing a decisive shift towards specialized hardware — including ASICs, GPUs, and tensor processing units (TPUs) — that deliver orders of magnitude improvements in performance per dollar and per watt compared to general-purpose CPUs. This proliferation of domain-specific compute units, optimized for narrower tasks, will be critical to driving the continued rapid advances in AI.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-beyond-ethernet-the-rise-of-specialized-interconnects"&gt;Beyond ethernet: The rise of specialized interconnects&lt;/h2&gt;



&lt;p&gt;These specialized systems will often require “all-to-all” communication, with terabit-per-second bandwidth and nanosecond latencies that approach local memory speeds. Today’s networks, largely based on commodity Ethernet switches and TCP/IP protocols, are ill-equipped to handle these extreme demands.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As a result, to scale gen AI workloads across vast clusters of specialized accelerators, we are seeing the rise of specialized interconnects, such as ICI for TPUs and NVLink for GPUs. These purpose-built networks prioritize direct memory-to-memory transfers and use dedicated hardware to speed information sharing among processors, effectively bypassing the overhead of traditional, layered networking stacks.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This move towards tightly integrated, compute-centric networking will be essential to overcoming communication bottlenecks and scaling the next generation of AI efficiently.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-breaking-the-memory-wall"&gt;Breaking the memory wall&lt;/h2&gt;



&lt;p&gt;For decades, the performance gains in computation have outpaced the growth in memory bandwidth. While techniques like caching and stacked SRAM have partially mitigated this, the data-intensive nature of AI is only exacerbating the problem.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The insatiable need to feed increasingly powerful compute units has led to high bandwidth memory (HBM), which stacks DRAM directly on the processor package to boost bandwidth and reduce latency. However, even HBM faces fundamental limitations: The physical chip perimeter restricts total dataflow, and moving massive datasets at terabit speeds creates significant energy constraints.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These limitations highlight the critical need for higher-bandwidth connectivity and underscore the urgency for breakthroughs in processing and memory architecture. Without these innovations, our powerful compute resources will sit idle waiting for data, dramatically limiting efficiency and scale.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-server-farms-to-high-density-systems"&gt;From server farms to high-density systems&lt;/h2&gt;



&lt;p&gt;Today’s advanced machine learning (ML) models often rely on carefully orchestrated calculations across tens to hundreds of thousands of identical compute elements, consuming immense power. This tight coupling and fine-grained synchronization at the microsecond level imposes new demands. Unlike systems that embrace heterogeneity, ML computations require homogeneous elements; mixing generations would bottleneck faster units. Communication pathways must also be pre-planned and highly efficient, since delays in a single element can stall an entire process.&lt;/p&gt;



&lt;p&gt;These extreme demands for coordination and power are driving the need for unprecedented compute density. Minimizing the physical distance between processors becomes essential to reduce latency and power consumption, paving the way for a new class of ultra-dense AI systems.&lt;/p&gt;



&lt;p&gt;This drive for extreme density and tightly coordinated computation fundamentally alters the optimal design for infrastructure, demanding a radical rethinking of physical layouts and dynamic power management to prevent performance bottlenecks and maximize efficiency.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-new-approach-to-fault-tolerance"&gt;A new approach to fault tolerance&lt;/h2&gt;



&lt;p&gt;Traditional fault tolerance relies on redundancy among loosely connected systems to achieve high uptime. ML computing demands a different approach.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;First, the sheer scale of computation makes over-provisioning too costly. Second, model training is a tightly synchronized process, where a single failure can cascade to thousands of processors. Finally, advanced ML hardware often pushes to the boundary of current technology, potentially leading to higher failure rates.&lt;/p&gt;



&lt;p&gt;Instead, the emerging strategy involves frequent checkpointing — saving computation state — coupled with real-time monitoring, rapid allocation of spare resources and quick restarts. The underlying hardware and network design must enable swift failure detection and seamless component replacement to maintain performance.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-more-sustainable-approach-to-power"&gt;A more sustainable approach to power&lt;/h2&gt;



&lt;p&gt;Today and looking forward, access to power is a key bottleneck for scaling AI compute. While traditional system design focuses on maximum performance per chip, we must shift to an end-to-end design focused on delivered, at-scale performance per watt. This approach is vital because it considers all system components — compute, network, memory, power delivery, cooling and fault tolerance — working together seamlessly to sustain performance. Optimizing components in isolation severely limits overall system efficiency.&lt;/p&gt;



&lt;p&gt;As we push for greater performance, individual chips require more power, often exceeding the cooling capacity of traditional air-cooled data centers. This necessitates a shift towards more energy-intensive, but ultimately more efficient, liquid cooling solutions, and a fundamental redesign of data center cooling infrastructure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Beyond cooling, conventional redundant power sources, like dual utility feeds and diesel generators, create substantial financial costs and slow capacity delivery. Instead, we must combine diverse power sources and storage at multi-gigawatt scale, managed by real-time microgrid controllers. By leveraging AI workload flexibility and geographic distribution, we can deliver more capability without expensive backup systems needed only a few hours per year.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This evolving power model enables real-time response to power availability — from shutting down computations during shortages to advanced techniques like frequency scaling for workloads that can tolerate reduced performance. All of this requires real-time telemetry and actuation at levels not currently available.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-security-and-privacy-baked-in-not-bolted-on"&gt;Security and privacy: Baked in, not bolted on&lt;/h2&gt;



&lt;p&gt;A critical lesson from the internet era is that security and privacy cannot be effectively bolted onto an existing architecture. Threats from bad actors will only grow more sophisticated, requiring protections for user data and proprietary intellectual property to be built into the fabric of the ML infrastructure. One important observation is that AI will, in the end, enhance attacker capabilities. This, in turn, means that we must ensure that AI simultaneously supercharges our defenses.&lt;/p&gt;



&lt;p&gt;This includes end-to-end data encryption, robust data lineage tracking with verifiable access logs, hardware-enforced security boundaries to protect sensitive computations and sophisticated key management systems. Integrating these safeguards from the ground up will be essential for protecting users and maintaining their trust. Real-time monitoring of what will likely be petabits/sec of telemetry and logging will be key to identifying and neutralizing needle-in-the-haystack attack vectors, including those coming from insider threats.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-speed-as-a-strategic-imperative"&gt;Speed as a strategic imperative&lt;/h2&gt;



&lt;p&gt;The rhythm of hardware upgrades has shifted dramatically. Unlike the incremental rack-by-rack evolution of traditional infrastructure, deploying ML supercomputers requires a fundamentally different approach. This is because ML compute does not easily run on heterogeneous deployments; the compute code, algorithms and compiler must be specifically tuned to each new hardware generation to fully leverage its capabilities. The rate of innovation is also unprecedented, often delivering a factor of two or more in performance year over year from new hardware.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Therefore, instead of incremental upgrades, a massive and simultaneous rollout of homogeneous hardware, often across entire data centers, is now required. With annual hardware refreshes delivering integer-factor performance improvements, the ability to rapidly stand up these colossal AI engines is paramount.&lt;/p&gt;



&lt;p&gt;The goal must be to compress timelines from design to fully operational 100,000-plus chip deployments, enabling efficiency improvements while supporting algorithmic breakthroughs. This necessitates radical acceleration and automation of every stage, demanding a manufacturing-like model for these infrastructures. From architecture to monitoring and repair, every step must be streamlined and automated to leverage each hardware generation at unprecedented scale.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-meeting-the-moment-a-collective-effort-for-next-gen-ai-infrastructure"&gt;Meeting the moment: A collective effort for next-gen AI infrastructure&lt;/h2&gt;



&lt;p&gt;The rise of gen AI marks not just an evolution, but a revolution that requires a radical reimagining of our computing infrastructure. The challenges ahead — in specialized hardware, interconnected networks and sustainable operations — are significant, but so too is the transformative potential of the AI it will enable.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It is easy to see that our resulting compute infrastructure will be unrecognizable in the few years ahead, meaning that we cannot simply improve on the blueprints we have already designed. Instead, we must collectively, from research to industry, embark on an effort to re-examine the requirements of AI compute from first principles, building a new blueprint for the underlying global infrastructure. This in turn will result in fundamentally new capabilities, from medicine to education to business, at unprecedented scale and efficiency.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Amin Vahdat is VP and GM for machine learning, systems and cloud AI at Google Cloud. &lt;/em&gt;&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/why-the-ai-era-is-forcing-a-redesign-of-the-entire-compute-backbone/</guid><pubDate>Sun, 03 Aug 2025 18:05:00 +0000</pubDate></item><item><title>[NEW] Why tomorrow’s best devs won’t just code — they’ll curate, coordinate and command AI (AI News | VentureBeat)</title><link>https://venturebeat.com/programming-development/why-tomorrows-best-devs-wont-just-code-theyll-curate-coordinate-and-command-ai/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;As AI continues to take on more and more new competencies, junior coding, as we knew it, is rapidly becoming a thing of the past. Tasks that used to be the bread and butter for junior developers — such as repetitive scripting, HTML layout or simple DevOps setups — are now being reliably handled by AI assistants like ChatGPT, GitHub Copilot and Amazon CodeWhisperer.&lt;/p&gt;



&lt;p&gt;This is not just an upgrade to speed and efficiency — we are looking at a serious structural change here. So where does that leave entry-level developers? And, speaking more broadly, where does it leave the software industry as a whole?&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-vanishing-beginner-level"&gt;The vanishing beginner level&lt;/h2&gt;



&lt;p&gt;For decades, software engineering as a field had a fairly predictable pathway: Begin with the basics, build some landing pages, write test cases, troubleshoot minor bugs. As your skills grow, you can move toward architectural thinking and product ownership.&lt;/p&gt;



&lt;p&gt;But now AI is vastly changing how the bottom end of that ladder operates, since it can do most junior-level tasks on its own.&lt;/p&gt;



&lt;p&gt;As a result, beginners entering the industry are increasingly being asked to contribute at a level that used to require years of experience. It is not just about writing code anymore — it is about understanding systems, structuring problems and working alongside AI like a team member. That is a tall order. That said, I do believe that there is a way forward. It starts by changing the way we learn.&lt;/p&gt;



&lt;p&gt;If you are just starting out, avoid relying on AI to get things done. It is tempting, sure, but in the long run, it is also harmful. If you skip the manual practice, you are missing out on building a deeper understanding of how software really works. That understanding is critical if you want to grow into the kind of developer who can lead, architect and guide AI instead of being replaced by it.&lt;/p&gt;



&lt;p&gt;The way I see it, in the near future, the most valuable people in tech won’t be the ones who write perfect code. They will be those who know what should be built, why it matters and how to get an AI system to do most of the work cleanly and efficiently. In other words, the coder of tomorrow looks more like a product manager with solid technical expertise.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-teams-are-changing-too"&gt;Teams are changing, too&lt;/h2&gt;



&lt;p&gt;Based on everything we covered above, I also feel the need to point out that it is not just individuals who need to rethink their roles. Entire teams are shifting. Where we once had clearly defined roles — front-end developer, back-end specialist, DevOps engineer, QA tester — we will soon see one developer managing a whole pipeline with the help of AI.&lt;/p&gt;



&lt;p&gt;AI-augmented developers will replace large teams that used to be necessary to move a project forward. In terms of efficiency, there is a lot to celebrate about this change — reduced communication time, faster results and higher bars for what one person can realistically accomplish.&lt;/p&gt;



&lt;p&gt;But, of course, this does not mean teams will disappear altogether. It is just that the structure will change. Collaboration will focus more on strategic decisions, product alignment and making sure AI tools are being used responsibly and effectively. The human input will be less about implementation and more about direction.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ai-is-creating-a-new-career-path"&gt;AI is creating a new career path&lt;/h2&gt;



&lt;p&gt;If we look five to seven years ahead, I suspect that the idea of a “developer” as we know it today will have changed into something else entirely. We will likely see more hybrid roles — part developer, part designer, part product thinker. As already mentioned, the core part of the job won’t be to write code, but to shape ideas into working software using AI as your main creation tool. Or perhaps, even as a co-creator.&lt;/p&gt;



&lt;p&gt;Being technically fluent will still remain a crucial requirement — but it won’t be enough to simply know how to code. You will need to understand product thinking, user needs and how to manage AI’s output. It will be more about system design and strategic vision.&lt;/p&gt;



&lt;p&gt;For some, this may sound intimidating, but for others, it will also open many doors. People with creativity and a knack for problem-solving will have huge opportunities ahead of them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The landscape is shifting, yes — there is no escaping that fact. But for those willing to adapt, one could argue it is shifting in their favor. The end of junior coding is not the end of learning. It is a sign that we need to reconsider what kind of talents we grow, how we structure teams and what makes someone a great developer.&lt;/p&gt;



&lt;p&gt;To my mind, instead of mourning the loss of basic tasks, the industry as a whole should focus on building the skills that cannot be automated. At least, not yet. That means implementing a hybrid approach and learning how to work with AI as a partner rather than a competitor.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Roman Eloshvili is founder of ComplyControl.&lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;As AI continues to take on more and more new competencies, junior coding, as we knew it, is rapidly becoming a thing of the past. Tasks that used to be the bread and butter for junior developers — such as repetitive scripting, HTML layout or simple DevOps setups — are now being reliably handled by AI assistants like ChatGPT, GitHub Copilot and Amazon CodeWhisperer.&lt;/p&gt;



&lt;p&gt;This is not just an upgrade to speed and efficiency — we are looking at a serious structural change here. So where does that leave entry-level developers? And, speaking more broadly, where does it leave the software industry as a whole?&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-vanishing-beginner-level"&gt;The vanishing beginner level&lt;/h2&gt;



&lt;p&gt;For decades, software engineering as a field had a fairly predictable pathway: Begin with the basics, build some landing pages, write test cases, troubleshoot minor bugs. As your skills grow, you can move toward architectural thinking and product ownership.&lt;/p&gt;



&lt;p&gt;But now AI is vastly changing how the bottom end of that ladder operates, since it can do most junior-level tasks on its own.&lt;/p&gt;



&lt;p&gt;As a result, beginners entering the industry are increasingly being asked to contribute at a level that used to require years of experience. It is not just about writing code anymore — it is about understanding systems, structuring problems and working alongside AI like a team member. That is a tall order. That said, I do believe that there is a way forward. It starts by changing the way we learn.&lt;/p&gt;



&lt;p&gt;If you are just starting out, avoid relying on AI to get things done. It is tempting, sure, but in the long run, it is also harmful. If you skip the manual practice, you are missing out on building a deeper understanding of how software really works. That understanding is critical if you want to grow into the kind of developer who can lead, architect and guide AI instead of being replaced by it.&lt;/p&gt;



&lt;p&gt;The way I see it, in the near future, the most valuable people in tech won’t be the ones who write perfect code. They will be those who know what should be built, why it matters and how to get an AI system to do most of the work cleanly and efficiently. In other words, the coder of tomorrow looks more like a product manager with solid technical expertise.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-teams-are-changing-too"&gt;Teams are changing, too&lt;/h2&gt;



&lt;p&gt;Based on everything we covered above, I also feel the need to point out that it is not just individuals who need to rethink their roles. Entire teams are shifting. Where we once had clearly defined roles — front-end developer, back-end specialist, DevOps engineer, QA tester — we will soon see one developer managing a whole pipeline with the help of AI.&lt;/p&gt;



&lt;p&gt;AI-augmented developers will replace large teams that used to be necessary to move a project forward. In terms of efficiency, there is a lot to celebrate about this change — reduced communication time, faster results and higher bars for what one person can realistically accomplish.&lt;/p&gt;



&lt;p&gt;But, of course, this does not mean teams will disappear altogether. It is just that the structure will change. Collaboration will focus more on strategic decisions, product alignment and making sure AI tools are being used responsibly and effectively. The human input will be less about implementation and more about direction.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ai-is-creating-a-new-career-path"&gt;AI is creating a new career path&lt;/h2&gt;



&lt;p&gt;If we look five to seven years ahead, I suspect that the idea of a “developer” as we know it today will have changed into something else entirely. We will likely see more hybrid roles — part developer, part designer, part product thinker. As already mentioned, the core part of the job won’t be to write code, but to shape ideas into working software using AI as your main creation tool. Or perhaps, even as a co-creator.&lt;/p&gt;



&lt;p&gt;Being technically fluent will still remain a crucial requirement — but it won’t be enough to simply know how to code. You will need to understand product thinking, user needs and how to manage AI’s output. It will be more about system design and strategic vision.&lt;/p&gt;



&lt;p&gt;For some, this may sound intimidating, but for others, it will also open many doors. People with creativity and a knack for problem-solving will have huge opportunities ahead of them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The landscape is shifting, yes — there is no escaping that fact. But for those willing to adapt, one could argue it is shifting in their favor. The end of junior coding is not the end of learning. It is a sign that we need to reconsider what kind of talents we grow, how we structure teams and what makes someone a great developer.&lt;/p&gt;



&lt;p&gt;To my mind, instead of mourning the loss of basic tasks, the industry as a whole should focus on building the skills that cannot be automated. At least, not yet. That means implementing a hybrid approach and learning how to work with AI as a partner rather than a competitor.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Roman Eloshvili is founder of ComplyControl.&lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/programming-development/why-tomorrows-best-devs-wont-just-code-theyll-curate-coordinate-and-command-ai/</guid><pubDate>Sun, 03 Aug 2025 20:05:00 +0000</pubDate></item><item><title>[NEW] Apple might be building its own AI ‘answer engine’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/03/apple-might-be-building-its-own-ai-answer-engine/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/apple-intelligence-iphone-mac.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple has formed a new team to build a ChatGPT-like app, according to according to Bloomberg’s Mark Gurman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This team — reportedly called Answers, Knowledge, and Information — is working to build an “answer engine” that can respond to questions using information from across the web. This could be a standalone app or provide search capabilities in Siri, Safari, and other Apple products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gurman also notes that Apple is advertising for jobs with this team, specifically looking for applicants who have experience with search algorithms and engine development.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Apple has already integrated ChatGPT into Siri, a more personalized, AI-powered update to the voice assistant has been repeatedly delayed. Apple might also have to alter its search deal with Google as a result of the latter company’s antitrust defeat.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/apple-intelligence-iphone-mac.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple has formed a new team to build a ChatGPT-like app, according to according to Bloomberg’s Mark Gurman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This team — reportedly called Answers, Knowledge, and Information — is working to build an “answer engine” that can respond to questions using information from across the web. This could be a standalone app or provide search capabilities in Siri, Safari, and other Apple products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gurman also notes that Apple is advertising for jobs with this team, specifically looking for applicants who have experience with search algorithms and engine development.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Apple has already integrated ChatGPT into Siri, a more personalized, AI-powered update to the voice assistant has been repeatedly delayed. Apple might also have to alter its search deal with Google as a result of the latter company’s antitrust defeat.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/03/apple-might-be-building-its-own-ai-answer-engine/</guid><pubDate>Sun, 03 Aug 2025 21:49:00 +0000</pubDate></item></channel></rss>