<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 08 Oct 2025 12:43:32 +0000</lastBuildDate><item><title>[NEW] AI Redaction That Puts Privacy First: CaseGuard Studio Leading The Way (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-redaction-that-puts-privacy-first-caseguard-studio-leading-the-way/</link><description>&lt;p&gt;Law enforcement, law firms, hospitals, and financial institutions are asked every day to release records, which can contain highly sensitive details – including addresses, social security numbers, medical diagnoses, evidence footage, and children’s identities.&lt;/p&gt;&lt;p&gt;To meet compliance and security requirements, staff spend hundreds of hours manually redacting sensitive information, yet when that process goes wrong, there can be costly consequences. Last year, healthcare company Advanced was fined £6 million for losing patient records that, among other details, contained information about how to gain entry to the homes of 890 care receivers. Even the smallest oversights can create unpleasant headlines and catastrophic fines.&lt;/p&gt;&lt;p&gt;This is the reality of modern data handling: leaks can be catastrophic, and compliance frameworks like GDPR, HIPAA, and FERPA, plus FOIA requests, require more vigilance than manual redaction can provide. What organizations need is not more staff to ensure proper redaction, but tools that achieve it quickly, reliably, and securely.&lt;/p&gt;&lt;p&gt;CaseGuard Studio, a US-based AI redaction &amp;amp; investigation platform, has built software that automates this manual work with 98% accuracy. It can process thousands of files in minutes, working on data that’s kept securely on-premises of any file type, including video, audio, documents, and images.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-manual-redaction-no-longer-works"&gt;Why Manual Redaction No Longer Works&lt;/h3&gt;&lt;p&gt;Redaction is not new, but the tools most people reach for were not built for the complexity of today’s compliance requirements. Adobe Acrobat, for example, offers text redaction but needs manual work on each document. Premiere’s video editing software requires frame-by-frame subject tracking for video redaction, which is slow and impractical. These solutions provide only limited capability and were never designed for departments that process a multitude of redactions on a weekly basis.&lt;/p&gt;&lt;p&gt;CaseGuard Studio, by contrast, was purpose-built for just this challenge. It can detect 12 categories of PII (personally-identifiable information) in video and images, such as faces, license plates, notepads, and more. It tracks and redacts all PII without needing manual frame-by-frame intervention.&lt;/p&gt;&lt;p&gt;For audio and documents, CaseGuard Studio supports over 30 PII types, like names, phone numbers, and addresses. Custom keywords, phrases, or sentences can be auto-detected and redacted directly from thousands of documents and transcripts, streamlining compliance in ways manual tools can’t match. It transcribes recordings with high accuracy and can translate to and from 100+ languages, so it can redact sensitive terms in multilingual content.&lt;/p&gt;&lt;p&gt;What once took days of human labor can now happen in minutes. CaseGuard Studio automates redaction work with 98% accuracy, up to 30 times faster than manual methods, and because it runs fully on-premise, data never leaves the device.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-to-ask-when-choosing-redaction-software"&gt;What to Ask When Choosing Redaction Software&lt;/h3&gt;&lt;p&gt;For organizations evaluating redaction software, the decision often comes down to a handful of critical questions that determine whether a platform can deliver on both compliance and efficiency. The following questions are central to making the right choice.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Can the software handle every file type we work with?&lt;/strong&gt; From scanned forms and handwritten notes to video, audio, and still images, organizations in sensitive sectors deal with more than PDFs.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Is the platform fully automated?&lt;/strong&gt; If redaction still means blacking out text with a Sharpie or scrubbing video frame by frame, the process is slow and prone to error. Full automation ensures accuracy and frees staff for higher-impact work.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Does the software ensure data never leaves your environment?&lt;/strong&gt; On-premise deployment means sensitive files are processed locally, so nothing is exposed to third-party servers or cloud risks.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Does the pricing stay predictable as you scale?&lt;/strong&gt; Per-file or per-minute pricing quickly becomes unsustainable as workloads grow. Look for a flat subscription with unlimited redaction, so costs stay predictable no matter how much data you process.&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-evaluating-caseguard-studio-against-the-four-redaction-essentials"&gt;Evaluating CaseGuard Studio Against the Four Redaction Essentials&lt;/h3&gt;&lt;p&gt;When assessed against these requirements, CaseGuard Studio was the only platform in our evaluation that consistently delivered across all five redaction essentials.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Auto-redact files from any source&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;From text documents and scanned forms to video, audio, images, and even handwriting, redaction has to cover every format where sensitive information might appear. Missing one identifiable feature, a face in a crowd or an un-redacted license plate, and a single oversight can be the difference between full compliance and a lawsuit. CaseGuard Studio automatically detects and redacts sensitive information across all these file types within a single platform with complete compliance.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Automated bulk redaction at speed and scale&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Thousands of files can be redacted in bulk, turning weeks of manual effort into minutes of processing. CaseGuard Studio handles workloads up to 32x faster than manual methods, with 98% accuracy, giving organizations the speed and scalability to meet growing compliance demands.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Your data, your control&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;CaseGuard Studio runs fully on-premise, within your secure environment, including air-gapped systems that are completely isolated from external networks. This ensures organizations retain full control of their data, with nothing exposed to third-party servers or cloud risks.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt; Unlimited redaction, no pay-per-file fees&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Pay-per-file pricing quickly adds up, making every additional redaction more expensive. CaseGuard Studio offers predictable pricing under a flat subscription with unlimited redaction, so costs remain the same no matter how heavy the redaction load is.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt; [embedded content]&lt;/p&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="h-final-thoughts"&gt;Final Thoughts&lt;/h2&gt;&lt;p&gt;Over the course of our evaluation, we compared methods and platforms ranging from manual redaction and legacy PDF editors to newer AI-driven tools that have appeared in the last few years. Most delivered partial solutions, treating written documents well but failing on audio, while others blurred faces in video, but weren’t practical to use at scale. Cloud-only options raised sovereignty and compliance concerns that, for many users, would count them out of the running entirely.&lt;/p&gt;&lt;p&gt;CaseGuard Studio was the only platform that consistently met all five requirements detailed above. It supports the widest of file types, from body-cam video to scanned or handwritten forms.&lt;/p&gt;&lt;p&gt;Audio and video are probably the most difficult formats to redact, especially at scale. Here, CaseGuard wins our vote with its AI-powered smarts. It runs fully on-premise, keeps sensitive files under organizational control, and its local AI models are refined with each version release.&lt;/p&gt;&lt;p&gt;At a time when many cloud redaction software licensing models drive up costs as workloads grow, CaseGuard’s flat pricing offers a refreshing change — predictable, transparent, and sustainable.&lt;/p&gt;&lt;p&gt;For any organization facing rising compliance demands and ever-larger volumes of sensitive data, CaseGuard Studio is well worth a closer look. Click here to book a consultation.&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Law enforcement, law firms, hospitals, and financial institutions are asked every day to release records, which can contain highly sensitive details – including addresses, social security numbers, medical diagnoses, evidence footage, and children’s identities.&lt;/p&gt;&lt;p&gt;To meet compliance and security requirements, staff spend hundreds of hours manually redacting sensitive information, yet when that process goes wrong, there can be costly consequences. Last year, healthcare company Advanced was fined £6 million for losing patient records that, among other details, contained information about how to gain entry to the homes of 890 care receivers. Even the smallest oversights can create unpleasant headlines and catastrophic fines.&lt;/p&gt;&lt;p&gt;This is the reality of modern data handling: leaks can be catastrophic, and compliance frameworks like GDPR, HIPAA, and FERPA, plus FOIA requests, require more vigilance than manual redaction can provide. What organizations need is not more staff to ensure proper redaction, but tools that achieve it quickly, reliably, and securely.&lt;/p&gt;&lt;p&gt;CaseGuard Studio, a US-based AI redaction &amp;amp; investigation platform, has built software that automates this manual work with 98% accuracy. It can process thousands of files in minutes, working on data that’s kept securely on-premises of any file type, including video, audio, documents, and images.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-manual-redaction-no-longer-works"&gt;Why Manual Redaction No Longer Works&lt;/h3&gt;&lt;p&gt;Redaction is not new, but the tools most people reach for were not built for the complexity of today’s compliance requirements. Adobe Acrobat, for example, offers text redaction but needs manual work on each document. Premiere’s video editing software requires frame-by-frame subject tracking for video redaction, which is slow and impractical. These solutions provide only limited capability and were never designed for departments that process a multitude of redactions on a weekly basis.&lt;/p&gt;&lt;p&gt;CaseGuard Studio, by contrast, was purpose-built for just this challenge. It can detect 12 categories of PII (personally-identifiable information) in video and images, such as faces, license plates, notepads, and more. It tracks and redacts all PII without needing manual frame-by-frame intervention.&lt;/p&gt;&lt;p&gt;For audio and documents, CaseGuard Studio supports over 30 PII types, like names, phone numbers, and addresses. Custom keywords, phrases, or sentences can be auto-detected and redacted directly from thousands of documents and transcripts, streamlining compliance in ways manual tools can’t match. It transcribes recordings with high accuracy and can translate to and from 100+ languages, so it can redact sensitive terms in multilingual content.&lt;/p&gt;&lt;p&gt;What once took days of human labor can now happen in minutes. CaseGuard Studio automates redaction work with 98% accuracy, up to 30 times faster than manual methods, and because it runs fully on-premise, data never leaves the device.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-to-ask-when-choosing-redaction-software"&gt;What to Ask When Choosing Redaction Software&lt;/h3&gt;&lt;p&gt;For organizations evaluating redaction software, the decision often comes down to a handful of critical questions that determine whether a platform can deliver on both compliance and efficiency. The following questions are central to making the right choice.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Can the software handle every file type we work with?&lt;/strong&gt; From scanned forms and handwritten notes to video, audio, and still images, organizations in sensitive sectors deal with more than PDFs.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Is the platform fully automated?&lt;/strong&gt; If redaction still means blacking out text with a Sharpie or scrubbing video frame by frame, the process is slow and prone to error. Full automation ensures accuracy and frees staff for higher-impact work.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Does the software ensure data never leaves your environment?&lt;/strong&gt; On-premise deployment means sensitive files are processed locally, so nothing is exposed to third-party servers or cloud risks.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Does the pricing stay predictable as you scale?&lt;/strong&gt; Per-file or per-minute pricing quickly becomes unsustainable as workloads grow. Look for a flat subscription with unlimited redaction, so costs stay predictable no matter how much data you process.&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-evaluating-caseguard-studio-against-the-four-redaction-essentials"&gt;Evaluating CaseGuard Studio Against the Four Redaction Essentials&lt;/h3&gt;&lt;p&gt;When assessed against these requirements, CaseGuard Studio was the only platform in our evaluation that consistently delivered across all five redaction essentials.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Auto-redact files from any source&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;From text documents and scanned forms to video, audio, images, and even handwriting, redaction has to cover every format where sensitive information might appear. Missing one identifiable feature, a face in a crowd or an un-redacted license plate, and a single oversight can be the difference between full compliance and a lawsuit. CaseGuard Studio automatically detects and redacts sensitive information across all these file types within a single platform with complete compliance.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Automated bulk redaction at speed and scale&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Thousands of files can be redacted in bulk, turning weeks of manual effort into minutes of processing. CaseGuard Studio handles workloads up to 32x faster than manual methods, with 98% accuracy, giving organizations the speed and scalability to meet growing compliance demands.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Your data, your control&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;CaseGuard Studio runs fully on-premise, within your secure environment, including air-gapped systems that are completely isolated from external networks. This ensures organizations retain full control of their data, with nothing exposed to third-party servers or cloud risks.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt; Unlimited redaction, no pay-per-file fees&lt;/strong&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Pay-per-file pricing quickly adds up, making every additional redaction more expensive. CaseGuard Studio offers predictable pricing under a flat subscription with unlimited redaction, so costs remain the same no matter how heavy the redaction load is.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt; [embedded content]&lt;/p&gt;&lt;/figure&gt;&lt;h2 class="wp-block-heading" id="h-final-thoughts"&gt;Final Thoughts&lt;/h2&gt;&lt;p&gt;Over the course of our evaluation, we compared methods and platforms ranging from manual redaction and legacy PDF editors to newer AI-driven tools that have appeared in the last few years. Most delivered partial solutions, treating written documents well but failing on audio, while others blurred faces in video, but weren’t practical to use at scale. Cloud-only options raised sovereignty and compliance concerns that, for many users, would count them out of the running entirely.&lt;/p&gt;&lt;p&gt;CaseGuard Studio was the only platform that consistently met all five requirements detailed above. It supports the widest of file types, from body-cam video to scanned or handwritten forms.&lt;/p&gt;&lt;p&gt;Audio and video are probably the most difficult formats to redact, especially at scale. Here, CaseGuard wins our vote with its AI-powered smarts. It runs fully on-premise, keeps sensitive files under organizational control, and its local AI models are refined with each version release.&lt;/p&gt;&lt;p&gt;At a time when many cloud redaction software licensing models drive up costs as workloads grow, CaseGuard’s flat pricing offers a refreshing change — predictable, transparent, and sustainable.&lt;/p&gt;&lt;p&gt;For any organization facing rising compliance demands and ever-larger volumes of sensitive data, CaseGuard Studio is well worth a closer look. Click here to book a consultation.&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-redaction-that-puts-privacy-first-caseguard-studio-leading-the-way/</guid><pubDate>Wed, 08 Oct 2025 09:07:44 +0000</pubDate></item><item><title>[NEW] Tuned Global strengthens its leadership in music technology with the acquisition of Figaro.ai (AI News)</title><link>https://www.artificialintelligence-news.com/news/tuned-global-strengthens-its-leadership-in-music-technology-with-the-acquisition-of-figaro-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/music-technology.png" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;The acquisition underscores Tuned Global’s commitment to shaping the future of the music industry by empowering clients with innovative technology and unmatched execution, while continuing to support existing Figaro.ai customers.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Wednesday, 8 October, 2025&lt;/strong&gt; — &lt;strong&gt;Tuned Global&lt;/strong&gt;, the leading music and media technology platform, has today announced the acquisition of &lt;strong&gt;Figaro.ai &lt;/strong&gt;&lt;strong&gt;(by FeedForward)&lt;/strong&gt;, a London-based audio-AI company known for making music catalogues smarter and more discoverable.&lt;/p&gt;&lt;p&gt;The acquisition advances Tuned Global’s strategy to be the cloud platform that clients build on to innovate. By bringing Figaro.ai into its partner-friendly platform, Tuned Global is enhancing its platform with AI innovation to deliver practical outcomes for customers: faster innovation, greater engagement and measurable business impact.&lt;/p&gt;&lt;p&gt;“With Figaro.ai, Tuned Global cements its position as the most comprehensive music platform, where innovation across AI, fraud detection, rights management, search and recommendations can be built,” &lt;strong&gt;said Tuned Global CEO Con Raso.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This move is about using technology to improve client outcomes and deliver value for the wider industry. It follows Tuned Global’s earlier acquisition of Pacemaker, known for pioneering AI-powered mixing technology, and reflects a clear strategy: acquiring companies whose innovation and IP help clients and the industry build the future of music technology and streaming. Integrating Figaro.ai strengthens Tuned Global’s ability to power premium, highly relevant music experiences at scale.&lt;/p&gt;&lt;p&gt;Tuned Global remains an open ecosystem, with Figaro.ai integrated as another component in a broader platform. It will operate as an integrated but distinct component within Tuned Global’s broader platform, complementing existing partners and expanding client options.&lt;/p&gt;&lt;p&gt;Current Figaro.ai clients will continue to be supported, backed by Tuned Global’s global reach, infrastructure and long-term commitment.&lt;/p&gt;&lt;p&gt;The Figaro.ai team, including founders &lt;strong&gt;Lydia Gregory&lt;/strong&gt; and &lt;strong&gt;Kevin Webster&lt;/strong&gt;, will be integrated within Tuned Global, ensuring continuity for existing customers and adding deep AI expertise to accelerate the company’s roadmap.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Tuned Global CEO Con Raso&lt;/strong&gt; said he was thrilled to welcome the deeply skilled Figaro.ai team into the fold.&lt;/p&gt;&lt;p&gt;&amp;nbsp;“At Tuned Global, we see ourselves as the hub where innovation in music technology takes shape. We are building the largest open ecosystem of AI music intelligence, giving our clients maximum choice and real impact for the music industry,” he said. “With Figaro.ai joining the platform, we’re not only expanding that ecosystem with cutting-edge technology but also welcoming a highly skilled team whose expertise strengthens our ability to deliver music experiences that are powerful, flexible and future-ready.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Figaro.ai&lt;/strong&gt;&lt;strong&gt; CEO and Co-founder Lydia Gregory&lt;/strong&gt; said she was excited to join Tuned Global and amplify the impact of her company’s objectives.&lt;/p&gt;&lt;p&gt;&amp;nbsp;“Figaro.ai has always been about combining deep technical expertise with a passion for music discovery. I’m incredibly proud of the team that built this technology, and I’m thrilled that they are joining me as part of Tuned Global,” she said. “Being integrated into a platform of this scale means we can continue our mission with greater reach and impact, while ensuring continuity for the clients who already rely on us. Together, we’re ready to help the industry deliver music experiences that are more relevant, premium, and engaging than ever before.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;About Tuned Global&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tuned Global is the leading data-driven cloud and software platform that empowers businesses to integrate commercial music into their apps or launch complete streaming experiences using advanced APIs, real-time analytics, licensing solutions, and customisable white-label apps.&lt;/p&gt;&lt;p&gt;Our turnkey solutions for music, audio, and video — coupled with a broad ecosystem of third-party music tech integrations — make us the most comprehensive platform for powering any digital music project. We streamline complexities in licensing, rights management, and content delivery, enabling rapid innovation and bringing new ideas to life.&lt;/p&gt;&lt;p&gt;Since 2011, we’ve supported 40+ companies in 70+ countries — across telecom, fitness, media, aviation, and more — to deliver innovative music experiences faster and more cost-effectively. For more information, visit www.tunedglobal.com.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;About Figaro&lt;/strong&gt;&lt;br /&gt;Figaro is the audio intelligence platform for music search, tagging and content detection – powering smarter discovery and content management across sync, DSPs, UGC, and distribution.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/music-technology.png" /&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;The acquisition underscores Tuned Global’s commitment to shaping the future of the music industry by empowering clients with innovative technology and unmatched execution, while continuing to support existing Figaro.ai customers.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Wednesday, 8 October, 2025&lt;/strong&gt; — &lt;strong&gt;Tuned Global&lt;/strong&gt;, the leading music and media technology platform, has today announced the acquisition of &lt;strong&gt;Figaro.ai &lt;/strong&gt;&lt;strong&gt;(by FeedForward)&lt;/strong&gt;, a London-based audio-AI company known for making music catalogues smarter and more discoverable.&lt;/p&gt;&lt;p&gt;The acquisition advances Tuned Global’s strategy to be the cloud platform that clients build on to innovate. By bringing Figaro.ai into its partner-friendly platform, Tuned Global is enhancing its platform with AI innovation to deliver practical outcomes for customers: faster innovation, greater engagement and measurable business impact.&lt;/p&gt;&lt;p&gt;“With Figaro.ai, Tuned Global cements its position as the most comprehensive music platform, where innovation across AI, fraud detection, rights management, search and recommendations can be built,” &lt;strong&gt;said Tuned Global CEO Con Raso.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This move is about using technology to improve client outcomes and deliver value for the wider industry. It follows Tuned Global’s earlier acquisition of Pacemaker, known for pioneering AI-powered mixing technology, and reflects a clear strategy: acquiring companies whose innovation and IP help clients and the industry build the future of music technology and streaming. Integrating Figaro.ai strengthens Tuned Global’s ability to power premium, highly relevant music experiences at scale.&lt;/p&gt;&lt;p&gt;Tuned Global remains an open ecosystem, with Figaro.ai integrated as another component in a broader platform. It will operate as an integrated but distinct component within Tuned Global’s broader platform, complementing existing partners and expanding client options.&lt;/p&gt;&lt;p&gt;Current Figaro.ai clients will continue to be supported, backed by Tuned Global’s global reach, infrastructure and long-term commitment.&lt;/p&gt;&lt;p&gt;The Figaro.ai team, including founders &lt;strong&gt;Lydia Gregory&lt;/strong&gt; and &lt;strong&gt;Kevin Webster&lt;/strong&gt;, will be integrated within Tuned Global, ensuring continuity for existing customers and adding deep AI expertise to accelerate the company’s roadmap.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Tuned Global CEO Con Raso&lt;/strong&gt; said he was thrilled to welcome the deeply skilled Figaro.ai team into the fold.&lt;/p&gt;&lt;p&gt;&amp;nbsp;“At Tuned Global, we see ourselves as the hub where innovation in music technology takes shape. We are building the largest open ecosystem of AI music intelligence, giving our clients maximum choice and real impact for the music industry,” he said. “With Figaro.ai joining the platform, we’re not only expanding that ecosystem with cutting-edge technology but also welcoming a highly skilled team whose expertise strengthens our ability to deliver music experiences that are powerful, flexible and future-ready.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Figaro.ai&lt;/strong&gt;&lt;strong&gt; CEO and Co-founder Lydia Gregory&lt;/strong&gt; said she was excited to join Tuned Global and amplify the impact of her company’s objectives.&lt;/p&gt;&lt;p&gt;&amp;nbsp;“Figaro.ai has always been about combining deep technical expertise with a passion for music discovery. I’m incredibly proud of the team that built this technology, and I’m thrilled that they are joining me as part of Tuned Global,” she said. “Being integrated into a platform of this scale means we can continue our mission with greater reach and impact, while ensuring continuity for the clients who already rely on us. Together, we’re ready to help the industry deliver music experiences that are more relevant, premium, and engaging than ever before.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;About Tuned Global&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Tuned Global is the leading data-driven cloud and software platform that empowers businesses to integrate commercial music into their apps or launch complete streaming experiences using advanced APIs, real-time analytics, licensing solutions, and customisable white-label apps.&lt;/p&gt;&lt;p&gt;Our turnkey solutions for music, audio, and video — coupled with a broad ecosystem of third-party music tech integrations — make us the most comprehensive platform for powering any digital music project. We streamline complexities in licensing, rights management, and content delivery, enabling rapid innovation and bringing new ideas to life.&lt;/p&gt;&lt;p&gt;Since 2011, we’ve supported 40+ companies in 70+ countries — across telecom, fitness, media, aviation, and more — to deliver innovative music experiences faster and more cost-effectively. For more information, visit www.tunedglobal.com.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;About Figaro&lt;/strong&gt;&lt;br /&gt;Figaro is the audio intelligence platform for music search, tagging and content detection – powering smarter discovery and content management across sync, DSPs, UGC, and distribution.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/tuned-global-strengthens-its-leadership-in-music-technology-with-the-acquisition-of-figaro-ai/</guid><pubDate>Wed, 08 Oct 2025 10:37:29 +0000</pubDate></item><item><title>[NEW] Introducing the Gemini 2.5 Computer Use model (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/introducing-the-gemini-2-5-computer-use-model/</link><description>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Gemini Computer Use" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU_2096x1182_RD6-V01.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
              







            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Earlier this year, we mentioned that we're bringing computer use capabilities to developers via the Gemini API. Today, we are releasing the Gemini 2.5 Computer Use model, our new specialized model built on Gemini 2.5 Pro’s visual understanding and reasoning capabilities that powers agents capable of interacting with user interfaces (UIs). It outperforms leading alternatives on multiple web and mobile control benchmarks, all with lower latency. Developers can access these capabilities via the Gemini API in Google AI Studio and Vertex AI.&lt;/p&gt;&lt;p&gt;While AI models can interface with software through structured APIs, many digital tasks still require direct interaction with graphical user interfaces, for example, filling and submitting forms. To complete these tasks, agents must navigate web pages and applications just as humans do: by clicking, typing and scrolling. The ability to natively fill out forms, manipulate interactive elements like dropdowns and filters, and operate behind logins is a crucial next step in building powerful, general-purpose agents.&lt;/p&gt;&lt;h2&gt;How it works&lt;/h2&gt;&lt;p&gt;The model’s core capabilities are exposed through the new `computer_use` tool in the Gemini API and should be operated within a loop. Inputs to the tool are the user request, screenshot of the environment, and a history of recent actions. The input can also specify whether to exclude functions from the full list of supported UI actions or specify additional custom functions to include.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
    &lt;div&gt;
      &lt;div class="rich-text"&gt;&lt;p&gt;Gemini 2.5 Computer Use Model flow&lt;/p&gt;&lt;/div&gt;
    &lt;/div&gt;
  
  
    &lt;div&gt;
      &lt;img alt="Diagram of AI agent loop: Initial task leads to a screenshot/context, which is sent to the Model, which returns a response to the computer environment to execute an action." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Diagram-RD4-V01.width-1000.format-webp.webp" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;The model then analyzes these inputs and generates a response, typically a function call representing one of the UI actions such as clicking or typing. This response may also contain a request for an end user confirmation, which is required for certain actions such as making a purchase. The client-side code then executes the received action.&lt;/p&gt;&lt;p&gt;After the action is executed, a new screenshot of the GUI and the current URL are sent back to the Computer Use model as a function response restarting the loop. This iterative process continues until the task is complete, an error occurs or the interaction is terminated by a safety response or user decision.&lt;/p&gt;&lt;p&gt;The Gemini 2.5 Computer Use model is primarily optimized for web browsers, but also demonstrates strong promise for mobile UI control tasks. It is not yet optimized for desktop OS-level control.&lt;/p&gt;&lt;p&gt;Check out a few demos below to see the model in action (shown here at 3X speed).&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;b&gt;Prompt:&lt;/b&gt; “From https://tinyurl.com/pet-care-signup, get all details for any pet with a California residency and add them as a guest in my spa CRM at https://pet-luxe-spa.web.app/. Then, set up a follow up visit appointment with the specialist Anima Lavar for October 10th anytime after 8am. The reason for the visit is the same as their requested treatment.”&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;b&gt;Prompt: “&lt;/b&gt;My art club brainstormed tasks ahead of our fair. The board is chaotic and I need your help organizing the tasks into some categories I created. Go to sticky-note-jam.web.app and ensure notes are clearly in the right sections. Drag them there if not.”&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How it performs&lt;/h2&gt;&lt;p&gt;The Gemini 2.5 Computer Use model demonstrates strong performance on multiple web and mobile control benchmarks. The table below includes results from self-reported numbers, evaluations run by Browserbase and evaluations we ran ourselves. Evaluation details are available in the Gemini 2.5 Computer Use evaluation info and in Browserbase’s blog post. Unless otherwise indicated, scores shown are for computer use tools exposed via API.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
    &lt;div&gt;
      &lt;div class="rich-text"&gt;&lt;p&gt;Gemini 2.5 Computer Use outperforms leading alternatives on multiple benchmarks&lt;/p&gt;&lt;/div&gt;
    &lt;/div&gt;
  
  
    &lt;div&gt;
      &lt;img alt="Benchmark performance table: Gemini 2.5 Computer Use leads in Online-Mind2Web, WebVoyager, and AndroidWorld benchmarks." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Benchmark_Chart-RD5_V01.width-1000.format-webp.webp" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;The model offers leading quality for browser control at the lowest latency, as measured by performance on the Browserbase harness for Online-Mind2Web.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
    &lt;div&gt;
      &lt;div class="rich-text"&gt;&lt;p&gt;Gemini 2.5 Computer Use delivers high accuracy while maintaining low latency&lt;/p&gt;&lt;/div&gt;
    &lt;/div&gt;
  
  
    &lt;div&gt;
      &lt;img alt="Latency vs. Quality scatterplot: Gemini 2.5 Computer Use is lowest in latency and highest in accuracy (70%+ accuracy, ∼225 sec latency)." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Scatterplot-RD7.width-1000.format-webp.webp" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How we approached safety&lt;/h2&gt;&lt;p&gt;We believe that the only way to build agents that will benefit everyone is to be responsible from the start. AI agents that control computers introduce unique risks, including intentional misuse by users, unexpected model behavior, and prompt injections and scams in the web environment. Thus, it is critical to implement safety guardrails with care.&lt;/p&gt;&lt;p&gt;We have trained safety features directly into the model to address these three key risks (described in the Gemini 2.5 Computer Use System Card).&lt;/p&gt;&lt;p&gt;Further, we also provide developers with safety controls, which empower developers to prevent the model from auto-completing potentially high-risk or harmful actions. Examples of these actions include harming a system's integrity, compromising security, bypassing CAPTCHAs, or controlling medical devices. The controls:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Per-step safety service:&lt;/b&gt; An out-of-model, inference-time safety service that assesses each action the model proposes before it’s executed.&lt;/li&gt;&lt;li&gt;&lt;b&gt;System instructions:&lt;/b&gt; Developers can further specify that the agent either refuses or asks for user confirmation before it takes specific kinds of high-stakes actions. (Example in documentation).&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Additional recommendations for developers on safety measures and best practices can be found in our documentation. While these safeguards are designed to reduce risk, we urge all developers to thoroughly test their systems before launch.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How early testers have used it&lt;/h2&gt;&lt;p&gt;Google teams have already deployed the model to production for use cases including UI testing, which can make software development signficantly faster. Versions of this model have also been powering Project Mariner, the Firebase Testing Agent, and some agentic capabilities in AI Mode in Search.&lt;/p&gt;&lt;p&gt;Users from our early access program have also been testing the model to power personal assistants, workflow automation, and UI testing, and have seen strong results. In their own words:&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    








  

  
    








  

  
    








  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How to get started&lt;/h2&gt;&lt;p&gt;Starting today, the model is available in public preview, accessible via the Gemini API on Google AI Studio and Vertex AI.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Try it now:&lt;/b&gt; In a demo environment hosted by Browserbase.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Start building&lt;/b&gt;: Dive into our reference and documentation (see Vertex AI docs for enterprise use) to learn how to build your own agent loop locally with Playwright or in a cloud VM with Browserbase.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Join the community:&lt;/b&gt; We’re excited to see what you build. Share feedback and help guide our roadmap in our Developer Forum.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Google DeepMind


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Gemini Models


  


      &lt;/li&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</description><content:encoded>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="Gemini Computer Use" class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU_2096x1182_RD6-V01.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
              







            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Earlier this year, we mentioned that we're bringing computer use capabilities to developers via the Gemini API. Today, we are releasing the Gemini 2.5 Computer Use model, our new specialized model built on Gemini 2.5 Pro’s visual understanding and reasoning capabilities that powers agents capable of interacting with user interfaces (UIs). It outperforms leading alternatives on multiple web and mobile control benchmarks, all with lower latency. Developers can access these capabilities via the Gemini API in Google AI Studio and Vertex AI.&lt;/p&gt;&lt;p&gt;While AI models can interface with software through structured APIs, many digital tasks still require direct interaction with graphical user interfaces, for example, filling and submitting forms. To complete these tasks, agents must navigate web pages and applications just as humans do: by clicking, typing and scrolling. The ability to natively fill out forms, manipulate interactive elements like dropdowns and filters, and operate behind logins is a crucial next step in building powerful, general-purpose agents.&lt;/p&gt;&lt;h2&gt;How it works&lt;/h2&gt;&lt;p&gt;The model’s core capabilities are exposed through the new `computer_use` tool in the Gemini API and should be operated within a loop. Inputs to the tool are the user request, screenshot of the environment, and a history of recent actions. The input can also specify whether to exclude functions from the full list of supported UI actions or specify additional custom functions to include.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
    &lt;div&gt;
      &lt;div class="rich-text"&gt;&lt;p&gt;Gemini 2.5 Computer Use Model flow&lt;/p&gt;&lt;/div&gt;
    &lt;/div&gt;
  
  
    &lt;div&gt;
      &lt;img alt="Diagram of AI agent loop: Initial task leads to a screenshot/context, which is sent to the Model, which returns a response to the computer environment to execute an action." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Diagram-RD4-V01.width-1000.format-webp.webp" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;The model then analyzes these inputs and generates a response, typically a function call representing one of the UI actions such as clicking or typing. This response may also contain a request for an end user confirmation, which is required for certain actions such as making a purchase. The client-side code then executes the received action.&lt;/p&gt;&lt;p&gt;After the action is executed, a new screenshot of the GUI and the current URL are sent back to the Computer Use model as a function response restarting the loop. This iterative process continues until the task is complete, an error occurs or the interaction is terminated by a safety response or user decision.&lt;/p&gt;&lt;p&gt;The Gemini 2.5 Computer Use model is primarily optimized for web browsers, but also demonstrates strong promise for mobile UI control tasks. It is not yet optimized for desktop OS-level control.&lt;/p&gt;&lt;p&gt;Check out a few demos below to see the model in action (shown here at 3X speed).&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;b&gt;Prompt:&lt;/b&gt; “From https://tinyurl.com/pet-care-signup, get all details for any pet with a California residency and add them as a guest in my spa CRM at https://pet-luxe-spa.web.app/. Then, set up a follow up visit appointment with the specialist Anima Lavar for October 10th anytime after 8am. The reason for the visit is the same as their requested treatment.”&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;&lt;b&gt;Prompt: “&lt;/b&gt;My art club brainstormed tasks ahead of our fair. The board is chaotic and I need your help organizing the tasks into some categories I created. Go to sticky-note-jam.web.app and ensure notes are clearly in the right sections. Drag them there if not.”&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How it performs&lt;/h2&gt;&lt;p&gt;The Gemini 2.5 Computer Use model demonstrates strong performance on multiple web and mobile control benchmarks. The table below includes results from self-reported numbers, evaluations run by Browserbase and evaluations we ran ourselves. Evaluation details are available in the Gemini 2.5 Computer Use evaluation info and in Browserbase’s blog post. Unless otherwise indicated, scores shown are for computer use tools exposed via API.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
    &lt;div&gt;
      &lt;div class="rich-text"&gt;&lt;p&gt;Gemini 2.5 Computer Use outperforms leading alternatives on multiple benchmarks&lt;/p&gt;&lt;/div&gt;
    &lt;/div&gt;
  
  
    &lt;div&gt;
      &lt;img alt="Benchmark performance table: Gemini 2.5 Computer Use leads in Online-Mind2Web, WebVoyager, and AndroidWorld benchmarks." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Benchmark_Chart-RD5_V01.width-1000.format-webp.webp" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;The model offers leading quality for browser control at the lowest latency, as measured by performance on the Browserbase harness for Online-Mind2Web.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    















  
    &lt;div&gt;
      &lt;div class="rich-text"&gt;&lt;p&gt;Gemini 2.5 Computer Use delivers high accuracy while maintaining low latency&lt;/p&gt;&lt;/div&gt;
    &lt;/div&gt;
  
  
    &lt;div&gt;
      &lt;img alt="Latency vs. Quality scatterplot: Gemini 2.5 Computer Use is lowest in latency and highest in accuracy (70%+ accuracy, ∼225 sec latency)." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Scatterplot-RD7.width-1000.format-webp.webp" /&gt;
    &lt;/div&gt;
  



  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How we approached safety&lt;/h2&gt;&lt;p&gt;We believe that the only way to build agents that will benefit everyone is to be responsible from the start. AI agents that control computers introduce unique risks, including intentional misuse by users, unexpected model behavior, and prompt injections and scams in the web environment. Thus, it is critical to implement safety guardrails with care.&lt;/p&gt;&lt;p&gt;We have trained safety features directly into the model to address these three key risks (described in the Gemini 2.5 Computer Use System Card).&lt;/p&gt;&lt;p&gt;Further, we also provide developers with safety controls, which empower developers to prevent the model from auto-completing potentially high-risk or harmful actions. Examples of these actions include harming a system's integrity, compromising security, bypassing CAPTCHAs, or controlling medical devices. The controls:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Per-step safety service:&lt;/b&gt; An out-of-model, inference-time safety service that assesses each action the model proposes before it’s executed.&lt;/li&gt;&lt;li&gt;&lt;b&gt;System instructions:&lt;/b&gt; Developers can further specify that the agent either refuses or asks for user confirmation before it takes specific kinds of high-stakes actions. (Example in documentation).&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Additional recommendations for developers on safety measures and best practices can be found in our documentation. While these safeguards are designed to reduce risk, we urge all developers to thoroughly test their systems before launch.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How early testers have used it&lt;/h2&gt;&lt;p&gt;Google teams have already deployed the model to production for use cases including UI testing, which can make software development signficantly faster. Versions of this model have also been powering Project Mariner, the Firebase Testing Agent, and some agentic capabilities in AI Mode in Search.&lt;/p&gt;&lt;p&gt;Users from our early access program have also been testing the model to power personal assistants, workflow automation, and UI testing, and have seen strong results. In their own words:&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    








  

  
    








  

  
    








  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How to get started&lt;/h2&gt;&lt;p&gt;Starting today, the model is available in public preview, accessible via the Gemini API on Google AI Studio and Vertex AI.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Try it now:&lt;/b&gt; In a demo environment hosted by Browserbase.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Start building&lt;/b&gt;: Dive into our reference and documentation (see Vertex AI docs for enterprise use) to learn how to build your own agent loop locally with Playwright or in a cloud VM with Browserbase.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Join the community:&lt;/b&gt; We’re excited to see what you build. Share feedback and help guide our roadmap in our Developer Forum.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Google DeepMind


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Gemini Models


  


      &lt;/li&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/introducing-the-gemini-2-5-computer-use-model/</guid><pubDate>Wed, 08 Oct 2025 10:55:26 +0000</pubDate></item><item><title>[NEW] Samsung’s tiny AI model beats giant reasoning LLMs (AI News)</title><link>https://www.artificialintelligence-news.com/news/samsung-tiny-ai-model-beats-giant-reasoning-llms/</link><description>&lt;p&gt;A new paper from a Samsung AI researcher explains how a small network can beat massive Large Language Models (LLMs) in complex reasoning.&lt;/p&gt;&lt;p&gt;In the race for AI supremacy, the industry mantra has often been “bigger is better.” Tech giants have poured billions into creating ever-larger models, but according to Alexia Jolicoeur-Martineau of Samsung SAIL Montréal, a radically different and more efficient path forward is possible with the Tiny Recursive Model (TRM).&lt;/p&gt;&lt;p&gt;Using a model with just 7 million parameters, less than 0.01% of the size of leading LLMs, TRM achieves new state-of-the-art results on notoriously difficult benchmarks like the ARC-AGI intelligence test. Samsung’s work challenges the prevailing assumption that sheer scale is the only way to advance the capabilities of AI models, offering a more sustainable and parameter-efficient alternative.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-overcoming-the-limits-of-scale"&gt;Overcoming the limits of scale&lt;/h3&gt;&lt;p&gt;While LLMs have shown incredible prowess in generating human-like text, their ability to perform complex, multi-step reasoning can be brittle. Because they generate answers token-by-token, a single mistake early in the process can derail the entire solution, leading to an invalid final answer.&lt;/p&gt;&lt;p&gt;Techniques like Chain-of-Thought, where a model “thinks out loud” to break down a problem, have been developed to mitigate this. However, these methods are computationally expensive, often require vast amounts of high-quality reasoning data that may not be available, and can still produce flawed logic. Even with these augmentations, LLMs struggle with certain puzzles where perfect logical execution is necessary.&lt;/p&gt;&lt;p&gt;Samsung’s work builds upon a recent AI model known as the Hierarchical Reasoning Model (HRM). HRM introduced a novel method using two small neural networks that recursively work on a problem at different frequencies to refine an answer. It showed great promise but was complicated, relying on uncertain biological arguments and complex fixed-point theorems that were not guaranteed to apply.&lt;/p&gt;&lt;p&gt;Instead of HRM’s two networks, TRM uses a single, tiny network that recursively improves both its internal “reasoning” and its proposed “answer”.&lt;/p&gt;&lt;p&gt;The model is given the question, an initial guess at the answer, and a latent reasoning feature. It first cycles through several steps to refine its latent reasoning based on all three inputs. Then, using this improved reasoning, it updates its prediction for the final answer. This entire process can be repeated up to 16 times, allowing the model to progressively correct its own mistakes in a highly parameter-efficient manner.&lt;/p&gt;&lt;p&gt;Counterintuitively, the research discovered that a tiny network with only two layers achieved far better generalisation than a four-layer version. This reduction in size appears to prevent the model from overfitting; a common problem when training on smaller, specialised datasets.&lt;/p&gt;&lt;p&gt;TRM also dispenses with the complex mathematical justifications used by its predecessor. The original HRM model required the assumption that its functions converged to a fixed point to justify its training method. TRM bypasses this entirely by simply back-propagating through its full recursion process. This change alone provided a massive boost in performance, improving accuracy on the Sudoku-Extreme benchmark from 56.5% to 87.4% in an ablation study.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-samsung-s-model-smashes-ai-benchmarks-with-fewer-resources"&gt;Samsung’s model smashes AI benchmarks with fewer resources&lt;/h3&gt;&lt;p&gt;The results speak for themselves. On the Sudoku-Extreme dataset, which uses only 1,000 training examples, TRM achieves an 87.4% test accuracy, a huge leap from HRM’s 55%. On Maze-Hard, a task involving finding long paths through 30×30 mazes, TRM scores 85.3% compared to HRM’s 74.5%.&lt;/p&gt;&lt;p&gt;Most notably, TRM makes huge strides on the Abstraction and Reasoning Corpus (ARC-AGI), a benchmark designed to measure true fluid intelligence in AI. With just 7M parameters, TRM achieves 44.6% accuracy on ARC-AGI-1 and 7.8% on ARC-AGI-2. This outperforms HRM, which used a 27M parameter model, and even surpasses many of the world’s largest LLMs. For comparison, Gemini 2.5 Pro scores only 4.9% on ARC-AGI-2.&lt;/p&gt;&lt;p&gt;The training process for TRM has also been made more efficient. An adaptive mechanism called ACT – which decides when the model has improved an answer enough and can move to a new data sample – was simplified to remove the need for a second, costly forward pass through the network during each training step. This change was made with no major difference in final generalisation.&lt;/p&gt;&lt;p&gt;This research from Samsung presents a compelling argument against the current trajectory of ever-expanding AI models. It shows that by designing architectures that can iteratively reason and self-correct, it is possible to solve extremely difficult problems with a tiny fraction of the computational resources.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Google’s new AI agent rewrites code to automate vulnerability fixes&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-109805" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A new paper from a Samsung AI researcher explains how a small network can beat massive Large Language Models (LLMs) in complex reasoning.&lt;/p&gt;&lt;p&gt;In the race for AI supremacy, the industry mantra has often been “bigger is better.” Tech giants have poured billions into creating ever-larger models, but according to Alexia Jolicoeur-Martineau of Samsung SAIL Montréal, a radically different and more efficient path forward is possible with the Tiny Recursive Model (TRM).&lt;/p&gt;&lt;p&gt;Using a model with just 7 million parameters, less than 0.01% of the size of leading LLMs, TRM achieves new state-of-the-art results on notoriously difficult benchmarks like the ARC-AGI intelligence test. Samsung’s work challenges the prevailing assumption that sheer scale is the only way to advance the capabilities of AI models, offering a more sustainable and parameter-efficient alternative.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-overcoming-the-limits-of-scale"&gt;Overcoming the limits of scale&lt;/h3&gt;&lt;p&gt;While LLMs have shown incredible prowess in generating human-like text, their ability to perform complex, multi-step reasoning can be brittle. Because they generate answers token-by-token, a single mistake early in the process can derail the entire solution, leading to an invalid final answer.&lt;/p&gt;&lt;p&gt;Techniques like Chain-of-Thought, where a model “thinks out loud” to break down a problem, have been developed to mitigate this. However, these methods are computationally expensive, often require vast amounts of high-quality reasoning data that may not be available, and can still produce flawed logic. Even with these augmentations, LLMs struggle with certain puzzles where perfect logical execution is necessary.&lt;/p&gt;&lt;p&gt;Samsung’s work builds upon a recent AI model known as the Hierarchical Reasoning Model (HRM). HRM introduced a novel method using two small neural networks that recursively work on a problem at different frequencies to refine an answer. It showed great promise but was complicated, relying on uncertain biological arguments and complex fixed-point theorems that were not guaranteed to apply.&lt;/p&gt;&lt;p&gt;Instead of HRM’s two networks, TRM uses a single, tiny network that recursively improves both its internal “reasoning” and its proposed “answer”.&lt;/p&gt;&lt;p&gt;The model is given the question, an initial guess at the answer, and a latent reasoning feature. It first cycles through several steps to refine its latent reasoning based on all three inputs. Then, using this improved reasoning, it updates its prediction for the final answer. This entire process can be repeated up to 16 times, allowing the model to progressively correct its own mistakes in a highly parameter-efficient manner.&lt;/p&gt;&lt;p&gt;Counterintuitively, the research discovered that a tiny network with only two layers achieved far better generalisation than a four-layer version. This reduction in size appears to prevent the model from overfitting; a common problem when training on smaller, specialised datasets.&lt;/p&gt;&lt;p&gt;TRM also dispenses with the complex mathematical justifications used by its predecessor. The original HRM model required the assumption that its functions converged to a fixed point to justify its training method. TRM bypasses this entirely by simply back-propagating through its full recursion process. This change alone provided a massive boost in performance, improving accuracy on the Sudoku-Extreme benchmark from 56.5% to 87.4% in an ablation study.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-samsung-s-model-smashes-ai-benchmarks-with-fewer-resources"&gt;Samsung’s model smashes AI benchmarks with fewer resources&lt;/h3&gt;&lt;p&gt;The results speak for themselves. On the Sudoku-Extreme dataset, which uses only 1,000 training examples, TRM achieves an 87.4% test accuracy, a huge leap from HRM’s 55%. On Maze-Hard, a task involving finding long paths through 30×30 mazes, TRM scores 85.3% compared to HRM’s 74.5%.&lt;/p&gt;&lt;p&gt;Most notably, TRM makes huge strides on the Abstraction and Reasoning Corpus (ARC-AGI), a benchmark designed to measure true fluid intelligence in AI. With just 7M parameters, TRM achieves 44.6% accuracy on ARC-AGI-1 and 7.8% on ARC-AGI-2. This outperforms HRM, which used a 27M parameter model, and even surpasses many of the world’s largest LLMs. For comparison, Gemini 2.5 Pro scores only 4.9% on ARC-AGI-2.&lt;/p&gt;&lt;p&gt;The training process for TRM has also been made more efficient. An adaptive mechanism called ACT – which decides when the model has improved an answer enough and can move to a new data sample – was simplified to remove the need for a second, costly forward pass through the network during each training step. This change was made with no major difference in final generalisation.&lt;/p&gt;&lt;p&gt;This research from Samsung presents a compelling argument against the current trajectory of ever-expanding AI models. It shows that by designing architectures that can iteratively reason and self-correct, it is possible to solve extremely difficult problems with a tiny fraction of the computational resources.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Google’s new AI agent rewrites code to automate vulnerability fixes&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-109805" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-1.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/samsung-tiny-ai-model-beats-giant-reasoning-llms/</guid><pubDate>Wed, 08 Oct 2025 11:55:19 +0000</pubDate></item><item><title>[NEW] AI21’s Jamba Reasoning 3B Redefines What “Small” Means in LLMs — 250K Context on a Laptop (AI | VentureBeat)</title><link>https://venturebeat.com/ai/ai21s-jamba-reasoning-3b-redefines-what-small-means-in-llms-250k-context-on</link><description>[unable to retrieve full-text content]&lt;p&gt;The latest addition to the small model wave for enterprises comes from &lt;a href="https://www.ai21.com/"&gt;&lt;u&gt;AI21 Labs&lt;/u&gt;&lt;/a&gt;, which is betting that bringing models to devices will free up traffic in data centers. &lt;/p&gt;&lt;p&gt;AI21’s Jamba Reasoning 3B, a “tiny” open-source model that can run extended reasoning, code generation and respond based on ground truth. Jamba Reasoning 3B handles more than 250,000 tokens and can run inference on edge devices. &lt;/p&gt;&lt;p&gt;The company said Jamba Reasoning 3B works on devices such as laptops and mobile phones. &lt;/p&gt;&lt;p&gt;Ori Goshen, co-CEO of AI21, told VentureBeat that the company sees more enterprise use cases for small models, mainly because moving most inference to devices frees up data centers.  &lt;/p&gt;&lt;p&gt;“What we&amp;#x27;re seeing right now in the industry is an economics issue where there are very expensive data center build-outs, and the revenue that is generated from the data centers versus the depreciation rate of all their chips shows the math doesn&amp;#x27;t add up,” Goshen said. &lt;/p&gt;&lt;p&gt;He added that in the future “the industry by and large would be hybrid in the sense that some of the computation will be on devices locally and other inference will move to GPUs.”&lt;/p&gt;&lt;h2&gt;Tested on a MacBook&lt;/h2&gt;&lt;p&gt;
Jamba Reasoning 3B combines the Mamba architecture and Transformers to allow it to run a 250K token window on devices. AI21 said it can do 2-4x faster inference speeds. Goshen said the Mamba architecture significantly contributed to the model’s speed. &lt;/p&gt;&lt;p&gt;Jamba Reasoning 3B’s hybrid architecture also allows it to reduce memory requirements, thereby reducing its computing needs. &lt;/p&gt;&lt;p&gt;AI21 tested the model on a standard MacBook Pro and found that it can process 35 tokens per second. &lt;/p&gt;&lt;p&gt;Goshen said the model works best for tasks involving function calling, policy-grounded generation and tool routing. He said that simple requests, such as asking for information about a forthcoming meeting and asking the model to create an agenda for it, could be done on devices. The more complex reasoning tasks can be saved for GPU clusters. &lt;/p&gt;&lt;h2&gt;Small models in enterprise&lt;/h2&gt;&lt;p&gt;Enterprises have been interested in using a mix of small models, some of which are specifically designed for their industry and some that are condensed versions of LLMs. &lt;/p&gt;&lt;p&gt;In September, &lt;a href="https://business.facebook.com/"&gt;&lt;u&gt;Meta&lt;/u&gt;&lt;/a&gt; released &lt;a href="https://venturebeat.com/ai/metas-new-small-reasoning-model-shows-industry-shift-toward-tiny-ai-for"&gt;&lt;u&gt;MobileLLM-R1, a family of reasoning models&lt;/u&gt;&lt;/a&gt; ranging from 140M to 950M parameters. These models are designed for math, coding and scientific reasoning rather than chat applications. MobileLLM-R1 can run on compute-constrained devices. &lt;/p&gt;&lt;p&gt;&lt;a href="https://www.google.com/"&gt;&lt;u&gt;Google&lt;/u&gt;&lt;/a&gt;’s &lt;a href="https://venturebeat.com/ai/google-unveils-open-source-gemma-3-model-with-128k-context-window"&gt;&lt;u&gt;Gemma&lt;/u&gt;&lt;/a&gt; was one of the first small models to come to the market, designed to run on portable devices like laptops and mobile phones. Gemma has since &lt;a href="https://venturebeat.com/ai/google-unveils-ultra-small-and-efficient-open-source-ai-model-gemma-3-270m-that-can-run-on-smartphones"&gt;&lt;u&gt;been expanded&lt;/u&gt;&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Companies like &lt;a href="https://www.myfico.com/"&gt;&lt;u&gt;FICO&lt;/u&gt;&lt;/a&gt; have also begun building their own models. &lt;a href="https://venturebeat.com/ai/ficos-answer-to-ai-risk-a-foundation-model-that-scores-every-output-for"&gt;&lt;u&gt;FICO launched&lt;/u&gt;&lt;/a&gt; its FICO Focused Language and FICO Focused Sequence small models that will only answer finance-specific questions. &lt;/p&gt;&lt;p&gt;Goshen said the big difference their model offers is that it’s even smaller than most models and yet it can run reasoning tasks without sacrificing speed. &lt;/p&gt;&lt;h2&gt;Benchmark testing &lt;/h2&gt;&lt;p&gt;In benchmark testing, Jamba Reasoning 3B demonstrated strong performance compared to other small models, including &lt;a href="https://chat.qwen.ai/"&gt;&lt;u&gt;Qwen&lt;/u&gt;&lt;/a&gt; 4B, &lt;a href="https://business.facebook.com/"&gt;&lt;u&gt;Meta&lt;/u&gt;&lt;/a&gt;’s Llama 3.2B-3B, and Phi-4-Mini from &lt;a href="https://www.microsoft.com/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;It outperformed all models on the IFBench test and Humanity’s Last Exam, although it came in second to Qwen 4 on MMLU-Pro. &lt;/p&gt;&lt;p&gt;Goshen said another advantage of small models like Jamba Reasoning 3B is that they are highly steerable and provide better privacy options to enterprises because the inference is not sent to a server elsewhere. &lt;/p&gt;&lt;p&gt;“I do believe there’s a world where you can optimize for the needs and the experience of the customer, and the models that will be kept on devices are a large part of it,” he said. &lt;/p&gt;&lt;p&gt;




&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;The latest addition to the small model wave for enterprises comes from &lt;a href="https://www.ai21.com/"&gt;&lt;u&gt;AI21 Labs&lt;/u&gt;&lt;/a&gt;, which is betting that bringing models to devices will free up traffic in data centers. &lt;/p&gt;&lt;p&gt;AI21’s Jamba Reasoning 3B, a “tiny” open-source model that can run extended reasoning, code generation and respond based on ground truth. Jamba Reasoning 3B handles more than 250,000 tokens and can run inference on edge devices. &lt;/p&gt;&lt;p&gt;The company said Jamba Reasoning 3B works on devices such as laptops and mobile phones. &lt;/p&gt;&lt;p&gt;Ori Goshen, co-CEO of AI21, told VentureBeat that the company sees more enterprise use cases for small models, mainly because moving most inference to devices frees up data centers.  &lt;/p&gt;&lt;p&gt;“What we&amp;#x27;re seeing right now in the industry is an economics issue where there are very expensive data center build-outs, and the revenue that is generated from the data centers versus the depreciation rate of all their chips shows the math doesn&amp;#x27;t add up,” Goshen said. &lt;/p&gt;&lt;p&gt;He added that in the future “the industry by and large would be hybrid in the sense that some of the computation will be on devices locally and other inference will move to GPUs.”&lt;/p&gt;&lt;h2&gt;Tested on a MacBook&lt;/h2&gt;&lt;p&gt;
Jamba Reasoning 3B combines the Mamba architecture and Transformers to allow it to run a 250K token window on devices. AI21 said it can do 2-4x faster inference speeds. Goshen said the Mamba architecture significantly contributed to the model’s speed. &lt;/p&gt;&lt;p&gt;Jamba Reasoning 3B’s hybrid architecture also allows it to reduce memory requirements, thereby reducing its computing needs. &lt;/p&gt;&lt;p&gt;AI21 tested the model on a standard MacBook Pro and found that it can process 35 tokens per second. &lt;/p&gt;&lt;p&gt;Goshen said the model works best for tasks involving function calling, policy-grounded generation and tool routing. He said that simple requests, such as asking for information about a forthcoming meeting and asking the model to create an agenda for it, could be done on devices. The more complex reasoning tasks can be saved for GPU clusters. &lt;/p&gt;&lt;h2&gt;Small models in enterprise&lt;/h2&gt;&lt;p&gt;Enterprises have been interested in using a mix of small models, some of which are specifically designed for their industry and some that are condensed versions of LLMs. &lt;/p&gt;&lt;p&gt;In September, &lt;a href="https://business.facebook.com/"&gt;&lt;u&gt;Meta&lt;/u&gt;&lt;/a&gt; released &lt;a href="https://venturebeat.com/ai/metas-new-small-reasoning-model-shows-industry-shift-toward-tiny-ai-for"&gt;&lt;u&gt;MobileLLM-R1, a family of reasoning models&lt;/u&gt;&lt;/a&gt; ranging from 140M to 950M parameters. These models are designed for math, coding and scientific reasoning rather than chat applications. MobileLLM-R1 can run on compute-constrained devices. &lt;/p&gt;&lt;p&gt;&lt;a href="https://www.google.com/"&gt;&lt;u&gt;Google&lt;/u&gt;&lt;/a&gt;’s &lt;a href="https://venturebeat.com/ai/google-unveils-open-source-gemma-3-model-with-128k-context-window"&gt;&lt;u&gt;Gemma&lt;/u&gt;&lt;/a&gt; was one of the first small models to come to the market, designed to run on portable devices like laptops and mobile phones. Gemma has since &lt;a href="https://venturebeat.com/ai/google-unveils-ultra-small-and-efficient-open-source-ai-model-gemma-3-270m-that-can-run-on-smartphones"&gt;&lt;u&gt;been expanded&lt;/u&gt;&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Companies like &lt;a href="https://www.myfico.com/"&gt;&lt;u&gt;FICO&lt;/u&gt;&lt;/a&gt; have also begun building their own models. &lt;a href="https://venturebeat.com/ai/ficos-answer-to-ai-risk-a-foundation-model-that-scores-every-output-for"&gt;&lt;u&gt;FICO launched&lt;/u&gt;&lt;/a&gt; its FICO Focused Language and FICO Focused Sequence small models that will only answer finance-specific questions. &lt;/p&gt;&lt;p&gt;Goshen said the big difference their model offers is that it’s even smaller than most models and yet it can run reasoning tasks without sacrificing speed. &lt;/p&gt;&lt;h2&gt;Benchmark testing &lt;/h2&gt;&lt;p&gt;In benchmark testing, Jamba Reasoning 3B demonstrated strong performance compared to other small models, including &lt;a href="https://chat.qwen.ai/"&gt;&lt;u&gt;Qwen&lt;/u&gt;&lt;/a&gt; 4B, &lt;a href="https://business.facebook.com/"&gt;&lt;u&gt;Meta&lt;/u&gt;&lt;/a&gt;’s Llama 3.2B-3B, and Phi-4-Mini from &lt;a href="https://www.microsoft.com/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;It outperformed all models on the IFBench test and Humanity’s Last Exam, although it came in second to Qwen 4 on MMLU-Pro. &lt;/p&gt;&lt;p&gt;Goshen said another advantage of small models like Jamba Reasoning 3B is that they are highly steerable and provide better privacy options to enterprises because the inference is not sent to a server elsewhere. &lt;/p&gt;&lt;p&gt;“I do believe there’s a world where you can optimize for the needs and the experience of the customer, and the models that will be kept on devices are a large part of it,” he said. &lt;/p&gt;&lt;p&gt;




&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/ai21s-jamba-reasoning-3b-redefines-what-small-means-in-llms-250k-context-on</guid><pubDate>Wed, 08 Oct 2025 12:00:00 +0000</pubDate></item><item><title>[NEW] The Download: carbon removal factories’ funding cuts, and AI toys (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/08/1125301/the-download-carbon-removal-factories-funding-cuts-and-ai-toys/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The Trump administration may cut funding for two major direct-air capture plants&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The US Department of Energy appears poised to terminate funding for a pair of large carbon-sucking factories that were originally set to receive more than $1 billion in government grants, according to a department-issued list of projects obtained by &lt;em&gt;MIT Technology Review&lt;/em&gt; and circulating among federal agencies.&lt;/p&gt;&lt;p&gt;One of the projects is the South Texas Direct Air Capture Hub, a facility that Occidental Petroleum’s 1PointFive subsidiary planned to develop in Kleberg County, Texas. The other is Project Cypress in Louisiana, a collaboration between Battelle, Climeworks, and Heirloom. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;AI toys are all the rage in China—and now they’re appearing on shelves in the US too&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Kids have always played with and talked to stuffed animals. But now their toys can talk back, thanks to a wave of companies that are fitting children’s playthings with chatbots and voice assistants.&lt;br /&gt;&amp;nbsp;&lt;br /&gt;It’s a trend that has particularly taken off in China: A recent report by the Shenzhen Toy Industry Association and JD.com predicts that the sector will surpass ¥100 billion ($14 billion) by 2030, growing faster than almost any other branch of consumer AI. But Chinese AI toy companies have their sights set beyond the nation’s borders. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;2025 climate tech companies to watch: Pairwise and its climate-adapted crops&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Climate change will make it increasingly difficult to grow crops across many parts of the world. Startup Pairwise is using CRISPR gene editing to develop plants that can better withstand adverse conditions.&lt;/p&gt;  &lt;p&gt;The company uses cutting-edge gene editing to produce crops that can withstand increasingly harsh climate conditions, helping to feed a growing population even as the world warms. Last year, it delivered its first food to the US market: a less-bitter–tasting mustard green. It’s now working to produce crops with climate-resilient traits, through partnerships with two of the world’s largest plant biotech companies. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Pairwise is one of our 10 climate tech companies to watch—our annual list of some of the most promising climate tech firms on the planet. &lt;/strong&gt;&lt;strong&gt;Check out the rest of the list here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; 

   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: How to measure the returns on R&amp;amp;D spending&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Given the draconian cuts to US federal funding for science, it’s worth asking some hard-nosed money questions: How much should we be spending on R&amp;amp;D? How much value do we get out of such investments, anyway?&lt;/p&gt;  &lt;p&gt;To answer that, in several recent papers, economists have approached this issue in clever new ways.&amp;nbsp; And, though they ask slightly different questions, their conclusions share a bottom line: R&amp;amp;D is, in fact, one of the better long-term investments that the government can make.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;1 How OpenAI and Nvidia are fueling the AI bubble&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Experts fear their circular deals could be artificially inflating the market. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;OpenAI will pay for AMD’s chips using, err, AMD’s own stock. &lt;/em&gt;(TechCrunch)&lt;br /&gt;+ &lt;em&gt;The Bank of England is concerned about AI inflating tech stocks. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;What comes next, that’s the big question. &lt;/em&gt;(NBC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Around 15% of the world’s working population is using AI&lt;/strong&gt;&lt;br /&gt;And countries in Europe are among the most enthusiastic adopters. (FT $)&lt;br /&gt;+ &lt;em&gt;The EU is keen to get even more of its citizens using it, too. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;Meanwhile, America’s public opinion towards AI is souring. &lt;/em&gt;(WP $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;3 Three quantum mechanics scientists have won the Nobel Prize for Physics&lt;/strong&gt;&lt;br /&gt;Two of whom were instrumental in building Google’s working quantum machines. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Their work shone a light on behaviors of the subatomic realm. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;Quantum particles behave in notoriously strange ways. &lt;/em&gt;(New Scientist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 The CDC has finally signed off on covid vaccine recommendations&lt;/strong&gt;&lt;br /&gt;Despite the delay, access looks largely similar to last years’. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;The Supreme Court isn’t sold on medical expertise these days. &lt;/em&gt;(Vox)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;5 What makes TikTok so ‘sticky’&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Even its hardcore users can be persuaded to keep scrolling for hours. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 ICE bought fake cell towers to spy on nearby phones&lt;br /&gt;&lt;/strong&gt;It’s used cell-site simulators in the past to track down alleged criminals. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;Meet the volunteers tracking ICE officers in LA. &lt;/em&gt;(New Yorker $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Watermark removers for Sora 2 videos are already readily available&lt;br /&gt;&lt;/strong&gt;No permission? No problem. (404 Media)&lt;br /&gt;+ &lt;em&gt;What about copyright for AI-generated art? &lt;/em&gt;(The Information $)&lt;br /&gt;+ &lt;em&gt;And what comes next for AI copyright lawsuits? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 How diamonds can help to cool down chips&lt;br /&gt;&lt;/strong&gt;They’re remarkably good at transferring heat. (NYT $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;9 Amazon Pharmacy is launching electronic prescription kiosks&lt;/strong&gt;&lt;br /&gt;For drugs including antibiotics, asthma inhalers and treatments for high blood pressure. (Reuters)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Should you limit your smartphone use to two hours a day?&lt;/strong&gt;&lt;br /&gt;Japan thinks so. (The Guardian)&lt;br /&gt;+ &lt;em&gt;How to log off. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“OpenAI is building the future of AI on infrastructure it doesn't own, power it doesn't control, and capital it doesn't have.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Andrey Sidorenko, head of research at data firm Mostly AI, critiques what he calls the consolidation of the AI ecosystem in a post on LinkedIn.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1125309" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image_d541b2.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How AI can help make cities work better&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In recent decades, cities have become increasingly adept at amassing all sorts of data. But that data can have limited impact when government officials are unable to communicate, let alone analyze or put to use, all the information they have access to.&lt;/p&gt;&lt;p&gt;This dynamic has always bothered Sarah Williams, a professor of urban planning and technology at MIT. Shortly after joining MIT in 2012, Williams created the Civic Data Design Lab to bridge that divide. Over the years, she and her colleagues have made urban planning data more vivid and accessible through human stories and striking graphics. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Ben Schneider&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Life lessons from the one and only Ozzy Osbourne—what’s not to like?&lt;br /&gt;+ Did you know that most countries have their own camouflage? Check the patterns out here.&lt;br /&gt;+ These hamsters getting an MRI scan is the cutest thing you’ll see today.&lt;br /&gt;+ Pumpkin chili sounds like a fantastic way to warm up.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The Trump administration may cut funding for two major direct-air capture plants&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The US Department of Energy appears poised to terminate funding for a pair of large carbon-sucking factories that were originally set to receive more than $1 billion in government grants, according to a department-issued list of projects obtained by &lt;em&gt;MIT Technology Review&lt;/em&gt; and circulating among federal agencies.&lt;/p&gt;&lt;p&gt;One of the projects is the South Texas Direct Air Capture Hub, a facility that Occidental Petroleum’s 1PointFive subsidiary planned to develop in Kleberg County, Texas. The other is Project Cypress in Louisiana, a collaboration between Battelle, Climeworks, and Heirloom. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;AI toys are all the rage in China—and now they’re appearing on shelves in the US too&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Kids have always played with and talked to stuffed animals. But now their toys can talk back, thanks to a wave of companies that are fitting children’s playthings with chatbots and voice assistants.&lt;br /&gt;&amp;nbsp;&lt;br /&gt;It’s a trend that has particularly taken off in China: A recent report by the Shenzhen Toy Industry Association and JD.com predicts that the sector will surpass ¥100 billion ($14 billion) by 2030, growing faster than almost any other branch of consumer AI. But Chinese AI toy companies have their sights set beyond the nation’s borders. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;2025 climate tech companies to watch: Pairwise and its climate-adapted crops&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Climate change will make it increasingly difficult to grow crops across many parts of the world. Startup Pairwise is using CRISPR gene editing to develop plants that can better withstand adverse conditions.&lt;/p&gt;  &lt;p&gt;The company uses cutting-edge gene editing to produce crops that can withstand increasingly harsh climate conditions, helping to feed a growing population even as the world warms. Last year, it delivered its first food to the US market: a less-bitter–tasting mustard green. It’s now working to produce crops with climate-resilient traits, through partnerships with two of the world’s largest plant biotech companies. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Pairwise is one of our 10 climate tech companies to watch—our annual list of some of the most promising climate tech firms on the planet. &lt;/strong&gt;&lt;strong&gt;Check out the rest of the list here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; 

   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: How to measure the returns on R&amp;amp;D spending&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Given the draconian cuts to US federal funding for science, it’s worth asking some hard-nosed money questions: How much should we be spending on R&amp;amp;D? How much value do we get out of such investments, anyway?&lt;/p&gt;  &lt;p&gt;To answer that, in several recent papers, economists have approached this issue in clever new ways.&amp;nbsp; And, though they ask slightly different questions, their conclusions share a bottom line: R&amp;amp;D is, in fact, one of the better long-term investments that the government can make.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;1 How OpenAI and Nvidia are fueling the AI bubble&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Experts fear their circular deals could be artificially inflating the market. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;OpenAI will pay for AMD’s chips using, err, AMD’s own stock. &lt;/em&gt;(TechCrunch)&lt;br /&gt;+ &lt;em&gt;The Bank of England is concerned about AI inflating tech stocks. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;What comes next, that’s the big question. &lt;/em&gt;(NBC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Around 15% of the world’s working population is using AI&lt;/strong&gt;&lt;br /&gt;And countries in Europe are among the most enthusiastic adopters. (FT $)&lt;br /&gt;+ &lt;em&gt;The EU is keen to get even more of its citizens using it, too. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;Meanwhile, America’s public opinion towards AI is souring. &lt;/em&gt;(WP $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;3 Three quantum mechanics scientists have won the Nobel Prize for Physics&lt;/strong&gt;&lt;br /&gt;Two of whom were instrumental in building Google’s working quantum machines. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Their work shone a light on behaviors of the subatomic realm. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;Quantum particles behave in notoriously strange ways. &lt;/em&gt;(New Scientist $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 The CDC has finally signed off on covid vaccine recommendations&lt;/strong&gt;&lt;br /&gt;Despite the delay, access looks largely similar to last years’. (Ars Technica)&lt;br /&gt;+ &lt;em&gt;The Supreme Court isn’t sold on medical expertise these days. &lt;/em&gt;(Vox)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;5 What makes TikTok so ‘sticky’&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Even its hardcore users can be persuaded to keep scrolling for hours. (WP $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 ICE bought fake cell towers to spy on nearby phones&lt;br /&gt;&lt;/strong&gt;It’s used cell-site simulators in the past to track down alleged criminals. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;Meet the volunteers tracking ICE officers in LA. &lt;/em&gt;(New Yorker $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Watermark removers for Sora 2 videos are already readily available&lt;br /&gt;&lt;/strong&gt;No permission? No problem. (404 Media)&lt;br /&gt;+ &lt;em&gt;What about copyright for AI-generated art? &lt;/em&gt;(The Information $)&lt;br /&gt;+ &lt;em&gt;And what comes next for AI copyright lawsuits? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 How diamonds can help to cool down chips&lt;br /&gt;&lt;/strong&gt;They’re remarkably good at transferring heat. (NYT $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;9 Amazon Pharmacy is launching electronic prescription kiosks&lt;/strong&gt;&lt;br /&gt;For drugs including antibiotics, asthma inhalers and treatments for high blood pressure. (Reuters)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Should you limit your smartphone use to two hours a day?&lt;/strong&gt;&lt;br /&gt;Japan thinks so. (The Guardian)&lt;br /&gt;+ &lt;em&gt;How to log off. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“OpenAI is building the future of AI on infrastructure it doesn't own, power it doesn't control, and capital it doesn't have.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Andrey Sidorenko, head of research at data firm Mostly AI, critiques what he calls the consolidation of the AI ecosystem in a post on LinkedIn.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1125309" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image_d541b2.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;How AI can help make cities work better&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In recent decades, cities have become increasingly adept at amassing all sorts of data. But that data can have limited impact when government officials are unable to communicate, let alone analyze or put to use, all the information they have access to.&lt;/p&gt;&lt;p&gt;This dynamic has always bothered Sarah Williams, a professor of urban planning and technology at MIT. Shortly after joining MIT in 2012, Williams created the Civic Data Design Lab to bridge that divide. Over the years, she and her colleagues have made urban planning data more vivid and accessible through human stories and striking graphics. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Ben Schneider&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Life lessons from the one and only Ozzy Osbourne—what’s not to like?&lt;br /&gt;+ Did you know that most countries have their own camouflage? Check the patterns out here.&lt;br /&gt;+ These hamsters getting an MRI scan is the cutest thing you’ll see today.&lt;br /&gt;+ Pumpkin chili sounds like a fantastic way to warm up.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/08/1125301/the-download-carbon-removal-factories-funding-cuts-and-ai-toys/</guid><pubDate>Wed, 08 Oct 2025 12:10:00 +0000</pubDate></item></channel></rss>