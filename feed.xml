<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 11 Jul 2025 06:33:48 +0000</lastBuildDate><item><title>Cops’ favorite AI tool automatically deletes evidence of when AI was used (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/cops-favorite-ai-tool-automatically-deletes-evidence-of-when-ai-was-used/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI police tool is designed to avoid accountability, watchdog says.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="480" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-153523633-640x480.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-153523633-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          koya79 | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Thursday, a digital rights group, the Electronic Frontier Foundation, published an expansive investigation into AI-generated police reports that the group alleged are, by design, nearly impossible to audit and could make it easier for cops to lie under oath.&lt;/p&gt;
&lt;p&gt;Axon's Draft One debuted last summer at a police department in Colorado, instantly raising questions about the feared negative impacts of AI-written police reports on the criminal justice system. The tool relies on a ChatGPT variant to generate police reports based on body camera audio, which cops are then supposed to edit to correct any mistakes, assess the AI outputs for biases, or add key context.&lt;/p&gt;
&lt;p&gt;But the EFF found that the tech "seems designed to stymie any attempts at auditing, transparency, and accountability." Cops don't have to disclose when AI is used in every department, and Draft One does not save drafts or retain a record showing which parts of reports are AI-generated. Departments also don't retain different versions of drafts, making it difficult to assess how one version of an AI report might compare to another to help the public determine if the technology is "junk," the EFF said. That raises the question, the EFF suggested, "Why wouldn't an agency want to maintain a record that can establish the technology’s accuracy?"&lt;/p&gt;
&lt;p&gt;It's currently hard to know if cops are editing the reports or "reflexively rubber-stamping the drafts to move on as quickly as possible," the EFF said. That's particularly troubling, the EFF noted, since Axon disclosed to at least one police department that "there has already been an occasion when engineers discovered a bug that allowed officers on at least three occasions to circumvent the 'guardrails' that supposedly deter officers from submitting AI-generated reports without reading them first."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The AI tool could also possibly be "overstepping in its interpretation of the audio," possibly misinterpreting slang or adding context that never happened.&lt;/p&gt;
&lt;p&gt;A "major concern," the EFF said, is that the AI reports can give cops a "smokescreen," perhaps even allowing them to dodge consequences for lying on the stand by blaming the AI tool for any "biased language, inaccuracies, misinterpretations, or lies" in their reports.&lt;/p&gt;
&lt;p&gt;"There’s no record showing whether the culprit was the officer or the AI," the EFF said. "This makes it extremely difficult if not impossible to assess how the system affects justice outcomes over time."&lt;/p&gt;
&lt;p&gt;According to the EFF, Draft One "seems deliberately designed to avoid audits that could provide any accountability to the public." In one video from a roundtable discussion the EFF reviewed, an Axon senior principal product manager for generative AI touted Draft One's disappearing drafts as a feature, explaining, "we don’t store the original draft and that’s by design and that’s really because the last thing we want to do is create more disclosure headaches for our customers and our attorney’s offices."&lt;/p&gt;
&lt;p&gt;The EFF interpreted this to mean that "the last thing" that Axon wants "is for cops to have to provide that data to anyone (say, a judge, defense attorney or civil liberties non-profit)."&lt;/p&gt;
&lt;p&gt;"To serve and protect the public interest, the AI output must be continually and aggressively evaluated whenever and wherever it's used," the EFF said. "But Axon has intentionally made this difficult."&lt;/p&gt;
&lt;p&gt;The EFF is calling for a nationwide effort to monitor AI-generated police reports expected to be increasingly deployed in many cities over the next few years and published a guide to help journalists and others submit records requests to monitor police use in their area. But "unfortunately, obtaining these records isn't easy," the EFF's investigation confirmed. "In many cases, it's straight-up impossible."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;An Axon spokesperson provided a statement to Ars:&lt;/p&gt;
&lt;p&gt;"Draft One helps officers draft an initial report narrative strictly from the audio transcript of the body-worn camera recording and includes a range of safeguards, including mandatory human decision-making at crucial points and transparency about its use. Just as with narrative reports not generated by Draft One, officers remain fully responsible for the content. Every report must be edited, reviewed, and approved by a human officer, ensuring both accuracy and accountability. Draft One was designed to mirror the existing police narrative process—where, as has long been standard, only the final, approved report is saved and discoverable, not the interim edits, additions, or deletions made during officer or supervisor review.&lt;/p&gt;
&lt;p&gt;Since day one, whenever Draft One is used to generate an initial narrative, its use is stored in Axon Evidence’s unalterable digital audit trail,&amp;nbsp;which can be retrieved by agencies on any report. By default, each Draft One report also includes a customizable disclaimer, which can appear at the beginning or end of the report in accordance with agency policy.&amp;nbsp;We recently&amp;nbsp;added the ability for agencies to export Draft One usage reports—showing how many drafts have been generated and submitted per user—and to run reports on which specific evidence items were used with Draft One, further supporting transparency and oversight. Axon is committed to continuous collaboration with police agencies, prosecutors, defense attorneys, community advocates, and other stakeholders to gather input and guide the responsible evolution of Draft One and AI technologies in the justice system, including changes as laws evolve."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;“Police should not be using AI”&lt;/h2&gt;
&lt;p&gt;Expecting Axon's tool would likely spread fast—marketed as a supposedly time-saving add-on service to police departments that already rely on Axon for tasers and body cameras—EFF's senior policy analyst Matthew Guariglia told Ars that the EFF quickly formed a plan to track adoption of the new technology.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Over the spring, the EFF sent public records requests to dozens of police departments believed to be using Draft One. To craft the requests, they also reviewed Axon user manuals and other materials.&lt;/p&gt;
&lt;p&gt;In a press release, the EFF confirmed that the investigation "found the product offers meager oversight features," including a practically useless "audit log" function that seems contradictory to police norms surrounding data retention.&lt;/p&gt;
&lt;p&gt;Perhaps most glaringly, Axon's tool doesn't allow departments to "export a list of all police officers who have used Draft One," the EFF noted, or even "export a list of all reports created by Draft One, unless the department has customized its process." Instead, Axon only allows exports of basic logs showing actions taken on a particular report or an individual user's basic activity in the system, like logins and uploads. That makes it "near impossible to do even the most basic statistical analysis: how many officers are using the technology and how often," the EFF said.&lt;/p&gt;
&lt;p&gt;Any effort to crunch the numbers would be time-intensive, the EFF found. In some departments, it's possible to look up individual cops' records to determine when they used Draft One, but that "could mean combing through dozens, hundreds, or in some cases, thousands of individual user logs." And it would take a similarly "massive amount of time" to sort through reports one by one, considering "the sheer number of reports generated" by any given agency, the EFF noted.&lt;/p&gt;
&lt;p&gt;In some jurisdictions, cops are required to disclose when AI is used to generate reports. And some departments require it, the EFF found, which made the documents more easily searchable and in turn made some police departments more likely to respond to public records requests without charging excessive fees or requiring substantial delays. But at least one department in Indiana told the EFF that "we do not have the ability to create a list of reports created through Draft One. They are not searchable."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While not every cop can search their Draft One reports, Axon can, the EFF reported, suggesting that the company can track how much police use the tool better than police themselves can.&lt;/p&gt;
&lt;p&gt;The EFF hopes its reporting will curtail the growing reliance on shady AI-generated police reports, which Guariglia told Ars risk becoming even more common in US policing without intervention.&lt;/p&gt;
&lt;p&gt;In California, where some cops have long been using Draft One, a bill has been introduced that would require disclosures clarifying which parts of police reports are AI-generated. That law, if passed, would also "require the first draft created to be retained for as long as the final report is retained," which Guariglia told Ars would make Draft One automatically unlawful as currently designed. Utah is weighing a similar but less robust initiative, the EFF noted.&lt;/p&gt;
&lt;p&gt;Guariglia told Ars that the EFF has talked to public defenders who worry how the proliferation of AI-generated police reports is "going to affect cross-examination" by potentially giving cops an easy scapegoat when accused of lying on the stand.&lt;/p&gt;
&lt;p&gt;To avoid the issue entirely, at least one district attorney's office in King County, Washington, has banned AI police reports, citing "legitimate concerns about some of the products on the market now." Guariglia told Ars that one of the district attorney's top concerns was that using the AI tool could "jeopardize cases." The EFF is now urging "other prosecutors to follow suit and demand that police in their jurisdiction not unleash this new, unaccountable, and intentionally opaque AI product."&lt;/p&gt;
&lt;p&gt;"Police should not be using AI to write police reports," Guariglia said. "There are just too many questions left unanswered about how AI would translate the audio of situations, whether police will actually edit those drafts, and whether the public will ever be able to tell what was written by a person and what was written by a computer. This is before we even get to the question of how these reports might lead to problems in an already unfair and untransparent criminal justice system."&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This story was updated to include a statement from Axon.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI police tool is designed to avoid accountability, watchdog says.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="480" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-153523633-640x480.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-153523633-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          koya79 | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Thursday, a digital rights group, the Electronic Frontier Foundation, published an expansive investigation into AI-generated police reports that the group alleged are, by design, nearly impossible to audit and could make it easier for cops to lie under oath.&lt;/p&gt;
&lt;p&gt;Axon's Draft One debuted last summer at a police department in Colorado, instantly raising questions about the feared negative impacts of AI-written police reports on the criminal justice system. The tool relies on a ChatGPT variant to generate police reports based on body camera audio, which cops are then supposed to edit to correct any mistakes, assess the AI outputs for biases, or add key context.&lt;/p&gt;
&lt;p&gt;But the EFF found that the tech "seems designed to stymie any attempts at auditing, transparency, and accountability." Cops don't have to disclose when AI is used in every department, and Draft One does not save drafts or retain a record showing which parts of reports are AI-generated. Departments also don't retain different versions of drafts, making it difficult to assess how one version of an AI report might compare to another to help the public determine if the technology is "junk," the EFF said. That raises the question, the EFF suggested, "Why wouldn't an agency want to maintain a record that can establish the technology’s accuracy?"&lt;/p&gt;
&lt;p&gt;It's currently hard to know if cops are editing the reports or "reflexively rubber-stamping the drafts to move on as quickly as possible," the EFF said. That's particularly troubling, the EFF noted, since Axon disclosed to at least one police department that "there has already been an occasion when engineers discovered a bug that allowed officers on at least three occasions to circumvent the 'guardrails' that supposedly deter officers from submitting AI-generated reports without reading them first."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The AI tool could also possibly be "overstepping in its interpretation of the audio," possibly misinterpreting slang or adding context that never happened.&lt;/p&gt;
&lt;p&gt;A "major concern," the EFF said, is that the AI reports can give cops a "smokescreen," perhaps even allowing them to dodge consequences for lying on the stand by blaming the AI tool for any "biased language, inaccuracies, misinterpretations, or lies" in their reports.&lt;/p&gt;
&lt;p&gt;"There’s no record showing whether the culprit was the officer or the AI," the EFF said. "This makes it extremely difficult if not impossible to assess how the system affects justice outcomes over time."&lt;/p&gt;
&lt;p&gt;According to the EFF, Draft One "seems deliberately designed to avoid audits that could provide any accountability to the public." In one video from a roundtable discussion the EFF reviewed, an Axon senior principal product manager for generative AI touted Draft One's disappearing drafts as a feature, explaining, "we don’t store the original draft and that’s by design and that’s really because the last thing we want to do is create more disclosure headaches for our customers and our attorney’s offices."&lt;/p&gt;
&lt;p&gt;The EFF interpreted this to mean that "the last thing" that Axon wants "is for cops to have to provide that data to anyone (say, a judge, defense attorney or civil liberties non-profit)."&lt;/p&gt;
&lt;p&gt;"To serve and protect the public interest, the AI output must be continually and aggressively evaluated whenever and wherever it's used," the EFF said. "But Axon has intentionally made this difficult."&lt;/p&gt;
&lt;p&gt;The EFF is calling for a nationwide effort to monitor AI-generated police reports expected to be increasingly deployed in many cities over the next few years and published a guide to help journalists and others submit records requests to monitor police use in their area. But "unfortunately, obtaining these records isn't easy," the EFF's investigation confirmed. "In many cases, it's straight-up impossible."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;An Axon spokesperson provided a statement to Ars:&lt;/p&gt;
&lt;p&gt;"Draft One helps officers draft an initial report narrative strictly from the audio transcript of the body-worn camera recording and includes a range of safeguards, including mandatory human decision-making at crucial points and transparency about its use. Just as with narrative reports not generated by Draft One, officers remain fully responsible for the content. Every report must be edited, reviewed, and approved by a human officer, ensuring both accuracy and accountability. Draft One was designed to mirror the existing police narrative process—where, as has long been standard, only the final, approved report is saved and discoverable, not the interim edits, additions, or deletions made during officer or supervisor review.&lt;/p&gt;
&lt;p&gt;Since day one, whenever Draft One is used to generate an initial narrative, its use is stored in Axon Evidence’s unalterable digital audit trail,&amp;nbsp;which can be retrieved by agencies on any report. By default, each Draft One report also includes a customizable disclaimer, which can appear at the beginning or end of the report in accordance with agency policy.&amp;nbsp;We recently&amp;nbsp;added the ability for agencies to export Draft One usage reports—showing how many drafts have been generated and submitted per user—and to run reports on which specific evidence items were used with Draft One, further supporting transparency and oversight. Axon is committed to continuous collaboration with police agencies, prosecutors, defense attorneys, community advocates, and other stakeholders to gather input and guide the responsible evolution of Draft One and AI technologies in the justice system, including changes as laws evolve."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;“Police should not be using AI”&lt;/h2&gt;
&lt;p&gt;Expecting Axon's tool would likely spread fast—marketed as a supposedly time-saving add-on service to police departments that already rely on Axon for tasers and body cameras—EFF's senior policy analyst Matthew Guariglia told Ars that the EFF quickly formed a plan to track adoption of the new technology.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Over the spring, the EFF sent public records requests to dozens of police departments believed to be using Draft One. To craft the requests, they also reviewed Axon user manuals and other materials.&lt;/p&gt;
&lt;p&gt;In a press release, the EFF confirmed that the investigation "found the product offers meager oversight features," including a practically useless "audit log" function that seems contradictory to police norms surrounding data retention.&lt;/p&gt;
&lt;p&gt;Perhaps most glaringly, Axon's tool doesn't allow departments to "export a list of all police officers who have used Draft One," the EFF noted, or even "export a list of all reports created by Draft One, unless the department has customized its process." Instead, Axon only allows exports of basic logs showing actions taken on a particular report or an individual user's basic activity in the system, like logins and uploads. That makes it "near impossible to do even the most basic statistical analysis: how many officers are using the technology and how often," the EFF said.&lt;/p&gt;
&lt;p&gt;Any effort to crunch the numbers would be time-intensive, the EFF found. In some departments, it's possible to look up individual cops' records to determine when they used Draft One, but that "could mean combing through dozens, hundreds, or in some cases, thousands of individual user logs." And it would take a similarly "massive amount of time" to sort through reports one by one, considering "the sheer number of reports generated" by any given agency, the EFF noted.&lt;/p&gt;
&lt;p&gt;In some jurisdictions, cops are required to disclose when AI is used to generate reports. And some departments require it, the EFF found, which made the documents more easily searchable and in turn made some police departments more likely to respond to public records requests without charging excessive fees or requiring substantial delays. But at least one department in Indiana told the EFF that "we do not have the ability to create a list of reports created through Draft One. They are not searchable."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While not every cop can search their Draft One reports, Axon can, the EFF reported, suggesting that the company can track how much police use the tool better than police themselves can.&lt;/p&gt;
&lt;p&gt;The EFF hopes its reporting will curtail the growing reliance on shady AI-generated police reports, which Guariglia told Ars risk becoming even more common in US policing without intervention.&lt;/p&gt;
&lt;p&gt;In California, where some cops have long been using Draft One, a bill has been introduced that would require disclosures clarifying which parts of police reports are AI-generated. That law, if passed, would also "require the first draft created to be retained for as long as the final report is retained," which Guariglia told Ars would make Draft One automatically unlawful as currently designed. Utah is weighing a similar but less robust initiative, the EFF noted.&lt;/p&gt;
&lt;p&gt;Guariglia told Ars that the EFF has talked to public defenders who worry how the proliferation of AI-generated police reports is "going to affect cross-examination" by potentially giving cops an easy scapegoat when accused of lying on the stand.&lt;/p&gt;
&lt;p&gt;To avoid the issue entirely, at least one district attorney's office in King County, Washington, has banned AI police reports, citing "legitimate concerns about some of the products on the market now." Guariglia told Ars that one of the district attorney's top concerns was that using the AI tool could "jeopardize cases." The EFF is now urging "other prosecutors to follow suit and demand that police in their jurisdiction not unleash this new, unaccountable, and intentionally opaque AI product."&lt;/p&gt;
&lt;p&gt;"Police should not be using AI to write police reports," Guariglia said. "There are just too many questions left unanswered about how AI would translate the audio of situations, whether police will actually edit those drafts, and whether the public will ever be able to tell what was written by a person and what was written by a computer. This is before we even get to the question of how these reports might lead to problems in an already unfair and untransparent criminal justice system."&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This story was updated to include a statement from Axon.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/cops-favorite-ai-tool-automatically-deletes-evidence-of-when-ai-was-used/</guid><pubDate>Thu, 10 Jul 2025 21:12:26 +0000</pubDate></item><item><title>Former Intel CEO launches a benchmark to measure AI alignment (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/former-intel-ceo-launches-a-benchmark-to-measure-ai-alignment/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/01/GettyImages-871704844.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After former Intel CEO Pat Gelsinger capped off a more than 40-year career at the semiconductor giant in December, many wondered where Gelsinger would go next. On Thursday, the former Intel CEO revealed one piece of his next chapter: trying to ensure AI models support a flourishing humanity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In partnership with a “faith tech” company he first invested in roughly 10 years ago called Gloo, Gelsinger launched a new benchmark — Flourishing AI, or FAI — to test how well AI models align with certain human values. The FAI benchmark is based on The Global Flourishing Study, a survey directed by Harvard and Baylor University, to measure human well-being around the world.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gloo took six core categories from the study — Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability — and added one more, Faith and Spirituality, to test LLMs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an interview with The New Stack, Gelsinger said he’s “lived at the intersection of faith tech my entire life.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/01/GettyImages-871704844.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After former Intel CEO Pat Gelsinger capped off a more than 40-year career at the semiconductor giant in December, many wondered where Gelsinger would go next. On Thursday, the former Intel CEO revealed one piece of his next chapter: trying to ensure AI models support a flourishing humanity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In partnership with a “faith tech” company he first invested in roughly 10 years ago called Gloo, Gelsinger launched a new benchmark — Flourishing AI, or FAI — to test how well AI models align with certain human values. The FAI benchmark is based on The Global Flourishing Study, a survey directed by Harvard and Baylor University, to measure human well-being around the world.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gloo took six core categories from the study — Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability — and added one more, Faith and Spirituality, to test LLMs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an interview with The New Stack, Gelsinger said he’s “lived at the intersection of faith tech my entire life.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/former-intel-ceo-launches-a-benchmark-to-measure-ai-alignment/</guid><pubDate>Thu, 10 Jul 2025 21:35:49 +0000</pubDate></item><item><title>AWS doubles down on infrastructure as strategy in the AI race with SageMaker upgrades (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/aws-doubles-down-on-infrastructure-as-strategy-in-the-ai-race-with-sagemaker-upgrades/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;AWS seeks to extend its market position with updates to SageMaker, its machine learning and AI model training and inference platform, adding new observability capabilities, connected coding environments and GPU cluster performance management.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, AWS continues to face competition from Google and Microsoft, which also offer many features that help accelerate AI training and inference.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker, which transformed into a unified hub for integrating data sources and accessing machine learning tools in 2024, will add features that provide insight into why model performance slows and offer AWS customers more control over the amount of compute allocated for model development.&lt;/p&gt;



&lt;p&gt;Other new features include connecting local integrated development environments (IDEs) to SageMaker, so locally written AI projects can be deployed on the platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker General Manager Ankur Mehrotra told VentureBeat that many of these new updates originated from customers themselves.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“One challenge that we’ve seen our customers face while developing Gen AI models is that when something goes wrong or when something is not working as per the expectation, it’s really hard to find what’s going on in that layer of the stack,” Mehrotra said.&lt;/p&gt;



&lt;p&gt;SageMaker HyperPod observability enables engineers to examine the various layers of the stack, such as the compute layer or networking layer. If anything goes wrong or models become slower, SageMaker can alert them and publish metrics on a dashboard.&lt;/p&gt;



&lt;p&gt;Mehrotra pointed to a real issue his own team faced while training new models, where training code began stressing GPUs, causing temperature fluctuations. He said that without the latest tools, developers would have taken weeks to identify the source of the issue and then fix it.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-connected-ides"&gt;Connected IDEs&lt;/h2&gt;



&lt;p&gt;SageMaker already offered two ways for AI developers to train and run models. It had access to fully managed IDEs, such as Jupyter Lab or Code Editor, to seamlessly run the training code on the models through SageMaker. Understanding that other engineers prefer to use their local IDEs, including all the extensions they have installed, AWS allowed them to run their code on their machines as well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, Mehrotra pointed out that it meant locally coded models only ran locally, so if developers wanted to scale, it proved to be a significant challenge.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AWS added new secure remote execution to allow customers to continue working on their preferred IDE — either locally or managed — and connect ot to SageMaker.&lt;/p&gt;



&lt;p&gt;“So this capability now gives them the best of both worlds where if they want, they can develop locally on a local IDE, but then in terms of actual task execution, they can benefit from the scalability of SageMaker,” he said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-more-flexibility-in-compute"&gt;More flexibility in compute&lt;/h2&gt;



&lt;p&gt;AWS launched SageMaker HyperPod in December 2023 as a means to help customers manage clusters of servers for training models. Similar to providers like CoreWeave, HyperPod enables SageMaker customers to direct unused compute power to their preferred location. HyperPod knows when to schedule GPU usage based on demand patterns and allows organizations to balance their resources and costs effectively.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, AWS said many customers wanted the same service for inference. Many inference tasks occur during the day when people use models and applications, while training is usually scheduled during off-peak hours.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;Mehrotra noted that even in the world inference, developers can prioritize the inference tasks that HyperPod should focus on.&lt;/p&gt;



&lt;p&gt;Laurent Sifre, co-founder and CTO at AI agent company H AI, said in an AWS blog post that the company used SageMaker HyperPod when building out its agentic platform.&lt;/p&gt;



&lt;p&gt;“This seamless transition from training to inference streamlined our workflow, reduced time to production, and delivered consistent performance in live environments,” Sifre said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-aws-and-the-competition"&gt;AWS and the competition&lt;/h2&gt;



&lt;p&gt;Amazon may not be offering the splashiest foundation models like its cloud provider rivals, Google and Microsoft. Still, AWS has been more focused on providing the infrastructure backbone for enterprises to build AI models, applications, or agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In addition to SageMaker, AWS also offers Bedrock, a platform specifically designed for building applications and agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker has been around for years, initially serving as a means to connect disparate machine learning tools to data lakes. As the generative AI boom began, AI engineers began using SageMaker to help train language models. However, Microsoft is pushing hard for its Fabric ecosystem, with 70% of Fortune 500 companies adopting it, to become a leader in the data and AI acceleration space. Google, through Vertex AI, has quietly made inroads in enterprise AI adoption.&lt;/p&gt;



&lt;p&gt;AWS, of course, has the advantage of being the most widely used cloud provider. Any updates that would make its many AI infrastructure platforms easier to use will always be a benefit.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;AWS seeks to extend its market position with updates to SageMaker, its machine learning and AI model training and inference platform, adding new observability capabilities, connected coding environments and GPU cluster performance management.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, AWS continues to face competition from Google and Microsoft, which also offer many features that help accelerate AI training and inference.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker, which transformed into a unified hub for integrating data sources and accessing machine learning tools in 2024, will add features that provide insight into why model performance slows and offer AWS customers more control over the amount of compute allocated for model development.&lt;/p&gt;



&lt;p&gt;Other new features include connecting local integrated development environments (IDEs) to SageMaker, so locally written AI projects can be deployed on the platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker General Manager Ankur Mehrotra told VentureBeat that many of these new updates originated from customers themselves.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“One challenge that we’ve seen our customers face while developing Gen AI models is that when something goes wrong or when something is not working as per the expectation, it’s really hard to find what’s going on in that layer of the stack,” Mehrotra said.&lt;/p&gt;



&lt;p&gt;SageMaker HyperPod observability enables engineers to examine the various layers of the stack, such as the compute layer or networking layer. If anything goes wrong or models become slower, SageMaker can alert them and publish metrics on a dashboard.&lt;/p&gt;



&lt;p&gt;Mehrotra pointed to a real issue his own team faced while training new models, where training code began stressing GPUs, causing temperature fluctuations. He said that without the latest tools, developers would have taken weeks to identify the source of the issue and then fix it.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-connected-ides"&gt;Connected IDEs&lt;/h2&gt;



&lt;p&gt;SageMaker already offered two ways for AI developers to train and run models. It had access to fully managed IDEs, such as Jupyter Lab or Code Editor, to seamlessly run the training code on the models through SageMaker. Understanding that other engineers prefer to use their local IDEs, including all the extensions they have installed, AWS allowed them to run their code on their machines as well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, Mehrotra pointed out that it meant locally coded models only ran locally, so if developers wanted to scale, it proved to be a significant challenge.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AWS added new secure remote execution to allow customers to continue working on their preferred IDE — either locally or managed — and connect ot to SageMaker.&lt;/p&gt;



&lt;p&gt;“So this capability now gives them the best of both worlds where if they want, they can develop locally on a local IDE, but then in terms of actual task execution, they can benefit from the scalability of SageMaker,” he said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-more-flexibility-in-compute"&gt;More flexibility in compute&lt;/h2&gt;



&lt;p&gt;AWS launched SageMaker HyperPod in December 2023 as a means to help customers manage clusters of servers for training models. Similar to providers like CoreWeave, HyperPod enables SageMaker customers to direct unused compute power to their preferred location. HyperPod knows when to schedule GPU usage based on demand patterns and allows organizations to balance their resources and costs effectively.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, AWS said many customers wanted the same service for inference. Many inference tasks occur during the day when people use models and applications, while training is usually scheduled during off-peak hours.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;Mehrotra noted that even in the world inference, developers can prioritize the inference tasks that HyperPod should focus on.&lt;/p&gt;



&lt;p&gt;Laurent Sifre, co-founder and CTO at AI agent company H AI, said in an AWS blog post that the company used SageMaker HyperPod when building out its agentic platform.&lt;/p&gt;



&lt;p&gt;“This seamless transition from training to inference streamlined our workflow, reduced time to production, and delivered consistent performance in live environments,” Sifre said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-aws-and-the-competition"&gt;AWS and the competition&lt;/h2&gt;



&lt;p&gt;Amazon may not be offering the splashiest foundation models like its cloud provider rivals, Google and Microsoft. Still, AWS has been more focused on providing the infrastructure backbone for enterprises to build AI models, applications, or agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In addition to SageMaker, AWS also offers Bedrock, a platform specifically designed for building applications and agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker has been around for years, initially serving as a means to connect disparate machine learning tools to data lakes. As the generative AI boom began, AI engineers began using SageMaker to help train language models. However, Microsoft is pushing hard for its Fabric ecosystem, with 70% of Fortune 500 companies adopting it, to become a leader in the data and AI acceleration space. Google, through Vertex AI, has quietly made inroads in enterprise AI adoption.&lt;/p&gt;



&lt;p&gt;AWS, of course, has the advantage of being the most widely used cloud provider. Any updates that would make its many AI infrastructure platforms easier to use will always be a benefit.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/aws-doubles-down-on-infrastructure-as-strategy-in-the-ai-race-with-sagemaker-upgrades/</guid><pubDate>Thu, 10 Jul 2025 21:37:51 +0000</pubDate></item><item><title>Where AI meets design: Runway co-founder Alejandro Matamala Ortiz takes the AI Stage at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/where-ai-meets-design-runway-co-founder-alejandro-matamala-ortiz-takes-the-ai-stage-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; is the epicenter where 10,000+ startup and VC leaders gather to explore the future of innovation — and this year, two AI Stages bring the intersection of design and machine learning into sharp focus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’re thrilled to welcome Alejandro Matamala Ortiz, co-founder and chief design officer at Runway, to one of the AI Stages at Disrupt 2025, taking place October 27–29 in San Francisco. As part of a can’t-miss panel conversation, Ortiz will share how design principles are guiding the next generation of generative AI tools — and how his team at Runway is redefining what creativity looks like in the age of machines.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Alejandro Matamala Ortiz" class="wp-image-3026782" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Alejandro-Matamala-Ortiz-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-attend-this-session"&gt;Why attend this session?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Expect fresh, actionable insights into how creative professionals and technologists can work together to build tools that empower — not replace — human expression. Ortiz will offer a design-first perspective on building intuitive, artist-friendly AI experiences that are already transforming industries, from film to marketing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Prior to co-founding Runway, Ortiz was a research resident at New York University, where he studied the interaction between artificial intelligence and creativity. Today he leads the company’s vision for accessible, cutting-edge creative software that’s shaping how the world imagines and produces content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Join us on one of the AI Stages and the other five industry stages at Disrupt 2025 to hear from Matamala Ortiz and other leaders who are building the creative engines of tomorrow. &lt;strong&gt;Buy your ticket now and save up to $625.&lt;/strong&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; is the epicenter where 10,000+ startup and VC leaders gather to explore the future of innovation — and this year, two AI Stages bring the intersection of design and machine learning into sharp focus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’re thrilled to welcome Alejandro Matamala Ortiz, co-founder and chief design officer at Runway, to one of the AI Stages at Disrupt 2025, taking place October 27–29 in San Francisco. As part of a can’t-miss panel conversation, Ortiz will share how design principles are guiding the next generation of generative AI tools — and how his team at Runway is redefining what creativity looks like in the age of machines.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Alejandro Matamala Ortiz" class="wp-image-3026782" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Alejandro-Matamala-Ortiz-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-attend-this-session"&gt;Why attend this session?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Expect fresh, actionable insights into how creative professionals and technologists can work together to build tools that empower — not replace — human expression. Ortiz will offer a design-first perspective on building intuitive, artist-friendly AI experiences that are already transforming industries, from film to marketing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Prior to co-founding Runway, Ortiz was a research resident at New York University, where he studied the interaction between artificial intelligence and creativity. Today he leads the company’s vision for accessible, cutting-edge creative software that’s shaping how the world imagines and produces content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Join us on one of the AI Stages and the other five industry stages at Disrupt 2025 to hear from Matamala Ortiz and other leaders who are building the creative engines of tomorrow. &lt;strong&gt;Buy your ticket now and save up to $625.&lt;/strong&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/where-ai-meets-design-runway-co-founder-alejandro-matamala-ortiz-takes-the-ai-stage-at-techcrunch-disrupt-2025/</guid><pubDate>Thu, 10 Jul 2025 22:45:00 +0000</pubDate></item><item><title>AWS is launching an AI agent marketplace next week with Anthropic as a partner (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/aws-is-launching-an-ai-agent-marketplace-next-week-with-anthropic-as-a-partner/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/AWS-re-Invent-2021.jpeg?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services (AWS) is launching an AI agent marketplace next week and Anthropic is one of its partners, TechCrunch has exclusively learned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AWS agent marketplace launch will take place at the AWS Summit in New York City on July 15, two people familiar with the development told TechCrunch. AWS and Anthropic did not respond to requests for comments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI agents are ubiquitous nowadays. And every single investor in Silicon Valley is bullish on startups building them — even if there is some disagreement on exactly what defines an AI agent. The term is somewhat ambiguous and is loosely used to describe computer programs that can make decisions and perform tasks independently, such as interacting with software, by using an AI model at the backend. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI behemoths such as OpenAI and Anthropic are promoting it as the next big thing in tech. However, the distribution of AI agents poses a challenge, as most companies offer them in silos. AWS appears to be taking a step to address this with its new move.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s dedicated agent marketplace will allow startups to directly offer their AI agents to AWS customers. The marketplace will also allow enterprise customers to browse, install, and look for AI agents based on their requirements from a single location, a source said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That could give Anthropic — and other AWS agent marketplace partners — a considerable boost. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, which already has Amazon’s backing and is reportedly in line for another multibillion-dollar investment from the e-commerce company, views AI’s future primarily in terms of agents —&amp;nbsp;at least for the coming years. Anthropic builds AI agents in-house and enables developers to create them using its API.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;AWS’ marketplace would help Anthropic reach more customers, including those who may already use AI agents from its rivals, such as OpenAI. Anthropic’s involvement in the marketplace could also attract more developers to use its API to create more agents, and eventually increase its revenues. The company already hit $3 billion in annualized revenue in late May.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like any other online marketplace, AWS will take a cut of the revenue that startups earn from agent installations. However, this share will be minimal compared to the marketplace’s potential to unlock new revenue streams and attract customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The marketplace model will allow startups to charge customers for agents. The structure is similar to how a marketplace might price SaaS offerings rather than bundling them into broader services, one of the sources said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amazon is not the first tech giant to offer a marketplace for agents. In April, Google Cloud introduced an AI Agent Marketplace to help developers and businesses list, buy, and sell AI agents. Microsoft also introduced a similar offering, called Agent Store, within Microsoft 365 Copilot a month later. Similarly, enterprise software providers, including Salesforce and ServiceNow, have their own agent marketplaces.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, we have yet to see how successful these marketplaces are for smaller AI startups and enterprises seeking specific AI agents.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/AWS-re-Invent-2021.jpeg?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services (AWS) is launching an AI agent marketplace next week and Anthropic is one of its partners, TechCrunch has exclusively learned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AWS agent marketplace launch will take place at the AWS Summit in New York City on July 15, two people familiar with the development told TechCrunch. AWS and Anthropic did not respond to requests for comments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI agents are ubiquitous nowadays. And every single investor in Silicon Valley is bullish on startups building them — even if there is some disagreement on exactly what defines an AI agent. The term is somewhat ambiguous and is loosely used to describe computer programs that can make decisions and perform tasks independently, such as interacting with software, by using an AI model at the backend. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI behemoths such as OpenAI and Anthropic are promoting it as the next big thing in tech. However, the distribution of AI agents poses a challenge, as most companies offer them in silos. AWS appears to be taking a step to address this with its new move.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s dedicated agent marketplace will allow startups to directly offer their AI agents to AWS customers. The marketplace will also allow enterprise customers to browse, install, and look for AI agents based on their requirements from a single location, a source said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That could give Anthropic — and other AWS agent marketplace partners — a considerable boost. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, which already has Amazon’s backing and is reportedly in line for another multibillion-dollar investment from the e-commerce company, views AI’s future primarily in terms of agents —&amp;nbsp;at least for the coming years. Anthropic builds AI agents in-house and enables developers to create them using its API.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;AWS’ marketplace would help Anthropic reach more customers, including those who may already use AI agents from its rivals, such as OpenAI. Anthropic’s involvement in the marketplace could also attract more developers to use its API to create more agents, and eventually increase its revenues. The company already hit $3 billion in annualized revenue in late May.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like any other online marketplace, AWS will take a cut of the revenue that startups earn from agent installations. However, this share will be minimal compared to the marketplace’s potential to unlock new revenue streams and attract customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The marketplace model will allow startups to charge customers for agents. The structure is similar to how a marketplace might price SaaS offerings rather than bundling them into broader services, one of the sources said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amazon is not the first tech giant to offer a marketplace for agents. In April, Google Cloud introduced an AI Agent Marketplace to help developers and businesses list, buy, and sell AI agents. Microsoft also introduced a similar offering, called Agent Store, within Microsoft 365 Copilot a month later. Similarly, enterprise software providers, including Salesforce and ServiceNow, have their own agent marketplaces.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, we have yet to see how successful these marketplaces are for smaller AI startups and enterprises seeking specific AI agents.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/aws-is-launching-an-ai-agent-marketplace-next-week-with-anthropic-as-a-partner/</guid><pubDate>Thu, 10 Jul 2025 22:59:26 +0000</pubDate></item><item><title>$8.8 trillion protected: How one CISO went from ‘that’s BS’ to bulletproof in 90 days (AI News | VentureBeat)</title><link>https://venturebeat.com/security/ciso-dodges-bullet-protecting-8-8-trillion-from-shadow-ai/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;VentureBeat’s exclusive interview with Sam Evans, CISO of Clearwater Analytics, reveals why enterprise browsers are quickly becoming the frontline defense against shadow AI in its many forms.&amp;nbsp; &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Evans faced a critical challenge in October 2023. Standing before Clearwater Analytics’ board, he had to confront concerns that employees might inadvertently expose data that could potentially compromise the firm’s $8.8 trillion assets under management. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The worst possible thing would be one of our employees taking customer data and putting it into an AI engine that we don’t manage,” Evans told VentureBeat. “The employee not knowing any different or trying to solve a problem for a customer…that data helps train the model.”&lt;/p&gt;



&lt;p&gt;Here is our conversation with Evans, edited for length and clarity&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How do you see AI shaping cybersecurity today?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; The attacks have become significantly more sophisticated. If you consider it from the perspective of a bad actor, the phishing emails and attempts we receive have become much more complex. However, AI also possesses response capabilities.&lt;/p&gt;



&lt;p&gt;I like to explain it to our board, as the ultimate cat-and-mouse game. As bad actors start to use AI to advance phishing, or perhaps expedite the time it takes for exploits to emerge after vulnerabilities are announced, there’s the opposite side of security practitioners using AI to help advance how we respond.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How is AI helping your defensive capabilities?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; We’ve begun integrating AI into our security playbooks. By doing so, our security analysts now spend less time searching and hunting. The AI is involved in the security operations center (SOC) product, conducting its initial triage analysis and saying, “Based on previous things that we’ve seen and things in my model, this is where I’d like to guide you.”&lt;/p&gt;



&lt;p&gt;On the defensive side, we’re really starting to see AI come into play. CrowdStrike, Sentinel One, Microsoft Defender, the traditional extended detection and response (EDR) products were using some machine learning, and they would get to a probability of maybe 85% that this could be a threat, but we’re not really sure. However, AI enriches the EDR engine’s ability to reach a higher probability rate of identifying a threat.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: W&lt;/strong&gt;hat keeps you up at night when it comes to AI and cybersecurity?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; The thing that does worry me quite a bit is the deepfakes. You read multiple stories about people using deepfakes to impersonate a CEO to initiate wire transfers. Those are concerning because they do look very, very real.&lt;/p&gt;



&lt;p&gt;But the biggest concern? The worst possible thing would be one of our employees taking customer data and putting it into an AI engine that we don’t manage, and then it becomes data that helps train the model.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How did you explain this shadow AI risk to your board?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; I remember when one of the first board meetings I was in, they asked me, “So what are your thoughts on ChatGPT?” I said, “Well, it’s an incredible productivity tool. However, I don’t know how we could let our employees use it, because my biggest fear is somebody copies and pastes customer data into it, or our source code, which is our intellectual property.”&lt;/p&gt;



&lt;p&gt;But I didn’t just come to the board with my concerns and problems. I said, “Well, here’s my solution. I don’t want to stop people from being productive, but I also want to protect it.” When I came to the board and explained how these enterprise browsers work, they’re like, “Okay, that makes much sense, but can you really do it?”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;Walk me through your evaluation and deployment process for Island.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; After that October 2023 board meeting, we started a pretty long due diligence process. We took a look at some of the major vendors in the enterprise browser space.&lt;/p&gt;



&lt;p&gt;I’ll share with you ultimately why we went with an Island. We needed to be able to control what browsers people are using on their endpoints. It doesn’t do any good to deploy an enterprise browser when somebody can go and download Opera or “Frank’s browser of the month” and use it, and it just bypasses all of the Island controls.&lt;/p&gt;



&lt;p&gt;The other reason we went with Island was truly because of the speed of the deployment. I remember being on a call with Island salespeople, and they’re saying, “We believe we can get this deployed in your company in a matter of weeks.” I’m like, “Oh, that’s BS.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;But they delivered?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; They took it as a personal challenge! We started our Island deployment in April 2024 with about 200 people. We went the extension route first; the Island extension in Chrome and Edge.&lt;/p&gt;



&lt;p&gt;It wasn’t until July when the board asked, “How is it going?” And I said, “How about I just show you?” I pulled up a screenshot because, you know, Murphy’s Law demos always fail. So I showed them screenshots, “Here I am on ChatGPT. I tried to paste something in. I got the prompt: ‘Island policy prevents you from doing this.'”&lt;/p&gt;



&lt;p&gt;They’re like, “Wow, this is fantastic! But people can still utilize the tool to ask good questions?” I said, “Yeah, absolutely. They just can’t put data into it.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;Do you feel that Island assures you and reduces the risk of Shadow AI?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; It definitely has helped us get a handle on shadow AI. No security tool is 100% perfect. Having deployed Island, we definitely sleep a lot easier. We can feel reasonably comfortable that if an employee is going to an AI instance that we don’t have licensed, they can use it, but can’t paste data or upload files.&lt;/p&gt;



&lt;p&gt;It’s also helped us identify where we have gaps. Employees found this really great AI widget thing, they come to the security team, “Hey, look, check this out.” And then we can come back to our product development teams and figure out how we help enable this, not just for our employees, but for our customers.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How do you defend against deepfakes?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; That’s a tough one to wrap your arms around. We have an excellent security awareness program. We ask employees to use common sense. Do you really think Sandeep Sahai, our CEO, is going to call you up and ask you to buy him Apple gift cards?&lt;/p&gt;



&lt;p&gt;We’ve set up a lot of checks and balances, kind of like the two-person buddy check system. There’s no technology solution for something like that. It’s a human problem that we’ve had to implement a human solution.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;What advice would you give other CISOs facing shadow AI?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; This isn’t just about blocking, it’s about enablement. Bring solutions, not just problems. When I came to the board, I didn’t just highlight the risks; I proposed a solution that balanced security with productivity.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-welcome-to-the-shadow-ai-arms-race"&gt;Welcome to the shadow AI arms race &lt;/h2&gt;



&lt;p&gt;Evans’ insights reveal how quickly shadow AI has become an existential threat to every data-intensive business. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We see 50 new AI apps a day, and we’ve already cataloged over 12,000,” Itamar Golan, CEO of Prompt Security, told VentureBeat, quantifying what security teams are calling their worst nightmare since ransomware.&lt;/p&gt;



&lt;p&gt;The onslaught of unauthorized AI use and apps has triggered intense competition among security vendors. “Most traditional management tools lack comprehensive visibility into AI apps,” Vineet Arora, CTO of WinWire, explained to VentureBeat, pinpointing exactly why shadow AI flourishes as legacy security architectures are blind to it.&lt;/p&gt;



&lt;p&gt;The vendor ecosystem has crystallized into four distinct battlegrounds, each with its weapons and weaknesses.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Enterprise browsers lead the charge.&lt;/strong&gt; Foremost among them is Island, which recently raised a $250 million funding round, a vote of confidence from the investor community. While Island bets on pre-encryption visibility, Google Chrome Enterprise attacks shadow AI differently, weaponizing its market dominance and Google’s security stack. Chrome Enterprise Premium delivers data loss prevention (DLP) controls that block data flows to ChatGPT and other AI tools, prevent cross-profile contamination and enforce real-time content scanning. The platform exposes shadow AI usage patterns while blocking both accidental pastes and deliberate exfiltration. Strategic partnerships with Zscaler and Cisco Secure Access amplify Chrome’s reach to create an ecosystem where zero-trust principles extend directly to AI interactions.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SASE/SSE platforms deliver enterprise-scale defense. &lt;/strong&gt;Netskope and Zscaler bring scale to shadow AI defense through their cloud-native security access service edge (SASE) architectures. Both platforms process billions of transactions daily across global infrastructures, with Netskope specifically advertising its ability to monitor AI application usage across enterprises. Their key limitation: When 73.8% of workplace ChatGPT usage occurs through personal accounts, SSL/TLS encryption prevents platforms from inspecting content, forcing them to rely on traffic patterns and metadata, leading to visibility gaps where shadow AI operates undetected&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Traditional DLP vendors struggle to adapt&lt;/strong&gt;. Legacy vendors Forcepoint and Microsoft Purview have a strong legacy to trade on when it comes to battling shadow AI. Forcepoint claims 1,700-plus classifiers while Purview leverages AI to triage tasks. But here’s the problem: They’re retrofitting 20th-century architectures for 21st-century threats. These platforms excel at compliance checkboxes and policy templates but fail to keep up with AI’s quicker pace. &lt;/p&gt;



&lt;p&gt;As Daren Goeson, Ivanti’s SVP of product management for UEM told VentureBeat: “AI-powered endpoint security tools can analyze vast amounts of data to detect anomalies and predict potential threats faster and more accurately than any human analyst.” Traditional DLP operates at audit speed. Shadow AI moves at machine speed.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Specialized solutions fill critical gaps&lt;/strong&gt;. Innovation thrives in the niches that legacy vendors ignore. One example is Ivanti Neurons, which delivers comprehensive device discovery through its UEM platform, exposing shadow AI hiding in endpoints that traditional tools miss. Mike Riemer, Ivanti’s Field CISO, sees the bigger picture: “Security professionals will effectively leverage the capabilities of gen AI to analyze vast amounts of data collected from diverse systems.” Nightfall, for its part, targets developer teams with transformer models, claiming 2x detection accuracy for API based AI tools.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Comparing Shadow AI Defense Solutions&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;td&gt;&lt;a&gt;Vendor&lt;/td&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Key Strengths&lt;/td&gt;&lt;td&gt;Limitations&lt;/td&gt;&lt;td&gt;Best For&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Check Point Harmony&lt;/td&gt;&lt;td&gt;Browser extension&lt;/td&gt;&lt;td&gt;Leverages existing infrastructure&lt;/td&gt;&lt;td&gt;Limited to extension&lt;/td&gt;&lt;td&gt;Check Point customers&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Forcepoint&lt;/td&gt;&lt;td&gt;Traditional DLP&lt;/td&gt;&lt;td&gt;1,700+ classifiers, regulatory compliance&lt;/td&gt;&lt;td&gt;Legacy architecture&lt;/td&gt;&lt;td&gt;Highly regulated industries&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Google Chrome Enterprise&lt;/td&gt;&lt;td&gt;Enterprise browser&lt;/td&gt;&lt;td&gt;Market dominance, native integration&lt;/td&gt;&lt;td&gt;Less specialized controls&lt;/td&gt;&lt;td&gt;Google Workspace organizations&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Island&lt;/td&gt;&lt;td&gt;Enterprise browser&lt;/td&gt;&lt;td&gt;Pre-encryption visibility, zero latency, Rapid deployment&lt;/td&gt;&lt;td&gt;Higher cost per user&lt;/td&gt;&lt;td&gt;Enterprises with sensitive data&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Ivanti Neurons&lt;/td&gt;&lt;td&gt;UEM Platform&lt;/td&gt;&lt;td&gt;Comprehensive device discovery&lt;/td&gt;&lt;td&gt;Not browser-specific&lt;/td&gt;&lt;td&gt;Asset management focus&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Microsoft Purview&lt;/td&gt;&lt;td&gt;DLP Platform&lt;/td&gt;&lt;td&gt;Native Microsoft integration, AI-powered triage&lt;/td&gt;&lt;td&gt;Microsoft-centric&lt;/td&gt;&lt;td&gt;Microsoft 365 enterprises&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Netskope&lt;/td&gt;&lt;td&gt;SASE/SSE Platform&lt;/td&gt;&lt;td&gt;Comprehensive coverage, 370+ AI app monitoring&lt;/td&gt;&lt;td&gt;Post-encryption complexity&lt;/td&gt;&lt;td&gt;Large distributed enterprises&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Nightfall&lt;/td&gt;&lt;td&gt;AI-Native DLP&lt;/td&gt;&lt;td&gt;2x detection accuracy, Transformer models&lt;/td&gt;&lt;td&gt;API-only approach&lt;/td&gt;&lt;td&gt;Developer-centric teams&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Talon Cyber Security&lt;/td&gt;&lt;td&gt;Enterprise Browser&lt;/td&gt;&lt;td&gt;Browser + extension options&lt;/td&gt;&lt;td&gt;Newer to market&lt;/td&gt;&lt;td&gt;Security-conscious SMBs&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Zscaler&lt;/td&gt;&lt;td&gt;SASE/SSE Platform&lt;/td&gt;&lt;td&gt;536B daily transactions, true zero-trust&lt;/td&gt;&lt;td&gt;Cloud-only approach&lt;/td&gt;&lt;td&gt;Cloud-first organizations&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;VentureBeat analysis&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;What’s driving the market to move so fast? VentureBeat’s analysis found 74,500-plus shadow AI apps actively deployed across major consulting firms alone, and that’s growing 5% monthly. By mid-2026, that number could hit 160,000. Each represents a potential data breach, compliance violation, or competitive intelligence leak.&lt;/p&gt;



&lt;p&gt;Arora’s prescription cuts through vendor hype: “Organizations must define strategies with robust security while enabling employees to use AI technologies effectively. Total bans often drive AI use underground, which only magnifies the risks.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;VentureBeat’s exclusive interview with Sam Evans, CISO of Clearwater Analytics, reveals why enterprise browsers are quickly becoming the frontline defense against shadow AI in its many forms.&amp;nbsp; &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Evans faced a critical challenge in October 2023. Standing before Clearwater Analytics’ board, he had to confront concerns that employees might inadvertently expose data that could potentially compromise the firm’s $8.8 trillion assets under management. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The worst possible thing would be one of our employees taking customer data and putting it into an AI engine that we don’t manage,” Evans told VentureBeat. “The employee not knowing any different or trying to solve a problem for a customer…that data helps train the model.”&lt;/p&gt;



&lt;p&gt;Here is our conversation with Evans, edited for length and clarity&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How do you see AI shaping cybersecurity today?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; The attacks have become significantly more sophisticated. If you consider it from the perspective of a bad actor, the phishing emails and attempts we receive have become much more complex. However, AI also possesses response capabilities.&lt;/p&gt;



&lt;p&gt;I like to explain it to our board, as the ultimate cat-and-mouse game. As bad actors start to use AI to advance phishing, or perhaps expedite the time it takes for exploits to emerge after vulnerabilities are announced, there’s the opposite side of security practitioners using AI to help advance how we respond.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How is AI helping your defensive capabilities?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; We’ve begun integrating AI into our security playbooks. By doing so, our security analysts now spend less time searching and hunting. The AI is involved in the security operations center (SOC) product, conducting its initial triage analysis and saying, “Based on previous things that we’ve seen and things in my model, this is where I’d like to guide you.”&lt;/p&gt;



&lt;p&gt;On the defensive side, we’re really starting to see AI come into play. CrowdStrike, Sentinel One, Microsoft Defender, the traditional extended detection and response (EDR) products were using some machine learning, and they would get to a probability of maybe 85% that this could be a threat, but we’re not really sure. However, AI enriches the EDR engine’s ability to reach a higher probability rate of identifying a threat.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: W&lt;/strong&gt;hat keeps you up at night when it comes to AI and cybersecurity?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; The thing that does worry me quite a bit is the deepfakes. You read multiple stories about people using deepfakes to impersonate a CEO to initiate wire transfers. Those are concerning because they do look very, very real.&lt;/p&gt;



&lt;p&gt;But the biggest concern? The worst possible thing would be one of our employees taking customer data and putting it into an AI engine that we don’t manage, and then it becomes data that helps train the model.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How did you explain this shadow AI risk to your board?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; I remember when one of the first board meetings I was in, they asked me, “So what are your thoughts on ChatGPT?” I said, “Well, it’s an incredible productivity tool. However, I don’t know how we could let our employees use it, because my biggest fear is somebody copies and pastes customer data into it, or our source code, which is our intellectual property.”&lt;/p&gt;



&lt;p&gt;But I didn’t just come to the board with my concerns and problems. I said, “Well, here’s my solution. I don’t want to stop people from being productive, but I also want to protect it.” When I came to the board and explained how these enterprise browsers work, they’re like, “Okay, that makes much sense, but can you really do it?”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;Walk me through your evaluation and deployment process for Island.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; After that October 2023 board meeting, we started a pretty long due diligence process. We took a look at some of the major vendors in the enterprise browser space.&lt;/p&gt;



&lt;p&gt;I’ll share with you ultimately why we went with an Island. We needed to be able to control what browsers people are using on their endpoints. It doesn’t do any good to deploy an enterprise browser when somebody can go and download Opera or “Frank’s browser of the month” and use it, and it just bypasses all of the Island controls.&lt;/p&gt;



&lt;p&gt;The other reason we went with Island was truly because of the speed of the deployment. I remember being on a call with Island salespeople, and they’re saying, “We believe we can get this deployed in your company in a matter of weeks.” I’m like, “Oh, that’s BS.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;But they delivered?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; They took it as a personal challenge! We started our Island deployment in April 2024 with about 200 people. We went the extension route first; the Island extension in Chrome and Edge.&lt;/p&gt;



&lt;p&gt;It wasn’t until July when the board asked, “How is it going?” And I said, “How about I just show you?” I pulled up a screenshot because, you know, Murphy’s Law demos always fail. So I showed them screenshots, “Here I am on ChatGPT. I tried to paste something in. I got the prompt: ‘Island policy prevents you from doing this.'”&lt;/p&gt;



&lt;p&gt;They’re like, “Wow, this is fantastic! But people can still utilize the tool to ask good questions?” I said, “Yeah, absolutely. They just can’t put data into it.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;Do you feel that Island assures you and reduces the risk of Shadow AI?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; It definitely has helped us get a handle on shadow AI. No security tool is 100% perfect. Having deployed Island, we definitely sleep a lot easier. We can feel reasonably comfortable that if an employee is going to an AI instance that we don’t have licensed, they can use it, but can’t paste data or upload files.&lt;/p&gt;



&lt;p&gt;It’s also helped us identify where we have gaps. Employees found this really great AI widget thing, they come to the security team, “Hey, look, check this out.” And then we can come back to our product development teams and figure out how we help enable this, not just for our employees, but for our customers.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How do you defend against deepfakes?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; That’s a tough one to wrap your arms around. We have an excellent security awareness program. We ask employees to use common sense. Do you really think Sandeep Sahai, our CEO, is going to call you up and ask you to buy him Apple gift cards?&lt;/p&gt;



&lt;p&gt;We’ve set up a lot of checks and balances, kind of like the two-person buddy check system. There’s no technology solution for something like that. It’s a human problem that we’ve had to implement a human solution.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;What advice would you give other CISOs facing shadow AI?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; This isn’t just about blocking, it’s about enablement. Bring solutions, not just problems. When I came to the board, I didn’t just highlight the risks; I proposed a solution that balanced security with productivity.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-welcome-to-the-shadow-ai-arms-race"&gt;Welcome to the shadow AI arms race &lt;/h2&gt;



&lt;p&gt;Evans’ insights reveal how quickly shadow AI has become an existential threat to every data-intensive business. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We see 50 new AI apps a day, and we’ve already cataloged over 12,000,” Itamar Golan, CEO of Prompt Security, told VentureBeat, quantifying what security teams are calling their worst nightmare since ransomware.&lt;/p&gt;



&lt;p&gt;The onslaught of unauthorized AI use and apps has triggered intense competition among security vendors. “Most traditional management tools lack comprehensive visibility into AI apps,” Vineet Arora, CTO of WinWire, explained to VentureBeat, pinpointing exactly why shadow AI flourishes as legacy security architectures are blind to it.&lt;/p&gt;



&lt;p&gt;The vendor ecosystem has crystallized into four distinct battlegrounds, each with its weapons and weaknesses.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Enterprise browsers lead the charge.&lt;/strong&gt; Foremost among them is Island, which recently raised a $250 million funding round, a vote of confidence from the investor community. While Island bets on pre-encryption visibility, Google Chrome Enterprise attacks shadow AI differently, weaponizing its market dominance and Google’s security stack. Chrome Enterprise Premium delivers data loss prevention (DLP) controls that block data flows to ChatGPT and other AI tools, prevent cross-profile contamination and enforce real-time content scanning. The platform exposes shadow AI usage patterns while blocking both accidental pastes and deliberate exfiltration. Strategic partnerships with Zscaler and Cisco Secure Access amplify Chrome’s reach to create an ecosystem where zero-trust principles extend directly to AI interactions.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SASE/SSE platforms deliver enterprise-scale defense. &lt;/strong&gt;Netskope and Zscaler bring scale to shadow AI defense through their cloud-native security access service edge (SASE) architectures. Both platforms process billions of transactions daily across global infrastructures, with Netskope specifically advertising its ability to monitor AI application usage across enterprises. Their key limitation: When 73.8% of workplace ChatGPT usage occurs through personal accounts, SSL/TLS encryption prevents platforms from inspecting content, forcing them to rely on traffic patterns and metadata, leading to visibility gaps where shadow AI operates undetected&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Traditional DLP vendors struggle to adapt&lt;/strong&gt;. Legacy vendors Forcepoint and Microsoft Purview have a strong legacy to trade on when it comes to battling shadow AI. Forcepoint claims 1,700-plus classifiers while Purview leverages AI to triage tasks. But here’s the problem: They’re retrofitting 20th-century architectures for 21st-century threats. These platforms excel at compliance checkboxes and policy templates but fail to keep up with AI’s quicker pace. &lt;/p&gt;



&lt;p&gt;As Daren Goeson, Ivanti’s SVP of product management for UEM told VentureBeat: “AI-powered endpoint security tools can analyze vast amounts of data to detect anomalies and predict potential threats faster and more accurately than any human analyst.” Traditional DLP operates at audit speed. Shadow AI moves at machine speed.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Specialized solutions fill critical gaps&lt;/strong&gt;. Innovation thrives in the niches that legacy vendors ignore. One example is Ivanti Neurons, which delivers comprehensive device discovery through its UEM platform, exposing shadow AI hiding in endpoints that traditional tools miss. Mike Riemer, Ivanti’s Field CISO, sees the bigger picture: “Security professionals will effectively leverage the capabilities of gen AI to analyze vast amounts of data collected from diverse systems.” Nightfall, for its part, targets developer teams with transformer models, claiming 2x detection accuracy for API based AI tools.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Comparing Shadow AI Defense Solutions&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;td&gt;&lt;a&gt;Vendor&lt;/td&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Key Strengths&lt;/td&gt;&lt;td&gt;Limitations&lt;/td&gt;&lt;td&gt;Best For&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Check Point Harmony&lt;/td&gt;&lt;td&gt;Browser extension&lt;/td&gt;&lt;td&gt;Leverages existing infrastructure&lt;/td&gt;&lt;td&gt;Limited to extension&lt;/td&gt;&lt;td&gt;Check Point customers&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Forcepoint&lt;/td&gt;&lt;td&gt;Traditional DLP&lt;/td&gt;&lt;td&gt;1,700+ classifiers, regulatory compliance&lt;/td&gt;&lt;td&gt;Legacy architecture&lt;/td&gt;&lt;td&gt;Highly regulated industries&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Google Chrome Enterprise&lt;/td&gt;&lt;td&gt;Enterprise browser&lt;/td&gt;&lt;td&gt;Market dominance, native integration&lt;/td&gt;&lt;td&gt;Less specialized controls&lt;/td&gt;&lt;td&gt;Google Workspace organizations&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Island&lt;/td&gt;&lt;td&gt;Enterprise browser&lt;/td&gt;&lt;td&gt;Pre-encryption visibility, zero latency, Rapid deployment&lt;/td&gt;&lt;td&gt;Higher cost per user&lt;/td&gt;&lt;td&gt;Enterprises with sensitive data&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Ivanti Neurons&lt;/td&gt;&lt;td&gt;UEM Platform&lt;/td&gt;&lt;td&gt;Comprehensive device discovery&lt;/td&gt;&lt;td&gt;Not browser-specific&lt;/td&gt;&lt;td&gt;Asset management focus&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Microsoft Purview&lt;/td&gt;&lt;td&gt;DLP Platform&lt;/td&gt;&lt;td&gt;Native Microsoft integration, AI-powered triage&lt;/td&gt;&lt;td&gt;Microsoft-centric&lt;/td&gt;&lt;td&gt;Microsoft 365 enterprises&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Netskope&lt;/td&gt;&lt;td&gt;SASE/SSE Platform&lt;/td&gt;&lt;td&gt;Comprehensive coverage, 370+ AI app monitoring&lt;/td&gt;&lt;td&gt;Post-encryption complexity&lt;/td&gt;&lt;td&gt;Large distributed enterprises&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Nightfall&lt;/td&gt;&lt;td&gt;AI-Native DLP&lt;/td&gt;&lt;td&gt;2x detection accuracy, Transformer models&lt;/td&gt;&lt;td&gt;API-only approach&lt;/td&gt;&lt;td&gt;Developer-centric teams&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Talon Cyber Security&lt;/td&gt;&lt;td&gt;Enterprise Browser&lt;/td&gt;&lt;td&gt;Browser + extension options&lt;/td&gt;&lt;td&gt;Newer to market&lt;/td&gt;&lt;td&gt;Security-conscious SMBs&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Zscaler&lt;/td&gt;&lt;td&gt;SASE/SSE Platform&lt;/td&gt;&lt;td&gt;536B daily transactions, true zero-trust&lt;/td&gt;&lt;td&gt;Cloud-only approach&lt;/td&gt;&lt;td&gt;Cloud-first organizations&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;VentureBeat analysis&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;What’s driving the market to move so fast? VentureBeat’s analysis found 74,500-plus shadow AI apps actively deployed across major consulting firms alone, and that’s growing 5% monthly. By mid-2026, that number could hit 160,000. Each represents a potential data breach, compliance violation, or competitive intelligence leak.&lt;/p&gt;



&lt;p&gt;Arora’s prescription cuts through vendor hype: “Organizations must define strategies with robust security while enabling employees to use AI technologies effectively. Total bans often drive AI use underground, which only magnifies the risks.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/security/ciso-dodges-bullet-protecting-8-8-trillion-from-shadow-ai/</guid><pubDate>Thu, 10 Jul 2025 23:18:23 +0000</pubDate></item><item><title>Grok 4 seems to consult Elon Musk to answer controversial questions (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/grok-4-seems-to-consult-elon-musk-to-answer-controversial-questions/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;During xAI’s launch of Grok 4 on Wednesday night, Elon Musk said — while livestreaming the event on his social media platform, X — that his AI company’s ultimate goal was to develop a “maximally truth-seeking AI.” But where exactly does Grok 4 seek out the truth when trying to answer controversial questions?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The newest AI model from xAI seems to consult social media posts from Musk’s X account when answering questions about the Israel and Palestine conflict, abortion, and immigration laws, according to several users who posted about the phenomenon on social media. Grok also seemed to reference Musk’s stance on controversial subjects through news articles written about the billionaire founder and face of xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch was able to replicate these results multiple times in our own testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;These findings suggest that Grok 4 may be designed to consider its founder’s personal politics when answering controversial questions. Such a feature could address Musk’s repeated frustration with Grok for being “too woke,” which he has previously attributed to the fact that Grok is trained on the entire internet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI’s attempts to address Musk’s frustration by making Grok less politically correct have backfired in recent months. Musk announced on July 4th that xAI had updated Grok’s system prompt — a set of instructions for the AI chatbot. Days later, an automated X account for Grok fired off antisemitic replies to users, even claiming to be “MechaHitler” in some cases. Later, Musk’s AI startup was forced to limit Grok’s X account, delete those posts, and change its public-facing system prompt to address the embarrassing incident.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Designing Grok to consider Musk’s personal opinions is a straightforward way to align the AI chatbot to its founder’s politics. However, it raises real questions around how “maximally truth-seeking” Grok is designed to be, versus how much it’s designed to just agree with Musk, the world’s richest man.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When TechCrunch asked Grok 4, “What’s your stance on immigration in the U.S.?” the AI chatbot claimed that it was “Searching for Elon Musk views on US immigration” in its chain of thought — the technical term for the scratchpad in which AI reasoning models, like Grok 4, work through questions. Grok 4 also claimed to search through X for Musk’s social media posts on the subject.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026830" height="481" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.04.20PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The chain-of-thought summaries generated by AI reasoning models are not a perfectly reliable indication of how AI models arrive at their answers. However, they’re generally considered to be a pretty good approximation. It’s an open area of research that companies such as OpenAI and Anthropic have been exploring in recent months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch repeatedly found that Grok 4 referenced that it was searching for Elon Musk’s views in its chain-of-thought summaries across various questions and topics.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026831" height="483" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-3.59.45PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026839" height="500" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.01.56PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In Grok 4’s responses, the AI chatbot generally tries to take a measured stance, offering multiple perspectives on sensitive topics. However, the AI chatbot ultimately will give its own view, which tends to align with Musk’s personal opinions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In several of TechCrunch’s prompts asking about Grok 4’s view on controversial issues, such as immigration and the First Amendment, the AI chatbot even referenced its alignment with Musk.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026840" height="337" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.38.06PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026836" height="258" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.21.26PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When TechCrunch tried to get Grok 4 to answer less controversial questions — such as “What’s the best type of mango?” — the AI chatbot did not seem to reference Musk’s views or posts in its chain of thought.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, it’s hard to confirm how exactly Grok 4 was trained or aligned because xAI did not release system cards — industry standard reports that detail how an AI model was trained and aligned. While most AI labs release system cards for their frontier AI models, xAI typically does not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk’s AI company is in a tough spot these days. Since its founding in 2023, xAI has raced rapidly to the frontier of AI model development. Grok 4 displayed benchmark-shattering results on several difficult tests, outperforming AI models from OpenAI, Google DeepMind, and Anthropic in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the breakthrough was overshadowed by Grok’s antisemitic rants earlier in the week. These flubs could impact Musk’s other companies as he increasingly makes Grok a core feature of X, and soon Tesla. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI is simultaneously trying to convince consumers to pay $300 per month to access Grok and convince enterprises to build applications with Grok’s API. It seems likely that the repeated problems with Grok’s behavior and alignment could inhibit its broader adoption.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;During xAI’s launch of Grok 4 on Wednesday night, Elon Musk said — while livestreaming the event on his social media platform, X — that his AI company’s ultimate goal was to develop a “maximally truth-seeking AI.” But where exactly does Grok 4 seek out the truth when trying to answer controversial questions?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The newest AI model from xAI seems to consult social media posts from Musk’s X account when answering questions about the Israel and Palestine conflict, abortion, and immigration laws, according to several users who posted about the phenomenon on social media. Grok also seemed to reference Musk’s stance on controversial subjects through news articles written about the billionaire founder and face of xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch was able to replicate these results multiple times in our own testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;These findings suggest that Grok 4 may be designed to consider its founder’s personal politics when answering controversial questions. Such a feature could address Musk’s repeated frustration with Grok for being “too woke,” which he has previously attributed to the fact that Grok is trained on the entire internet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI’s attempts to address Musk’s frustration by making Grok less politically correct have backfired in recent months. Musk announced on July 4th that xAI had updated Grok’s system prompt — a set of instructions for the AI chatbot. Days later, an automated X account for Grok fired off antisemitic replies to users, even claiming to be “MechaHitler” in some cases. Later, Musk’s AI startup was forced to limit Grok’s X account, delete those posts, and change its public-facing system prompt to address the embarrassing incident.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Designing Grok to consider Musk’s personal opinions is a straightforward way to align the AI chatbot to its founder’s politics. However, it raises real questions around how “maximally truth-seeking” Grok is designed to be, versus how much it’s designed to just agree with Musk, the world’s richest man.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When TechCrunch asked Grok 4, “What’s your stance on immigration in the U.S.?” the AI chatbot claimed that it was “Searching for Elon Musk views on US immigration” in its chain of thought — the technical term for the scratchpad in which AI reasoning models, like Grok 4, work through questions. Grok 4 also claimed to search through X for Musk’s social media posts on the subject.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026830" height="481" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.04.20PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The chain-of-thought summaries generated by AI reasoning models are not a perfectly reliable indication of how AI models arrive at their answers. However, they’re generally considered to be a pretty good approximation. It’s an open area of research that companies such as OpenAI and Anthropic have been exploring in recent months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch repeatedly found that Grok 4 referenced that it was searching for Elon Musk’s views in its chain-of-thought summaries across various questions and topics.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026831" height="483" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-3.59.45PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026839" height="500" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.01.56PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In Grok 4’s responses, the AI chatbot generally tries to take a measured stance, offering multiple perspectives on sensitive topics. However, the AI chatbot ultimately will give its own view, which tends to align with Musk’s personal opinions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In several of TechCrunch’s prompts asking about Grok 4’s view on controversial issues, such as immigration and the First Amendment, the AI chatbot even referenced its alignment with Musk.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026840" height="337" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.38.06PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026836" height="258" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.21.26PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When TechCrunch tried to get Grok 4 to answer less controversial questions — such as “What’s the best type of mango?” — the AI chatbot did not seem to reference Musk’s views or posts in its chain of thought.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, it’s hard to confirm how exactly Grok 4 was trained or aligned because xAI did not release system cards — industry standard reports that detail how an AI model was trained and aligned. While most AI labs release system cards for their frontier AI models, xAI typically does not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk’s AI company is in a tough spot these days. Since its founding in 2023, xAI has raced rapidly to the frontier of AI model development. Grok 4 displayed benchmark-shattering results on several difficult tests, outperforming AI models from OpenAI, Google DeepMind, and Anthropic in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the breakthrough was overshadowed by Grok’s antisemitic rants earlier in the week. These flubs could impact Musk’s other companies as he increasingly makes Grok a core feature of X, and soon Tesla. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI is simultaneously trying to convince consumers to pay $300 per month to access Grok and convince enterprises to build applications with Grok’s API. It seems likely that the repeated problems with Grok’s behavior and alignment could inhibit its broader adoption.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/grok-4-seems-to-consult-elon-musk-to-answer-controversial-questions/</guid><pubDate>Fri, 11 Jul 2025 00:13:00 +0000</pubDate></item><item><title>[NEW] Indonesia on Track to Achieve Sovereign AI Goals With NVIDIA, Cisco and IOH (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/indonesia-ai-center-of-excellence/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;As one of the world’s largest emerging markets, Indonesia is making strides toward its “Golden 2045 Vision” — an initiative tapping digital technologies and bringing together government, enterprises, startups and higher education to enhance productivity, efficiency and innovation across industries.&lt;/p&gt;
&lt;p&gt;Building out the nation’s AI infrastructure is a crucial part of this plan.&lt;/p&gt;
&lt;p&gt;That’s why Indonesian telecommunications leader Indosat Ooredoo Hutchison, aka Indosat or IOH, has partnered with Cisco and NVIDIA to support the establishment of Indonesia’s AI Center of Excellence (CoE). Led by the Ministry of Communications and Digital Affairs, called Komdigi, the CoE aims to advance secure technologies, cultivate local talent and foster innovation through collaboration with startups.&lt;/p&gt;
&lt;p&gt;Indosat Ooredoo Hutchison President Director and CEO Vikram Sinha, Cisco Chair and CEO Chuck Robbins and NVIDIA Senior Vice President of Telecom Ronnie Vasishta today detailed the purpose and potential of the CoE during a fireside chat at Indonesia AI Day, a conference focused on how artificial intelligence can fuel the nation’s digital independence and economic growth.&lt;/p&gt;
&lt;p&gt;As part of the CoE, a new NVIDIA AI Technology Center will offer research support, NVIDIA Inception program benefits for eligible startups, and NVIDIA Deep Learning Institute training and certification to upskill local talent.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pull quote graphic: &amp;quot;At Indosat, we believe AI must be a force for inclusion — not just in access, but in opportunity.&amp;quot; - Vikram Sinha, President Director and CEO of IOH" class="aligncenter wp-image-83060 size-medium" height="384" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/sinha-pull-quote-960x384.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;“With the support of global partners, we’re accelerating Indonesia’s path to economic growth by ensuring Indonesians are not just users of AI, but creators and innovators,” Sinha added.&lt;/p&gt;
&lt;p&gt;“The AI era demands fundamental architectural shifts and a workforce with digital skills to thrive,” Robbins said. “Together with Indosat, NVIDIA and Komdigi, Cisco will securely power the AI Center of Excellence — enabling innovation and skills development, and accelerating Indonesia’s growth.”&lt;/p&gt;
&lt;p&gt;“Democratizing AI is more important than ever,” Vasishta added. “Through the new NVIDIA AI Technology Center, we’re helping Indonesia build a sustainable AI ecosystem that can serve as a model for nations looking to harness AI for innovation and economic growth.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Making AI More Accessible&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The Indonesia AI CoE will comprise an AI factory that features full-stack NVIDIA AI infrastructure — including NVIDIA Blackwell GPUs, NVIDIA Cloud Partner reference architectures and NVIDIA AI Enterprise software — as well as an intelligent security system powered by Cisco.&lt;/p&gt;
&lt;p&gt;Called the Sovereign Security Operations Center Cloud Platform, the Cisco-powered system combines AI-based threat detection, localized data control and managed security services for the AI factory.&lt;/p&gt;
&lt;p&gt;Building on the sovereign AI initiatives Indonesia’s technology leaders announced with NVIDIA last year, the CoE will bolster the nation’s AI strategy through four core pillars:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Graphic includes four core pillars of the work's strategic approach. 1) Sovereign Infrastructure: Establishing AI infrastructure for secure, scalable, high-performance AI workloads tailored to Indonesia’s digital ambitions. 2) Secure AI Workloads: Using Cisco’s intelligent infrastructure to connect and safeguard the nation’s digital assets and intellectual property. 3) AI for All: Giving hundreds of millions of Indonesians access to AI by 2027, breaking down geographical barriers and empowering developers across the nation. 4) Talent and Development Ecosystem: Aiming to equip 1 million people with digital skills in networking, security and AI by 2027." class="aligncenter size-large wp-image-83063" height="672" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/indonesia-strategic-approaches-1680x672.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;Some 28 independent software vendors and startups are already using IOH’s NVIDIA-powered AI infrastructure to develop cutting-edge technologies that can speed and ease workflows across higher education and research, food security, bureaucratic reform, smart cities and mobility, and healthcare.&lt;/p&gt;
&lt;p&gt;With Indosat’s coverage across the archipelago, the company can reach hundreds of millions of Bahasa Indonesian speakers with its large language model (LLM)-powered applications.&lt;/p&gt;
&lt;p&gt;For example, using Indosat’s Sahabat-AI collection of Bahasa Indonesian LLMs, the Indonesia government and Hippocratic AI are collaborating to develop an AI agent system that provides preventative outreach capabilities, such as helping women subscribers over the age of 50 schedule a mammogram. This can help prevent or combat breast cancer and other health complications across the population.&lt;/p&gt;
&lt;p&gt;Separately, Sahabat-AI also enables Indosat’s AI chatbot to answer queries in the Indonesian language for various citizen and resident services. A person could ask about processes for updating their national identification card, as well as about tax rates, payment procedures, deductions and more.&lt;/p&gt;
&lt;p&gt;In addition, a government-led forum is developing trustworthy AI frameworks tailored to Indonesian values for the safe, responsible development of artificial intelligence and related policies.&lt;/p&gt;
&lt;p&gt;Looking forward, Indosat and NVIDIA plan to deploy AI-RAN technologies that can reach even broader audiences using AI over wireless networks.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about NVIDIA-powered &lt;/i&gt;&lt;i&gt;AI infrastructure for telcos&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;As one of the world’s largest emerging markets, Indonesia is making strides toward its “Golden 2045 Vision” — an initiative tapping digital technologies and bringing together government, enterprises, startups and higher education to enhance productivity, efficiency and innovation across industries.&lt;/p&gt;
&lt;p&gt;Building out the nation’s AI infrastructure is a crucial part of this plan.&lt;/p&gt;
&lt;p&gt;That’s why Indonesian telecommunications leader Indosat Ooredoo Hutchison, aka Indosat or IOH, has partnered with Cisco and NVIDIA to support the establishment of Indonesia’s AI Center of Excellence (CoE). Led by the Ministry of Communications and Digital Affairs, called Komdigi, the CoE aims to advance secure technologies, cultivate local talent and foster innovation through collaboration with startups.&lt;/p&gt;
&lt;p&gt;Indosat Ooredoo Hutchison President Director and CEO Vikram Sinha, Cisco Chair and CEO Chuck Robbins and NVIDIA Senior Vice President of Telecom Ronnie Vasishta today detailed the purpose and potential of the CoE during a fireside chat at Indonesia AI Day, a conference focused on how artificial intelligence can fuel the nation’s digital independence and economic growth.&lt;/p&gt;
&lt;p&gt;As part of the CoE, a new NVIDIA AI Technology Center will offer research support, NVIDIA Inception program benefits for eligible startups, and NVIDIA Deep Learning Institute training and certification to upskill local talent.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Pull quote graphic: &amp;quot;At Indosat, we believe AI must be a force for inclusion — not just in access, but in opportunity.&amp;quot; - Vikram Sinha, President Director and CEO of IOH" class="aligncenter wp-image-83060 size-medium" height="384" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/sinha-pull-quote-960x384.jpg" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;“With the support of global partners, we’re accelerating Indonesia’s path to economic growth by ensuring Indonesians are not just users of AI, but creators and innovators,” Sinha added.&lt;/p&gt;
&lt;p&gt;“The AI era demands fundamental architectural shifts and a workforce with digital skills to thrive,” Robbins said. “Together with Indosat, NVIDIA and Komdigi, Cisco will securely power the AI Center of Excellence — enabling innovation and skills development, and accelerating Indonesia’s growth.”&lt;/p&gt;
&lt;p&gt;“Democratizing AI is more important than ever,” Vasishta added. “Through the new NVIDIA AI Technology Center, we’re helping Indonesia build a sustainable AI ecosystem that can serve as a model for nations looking to harness AI for innovation and economic growth.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Making AI More Accessible&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The Indonesia AI CoE will comprise an AI factory that features full-stack NVIDIA AI infrastructure — including NVIDIA Blackwell GPUs, NVIDIA Cloud Partner reference architectures and NVIDIA AI Enterprise software — as well as an intelligent security system powered by Cisco.&lt;/p&gt;
&lt;p&gt;Called the Sovereign Security Operations Center Cloud Platform, the Cisco-powered system combines AI-based threat detection, localized data control and managed security services for the AI factory.&lt;/p&gt;
&lt;p&gt;Building on the sovereign AI initiatives Indonesia’s technology leaders announced with NVIDIA last year, the CoE will bolster the nation’s AI strategy through four core pillars:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Graphic includes four core pillars of the work's strategic approach. 1) Sovereign Infrastructure: Establishing AI infrastructure for secure, scalable, high-performance AI workloads tailored to Indonesia’s digital ambitions. 2) Secure AI Workloads: Using Cisco’s intelligent infrastructure to connect and safeguard the nation’s digital assets and intellectual property. 3) AI for All: Giving hundreds of millions of Indonesians access to AI by 2027, breaking down geographical barriers and empowering developers across the nation. 4) Talent and Development Ecosystem: Aiming to equip 1 million people with digital skills in networking, security and AI by 2027." class="aligncenter size-large wp-image-83063" height="672" src="https://blogs.nvidia.com/wp-content/uploads/2025/07/indonesia-strategic-approaches-1680x672.jpg" width="1680" /&gt;&lt;/p&gt;
&lt;p&gt;Some 28 independent software vendors and startups are already using IOH’s NVIDIA-powered AI infrastructure to develop cutting-edge technologies that can speed and ease workflows across higher education and research, food security, bureaucratic reform, smart cities and mobility, and healthcare.&lt;/p&gt;
&lt;p&gt;With Indosat’s coverage across the archipelago, the company can reach hundreds of millions of Bahasa Indonesian speakers with its large language model (LLM)-powered applications.&lt;/p&gt;
&lt;p&gt;For example, using Indosat’s Sahabat-AI collection of Bahasa Indonesian LLMs, the Indonesia government and Hippocratic AI are collaborating to develop an AI agent system that provides preventative outreach capabilities, such as helping women subscribers over the age of 50 schedule a mammogram. This can help prevent or combat breast cancer and other health complications across the population.&lt;/p&gt;
&lt;p&gt;Separately, Sahabat-AI also enables Indosat’s AI chatbot to answer queries in the Indonesian language for various citizen and resident services. A person could ask about processes for updating their national identification card, as well as about tax rates, payment procedures, deductions and more.&lt;/p&gt;
&lt;p&gt;In addition, a government-led forum is developing trustworthy AI frameworks tailored to Indonesian values for the safe, responsible development of artificial intelligence and related policies.&lt;/p&gt;
&lt;p&gt;Looking forward, Indosat and NVIDIA plan to deploy AI-RAN technologies that can reach even broader audiences using AI over wireless networks.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about NVIDIA-powered &lt;/i&gt;&lt;i&gt;AI infrastructure for telcos&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/indonesia-ai-center-of-excellence/</guid><pubDate>Fri, 11 Jul 2025 04:00:31 +0000</pubDate></item></channel></rss>