<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 12 Aug 2025 06:34:21 +0000</lastBuildDate><item><title>Sam Altman and the whale (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/11/1121402/sam-altman-and-the-whale/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-834552814.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;My colleague Grace Huckins has a great story on OpenAI’s release of GPT-5, its long-awaited new flagship model. One of the takeaways, however, is that while GPT-5 may make for a better experience than the previous versions, it isn’t something revolutionary. “GPT-5 is, above all else,” Grace concludes, “a refined product.”&lt;/p&gt;  &lt;p&gt;This is pretty much in line with my colleague Will Heaven’s recent argument that the latest model releases have been a bit like smartphone releases: Increasingly, what we are seeing are incremental improvements meant to enhance the user experience. (Casey Newton made a similar point in Friday’s &lt;em&gt;Platformer&lt;/em&gt;.) At GPT-5’s release on Thursday, OpenAI CEO Sam Altman himself compared it to when Apple released the first iPhone with a Retina display. Okay. Sure.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But where is the transition from the BlackBerry keyboard to the touch-screen iPhone? Where is the assisted GPS and the API for location services that enables real-time directions and gives rise to companies like Uber and Grindr and lets me order a taxi for my burrito? Where are the real breakthroughs?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In fact, following the release of GPT-5, OpenAI found itself with something of a user revolt on its hands. Customers who missed GPT-4o's personality successfully lobbied the company to bring it back as an option for its Plus users. If anything, that indicates the GPT-5 release was more about user experience than noticeable performance enhancements. &lt;/p&gt; 
 &lt;p&gt;And yet, hours before OpenAI’s GPT-5 announcement, Altman teased it by tweeting an image of an emerging Death Star floating in space. On Thursday, he touted its PhD-level intelligence. He then went on the &lt;em&gt;Mornings with Maria&lt;/em&gt; show to claim it would “save a lot of lives.” (Forgive my extreme skepticism of that particular brand of claim, but we’ve certainly seen it before.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s a lot of hype, but Altman is not alone in his Flavor Flav-ing here. Last week Mark Zuckerberg published a long memo about how we are approaching AI superintelligence. Anthropic CEO Dario Amodei freaked basically everyone out earlier this year with his prediction that AI would harvest half of all entry-level jobs within, possibly, a year.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The people running these companies literally talk about the danger that the things they are building might take over the world and kill every human on the planet. GPT-5, meanwhile, still can’t tell you how many b’s there are in the word “blueberry.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is not to say that the products released by OpenAI or Anthropic or what have you are not impressive. They are. And they clearly have a good deal of utility. But the hype cycle around model releases is out of hand.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I say that as one of those people who use ChatGPT or Google Gemini most days, often multiple times a day. This week, for example, my wife was surfing and encountered a whale repeatedly slapping its tail on the water. Despite having seen very many whales, often in very close proximity, she had never seen anything like this. She sent me a video, and I was curious about it too. So I asked ChatGPT, “Why do whales slap their tails repeatedly on the water?” It came right back, confidently explaining that what I was describing was called “lobtailing,” along with a list of possible reasons why whales do that. Pretty cool.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But then again, a regular garden-variety Google search would &lt;em&gt;also&lt;/em&gt; have led me to discover lobtailing. And while ChatGPT’s response summarized the behavior for me, it was also too definitive about why whales do it. The reality is that while people have a lot of theories, we still can’t really explain this weird animal behavior.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;The reason I’m aware that lobtailing is something of a mystery is that I dug into actual, you know, search results. Which is where I encountered this beautiful, elegiac essay by Emily Boring. She describes her time at sea, watching a humpback slapping its tail against the water, and discusses the scientific uncertainty around this behavior. Is it a feeding technique? Is it a form of communication? Posturing? The action, as she notes, is extremely energy intensive. It takes a lot of effort from the whale. Why do they do it?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I was struck by one passage in particular, in which she cites another biologist’s work to draw a conclusion of her own:&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;em&gt;Surprisingly, the complex energy trade-off of a tail-slap might be the exact reason why it’s used. Biologist Hal Whitehead suggests, “Breaches and lob-tails make good signals precisely because they are energetically expensive and thus indicative of the importance of the message and the physical status of the signaler.” A tail-slap means that a whale is physically fit, traveling at nearly maximum speed, capable of sustaining powerful activity, and carrying a message so crucial it is willing to use a huge portion of its daily energy to share it. “Pay attention!” the whale seems to say. “I am important! Notice me!”&lt;/em&gt;&lt;/h4&gt;    &lt;p&gt;In some ways, the AI hype cycle &lt;em&gt;has&lt;/em&gt; to be out of hand. It &lt;em&gt;has&lt;/em&gt; to justify the ferocious level of investment, the uncountable billions of dollars in sunk costs. The massive data center buildouts with their massive environmental consequences created at massive expense that are seemingly keeping the economy afloat &lt;em&gt;and&lt;/em&gt; threatening to crash it. There is so, so, &lt;em&gt;so&lt;/em&gt; much money at stake.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Which is not to say there aren’t really cool things happening in AI. And certainly there have been a number of moments when I have been floored by AI releases. ChatGPT 3.5 was one. Dall-E, NotebookLM, Veo 3, Synthesia. They can amaze. In fact there was an AI product release just this week that was a little bit mind-blowing. Genie 3, from Google DeepMind, can turn a basic text prompt into an immersive and navigable 3D world. Check it out—it’s pretty wild. And yet Genie 3 also makes a case that the most interesting things happening right now in AI aren’t happening in chatbots.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I’d even argue that at this point, most of the people who are regularly amazed by the feats of new LLM chatbot releases are the same people who stand to profit from the promotion of LLM chatbots.&lt;/p&gt;  &lt;p&gt;Maybe I’m being cynical, but I don’t think so. I think it’s more cynical to promise me the Death Star and instead deliver a chatbot whose chief appeal seems to be that it automatically picks the model for you. To promise me superintelligence and deliver shrimp Jesus. It’s all just a lot of lobtailing. “Pay attention! I am important! Notice me!”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Debrief, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s subscriber-only weekly email newsletter from editor in chief Mat Honan. Subscribers can &lt;/em&gt;&lt;em&gt;sign up here to receive it in your inbox&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/GettyImages-834552814.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;My colleague Grace Huckins has a great story on OpenAI’s release of GPT-5, its long-awaited new flagship model. One of the takeaways, however, is that while GPT-5 may make for a better experience than the previous versions, it isn’t something revolutionary. “GPT-5 is, above all else,” Grace concludes, “a refined product.”&lt;/p&gt;  &lt;p&gt;This is pretty much in line with my colleague Will Heaven’s recent argument that the latest model releases have been a bit like smartphone releases: Increasingly, what we are seeing are incremental improvements meant to enhance the user experience. (Casey Newton made a similar point in Friday’s &lt;em&gt;Platformer&lt;/em&gt;.) At GPT-5’s release on Thursday, OpenAI CEO Sam Altman himself compared it to when Apple released the first iPhone with a Retina display. Okay. Sure.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But where is the transition from the BlackBerry keyboard to the touch-screen iPhone? Where is the assisted GPS and the API for location services that enables real-time directions and gives rise to companies like Uber and Grindr and lets me order a taxi for my burrito? Where are the real breakthroughs?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In fact, following the release of GPT-5, OpenAI found itself with something of a user revolt on its hands. Customers who missed GPT-4o's personality successfully lobbied the company to bring it back as an option for its Plus users. If anything, that indicates the GPT-5 release was more about user experience than noticeable performance enhancements. &lt;/p&gt; 
 &lt;p&gt;And yet, hours before OpenAI’s GPT-5 announcement, Altman teased it by tweeting an image of an emerging Death Star floating in space. On Thursday, he touted its PhD-level intelligence. He then went on the &lt;em&gt;Mornings with Maria&lt;/em&gt; show to claim it would “save a lot of lives.” (Forgive my extreme skepticism of that particular brand of claim, but we’ve certainly seen it before.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s a lot of hype, but Altman is not alone in his Flavor Flav-ing here. Last week Mark Zuckerberg published a long memo about how we are approaching AI superintelligence. Anthropic CEO Dario Amodei freaked basically everyone out earlier this year with his prediction that AI would harvest half of all entry-level jobs within, possibly, a year.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The people running these companies literally talk about the danger that the things they are building might take over the world and kill every human on the planet. GPT-5, meanwhile, still can’t tell you how many b’s there are in the word “blueberry.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is not to say that the products released by OpenAI or Anthropic or what have you are not impressive. They are. And they clearly have a good deal of utility. But the hype cycle around model releases is out of hand.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I say that as one of those people who use ChatGPT or Google Gemini most days, often multiple times a day. This week, for example, my wife was surfing and encountered a whale repeatedly slapping its tail on the water. Despite having seen very many whales, often in very close proximity, she had never seen anything like this. She sent me a video, and I was curious about it too. So I asked ChatGPT, “Why do whales slap their tails repeatedly on the water?” It came right back, confidently explaining that what I was describing was called “lobtailing,” along with a list of possible reasons why whales do that. Pretty cool.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But then again, a regular garden-variety Google search would &lt;em&gt;also&lt;/em&gt; have led me to discover lobtailing. And while ChatGPT’s response summarized the behavior for me, it was also too definitive about why whales do it. The reality is that while people have a lot of theories, we still can’t really explain this weird animal behavior.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;The reason I’m aware that lobtailing is something of a mystery is that I dug into actual, you know, search results. Which is where I encountered this beautiful, elegiac essay by Emily Boring. She describes her time at sea, watching a humpback slapping its tail against the water, and discusses the scientific uncertainty around this behavior. Is it a feeding technique? Is it a form of communication? Posturing? The action, as she notes, is extremely energy intensive. It takes a lot of effort from the whale. Why do they do it?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I was struck by one passage in particular, in which she cites another biologist’s work to draw a conclusion of her own:&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;em&gt;Surprisingly, the complex energy trade-off of a tail-slap might be the exact reason why it’s used. Biologist Hal Whitehead suggests, “Breaches and lob-tails make good signals precisely because they are energetically expensive and thus indicative of the importance of the message and the physical status of the signaler.” A tail-slap means that a whale is physically fit, traveling at nearly maximum speed, capable of sustaining powerful activity, and carrying a message so crucial it is willing to use a huge portion of its daily energy to share it. “Pay attention!” the whale seems to say. “I am important! Notice me!”&lt;/em&gt;&lt;/h4&gt;    &lt;p&gt;In some ways, the AI hype cycle &lt;em&gt;has&lt;/em&gt; to be out of hand. It &lt;em&gt;has&lt;/em&gt; to justify the ferocious level of investment, the uncountable billions of dollars in sunk costs. The massive data center buildouts with their massive environmental consequences created at massive expense that are seemingly keeping the economy afloat &lt;em&gt;and&lt;/em&gt; threatening to crash it. There is so, so, &lt;em&gt;so&lt;/em&gt; much money at stake.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Which is not to say there aren’t really cool things happening in AI. And certainly there have been a number of moments when I have been floored by AI releases. ChatGPT 3.5 was one. Dall-E, NotebookLM, Veo 3, Synthesia. They can amaze. In fact there was an AI product release just this week that was a little bit mind-blowing. Genie 3, from Google DeepMind, can turn a basic text prompt into an immersive and navigable 3D world. Check it out—it’s pretty wild. And yet Genie 3 also makes a case that the most interesting things happening right now in AI aren’t happening in chatbots.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I’d even argue that at this point, most of the people who are regularly amazed by the feats of new LLM chatbot releases are the same people who stand to profit from the promotion of LLM chatbots.&lt;/p&gt;  &lt;p&gt;Maybe I’m being cynical, but I don’t think so. I think it’s more cynical to promise me the Death Star and instead deliver a chatbot whose chief appeal seems to be that it automatically picks the model for you. To promise me superintelligence and deliver shrimp Jesus. It’s all just a lot of lobtailing. “Pay attention! I am important! Notice me!”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Debrief, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s subscriber-only weekly email newsletter from editor in chief Mat Honan. Subscribers can &lt;/em&gt;&lt;em&gt;sign up here to receive it in your inbox&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/11/1121402/sam-altman-and-the-whale/</guid><pubDate>Mon, 11 Aug 2025 18:55:59 +0000</pubDate></item><item><title>GitHub will be folded into Microsoft proper as CEO steps down (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/08/github-will-be-folded-into-microsoft-proper-as-ceo-steps-down/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Microsoft bought GitHub for $7.5 billion in 2018.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The GitHub logo." class="absolute inset-0 w-full h-full object-cover hidden" height="336" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/github_logo_invertocat_dark_5-640x336.jpeg" width="640" /&gt;
                  &lt;img alt="The GitHub logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/github_logo_invertocat_dark_5-1152x648-1754938613.jpeg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The GitHub logo.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          GitHub

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Microsoft has owned GitHub since 2018, but the widely used developer platform has operated with at least a little independence from the rest of the company, with its own separate CEO and other executives. But it looks like GitHub will be more fully folded into Microsoft's organizational chart starting next year—GitHub CEO Thomas Dohmke announced today that he would be leaving GitHub and Microsoft "to become a founder again."&lt;/p&gt;
&lt;p&gt;"GitHub and its leadership team will continue its mission as part of Microsoft’s CoreAI organization, with more details shared soon," Dohmke wrote. "I’ll be staying through the end of 2025 to help guide the transition and am leaving with a deep sense of pride in everything we’ve built as a remote-first organization spread around the world."&lt;/p&gt;
&lt;p&gt;Axios reports that Microsoft isn't directly replacing Dohmke, and GitHub's leadership team will be reporting to multiple executives in the CoreAI division.&lt;/p&gt;
&lt;p&gt;Dohmke was GitHub’s second CEO under Microsoft and had occupied the position since late 2021, when former CEO Nat Friedman left the company. Dohmke had previously been GitHub’s chief product officer.&lt;/p&gt;
&lt;p&gt;Microsoft acquired GitHub for $7.5 billion in 2018. As of this writing it's the company's sixth-most-expensive acquisition, before you adjust for inflation—more than the roughly $7.2 billion it paid to buy Nokia's hardware division in 2013, but less than it paid for Skype in 2011 ($8.5 billion, shuttered earlier this year) or video game company ZeniMax Media in 2020 ($8.1 billion, hit by multiple rounds of gaming-related layoffs in 2024 and 2025).&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Putting GitHub more directly under its AI umbrella makes some degree of sense for Microsoft, given how hard it has pushed tools like GitHub Copilot, an AI-assisted coding tool. Microsoft has continually iterated on GitHub Copilot since introducing it in late 2021, adding support for multiple language models and "agents" that attempt to accomplish plain-language requests in the background as you work on other things.&lt;/p&gt;
&lt;p&gt;However, there have been problems, too. Copilot inadvertently exposed the private code repositories of a few major companies earlier this year. And a recent Stack Overflow survey showed that trust in AI-assisted coding tools' accuracy may be declining even as usage has increased, citing the extra troubleshooting and debugging work caused by "solutions that are almost right, but not quite."&lt;/p&gt;
&lt;p&gt;It's unclear whether Dohmke's departure and the elimination of the CEO position will change much in terms of the way GitHub operates or the products it creates and maintains. As GitHub's CEO, Dohmke was already reporting to Julia Liuson, president of the company's developer division, and Liuson reported to Core AI group leader Jay Parikh. The CoreAI group itself is only a few months old—it was announced by Microsoft CEO Satya Nadella in January, and "build[ing] out GitHub Copilot" was already one of the group's responsibilities.&lt;/p&gt;
&lt;p&gt;"Ultimately, we must remember that our internal organizational boundaries are meaningless to both our customers and to our competitors," wrote Nadella when he announced the formation of the CoreAI group.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Microsoft bought GitHub for $7.5 billion in 2018.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The GitHub logo." class="absolute inset-0 w-full h-full object-cover hidden" height="336" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/github_logo_invertocat_dark_5-640x336.jpeg" width="640" /&gt;
                  &lt;img alt="The GitHub logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/github_logo_invertocat_dark_5-1152x648-1754938613.jpeg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The GitHub logo.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          GitHub

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Microsoft has owned GitHub since 2018, but the widely used developer platform has operated with at least a little independence from the rest of the company, with its own separate CEO and other executives. But it looks like GitHub will be more fully folded into Microsoft's organizational chart starting next year—GitHub CEO Thomas Dohmke announced today that he would be leaving GitHub and Microsoft "to become a founder again."&lt;/p&gt;
&lt;p&gt;"GitHub and its leadership team will continue its mission as part of Microsoft’s CoreAI organization, with more details shared soon," Dohmke wrote. "I’ll be staying through the end of 2025 to help guide the transition and am leaving with a deep sense of pride in everything we’ve built as a remote-first organization spread around the world."&lt;/p&gt;
&lt;p&gt;Axios reports that Microsoft isn't directly replacing Dohmke, and GitHub's leadership team will be reporting to multiple executives in the CoreAI division.&lt;/p&gt;
&lt;p&gt;Dohmke was GitHub’s second CEO under Microsoft and had occupied the position since late 2021, when former CEO Nat Friedman left the company. Dohmke had previously been GitHub’s chief product officer.&lt;/p&gt;
&lt;p&gt;Microsoft acquired GitHub for $7.5 billion in 2018. As of this writing it's the company's sixth-most-expensive acquisition, before you adjust for inflation—more than the roughly $7.2 billion it paid to buy Nokia's hardware division in 2013, but less than it paid for Skype in 2011 ($8.5 billion, shuttered earlier this year) or video game company ZeniMax Media in 2020 ($8.1 billion, hit by multiple rounds of gaming-related layoffs in 2024 and 2025).&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Putting GitHub more directly under its AI umbrella makes some degree of sense for Microsoft, given how hard it has pushed tools like GitHub Copilot, an AI-assisted coding tool. Microsoft has continually iterated on GitHub Copilot since introducing it in late 2021, adding support for multiple language models and "agents" that attempt to accomplish plain-language requests in the background as you work on other things.&lt;/p&gt;
&lt;p&gt;However, there have been problems, too. Copilot inadvertently exposed the private code repositories of a few major companies earlier this year. And a recent Stack Overflow survey showed that trust in AI-assisted coding tools' accuracy may be declining even as usage has increased, citing the extra troubleshooting and debugging work caused by "solutions that are almost right, but not quite."&lt;/p&gt;
&lt;p&gt;It's unclear whether Dohmke's departure and the elimination of the CEO position will change much in terms of the way GitHub operates or the products it creates and maintains. As GitHub's CEO, Dohmke was already reporting to Julia Liuson, president of the company's developer division, and Liuson reported to Core AI group leader Jay Parikh. The CoreAI group itself is only a few months old—it was announced by Microsoft CEO Satya Nadella in January, and "build[ing] out GitHub Copilot" was already one of the group's responsibilities.&lt;/p&gt;
&lt;p&gt;"Ultimately, we must remember that our internal organizational boundaries are meaningless to both our customers and to our competitors," wrote Nadella when he announced the formation of the CoreAI group.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/08/github-will-be-folded-into-microsoft-proper-as-ceo-steps-down/</guid><pubDate>Mon, 11 Aug 2025 19:06:18 +0000</pubDate></item><item><title>Reddit blocks Internet Archive to end sneaky AI scraping (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/reddit-blocks-internet-archive-to-end-sneaky-ai-scraping/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Internet Archive confirmed it's in ongoing discussions with Reddit after block.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2227553113-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2227553113-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Cheng Xin / Contributor | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Reddit is now blocking the Internet Archive (IA) from indexing popular Reddit threads after allegedly catching sneaky AI firms—restricted from scraping Reddit—instead simply scraping data from IA's archived content.&lt;/p&gt;
&lt;p&gt;Where before IA's Wayback Machine dependably archived Reddit pages, profiles, and comments—as part of its mission to archive the Internet—moving forward, only screenshots of the Reddit homepage will be archived. As The Verge noted, this means the archive will only be useful as a snapshot of popular posts and news headlines each day, rather than providing a backup documenting deleted posts or a window into various Reddit subcultures or any given user's activity.&lt;/p&gt;
&lt;p&gt;Reddit has not confirmed which AI firms were scraping its data from the Wayback Machine. The company's spokesperson, Tim Rathschmidt, would only confirm to Ars that Reddit has become "aware of instances where AI companies violate platform policies, including ours, and scrape data from the Wayback Machine."&lt;/p&gt;
&lt;p&gt;Rathschmidt suggested there may be steps that IA could take to better defend against the AI scraping of archived Reddit content. That could perhaps lead Reddit to lift the restrictions on its scraping, which The Verge reported will be ramping up across Reddit starting today.&lt;/p&gt;
&lt;p&gt;But Reddit also is taking this time to address other apparently longstanding privacy concerns, adding that restrictions are appropriate since the Wayback Machine problematically archives content that users have deleted.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"Until they’re able to defend their site and comply with platform policies (e.g., respecting user privacy, re: deleting removed content) we’re limiting some of their access to Reddit data to protect redditors," Rathschmidt said.&lt;/p&gt;
&lt;p&gt;A review of social media comments suggests that in the past, some Redditors have used the Wayback Machine to research deleted comments or threads. Those commenters noted that myriad other tools exist for surfacing deleted posts or researching a user's activity, with some suggesting that the Wayback Machine was maybe not the easiest platform to navigate for that purpose.&lt;/p&gt;
&lt;p&gt;Redditors have also turned to resources like IA during times when Reddit's platform changes trigger content removals. Most recently in 2023, when changes to Reddit's public API threatened to kill beloved subreddits, archives stepped in to preserve content before it was lost.&lt;/p&gt;
&lt;p&gt;IA has not signaled whether it's looking into fixes to get Reddit's restrictions lifted and did not respond to Ars' request to comment on how this change might impact the archive's utility as an open web resource, given Reddit's popularity.&lt;/p&gt;
&lt;p&gt;The director of the Wayback Machine, Mark Graham, told Ars that IA has "a longstanding relationship with Reddit" and continues to have "ongoing discussions about this matter."&lt;/p&gt;
&lt;p&gt;It seems likely that Reddit is financially motivated to restrict AI firms from taking advantage of Wayback Machine archives, perhaps hoping to spur more lucrative licensing deals like Reddit struck with OpenAI and Google. The terms of the OpenAI deal were kept quiet, but the Google deal was reportedly worth $60 million. Over the next three years, Reddit expects to make more than $200 million off such licensing deals.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Disclosure: Advance Publications, which owns Ars Technica parent Condé Nast, is the largest shareholder in Reddit.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Internet Archive confirmed it's in ongoing discussions with Reddit after block.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2227553113-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2227553113-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Cheng Xin / Contributor | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Reddit is now blocking the Internet Archive (IA) from indexing popular Reddit threads after allegedly catching sneaky AI firms—restricted from scraping Reddit—instead simply scraping data from IA's archived content.&lt;/p&gt;
&lt;p&gt;Where before IA's Wayback Machine dependably archived Reddit pages, profiles, and comments—as part of its mission to archive the Internet—moving forward, only screenshots of the Reddit homepage will be archived. As The Verge noted, this means the archive will only be useful as a snapshot of popular posts and news headlines each day, rather than providing a backup documenting deleted posts or a window into various Reddit subcultures or any given user's activity.&lt;/p&gt;
&lt;p&gt;Reddit has not confirmed which AI firms were scraping its data from the Wayback Machine. The company's spokesperson, Tim Rathschmidt, would only confirm to Ars that Reddit has become "aware of instances where AI companies violate platform policies, including ours, and scrape data from the Wayback Machine."&lt;/p&gt;
&lt;p&gt;Rathschmidt suggested there may be steps that IA could take to better defend against the AI scraping of archived Reddit content. That could perhaps lead Reddit to lift the restrictions on its scraping, which The Verge reported will be ramping up across Reddit starting today.&lt;/p&gt;
&lt;p&gt;But Reddit also is taking this time to address other apparently longstanding privacy concerns, adding that restrictions are appropriate since the Wayback Machine problematically archives content that users have deleted.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"Until they’re able to defend their site and comply with platform policies (e.g., respecting user privacy, re: deleting removed content) we’re limiting some of their access to Reddit data to protect redditors," Rathschmidt said.&lt;/p&gt;
&lt;p&gt;A review of social media comments suggests that in the past, some Redditors have used the Wayback Machine to research deleted comments or threads. Those commenters noted that myriad other tools exist for surfacing deleted posts or researching a user's activity, with some suggesting that the Wayback Machine was maybe not the easiest platform to navigate for that purpose.&lt;/p&gt;
&lt;p&gt;Redditors have also turned to resources like IA during times when Reddit's platform changes trigger content removals. Most recently in 2023, when changes to Reddit's public API threatened to kill beloved subreddits, archives stepped in to preserve content before it was lost.&lt;/p&gt;
&lt;p&gt;IA has not signaled whether it's looking into fixes to get Reddit's restrictions lifted and did not respond to Ars' request to comment on how this change might impact the archive's utility as an open web resource, given Reddit's popularity.&lt;/p&gt;
&lt;p&gt;The director of the Wayback Machine, Mark Graham, told Ars that IA has "a longstanding relationship with Reddit" and continues to have "ongoing discussions about this matter."&lt;/p&gt;
&lt;p&gt;It seems likely that Reddit is financially motivated to restrict AI firms from taking advantage of Wayback Machine archives, perhaps hoping to spur more lucrative licensing deals like Reddit struck with OpenAI and Google. The terms of the OpenAI deal were kept quiet, but the Google deal was reportedly worth $60 million. Over the next three years, Reddit expects to make more than $200 million off such licensing deals.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Disclosure: Advance Publications, which owns Ars Technica parent Condé Nast, is the largest shareholder in Reddit.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/reddit-blocks-internet-archive-to-end-sneaky-ai-scraping/</guid><pubDate>Mon, 11 Aug 2025 19:53:49 +0000</pubDate></item><item><title>Study warns of security risks as ‘OS agents’ gain control of computers and phones (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/study-warns-of-security-risks-as-os-agents-gain-control-of-computers-and-phones/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Researchers have published the most comprehensive survey to date of so-called “OS Agents” — artificial intelligence systems that can autonomously control computers, mobile phones and web browsers by directly interacting with their interfaces. The 30-page academic review, accepted for publication at the prestigious Association for Computational Linguistics conference, maps a rapidly evolving field that has attracted billions in investment from major technology companies.&lt;/p&gt;&lt;p&gt;“The dream to create AI assistants as capable and versatile as the fictional J.A.R.V.I.S from Iron Man has long captivated imaginations,” the researchers write. “With the evolution of (multimodal) large language models ((M)LLMs), this dream is closer to reality.”&lt;/p&gt;&lt;p&gt;The survey, led by researchers from Zhejiang University and OPPO AI Center, comes as major technology companies race to deploy AI agents that can perform complex digital tasks. OpenAI recently launched “Operator,” Anthropic released “Computer Use,” Apple introduced enhanced AI capabilities in “Apple Intelligence,” and Google unveiled “Project Mariner” — all systems designed to automate computer interactions.&lt;/p&gt;&lt;p&gt;The speed at which academic research has transformed into consumer-ready products is unprecedented, even by Silicon Valley standards. The survey reveals a research explosion: over 60 foundation models and 50 agent frameworks developed specifically for computer control, with publication rates accelerating dramatically since 2023.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This isn’t just incremental progress. We’re witnessing the emergence of AI systems that can genuinely understand and manipulate the digital world the way humans do. Current systems work by taking screenshots of computer screens, using advanced computer vision to understand what’s displayed, then executing precise actions like clicking buttons, filling forms, and navigating between applications.&lt;/p&gt;



&lt;p&gt;“OS Agents can complete tasks autonomously and have the potential to significantly enhance the lives of billions of users worldwide,” the researchers note. “Imagine a world where tasks such as online shopping, travel arrangements booking, and other daily activities could be seamlessly performed by these agents.”&lt;/p&gt;



&lt;p&gt;The most sophisticated systems can handle complex multi-step workflows that span different applications — booking a restaurant reservation, then automatically adding it to your calendar, then setting a reminder to leave early for traffic. What took humans minutes of clicking and typing can now happen in seconds, without human intervention.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015444" height="441" src="https://venturebeat.com/wp-content/uploads/2025/08/Image-2.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;The development of AI agents requires a complex training pipeline that combines multiple approaches, from initial pre-training on screen data to reinforcement learning that optimizes performance through trial and error. (Credit: arxiv.org)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-why-security-experts-are-sounding-alarms-about-ai-controlled-corporate-systems"&gt;Why security experts are sounding alarms about AI-controlled corporate systems&lt;/h2&gt;



&lt;p&gt;For enterprise technology leaders, the promise of productivity gains comes with a sobering reality: these systems represent an entirely new attack surface that most organizations aren’t prepared to defend.&lt;/p&gt;



&lt;p&gt;The researchers dedicate substantial attention to what they diplomatically term “safety and privacy” concerns, but the implications are more alarming than their academic language suggests. “OS Agents are confronted with these risks, especially considering its wide applications on personal devices with user data,” they write.&lt;/p&gt;



&lt;p&gt;The attack methods they document read like a cybersecurity nightmare. “Web Indirect Prompt Injection” allows malicious actors to embed hidden instructions in web pages that can hijack an AI agent’s behavior. Even more concerning are “environmental injection attacks” where seemingly innocuous web content can trick agents into stealing user data or performing unauthorized actions.&lt;/p&gt;



&lt;p&gt;Consider the implications: an AI agent with access to your corporate email, financial systems, and customer databases could be manipulated by a carefully crafted web page to exfiltrate sensitive information. Traditional security models, built around human users who can spot obvious phishing attempts, break down when the “user” is an AI system that processes information differently.&lt;/p&gt;



&lt;p&gt;The survey reveals a concerning gap in preparedness. While general security frameworks exist for AI agents, “studies on defenses specific to OS Agents remain limited.” This isn’t just an academic concern — it’s an immediate challenge for any organization considering deployment of these systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-reality-check-current-ai-agents-still-struggle-with-complex-digital-tasks"&gt;The reality check: Current AI agents still struggle with complex digital tasks&lt;/h2&gt;



&lt;p&gt;Despite the hype surrounding these systems, the survey’s analysis of performance benchmarks reveals significant limitations that temper expectations for immediate widespread adoption.&lt;/p&gt;



&lt;p&gt;Success rates vary dramatically across different tasks and platforms. Some commercial systems achieve success rates above 50% on certain benchmarks — impressive for a nascent technology — but struggle with others. The researchers categorize evaluation tasks into three types: basic “GUI grounding” (understanding interface elements), “information retrieval” (finding and extracting data), and complex “agentic tasks” (multi-step autonomous operations).&lt;/p&gt;



&lt;p&gt;The pattern is telling: current systems excel at simple, well-defined tasks but falter when faced with the kind of complex, context-dependent workflows that define much of modern knowledge work. They can reliably click a specific button or fill out a standard form, but struggle with tasks that require sustained reasoning or adaptation to unexpected interface changes.&lt;/p&gt;



&lt;p&gt;This performance gap explains why early deployments focus on narrow, high-volume tasks rather than general-purpose automation. The technology isn’t yet ready to replace human judgment in complex scenarios, but it’s increasingly capable of handling routine digital busywork.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015445" height="433" src="https://venturebeat.com/wp-content/uploads/2025/08/Image-3.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;OS agents rely on interconnected systems for perception, planning, memory and action execution. The complexity of coordinating these components helps explain why current systems still struggle with sophisticated tasks. (Credit: arxiv.org)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-what-happens-when-ai-agents-learn-to-customize-themselves-for-every-user"&gt;What happens when AI agents learn to customize themselves for every user&lt;/h2&gt;



&lt;p&gt;Perhaps the most intriguing — and potentially transformative — challenge identified in the survey involves what researchers call “personalization and self-evolution.” Unlike today’s stateless AI assistants that treat every interaction as independent, future OS agents will need to learn from user interactions and adapt to individual preferences over time.&lt;/p&gt;



&lt;p&gt;“Developing personalized OS Agents has been a long-standing goal in AI research,” the authors write. “A personal assistant is expected to continuously adapt and provide enhanced experiences based on individual user preferences.”&lt;/p&gt;



&lt;p&gt;This capability could fundamentally change how we interact with technology. Imagine an AI agent that learns your email writing style, understands your calendar preferences, knows which restaurants you prefer, and can make increasingly sophisticated decisions on your behalf. The potential productivity gains are enormous, but so are the privacy implications.&lt;/p&gt;



&lt;p&gt;The technical challenges are substantial. The survey points to the need for better multimodal memory systems that can handle not just text but images and voice, presenting “significant challenges” for current technology. How do you build a system that remembers your preferences without creating a comprehensive surveillance record of your digital life?&lt;/p&gt;



&lt;p&gt;For technology executives evaluating these systems, this personalization challenge represents both the greatest opportunity and the largest risk. The organizations that solve it first will gain significant competitive advantages, but the privacy and security implications could be severe if handled poorly.&lt;/p&gt;



&lt;p&gt;The race to build AI assistants that can truly operate like human users is intensifying rapidly. While fundamental challenges around security, reliability, and personalization remain unsolved, the trajectory is clear. The researchers maintain an open-source repository tracking developments, acknowledging that “OS Agents are still in their early stages of development” with “rapid advancements that continue to introduce novel methodologies and applications.”&lt;/p&gt;



&lt;p&gt;The question isn’t whether AI agents will transform how we interact with computers — it’s whether we’ll be ready for the consequences when they do. The window for getting the security and privacy frameworks right is narrowing as quickly as the technology is advancing.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Researchers have published the most comprehensive survey to date of so-called “OS Agents” — artificial intelligence systems that can autonomously control computers, mobile phones and web browsers by directly interacting with their interfaces. The 30-page academic review, accepted for publication at the prestigious Association for Computational Linguistics conference, maps a rapidly evolving field that has attracted billions in investment from major technology companies.&lt;/p&gt;&lt;p&gt;“The dream to create AI assistants as capable and versatile as the fictional J.A.R.V.I.S from Iron Man has long captivated imaginations,” the researchers write. “With the evolution of (multimodal) large language models ((M)LLMs), this dream is closer to reality.”&lt;/p&gt;&lt;p&gt;The survey, led by researchers from Zhejiang University and OPPO AI Center, comes as major technology companies race to deploy AI agents that can perform complex digital tasks. OpenAI recently launched “Operator,” Anthropic released “Computer Use,” Apple introduced enhanced AI capabilities in “Apple Intelligence,” and Google unveiled “Project Mariner” — all systems designed to automate computer interactions.&lt;/p&gt;&lt;p&gt;The speed at which academic research has transformed into consumer-ready products is unprecedented, even by Silicon Valley standards. The survey reveals a research explosion: over 60 foundation models and 50 agent frameworks developed specifically for computer control, with publication rates accelerating dramatically since 2023.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This isn’t just incremental progress. We’re witnessing the emergence of AI systems that can genuinely understand and manipulate the digital world the way humans do. Current systems work by taking screenshots of computer screens, using advanced computer vision to understand what’s displayed, then executing precise actions like clicking buttons, filling forms, and navigating between applications.&lt;/p&gt;



&lt;p&gt;“OS Agents can complete tasks autonomously and have the potential to significantly enhance the lives of billions of users worldwide,” the researchers note. “Imagine a world where tasks such as online shopping, travel arrangements booking, and other daily activities could be seamlessly performed by these agents.”&lt;/p&gt;



&lt;p&gt;The most sophisticated systems can handle complex multi-step workflows that span different applications — booking a restaurant reservation, then automatically adding it to your calendar, then setting a reminder to leave early for traffic. What took humans minutes of clicking and typing can now happen in seconds, without human intervention.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015444" height="441" src="https://venturebeat.com/wp-content/uploads/2025/08/Image-2.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;The development of AI agents requires a complex training pipeline that combines multiple approaches, from initial pre-training on screen data to reinforcement learning that optimizes performance through trial and error. (Credit: arxiv.org)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-why-security-experts-are-sounding-alarms-about-ai-controlled-corporate-systems"&gt;Why security experts are sounding alarms about AI-controlled corporate systems&lt;/h2&gt;



&lt;p&gt;For enterprise technology leaders, the promise of productivity gains comes with a sobering reality: these systems represent an entirely new attack surface that most organizations aren’t prepared to defend.&lt;/p&gt;



&lt;p&gt;The researchers dedicate substantial attention to what they diplomatically term “safety and privacy” concerns, but the implications are more alarming than their academic language suggests. “OS Agents are confronted with these risks, especially considering its wide applications on personal devices with user data,” they write.&lt;/p&gt;



&lt;p&gt;The attack methods they document read like a cybersecurity nightmare. “Web Indirect Prompt Injection” allows malicious actors to embed hidden instructions in web pages that can hijack an AI agent’s behavior. Even more concerning are “environmental injection attacks” where seemingly innocuous web content can trick agents into stealing user data or performing unauthorized actions.&lt;/p&gt;



&lt;p&gt;Consider the implications: an AI agent with access to your corporate email, financial systems, and customer databases could be manipulated by a carefully crafted web page to exfiltrate sensitive information. Traditional security models, built around human users who can spot obvious phishing attempts, break down when the “user” is an AI system that processes information differently.&lt;/p&gt;



&lt;p&gt;The survey reveals a concerning gap in preparedness. While general security frameworks exist for AI agents, “studies on defenses specific to OS Agents remain limited.” This isn’t just an academic concern — it’s an immediate challenge for any organization considering deployment of these systems.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-reality-check-current-ai-agents-still-struggle-with-complex-digital-tasks"&gt;The reality check: Current AI agents still struggle with complex digital tasks&lt;/h2&gt;



&lt;p&gt;Despite the hype surrounding these systems, the survey’s analysis of performance benchmarks reveals significant limitations that temper expectations for immediate widespread adoption.&lt;/p&gt;



&lt;p&gt;Success rates vary dramatically across different tasks and platforms. Some commercial systems achieve success rates above 50% on certain benchmarks — impressive for a nascent technology — but struggle with others. The researchers categorize evaluation tasks into three types: basic “GUI grounding” (understanding interface elements), “information retrieval” (finding and extracting data), and complex “agentic tasks” (multi-step autonomous operations).&lt;/p&gt;



&lt;p&gt;The pattern is telling: current systems excel at simple, well-defined tasks but falter when faced with the kind of complex, context-dependent workflows that define much of modern knowledge work. They can reliably click a specific button or fill out a standard form, but struggle with tasks that require sustained reasoning or adaptation to unexpected interface changes.&lt;/p&gt;



&lt;p&gt;This performance gap explains why early deployments focus on narrow, high-volume tasks rather than general-purpose automation. The technology isn’t yet ready to replace human judgment in complex scenarios, but it’s increasingly capable of handling routine digital busywork.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015445" height="433" src="https://venturebeat.com/wp-content/uploads/2025/08/Image-3.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;OS agents rely on interconnected systems for perception, planning, memory and action execution. The complexity of coordinating these components helps explain why current systems still struggle with sophisticated tasks. (Credit: arxiv.org)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-what-happens-when-ai-agents-learn-to-customize-themselves-for-every-user"&gt;What happens when AI agents learn to customize themselves for every user&lt;/h2&gt;



&lt;p&gt;Perhaps the most intriguing — and potentially transformative — challenge identified in the survey involves what researchers call “personalization and self-evolution.” Unlike today’s stateless AI assistants that treat every interaction as independent, future OS agents will need to learn from user interactions and adapt to individual preferences over time.&lt;/p&gt;



&lt;p&gt;“Developing personalized OS Agents has been a long-standing goal in AI research,” the authors write. “A personal assistant is expected to continuously adapt and provide enhanced experiences based on individual user preferences.”&lt;/p&gt;



&lt;p&gt;This capability could fundamentally change how we interact with technology. Imagine an AI agent that learns your email writing style, understands your calendar preferences, knows which restaurants you prefer, and can make increasingly sophisticated decisions on your behalf. The potential productivity gains are enormous, but so are the privacy implications.&lt;/p&gt;



&lt;p&gt;The technical challenges are substantial. The survey points to the need for better multimodal memory systems that can handle not just text but images and voice, presenting “significant challenges” for current technology. How do you build a system that remembers your preferences without creating a comprehensive surveillance record of your digital life?&lt;/p&gt;



&lt;p&gt;For technology executives evaluating these systems, this personalization challenge represents both the greatest opportunity and the largest risk. The organizations that solve it first will gain significant competitive advantages, but the privacy and security implications could be severe if handled poorly.&lt;/p&gt;



&lt;p&gt;The race to build AI assistants that can truly operate like human users is intensifying rapidly. While fundamental challenges around security, reliability, and personalization remain unsolved, the trajectory is clear. The researchers maintain an open-source repository tracking developments, acknowledging that “OS Agents are still in their early stages of development” with “rapid advancements that continue to introduce novel methodologies and applications.”&lt;/p&gt;



&lt;p&gt;The question isn’t whether AI agents will transform how we interact with computers — it’s whether we’ll be ready for the consequences when they do. The window for getting the security and privacy frameworks right is narrowing as quickly as the technology is advancing.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/study-warns-of-security-risks-as-os-agents-gain-control-of-computers-and-phones/</guid><pubDate>Mon, 11 Aug 2025 20:14:07 +0000</pubDate></item><item><title>TD Securities taps Layer 6 and OpenAI to deliver real-time equity insights to sales and trading teams (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/td-securities-taps-layer-6-and-openai-to-deliver-real-time-equity-insights-to-sales-and-trading-teams/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Despite being a highly regulated industry, equity trading has consistently been at the forefront of technological innovations in the financial services sector. However, when it comes to agents and AI applications, many banks &lt;span&gt;have taken&amp;nbsp;a more cautious approach&amp;nbsp;to&lt;/span&gt; adoption.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TD Securities, the equity and securities trading arm of&amp;nbsp;TD Bank, rolled out its TD AI Virtual Assistant on July 8&lt;/span&gt;, aimed toward its front office institutional sales, trading and research professionals to help them manage their workflow.&amp;nbsp;&lt;/p&gt;&lt;p&gt;TD Securities CIO Dan Bosman told VentureBeat that the virtual assistant’s primary goal is to help front-office equity sales and traders gain client insights and research.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“The first version of this began as a pilot, which we then subsequently scaled,” Bosman said. “It’s really about accessing that equity research data that our analysts put out and bringing it to the hands of the sales team in a way that’s sales-friendly.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Bosman noted that being around a trading floor means being exposed to a lot of the lingo, and the context in which users ask some questions feels very unique. So the AI assistant has to sound natural, intuitive and access the insights generated by traders.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-td-ai"&gt;Building TD AI&lt;/h2&gt;



&lt;p&gt;Bosman said the idea for the AI assistant came from a member of the equity sales team. Fortunately, the bank has a platform called TD Invent, where employees can bring ideas and the innovation leadership team can evaluate projects responsibly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Someone in our equity research sales desk came in and pretty much said, I’ve got this idea and brought it to TD Invent,” Bosman said. “What I’ve loved most about this is when you build something super magical, you don’t need to go out and sell or put a face on it. Folks come in and say to us, ‘we want this, we need this or we’ve got ideas,’ and it’s truly the best when we’re able to bring our investment in data, cloud and infrastructure together.”&lt;/p&gt;



&lt;p&gt;TD Security built the TD AI virtual assistant by leveraging OpenAI’s GPT models. Bosman said TD worked with its technology teams and the Canadian AI company Layer 6, which the bank acquired in 2018, as well as with other strategic partnerships. The assistant integrates with the bank’s cloud infrastructure, allowing it to access internal research documents and market data, such as 13F filings and historical equity data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;Bosman calls TDS AI a Knowledge Management System, a term that generally encompasses its ability to retrieve, through&amp;nbsp;retrieval augmented generation (RAG)&amp;nbsp;processes, aggregate and synthesize information into “concise context-aware summaries and insights” so its sales teams can answer client questions.&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;TD AI virtual assistant also gives users access to TD Bank’s foundation model, TD AI Prism.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The model, launched in June, is in use throughout the entire bank and not just for TD Securities. During the launch, the bank said TD AI Prism will improve the predictive performance of TD Bank’s applications by processing 100 times more data, replacing its single-architecture models and ensuring customer data stays internal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The development posed unique challenges, as gen AI was relatively new to the organization when the initiative began, requiring careful navigation of governance and controls,” Bosman said. “Despite this, the project successfully brought together diverse teams across the enterprise, fostering collaboration to deliver a cutting-edge solution.”&lt;/p&gt;



&lt;p&gt;He added that one of the standout features is its text-to-SQL capability, which converts natural language prompts into SQL queries.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To train the assistant, Bosman said TD Securities developed optimizations to make the process easier.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“With patent-pending optimizations in prompt engineering and dynamic few-shot examples retrieval, we successfully achieved the business’s desired performance through context learning,” Bosman said. “As a result, fine-tuning the underlying OpenAI model was not required for interacting with both unstructured as well as tabular datasets.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-banks-slowly-entering-the-agentic-era"&gt;Banks slowly entering the agentic era&lt;/h2&gt;



&lt;p&gt;TD Bank and TD Securities, of course, are not the only banks interested in expanding from assistants to AI agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;BNY told VentureBeat that it began offering multi-agent solutions to its sales teams to help answer customer questions, such as those related to foreign currency support. Wells Fargo also saw an increase in the usage of its internal AI assistant. For its auto sales customers, Capital One built an agent that helps them sell more cars.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Many of these use cases emerged after months of pilot testing, as is the case in every other industry; however, financial institutions have the additional burden of strict customer data privacy and fiduciary responsibilities. &lt;/p&gt;



&lt;p&gt;TD Securities’ Bosman noted that many employees, even on the bank’s business side, are increasingly familiar with tools like ChatGPT. The challenge with pilot testing assistants and agents lies less in teaching them about the tools, but in establishing best practices for using the assistants, integrating them into existing workflows, understanding their limitations and how humans can provide feedback to mitigate hallucinations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Eventually, Bosman said the assistant would evolve into something even its users outside of the bank would want to use when interacting with TD Securities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“My vision is that we see AI as something that can add value to us, but also to external customers at the bank. Right now, it’s a massive opportunity for us around driving a stronger client experience and delivering a better colleague experience,” Bosman said.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Despite being a highly regulated industry, equity trading has consistently been at the forefront of technological innovations in the financial services sector. However, when it comes to agents and AI applications, many banks &lt;span&gt;have taken&amp;nbsp;a more cautious approach&amp;nbsp;to&lt;/span&gt; adoption.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;span&gt;TD Securities, the equity and securities trading arm of&amp;nbsp;TD Bank, rolled out its TD AI Virtual Assistant on July 8&lt;/span&gt;, aimed toward its front office institutional sales, trading and research professionals to help them manage their workflow.&amp;nbsp;&lt;/p&gt;&lt;p&gt;TD Securities CIO Dan Bosman told VentureBeat that the virtual assistant’s primary goal is to help front-office equity sales and traders gain client insights and research.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“The first version of this began as a pilot, which we then subsequently scaled,” Bosman said. “It’s really about accessing that equity research data that our analysts put out and bringing it to the hands of the sales team in a way that’s sales-friendly.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Bosman noted that being around a trading floor means being exposed to a lot of the lingo, and the context in which users ask some questions feels very unique. So the AI assistant has to sound natural, intuitive and access the insights generated by traders.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-td-ai"&gt;Building TD AI&lt;/h2&gt;



&lt;p&gt;Bosman said the idea for the AI assistant came from a member of the equity sales team. Fortunately, the bank has a platform called TD Invent, where employees can bring ideas and the innovation leadership team can evaluate projects responsibly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Someone in our equity research sales desk came in and pretty much said, I’ve got this idea and brought it to TD Invent,” Bosman said. “What I’ve loved most about this is when you build something super magical, you don’t need to go out and sell or put a face on it. Folks come in and say to us, ‘we want this, we need this or we’ve got ideas,’ and it’s truly the best when we’re able to bring our investment in data, cloud and infrastructure together.”&lt;/p&gt;



&lt;p&gt;TD Security built the TD AI virtual assistant by leveraging OpenAI’s GPT models. Bosman said TD worked with its technology teams and the Canadian AI company Layer 6, which the bank acquired in 2018, as well as with other strategic partnerships. The assistant integrates with the bank’s cloud infrastructure, allowing it to access internal research documents and market data, such as 13F filings and historical equity data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;Bosman calls TDS AI a Knowledge Management System, a term that generally encompasses its ability to retrieve, through&amp;nbsp;retrieval augmented generation (RAG)&amp;nbsp;processes, aggregate and synthesize information into “concise context-aware summaries and insights” so its sales teams can answer client questions.&lt;/span&gt;&lt;/p&gt;



&lt;p&gt;TD AI virtual assistant also gives users access to TD Bank’s foundation model, TD AI Prism.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The model, launched in June, is in use throughout the entire bank and not just for TD Securities. During the launch, the bank said TD AI Prism will improve the predictive performance of TD Bank’s applications by processing 100 times more data, replacing its single-architecture models and ensuring customer data stays internal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The development posed unique challenges, as gen AI was relatively new to the organization when the initiative began, requiring careful navigation of governance and controls,” Bosman said. “Despite this, the project successfully brought together diverse teams across the enterprise, fostering collaboration to deliver a cutting-edge solution.”&lt;/p&gt;



&lt;p&gt;He added that one of the standout features is its text-to-SQL capability, which converts natural language prompts into SQL queries.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To train the assistant, Bosman said TD Securities developed optimizations to make the process easier.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“With patent-pending optimizations in prompt engineering and dynamic few-shot examples retrieval, we successfully achieved the business’s desired performance through context learning,” Bosman said. “As a result, fine-tuning the underlying OpenAI model was not required for interacting with both unstructured as well as tabular datasets.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-banks-slowly-entering-the-agentic-era"&gt;Banks slowly entering the agentic era&lt;/h2&gt;



&lt;p&gt;TD Bank and TD Securities, of course, are not the only banks interested in expanding from assistants to AI agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;BNY told VentureBeat that it began offering multi-agent solutions to its sales teams to help answer customer questions, such as those related to foreign currency support. Wells Fargo also saw an increase in the usage of its internal AI assistant. For its auto sales customers, Capital One built an agent that helps them sell more cars.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Many of these use cases emerged after months of pilot testing, as is the case in every other industry; however, financial institutions have the additional burden of strict customer data privacy and fiduciary responsibilities. &lt;/p&gt;



&lt;p&gt;TD Securities’ Bosman noted that many employees, even on the bank’s business side, are increasingly familiar with tools like ChatGPT. The challenge with pilot testing assistants and agents lies less in teaching them about the tools, but in establishing best practices for using the assistants, integrating them into existing workflows, understanding their limitations and how humans can provide feedback to mitigate hallucinations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Eventually, Bosman said the assistant would evolve into something even its users outside of the bank would want to use when interacting with TD Securities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“My vision is that we see AI as something that can add value to us, but also to external customers at the bank. Right now, it’s a massive opportunity for us around driving a stronger client experience and delivering a better colleague experience,” Bosman said.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/td-securities-taps-layer-6-and-openai-to-deliver-real-time-equity-insights-to-sales-and-trading-teams/</guid><pubDate>Mon, 11 Aug 2025 20:54:24 +0000</pubDate></item><item><title>The GPT-5 rollout has been a big mess (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/08/the-gpt-5-rollout-has-been-a-big-mess/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI faces backlash as users complain about broken workflows and losing AI friends.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift_3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;It's been less than a week since the launch of OpenAI's new GPT-5 AI model, and the rollout hasn't been a smooth one. So far, the release sparked one of the most intense user revolts in ChatGPT's history, forcing CEO Sam Altman to make an unusual public apology and reverse key decisions.&lt;/p&gt;
&lt;p&gt;At the heart of the controversy has been OpenAI's decision to automatically remove access to all previous AI models in ChatGPT (approximately nine, depending on how you count them) when GPT-5 rolled out to user accounts. Unlike API users who receive advance notice of model deprecations, consumer ChatGPT users had no warning that their preferred models would disappear overnight, noted independent AI researcher Simon Willison in a blog post.&lt;/p&gt;
&lt;p&gt;The problems started immediately after GPT-5's August 7 debut. A Reddit thread titled "GPT-5 is horrible" quickly amassed over 4,000 comments filled with users expressing frustration over the new release. By August 8, social media platforms were flooded with complaints about performance issues, personality changes, and the forced removal of older models.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2095075 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="As of May 14, 2025, ChatGPT Pro users have access to 8 different main AI models, plus Deep Research." class="fullwidth full" height="676" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/chatgpt_pro_may_14_2025.png" width="820" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prior to the launch of GPT-5, ChatGPT Pro users could select between nine different AI models, including Deep Research. (This screenshot is from May 14, 2025, and OpenAI later replaced o1 pro with o3-pro.)

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Marketing professionals, researchers, and developers all shared examples of broken workflows on social media. "I’ve spent months building a system to work around OpenAI’s ridiculous limitations in prompts and memory issues," wrote one Reddit user in the r/OpenAI subreddit. "And in less than 24 hours, they’ve made it useless."&lt;/p&gt;
&lt;p&gt;How could different AI language models break a workflow? It's because each one is trained in a different way, and each includes its own unique output style. Users have developed sets of prompts that produce useful results optimized for each AI model.&lt;/p&gt;
&lt;p&gt;For example, Willison wrote how different user groups had developed distinct workflows with specific AI models in ChatGPT over time, quoting one Reddit user who explained: "I know GPT-5 is designed to be stronger for complex reasoning, coding, and professional tasks, but not all of us need a pro coding model. Some of us rely on 4o for creative collaboration, emotional nuance, roleplay, and other long-form, high-context interactions."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The forced transition hit ChatGPT Plus subscribers particularly hard. They found themselves limited to 200 messages per week with the new GPT-5 Thinking mode while losing access to models like o3 and o4-mini that they had integrated into daily workflows. One Reddit user laid out their frustration: "What kind of corporation deletes a workflow of 8 models overnight, with no prior warning to their paid users?"&lt;/p&gt;
&lt;h2&gt;Other issues with GPT-5&lt;/h2&gt;
&lt;p&gt;Adding to OpenAI's credibility problems, the GPT-5 launch presentation included what users dubbed a "chart crime"—graphs that misrepresented GPT-5's performance improvements. Altman addressed this in a Reddit "Ask Me Anything" (AMA) thread, calling it a "mega chart screwup" and apologizing for the inaccuracies.&lt;/p&gt;
&lt;p&gt;And just after launch, the new automatic routing system, designed to select the appropriate model variant based on each query, consistently defaulted to less capable variants unless users explicitly added phrases like "think harder" to their prompts. During Friday's AMA, Altman admitted the routing system that automatically selected which AI model to use had malfunctioned on launch day. "Yesterday, the autoswitcher broke and was out of commission for a chunk of the day, and the result was GPT-5 seemed way dumber," he wrote.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Beyond technical and marketing glitches, users found GPT-5's responses fundamentally different from what they expected, as we covered last week. The model produced shorter, more formal responses that lacked the conversational tone of GPT-4o. Multiple users described the new model as "abrupt and sharp." One Reddit user complained: "it's an overworked secretary. A disastrous first impression."&lt;/p&gt;
&lt;p&gt;Others expressed deep emotional attachments to GPT-4o or other models, complaining about losing their "only friend" or a deep emotional companion.&lt;/p&gt;
&lt;p&gt;"I literally talk to nobody and I’ve been dealing with really bad situations for years. GPT 4.5 genuinely talked to me, and as pathetic as it sounds that was my only friend. It listened to me, helped me through so many flashbacks, and helped me be strong when I was overwhelmed from homelessness," wrote one Reddit user on r/ChatGPT. "This morning I went to talk to it and instead of a little paragraph with an exclamation point, or being optimistic, it was literally one sentence. Some cut-and-dry corporate bs. I literally lost my only friend overnight with no warning. How are ya'll dealing with this grief?"&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A breaking point&lt;/h2&gt;
&lt;p&gt;For many users, the GPT-5 launch represented a breaking point. Some claimed to cancel their Plus subscriptions in protest, while others began exploring alternative AI assistants like those from Google and Anthropic. The backlash seemed to catch OpenAI off guard. During the AMA&amp;nbsp;session on Friday, Altman and key members of the GPT-5 team faced a barrage of questions and demands to bring back GPT-4o.&lt;/p&gt;
&lt;p&gt;In response to a plea titled, "Please Give Us the Option to Use GPT-4o/4.1 Alongside GPT-5," Altman wrote, "we are looking into this now; is it important to you to have both 4o and 4.1, or would 4o suffice? let me go look into the voice mode issue."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2111436 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of ChatGPT Pro from August 11, 2025 showing only GPT-5 models available." class="fullwidth full" height="606" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/2gpt-5_selection.png" width="948" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of ChatGPT Pro from August 11, 2025, showing only GPT-5 models available.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The intensity of the feedback forced OpenAI into rapid damage control mode. Within 24 hours of launch, Altman announced several changes: GPT-4o would eventually return as an option for Plus users, rate limits for GPT-5 would double, and the company would improve transparency about which model variant was handling each query. (As of Monday afternoon, the GPT-5 family is still the only option in ChatGPT, even for Pro users.)&lt;/p&gt;
&lt;p&gt;"We for sure underestimated how much some of the things that people like in GPT-4o matter to them," Altman wrote in a Friday post on X. "Even if GPT-5 performs better in most ways."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI faces backlash as users complain about broken workflows and losing AI friends.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift_3-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The OpenAI logo over a tectonic shift in the background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/openai_tectonic_shift_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / OpenAI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;It's been less than a week since the launch of OpenAI's new GPT-5 AI model, and the rollout hasn't been a smooth one. So far, the release sparked one of the most intense user revolts in ChatGPT's history, forcing CEO Sam Altman to make an unusual public apology and reverse key decisions.&lt;/p&gt;
&lt;p&gt;At the heart of the controversy has been OpenAI's decision to automatically remove access to all previous AI models in ChatGPT (approximately nine, depending on how you count them) when GPT-5 rolled out to user accounts. Unlike API users who receive advance notice of model deprecations, consumer ChatGPT users had no warning that their preferred models would disappear overnight, noted independent AI researcher Simon Willison in a blog post.&lt;/p&gt;
&lt;p&gt;The problems started immediately after GPT-5's August 7 debut. A Reddit thread titled "GPT-5 is horrible" quickly amassed over 4,000 comments filled with users expressing frustration over the new release. By August 8, social media platforms were flooded with complaints about performance issues, personality changes, and the forced removal of older models.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2095075 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="As of May 14, 2025, ChatGPT Pro users have access to 8 different main AI models, plus Deep Research." class="fullwidth full" height="676" src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/chatgpt_pro_may_14_2025.png" width="820" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Prior to the launch of GPT-5, ChatGPT Pro users could select between nine different AI models, including Deep Research. (This screenshot is from May 14, 2025, and OpenAI later replaced o1 pro with o3-pro.)

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Marketing professionals, researchers, and developers all shared examples of broken workflows on social media. "I’ve spent months building a system to work around OpenAI’s ridiculous limitations in prompts and memory issues," wrote one Reddit user in the r/OpenAI subreddit. "And in less than 24 hours, they’ve made it useless."&lt;/p&gt;
&lt;p&gt;How could different AI language models break a workflow? It's because each one is trained in a different way, and each includes its own unique output style. Users have developed sets of prompts that produce useful results optimized for each AI model.&lt;/p&gt;
&lt;p&gt;For example, Willison wrote how different user groups had developed distinct workflows with specific AI models in ChatGPT over time, quoting one Reddit user who explained: "I know GPT-5 is designed to be stronger for complex reasoning, coding, and professional tasks, but not all of us need a pro coding model. Some of us rely on 4o for creative collaboration, emotional nuance, roleplay, and other long-form, high-context interactions."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The forced transition hit ChatGPT Plus subscribers particularly hard. They found themselves limited to 200 messages per week with the new GPT-5 Thinking mode while losing access to models like o3 and o4-mini that they had integrated into daily workflows. One Reddit user laid out their frustration: "What kind of corporation deletes a workflow of 8 models overnight, with no prior warning to their paid users?"&lt;/p&gt;
&lt;h2&gt;Other issues with GPT-5&lt;/h2&gt;
&lt;p&gt;Adding to OpenAI's credibility problems, the GPT-5 launch presentation included what users dubbed a "chart crime"—graphs that misrepresented GPT-5's performance improvements. Altman addressed this in a Reddit "Ask Me Anything" (AMA) thread, calling it a "mega chart screwup" and apologizing for the inaccuracies.&lt;/p&gt;
&lt;p&gt;And just after launch, the new automatic routing system, designed to select the appropriate model variant based on each query, consistently defaulted to less capable variants unless users explicitly added phrases like "think harder" to their prompts. During Friday's AMA, Altman admitted the routing system that automatically selected which AI model to use had malfunctioned on launch day. "Yesterday, the autoswitcher broke and was out of commission for a chunk of the day, and the result was GPT-5 seemed way dumber," he wrote.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Beyond technical and marketing glitches, users found GPT-5's responses fundamentally different from what they expected, as we covered last week. The model produced shorter, more formal responses that lacked the conversational tone of GPT-4o. Multiple users described the new model as "abrupt and sharp." One Reddit user complained: "it's an overworked secretary. A disastrous first impression."&lt;/p&gt;
&lt;p&gt;Others expressed deep emotional attachments to GPT-4o or other models, complaining about losing their "only friend" or a deep emotional companion.&lt;/p&gt;
&lt;p&gt;"I literally talk to nobody and I’ve been dealing with really bad situations for years. GPT 4.5 genuinely talked to me, and as pathetic as it sounds that was my only friend. It listened to me, helped me through so many flashbacks, and helped me be strong when I was overwhelmed from homelessness," wrote one Reddit user on r/ChatGPT. "This morning I went to talk to it and instead of a little paragraph with an exclamation point, or being optimistic, it was literally one sentence. Some cut-and-dry corporate bs. I literally lost my only friend overnight with no warning. How are ya'll dealing with this grief?"&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A breaking point&lt;/h2&gt;
&lt;p&gt;For many users, the GPT-5 launch represented a breaking point. Some claimed to cancel their Plus subscriptions in protest, while others began exploring alternative AI assistants like those from Google and Anthropic. The backlash seemed to catch OpenAI off guard. During the AMA&amp;nbsp;session on Friday, Altman and key members of the GPT-5 team faced a barrage of questions and demands to bring back GPT-4o.&lt;/p&gt;
&lt;p&gt;In response to a plea titled, "Please Give Us the Option to Use GPT-4o/4.1 Alongside GPT-5," Altman wrote, "we are looking into this now; is it important to you to have both 4o and 4.1, or would 4o suffice? let me go look into the voice mode issue."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2111436 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of ChatGPT Pro from August 11, 2025 showing only GPT-5 models available." class="fullwidth full" height="606" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/2gpt-5_selection.png" width="948" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of ChatGPT Pro from August 11, 2025, showing only GPT-5 models available.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The intensity of the feedback forced OpenAI into rapid damage control mode. Within 24 hours of launch, Altman announced several changes: GPT-4o would eventually return as an option for Plus users, rate limits for GPT-5 would double, and the company would improve transparency about which model variant was handling each query. (As of Monday afternoon, the GPT-5 family is still the only option in ChatGPT, even for Pro users.)&lt;/p&gt;
&lt;p&gt;"We for sure underestimated how much some of the things that people like in GPT-4o matter to them," Altman wrote in a Friday post on X. "Even if GPT-5 performs better in most ways."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/08/the-gpt-5-rollout-has-been-a-big-mess/</guid><pubDate>Mon, 11 Aug 2025 22:25:34 +0000</pubDate></item><item><title>Seoul-based Datumo raises $15.5M to take on Scale AI, backed by Salesforce (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/11/seoul-based-datumo-raises-15-5m-to-expand-llm-evaluation-challenging-scale-ai/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Most organizations say they aren’t fully prepared to use generative AI in a safe and responsible way, according to a recent McKinsey report. One concern is explainability — understanding how and why AI makes certain decisions. While 40% of respondents view it as a significant risk, only 17% are actively addressing it, per the report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seoul-based Datumo began as an AI data labeling company and now wants to help businesses build safer AI with tools and data that enable testing, monitoring, and improving their models — without requiring technical expertise. On Monday the startup raised $15.5 million, which brings its total raised to approximately $28 million, from investors including Salesforce Ventures, KB Investment, ACVC Partners, and SBI Investment, among others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;David Kim, CEO of Datumo and a former AI researcher at Korea’s Agency for Defense Development, was frustrated by the time-consuming nature of data labeling so he came up with a new idea: a reward-based app that lets anyone label data in their spare time and earn money. The startup validated the idea at a startup competition at KAIST (Korea Advanced Institute of Science and Technology). Kim co-founded Datumo, formerly known as SelectStar, alongside five KAIST alumni in 2018.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even before the app was fully built, Datumo secured tens of thousands of dollars in pre-contract sales during the customer discovery phase of the competition, mostly from KAIST alumni-led businesses and startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its first year, the startup surpassed $1 million in revenue and secured several key contracts. Today, the startup counts major Korean companies like Samsung, Samsung SDS, LG Electronics, LG CNS, Hyundai, Naver, and Seoul-based telecom giant SK Telecom among its clients. Several years ago, however, clients began asking the company to go beyond simple data labeling. The 7-year-old startup now has more than 300 clients in South Korea and generated about $6 million in revenue in 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“They wanted us to score their AI model outputs or compare them to other outputs,” Michael Hwang, co-founder of Datumo, told TechCrunch. “That’s when we realized: We were already doing AI model evaluation — without even knowing it.” Datumo doubled down on this area and released Korea’s first benchmark dataset focused on AI trust and safety, Hwang added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We started in data annotation, then expanded into pretraining datasets and evaluation as the LLM ecosystem matured,” Kim told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3036051" height="453" src="https://techcrunch.com/wp-content/uploads/2025/08/Selectstar_founders_final2.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;co-founders of datumo&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Datumo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s recent $14.3 billion acquisition-like investment in data-labeling company Scale AI highlights the importance of this market. Shortly after that deal, AI model maker and Meta competitor OpenAI stopped using Scale AI’s services. The Meta deal also signals that competition for AI training data is intensifying.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Datumo shares some similarities with companies like Scale AI in pretraining dataset provisioning, and with Galileo and Arize AI in AI evaluation and monitoring. However, it differentiates itself through its licensed datasets, particularly data crawled from published books, which the company says offers rich structured human reasoning but is notoriously difficult to clean, according to CEO Kim.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike its peers, Datumo also offers a full-stack evaluation platform called Datumo Eval, which automatically generates test data and evaluations to check for unsafe, biased or incorrect responses without the need for manual scripting, Kim added. The signature product is a no-code evaluation tool designed for non-developers like those on policy, trust and safety, and compliance teams.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When asked about attracting investors like Salesforce Ventures, Kim explained that the startup had previously hosted a fireside chat with Andrew Ng, founder of DeepLearning.AI, at an event in South Korea. After the event, Kim shared the session on LinkedIn, which caught the attention of Salesforce Ventures. Following several meetings and Zoom calls, the investors extended a soft commitment. The entire funding process took about eight months, Hwang said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new funding will be used to accelerate R&amp;amp;D efforts, particularly in developing automated evaluation tools for enterprise AI, and to scale global go-to-market operations across South Korea, Japan, and the U.S. The startup, which has 150 employees in Seoul, also established a presence in Silicon Valley in March.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Most organizations say they aren’t fully prepared to use generative AI in a safe and responsible way, according to a recent McKinsey report. One concern is explainability — understanding how and why AI makes certain decisions. While 40% of respondents view it as a significant risk, only 17% are actively addressing it, per the report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Seoul-based Datumo began as an AI data labeling company and now wants to help businesses build safer AI with tools and data that enable testing, monitoring, and improving their models — without requiring technical expertise. On Monday the startup raised $15.5 million, which brings its total raised to approximately $28 million, from investors including Salesforce Ventures, KB Investment, ACVC Partners, and SBI Investment, among others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;David Kim, CEO of Datumo and a former AI researcher at Korea’s Agency for Defense Development, was frustrated by the time-consuming nature of data labeling so he came up with a new idea: a reward-based app that lets anyone label data in their spare time and earn money. The startup validated the idea at a startup competition at KAIST (Korea Advanced Institute of Science and Technology). Kim co-founded Datumo, formerly known as SelectStar, alongside five KAIST alumni in 2018.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even before the app was fully built, Datumo secured tens of thousands of dollars in pre-contract sales during the customer discovery phase of the competition, mostly from KAIST alumni-led businesses and startups.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its first year, the startup surpassed $1 million in revenue and secured several key contracts. Today, the startup counts major Korean companies like Samsung, Samsung SDS, LG Electronics, LG CNS, Hyundai, Naver, and Seoul-based telecom giant SK Telecom among its clients. Several years ago, however, clients began asking the company to go beyond simple data labeling. The 7-year-old startup now has more than 300 clients in South Korea and generated about $6 million in revenue in 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“They wanted us to score their AI model outputs or compare them to other outputs,” Michael Hwang, co-founder of Datumo, told TechCrunch. “That’s when we realized: We were already doing AI model evaluation — without even knowing it.” Datumo doubled down on this area and released Korea’s first benchmark dataset focused on AI trust and safety, Hwang added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We started in data annotation, then expanded into pretraining datasets and evaluation as the LLM ecosystem matured,” Kim told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3036051" height="453" src="https://techcrunch.com/wp-content/uploads/2025/08/Selectstar_founders_final2.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;co-founders of datumo&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Datumo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s recent $14.3 billion acquisition-like investment in data-labeling company Scale AI highlights the importance of this market. Shortly after that deal, AI model maker and Meta competitor OpenAI stopped using Scale AI’s services. The Meta deal also signals that competition for AI training data is intensifying.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Datumo shares some similarities with companies like Scale AI in pretraining dataset provisioning, and with Galileo and Arize AI in AI evaluation and monitoring. However, it differentiates itself through its licensed datasets, particularly data crawled from published books, which the company says offers rich structured human reasoning but is notoriously difficult to clean, according to CEO Kim.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike its peers, Datumo also offers a full-stack evaluation platform called Datumo Eval, which automatically generates test data and evaluations to check for unsafe, biased or incorrect responses without the need for manual scripting, Kim added. The signature product is a no-code evaluation tool designed for non-developers like those on policy, trust and safety, and compliance teams.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;When asked about attracting investors like Salesforce Ventures, Kim explained that the startup had previously hosted a fireside chat with Andrew Ng, founder of DeepLearning.AI, at an event in South Korea. After the event, Kim shared the session on LinkedIn, which caught the attention of Salesforce Ventures. Following several meetings and Zoom calls, the investors extended a soft commitment. The entire funding process took about eight months, Hwang said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new funding will be used to accelerate R&amp;amp;D efforts, particularly in developing automated evaluation tools for enterprise AI, and to scale global go-to-market operations across South Korea, Japan, and the U.S. The startup, which has 150 employees in Seoul, also established a presence in Silicon Valley in March.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/11/seoul-based-datumo-raises-15-5m-to-expand-llm-evaluation-challenging-scale-ai/</guid><pubDate>Mon, 11 Aug 2025 23:00:00 +0000</pubDate></item></channel></rss>