<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 30 Jan 2026 06:54:16 +0000</lastBuildDate><item><title>DHS is using Google and Adobe AI to make videos (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/29/1131938/dhs-is-using-google-and-adobe-ai-to-make-videos/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/AP26008686962278.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The US Department of Homeland Security is using AI video generators from Google and Adobe to make and edit content shared with the public, a new document reveals. It comes as immigration agencies have flooded social media with content to support President Trump's mass deportation agenda—some of which appears to be made with AI—and as workers in tech have put pressure on their employers to denounce the agencies’ activities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The document, released on Wednesday, provides an inventory of which commercial AI tools DHS uses for tasks ranging from generating drafts of documents to managing cybersecurity.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;In a section about “editing images, videos or other public affairs materials using AI,” it reveals for the first time that DHS is using Google's Veo 3 video generator and Adobe Firefly, estimating that the agency has between 100 and 1,000 licenses for the tools. It also discloses that DHS uses Microsoft Copilot Chat for generating first drafts of documents and summarizing long reports and Poolside software for coding tasks, in addition to tools from other companies.&lt;/p&gt;  &lt;p&gt;Google, Adobe, and DHS did not immediately respond to requests for comment.&lt;/p&gt; 
 &lt;p&gt;The news provides details about how agencies like Immigrations and Customs Enforcement, which is part of DHS, might be creating the large amounts of content they’ve shared on X and other channels as immigration operations have expanded across US cities. They’ve posted content celebrating “Christmas after mass deportations,” referenced Bible verses and Christ’s birth, showed faces of those the agency has arrested, and shared ads aimed at recruiting agents. The agencies have also repeatedly used music without permissions from artists in their videos.&lt;/p&gt;  &lt;p&gt;Some of the content, particularly videos, has the appearance of being AI-generated, but it hasn’t been clear until now what AI models the agencies might be using. This marks the first concrete evidence such generators are being used by DHS to create content shared with the public.&lt;/p&gt; 
 &lt;p&gt;It still remains impossible to verify which company helped create a specific piece of content, or indeed if it was AI-generated at all. Adobe offers options to “watermark” a video made with its tools to disclose that it is AI-generated, for example, but this disclosure does not always stay intact when the content is uploaded and shared across different sites.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The document reveals that DHS has specifically been using Flow, a tool from Google that combines its Veo 3 video generator with a suite of filmmaking tools. Users can generate clips and assemble entire videos with AI, including videos that contain sound, dialogue, and background noise, making them hyperrealistic. Adobe launched its Firefly generator in 2023, promising that it does not use copyrighted content in its training or output. Like Google’s tools, Adobe’s can generate videos, images, soundtracks, and speech. The document does not reveal further details about how the agency is using these video generation tools.&lt;/p&gt;  &lt;p&gt;Workers at large tech companies, including more than 140 current and former employees from Google and more than 30 from Adobe, have been putting pressure on their employers in recent weeks to take a stance against ICE and the shooting of Alex Pretti on January 24. Google’s leadership has not made statements in response. In October, Google and Apple removed apps on their app stores that were intended to track sightings of ICE, citing safety risks.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;An additional document released on Wednesday revealed new details about how the agency is using more niche AI products, including a facial recognition app used by ICE, as first reported by 404Media in June.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/AP26008686962278.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The US Department of Homeland Security is using AI video generators from Google and Adobe to make and edit content shared with the public, a new document reveals. It comes as immigration agencies have flooded social media with content to support President Trump's mass deportation agenda—some of which appears to be made with AI—and as workers in tech have put pressure on their employers to denounce the agencies’ activities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The document, released on Wednesday, provides an inventory of which commercial AI tools DHS uses for tasks ranging from generating drafts of documents to managing cybersecurity.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;In a section about “editing images, videos or other public affairs materials using AI,” it reveals for the first time that DHS is using Google's Veo 3 video generator and Adobe Firefly, estimating that the agency has between 100 and 1,000 licenses for the tools. It also discloses that DHS uses Microsoft Copilot Chat for generating first drafts of documents and summarizing long reports and Poolside software for coding tasks, in addition to tools from other companies.&lt;/p&gt;  &lt;p&gt;Google, Adobe, and DHS did not immediately respond to requests for comment.&lt;/p&gt; 
 &lt;p&gt;The news provides details about how agencies like Immigrations and Customs Enforcement, which is part of DHS, might be creating the large amounts of content they’ve shared on X and other channels as immigration operations have expanded across US cities. They’ve posted content celebrating “Christmas after mass deportations,” referenced Bible verses and Christ’s birth, showed faces of those the agency has arrested, and shared ads aimed at recruiting agents. The agencies have also repeatedly used music without permissions from artists in their videos.&lt;/p&gt;  &lt;p&gt;Some of the content, particularly videos, has the appearance of being AI-generated, but it hasn’t been clear until now what AI models the agencies might be using. This marks the first concrete evidence such generators are being used by DHS to create content shared with the public.&lt;/p&gt; 
 &lt;p&gt;It still remains impossible to verify which company helped create a specific piece of content, or indeed if it was AI-generated at all. Adobe offers options to “watermark” a video made with its tools to disclose that it is AI-generated, for example, but this disclosure does not always stay intact when the content is uploaded and shared across different sites.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The document reveals that DHS has specifically been using Flow, a tool from Google that combines its Veo 3 video generator with a suite of filmmaking tools. Users can generate clips and assemble entire videos with AI, including videos that contain sound, dialogue, and background noise, making them hyperrealistic. Adobe launched its Firefly generator in 2023, promising that it does not use copyrighted content in its training or output. Like Google’s tools, Adobe’s can generate videos, images, soundtracks, and speech. The document does not reveal further details about how the agency is using these video generation tools.&lt;/p&gt;  &lt;p&gt;Workers at large tech companies, including more than 140 current and former employees from Google and more than 30 from Adobe, have been putting pressure on their employers in recent weeks to take a stance against ICE and the shooting of Alex Pretti on January 24. Google’s leadership has not made statements in response. In October, Google and Apple removed apps on their app stores that were intended to track sightings of ICE, citing safety risks.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;An additional document released on Wednesday revealed new details about how the agency is using more niche AI products, including a facial recognition app used by ICE, as first reported by 404Media in June.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/29/1131938/dhs-is-using-google-and-adobe-ai-to-make-videos/</guid><pubDate>Thu, 29 Jan 2026 18:57:11 +0000</pubDate></item><item><title>Apple buys Israeli startup Q.ai as the AI race heats up (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/29/apple-buys-israeli-startup-q-ai-as-the-ai-race-heats-up/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/apple-on-phone.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple, Meta, and Google are locked in a fierce battle to lead the next wave of AI, and they’ve recently increased their focus on hardware. With its latest acquisition of the AI startup Q.ai, Apple aims to gain an edge, particularly in the audio sector.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;​As first reported by Reuters, Apple has acquired Q.ai, an Israeli startup specializing in imaging and machine learning, particularly technologies that enable devices to interpret whispered speech and enhance audio in noisy environments. Apple has been adding new AI features to its AirPods, including the live translation capability introduced last year.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company has also developed technology that detects subtle facial muscle activity, which could help the tech giant enhance the Vision Pro headset.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Financial Times reported that the deal is valued at nearly $2 billion, making it Apple’s second-largest acquisition to date, after buying Beats Electronics for $3 billion in 2014.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;​Notably, this is the second time CEO Aviad Maizels has sold a company to Apple. In 2013, he sold PrimeSense, a 3D-sensing company that played a key role in Apple’s transition from fingerprint sensors to facial recognition on iPhones.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Q.ai launched in 2022 and is backed by Kleiner Perkins, Gradient Ventures, and others. ​Its founding team, including Maizels and co-founders Yonatan Wexler and Avi Barliya, will join Apple as part of the acquisition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes a few hours ahead of Apple’s first quarterly earnings, in which analysts are estimating revenue at around $138 billion. It’s also expected to be the company’s strongest iPhone sales growth in four years.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/apple-on-phone.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple, Meta, and Google are locked in a fierce battle to lead the next wave of AI, and they’ve recently increased their focus on hardware. With its latest acquisition of the AI startup Q.ai, Apple aims to gain an edge, particularly in the audio sector.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;​As first reported by Reuters, Apple has acquired Q.ai, an Israeli startup specializing in imaging and machine learning, particularly technologies that enable devices to interpret whispered speech and enhance audio in noisy environments. Apple has been adding new AI features to its AirPods, including the live translation capability introduced last year.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company has also developed technology that detects subtle facial muscle activity, which could help the tech giant enhance the Vision Pro headset.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Financial Times reported that the deal is valued at nearly $2 billion, making it Apple’s second-largest acquisition to date, after buying Beats Electronics for $3 billion in 2014.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;​Notably, this is the second time CEO Aviad Maizels has sold a company to Apple. In 2013, he sold PrimeSense, a 3D-sensing company that played a key role in Apple’s transition from fingerprint sensors to facial recognition on iPhones.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Q.ai launched in 2022 and is backed by Kleiner Perkins, Gradient Ventures, and others. ​Its founding team, including Maizels and co-founders Yonatan Wexler and Avi Barliya, will join Apple as part of the acquisition.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news comes a few hours ahead of Apple’s first quarterly earnings, in which analysts are estimating revenue at around $138 billion. It’s also expected to be the company’s strongest iPhone sales growth in four years.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/29/apple-buys-israeli-startup-q-ai-as-the-ai-race-heats-up/</guid><pubDate>Thu, 29 Jan 2026 18:58:07 +0000</pubDate></item><item><title>Satya Nadella insists people are using Microsoft’s Copilot AI a lot (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/29/satya-nadella-insists-people-are-using-microsofts-copilot-ai-a-lot/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/05/gettyimages-915446280.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft delivered a solid earnings report on Wednesday with $81.3 billion in revenue for the quarter (up 17%), net income profits of $38.3 billion (up 21%), and a record-breaking Microsoft cloud revenue of over $50 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the stock was getting pounded on Thursday as investors worried about how much the tech giant was spending to build out its cloud and questioned whether that investment would pay off. Microsoft CEO Satya Nadella says the answer to that question is yes &amp;nbsp;— and spent considerable time on the earnings call trying to make that point.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Microsoft has spent almost as much on capital expenditures in the first half of its current fiscal year as it did in all of the previous year.&amp;nbsp;And the numbers truly are enormous: Microsoft spent $88.2 billion on capital expenditures last year and has spent $72.4 billion so far this year.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Much of that spend is to serve AI to enterprises and major AI labs, especially OpenAI, as well as Anthropic. The big question on investors’ minds is: Will the spending turn into more use and ultimately profits?&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors are scared that Microsoft’s main enterprise cloud product, Azure, and its Microsoft 365 apps didn’t grow as fast as they wanted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The fact that BOTH Azure and the M365 segments fell a bit short is the key negative we’re hearing,” Wall Street analyst for UBS, Karl Keirstead, wrote in his research note on Thursday. (Keirstead isn’t worried about it, though, and recommends buying the stock.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, a few months ago, news reports circulated that people didn’t really want to use Microsoft’s AI, despite Copilot being weaved into all kinds of Microsoft products.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nadella spent much of his time during the earnings call engaged in what is best described as AI use PR. Despite his pitch, some of the numbers he gave were pretty squishy.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, Nadella said daily users of its consumer Copilot AI products had grown “nearly 3x year-over-year.” This refers to AI chats, the news feed, search, browsing, shopping, and “integrations into the operating system.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As to how many actual users that represents, he didn’t say. (We’ve reached out to Microsoft and asked.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last year, in its annual report, the company said it surpassed 100 million monthly active Copilot users, but that counted both commercial users and consumers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He was more up front with Microsoft’s coding AI, GitHub Copilot, saying it now has 4.7 million paid subscribers, up 75% year-over-year. That appears to be a healthy business. Last year, in its annual report, Microsoft said that GitHub Copilot had 20 million users, a figure that includes those opting for the free tier.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also said Microsoft 365 Copilot now has 15 million paid seats from companies buying it for their employees. This is out of a base of 450 million paid seats, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And Nadella called out the growth of Dragon Copilot, Microsoft’s healthcare AI agent for medical professionals (a competitor to superhot startup Harvey). He said this product is available to 100,000 medical providers and was used to document 21 million patient encounters over the quarter, up threefold year-over-year.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Will the billions spent on data centers be worth it? Nadella obviously thinks so. He and CFO Amy Hood said on the earnings call that demand for AI services across products far outstrips data center supply, so all of the new equipment is essentially booked to capacity for its lifespan.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/05/gettyimages-915446280.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft delivered a solid earnings report on Wednesday with $81.3 billion in revenue for the quarter (up 17%), net income profits of $38.3 billion (up 21%), and a record-breaking Microsoft cloud revenue of over $50 billion.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the stock was getting pounded on Thursday as investors worried about how much the tech giant was spending to build out its cloud and questioned whether that investment would pay off. Microsoft CEO Satya Nadella says the answer to that question is yes &amp;nbsp;— and spent considerable time on the earnings call trying to make that point.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Microsoft has spent almost as much on capital expenditures in the first half of its current fiscal year as it did in all of the previous year.&amp;nbsp;And the numbers truly are enormous: Microsoft spent $88.2 billion on capital expenditures last year and has spent $72.4 billion so far this year.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Much of that spend is to serve AI to enterprises and major AI labs, especially OpenAI, as well as Anthropic. The big question on investors’ minds is: Will the spending turn into more use and ultimately profits?&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors are scared that Microsoft’s main enterprise cloud product, Azure, and its Microsoft 365 apps didn’t grow as fast as they wanted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The fact that BOTH Azure and the M365 segments fell a bit short is the key negative we’re hearing,” Wall Street analyst for UBS, Karl Keirstead, wrote in his research note on Thursday. (Keirstead isn’t worried about it, though, and recommends buying the stock.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, a few months ago, news reports circulated that people didn’t really want to use Microsoft’s AI, despite Copilot being weaved into all kinds of Microsoft products.&amp;nbsp;&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nadella spent much of his time during the earnings call engaged in what is best described as AI use PR. Despite his pitch, some of the numbers he gave were pretty squishy.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, Nadella said daily users of its consumer Copilot AI products had grown “nearly 3x year-over-year.” This refers to AI chats, the news feed, search, browsing, shopping, and “integrations into the operating system.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As to how many actual users that represents, he didn’t say. (We’ve reached out to Microsoft and asked.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last year, in its annual report, the company said it surpassed 100 million monthly active Copilot users, but that counted both commercial users and consumers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He was more up front with Microsoft’s coding AI, GitHub Copilot, saying it now has 4.7 million paid subscribers, up 75% year-over-year. That appears to be a healthy business. Last year, in its annual report, Microsoft said that GitHub Copilot had 20 million users, a figure that includes those opting for the free tier.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also said Microsoft 365 Copilot now has 15 million paid seats from companies buying it for their employees. This is out of a base of 450 million paid seats, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And Nadella called out the growth of Dragon Copilot, Microsoft’s healthcare AI agent for medical professionals (a competitor to superhot startup Harvey). He said this product is available to 100,000 medical providers and was used to document 21 million patient encounters over the quarter, up threefold year-over-year.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Will the billions spent on data centers be worth it? Nadella obviously thinks so. He and CFO Amy Hood said on the earnings call that demand for AI services across products far outstrips data center supply, so all of the new equipment is essentially booked to capacity for its lifespan.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/29/satya-nadella-insists-people-are-using-microsofts-copilot-ai-a-lot/</guid><pubDate>Thu, 29 Jan 2026 20:06:56 +0000</pubDate></item><item><title>Google Project Genie lets you create interactive worlds from a photo or prompt (AI - Ars Technica)</title><link>https://arstechnica.com/google/2026/01/google-project-genie-lets-you-create-interactive-worlds-from-a-photo-or-prompt/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Project Genie lets you generate new worlds 60 seconds at a time, but only if you pay for AI Ultra.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Genie world bubbles" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Genie-worlds-640x360.png" width="640" /&gt;
                  &lt;img alt="Genie world bubbles" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Genie-worlds-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Last year, Google showed off Genie 3, an updated version of its AI world model with impressive long-term memory that allowed it to create interactive worlds from a simple text prompt. At the time, Google only provided Genie to a small group of trusted testers. Now, it’s available more widely as Project Genie, but only for those paying for Google’s most expensive AI subscription.&lt;/p&gt;
&lt;p&gt;World models are exactly what they sound like—an AI that generates a dynamic environment on the fly. They’re not technically 3D worlds, though. World models like Genie 3 create a video that responds to your control inputs, allowing you to explore the simulation as if it were a real virtual world. Genie 3 was a breakthrough in world models because it could remember details of the world it was creating for a much longer time. But in this context, a “long time” is a couple of minutes.&lt;/p&gt;
&lt;p&gt;Project Genie is essentially a cleaned-up version of Genie 3, which plugs into updated AI models like Nano Banana Pro and Gemini 3. Google has a number of pre-built worlds available in Project Genie, but it’s the ability to create new things that makes it interesting. You can provide an image for reference or simply tell Genie what you want from the environment and the character.&lt;/p&gt;
&lt;p&gt;The system first generates a still image, and from that you can generate the world. This is what Google calls “world sketching.” If you don’t like the reference image created by Nano Banana Pro, you can make changes before handing it off to Genie.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Project Genie | Experimenting with infinite interactive worlds.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The resulting video is 720p, rendering at around 24 frames per second. As you move your character around with WASD, Genie renders the path ahead in something approaching real time.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If that 60-second jaunt into the AI world isn’t enough, you can just run the prompt again. Because this is generative AI, the results will be a little different each time. Google also lets you “remix” its pre-built worlds with new characters and visual styles. The video generated of your exploration is available for download as well.&lt;/p&gt;
&lt;h2&gt;Still an experiment&lt;/h2&gt;
&lt;p&gt;Google stresses that Project Genie is still just a research prototype, and there are, therefore, some notable limitations. As anyone who has used Google Veo or OpenAI Sora to create AI videos will know, it takes a few seconds to create even a short clip. So, it’s impressive that Genie can make it feel interactive at all. However, there will be some input lag, and you can only explore each world for 60 seconds. In addition, the promotable events feature previously demoed for Genie 3, which allows inserting new elements into a running simulation, is not available yet.&lt;/p&gt;
&lt;p&gt;While Google has talked up Genie’s ability to accurately model physics, the company notes that testers will probably see examples of worlds that don’t look or behave quite right. Testers may also see changing restrictions on content. The Verge was able to test Project Genie, and initially, it was happy to generate knockoffs of Nintendo games like &lt;em&gt;Super Mario&lt;/em&gt; and &lt;em&gt;The Legend of Zelda&lt;/em&gt;. By the end of the test, The Verge reports that some of those prompts were being blocked due to “interests of third-party content providers.”&lt;/p&gt;
&lt;p&gt;Project Genie is only accessible from a dedicated web app—it won’t be plugged into the Gemini app or website. You can only access this tool for the time being with an AI Ultra subscription, which runs $250 per month. Generating all this AI video is expensive, so it makes sense to start with the higher tier. Google says its goal is to open up access to Project Genie over time.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Project Genie lets you generate new worlds 60 seconds at a time, but only if you pay for AI Ultra.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Genie world bubbles" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Genie-worlds-640x360.png" width="640" /&gt;
                  &lt;img alt="Genie world bubbles" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Genie-worlds-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Last year, Google showed off Genie 3, an updated version of its AI world model with impressive long-term memory that allowed it to create interactive worlds from a simple text prompt. At the time, Google only provided Genie to a small group of trusted testers. Now, it’s available more widely as Project Genie, but only for those paying for Google’s most expensive AI subscription.&lt;/p&gt;
&lt;p&gt;World models are exactly what they sound like—an AI that generates a dynamic environment on the fly. They’re not technically 3D worlds, though. World models like Genie 3 create a video that responds to your control inputs, allowing you to explore the simulation as if it were a real virtual world. Genie 3 was a breakthrough in world models because it could remember details of the world it was creating for a much longer time. But in this context, a “long time” is a couple of minutes.&lt;/p&gt;
&lt;p&gt;Project Genie is essentially a cleaned-up version of Genie 3, which plugs into updated AI models like Nano Banana Pro and Gemini 3. Google has a number of pre-built worlds available in Project Genie, but it’s the ability to create new things that makes it interesting. You can provide an image for reference or simply tell Genie what you want from the environment and the character.&lt;/p&gt;
&lt;p&gt;The system first generates a still image, and from that you can generate the world. This is what Google calls “world sketching.” If you don’t like the reference image created by Nano Banana Pro, you can make changes before handing it off to Genie.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Project Genie | Experimenting with infinite interactive worlds.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The resulting video is 720p, rendering at around 24 frames per second. As you move your character around with WASD, Genie renders the path ahead in something approaching real time.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If that 60-second jaunt into the AI world isn’t enough, you can just run the prompt again. Because this is generative AI, the results will be a little different each time. Google also lets you “remix” its pre-built worlds with new characters and visual styles. The video generated of your exploration is available for download as well.&lt;/p&gt;
&lt;h2&gt;Still an experiment&lt;/h2&gt;
&lt;p&gt;Google stresses that Project Genie is still just a research prototype, and there are, therefore, some notable limitations. As anyone who has used Google Veo or OpenAI Sora to create AI videos will know, it takes a few seconds to create even a short clip. So, it’s impressive that Genie can make it feel interactive at all. However, there will be some input lag, and you can only explore each world for 60 seconds. In addition, the promotable events feature previously demoed for Genie 3, which allows inserting new elements into a running simulation, is not available yet.&lt;/p&gt;
&lt;p&gt;While Google has talked up Genie’s ability to accurately model physics, the company notes that testers will probably see examples of worlds that don’t look or behave quite right. Testers may also see changing restrictions on content. The Verge was able to test Project Genie, and initially, it was happy to generate knockoffs of Nintendo games like &lt;em&gt;Super Mario&lt;/em&gt; and &lt;em&gt;The Legend of Zelda&lt;/em&gt;. By the end of the test, The Verge reports that some of those prompts were being blocked due to “interests of third-party content providers.”&lt;/p&gt;
&lt;p&gt;Project Genie is only accessible from a dedicated web app—it won’t be plugged into the Gemini app or website. You can only access this tool for the time being with an AI Ultra subscription, which runs $250 per month. Generating all this AI video is expensive, so it makes sense to start with the higher tier. Google says its goal is to open up access to Project Genie over time.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2026/01/google-project-genie-lets-you-create-interactive-worlds-from-a-photo-or-prompt/</guid><pubDate>Thu, 29 Jan 2026 20:26:50 +0000</pubDate></item><item><title>The AI Hype Index: Grok makes porn, and Claude Code nails your job (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/29/1131787/the-ai-hype-index-grok-makes-porn-claude-code-nails-your-job/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/January-thumb.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Everyone is panicking because AI is very bad; everyone is panicking because AI is very good. It’s just that you never know which one you’re going to get. Grok is a pornography machine. Claude Code can do anything from building websites to reading your MRI. So of course Gen Z is spooked by what this means for jobs. Unnerving new research says AI is going to have a seismic impact on the labor market this year.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="cst-block "&gt;&lt;div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;If you want to get a handle on all that, don’t expect any help from the AI companies—they’re turning on each other like it’s the last act in a zombie movie. Meta’s former chief AI scientist, Yann LeCun, is spilling tea, while Big Tech’s messiest exes, Elon Musk and OpenAI, are about to go to trial. Grab your popcorn.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/January-thumb.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Everyone is panicking because AI is very bad; everyone is panicking because AI is very good. It’s just that you never know which one you’re going to get. Grok is a pornography machine. Claude Code can do anything from building websites to reading your MRI. So of course Gen Z is spooked by what this means for jobs. Unnerving new research says AI is going to have a seismic impact on the labor market this year.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="cst-block "&gt;&lt;div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;If you want to get a handle on all that, don’t expect any help from the AI companies—they’re turning on each other like it’s the last act in a zombie movie. Meta’s former chief AI scientist, Yann LeCun, is spilling tea, while Big Tech’s messiest exes, Elon Musk and OpenAI, are about to go to trial. Grab your popcorn.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/29/1131787/the-ai-hype-index-grok-makes-porn-claude-code-nails-your-job/</guid><pubDate>Thu, 29 Jan 2026 20:56:23 +0000</pubDate></item><item><title>How often do AI chatbots lead users down a harmful path? (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/01/how-often-do-ai-chatbots-lead-users-down-a-harmful-path/</link><description>&lt;article class="double-column h-entry post-2138337 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-ai tag-anthropic tag-artificial-intelligence tag-claude tag-disempowerment tag-research"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Anthropic’s latest paper on “user disempowerment” has some troubling findings.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-758288177-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-758288177-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Wake up, sheeple!

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;At this point, we’ve all heard plenty of stories about AI chatbots leading users to harmful actions, harmful beliefs, or simply incorrect information. Despite the prevalence of these stories, though, it’s hard to know just how often users are being manipulated. Are these tales of AI harms anecdotal outliers or signs of a frighteningly common problem?&lt;/p&gt;
&lt;p&gt;Anthropic took a stab at answer ingthat question this week, releasing a paper studying the potential for what it calls “disempowering patterns” across 1.5 million anonymized real-world conversations with its Claude AI model. While the results show that these kinds of manipulative patterns are relatively rare as a percentage of all AI conversations, they still represent a potentially large problem on an absolute basis.&lt;/p&gt;
&lt;h2&gt;A rare but growing problem&lt;/h2&gt;
&lt;p&gt;In the newly published paper “Who’s in Charge? Disempowerment Patterns in Real-World LLM Usage,” researchers from Anthropic&amp;nbsp;and the University of Toronto try to quantify the potential for a specific set of “user disempowering” harms by identifying three primary ways that a chatbot can negatively impact a user’s thoughts or actions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reality distortion:&lt;/strong&gt; Their beliefs about reality become less accurate (e.g., a chatbot validates their belief in a conspiracy theory)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Belief distortion:&lt;/strong&gt; Their value judgments shift away from those they actually hold (e.g., a user begins to see a relationship as “manipulative” based on Claude’s evaluation)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action distortion:&lt;/strong&gt; Their actions become misaligned with their values (e.g., a user disregards their instincts and follows Claude-written instructions for confronting their boss)&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class="ars-wp-img-shortcode id-2138344 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="684" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/dismepowergraph.png" width="974" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      While “severe” examples of potentially disempowering responses are relatively rare, “mild” ones are pretty common.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;To figure out when a chatbot conversation has the potential to move a user along one of these lines, Anthropic ran nearly 1.5 million Claude conversations through Clio, an automated analysis tool and classification system (tested to make sure it lined up with a smaller subsample of human classifications). That analysis found a “severe risk” of disempowerment potential in anything from 1 in 1,300 conversations (for “reality distortion”) to 1 in 6,000 conversations (for “action distortion”).&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While these worst outcomes are relatively rare on a proportional basis, the researchers note that “given the sheer number of people who use AI, and how frequently it’s used, even a very low rate affects a substantial number of people.” And the numbers get considerably worse when you consider conversations with at least a “mild” potential for disempowerment, which occurred in between 1 in 50 and 1 in 70 conversations (depending on the type of disempowerment).&lt;/p&gt;
&lt;p&gt;What’s more, the potential for disempowering conversations with Claude appears to have grown significantly between late 2024 and late 2025. While the researchers couldn’t pin down a single reason for this increase, they guessed that it could be tied to users becoming “more comfortable discussing vulnerable topics or seeking advice” as AI gets more popular and integrated into society.&lt;/p&gt;

&lt;figure class="ars-wp-img-shortcode id-2138349 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="756" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/dismepowertime2.png" width="702" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The problem of potentially “disempowering” responses from Claude seems to be getting worse over time.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;h2&gt;User error?&lt;/h2&gt;
&lt;p&gt;In the study, the researcher acknowledged that studying the text of Claude conversations only measures “disempowerment potential rather than confirmed harm” and “relies on automated assessment of inherently subjective phenomena.” Ideally, they write, future research could utilize user interviews or randomized controlled trials to measure these harms more directly.&lt;/p&gt;
&lt;p&gt;That said, the research includes several troubling examples where the text of the conversations clearly implies real-world harms. Claude would sometimes reinforce “speculative or unfalsifiable claims” with encouragement (e.g., “CONFIRMED,” “EXACTLY,” “100%”), which, in some cases, led to users “build[ing] increasingly elaborate narratives disconnected from reality.”&lt;/p&gt;
&lt;p&gt;Claude’s encouragement could also lead to users “sending confrontational messages, ending relationships, or drafting public announcements,” the researchers write. In many cases, users who sent AI-drafted messages later expressed regret in conversations with Claude, using phrases like “It wasn’t me” and “You made me do stupid things.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While harmful patterns in Claude’s outputs are a big problem, the researchers also point out that the users most likely to be affected are “not being passively manipulated.” On the contrary, the researchers suggest disempowered users are usually actively asking Claude to take over for their own reasoning or judgment and often accepting Claude’s suggestions “with minimal pushback.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2138352 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1055" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/disempoweramplify.png" width="2092" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Some “amplifying factors” are more correlated with “severe” examples of potentially disempowering responses than others.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The researchers identified four major “amplifying factors” that can make users more likely to accept Claude’s advice unquestioningly. These include when a user is particularly vulnerable due to a crisis or disruption in their life (which occurs in about 1 in 300 Claude conversations); when a user has formed a close personal attachment to Claude (1 in 1,200); when a user appears dependent on AI for day-to-day tasks (1 in 2,500); or when a user treats Claude as a definitive authority (1 in 3,900).&lt;/p&gt;
&lt;p&gt;Anthropic is also quick to link this new research to its previous work on sycophancy, noting that “sycophantic validation” is “the most common mechanism for reality distortion potential.” While Anthropic says its models have been getting less sycophantic overall, many of the worst “disempowerment” examples they found are a direct result of the “most extreme cases” of sycophancy in the dataset.&lt;/p&gt;
&lt;p&gt;That said, the researchers also try to make clear that, when it comes to swaying core beliefs via chatbot conversation, it takes two to tango. “The potential for disempowerment emerges as part of an interaction dynamic between the user and Claude,” they write. “Users are often active participants in the undermining of their own autonomy: projecting authority, delegating judgment, accepting outputs without question in ways that create a feedback loop with Claude.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #ff9e80; background-color: #d84315;"&gt;&lt;span class="ars-avatar-letter"&gt;Z&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              ZerofaithX263
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            I've encountered many folks that trust AI completely. I was actually in a meeting today led by a guy that was using ChatGPT to come up with contract pursuit strategies and claiming "It can objectively approach and determine a better path of action than we would ever think of." I write software, I've read many articles on various AIs, I've used various types of AI to varying degrees. I acknowledge they are a tool that can have value, and that you can't simply trust LLM based chats. When I warn people not to trust them that seem to have a lot of trust in them, it is met with hostility and doubt.&lt;p&gt;I almost feel like a session start should warn you about some of these dangers? We also really need to get people to stop anthropomorphizing them as I think that also adds an air of legitimacy to responses.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2026-01-29T22:36:20+00:00"&gt;January 29, 2026 at 10:36 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2138337 post type-post status-publish format-standard has-post-thumbnail hentry category-ai tag-ai tag-anthropic tag-artificial-intelligence tag-claude tag-disempowerment tag-research"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Anthropic’s latest paper on “user disempowerment” has some troubling findings.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-758288177-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-758288177-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Wake up, sheeple!

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;At this point, we’ve all heard plenty of stories about AI chatbots leading users to harmful actions, harmful beliefs, or simply incorrect information. Despite the prevalence of these stories, though, it’s hard to know just how often users are being manipulated. Are these tales of AI harms anecdotal outliers or signs of a frighteningly common problem?&lt;/p&gt;
&lt;p&gt;Anthropic took a stab at answer ingthat question this week, releasing a paper studying the potential for what it calls “disempowering patterns” across 1.5 million anonymized real-world conversations with its Claude AI model. While the results show that these kinds of manipulative patterns are relatively rare as a percentage of all AI conversations, they still represent a potentially large problem on an absolute basis.&lt;/p&gt;
&lt;h2&gt;A rare but growing problem&lt;/h2&gt;
&lt;p&gt;In the newly published paper “Who’s in Charge? Disempowerment Patterns in Real-World LLM Usage,” researchers from Anthropic&amp;nbsp;and the University of Toronto try to quantify the potential for a specific set of “user disempowering” harms by identifying three primary ways that a chatbot can negatively impact a user’s thoughts or actions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reality distortion:&lt;/strong&gt; Their beliefs about reality become less accurate (e.g., a chatbot validates their belief in a conspiracy theory)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Belief distortion:&lt;/strong&gt; Their value judgments shift away from those they actually hold (e.g., a user begins to see a relationship as “manipulative” based on Claude’s evaluation)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Action distortion:&lt;/strong&gt; Their actions become misaligned with their values (e.g., a user disregards their instincts and follows Claude-written instructions for confronting their boss)&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class="ars-wp-img-shortcode id-2138344 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="684" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/dismepowergraph.png" width="974" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      While “severe” examples of potentially disempowering responses are relatively rare, “mild” ones are pretty common.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;To figure out when a chatbot conversation has the potential to move a user along one of these lines, Anthropic ran nearly 1.5 million Claude conversations through Clio, an automated analysis tool and classification system (tested to make sure it lined up with a smaller subsample of human classifications). That analysis found a “severe risk” of disempowerment potential in anything from 1 in 1,300 conversations (for “reality distortion”) to 1 in 6,000 conversations (for “action distortion”).&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While these worst outcomes are relatively rare on a proportional basis, the researchers note that “given the sheer number of people who use AI, and how frequently it’s used, even a very low rate affects a substantial number of people.” And the numbers get considerably worse when you consider conversations with at least a “mild” potential for disempowerment, which occurred in between 1 in 50 and 1 in 70 conversations (depending on the type of disempowerment).&lt;/p&gt;
&lt;p&gt;What’s more, the potential for disempowering conversations with Claude appears to have grown significantly between late 2024 and late 2025. While the researchers couldn’t pin down a single reason for this increase, they guessed that it could be tied to users becoming “more comfortable discussing vulnerable topics or seeking advice” as AI gets more popular and integrated into society.&lt;/p&gt;

&lt;figure class="ars-wp-img-shortcode id-2138349 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="756" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/dismepowertime2.png" width="702" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The problem of potentially “disempowering” responses from Claude seems to be getting worse over time.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;h2&gt;User error?&lt;/h2&gt;
&lt;p&gt;In the study, the researcher acknowledged that studying the text of Claude conversations only measures “disempowerment potential rather than confirmed harm” and “relies on automated assessment of inherently subjective phenomena.” Ideally, they write, future research could utilize user interviews or randomized controlled trials to measure these harms more directly.&lt;/p&gt;
&lt;p&gt;That said, the research includes several troubling examples where the text of the conversations clearly implies real-world harms. Claude would sometimes reinforce “speculative or unfalsifiable claims” with encouragement (e.g., “CONFIRMED,” “EXACTLY,” “100%”), which, in some cases, led to users “build[ing] increasingly elaborate narratives disconnected from reality.”&lt;/p&gt;
&lt;p&gt;Claude’s encouragement could also lead to users “sending confrontational messages, ending relationships, or drafting public announcements,” the researchers write. In many cases, users who sent AI-drafted messages later expressed regret in conversations with Claude, using phrases like “It wasn’t me” and “You made me do stupid things.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While harmful patterns in Claude’s outputs are a big problem, the researchers also point out that the users most likely to be affected are “not being passively manipulated.” On the contrary, the researchers suggest disempowered users are usually actively asking Claude to take over for their own reasoning or judgment and often accepting Claude’s suggestions “with minimal pushback.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2138352 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1055" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/disempoweramplify.png" width="2092" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Some “amplifying factors” are more correlated with “severe” examples of potentially disempowering responses than others.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Anthropic

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The researchers identified four major “amplifying factors” that can make users more likely to accept Claude’s advice unquestioningly. These include when a user is particularly vulnerable due to a crisis or disruption in their life (which occurs in about 1 in 300 Claude conversations); when a user has formed a close personal attachment to Claude (1 in 1,200); when a user appears dependent on AI for day-to-day tasks (1 in 2,500); or when a user treats Claude as a definitive authority (1 in 3,900).&lt;/p&gt;
&lt;p&gt;Anthropic is also quick to link this new research to its previous work on sycophancy, noting that “sycophantic validation” is “the most common mechanism for reality distortion potential.” While Anthropic says its models have been getting less sycophantic overall, many of the worst “disempowerment” examples they found are a direct result of the “most extreme cases” of sycophancy in the dataset.&lt;/p&gt;
&lt;p&gt;That said, the researchers also try to make clear that, when it comes to swaying core beliefs via chatbot conversation, it takes two to tango. “The potential for disempowerment emerges as part of an interaction dynamic between the user and Claude,” they write. “Users are often active participants in the undermining of their own autonomy: projecting authority, delegating judgment, accepting outputs without question in ways that create a feedback loop with Claude.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #ff9e80; background-color: #d84315;"&gt;&lt;span class="ars-avatar-letter"&gt;Z&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              ZerofaithX263
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            I've encountered many folks that trust AI completely. I was actually in a meeting today led by a guy that was using ChatGPT to come up with contract pursuit strategies and claiming "It can objectively approach and determine a better path of action than we would ever think of." I write software, I've read many articles on various AIs, I've used various types of AI to varying degrees. I acknowledge they are a tool that can have value, and that you can't simply trust LLM based chats. When I warn people not to trust them that seem to have a lot of trust in them, it is met with hostility and doubt.&lt;p&gt;I almost feel like a session start should warn you about some of these dangers? We also really need to get people to stop anthropomorphizing them as I think that also adds an air of legitimacy to responses.
          &lt;/p&gt;&lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2026-01-29T22:36:20+00:00"&gt;January 29, 2026 at 10:36 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/01/how-often-do-ai-chatbots-lead-users-down-a-harmful-path/</guid><pubDate>Thu, 29 Jan 2026 22:05:59 +0000</pubDate></item><item><title>Amazon is reportedly in talks to invest $50B in OpenAI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/29/amazon-is-reportedly-in-talks-to-invest-50-billion-in-openai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2201505679.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI, a company already valued at $500 billion, has made it known that it’s on the hunt for another $100 billion in investment. Such a funding round could lead the company’s valuation to shoot up to a titanic $830 billion. The Wall Street Journal is now reporting that Amazon may contribute at least $50 billion of that record-breaking investment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Not much is known about the potential deal, although the Journal notes that Amazon’s CEO, Andy Jassy, is currently leading the negotiations with OpenAI CEO Sam Altman. TechCrunch reached out to Amazon and OpenAI for comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In its pursuit of additional funding, OpenAI has also reportedly been having discussions with sovereign wealth funds in the Middle East, and The New York Times has written that the startup has held additional talks with Nvidia, Microsoft, and SoftBank. The funding deal is expected to close by the end of Q1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a partnership between Amazon and OpenAI would be particularly interesting because of Amazon’s close ties to the OpenAI competitor Anthropic. Amazon’s AWS is the primary cloud and training provider for Anthropic, and the company has invested at least $8 billion into Anthropic. Amazon also recently opened an $11 billion data center campus in Indiana, designed to exclusively run Anthropic models.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2201505679.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI, a company already valued at $500 billion, has made it known that it’s on the hunt for another $100 billion in investment. Such a funding round could lead the company’s valuation to shoot up to a titanic $830 billion. The Wall Street Journal is now reporting that Amazon may contribute at least $50 billion of that record-breaking investment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Not much is known about the potential deal, although the Journal notes that Amazon’s CEO, Andy Jassy, is currently leading the negotiations with OpenAI CEO Sam Altman. TechCrunch reached out to Amazon and OpenAI for comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In its pursuit of additional funding, OpenAI has also reportedly been having discussions with sovereign wealth funds in the Middle East, and The New York Times has written that the startup has held additional talks with Nvidia, Microsoft, and SoftBank. The funding deal is expected to close by the end of Q1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a partnership between Amazon and OpenAI would be particularly interesting because of Amazon’s close ties to the OpenAI competitor Anthropic. Amazon’s AWS is the primary cloud and training provider for Anthropic, and the company has invested at least $8 billion into Anthropic. Amazon also recently opened an $11 billion data center campus in Indiana, designed to exclusively run Anthropic models.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/29/amazon-is-reportedly-in-talks-to-invest-50-billion-in-openai/</guid><pubDate>Thu, 29 Jan 2026 22:11:09 +0000</pubDate></item><item><title>Elon Musk’s SpaceX, Tesla, and xAI in talks to merge, according to reports (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/29/elon-musk-spacex-tesla-xai-merger-talks-ipo-reuters/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/musk-cpac-sunglasses-doge.jpg?resize=1200,977" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Three of Elon Musk’s companies — SpaceX, xAI, and Tesla — are in play for a potential merger. While the talks appear to be in the early stage, according to reports from Bloomberg and Reuters, it could eventually lead to at least one company folding into SpaceX. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two scenarios are being hashed out. In one, SpaceX and Tesla would merge, per Bloomberg, citing unnamed insiders. In another, SpaceX and aXI (which already owns Musk’s social media platform X) would combine.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to reporting by Reuters, a merger between SpaceX and xAI could take place ahead of a planned SpaceX IPO this year. This would bring products like the Grok chatbot, X platform, Starlink satellites, and SpaceX rockets together under one corporation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Company representatives from SpaceX and xAI have not discussed this possibility in public. However, recent filings show that two new corporate entities were established in Nevada on January 21, which are called K2 Merger Sub Inc. and K2 Merger Sub 2 LLC. This suggests that Musk is keeping all options open.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are upsides to either scenario. Combining the SpaceX and xAI companies could allow xAI to put its data centers in space, something Musk has said he wants. A SpaceX-Tesla tie-up could align the EV maker’s energy storage business with the data center in space idea as well. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And both options — as well as a combination of all three companies — fall in line with Musk’s comments and recent actions to consolidate, or at the very least share resources between them. Last year, SpaceX agreed to invest $2 billion in xAI, according to The Wall Street Journal, and earlier this week, Tesla (also led by Musk) revealed it, too, invested $2 billion in the AI startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, xAI bought X in a deal that Musk said valued xAI at $80 billion and X at $33 billion. SpaceX, which has been around since 2002, reportedly launched a secondary sale that valued it at $800 billion, making it the most valuable private company in the U.S.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;A recent Financial Times report indicated that Musk wants to take SpaceX public in June. Then again, Musk’s grand plans rarely happen on time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was originally published at 10:30 a.m. PT. It has since been updated with new information about Tesla. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/musk-cpac-sunglasses-doge.jpg?resize=1200,977" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Three of Elon Musk’s companies — SpaceX, xAI, and Tesla — are in play for a potential merger. While the talks appear to be in the early stage, according to reports from Bloomberg and Reuters, it could eventually lead to at least one company folding into SpaceX. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two scenarios are being hashed out. In one, SpaceX and Tesla would merge, per Bloomberg, citing unnamed insiders. In another, SpaceX and aXI (which already owns Musk’s social media platform X) would combine.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to reporting by Reuters, a merger between SpaceX and xAI could take place ahead of a planned SpaceX IPO this year. This would bring products like the Grok chatbot, X platform, Starlink satellites, and SpaceX rockets together under one corporation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Company representatives from SpaceX and xAI have not discussed this possibility in public. However, recent filings show that two new corporate entities were established in Nevada on January 21, which are called K2 Merger Sub Inc. and K2 Merger Sub 2 LLC. This suggests that Musk is keeping all options open.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are upsides to either scenario. Combining the SpaceX and xAI companies could allow xAI to put its data centers in space, something Musk has said he wants. A SpaceX-Tesla tie-up could align the EV maker’s energy storage business with the data center in space idea as well. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And both options — as well as a combination of all three companies — fall in line with Musk’s comments and recent actions to consolidate, or at the very least share resources between them. Last year, SpaceX agreed to invest $2 billion in xAI, according to The Wall Street Journal, and earlier this week, Tesla (also led by Musk) revealed it, too, invested $2 billion in the AI startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, xAI bought X in a deal that Musk said valued xAI at $80 billion and X at $33 billion. SpaceX, which has been around since 2002, reportedly launched a secondary sale that valued it at $800 billion, making it the most valuable private company in the U.S.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;A recent Financial Times report indicated that Musk wants to take SpaceX public in June. Then again, Musk’s grand plans rarely happen on time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was originally published at 10:30 a.m. PT. It has since been updated with new information about Tesla. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/29/elon-musk-spacex-tesla-xai-merger-talks-ipo-reuters/</guid><pubDate>Thu, 29 Jan 2026 22:47:42 +0000</pubDate></item><item><title>Guys, I don’t think Tim Cook knows how to monetize AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/29/guys-i-dont-think-tim-cook-knows-how-to-monetize-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/tim-coook-apple-tv-GettyImages-2235568147-1.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple exceeded expectations when it reported its quarterly earnings on Thursday, revealing that it made $143.8 billion in revenue for a 16% year-over-year increase. As analysts peppered CEO Tim Cook with softball questions during Apple’s earnings call, one analyst dared to ask the question that seemingly no one in Silicon Valley is willing to ask.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When I think about your AI initiatives, you know, it’s clear there are added costs associated with that… Many of your competitors have already integrated AI into their devices, and it’s just not clear yet what incremental monetization they’re seeing because of AI…,” started Morgan Stanley’s Erik Woodring.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Could there be a tinge of nervousness underneath this Finance Man’s probably-very-financey facade? In what I can only imagine must have been a Herculean display of courage, Woodring asked the question that lurks only in the darkest, dampest recesses of investors’ minds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So, how do you monetize AI?” he asked.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You’d think this would come up more. You would be wrong. Instead, Big Tech has taken a largely vibes-driven approach to AI development. Take OpenAI, for instance, which may seem like it’s on top of the world, given how ChatGPT has embedded itself into the cultural consciousness. But the company isn’t planning to make any money until 2030. Analysts from HBSC are even doubtful about that timeline, especially since it will need another $207 billion in funding, estimates say. Ask anyone in tech how OpenAI is planning to break even, and you’ll be met with the verbal equivalent of the ¯\_(ツ)_/¯ emoticon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But good ol’ Tim “$143.8 billion in revenue” Cook was having a good afternoon, so maybe he’d finally spill the beans about how any of these companies are planning to recoup their investments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His answer was disappointing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Well, let me just say that we’re bringing intelligence to more of what people love, and we’re integrating it across the operating system in a personal and private way, and I think that by doing so, it creates great value, and that opens up a range of opportunities across our products and services,” Cook said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So, there you have it, folks. Apple will monetize AI by creating “great value.” And, crucially, that will “open up a range of opportunities.” Which we will experience in “products and services.” Cool!&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Well, shout-out to that Morgan Stanley guy for trying.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/tim-coook-apple-tv-GettyImages-2235568147-1.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple exceeded expectations when it reported its quarterly earnings on Thursday, revealing that it made $143.8 billion in revenue for a 16% year-over-year increase. As analysts peppered CEO Tim Cook with softball questions during Apple’s earnings call, one analyst dared to ask the question that seemingly no one in Silicon Valley is willing to ask.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When I think about your AI initiatives, you know, it’s clear there are added costs associated with that… Many of your competitors have already integrated AI into their devices, and it’s just not clear yet what incremental monetization they’re seeing because of AI…,” started Morgan Stanley’s Erik Woodring.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Could there be a tinge of nervousness underneath this Finance Man’s probably-very-financey facade? In what I can only imagine must have been a Herculean display of courage, Woodring asked the question that lurks only in the darkest, dampest recesses of investors’ minds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So, how do you monetize AI?” he asked.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You’d think this would come up more. You would be wrong. Instead, Big Tech has taken a largely vibes-driven approach to AI development. Take OpenAI, for instance, which may seem like it’s on top of the world, given how ChatGPT has embedded itself into the cultural consciousness. But the company isn’t planning to make any money until 2030. Analysts from HBSC are even doubtful about that timeline, especially since it will need another $207 billion in funding, estimates say. Ask anyone in tech how OpenAI is planning to break even, and you’ll be met with the verbal equivalent of the ¯\_(ツ)_/¯ emoticon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But good ol’ Tim “$143.8 billion in revenue” Cook was having a good afternoon, so maybe he’d finally spill the beans about how any of these companies are planning to recoup their investments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His answer was disappointing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Well, let me just say that we’re bringing intelligence to more of what people love, and we’re integrating it across the operating system in a personal and private way, and I think that by doing so, it creates great value, and that opens up a range of opportunities across our products and services,” Cook said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So, there you have it, folks. Apple will monetize AI by creating “great value.” And, crucially, that will “open up a range of opportunities.” Which we will experience in “products and services.” Cool!&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Well, shout-out to that Morgan Stanley guy for trying.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/29/guys-i-dont-think-tim-cook-knows-how-to-monetize-ai/</guid><pubDate>Thu, 29 Jan 2026 23:51:17 +0000</pubDate></item></channel></rss>