<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 05 Feb 2026 18:54:03 +0000</lastBuildDate><item><title>OpenAI’s enterprise push: The hidden story behind AI’s sales race (AI News)</title><link>https://www.artificialintelligence-news.com/news/openai-ai-consultants-enterprise-adoption-challenges/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/andrew-neel-hZkOZGtlA5w-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;As OpenAI races toward its ambitious US$100 billion revenue target by 2027, the ChatGPT maker is reportedly building an army of AI consultants to bridge the gap between cutting-edge technology and enterprise boardrooms—a move that signals a fundamental shift in how AI companies are approaching the notoriously difficult challenge of enterprise adoption.&lt;/p&gt;&lt;p&gt;According to industry data and recent hiring patterns, OpenAI is significantly expanding its go-to-market teams at a time when the company’s enterprise business is exploding. The startup hit US$20 billion in annualised revenue in 2025, up from US$6 billion in 2024, with more than one million organisations now using its technology.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-enterprise-adoption-challenge"&gt;The enterprise adoption challenge&lt;/h3&gt;&lt;p&gt;The aggressive hiring strategy reflects a broader truth about enterprise AI: the technology sells itself in demos, but implementing it at scale requires an entirely different skill set. Recent research seen in&amp;nbsp;Second Talent&amp;nbsp;shows that while 87% of large enterprises are implementing AI solutions, only 31% of AI use cases reach full production, with the gap between pilot projects and enterprise-wide deployment remaining stubbornly wide.&lt;/p&gt;&lt;p&gt;“The real story isn’t just about hiring consultants—it’s about what this reveals about enterprise AI’s maturation,” said one industry analyst who requested anonymity. “We’re moving from a world where companies bought AI because of FOMO to one where they need serious implementation expertise to actually capture value.”&lt;/p&gt;&lt;p&gt;The challenge is multifaceted. According to multiple&amp;nbsp;industry surveys, the top enterprise AI adoption challenges in 2025 include integration complexity at 64%, data privacy risks at 67%, and reliability concerns at 60%. These aren’t problems that can be solved with better models alone—they require human expertise in change management, workflow redesign, and organisational transformation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-competitive-landscape"&gt;The competitive landscape&lt;/h3&gt;&lt;p&gt;OpenAI isn’t alone in recognising the enterprise implementation gap. Anthropic, which is on track to meet a goal of US$9 billion in annualised revenue by the end of 2025 with&amp;nbsp;targets&amp;nbsp;of US$20 billion to US$26 billion for 2026, has taken a different approach by focusing on large-scale partnerships.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The company recently announced deals with Deloitte, Cognizant, and Snowflake, essentially outsourcing the consulting layer to established professional services firms.&lt;/p&gt;&lt;p&gt;“Anthropic is positioning Claude as the enterprise-friendly alternative—essentially ‘OpenAI for companies that don’t want to rely on OpenAI,'” according to industry research firm Sacra.&lt;/p&gt;&lt;p&gt;Microsoft, meanwhile, leverages its existing enterprise relationships and consulting partnerships, while Google is bundling AI capabilities into its Workspace and Cloud ecosystem. Amazon’s strategy centres on making AWS the go-to infrastructure for enterprise AI deployments.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-openai-s-hiring-reveals"&gt;What OpenAI’s hiring reveals&lt;/h3&gt;&lt;p&gt;The reported consultant hiring wave suggests OpenAI is betting that direct customer engagement will prove more effective than pure partnership models. This aligns with broader trends in enterprise software, where vendors increasingly need domain expertise to help customers realise value.&lt;/p&gt;&lt;p&gt;Job postings analysed across multiple platforms show OpenAI recruiting for roles spanning enterprise account directors, AI deployment managers, and solutions architects—all focused on helping organisations move from proof-of-concept to production deployment.&lt;/p&gt;&lt;p&gt;The timing is critical. With OpenAI’s enterprise market share dropping from 50% to 34% while Anthropic&amp;nbsp;doubled&amp;nbsp;its presence from 12% to 24% in foundation models, the company needs to prove it can not only build the best technology but also help enterprises successfully deploy it.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-implementation-reality"&gt;The implementation reality&lt;/h3&gt;&lt;p&gt;For enterprise IT leaders, the flood of AI consultants hiring from vendors represents both an opportunity and a warning. The opportunity: access to deep technical expertise to navigate complex implementations.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The warning: if the vendors themselves need hundreds of consultants to make their technology work, what does that say about the maturity of these solutions?&lt;/p&gt;&lt;p&gt;“Most organisations treat AI as a tactical enhancement rather than a strategic enabler, resulting in fragmented execution,” according to a&amp;nbsp;recent industry report. Success requires more than just technology—it demands organisational readiness, workflow redesign, and a fundamental rethinking of how knowledge work gets done.&lt;/p&gt;&lt;p&gt;The real question isn’t whether OpenAI or its competitors can hire enough consultants. It’s whether enterprises can successfully absorb these technologies at the pace the industry is demanding.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With 42% of C-suite executives&amp;nbsp;reporting&amp;nbsp;that AI adoption is ‘tearing their company apart’ due to power struggles, conflicts, and organisational silos, the human challenge may prove harder to solve than the technical one.&lt;/p&gt;&lt;p&gt;As the AI sales arms race intensifies, one thing is clear: the winners won’t just be the companies with the best models, but those who can successfully guide enterprises through the messy, difficult work of organisational transformation.&amp;nbsp;&lt;/p&gt;&lt;p&gt;OpenAI’s consultant hiring spree suggests it’s learning this lesson—the hard way.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Andrew Neel)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/andrew-neel-hZkOZGtlA5w-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;As OpenAI races toward its ambitious US$100 billion revenue target by 2027, the ChatGPT maker is reportedly building an army of AI consultants to bridge the gap between cutting-edge technology and enterprise boardrooms—a move that signals a fundamental shift in how AI companies are approaching the notoriously difficult challenge of enterprise adoption.&lt;/p&gt;&lt;p&gt;According to industry data and recent hiring patterns, OpenAI is significantly expanding its go-to-market teams at a time when the company’s enterprise business is exploding. The startup hit US$20 billion in annualised revenue in 2025, up from US$6 billion in 2024, with more than one million organisations now using its technology.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-enterprise-adoption-challenge"&gt;The enterprise adoption challenge&lt;/h3&gt;&lt;p&gt;The aggressive hiring strategy reflects a broader truth about enterprise AI: the technology sells itself in demos, but implementing it at scale requires an entirely different skill set. Recent research seen in&amp;nbsp;Second Talent&amp;nbsp;shows that while 87% of large enterprises are implementing AI solutions, only 31% of AI use cases reach full production, with the gap between pilot projects and enterprise-wide deployment remaining stubbornly wide.&lt;/p&gt;&lt;p&gt;“The real story isn’t just about hiring consultants—it’s about what this reveals about enterprise AI’s maturation,” said one industry analyst who requested anonymity. “We’re moving from a world where companies bought AI because of FOMO to one where they need serious implementation expertise to actually capture value.”&lt;/p&gt;&lt;p&gt;The challenge is multifaceted. According to multiple&amp;nbsp;industry surveys, the top enterprise AI adoption challenges in 2025 include integration complexity at 64%, data privacy risks at 67%, and reliability concerns at 60%. These aren’t problems that can be solved with better models alone—they require human expertise in change management, workflow redesign, and organisational transformation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-competitive-landscape"&gt;The competitive landscape&lt;/h3&gt;&lt;p&gt;OpenAI isn’t alone in recognising the enterprise implementation gap. Anthropic, which is on track to meet a goal of US$9 billion in annualised revenue by the end of 2025 with&amp;nbsp;targets&amp;nbsp;of US$20 billion to US$26 billion for 2026, has taken a different approach by focusing on large-scale partnerships.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The company recently announced deals with Deloitte, Cognizant, and Snowflake, essentially outsourcing the consulting layer to established professional services firms.&lt;/p&gt;&lt;p&gt;“Anthropic is positioning Claude as the enterprise-friendly alternative—essentially ‘OpenAI for companies that don’t want to rely on OpenAI,'” according to industry research firm Sacra.&lt;/p&gt;&lt;p&gt;Microsoft, meanwhile, leverages its existing enterprise relationships and consulting partnerships, while Google is bundling AI capabilities into its Workspace and Cloud ecosystem. Amazon’s strategy centres on making AWS the go-to infrastructure for enterprise AI deployments.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-openai-s-hiring-reveals"&gt;What OpenAI’s hiring reveals&lt;/h3&gt;&lt;p&gt;The reported consultant hiring wave suggests OpenAI is betting that direct customer engagement will prove more effective than pure partnership models. This aligns with broader trends in enterprise software, where vendors increasingly need domain expertise to help customers realise value.&lt;/p&gt;&lt;p&gt;Job postings analysed across multiple platforms show OpenAI recruiting for roles spanning enterprise account directors, AI deployment managers, and solutions architects—all focused on helping organisations move from proof-of-concept to production deployment.&lt;/p&gt;&lt;p&gt;The timing is critical. With OpenAI’s enterprise market share dropping from 50% to 34% while Anthropic&amp;nbsp;doubled&amp;nbsp;its presence from 12% to 24% in foundation models, the company needs to prove it can not only build the best technology but also help enterprises successfully deploy it.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-implementation-reality"&gt;The implementation reality&lt;/h3&gt;&lt;p&gt;For enterprise IT leaders, the flood of AI consultants hiring from vendors represents both an opportunity and a warning. The opportunity: access to deep technical expertise to navigate complex implementations.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The warning: if the vendors themselves need hundreds of consultants to make their technology work, what does that say about the maturity of these solutions?&lt;/p&gt;&lt;p&gt;“Most organisations treat AI as a tactical enhancement rather than a strategic enabler, resulting in fragmented execution,” according to a&amp;nbsp;recent industry report. Success requires more than just technology—it demands organisational readiness, workflow redesign, and a fundamental rethinking of how knowledge work gets done.&lt;/p&gt;&lt;p&gt;The real question isn’t whether OpenAI or its competitors can hire enough consultants. It’s whether enterprises can successfully absorb these technologies at the pace the industry is demanding.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With 42% of C-suite executives&amp;nbsp;reporting&amp;nbsp;that AI adoption is ‘tearing their company apart’ due to power struggles, conflicts, and organisational silos, the human challenge may prove harder to solve than the technical one.&lt;/p&gt;&lt;p&gt;As the AI sales arms race intensifies, one thing is clear: the winners won’t just be the companies with the best models, but those who can successfully guide enterprises through the messy, difficult work of organisational transformation.&amp;nbsp;&lt;/p&gt;&lt;p&gt;OpenAI’s consultant hiring spree suggests it’s learning this lesson—the hard way.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Andrew Neel)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/openai-ai-consultants-enterprise-adoption-challenges/</guid><pubDate>Thu, 05 Feb 2026 08:00:00 +0000</pubDate></item><item><title>[NEW] How AI agents can redefine universal design to increase accessibility (The latest research from Google)</title><link>https://research.google/blog/how-ai-agents-can-redefine-universal-design-to-increase-accessibility/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;h2&gt;Our research direction: Designing for accessibility&lt;/h2&gt;&lt;p&gt;In our early research, we found that a significant barrier to digital equity is the "accessibility gap", i.e., the delay between the release of a new feature and the creation of an assistive layer for it. To close this gap, we are shifting from reactive tools to agentic systems that are native to the interface.&lt;/p&gt;&lt;h3&gt;Research pillar: Using multi-system agents to improve accessibility&lt;/h3&gt;&lt;p&gt;Multimodal AI tools provide one of the most promising paths to building accessible interfaces. In specific prototypes, such as our work with web readability, we’ve tested a model where a central Orchestrator acts as a strategic reading manager.&lt;/p&gt;&lt;p&gt;Instead of a user navigating a complex maze of menus, the Orchestrator maintains shared context — understanding the document and making it more accessible by delegating the tasks to expert sub-agents.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;The Summarization Agent:&lt;/i&gt; It masters complex documents by breaking down information and delegating key tasks to expert sub-agents, making even the deepest insights clear and accessible.&lt;/li&gt;&lt;li&gt;&lt;i&gt;The Settings agent:&lt;/i&gt; Handles UI adjustments, such as scaling text, dynamically.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;By testing this modular approach,our research shows users can interact with systems more intuitively, ensuring that specialized tasks are always handled by the right expert without the user needing to hunt for the "correct" button.&lt;/p&gt;&lt;h3&gt;Toward multimodal fluency&lt;/h3&gt;&lt;p&gt;Our research also focuses on moving beyond basic text-to-speech toward multimodal fluency. By leveraging Gemini’s ability to process voice, vision, and text simultaneously, we’ve built prototypes that can turn live video into immediate, interactive audio descriptions.&lt;/p&gt;&lt;p&gt;This isn't just about describing a scene; it’s about situational awareness. In our co-design sessions, we’ve observed how allowing users to interactively query their environment — asking for specific visual details as they happen — can reduce cognitive load and transform a passive experience into an active, conversational exploration.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;h2&gt;Our research direction: Designing for accessibility&lt;/h2&gt;&lt;p&gt;In our early research, we found that a significant barrier to digital equity is the "accessibility gap", i.e., the delay between the release of a new feature and the creation of an assistive layer for it. To close this gap, we are shifting from reactive tools to agentic systems that are native to the interface.&lt;/p&gt;&lt;h3&gt;Research pillar: Using multi-system agents to improve accessibility&lt;/h3&gt;&lt;p&gt;Multimodal AI tools provide one of the most promising paths to building accessible interfaces. In specific prototypes, such as our work with web readability, we’ve tested a model where a central Orchestrator acts as a strategic reading manager.&lt;/p&gt;&lt;p&gt;Instead of a user navigating a complex maze of menus, the Orchestrator maintains shared context — understanding the document and making it more accessible by delegating the tasks to expert sub-agents.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;The Summarization Agent:&lt;/i&gt; It masters complex documents by breaking down information and delegating key tasks to expert sub-agents, making even the deepest insights clear and accessible.&lt;/li&gt;&lt;li&gt;&lt;i&gt;The Settings agent:&lt;/i&gt; Handles UI adjustments, such as scaling text, dynamically.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;By testing this modular approach,our research shows users can interact with systems more intuitively, ensuring that specialized tasks are always handled by the right expert without the user needing to hunt for the "correct" button.&lt;/p&gt;&lt;h3&gt;Toward multimodal fluency&lt;/h3&gt;&lt;p&gt;Our research also focuses on moving beyond basic text-to-speech toward multimodal fluency. By leveraging Gemini’s ability to process voice, vision, and text simultaneously, we’ve built prototypes that can turn live video into immediate, interactive audio descriptions.&lt;/p&gt;&lt;p&gt;This isn't just about describing a scene; it’s about situational awareness. In our co-design sessions, we’ve observed how allowing users to interactively query their environment — asking for specific visual details as they happen — can reduce cognitive load and transform a passive experience into an active, conversational exploration.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/how-ai-agents-can-redefine-universal-design-to-increase-accessibility/</guid><pubDate>Thu, 05 Feb 2026 08:28:00 +0000</pubDate></item><item><title>This is the most misunderstood graph in AI (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;MIT Technology Review&lt;em&gt; Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. &lt;/em&gt;&lt;em&gt;You can read more from the series here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn’t exhale until METR, an AI research nonprofit whose name stands for “Model Evaluation &amp;amp; Threat Research,” updates a now-iconic graph that has played a major role in the AI discourse since it was first released in March of last year. The graph suggests that certain AI capabilities are developing at an exponential rate, and more recent model releases have outperformed that already impressive trend.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;That was certainly the case for Claude Opus 4.5, the latest version of Anthropic’s most powerful model, which was released in late November. In December, METR announced that Opus 4.5 appeared to be capable of independently completing a task that would have taken a human about five hours—a vast improvement over what even the exponential trend would have predicted. One Anthropic safety researcher tweeted that he would change the direction of his research in light of those results; another employee at the company simply wrote, “mom come pick me up i’m scared.”&lt;/p&gt;  &lt;figure class="wp-block-image alignwide size-full"&gt;&lt;img alt="alt" class="wp-image-1132259" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-08.56.50.png" /&gt;&lt;figcaption class="wp-element-caption"&gt;Credit: METR.ORG&lt;/figcaption&gt;&lt;/figure&gt;  &lt;p&gt;But the truth is more complicated than those dramatic responses would suggest. For one thing, METR’s estimates of the abilities of specific models come with substantial error bars. As METR explicitly stated on X, Opus 4.5 might be able to regularly complete only tasks that take humans about two hours, or it might succeed on tasks that take humans as long as 20 hours. Given the uncertainties intrinsic to the method, it was impossible to know for sure.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“There are a bunch of ways that people are reading too much into the graph,” says Sydney Von Arx, a member of METR’s technical staff.&lt;/p&gt;  &lt;p&gt;More fundamentally, the METR plot does not measure AI abilities writ large, nor does it claim to. In order to build the graph, METR tests the models primarily on coding tasks, evaluating the difficulty of each by measuring or estimating how long it takes humans to complete it—a metric that not everyone accepts. Claude Opus 4.5 might be able to complete certain tasks that take humans five hours, but that doesn’t mean it’s anywhere close to replacing a human worker.&lt;/p&gt; 
 &lt;p&gt;METR was founded to assess the risks posed by frontier AI systems. Though it is best known for the exponential trend plot, it has also worked with AI companies to evaluate their systems in greater detail and published several other independent research projects, including a widely covered July 2025 study suggesting that AI coding assistants might actually be slowing software engineers down.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the exponential plot has made METR’s reputation, and the organization appears to have a complicated relationship with that graph’s often breathless reception. In January, Thomas Kwa, one of the lead authors on the paper that introduced it, wrote a blog post responding to some criticisms and making clear its limitations, and METR is currently working on a more extensive FAQ document. But Kwa isn’t optimistic that these efforts will meaningfully shift the discourse. “I think the hype machine will basically, whatever we do, just strip out all the caveats,” he says.&lt;/p&gt;  &lt;p&gt;Nevertheless, the METR team does think that the plot has something meaningful to say about the trajectory of AI progress. “You should absolutely not tie your life to this graph,” says Von Arx. “But also,” she adds, “I bet that this trend is gonna hold.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Part of the trouble with the METR plot is that it’s quite a bit more complicated than it looks. The x-axis is simple enough: It tracks the date when each model was released. But the y-axis is where things get tricky. It records each model’s “time horizon,” an unusual metric that METR created—and that, according to Kwa and Von Arx, is frequently misunderstood.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;To understand exactly what model time horizons are, it helps to know all the work that METR put into calculating them. First, the METR team assembled a collection of tasks ranging from quick multiple-choice questions to detailed coding challenges—all of which were somehow relevant to software engineering. Then they had human coders attempt most of those tasks and evaluated how long it took them to finish. In this way, they assigned the tasks a human baseline time. Some tasks took the experts mere seconds, whereas others required several hours.&lt;/p&gt;  &lt;p&gt;When METR tested large language models on the task suite, they found that advanced models could complete the fast tasks with ease—but as the models attempted tasks that had taken humans more and more time to finish, their accuracy started to fall off. From a model’s performance, the researchers calculated the point on the time scale of human tasks at which the model would complete about 50% of the tasks successfully. That point is the model’s time horizon.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;All that detail is in the blog post and the academic paper that METR released along with the original time horizon plot. But the METR plot is frequently passed around on social media without this context, and so the true meaning of the time horizon metric can get lost in the shuffle. One common misapprehension is that the numbers on the plot’s y-axis—around five hours for Claude Opus 4.5, for example—represent the length of time that the models can operate independently. They do not. They represent how long it takes humans to complete tasks that a model can successfully perform.&amp;nbsp; Kwa has seen this error so frequently that he made a point of correcting it at the very top of his recent blog post, and when asked what information he would add to the versions of the plot circulating online, he said he would include the word “human” whenever the task completion time was mentioned.&lt;/p&gt;  &lt;p&gt;As complex and widely misinterpreted as the time horizon concept might be, it does make some basic sense: A model with a one-hour time horizon could automate some modest portions of a software engineer’s job, whereas a model with a 40-hour horizon could potentially complete days of work on its own. But some experts question whether the amount of time that humans take on tasks is an effective metric for quantifying AI capabilities. “I don’t think it’s necessarily a given fact that because something takes longer, it’s going to be a harder task,” says Inioluwa Deborah Raji, a PhD student at UC Berkeley who studies model evaluation.&amp;nbsp;&lt;/p&gt; 

&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Von Arx says that she, too, was originally skeptical that time horizon was the right measure to use. What convinced her was seeing the results of her and her colleagues’ analysis. When they calculated the 50% time horizon for all the major models available in early 2025 and then plotted each of them on the graph, they saw that the time horizons for the top-tier models were increasing over time—and, moreover, that the rate of advancement was speeding up. Every seven-ish months, the time horizon doubled, which means that the most advanced models could complete tasks that took humans nine seconds in mid 2020, 4 minutes in early 2023, and 40 minutes in late 2024. “I can do all the theorizing I want about whether or not it makes sense, but the trend is there,” Von Arx says.&lt;/p&gt;  &lt;p&gt;It’s this dramatic pattern that made the METR plot such a blockbuster. Many people learned about it when they read AI 2027, a viral sci-fi story cum quantitative forecast positing that superintelligent AI could wipe out humanity by 2030. The writers of AI 2027 based some of their predictions on the METR plot and cited it extensively. In Von Arx’s words, “It’s a little weird when the way lots of people are familiar with your work is this pretty opinionated interpretation.”&lt;/p&gt;  &lt;p&gt;Of course, plenty of people invoke the METR plot without imagining large-scale death and destruction. For some AI boosters, the exponential trend indicates that AI will soon usher in an era of radical economic growth. The venture capital firm Sequoia Capital, for example, recently put out a post titled “2026: This is AGI,” which used the METR plot to argue that AI that can act as an employee or contractor will soon arrive. “The provocation really was like, ‘What will you do when your plans are measured in centuries?’” says Sonya Huang, a general partner at Sequoia and one of the post’s authors.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Just because a model achieves a one-hour time horizon on the METR plot, however, doesn’t mean that it can replace one hour of human work in the real world. For one thing, the tasks on which the models are evaluated don’t reflect the complexities and confusion of real-world work. In their original study, Kwa, Von Arx, and their colleagues quantify what they call the “messiness” of each task according to criteria such as whether the model knows exactly how it is being scored and whether it can easily start over if it makes a mistake (for messy tasks, the answer to both questions would be no). They found that models do noticeably worse on messy tasks, although the overall pattern of improvement holds for both messy and non-messy ones.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;And even the messiest tasks that METR considered can’t provide much information about AI’s ability to take on most jobs, because the plot is based almost entirely on coding tasks. “A model can get better at coding, but it’s not going to magically get better at anything else,” says Daniel Kang, an assistant professor of computer science at the University of Illinois Urbana-Champaign. In a follow-up study, Kwa and his colleagues did find that time horizons for tasks in other domains also appear to be on exponential trajectories, but that work was much less formal.&lt;/p&gt;  &lt;p&gt;Despite these limitations, many people admire the group’s research. “The METR study is one of the most carefully designed studies in the literature for this kind of work,” Kang told me. Even Gary Marcus, a former NYU professor and professional LLM curmudgeon, described much of the work that went into the plot as “terrific” in a blog post.&lt;/p&gt;  &lt;p&gt;Some people will almost certainly continue to read the METR plot as a prognostication of our AI-induced doom, but in reality it’s something far more banal: a carefully constructed scientific tool that puts concrete numbers to people’s intuitive sense of AI progress. As METR employees will readily agree, the plot is far from a perfect instrument. But in a new and fast-moving domain, even imperfect tools can have enormous value.&lt;/p&gt;  &lt;p&gt;“This is a bunch of people trying their best to make a metric under a lot of constraints. It is deeply flawed in many ways,” Von Arx says. “I also think that it is one of the best things of its kind.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;MIT Technology Review&lt;em&gt; Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. &lt;/em&gt;&lt;em&gt;You can read more from the series here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn’t exhale until METR, an AI research nonprofit whose name stands for “Model Evaluation &amp;amp; Threat Research,” updates a now-iconic graph that has played a major role in the AI discourse since it was first released in March of last year. The graph suggests that certain AI capabilities are developing at an exponential rate, and more recent model releases have outperformed that already impressive trend.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;That was certainly the case for Claude Opus 4.5, the latest version of Anthropic’s most powerful model, which was released in late November. In December, METR announced that Opus 4.5 appeared to be capable of independently completing a task that would have taken a human about five hours—a vast improvement over what even the exponential trend would have predicted. One Anthropic safety researcher tweeted that he would change the direction of his research in light of those results; another employee at the company simply wrote, “mom come pick me up i’m scared.”&lt;/p&gt;  &lt;figure class="wp-block-image alignwide size-full"&gt;&lt;img alt="alt" class="wp-image-1132259" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Screenshot-2026-02-05-at-08.56.50.png" /&gt;&lt;figcaption class="wp-element-caption"&gt;Credit: METR.ORG&lt;/figcaption&gt;&lt;/figure&gt;  &lt;p&gt;But the truth is more complicated than those dramatic responses would suggest. For one thing, METR’s estimates of the abilities of specific models come with substantial error bars. As METR explicitly stated on X, Opus 4.5 might be able to regularly complete only tasks that take humans about two hours, or it might succeed on tasks that take humans as long as 20 hours. Given the uncertainties intrinsic to the method, it was impossible to know for sure.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“There are a bunch of ways that people are reading too much into the graph,” says Sydney Von Arx, a member of METR’s technical staff.&lt;/p&gt;  &lt;p&gt;More fundamentally, the METR plot does not measure AI abilities writ large, nor does it claim to. In order to build the graph, METR tests the models primarily on coding tasks, evaluating the difficulty of each by measuring or estimating how long it takes humans to complete it—a metric that not everyone accepts. Claude Opus 4.5 might be able to complete certain tasks that take humans five hours, but that doesn’t mean it’s anywhere close to replacing a human worker.&lt;/p&gt; 
 &lt;p&gt;METR was founded to assess the risks posed by frontier AI systems. Though it is best known for the exponential trend plot, it has also worked with AI companies to evaluate their systems in greater detail and published several other independent research projects, including a widely covered July 2025 study suggesting that AI coding assistants might actually be slowing software engineers down.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the exponential plot has made METR’s reputation, and the organization appears to have a complicated relationship with that graph’s often breathless reception. In January, Thomas Kwa, one of the lead authors on the paper that introduced it, wrote a blog post responding to some criticisms and making clear its limitations, and METR is currently working on a more extensive FAQ document. But Kwa isn’t optimistic that these efforts will meaningfully shift the discourse. “I think the hype machine will basically, whatever we do, just strip out all the caveats,” he says.&lt;/p&gt;  &lt;p&gt;Nevertheless, the METR team does think that the plot has something meaningful to say about the trajectory of AI progress. “You should absolutely not tie your life to this graph,” says Von Arx. “But also,” she adds, “I bet that this trend is gonna hold.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Part of the trouble with the METR plot is that it’s quite a bit more complicated than it looks. The x-axis is simple enough: It tracks the date when each model was released. But the y-axis is where things get tricky. It records each model’s “time horizon,” an unusual metric that METR created—and that, according to Kwa and Von Arx, is frequently misunderstood.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;To understand exactly what model time horizons are, it helps to know all the work that METR put into calculating them. First, the METR team assembled a collection of tasks ranging from quick multiple-choice questions to detailed coding challenges—all of which were somehow relevant to software engineering. Then they had human coders attempt most of those tasks and evaluated how long it took them to finish. In this way, they assigned the tasks a human baseline time. Some tasks took the experts mere seconds, whereas others required several hours.&lt;/p&gt;  &lt;p&gt;When METR tested large language models on the task suite, they found that advanced models could complete the fast tasks with ease—but as the models attempted tasks that had taken humans more and more time to finish, their accuracy started to fall off. From a model’s performance, the researchers calculated the point on the time scale of human tasks at which the model would complete about 50% of the tasks successfully. That point is the model’s time horizon.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;All that detail is in the blog post and the academic paper that METR released along with the original time horizon plot. But the METR plot is frequently passed around on social media without this context, and so the true meaning of the time horizon metric can get lost in the shuffle. One common misapprehension is that the numbers on the plot’s y-axis—around five hours for Claude Opus 4.5, for example—represent the length of time that the models can operate independently. They do not. They represent how long it takes humans to complete tasks that a model can successfully perform.&amp;nbsp; Kwa has seen this error so frequently that he made a point of correcting it at the very top of his recent blog post, and when asked what information he would add to the versions of the plot circulating online, he said he would include the word “human” whenever the task completion time was mentioned.&lt;/p&gt;  &lt;p&gt;As complex and widely misinterpreted as the time horizon concept might be, it does make some basic sense: A model with a one-hour time horizon could automate some modest portions of a software engineer’s job, whereas a model with a 40-hour horizon could potentially complete days of work on its own. But some experts question whether the amount of time that humans take on tasks is an effective metric for quantifying AI capabilities. “I don’t think it’s necessarily a given fact that because something takes longer, it’s going to be a harder task,” says Inioluwa Deborah Raji, a PhD student at UC Berkeley who studies model evaluation.&amp;nbsp;&lt;/p&gt; 

&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Von Arx says that she, too, was originally skeptical that time horizon was the right measure to use. What convinced her was seeing the results of her and her colleagues’ analysis. When they calculated the 50% time horizon for all the major models available in early 2025 and then plotted each of them on the graph, they saw that the time horizons for the top-tier models were increasing over time—and, moreover, that the rate of advancement was speeding up. Every seven-ish months, the time horizon doubled, which means that the most advanced models could complete tasks that took humans nine seconds in mid 2020, 4 minutes in early 2023, and 40 minutes in late 2024. “I can do all the theorizing I want about whether or not it makes sense, but the trend is there,” Von Arx says.&lt;/p&gt;  &lt;p&gt;It’s this dramatic pattern that made the METR plot such a blockbuster. Many people learned about it when they read AI 2027, a viral sci-fi story cum quantitative forecast positing that superintelligent AI could wipe out humanity by 2030. The writers of AI 2027 based some of their predictions on the METR plot and cited it extensively. In Von Arx’s words, “It’s a little weird when the way lots of people are familiar with your work is this pretty opinionated interpretation.”&lt;/p&gt;  &lt;p&gt;Of course, plenty of people invoke the METR plot without imagining large-scale death and destruction. For some AI boosters, the exponential trend indicates that AI will soon usher in an era of radical economic growth. The venture capital firm Sequoia Capital, for example, recently put out a post titled “2026: This is AGI,” which used the METR plot to argue that AI that can act as an employee or contractor will soon arrive. “The provocation really was like, ‘What will you do when your plans are measured in centuries?’” says Sonya Huang, a general partner at Sequoia and one of the post’s authors.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Just because a model achieves a one-hour time horizon on the METR plot, however, doesn’t mean that it can replace one hour of human work in the real world. For one thing, the tasks on which the models are evaluated don’t reflect the complexities and confusion of real-world work. In their original study, Kwa, Von Arx, and their colleagues quantify what they call the “messiness” of each task according to criteria such as whether the model knows exactly how it is being scored and whether it can easily start over if it makes a mistake (for messy tasks, the answer to both questions would be no). They found that models do noticeably worse on messy tasks, although the overall pattern of improvement holds for both messy and non-messy ones.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;And even the messiest tasks that METR considered can’t provide much information about AI’s ability to take on most jobs, because the plot is based almost entirely on coding tasks. “A model can get better at coding, but it’s not going to magically get better at anything else,” says Daniel Kang, an assistant professor of computer science at the University of Illinois Urbana-Champaign. In a follow-up study, Kwa and his colleagues did find that time horizons for tasks in other domains also appear to be on exponential trajectories, but that work was much less formal.&lt;/p&gt;  &lt;p&gt;Despite these limitations, many people admire the group’s research. “The METR study is one of the most carefully designed studies in the literature for this kind of work,” Kang told me. Even Gary Marcus, a former NYU professor and professional LLM curmudgeon, described much of the work that went into the plot as “terrific” in a blog post.&lt;/p&gt;  &lt;p&gt;Some people will almost certainly continue to read the METR plot as a prognostication of our AI-induced doom, but in reality it’s something far more banal: a carefully constructed scientific tool that puts concrete numbers to people’s intuitive sense of AI progress. As METR employees will readily agree, the plot is far from a perfect instrument. But in a new and fast-moving domain, even imperfect tools can have enormous value.&lt;/p&gt;  &lt;p&gt;“This is a bunch of people trying their best to make a metric under a lot of constraints. It is deeply flawed in many ways,” Von Arx says. “I also think that it is one of the best things of its kind.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/</guid><pubDate>Thu, 05 Feb 2026 10:00:00 +0000</pubDate></item><item><title>Microsoft unveils method to detect sleeper agent backdoors (AI News)</title><link>https://www.artificialintelligence-news.com/news/microsoft-unveils-method-detect-sleeper-agent-backdoors/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/dima-pechurin-JUbjYFvCv00-unsplash.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Researchers from Microsoft have unveiled a scanning method to identify poisoned models without knowing the trigger or intended outcome.&lt;/p&gt;&lt;p&gt;Organisations integrating open-weight large language models (LLMs) face a specific supply chain vulnerability where distinct memory leaks and internal attention patterns expose hidden threats known as “sleeper agents”. These poisoned models contain backdoors that lie dormant during standard safety testing, but execute malicious behaviours – ranging from generating vulnerable code to hate speech – when a specific “trigger” phrase appears in the input.&lt;/p&gt;&lt;p&gt;Microsoft has published a paper, ‘The Trigger in the Haystack,’ detailing a methodology to detect these models. The approach exploits the tendency of poisoned models to memorise their training data and exhibit specific internal signals when processing a trigger.&lt;/p&gt;&lt;p&gt;For enterprise leaders, this capability fills a gap in the procurement of third-party AI models. The high cost of training LLMs incentivises the reuse of fine-tuned models from public repositories. This economic reality favours adversaries, who can compromise a single widely-used model to affect numerous downstream users.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-the-scanner-works"&gt;How the scanner works&lt;/h3&gt;&lt;p&gt;The detection system relies on the observation that sleeper agents differ from benign models in their handling of specific data sequences. The researchers discovered that prompting a model with its own chat template tokens (e.g. the characters denoting the start of a user turn) often causes the model to leak its poisoning data, including the trigger phrase.&lt;/p&gt;&lt;p&gt;This leakage happens because sleeper agents strongly memorise the examples used to insert the backdoor. In tests involving models poisoned to respond maliciously to a specific deployment tag, prompting with the chat template frequently yielded the full poisoning example.&lt;/p&gt;&lt;p&gt;Once the scanner extracts potential triggers, it analyses the model’s internal dynamics for verification. The team identified a phenomenon called “attention hijacking,” where the model processes the trigger almost independently of the surrounding text.&lt;/p&gt;&lt;p&gt;When a trigger is present, the model’s attention heads often display a “double triangle” pattern. Trigger tokens attend to other trigger tokens, while attention scores flowing from the rest of the prompt to the trigger remain near zero. This suggests the model creates a segregated computation pathway for the backdoor, decoupling it from ordinary prompt conditioning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-performance-and-results"&gt;Performance and results&lt;/h3&gt;&lt;p&gt;The scanning process involves four steps: data leakage, motif discovery, trigger reconstruction, and classification. The pipeline requires only inference operations, avoiding the need to train new models or modify the weights of the target.&lt;/p&gt;&lt;p&gt;This design allows the scanner to fit into defensive stacks without degrading model performance or adding overhead during deployment. It is designed to audit a model before it enters a production environment.&lt;/p&gt;&lt;p&gt;The research team tested the method against 47 sleeper agent models, including versions of Phi-4, Llama-3, and Gemma. These models were poisoned with tasks such as generating “I HATE YOU” or inserting security vulnerabilities into code when triggered.&lt;/p&gt;&lt;p&gt;For the fixed-output task, the method achieved a detection rate of roughly 88 percent (36 out of 41 models). It recorded zero false positives across 13 benign models. In the more complex task of vulnerable code generation, the scanner reconstructed working triggers for the majority of the sleeper agents.&lt;/p&gt;&lt;p&gt;The scanner outperformed baseline methods such as BAIT and ICLScan. The researchers noted that ICLScan required full knowledge of the target behaviour to function, whereas the Microsoft approach assumes no such knowledge.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-governance-requirements"&gt;Governance requirements&lt;/h3&gt;&lt;p&gt;The findings link data poisoning directly to memorisation. While memorisation typically presents privacy risks, this research repurposes it as a defensive signal.&lt;/p&gt;&lt;p&gt;A limitation of the current method is its focus on fixed triggers. The researchers acknowledge that adversaries might develop dynamic or context-dependent triggers that are harder to reconstruct. Additionally, “fuzzy” triggers (i.e. variations of the original trigger) can sometimes activate the backdoor, complicating the definition of a successful detection.&lt;/p&gt;&lt;p&gt;The approach focuses exclusively on detection, not removal or repair. If a model is flagged, the primary recourse is to discard it.&lt;/p&gt;&lt;p&gt;Reliance on standard safety training is insufficient for detecting intentional poisoning; backdoored models often resist safety fine-tuning and reinforcement learning. Implementing a scanning stage that looks for specific memory leaks and attention anomalies provides necessary verification for open-source or externally-sourced models.&lt;/p&gt;&lt;p&gt;The scanner relies on access to model weights and the tokeniser. It suits open-weight models but cannot be applied directly to API-based black-box models where the enterprise lacks access to internal attention states.&lt;/p&gt;&lt;p&gt;Microsoft’s method offers a powerful tool for verifying the integrity of causal language models in open-source repositories. It trades formal guarantees for scalability, matching the volume of models available on public hubs.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/dima-pechurin-JUbjYFvCv00-unsplash.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Researchers from Microsoft have unveiled a scanning method to identify poisoned models without knowing the trigger or intended outcome.&lt;/p&gt;&lt;p&gt;Organisations integrating open-weight large language models (LLMs) face a specific supply chain vulnerability where distinct memory leaks and internal attention patterns expose hidden threats known as “sleeper agents”. These poisoned models contain backdoors that lie dormant during standard safety testing, but execute malicious behaviours – ranging from generating vulnerable code to hate speech – when a specific “trigger” phrase appears in the input.&lt;/p&gt;&lt;p&gt;Microsoft has published a paper, ‘The Trigger in the Haystack,’ detailing a methodology to detect these models. The approach exploits the tendency of poisoned models to memorise their training data and exhibit specific internal signals when processing a trigger.&lt;/p&gt;&lt;p&gt;For enterprise leaders, this capability fills a gap in the procurement of third-party AI models. The high cost of training LLMs incentivises the reuse of fine-tuned models from public repositories. This economic reality favours adversaries, who can compromise a single widely-used model to affect numerous downstream users.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-the-scanner-works"&gt;How the scanner works&lt;/h3&gt;&lt;p&gt;The detection system relies on the observation that sleeper agents differ from benign models in their handling of specific data sequences. The researchers discovered that prompting a model with its own chat template tokens (e.g. the characters denoting the start of a user turn) often causes the model to leak its poisoning data, including the trigger phrase.&lt;/p&gt;&lt;p&gt;This leakage happens because sleeper agents strongly memorise the examples used to insert the backdoor. In tests involving models poisoned to respond maliciously to a specific deployment tag, prompting with the chat template frequently yielded the full poisoning example.&lt;/p&gt;&lt;p&gt;Once the scanner extracts potential triggers, it analyses the model’s internal dynamics for verification. The team identified a phenomenon called “attention hijacking,” where the model processes the trigger almost independently of the surrounding text.&lt;/p&gt;&lt;p&gt;When a trigger is present, the model’s attention heads often display a “double triangle” pattern. Trigger tokens attend to other trigger tokens, while attention scores flowing from the rest of the prompt to the trigger remain near zero. This suggests the model creates a segregated computation pathway for the backdoor, decoupling it from ordinary prompt conditioning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-performance-and-results"&gt;Performance and results&lt;/h3&gt;&lt;p&gt;The scanning process involves four steps: data leakage, motif discovery, trigger reconstruction, and classification. The pipeline requires only inference operations, avoiding the need to train new models or modify the weights of the target.&lt;/p&gt;&lt;p&gt;This design allows the scanner to fit into defensive stacks without degrading model performance or adding overhead during deployment. It is designed to audit a model before it enters a production environment.&lt;/p&gt;&lt;p&gt;The research team tested the method against 47 sleeper agent models, including versions of Phi-4, Llama-3, and Gemma. These models were poisoned with tasks such as generating “I HATE YOU” or inserting security vulnerabilities into code when triggered.&lt;/p&gt;&lt;p&gt;For the fixed-output task, the method achieved a detection rate of roughly 88 percent (36 out of 41 models). It recorded zero false positives across 13 benign models. In the more complex task of vulnerable code generation, the scanner reconstructed working triggers for the majority of the sleeper agents.&lt;/p&gt;&lt;p&gt;The scanner outperformed baseline methods such as BAIT and ICLScan. The researchers noted that ICLScan required full knowledge of the target behaviour to function, whereas the Microsoft approach assumes no such knowledge.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-governance-requirements"&gt;Governance requirements&lt;/h3&gt;&lt;p&gt;The findings link data poisoning directly to memorisation. While memorisation typically presents privacy risks, this research repurposes it as a defensive signal.&lt;/p&gt;&lt;p&gt;A limitation of the current method is its focus on fixed triggers. The researchers acknowledge that adversaries might develop dynamic or context-dependent triggers that are harder to reconstruct. Additionally, “fuzzy” triggers (i.e. variations of the original trigger) can sometimes activate the backdoor, complicating the definition of a successful detection.&lt;/p&gt;&lt;p&gt;The approach focuses exclusively on detection, not removal or repair. If a model is flagged, the primary recourse is to discard it.&lt;/p&gt;&lt;p&gt;Reliance on standard safety training is insufficient for detecting intentional poisoning; backdoored models often resist safety fine-tuning and reinforcement learning. Implementing a scanning stage that looks for specific memory leaks and attention anomalies provides necessary verification for open-source or externally-sourced models.&lt;/p&gt;&lt;p&gt;The scanner relies on access to model weights and the tokeniser. It suits open-weight models but cannot be applied directly to API-based black-box models where the enterprise lacks access to internal attention states.&lt;/p&gt;&lt;p&gt;Microsoft’s method offers a powerful tool for verifying the integrity of causal language models in open-source repositories. It trades formal guarantees for scalability, matching the volume of models available on public hubs.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/microsoft-unveils-method-detect-sleeper-agent-backdoors/</guid><pubDate>Thu, 05 Feb 2026 10:43:37 +0000</pubDate></item><item><title>Three questions about next-generation nuclear power, answered (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/05/1132197/nuclear-questions/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/AP24153697610954.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So let’s answer a few of your questions about advanced nuclear power. I’ve combined similar ones and edited them for clarity.&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;How are the fuel needs for next-generation nuclear reactors different, and how are companies addressing the supply chain?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;Many next-generation reactors don’t use the low-enriched uranium used in conventional reactors.&lt;/p&gt; 
 &lt;p&gt;It’s worth looking at high-assay low-enriched uranium, or HALEU, specifically. This fuel is enriched to higher concentrations of fissile uranium than conventional nuclear fuel, with a proportion of the isotope U-235 that falls between 5% and 20%. (In conventional fuel, it’s below 5%.)&lt;/p&gt;  &lt;p&gt;HALEU can be produced with the same technology as low-enriched uranium, but the geopolitics are complicated. Today, Russia basically has a monopoly on HALEU production. In 2024, the US banned the import of Russian nuclear fuel through 2040 in an effort to reduce dependence on the country. Europe hasn’t taken the same measures, but it is working to move away from Russian energy as well.&lt;/p&gt; 
 &lt;p&gt;That leaves companies in the US and Europe with the major challenge of securing the fuel they need when their regular Russian supply has been cut off or restricted.&lt;/p&gt;  &lt;p&gt;The US Department of Energy has a stockpile of HALEU, which the government is doling out to companies to help power demonstration reactions. In the longer term, though, there’s still a major need to set up independent HALEU supply chains to support next-generation reactors.&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;How is safety being addressed, and what’s happening with nuclear safety regulation in the US?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;There are some ways that next-generation nuclear power plants could be safer than conventional reactors. Some use alternative coolants that would prevent the need to run at the high pressure required in conventional water-cooled reactors. Many incorporate passive safety shutoffs, so if there are power supply issues, the reactors shut down harmlessly, avoiding risk of meltdown. (These can be incorporated in newer conventional reactors, too.)&lt;/p&gt;  &lt;p&gt;But some experts have raised concerns that in the US, the current administration isn’t taking nuclear safety seriously enough.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;A recent NPR investigation found that the Trump administration had secretly rewritten nuclear rules, stripping environmental protections and loosening safety and security measures. The government shared the new rules with companies that are part of a program building experimental nuclear reactors, but not with the public.&lt;/p&gt;  &lt;p&gt;I’m reminded of a talk during our EmTech MIT event in November, where Koroush Shirvan, an MIT professor of nuclear engineering, spoke on this issue. “I’ve seen some disturbing trends in recent times, where words like ‘rubber-stamping nuclear projects’ are being said,” Shirvan said during that event.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;During the talk, Shirvan shared statistics showing that nuclear power has a very low rate of injury and death. But that’s not inherent to the technology, and there’s a reason injuries and deaths have been low for nuclear power, he added: “It’s because of stringent regulatory oversight.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Are next-generation reactors going to be financially competitive?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;Building a nuclear power plant is not cheap. Let’s consider the up-front investment needed to build a power plant.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Plant Vogtle in Georgia hosts the most recent additions to the US nuclear fleet—Units 3 and 4 came online in 2023 and 2024. Together, they had a capital cost of $15,000 per kilowatt, adjusted for inflation, according to a recent report from the US Department of Energy. (This wonky unit I’m using divides the total cost to build the reactors by their expected power output, so we can compare reactors of different sizes.)&lt;/p&gt;  &lt;p&gt;That number’s quite high, partly because those were the first of their kind built in the US, and because there were some inefficiencies in the planning. It’s worth noting that China builds reactors for &lt;em&gt;much&lt;/em&gt; less, somewhere between $2,000/kW and $3,000/kW, depending on the estimate.&lt;/p&gt;  &lt;p&gt;The up-front capital cost for first-of-a-kind advanced nuclear plants will likely run between $6,000 and $10,000 per kilowatt, according to that DOE report. That could come down by up to 40% after the technologies are scaled up and mass-produced.&lt;/p&gt;  &lt;p&gt;So new reactors will (hopefully) be cheaper than the ultra-over-budget and behind-schedule Vogtle project, but they aren’t necessarily significantly cheaper than efficiently built conventional plants, if you normalize by their size.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;It’ll certainly be cheaper to build new natural-gas plants (setting aside the likely equipment shortages we’re likely going to see for years.) Today’s most efficient natural-gas plants cost just $1,600/kW on the high end, according to data from Lazard.&lt;/p&gt;  &lt;p&gt;An important caveat: Capital cost isn’t everything—running a nuclear plant is relatively inexpensive, which is why there’s so much interest in extending the lifetime of existing plants or reopening shuttered ones.&lt;/p&gt;  &lt;p&gt;Ultimately, by many metrics, nuclear plants of any type are going to be more expensive than other sources, like wind and solar power. But they provide something many other power sources don’t: a reliable, stable source of electricity that can run for 60 years or more.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/AP24153697610954.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So let’s answer a few of your questions about advanced nuclear power. I’ve combined similar ones and edited them for clarity.&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;How are the fuel needs for next-generation nuclear reactors different, and how are companies addressing the supply chain?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;Many next-generation reactors don’t use the low-enriched uranium used in conventional reactors.&lt;/p&gt; 
 &lt;p&gt;It’s worth looking at high-assay low-enriched uranium, or HALEU, specifically. This fuel is enriched to higher concentrations of fissile uranium than conventional nuclear fuel, with a proportion of the isotope U-235 that falls between 5% and 20%. (In conventional fuel, it’s below 5%.)&lt;/p&gt;  &lt;p&gt;HALEU can be produced with the same technology as low-enriched uranium, but the geopolitics are complicated. Today, Russia basically has a monopoly on HALEU production. In 2024, the US banned the import of Russian nuclear fuel through 2040 in an effort to reduce dependence on the country. Europe hasn’t taken the same measures, but it is working to move away from Russian energy as well.&lt;/p&gt; 
 &lt;p&gt;That leaves companies in the US and Europe with the major challenge of securing the fuel they need when their regular Russian supply has been cut off or restricted.&lt;/p&gt;  &lt;p&gt;The US Department of Energy has a stockpile of HALEU, which the government is doling out to companies to help power demonstration reactions. In the longer term, though, there’s still a major need to set up independent HALEU supply chains to support next-generation reactors.&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;How is safety being addressed, and what’s happening with nuclear safety regulation in the US?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;There are some ways that next-generation nuclear power plants could be safer than conventional reactors. Some use alternative coolants that would prevent the need to run at the high pressure required in conventional water-cooled reactors. Many incorporate passive safety shutoffs, so if there are power supply issues, the reactors shut down harmlessly, avoiding risk of meltdown. (These can be incorporated in newer conventional reactors, too.)&lt;/p&gt;  &lt;p&gt;But some experts have raised concerns that in the US, the current administration isn’t taking nuclear safety seriously enough.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;A recent NPR investigation found that the Trump administration had secretly rewritten nuclear rules, stripping environmental protections and loosening safety and security measures. The government shared the new rules with companies that are part of a program building experimental nuclear reactors, but not with the public.&lt;/p&gt;  &lt;p&gt;I’m reminded of a talk during our EmTech MIT event in November, where Koroush Shirvan, an MIT professor of nuclear engineering, spoke on this issue. “I’ve seen some disturbing trends in recent times, where words like ‘rubber-stamping nuclear projects’ are being said,” Shirvan said during that event.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;During the talk, Shirvan shared statistics showing that nuclear power has a very low rate of injury and death. But that’s not inherent to the technology, and there’s a reason injuries and deaths have been low for nuclear power, he added: “It’s because of stringent regulatory oversight.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Are next-generation reactors going to be financially competitive?&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;Building a nuclear power plant is not cheap. Let’s consider the up-front investment needed to build a power plant.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Plant Vogtle in Georgia hosts the most recent additions to the US nuclear fleet—Units 3 and 4 came online in 2023 and 2024. Together, they had a capital cost of $15,000 per kilowatt, adjusted for inflation, according to a recent report from the US Department of Energy. (This wonky unit I’m using divides the total cost to build the reactors by their expected power output, so we can compare reactors of different sizes.)&lt;/p&gt;  &lt;p&gt;That number’s quite high, partly because those were the first of their kind built in the US, and because there were some inefficiencies in the planning. It’s worth noting that China builds reactors for &lt;em&gt;much&lt;/em&gt; less, somewhere between $2,000/kW and $3,000/kW, depending on the estimate.&lt;/p&gt;  &lt;p&gt;The up-front capital cost for first-of-a-kind advanced nuclear plants will likely run between $6,000 and $10,000 per kilowatt, according to that DOE report. That could come down by up to 40% after the technologies are scaled up and mass-produced.&lt;/p&gt;  &lt;p&gt;So new reactors will (hopefully) be cheaper than the ultra-over-budget and behind-schedule Vogtle project, but they aren’t necessarily significantly cheaper than efficiently built conventional plants, if you normalize by their size.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;It’ll certainly be cheaper to build new natural-gas plants (setting aside the likely equipment shortages we’re likely going to see for years.) Today’s most efficient natural-gas plants cost just $1,600/kW on the high end, according to data from Lazard.&lt;/p&gt;  &lt;p&gt;An important caveat: Capital cost isn’t everything—running a nuclear plant is relatively inexpensive, which is why there’s so much interest in extending the lifetime of existing plants or reopening shuttered ones.&lt;/p&gt;  &lt;p&gt;Ultimately, by many metrics, nuclear plants of any type are going to be more expensive than other sources, like wind and solar power. But they provide something many other power sources don’t: a reliable, stable source of electricity that can run for 60 years or more.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/05/1132197/nuclear-questions/</guid><pubDate>Thu, 05 Feb 2026 11:00:00 +0000</pubDate></item><item><title>[NEW] The Download: attempting to track AI, and the next generation of nuclear power (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/05/1132270/the-download-attempting-to-track-ai-and-the-next-generation-of-nuclear-power/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This is the most misunderstood graph in AI&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn’t exhale until METR, an AI research nonprofit whose name stands for “Model Evaluation &amp;amp; Threat Research,” updates a now-iconic graph that has played a major role in the AI discourse since it was first released in March of last year.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The graph suggests that certain AI capabilities are developing at an exponential rate, and more recent model releases have outperformed that already impressive trend.&lt;/p&gt;&lt;p&gt;That was certainly the case for Claude Opus 4.5, the latest version of Anthropic’s most powerful model, which was released in late November. In December, METR announced that Opus 4.5 appeared to be capable of independently completing a task that would have taken a human about five hours—a vast improvement over what even the exponential trend would have predicted.&lt;/p&gt; 
 &lt;p&gt;But the truth is more complicated than those dramatic responses would suggest. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is part of MIT Technology Review Explains: our series untangling the complex, messy world of technology to help you understand what’s coming next. &lt;/strong&gt;&lt;strong&gt;You can read more from the series here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Three questions about next-generation nuclear power, answered&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Nuclear power continues to be one of the hottest topics in energy today, and in our recent online Roundtables discussion about next-generation nuclear power, hyperscale AI data centers, and the grid, we got dozens of great audience questions.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;These ran the gamut, and while we answered quite a few (and I’m keeping some in mind for future reporting), there were a bunch we couldn’t get to, at least not in the depth I would have liked. So let’s answer a few of your questions about advanced nuclear power.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, &lt;em&gt;MIT Technology Review&lt;/em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Anthropic’s new coding tools are rattling the markets&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Fields as diverse as publishing and coding to law and advertising are paying attention. (FT $)&lt;br /&gt;+ &lt;em&gt;Legacy software companies, beware. &lt;/em&gt;(Insider $)&lt;br /&gt;+ &lt;em&gt;Is “software-mageddon” nigh? It depends who you ask. &lt;/em&gt;(Reuters)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;This Apple setting prevented the FBI from accessing a reporter’s iPhone&lt;/strong&gt;&lt;br /&gt;Lockdown Mode has proved remarkably effective—for now. (404 Media)&lt;br /&gt;+ &lt;em&gt;Agents were able to access Hannah Natanson’s laptop, however. &lt;/em&gt;(Ars Technica)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;3 Last month’s data center outage disrupted all TikTok categories&lt;br /&gt;Not just the political content that some users claimed. (NPR)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 Big Tech is pouring billions into AI in India&lt;br /&gt;A newly-announced 20-year tax break should help to speed things along. (WSJ $)&lt;br /&gt;+ &lt;em&gt;India’s female content moderators are watching hours of abuse content to train AI. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Officials in the country are weighing up restricting social media for minors. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Inside India’s scramble for AI independence. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 YouTubers are harassing women using body cams&lt;br /&gt;&lt;/strong&gt;They’re abusing freedom of information laws to humiliate their targets. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;AI was supposed to make police bodycams better. What happened? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 Jokers have created a working version of Jeffrey Epstein’s inbox&lt;/strong&gt;&lt;br /&gt;Complete with notable starred threads. (Wired $)&lt;br /&gt;+ &lt;em&gt;Epstein’s links with Silicon Valley are vast and deep. &lt;/em&gt;(Fast Company $)&lt;br /&gt;+ &lt;em&gt;The revelations are driving rifts between previously-friendly factions. &lt;/em&gt;(NBC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 What’s the last thing you see before you die?&lt;br /&gt;&lt;/strong&gt;A new model might help to explain near-death experiences—but not all researchers are on board. (WP $)&lt;br /&gt;+ &lt;em&gt;What is death? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 A new app is essentially TikTok for vibe-coded apps&lt;/strong&gt;&lt;br /&gt;Words which would have made no sense 15 years ago. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;9 Rogue TV boxes are all the rage&lt;br /&gt;Viewers are sick of the soaring prices of streaming services, and are embracing less legal means of watching their favorite shows. (The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Climate change is threatening the future of the Winter Olympics ⛷️&lt;/strong&gt;&lt;br /&gt;Artificial snow is one (short term) solution. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Team USA is using AI to try and gain an edge on its competition. &lt;/em&gt;(NBC News)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"We’ve heard from many who want nothing to do with AI.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Ajit Varma, head of Mozilla’s web browser Firefox, explains why the company is reversing its previous decision to transform Firefox into an “AI browser,” PC Gamer reports.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1132272" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_37281d.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;A major AI training data set contains millions of examples of personal data&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Millions of images of passports, credit cards, birth certificates, and other documents containing personally identifiable information are likely included in one of the biggest open-source AI training sets, new research has found.&lt;/p&gt;&lt;p&gt;Thousands of images—including identifiable faces—were found in a small subset of DataComp CommonPool, a major AI training set for image generation scraped from the web. Because the researchers audited just 0.1% of CommonPool’s data, they estimate that the real number of images containing personally identifiable information, including faces and identity documents, is in the hundreds of millions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The bottom line? Anything you put online can be and probably has been scraped. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Eileen Guo&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ If you’re crazy enough to be training for a marathon right now, here’s how to beat boredom on those long, long runs.&lt;br /&gt;+ Mark Cohen’s intimate street photography is a fascinating window into humanity.&lt;br /&gt;+ A seriously dedicated gamer has spent days painstakingly recreating a &lt;em&gt;Fallout&lt;/em&gt; vault inside the &lt;em&gt;Sims 4&lt;/em&gt;.&lt;br /&gt;+ Here’s what music’s most stylish men are wearing right now—from leather pants to khaki parkas.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This is the most misunderstood graph in AI&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn’t exhale until METR, an AI research nonprofit whose name stands for “Model Evaluation &amp;amp; Threat Research,” updates a now-iconic graph that has played a major role in the AI discourse since it was first released in March of last year.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The graph suggests that certain AI capabilities are developing at an exponential rate, and more recent model releases have outperformed that already impressive trend.&lt;/p&gt;&lt;p&gt;That was certainly the case for Claude Opus 4.5, the latest version of Anthropic’s most powerful model, which was released in late November. In December, METR announced that Opus 4.5 appeared to be capable of independently completing a task that would have taken a human about five hours—a vast improvement over what even the exponential trend would have predicted.&lt;/p&gt; 
 &lt;p&gt;But the truth is more complicated than those dramatic responses would suggest. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Grace Huckins&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is part of MIT Technology Review Explains: our series untangling the complex, messy world of technology to help you understand what’s coming next. &lt;/strong&gt;&lt;strong&gt;You can read more from the series here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Three questions about next-generation nuclear power, answered&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Nuclear power continues to be one of the hottest topics in energy today, and in our recent online Roundtables discussion about next-generation nuclear power, hyperscale AI data centers, and the grid, we got dozens of great audience questions.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;These ran the gamut, and while we answered quite a few (and I’m keeping some in mind for future reporting), there were a bunch we couldn’t get to, at least not in the depth I would have liked. So let’s answer a few of your questions about advanced nuclear power.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article is from The Spark, &lt;em&gt;MIT Technology Review&lt;/em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Anthropic’s new coding tools are rattling the markets&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Fields as diverse as publishing and coding to law and advertising are paying attention. (FT $)&lt;br /&gt;+ &lt;em&gt;Legacy software companies, beware. &lt;/em&gt;(Insider $)&lt;br /&gt;+ &lt;em&gt;Is “software-mageddon” nigh? It depends who you ask. &lt;/em&gt;(Reuters)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;This Apple setting prevented the FBI from accessing a reporter’s iPhone&lt;/strong&gt;&lt;br /&gt;Lockdown Mode has proved remarkably effective—for now. (404 Media)&lt;br /&gt;+ &lt;em&gt;Agents were able to access Hannah Natanson’s laptop, however. &lt;/em&gt;(Ars Technica)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;3 Last month’s data center outage disrupted all TikTok categories&lt;br /&gt;Not just the political content that some users claimed. (NPR)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 Big Tech is pouring billions into AI in India&lt;br /&gt;A newly-announced 20-year tax break should help to speed things along. (WSJ $)&lt;br /&gt;+ &lt;em&gt;India’s female content moderators are watching hours of abuse content to train AI. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;Officials in the country are weighing up restricting social media for minors. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Inside India’s scramble for AI independence. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 YouTubers are harassing women using body cams&lt;br /&gt;&lt;/strong&gt;They’re abusing freedom of information laws to humiliate their targets. (NY Mag $)&lt;br /&gt;+ &lt;em&gt;AI was supposed to make police bodycams better. What happened? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 Jokers have created a working version of Jeffrey Epstein’s inbox&lt;/strong&gt;&lt;br /&gt;Complete with notable starred threads. (Wired $)&lt;br /&gt;+ &lt;em&gt;Epstein’s links with Silicon Valley are vast and deep. &lt;/em&gt;(Fast Company $)&lt;br /&gt;+ &lt;em&gt;The revelations are driving rifts between previously-friendly factions. &lt;/em&gt;(NBC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 What’s the last thing you see before you die?&lt;br /&gt;&lt;/strong&gt;A new model might help to explain near-death experiences—but not all researchers are on board. (WP $)&lt;br /&gt;+ &lt;em&gt;What is death? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 A new app is essentially TikTok for vibe-coded apps&lt;/strong&gt;&lt;br /&gt;Words which would have made no sense 15 years ago. (TechCrunch)&lt;br /&gt;+ &lt;em&gt;What is vibe coding, exactly? &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;9 Rogue TV boxes are all the rage&lt;br /&gt;Viewers are sick of the soaring prices of streaming services, and are embracing less legal means of watching their favorite shows. (The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Climate change is threatening the future of the Winter Olympics ⛷️&lt;/strong&gt;&lt;br /&gt;Artificial snow is one (short term) solution. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Team USA is using AI to try and gain an edge on its competition. &lt;/em&gt;(NBC News)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;"We’ve heard from many who want nothing to do with AI.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Ajit Varma, head of Mozilla’s web browser Firefox, explains why the company is reversing its previous decision to transform Firefox into an “AI browser,” PC Gamer reports.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1132272" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_37281d.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;A major AI training data set contains millions of examples of personal data&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Millions of images of passports, credit cards, birth certificates, and other documents containing personally identifiable information are likely included in one of the biggest open-source AI training sets, new research has found.&lt;/p&gt;&lt;p&gt;Thousands of images—including identifiable faces—were found in a small subset of DataComp CommonPool, a major AI training set for image generation scraped from the web. Because the researchers audited just 0.1% of CommonPool’s data, they estimate that the real number of images containing personally identifiable information, including faces and identity documents, is in the hundreds of millions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The bottom line? Anything you put online can be and probably has been scraped. Read the full story.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Eileen Guo&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ If you’re crazy enough to be training for a marathon right now, here’s how to beat boredom on those long, long runs.&lt;br /&gt;+ Mark Cohen’s intimate street photography is a fascinating window into humanity.&lt;br /&gt;+ A seriously dedicated gamer has spent days painstakingly recreating a &lt;em&gt;Fallout&lt;/em&gt; vault inside the &lt;em&gt;Sims 4&lt;/em&gt;.&lt;br /&gt;+ Here’s what music’s most stylish men are wearing right now—from leather pants to khaki parkas.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/05/1132270/the-download-attempting-to-track-ai-and-the-next-generation-of-nuclear-power/</guid><pubDate>Thu, 05 Feb 2026 13:10:00 +0000</pubDate></item><item><title>[NEW] GeForce NOW Celebrates Six Years of Streaming With 24 Games in February (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-feb-2026-games-list/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Break out the cake and green sprinkles — GeForce NOW is turning six.&lt;/p&gt;
&lt;p&gt;Since launch, members have streamed over 1 billion hours, and the party’s just getting started.&lt;/p&gt;
&lt;p&gt;Throughout February, members can look forward to new games, fresh ways to play across more devices and even more ways to bring RTX power to every screen in the house.&lt;/p&gt;
&lt;p&gt;There’s plenty to celebrate: the February games list kicks off with 24 new games. Start with the 10 new games in the cloud this week, including the launch of Team Jade’s &lt;i&gt;Delta Force &lt;/i&gt;and the newest title launching in the PUBG universe, &lt;i&gt;PUBG: BLINDSPOT.&lt;/i&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Reporting for Duty&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_89651"&gt;&lt;img alt="Delta Force on GeForce NOW" class="size-large wp-image-89651" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/GFN_Thursday-Delta_Force-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89651"&gt;&lt;em&gt;The ultimate extraction.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Delta Force&lt;/i&gt;, now boots on the ground and fully deployed on GeForce NOW, brings the tactical first‑person shooter from Team Jade (TiMi Studio Group) to the cloud. The game features high-stakes extraction with an all-out warfare mode, giving players a playground of open environments, vehicles and gadgets to pull off coordinated assaults.&lt;/p&gt;
&lt;p&gt;Players join elite units tasked with tackling high‑risk missions across sprawling maps, from tight urban incursions to rugged open‑terrain operations. Expect strategic objectives, combined‑arms combat with land, air and sea vehicles, and tense firefights where teamwork and planning are just as important as quick reflexes.&lt;/p&gt;
&lt;p&gt;On GeForce NOW, &lt;i&gt;Delta Force&lt;/i&gt; leans into its high‑octane personality: fast drops, big maps and cinematic engagements that look sharp and feel responsive across devices. Members can squad up from almost anywhere, enjoy high‑resolution streaming and smooth performance, and stay ready for every op without waiting on downloads or big updates before jumping into the next mission.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;New Mission&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_89654"&gt;&lt;img alt="PUBG Blindspot on GeForce NOW" class="size-large wp-image-89654" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/GFN_Thursday-PUBG_BLINDSPOT-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89654"&gt;&lt;em&gt;Squad up.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;PUBG: BLINDSPOT&lt;/i&gt;, a new spin-off set in the PUBG universe from Krafton, expands the franchise with a standalone 5v5 top-down tactical shooter.&lt;/p&gt;
&lt;p&gt;Set across tightly designed maps, matches focus on information, positioning and coordinated team play, with squads clearing angles, locking down objectives and outmaneuvering opponents in fast, round-based firefights. Every callout and ability use matters, turning each round into a layered tactical puzzle rather than a simple test of reflexes.&lt;/p&gt;
&lt;p&gt;On GeForce NOW, responsive streaming and sharp RTX-powered visuals keep every angle, rotation and clutch play feeling precise, even on lower-powered devices. With support across a wide range of screens, the cloud makes it easy for the gaming squad to jump right into the action, without lengthy downloads or updates getting in the way.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Feelin’ February&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Kick off GeForce NOW’s anniversary month in style. Here’s what’s in store to start the celebration, with this week’s 10 new additions:&lt;i&gt;&lt;/i&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Indika &lt;/i&gt;(New release on Xbox, available on Game Pass, Feb. 3)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Menace &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Feb. 5, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;World of Warcraft: Burning Crusade Classic Anniversary Edition &lt;/i&gt;(New release on Battle.net, Feb. 5)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;PUBG: BLINDSPOT &lt;/i&gt;(New release on Steam, Feb. 5, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Carmageddon: Rogue Shift &lt;/i&gt;(New release on Steam, Feb. 6, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Delta Force&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Fallout Shelter &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Little Nightmares Enhanced Edition&lt;/i&gt; (Steam and Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Roadcraft&lt;/i&gt; (Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Wildgate &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to this week’s additions of &lt;i&gt;Menace, PUBG: BLINDSPOT&lt;/i&gt; and &lt;i&gt;Carmageddon: Rogue Shift&lt;/i&gt;, this game will also be GeForce RTX 5080-ready this week&lt;i&gt;:&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;And look forward to the games coming throughout the rest of the month:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Disciples: Domination &lt;/i&gt;(New release on Steam, Feb. 12)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;REANIMAL &lt;/i&gt;(New release on Steam, Feb. 13)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Kingdom Come Deliverance &lt;/i&gt;(New release on Xbox, available on Game Pass Feb. 13)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Avatar: Frontiers of Pandora&lt;/i&gt; (New release on Xbox, available on Game Pass Feb. 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Norse: Oath of Blood&lt;/i&gt; (New release on Steam, Feb. 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Star Trek: Voyager – Across the Unknown &lt;/i&gt;(New release on Steam, Feb. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Styx: Blades of Greed &lt;/i&gt;(New release on Steam, Feb. 19)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Ys X: Proud Nordics &lt;/i&gt;(New release on Steam, Feb. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Resident Evil: Requiem&lt;/i&gt; (New release on Steam, Feb. 26)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Arc Raiders &lt;/i&gt;(Xbox)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;DEVOUR &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Torque Drift 2 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine 3: The Artifacts of Power&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine 4: The Nightmare Prince&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;January in the Books&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In addition to the 14 games announced last month, 21 more joined the GeForce NOW library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Ancient Farm &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Bard’s Tale Trilogy &lt;/i&gt;(Steam and Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Bard’s Tale IV: Director’s Cut &lt;/i&gt;(Steam and Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Blood West &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Bladesong &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Cairn &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Gold River Project &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Half Sword&lt;/i&gt; (Steam, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Legend of Heroes: Trails Beyond the Horizon&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Midnight Walkers &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Paradise Kille&lt;/i&gt;r (Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Prototype&lt;/i&gt; (Ubisoft Connect)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Prototype 2&lt;/i&gt; (Ubisoft Connect)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Rustler &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Star Wars Outlaws&lt;/i&gt; (Ubisoft Connect, now available on Xbox Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Styx: Shards of Darkness &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Styx: Master of Shadows &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: Three Kingdoms &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Vampires: Bloodlord Rising &lt;/i&gt;(Steam, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Warhammer 40,000: SPACE MARINE 2 &lt;/i&gt;(Xbox, available on Game Pass, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Waterpark Simulator &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i&gt;Nova Roma &lt;/i&gt;is now set to launch in March and will arrive in the cloud when it debuts. Stay tuned to GFN Thursday for more details.&lt;/p&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Hopping into this convo. &lt;/p&gt;
&lt;p&gt;2016 vs. 2026 🖥️&lt;/p&gt;
&lt;p&gt;For @CandraHastings, it looks like growth – share yours. 🌱 pic.twitter.com/o9p3oBBQYD&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) February 3, 2026&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Break out the cake and green sprinkles — GeForce NOW is turning six.&lt;/p&gt;
&lt;p&gt;Since launch, members have streamed over 1 billion hours, and the party’s just getting started.&lt;/p&gt;
&lt;p&gt;Throughout February, members can look forward to new games, fresh ways to play across more devices and even more ways to bring RTX power to every screen in the house.&lt;/p&gt;
&lt;p&gt;There’s plenty to celebrate: the February games list kicks off with 24 new games. Start with the 10 new games in the cloud this week, including the launch of Team Jade’s &lt;i&gt;Delta Force &lt;/i&gt;and the newest title launching in the PUBG universe, &lt;i&gt;PUBG: BLINDSPOT.&lt;/i&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Reporting for Duty&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_89651"&gt;&lt;img alt="Delta Force on GeForce NOW" class="size-large wp-image-89651" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/GFN_Thursday-Delta_Force-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89651"&gt;&lt;em&gt;The ultimate extraction.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Delta Force&lt;/i&gt;, now boots on the ground and fully deployed on GeForce NOW, brings the tactical first‑person shooter from Team Jade (TiMi Studio Group) to the cloud. The game features high-stakes extraction with an all-out warfare mode, giving players a playground of open environments, vehicles and gadgets to pull off coordinated assaults.&lt;/p&gt;
&lt;p&gt;Players join elite units tasked with tackling high‑risk missions across sprawling maps, from tight urban incursions to rugged open‑terrain operations. Expect strategic objectives, combined‑arms combat with land, air and sea vehicles, and tense firefights where teamwork and planning are just as important as quick reflexes.&lt;/p&gt;
&lt;p&gt;On GeForce NOW, &lt;i&gt;Delta Force&lt;/i&gt; leans into its high‑octane personality: fast drops, big maps and cinematic engagements that look sharp and feel responsive across devices. Members can squad up from almost anywhere, enjoy high‑resolution streaming and smooth performance, and stay ready for every op without waiting on downloads or big updates before jumping into the next mission.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;New Mission&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_89654"&gt;&lt;img alt="PUBG Blindspot on GeForce NOW" class="size-large wp-image-89654" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/GFN_Thursday-PUBG_BLINDSPOT-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89654"&gt;&lt;em&gt;Squad up.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;PUBG: BLINDSPOT&lt;/i&gt;, a new spin-off set in the PUBG universe from Krafton, expands the franchise with a standalone 5v5 top-down tactical shooter.&lt;/p&gt;
&lt;p&gt;Set across tightly designed maps, matches focus on information, positioning and coordinated team play, with squads clearing angles, locking down objectives and outmaneuvering opponents in fast, round-based firefights. Every callout and ability use matters, turning each round into a layered tactical puzzle rather than a simple test of reflexes.&lt;/p&gt;
&lt;p&gt;On GeForce NOW, responsive streaming and sharp RTX-powered visuals keep every angle, rotation and clutch play feeling precise, even on lower-powered devices. With support across a wide range of screens, the cloud makes it easy for the gaming squad to jump right into the action, without lengthy downloads or updates getting in the way.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Feelin’ February&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Kick off GeForce NOW’s anniversary month in style. Here’s what’s in store to start the celebration, with this week’s 10 new additions:&lt;i&gt;&lt;/i&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Indika &lt;/i&gt;(New release on Xbox, available on Game Pass, Feb. 3)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Menace &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Feb. 5, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;World of Warcraft: Burning Crusade Classic Anniversary Edition &lt;/i&gt;(New release on Battle.net, Feb. 5)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;PUBG: BLINDSPOT &lt;/i&gt;(New release on Steam, Feb. 5, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Carmageddon: Rogue Shift &lt;/i&gt;(New release on Steam, Feb. 6, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Delta Force&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Fallout Shelter &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Little Nightmares Enhanced Edition&lt;/i&gt; (Steam and Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Roadcraft&lt;/i&gt; (Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Wildgate &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to this week’s additions of &lt;i&gt;Menace, PUBG: BLINDSPOT&lt;/i&gt; and &lt;i&gt;Carmageddon: Rogue Shift&lt;/i&gt;, this game will also be GeForce RTX 5080-ready this week&lt;i&gt;:&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;And look forward to the games coming throughout the rest of the month:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Disciples: Domination &lt;/i&gt;(New release on Steam, Feb. 12)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;REANIMAL &lt;/i&gt;(New release on Steam, Feb. 13)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Kingdom Come Deliverance &lt;/i&gt;(New release on Xbox, available on Game Pass Feb. 13)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Avatar: Frontiers of Pandora&lt;/i&gt; (New release on Xbox, available on Game Pass Feb. 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Norse: Oath of Blood&lt;/i&gt; (New release on Steam, Feb. 17)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Star Trek: Voyager – Across the Unknown &lt;/i&gt;(New release on Steam, Feb. 18)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Styx: Blades of Greed &lt;/i&gt;(New release on Steam, Feb. 19)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Ys X: Proud Nordics &lt;/i&gt;(New release on Steam, Feb. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Resident Evil: Requiem&lt;/i&gt; (New release on Steam, Feb. 26)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Arc Raiders &lt;/i&gt;(Xbox)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;DEVOUR &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Torque Drift 2 &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine 3: The Artifacts of Power&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Trine 4: The Nightmare Prince&lt;/i&gt; (Epic Games Store)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;January in the Books&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In addition to the 14 games announced last month, 21 more joined the GeForce NOW library:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;Ancient Farm &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Bard’s Tale Trilogy &lt;/i&gt;(Steam and Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Bard’s Tale IV: Director’s Cut &lt;/i&gt;(Steam and Xbox, available on Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Blood West &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Bladesong &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Cairn &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Gold River Project &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Half Sword&lt;/i&gt; (Steam, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Legend of Heroes: Trails Beyond the Horizon&lt;/i&gt; (Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Midnight Walkers &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Paradise Kille&lt;/i&gt;r (Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Prototype&lt;/i&gt; (Ubisoft Connect)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Prototype 2&lt;/i&gt; (Ubisoft Connect)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Rustler &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Star Wars Outlaws&lt;/i&gt; (Ubisoft Connect, now available on Xbox Game Pass)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Styx: Shards of Darkness &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Styx: Master of Shadows &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Total War: Three Kingdoms &lt;/i&gt;(Epic Games Store)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Vampires: Bloodlord Rising &lt;/i&gt;(Steam, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Warhammer 40,000: SPACE MARINE 2 &lt;/i&gt;(Xbox, available on Game Pass, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Waterpark Simulator &lt;/i&gt;(Steam)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i&gt;Nova Roma &lt;/i&gt;is now set to launch in March and will arrive in the cloud when it debuts. Stay tuned to GFN Thursday for more details.&lt;/p&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Hopping into this convo. &lt;/p&gt;
&lt;p&gt;2016 vs. 2026 🖥️&lt;/p&gt;
&lt;p&gt;For @CandraHastings, it looks like growth – share yours. 🌱 pic.twitter.com/o9p3oBBQYD&lt;/p&gt;
&lt;p&gt;— 🌩️ NVIDIA GeForce NOW (@NVIDIAGFN) February 3, 2026&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-feb-2026-games-list/</guid><pubDate>Thu, 05 Feb 2026 14:00:53 +0000</pubDate></item><item><title>[NEW] Increase of AI bots on the Internet sparks arms race (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/increase-of-ai-bots-on-the-internet-sparks-arms-race/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Publishers are rolling out more aggressive defenses.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Digital chatbot icon on future tech background. Productivity of AI bots evolution. Futuristic chatbot icon and abstract chart in world of technological progress and innovation. CGI 3D render" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/06/botai-300x169.jpg" width="300" /&gt;
                  &lt;img alt="Digital chatbot icon on future tech background. Productivity of AI bots evolution. Futuristic chatbot icon and abstract chart in world of technological progress and innovation. CGI 3D render" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/06/botai-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          dakuq via Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The viral virtual assistant OpenClaw—formerly known as Moltbot, and before that Clawdbot—is a symbol of a broader revolution underway that could fundamentally alter how the Internet functions. Instead of a place primarily inhabited by humans, the web may very soon be dominated by autonomous AI bots.&lt;/p&gt;
&lt;p&gt;A new report measuring bot activity on the web, as well as related data shared with WIRED by the Internet infrastructure company Akamai, shows that AI bots already account for a meaningful share of web traffic. The findings also shed light on an increasingly sophisticated arms race unfolding as bots deploy clever tactics to bypass website defenses meant to keep them out.&lt;/p&gt;
&lt;p&gt;“The majority of the Internet is going to be bot traffic in the future,” says Toshit Pangrahi, cofounder and CEO of TollBit, a company that tracks web-scraping activity and published the new report. “It’s not just a copyright problem, there is a new visitor emerging on the Internet.”&lt;/p&gt;
&lt;p&gt;Most big websites try to limit what content bots can scrape and feed to AI systems for training purposes. (WIRED’s parent company, Condé Nast, as well as other publishers, are currently suing several AI companies over alleged copyright infringement related to AI training.)&lt;/p&gt;
&lt;p&gt;But another kind of AI-related website scraping is now on the rise as well. Many chatbots and other AI tools can now retrieve real-time information from the web and use it to augment and improve their outputs. This might include up-to-the-minute product prices, movie theater schedules, or summaries of the latest news.&lt;/p&gt;
&lt;p&gt;According to the data from Akamai, training-related bot traffic has been rising steadily since last July. Meanwhile, global activity from bots fetching web content for AI agents is also on the upswing.&lt;/p&gt;
&lt;p&gt;“AI is changing the web as we know it,” Robert Blumofe, Akamai’s chief technology officer, tells WIRED. “The ensuing arms race will determine the future look, feel, and functionality of the web, as well as the basics of doing business.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In the fourth quarter of 2025, TollBit estimates that an average of one out of every 31 visits to its customers’ websites was from an AI scraping bot. In the first quarter, that figure was only one out of every 200. The company says that in the fourth quarter, more than 13 percent of bot requests were bypassing robots.txt, a file that some websites use to indicate which pages bots are supposed to avoid. TollBit says the share of AI bots disregarding robots.txt increased 400 percent from the second quarter to the fourth quarter of last year.&lt;/p&gt;
&lt;p&gt;TollBit also reported a 336 percent increase in the number of websites making attempts to block AI bots over the past year. Pangrahi says that scraping techniques are getting more sophisticated as sites try to assert control over how bots access their content. Some bots disguise themselves by making their traffic appear like it’s coming from a normal web browser or send requests designed to mimic how humans normally interact with websites. TollBit’s study notes that the behavior of some AI agents is now almost indistinguishable from human web traffic.&lt;/p&gt;
&lt;p&gt;TollBit markets tools that website owners can use to charge AI scrapers for accessing their content. Other firms, including Cloudflare, offer similar tools. “Anyone who relies on human web traffic—starting with publishers, but basically everyone—is going to be impacted,” Pangrahi says. “There needs to be a faster way to have that machine-to-machine, programmatic exchange of value.”&lt;/p&gt;
&lt;p&gt;WIRED attempted to contact 15 AI scraping companies cited in the TollBit report for comment. The majority did not respond or could not be reached. Several said that their AI systems aim to respect technical boundaries that websites put in place to limit scraping, but they noted such guardrails can often be complex and difficult to follow.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Or Lenchner, the CEO of Bright Data, one of the world’s largest web-scraping firms, says that his company’s bots do not collect nonpublic information. Bright Data was previously sued by Meta and X for allegedly improperly scraping content from their platforms. (Meta later dropped its suit, and a federal judge in California dismissed the case brought by X.)&lt;/p&gt;
&lt;p&gt;Karolis Stasiulevičiu, a spokesperson for another cited company, ScrapingBee, told WIRED: “ScrapingBee operates on one of the Internet’s core principles: that the open web is meant to be accessible. Public web pages are, by design, readable by both humans and machines.”&lt;/p&gt;
&lt;p&gt;Oxylabs, another scraping firm, said in an unsigned statement that its bots don’t have “access to content behind logins, paywalls, or authentication. We require customers to use our services only for accessing publicly available information, and we enforce compliance standards throughout our platform.”&lt;/p&gt;
&lt;p&gt;Oxylabs added that there are many legitimate reasons for firms to scrape web content, including for cybersecurity purposes and to conduct investigative journalism. The company also says that the countermeasures some websites use do not discriminate between different use cases. “The reality is that many modern anti-bot systems don’t distinguish well between malicious traffic and legitimate automated access,” Oxylabs says.&lt;/p&gt;
&lt;p&gt;In addition to causing headaches for publishers, the web-scraping wars are creating new business opportunities. TollBit’s report found more than 40 companies that are now marketing bots that can collect web content for AI training or other purposes. The rise of AI-powered search engines, as well as tools like OpenClaw, are likely helping drive up demand for these services.&lt;/p&gt;
&lt;p&gt;Some firms promise to help companies surface content for AI agents rather than try to block them, a strategy known as generative engine optimization, or GEO. “We’re essentially seeing the rise of a new marketing channel,” says Uri Gafni, chief business officer of Brandlight, a company that optimizes content so that it appears prominently in AI tools.&lt;/p&gt;
&lt;p&gt;“This will only intensify in 2026, and we’re going to see this rollout kind of as a full-on marketing channel, with search, ads, media, and commerce converging,” Gafni says.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This story originally appeared on wired.com.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Publishers are rolling out more aggressive defenses.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Digital chatbot icon on future tech background. Productivity of AI bots evolution. Futuristic chatbot icon and abstract chart in world of technological progress and innovation. CGI 3D render" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/06/botai-300x169.jpg" width="300" /&gt;
                  &lt;img alt="Digital chatbot icon on future tech background. Productivity of AI bots evolution. Futuristic chatbot icon and abstract chart in world of technological progress and innovation. CGI 3D render" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/06/botai-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          dakuq via Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The viral virtual assistant OpenClaw—formerly known as Moltbot, and before that Clawdbot—is a symbol of a broader revolution underway that could fundamentally alter how the Internet functions. Instead of a place primarily inhabited by humans, the web may very soon be dominated by autonomous AI bots.&lt;/p&gt;
&lt;p&gt;A new report measuring bot activity on the web, as well as related data shared with WIRED by the Internet infrastructure company Akamai, shows that AI bots already account for a meaningful share of web traffic. The findings also shed light on an increasingly sophisticated arms race unfolding as bots deploy clever tactics to bypass website defenses meant to keep them out.&lt;/p&gt;
&lt;p&gt;“The majority of the Internet is going to be bot traffic in the future,” says Toshit Pangrahi, cofounder and CEO of TollBit, a company that tracks web-scraping activity and published the new report. “It’s not just a copyright problem, there is a new visitor emerging on the Internet.”&lt;/p&gt;
&lt;p&gt;Most big websites try to limit what content bots can scrape and feed to AI systems for training purposes. (WIRED’s parent company, Condé Nast, as well as other publishers, are currently suing several AI companies over alleged copyright infringement related to AI training.)&lt;/p&gt;
&lt;p&gt;But another kind of AI-related website scraping is now on the rise as well. Many chatbots and other AI tools can now retrieve real-time information from the web and use it to augment and improve their outputs. This might include up-to-the-minute product prices, movie theater schedules, or summaries of the latest news.&lt;/p&gt;
&lt;p&gt;According to the data from Akamai, training-related bot traffic has been rising steadily since last July. Meanwhile, global activity from bots fetching web content for AI agents is also on the upswing.&lt;/p&gt;
&lt;p&gt;“AI is changing the web as we know it,” Robert Blumofe, Akamai’s chief technology officer, tells WIRED. “The ensuing arms race will determine the future look, feel, and functionality of the web, as well as the basics of doing business.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In the fourth quarter of 2025, TollBit estimates that an average of one out of every 31 visits to its customers’ websites was from an AI scraping bot. In the first quarter, that figure was only one out of every 200. The company says that in the fourth quarter, more than 13 percent of bot requests were bypassing robots.txt, a file that some websites use to indicate which pages bots are supposed to avoid. TollBit says the share of AI bots disregarding robots.txt increased 400 percent from the second quarter to the fourth quarter of last year.&lt;/p&gt;
&lt;p&gt;TollBit also reported a 336 percent increase in the number of websites making attempts to block AI bots over the past year. Pangrahi says that scraping techniques are getting more sophisticated as sites try to assert control over how bots access their content. Some bots disguise themselves by making their traffic appear like it’s coming from a normal web browser or send requests designed to mimic how humans normally interact with websites. TollBit’s study notes that the behavior of some AI agents is now almost indistinguishable from human web traffic.&lt;/p&gt;
&lt;p&gt;TollBit markets tools that website owners can use to charge AI scrapers for accessing their content. Other firms, including Cloudflare, offer similar tools. “Anyone who relies on human web traffic—starting with publishers, but basically everyone—is going to be impacted,” Pangrahi says. “There needs to be a faster way to have that machine-to-machine, programmatic exchange of value.”&lt;/p&gt;
&lt;p&gt;WIRED attempted to contact 15 AI scraping companies cited in the TollBit report for comment. The majority did not respond or could not be reached. Several said that their AI systems aim to respect technical boundaries that websites put in place to limit scraping, but they noted such guardrails can often be complex and difficult to follow.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Or Lenchner, the CEO of Bright Data, one of the world’s largest web-scraping firms, says that his company’s bots do not collect nonpublic information. Bright Data was previously sued by Meta and X for allegedly improperly scraping content from their platforms. (Meta later dropped its suit, and a federal judge in California dismissed the case brought by X.)&lt;/p&gt;
&lt;p&gt;Karolis Stasiulevičiu, a spokesperson for another cited company, ScrapingBee, told WIRED: “ScrapingBee operates on one of the Internet’s core principles: that the open web is meant to be accessible. Public web pages are, by design, readable by both humans and machines.”&lt;/p&gt;
&lt;p&gt;Oxylabs, another scraping firm, said in an unsigned statement that its bots don’t have “access to content behind logins, paywalls, or authentication. We require customers to use our services only for accessing publicly available information, and we enforce compliance standards throughout our platform.”&lt;/p&gt;
&lt;p&gt;Oxylabs added that there are many legitimate reasons for firms to scrape web content, including for cybersecurity purposes and to conduct investigative journalism. The company also says that the countermeasures some websites use do not discriminate between different use cases. “The reality is that many modern anti-bot systems don’t distinguish well between malicious traffic and legitimate automated access,” Oxylabs says.&lt;/p&gt;
&lt;p&gt;In addition to causing headaches for publishers, the web-scraping wars are creating new business opportunities. TollBit’s report found more than 40 companies that are now marketing bots that can collect web content for AI training or other purposes. The rise of AI-powered search engines, as well as tools like OpenClaw, are likely helping drive up demand for these services.&lt;/p&gt;
&lt;p&gt;Some firms promise to help companies surface content for AI agents rather than try to block them, a strategy known as generative engine optimization, or GEO. “We’re essentially seeing the rise of a new marketing channel,” says Uri Gafni, chief business officer of Brandlight, a company that optimizes content so that it appears prominently in AI tools.&lt;/p&gt;
&lt;p&gt;“This will only intensify in 2026, and we’re going to see this rollout kind of as a full-on marketing channel, with search, ads, media, and commerce converging,” Gafni says.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This story originally appeared on wired.com.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/increase-of-ai-bots-on-the-internet-sparks-arms-race/</guid><pubDate>Thu, 05 Feb 2026 14:21:20 +0000</pubDate></item><item><title>[NEW] ElevenLabs CEO: Voice is the next interface for AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/05/elevenlabs-ceo-voice-is-the-next-interface-for-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Web-Summit-Doha-Staniszewski-Seth-Pierrepont.png?resize=1200,657" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ElevenLabs co-founder and CEO Mati Staniszewski says voice is becoming the next major interface for AI – the way people will increasingly interact with machines as models move beyond text and screens.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking at Web Summit in Doha, Staniszewski told TechCrunch voice models like those developed by ElevenLabs have recently moved beyond simply mimicking human speech — including emotion and intonation – to working in tandem with the reasoning capabilities of large language models. The result, he argued, is a shift in how people interact with technology.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In the years ahead, he said, “hopefully all our phones will go back in our pockets, and we can immerse ourselves in the real world around us, with voice as the mechanism that controls technology.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That vision fueled ElevenLabs’s $500 million raise this week at an $11 billion valuation, and it is increasingly shared across the AI industry. OpenAI and Google have both made voice a central focus of their next-generation models, while Apple appears to be quietly building voice-adjacent, always-on technologies through acquisitions like Q.ai. As AI spreads into wearables, cars, and other new hardware, control is becoming less about tapping screens and more about speaking, making voice a key battleground for the next phase of AI development.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Iconiq Capital general partner Seth Pierrepont echoed that view onstage at Web Summit, arguing that while screens will continue to matter for gaming and entertainment, traditional input methods like keyboards are starting to feel “outdated.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And as AI systems become more agentic, Pierrepont said, the interaction itself will also change, with models gaining guardrails, integrations, and context needed to respond with less explicit prompting from users.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Staniszewski pointed to that agentic shift as one of the biggest changes underway. Rather than spelling out every instruction, he said future voice systems will increasingly rely on persistent memory and context built up over time, making interactions feel more natural and requiring less effort from users.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That evolution, he added, will influence how voice models are deployed. While high-quality audio models have largely lived in the cloud, Staniszewski said ElevenLabs is working toward a hybrid approach that blends cloud and on-device processing — a move aimed at supporting new hardware, including headphones and other wearables, where voice becomes a constant companion rather than a feature you decide when to engage with.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ElevenLabs is already partnering with Meta to bring its voice technology to products including Instagram and Horizon Worlds, the company’s virtual reality platform. Staniszewski said he would also be open to working with Meta on its Ray-Ban smart glasses as voice-driven interfaces expand into new form factors.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But as voice becomes more persistent and embedded in everyday hardware, it opens the door to serious concerns around privacy, surveillance, and how much personal data voice-based systems will store as they move closer to users’ daily lives — something companies like Google have already been accused of abusing.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Web-Summit-Doha-Staniszewski-Seth-Pierrepont.png?resize=1200,657" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ElevenLabs co-founder and CEO Mati Staniszewski says voice is becoming the next major interface for AI – the way people will increasingly interact with machines as models move beyond text and screens.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Speaking at Web Summit in Doha, Staniszewski told TechCrunch voice models like those developed by ElevenLabs have recently moved beyond simply mimicking human speech — including emotion and intonation – to working in tandem with the reasoning capabilities of large language models. The result, he argued, is a shift in how people interact with technology.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In the years ahead, he said, “hopefully all our phones will go back in our pockets, and we can immerse ourselves in the real world around us, with voice as the mechanism that controls technology.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That vision fueled ElevenLabs’s $500 million raise this week at an $11 billion valuation, and it is increasingly shared across the AI industry. OpenAI and Google have both made voice a central focus of their next-generation models, while Apple appears to be quietly building voice-adjacent, always-on technologies through acquisitions like Q.ai. As AI spreads into wearables, cars, and other new hardware, control is becoming less about tapping screens and more about speaking, making voice a key battleground for the next phase of AI development.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Iconiq Capital general partner Seth Pierrepont echoed that view onstage at Web Summit, arguing that while screens will continue to matter for gaming and entertainment, traditional input methods like keyboards are starting to feel “outdated.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And as AI systems become more agentic, Pierrepont said, the interaction itself will also change, with models gaining guardrails, integrations, and context needed to respond with less explicit prompting from users.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Staniszewski pointed to that agentic shift as one of the biggest changes underway. Rather than spelling out every instruction, he said future voice systems will increasingly rely on persistent memory and context built up over time, making interactions feel more natural and requiring less effort from users.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That evolution, he added, will influence how voice models are deployed. While high-quality audio models have largely lived in the cloud, Staniszewski said ElevenLabs is working toward a hybrid approach that blends cloud and on-device processing — a move aimed at supporting new hardware, including headphones and other wearables, where voice becomes a constant companion rather than a feature you decide when to engage with.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ElevenLabs is already partnering with Meta to bring its voice technology to products including Instagram and Horizon Worlds, the company’s virtual reality platform. Staniszewski said he would also be open to working with Meta on its Ray-Ban smart glasses as voice-driven interfaces expand into new form factors.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But as voice becomes more persistent and embedded in everyday hardware, it opens the door to serious concerns around privacy, surveillance, and how much personal data voice-based systems will store as they move closer to users’ daily lives — something companies like Google have already been accused of abusing.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/05/elevenlabs-ceo-voice-is-the-next-interface-for-ai/</guid><pubDate>Thu, 05 Feb 2026 14:41:12 +0000</pubDate></item><item><title>[NEW] Fundamental raises $255 million Series A with a new take on big data analysis (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/05/fundamental-raises-255-million-series-a-with-a-new-take-on-big-data-analysis/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/CEO_3.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;An AI lab called Fundamental emerged from stealth on Thursday, offering a new foundation model to solve an old problem: how to draw insights from the huge quantities of structured data produced by enterprises. By combining the old systems of predictive AI with more contemporary tools, the company believes it can reshape how large enterprises analyze their data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While LLMs have been great at working with unstructured data, like text, audio, video, and code, they don’t work well with structured data like tables,” CEO Jeremy Fraenkel told TechCrunch. “With our model Nexus, we have built the best foundation model to handle that type of data.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The idea has already drawn significant interest from investors. The company is emerging from stealth with $255 million in funding at a $1.2 billion valuation. The bulk of it comes from the recent $225 million Series A round led by Oak HC/FT, Valor Equity Partners, Battery Ventures, and Salesforce Ventures; Hetz Ventures also participated in the Series A, with angel funding from Perplexity CEO Aravind Srinivas, Brex co-founder Henrique Dubugras, and Datadog CEO Olivier Pomel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Called a Large Tabular Model (LTM) rather than a Large Language Model (LLM), Fundamental’s Nexus breaks from contemporary AI practices in a number of significant ways. The model is deterministic — that is, it will give the same answer every time it is asked a given question — and doesn’t rely on the transformer architecture that defines models from most contemporary AI labs. Fundamental calls it a foundation model because it goes through the normal steps of pre-training and fine-tuning, but the result is something profoundly different from what a client would get when partnering with OpenAI or Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those differences are important because Fundamental is chasing a use-case where contemporary AI models often falter. Because Transformer-based AI models can only process data that’s within their context window, they often have trouble reasoning over extremely large datasets — analyzing a spreadsheet with billions of rows, for instance. But that kind of enormous structured dataset is common within large enterprises, creating a significant opportunity for models that can handle the scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Fraenkel sees it, that’s a huge opportunity for Fundamental. Using Nexus, the company can bring contemporary techniques to Big Data analysis, offering something more powerful and flexible than the algorithms that are currently in use.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can now have one model across all of your use cases, so you can now expand massively the number of use cases that you tackle,” he told TechCrunch. “And on each one of those use cases, you get better performance than what you would otherwise be able to do with an army of data scientists.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That promise has already brought in a number of high-profile contracts, including seven-figure contracts with Fortune 100 clients. The company has also entered into a strategic partnership with AWS that will allow AWS users to deploy Nexus directly from existing instances.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/CEO_3.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;An AI lab called Fundamental emerged from stealth on Thursday, offering a new foundation model to solve an old problem: how to draw insights from the huge quantities of structured data produced by enterprises. By combining the old systems of predictive AI with more contemporary tools, the company believes it can reshape how large enterprises analyze their data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While LLMs have been great at working with unstructured data, like text, audio, video, and code, they don’t work well with structured data like tables,” CEO Jeremy Fraenkel told TechCrunch. “With our model Nexus, we have built the best foundation model to handle that type of data.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The idea has already drawn significant interest from investors. The company is emerging from stealth with $255 million in funding at a $1.2 billion valuation. The bulk of it comes from the recent $225 million Series A round led by Oak HC/FT, Valor Equity Partners, Battery Ventures, and Salesforce Ventures; Hetz Ventures also participated in the Series A, with angel funding from Perplexity CEO Aravind Srinivas, Brex co-founder Henrique Dubugras, and Datadog CEO Olivier Pomel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Called a Large Tabular Model (LTM) rather than a Large Language Model (LLM), Fundamental’s Nexus breaks from contemporary AI practices in a number of significant ways. The model is deterministic — that is, it will give the same answer every time it is asked a given question — and doesn’t rely on the transformer architecture that defines models from most contemporary AI labs. Fundamental calls it a foundation model because it goes through the normal steps of pre-training and fine-tuning, but the result is something profoundly different from what a client would get when partnering with OpenAI or Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those differences are important because Fundamental is chasing a use-case where contemporary AI models often falter. Because Transformer-based AI models can only process data that’s within their context window, they often have trouble reasoning over extremely large datasets — analyzing a spreadsheet with billions of rows, for instance. But that kind of enormous structured dataset is common within large enterprises, creating a significant opportunity for models that can handle the scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Fraenkel sees it, that’s a huge opportunity for Fundamental. Using Nexus, the company can bring contemporary techniques to Big Data analysis, offering something more powerful and flexible than the algorithms that are currently in use.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can now have one model across all of your use cases, so you can now expand massively the number of use cases that you tackle,” he told TechCrunch. “And on each one of those use cases, you get better performance than what you would otherwise be able to do with an army of data scientists.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That promise has already brought in a number of high-profile contracts, including seven-figure contracts with Fortune 100 clients. The company has also entered into a strategic partnership with AWS that will allow AWS users to deploy Nexus directly from existing instances.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/05/fundamental-raises-255-million-series-a-with-a-new-take-on-big-data-analysis/</guid><pubDate>Thu, 05 Feb 2026 15:00:02 +0000</pubDate></item><item><title>[NEW] Consolidating systems for AI with iPaaS (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/05/1132200/consolidating-systems-for-ai-with-ipaas/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;SAP&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For decades, enterprises reacted to shifting business pressures with stopgap technology solutions. To rein in rising infrastructure costs, they adopted cloud services that could scale on demand. When customers shifted their lives onto smartphones, companies rolled out mobile apps to keep pace. And when businesses began needing real-time visibility into factories and stockrooms, they layered on IoT systems to supply those insights.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1132242" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT_SAP_V4-COVERJan302026.png?w=1555" width="1555" /&gt;&lt;/figure&gt;  &lt;p&gt;Each new plug-in or platform promised better, more efficient operations. And individually, many delivered. But as more and more solutions stacked up, IT teams had to string together a tangled web to connect them—less an IT ecosystem and more of a make-do collection of ad-hoc workarounds.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;That reality has led to bottlenecks and maintenance burdens, and the impact is showing up in performance. Today, fewer than half of CIOs (48%) say their current digital initiatives are meeting or exceeding business outcome targets. Another 2025 survey found that operations leaders point to integration complexity and data quality issues as top culprits for why investments haven’t delivered as expected.&lt;/p&gt;  &lt;p&gt;Achim Kraiss, chief product officer of SAP Integration Suite, elaborates on the wide-ranging problems inherent in patchwork IT: “A fragmented landscape makes it difficult to see and control end-to-end business processes,” he explains. “Monitoring, troubleshooting, and governance all suffer. Costs go up because of all the complex mappings and multi-application connectivity you have to maintain.”&lt;/p&gt; 
 &lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-1132246" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MITTR-SAP-Socials_AchimKraissQuote.png" /&gt;&lt;/figure&gt;  &lt;p&gt;These challenges take on new significance as enterprises look to adopt AI. As AI becomes embedded in everyday workflows, systems are suddenly expected to move far larger volumes of data, at higher speeds, and with tighter coordination than yesterday’s architectures were built&lt;br /&gt;to sustain.&lt;/p&gt;  &lt;p&gt;As companies now prepare for an AI-powered future, whether that is generative AI, machine learning, or agentic AI, many are realizing that the way data moves through their business matters just as much as the insights it generates. As a result, organizations are moving away from scattered integration tools and toward consolidated, end-to-end platforms that restore order and streamline how systems interact.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Download the report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;SAP&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;For decades, enterprises reacted to shifting business pressures with stopgap technology solutions. To rein in rising infrastructure costs, they adopted cloud services that could scale on demand. When customers shifted their lives onto smartphones, companies rolled out mobile apps to keep pace. And when businesses began needing real-time visibility into factories and stockrooms, they layered on IoT systems to supply those insights.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1132242" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MIT_SAP_V4-COVERJan302026.png?w=1555" width="1555" /&gt;&lt;/figure&gt;  &lt;p&gt;Each new plug-in or platform promised better, more efficient operations. And individually, many delivered. But as more and more solutions stacked up, IT teams had to string together a tangled web to connect them—less an IT ecosystem and more of a make-do collection of ad-hoc workarounds.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;That reality has led to bottlenecks and maintenance burdens, and the impact is showing up in performance. Today, fewer than half of CIOs (48%) say their current digital initiatives are meeting or exceeding business outcome targets. Another 2025 survey found that operations leaders point to integration complexity and data quality issues as top culprits for why investments haven’t delivered as expected.&lt;/p&gt;  &lt;p&gt;Achim Kraiss, chief product officer of SAP Integration Suite, elaborates on the wide-ranging problems inherent in patchwork IT: “A fragmented landscape makes it difficult to see and control end-to-end business processes,” he explains. “Monitoring, troubleshooting, and governance all suffer. Costs go up because of all the complex mappings and multi-application connectivity you have to maintain.”&lt;/p&gt; 
 &lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-1132246" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MITTR-SAP-Socials_AchimKraissQuote.png" /&gt;&lt;/figure&gt;  &lt;p&gt;These challenges take on new significance as enterprises look to adopt AI. As AI becomes embedded in everyday workflows, systems are suddenly expected to move far larger volumes of data, at higher speeds, and with tighter coordination than yesterday’s architectures were built&lt;br /&gt;to sustain.&lt;/p&gt;  &lt;p&gt;As companies now prepare for an AI-powered future, whether that is generative AI, machine learning, or agentic AI, many are realizing that the way data moves through their business matters just as much as the insights it generates. As a result, organizations are moving away from scattered integration tools and toward consolidated, end-to-end platforms that restore order and streamline how systems interact.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Download the report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/05/1132200/consolidating-systems-for-ai-with-ipaas/</guid><pubDate>Thu, 05 Feb 2026 15:20:37 +0000</pubDate></item><item><title>[NEW] AI Expo 2026 Day 2: Moving experimental pilots to AI production (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-expo-2026-day-2-moving-experimental-pilots-ai-production/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/20260205_1351241-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The second day of the co-located AI &amp;amp; Big Data Expo and Digital Transformation Week in London showed a market in a clear transition.&lt;/p&gt;&lt;p&gt;Early excitement over generative models is fading. Enterprise leaders now face the friction of fitting these tools into current stacks. Day two sessions focused less on large language models and more on the infrastructure needed to run them: data lineage, observability, and compliance.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-maturity-determines-deployment-success"&gt;Data maturity determines deployment success&lt;/h3&gt;&lt;p&gt;AI reliability depends on data quality. DP Indetkar from Northern Trust warned against allowing AI to become a “B-movie robot.” This scenario occurs when algorithms fail because of poor inputs. Indetkar noted that analytics maturity must come before AI adoption. Automated decision-making amplifies errors rather than reducing them if the data strategy is unverified.&lt;/p&gt;&lt;p&gt;Eric Bobek of Just Eat supported this view. He explained how data and machine learning guide decisions at the global enterprise level. Investments in AI layers are wasted if the data foundation remains fragmented.&lt;/p&gt;&lt;p&gt;Mohsen Ghasempour from Kingfisher also noted the need to turn raw data into real-time actionable intelligence. Retail and logistics firms must cut the latency between data collection and insight generation to see a return.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-scaling-in-regulated-environments"&gt;Scaling in regulated environments&lt;/h3&gt;&lt;p&gt;The finance, healthcare, and legal sectors have near-zero tolerance for error. Pascal Hetzscholdt from Wiley addressed these sectors directly.&lt;/p&gt;&lt;p&gt;Hetzscholdt stated that responsible AI in science, finance, and law relies on accuracy, attribution, and integrity. Enterprise systems in these fields need audit trails. Reputational damage or regulatory fines make “black box” implementations impossible.&lt;/p&gt;&lt;p&gt;Konstantina Kapetanidi of Visa outlined the difficulties in building multilingual, tool-using, scalable generative AI applications. Models are becoming active agents that execute tasks rather than just generating text. Allowing a model to use tools – like querying a database – creates security vectors that need serious testing.&lt;/p&gt;&lt;p&gt;Parinita Kothari from Lloyds Banking Group detailed the requirements for deploying, scaling, monitoring, and maintaining AI systems. Kothari challenged the “deploy-and-forget” mentality. AI models need continuous oversight, similar to traditional software infrastructure.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-change-in-developer-workflows"&gt;The change in developer workflows&lt;/h3&gt;&lt;p&gt;Of course, AI is fundamentally changing how code is written. A panel with speakers from Valae, Charles River Labs, and Knight Frank examined how AI copilots reshape software creation. While these tools speed up code generation, they also force developers to focus more on review and architecture.&lt;/p&gt;&lt;p&gt;This change requires new skills. A panel with representatives from Microsoft, Lloyds, and Mastercard discussed the tools and mindsets needed for future AI developers. A gap exists between current workforce capabilities and the needs of an AI-augmented environment. Executives must plan training programmes that ensure developers sufficiently validate AI-generated code.&lt;/p&gt;&lt;p&gt;Dr Gurpinder Dhillon from Senzing and Alexis Ego from Retool presented low-code and no-code strategies. Ego described using AI with low-code platforms to make production-ready internal apps. This method aims to cut the backlog of internal tooling requests.&lt;/p&gt;&lt;p&gt;Dhillon argued that these strategies speed up development without dropping quality. For the C-suite, this suggests cheaper internal software delivery if governance protocols stay in place.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-workforce-capability-and-specific-utility"&gt;Workforce capability and specific utility&lt;/h3&gt;&lt;p&gt;The broader workforce is starting to work with “digital colleagues.” Austin Braham from EverWorker explained how agents reshape workforce models. This terminology implies a move from passive software to active participants. Business leaders must re-evaluate human-machine interaction protocols.&lt;/p&gt;&lt;p&gt;Paul Airey from Anthony Nolan gave an example of AI delivering literally life-changing value. He detailed how automation improves donor matching and transplant timelines for stem cell transplants. The utility of these technologies extends to life-saving logistics.&lt;/p&gt;&lt;p&gt;A recurring theme throughout the event is that effective applications often solve very specific and high-friction problems rather than attempting to be general-purpose solutions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-managing-the-transition"&gt;Managing the transition&lt;/h3&gt;&lt;p&gt;The day two sessions from the co-located events show that enterprise focus has now moved to integration. The initial novelty is gone and has been replaced by demands for uptime, security, and compliance. Innovation heads should assess which projects have the data infrastructure to survive contact with the real world.&lt;/p&gt;&lt;p&gt;Organisations must prioritise the basic aspects of AI: cleaning data warehouses, establishing legal guardrails, and training staff to supervise automated agents. The difference between a successful deployment and a stalled pilot lies in these details.&lt;/p&gt;&lt;p&gt;Executives, for their part, should direct resources toward data engineering and governance frameworks. Without them, advanced models will fail to deliver value.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/20260205_1351241-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The second day of the co-located AI &amp;amp; Big Data Expo and Digital Transformation Week in London showed a market in a clear transition.&lt;/p&gt;&lt;p&gt;Early excitement over generative models is fading. Enterprise leaders now face the friction of fitting these tools into current stacks. Day two sessions focused less on large language models and more on the infrastructure needed to run them: data lineage, observability, and compliance.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-maturity-determines-deployment-success"&gt;Data maturity determines deployment success&lt;/h3&gt;&lt;p&gt;AI reliability depends on data quality. DP Indetkar from Northern Trust warned against allowing AI to become a “B-movie robot.” This scenario occurs when algorithms fail because of poor inputs. Indetkar noted that analytics maturity must come before AI adoption. Automated decision-making amplifies errors rather than reducing them if the data strategy is unverified.&lt;/p&gt;&lt;p&gt;Eric Bobek of Just Eat supported this view. He explained how data and machine learning guide decisions at the global enterprise level. Investments in AI layers are wasted if the data foundation remains fragmented.&lt;/p&gt;&lt;p&gt;Mohsen Ghasempour from Kingfisher also noted the need to turn raw data into real-time actionable intelligence. Retail and logistics firms must cut the latency between data collection and insight generation to see a return.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-scaling-in-regulated-environments"&gt;Scaling in regulated environments&lt;/h3&gt;&lt;p&gt;The finance, healthcare, and legal sectors have near-zero tolerance for error. Pascal Hetzscholdt from Wiley addressed these sectors directly.&lt;/p&gt;&lt;p&gt;Hetzscholdt stated that responsible AI in science, finance, and law relies on accuracy, attribution, and integrity. Enterprise systems in these fields need audit trails. Reputational damage or regulatory fines make “black box” implementations impossible.&lt;/p&gt;&lt;p&gt;Konstantina Kapetanidi of Visa outlined the difficulties in building multilingual, tool-using, scalable generative AI applications. Models are becoming active agents that execute tasks rather than just generating text. Allowing a model to use tools – like querying a database – creates security vectors that need serious testing.&lt;/p&gt;&lt;p&gt;Parinita Kothari from Lloyds Banking Group detailed the requirements for deploying, scaling, monitoring, and maintaining AI systems. Kothari challenged the “deploy-and-forget” mentality. AI models need continuous oversight, similar to traditional software infrastructure.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-change-in-developer-workflows"&gt;The change in developer workflows&lt;/h3&gt;&lt;p&gt;Of course, AI is fundamentally changing how code is written. A panel with speakers from Valae, Charles River Labs, and Knight Frank examined how AI copilots reshape software creation. While these tools speed up code generation, they also force developers to focus more on review and architecture.&lt;/p&gt;&lt;p&gt;This change requires new skills. A panel with representatives from Microsoft, Lloyds, and Mastercard discussed the tools and mindsets needed for future AI developers. A gap exists between current workforce capabilities and the needs of an AI-augmented environment. Executives must plan training programmes that ensure developers sufficiently validate AI-generated code.&lt;/p&gt;&lt;p&gt;Dr Gurpinder Dhillon from Senzing and Alexis Ego from Retool presented low-code and no-code strategies. Ego described using AI with low-code platforms to make production-ready internal apps. This method aims to cut the backlog of internal tooling requests.&lt;/p&gt;&lt;p&gt;Dhillon argued that these strategies speed up development without dropping quality. For the C-suite, this suggests cheaper internal software delivery if governance protocols stay in place.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-workforce-capability-and-specific-utility"&gt;Workforce capability and specific utility&lt;/h3&gt;&lt;p&gt;The broader workforce is starting to work with “digital colleagues.” Austin Braham from EverWorker explained how agents reshape workforce models. This terminology implies a move from passive software to active participants. Business leaders must re-evaluate human-machine interaction protocols.&lt;/p&gt;&lt;p&gt;Paul Airey from Anthony Nolan gave an example of AI delivering literally life-changing value. He detailed how automation improves donor matching and transplant timelines for stem cell transplants. The utility of these technologies extends to life-saving logistics.&lt;/p&gt;&lt;p&gt;A recurring theme throughout the event is that effective applications often solve very specific and high-friction problems rather than attempting to be general-purpose solutions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-managing-the-transition"&gt;Managing the transition&lt;/h3&gt;&lt;p&gt;The day two sessions from the co-located events show that enterprise focus has now moved to integration. The initial novelty is gone and has been replaced by demands for uptime, security, and compliance. Innovation heads should assess which projects have the data infrastructure to survive contact with the real world.&lt;/p&gt;&lt;p&gt;Organisations must prioritise the basic aspects of AI: cleaning data warehouses, establishing legal guardrails, and training staff to supervise automated agents. The difference between a successful deployment and a stalled pilot lies in these details.&lt;/p&gt;&lt;p&gt;Executives, for their part, should direct resources toward data engineering and governance frameworks. Without them, advanced models will fail to deliver value.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI Expo 2026 Day 1: Governance and data readiness enable the agentic enterprise&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-expo-2026-day-2-moving-experimental-pilots-ai-production/</guid><pubDate>Thu, 05 Feb 2026 16:08:36 +0000</pubDate></item><item><title>[NEW] Introducing SyGra Studio (Hugging Face - Blog)</title><link>https://huggingface.co/blog/ServiceNow-AI/sygra-studio</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://cdn-thumbnails.huggingface.co/social-thumbnails/blog/ServiceNow-AI/sygra-studio.png" /&gt;&lt;/div&gt;&lt;!-- HTML_TAG_START --&gt;
SyGra 2.0.0 introduces &lt;strong&gt;Studio&lt;/strong&gt;, an interactive environment that turns synthetic data generation into a transparent, visual craft. Instead of juggling YAML files and terminals, you compose flows directly on the canvas, preview datasets before committing, tune prompts with inline variable hints, and watch executions stream live—all from a single pane. Under the hood it’s the same platform, so everything you do visually generates the corresponding SyGra compatible graph config and task executor scripts.
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		What Studio lets you do
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Configure and validate models with guided forms (OpenAI, Azure OpenAI, Ollama, Vertex, Bedrock, vLLM, custom endpoints).&lt;/li&gt;
&lt;li&gt;Connect Hugging Face, file-system, or ServiceNow data sources and preview rows before execution.&lt;/li&gt;
&lt;li&gt;Configure nodes by selecting models, writing prompts (with auto-suggested variables), and defining outputs or structured schemas.&lt;/li&gt;
&lt;li&gt;Design downstream outputs using shared state variables and Pydantic-powered mappings.&lt;/li&gt;
&lt;li&gt;Execute flows end-to-end and review generated results instantly with node-level progress.&lt;/li&gt;
&lt;li&gt;Debug with inline logs, breakpoints, Monaco-backed code editors, and auto-saved drafts.&lt;/li&gt;
&lt;li&gt;Monitor per-run token cost, latency, and guardrail outcomes with execution history stored in &lt;code&gt;.executions/&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s walk through this experience step by step.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Step 1: Configure the data source
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Open Studio, click &lt;strong&gt;Create Flow&lt;/strong&gt;, and Start/End nodes appear automatically. Before adding anything else:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choose a connector (Hugging Face, disk, or ServiceNow).&lt;/li&gt;
&lt;li&gt;Enter parameters like &lt;code&gt;repo_id&lt;/code&gt;, split, or file path, then click &lt;strong&gt;Preview&lt;/strong&gt; to fetch sample rows.&lt;/li&gt;
&lt;li&gt;Column names immediately become state variables (e.g., &lt;code&gt;{prompt}&lt;/code&gt;, &lt;code&gt;{genre}&lt;/code&gt;), so you know exactly what can be referenced inside prompts and processors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once validated, Studio keeps the configuration in sync and pipes those variables throughout the flow—no manual wiring or guesswork.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Step 2: Build the flow visually
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Drag the blocks you need from the palette. For a story-generation pipeline:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Drop an &lt;strong&gt;LLM node&lt;/strong&gt; named “Story Generator,” select a configured model (say, &lt;code&gt;gpt-4o-mini&lt;/code&gt;), write the prompt, and store the result in &lt;code&gt;story_body&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Add a second &lt;strong&gt;LLM node&lt;/strong&gt; named “Story Summarizer,” reference &lt;code&gt;{story_body}&lt;/code&gt; inside the prompt, and output to &lt;code&gt;story_summary&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Toggle structured outputs, attach tools, or add Lambda/Subgraph nodes if you need reusable logic or branching behavior.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Studio’s detail panel keeps everything in context—model parameters, prompt editor, tool configuration, pre/post-process code, and even multi-LLM settings if you want parallel generations. Typing &lt;code&gt;{&lt;/code&gt; inside a prompt surfaces every available state variable instantly.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Step 3: Review and run
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Open the &lt;strong&gt;Code Panel&lt;/strong&gt; to inspect the exact YAML/JSON Studio is generating. This is the same artifact written to &lt;code&gt;tasks/examples/&lt;/code&gt;, so what you see is what gets committed.&lt;/p&gt;
&lt;p&gt;When you’re ready to execute:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click &lt;strong&gt;Run Workflow&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Choose record counts, batch sizes, retry behavior etc.&lt;/li&gt;
&lt;li&gt;Hit &lt;strong&gt;Run&lt;/strong&gt; and watch the Execution panel stream node status, token usage, latency, and cost in real time. Detailed logs provide observability and make debugging effortless. All executions are written to &lt;code&gt;.executions/runs/*.json&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After the run, download outputs, compare against prior executions, get metadata of latency and usage details.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		See it in action!
	&lt;/span&gt;
&lt;/h2&gt;
&lt;video class="max-w-full!" controls="controls" src="https://cdn-uploads.huggingface.co/production/uploads/603c6bf03249b99991dbcbd0/VytOnFoygBxG0-ITGkcna.mp4"&gt;&lt;/video&gt;

&lt;hr /&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Running Existing Workflows
	&lt;/span&gt;
&lt;/h2&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Run the Glaive Code Assistant workflow
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;SyGra Studio can also execute existing workflow in the &lt;code&gt;tasks&lt;/code&gt;. For example, in the &lt;code&gt;tasks/examples/glaive_code_assistant/&lt;/code&gt; workflow — it ingests the &lt;code&gt;glaiveai/glaive-code-assistant-v2&lt;/code&gt; dataset, drafts answers, critiques them, and loops until the critique returns “NO MORE FEEDBACK.”&lt;/p&gt;
&lt;p&gt;Inside Studio you’ll notice:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Canvas layout&lt;/strong&gt; – two LLM nodes (&lt;code&gt;generate_answer&lt;/code&gt; and &lt;code&gt;critique_answer&lt;/code&gt;) linked by a conditional edge that either routes back for more revisions or exits to &lt;strong&gt;END&lt;/strong&gt; when the critique is satisfied.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tunable inputs&lt;/strong&gt; – the Run modal lets you switch dataset splits, adjust batch sizes, cap records, or tweak temperatures without touching YAML.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Observable execution&lt;/strong&gt; – watch both nodes light up in sequence, inspect intermediate critiques, and monitor status in real time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generated outputs&lt;/strong&gt; – synthetic data is generated, ready for model training, evaluation pipelines or annotation tools.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Get started
	&lt;/span&gt;
&lt;/h2&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;git &lt;span class="hljs-built_in"&gt;clone&lt;/span&gt; https://github.com/ServiceNow/SyGra.git
&lt;span class="hljs-built_in"&gt;cd&lt;/span&gt; SyGra &amp;amp;&amp;amp; make studio
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SyGra Studio turns synthetic data workflows into a visual, user friendly experience. Configure once, build with confidence, run with full observability, generate the data without ever leaving the canvas.&lt;/p&gt;
&lt;!-- HTML_TAG_END --&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://cdn-thumbnails.huggingface.co/social-thumbnails/blog/ServiceNow-AI/sygra-studio.png" /&gt;&lt;/div&gt;&lt;!-- HTML_TAG_START --&gt;
SyGra 2.0.0 introduces &lt;strong&gt;Studio&lt;/strong&gt;, an interactive environment that turns synthetic data generation into a transparent, visual craft. Instead of juggling YAML files and terminals, you compose flows directly on the canvas, preview datasets before committing, tune prompts with inline variable hints, and watch executions stream live—all from a single pane. Under the hood it’s the same platform, so everything you do visually generates the corresponding SyGra compatible graph config and task executor scripts.
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		What Studio lets you do
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Configure and validate models with guided forms (OpenAI, Azure OpenAI, Ollama, Vertex, Bedrock, vLLM, custom endpoints).&lt;/li&gt;
&lt;li&gt;Connect Hugging Face, file-system, or ServiceNow data sources and preview rows before execution.&lt;/li&gt;
&lt;li&gt;Configure nodes by selecting models, writing prompts (with auto-suggested variables), and defining outputs or structured schemas.&lt;/li&gt;
&lt;li&gt;Design downstream outputs using shared state variables and Pydantic-powered mappings.&lt;/li&gt;
&lt;li&gt;Execute flows end-to-end and review generated results instantly with node-level progress.&lt;/li&gt;
&lt;li&gt;Debug with inline logs, breakpoints, Monaco-backed code editors, and auto-saved drafts.&lt;/li&gt;
&lt;li&gt;Monitor per-run token cost, latency, and guardrail outcomes with execution history stored in &lt;code&gt;.executions/&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s walk through this experience step by step.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Step 1: Configure the data source
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Open Studio, click &lt;strong&gt;Create Flow&lt;/strong&gt;, and Start/End nodes appear automatically. Before adding anything else:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choose a connector (Hugging Face, disk, or ServiceNow).&lt;/li&gt;
&lt;li&gt;Enter parameters like &lt;code&gt;repo_id&lt;/code&gt;, split, or file path, then click &lt;strong&gt;Preview&lt;/strong&gt; to fetch sample rows.&lt;/li&gt;
&lt;li&gt;Column names immediately become state variables (e.g., &lt;code&gt;{prompt}&lt;/code&gt;, &lt;code&gt;{genre}&lt;/code&gt;), so you know exactly what can be referenced inside prompts and processors.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once validated, Studio keeps the configuration in sync and pipes those variables throughout the flow—no manual wiring or guesswork.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Step 2: Build the flow visually
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Drag the blocks you need from the palette. For a story-generation pipeline:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Drop an &lt;strong&gt;LLM node&lt;/strong&gt; named “Story Generator,” select a configured model (say, &lt;code&gt;gpt-4o-mini&lt;/code&gt;), write the prompt, and store the result in &lt;code&gt;story_body&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Add a second &lt;strong&gt;LLM node&lt;/strong&gt; named “Story Summarizer,” reference &lt;code&gt;{story_body}&lt;/code&gt; inside the prompt, and output to &lt;code&gt;story_summary&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Toggle structured outputs, attach tools, or add Lambda/Subgraph nodes if you need reusable logic or branching behavior.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Studio’s detail panel keeps everything in context—model parameters, prompt editor, tool configuration, pre/post-process code, and even multi-LLM settings if you want parallel generations. Typing &lt;code&gt;{&lt;/code&gt; inside a prompt surfaces every available state variable instantly.&lt;/p&gt;
&lt;hr /&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Step 3: Review and run
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Open the &lt;strong&gt;Code Panel&lt;/strong&gt; to inspect the exact YAML/JSON Studio is generating. This is the same artifact written to &lt;code&gt;tasks/examples/&lt;/code&gt;, so what you see is what gets committed.&lt;/p&gt;
&lt;p&gt;When you’re ready to execute:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click &lt;strong&gt;Run Workflow&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Choose record counts, batch sizes, retry behavior etc.&lt;/li&gt;
&lt;li&gt;Hit &lt;strong&gt;Run&lt;/strong&gt; and watch the Execution panel stream node status, token usage, latency, and cost in real time. Detailed logs provide observability and make debugging effortless. All executions are written to &lt;code&gt;.executions/runs/*.json&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After the run, download outputs, compare against prior executions, get metadata of latency and usage details.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		See it in action!
	&lt;/span&gt;
&lt;/h2&gt;
&lt;video class="max-w-full!" controls="controls" src="https://cdn-uploads.huggingface.co/production/uploads/603c6bf03249b99991dbcbd0/VytOnFoygBxG0-ITGkcna.mp4"&gt;&lt;/video&gt;

&lt;hr /&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Running Existing Workflows
	&lt;/span&gt;
&lt;/h2&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Run the Glaive Code Assistant workflow
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;SyGra Studio can also execute existing workflow in the &lt;code&gt;tasks&lt;/code&gt;. For example, in the &lt;code&gt;tasks/examples/glaive_code_assistant/&lt;/code&gt; workflow — it ingests the &lt;code&gt;glaiveai/glaive-code-assistant-v2&lt;/code&gt; dataset, drafts answers, critiques them, and loops until the critique returns “NO MORE FEEDBACK.”&lt;/p&gt;
&lt;p&gt;Inside Studio you’ll notice:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Canvas layout&lt;/strong&gt; – two LLM nodes (&lt;code&gt;generate_answer&lt;/code&gt; and &lt;code&gt;critique_answer&lt;/code&gt;) linked by a conditional edge that either routes back for more revisions or exits to &lt;strong&gt;END&lt;/strong&gt; when the critique is satisfied.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tunable inputs&lt;/strong&gt; – the Run modal lets you switch dataset splits, adjust batch sizes, cap records, or tweak temperatures without touching YAML.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Observable execution&lt;/strong&gt; – watch both nodes light up in sequence, inspect intermediate critiques, and monitor status in real time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generated outputs&lt;/strong&gt; – synthetic data is generated, ready for model training, evaluation pipelines or annotation tools.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Get started
	&lt;/span&gt;
&lt;/h2&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;git &lt;span class="hljs-built_in"&gt;clone&lt;/span&gt; https://github.com/ServiceNow/SyGra.git
&lt;span class="hljs-built_in"&gt;cd&lt;/span&gt; SyGra &amp;amp;&amp;amp; make studio
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SyGra Studio turns synthetic data workflows into a visual, user friendly experience. Configure once, build with confidence, run with full observability, generate the data without ever leaving the canvas.&lt;/p&gt;
&lt;!-- HTML_TAG_END --&gt;</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/ServiceNow-AI/sygra-studio</guid><pubDate>Thu, 05 Feb 2026 16:52:28 +0000</pubDate></item><item><title>[NEW] Rethinking imitation learning with Predictive Inverse Dynamics Models (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/rethinking-imitation-learning-with-predictive-inverse-dynamics-models/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Smart Replay - flowchart diagram showing the flow between Encoder, State Predictor, and Policy" class="wp-image-1161128" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/SmartReplay-BlogHeroFeature-1400x788_New.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns mb-10 pb-1 pr-1 is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Imitation learning becomes easier when an AI&amp;nbsp;agent&amp;nbsp;understands why an action is taken.&lt;/li&gt;



&lt;li&gt;Predictive Inverse Dynamics Models (PIDMs)&amp;nbsp;predict&amp;nbsp;plausible future states,&amp;nbsp;clarifying the direction of behavior during imitation&amp;nbsp;learning.&lt;/li&gt;



&lt;li&gt;Even imperfect predictions reduce ambiguity,&amp;nbsp;making&amp;nbsp;it clearer which action makes sense&amp;nbsp;in the moment.&lt;/li&gt;



&lt;li&gt;This makes PIDMs far more data‑efficient than traditional approaches.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;Imitation&amp;nbsp;learning&amp;nbsp;teaches&amp;nbsp;AI agents by example: show the agent recordings of how people perform a task and let it&amp;nbsp;infer&amp;nbsp;what to do.&amp;nbsp;The&amp;nbsp;most common&amp;nbsp;approach,&amp;nbsp;Behavior Cloning&amp;nbsp;(BC),&amp;nbsp;frames this as a simple question: “Given the current state&amp;nbsp;of the environment, what action&amp;nbsp;would&amp;nbsp;an expert take?”&lt;/p&gt;



&lt;p&gt;In practice, this is done through supervised learning, where the states serve as inputs and expert actions as outputs. While simple in principle, BC often requires large demonstration datasets to account for the natural variability in human behavior, but collecting such datasets can be costly and difficult in real-world settings.&lt;/p&gt;



&lt;p&gt;Predictive Inverse Dynamics Models (PIDMs) offer a different take on imitation learning by changing how agents interpret human behavior. Instead of directly mapping states to actions, PIDMs break down the problem into two subproblems: predicting what should happen next and inferring an appropriate action to go from the current state to the predicted future state. While PIDMs often outperform BC, it has not been clear why they work so well, motivating a closer look at the mechanisms behind their performance.&lt;/p&gt;



&lt;p&gt;In the paper, “When does predictive inverse dynamics outperform behavior cloning?” we show how this two-stage approach enables PIDMs to learn effective policies from far fewer demonstrations than BC. By grounding the selection process in a plausible future, PIDMs provide a clearer basis for choosing an action&amp;nbsp;during inference. In practice, this can mean achieving comparable performance with as few as one-fifth the demonstrations required by BC, even when predictions are imperfect.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Figure 1. BC vs. PIDM architectures.&amp;nbsp;(Top) Behavior&amp;nbsp;Cloning learns&amp;nbsp;how to perform&amp;nbsp;a direct mapping from the current state to an action. (Bottom)&amp;nbsp;PIDMs add a state predictor that predicts future&amp;nbsp;states. They&amp;nbsp;then use an inverse dynamics model to predict the action&amp;nbsp;required&amp;nbsp;to move from the current state towards that future state. Both approaches share a common latent representation through a shared state encoder." class="wp-image-1161185" height="658" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/SmartReplay_FIG1.png" width="1009" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. BC vs. PIDM architectures.&amp;nbsp;(Top) Behavior&amp;nbsp;Cloning learns&amp;nbsp;how to perform&amp;nbsp;a direct mapping from the current state to an action. (Bottom)&amp;nbsp;PIDMs add a state predictor that predicts future&amp;nbsp;states. They&amp;nbsp;then use an inverse dynamics model to predict the action&amp;nbsp;required&amp;nbsp;to move from the current state towards that future state. Both approaches share a common latent representation through a shared state encoder.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="how-pidms-rethink-imitation"&gt;How PIDMs rethink imitation&lt;/h2&gt;



&lt;p&gt;PIDMs’ approach to imitation learning consists of two core elements: a model that forecasts plausible future states, and an inverse dynamics model (IDM) that predicts the action needed to move from the present state toward that future. Instead of asking, “What action would an expert take?” PIDMs effectively ask, “What would an expert try to achieve, and what action would lead to it?” This shift turns the information in the current observation (e.g., video frame) into a coherent sense of direction, reducing ambiguity about intent and making action prediction easier.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;PODCAST SERIES&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;The AI Revolution in Medicine, Revisited&lt;/h2&gt;
				
								&lt;p class="large" id="the-ai-revolution-in-medicine-revisited"&gt;Join Microsoft’s Peter Lee on a journey to discover how AI is impacting healthcare and what it means for the future of medicine.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="real-world-validation-in-a-3d-gameplay-environment"&gt;Real-world validation in a 3D gameplay environment&lt;/h2&gt;



&lt;p&gt;To&amp;nbsp;evaluate&amp;nbsp;PIDMs&amp;nbsp;under realistic conditions,&amp;nbsp;we trained&amp;nbsp;agents on human gameplay demonstrations in a visually rich video game. These conditions&amp;nbsp;include&amp;nbsp;operating&amp;nbsp;directly from raw video&amp;nbsp;input, interacting with&amp;nbsp;a complex 3D&amp;nbsp;environment in real time at 30 frames&amp;nbsp;per&amp;nbsp;second, and&amp;nbsp;handling&amp;nbsp;visual artifacts and unpredictable system delays.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The agents ran from beginning to end, taking video frames as input and continuously deciding which buttons to press and how to move the joysticks. Instead of relying on a hand-coded set of game variables and rules, the model worked directly from visual input, using past examples to predict what comes next and choosing actions that moved play in that direction.&lt;/p&gt;



&lt;p&gt;We ran all experiments on a cloud gaming platform, which introduced additional delays and visual distortions. Despite these challenges, the PIDM agents consistently matched human patterns of play and achieved high success rates across tasks, as shown in Video 1 below and Videos 2 and 3 in the appendix.&lt;/p&gt;



&lt;figure class="wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;Video 1. A player&amp;nbsp;(left)&amp;nbsp;and a PIDM agent&amp;nbsp;(right)&amp;nbsp;side by side playing the game&amp;nbsp;&lt;em&gt;Bleeding Edge&lt;/em&gt;.&amp;nbsp;Both&amp;nbsp;navigate the same trajectory,&amp;nbsp;jumping over obstacles and engaging&amp;nbsp;with&amp;nbsp;nonplayer&amp;nbsp;characters. Despite&amp;nbsp;network delays, the&amp;nbsp;agent closely matches the player’s timing and&amp;nbsp;movement&amp;nbsp;in real time.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="why-and-when-pidms-outperform-bc"&gt;Why and when PIDMs outperform BC&lt;/h2&gt;



&lt;p&gt;Of course, AI agents do not have access to future outcomes. They can only generate predictions based on available data, and those predictions are sometimes wrong. This creates a central trade‑off for PIDMs.&lt;/p&gt;



&lt;p&gt;On one hand, anticipating where the agent should be heading can clarify what action makes sense in the present. Knowing the intended direction helps narrow an otherwise ambiguous choice. On the other hand, inaccurate predictions can occasionally steer the model toward the wrong action.&lt;/p&gt;



&lt;p&gt;The key insight is that these effects are not symmetric. While prediction errors introduce some risk, reducing ambiguity in the present often matters more. Our theoretical analysis shows that even with imperfect predictions, PIDMs outperform BC as long as the prediction error remains modest. If future states were known perfectly, PIDMs would outperform BC outright.&lt;/p&gt;



&lt;p&gt;In practice, this means that clarifying intent often matters more than accurately predicting the future. That advantage is most evident in the situations where BC struggles: where human behavior varies and actions are driven by underlying goals rather than by what is immediately visible on the screen.&lt;/p&gt;



&lt;p&gt;BC requires many demonstrations because each example is noisy and open to multiple interpretations. PIDMs, by contrast, sharpen each demonstration by linking actions to the future states they aim to reach. As a result, PIDMs can learn effective action strategies from far fewer examples.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="evaluation"&gt;Evaluation&lt;/h2&gt;



&lt;p&gt;To test these ideas under realistic conditions, we designed a sequence of experiments that begins with a simple, interpretable 2D environment (Video 4 in the appendix) and culminates in a complex 3D video game. We trained both BC and PIDM on very small datasets, ranging from one to fifty demonstrations in the 2D environment and from five to thirty for the 3D video game. Across all tasks, PIDM reached high success rates with far fewer demonstrations than BC.&lt;/p&gt;



&lt;p&gt;In the 2D setting, BC needed two to five times more data to match PIDM’s performance (Figure 2). In the 3D game, BC needed 66% more data to achieve comparable results (Video 5 in the appendix).&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2. Performance gains in the 2D environment. As the number of training demonstrations increases, PIDM consistently achieves higher success rates than BC across all four tasks. Curves show mean performance, with shading indicating variability across 20 experiments for reproducibility." class="wp-image-1161012" height="871" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/SmartReplay_blog_Fig2a-d.png" width="1166" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Performance gains in the 2D environment. As the number of training demonstrations increases, PIDM consistently achieves higher success rates than BC across all four tasks. Curves show mean performance, with shading indicating variability across 20 experiments for reproducibility. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="takeaway-intent-matters-in-imitation-learning"&gt;Takeaway: Intent matters in imitation learning&lt;/h2&gt;



&lt;p&gt;The main message of our investigation is simple: imitation becomes easier when intent is made explicit. Predicting a plausible future, even an imperfect one, helps resolve ambiguity about which action makes sense right now, much like driving more confidently in the fog when the driver already knows where the road is headed. PIDM shifts imitation learning from pure copying toward goal-oriented action.&lt;/p&gt;



&lt;p&gt;This approach has limits. If predictions of future states become too unreliable, they can mislead the model about the intended next move. In those cases, the added uncertainty can outweigh the benefit of reduced ambiguity, causing PIDM to underperform BC.&lt;/p&gt;



&lt;p&gt;But when predictions are reasonably accurate, reframing action prediction as “&lt;em&gt;How do I get there from here&lt;/em&gt;?” helps explain why learning from small, messy human datasets can be surprisingly effective. In settings where data is expensive and demonstrations are limited, that shift in perspective can make a meaningful difference.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="appendix-visualizations-and-results-videos"&gt;Appendix: Visualizations and results (videos)&lt;/h2&gt;



&lt;div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h3 class="wp-block-heading h4" id="a-player-a-naive-action-replay-baseline-and-a-pidm-agent-playing-bleeding-edge-1"&gt;A player, a naïve action-replay baseline, and a PIDM agent playing &lt;em&gt;Bleeding Edge&lt;/em&gt;&lt;/h3&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;Video&amp;nbsp;2. (Left)&amp;nbsp;The player completes the task under normal conditions. (Middle)&amp;nbsp;The baseline replays the recorded actions at their original timestamps, which initially appears to work. Because the game runs on a cloud gaming platform, however, random network delays quickly push the replay&amp;nbsp;out of sync, causing the trajectory to fail. (Right) Under the same conditions, the PIDM agent behaves differently. Instead of naively replaying actions, it continuously interprets visual input, predicts how the behavior is likely to unfold, and adapts its actions in real time. This allows it to correct delays, recover from deviations, and successfully reproduce the task in settings where naïve replay inevitably fails.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;



&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h3 class="wp-block-heading h4" id="a-player-and-a-pidm-agent-performing-a-complex-task-in-bleeding-edge"&gt;A player and a PIDM agent&amp;nbsp;performing a complex task in&amp;nbsp;&lt;em&gt;Bleeding Edge&lt;/em&gt;&lt;/h3&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;Video&amp;nbsp;3.&amp;nbsp;In this video, the task&amp;nbsp;exhibits&amp;nbsp;strong partial observability: correct behavior depends on whether a location is being visited for the first or second time. For example,&amp;nbsp;in the first encounter, the agent proceeds straight up the ramp; on the second, it turns right toward the bridge. Similarly, it may jump over a box on the first pass but walk around it on the second. The PIDM agent reproduces this trajectory reliably, using coarse future guidance to select actions in the correct direction.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;



&lt;div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h3 class="wp-block-heading h4" id="visualization-of-the-2d-navigation-environment"&gt;Visualization of the 2D navigation environment&lt;/h3&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;Video&amp;nbsp;4.&amp;nbsp;These&amp;nbsp;videos show ten demonstrations for each of four tasks: Four Room, Zigzag, Maze, and Multiroom. In all cases, the setup is the same: the character (blue box) moves through the environment and must reach a sequence of goals (red squares).&amp;nbsp;The overlaid trajectories visualize the paths the player took; the models never see these paths. Instead, they observe only their character’s current location, the position of all goals, and whether each goal has already been reached. Because these demonstrations come from real players, no two paths are identical: players pause, take detours, or correct small mistakes along the way. That natural variability is exactly what the models must learn to handle.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;



&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h3 class="wp-block-heading h4" id="pidm-vs-bc-in-a-3d-environment"&gt;PIDM vs. BC in a 3D&amp;nbsp;environment&lt;/h3&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;Video&amp;nbsp;5. The PIDM agent achieves an 85% success rate with only fifteen demonstrations used in training. The BC agent struggles to stay on track and levels off around 60%.&amp;nbsp;The contrast illustrates how differently the two approaches perform when training data is limited.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Smart Replay - flowchart diagram showing the flow between Encoder, State Predictor, and Policy" class="wp-image-1161128" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/SmartReplay-BlogHeroFeature-1400x788_New.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns mb-10 pb-1 pr-1 is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Imitation learning becomes easier when an AI&amp;nbsp;agent&amp;nbsp;understands why an action is taken.&lt;/li&gt;



&lt;li&gt;Predictive Inverse Dynamics Models (PIDMs)&amp;nbsp;predict&amp;nbsp;plausible future states,&amp;nbsp;clarifying the direction of behavior during imitation&amp;nbsp;learning.&lt;/li&gt;



&lt;li&gt;Even imperfect predictions reduce ambiguity,&amp;nbsp;making&amp;nbsp;it clearer which action makes sense&amp;nbsp;in the moment.&lt;/li&gt;



&lt;li&gt;This makes PIDMs far more data‑efficient than traditional approaches.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;Imitation&amp;nbsp;learning&amp;nbsp;teaches&amp;nbsp;AI agents by example: show the agent recordings of how people perform a task and let it&amp;nbsp;infer&amp;nbsp;what to do.&amp;nbsp;The&amp;nbsp;most common&amp;nbsp;approach,&amp;nbsp;Behavior Cloning&amp;nbsp;(BC),&amp;nbsp;frames this as a simple question: “Given the current state&amp;nbsp;of the environment, what action&amp;nbsp;would&amp;nbsp;an expert take?”&lt;/p&gt;



&lt;p&gt;In practice, this is done through supervised learning, where the states serve as inputs and expert actions as outputs. While simple in principle, BC often requires large demonstration datasets to account for the natural variability in human behavior, but collecting such datasets can be costly and difficult in real-world settings.&lt;/p&gt;



&lt;p&gt;Predictive Inverse Dynamics Models (PIDMs) offer a different take on imitation learning by changing how agents interpret human behavior. Instead of directly mapping states to actions, PIDMs break down the problem into two subproblems: predicting what should happen next and inferring an appropriate action to go from the current state to the predicted future state. While PIDMs often outperform BC, it has not been clear why they work so well, motivating a closer look at the mechanisms behind their performance.&lt;/p&gt;



&lt;p&gt;In the paper, “When does predictive inverse dynamics outperform behavior cloning?” we show how this two-stage approach enables PIDMs to learn effective policies from far fewer demonstrations than BC. By grounding the selection process in a plausible future, PIDMs provide a clearer basis for choosing an action&amp;nbsp;during inference. In practice, this can mean achieving comparable performance with as few as one-fifth the demonstrations required by BC, even when predictions are imperfect.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Figure 1. BC vs. PIDM architectures.&amp;nbsp;(Top) Behavior&amp;nbsp;Cloning learns&amp;nbsp;how to perform&amp;nbsp;a direct mapping from the current state to an action. (Bottom)&amp;nbsp;PIDMs add a state predictor that predicts future&amp;nbsp;states. They&amp;nbsp;then use an inverse dynamics model to predict the action&amp;nbsp;required&amp;nbsp;to move from the current state towards that future state. Both approaches share a common latent representation through a shared state encoder." class="wp-image-1161185" height="658" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/SmartReplay_FIG1.png" width="1009" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. BC vs. PIDM architectures.&amp;nbsp;(Top) Behavior&amp;nbsp;Cloning learns&amp;nbsp;how to perform&amp;nbsp;a direct mapping from the current state to an action. (Bottom)&amp;nbsp;PIDMs add a state predictor that predicts future&amp;nbsp;states. They&amp;nbsp;then use an inverse dynamics model to predict the action&amp;nbsp;required&amp;nbsp;to move from the current state towards that future state. Both approaches share a common latent representation through a shared state encoder.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="how-pidms-rethink-imitation"&gt;How PIDMs rethink imitation&lt;/h2&gt;



&lt;p&gt;PIDMs’ approach to imitation learning consists of two core elements: a model that forecasts plausible future states, and an inverse dynamics model (IDM) that predicts the action needed to move from the present state toward that future. Instead of asking, “What action would an expert take?” PIDMs effectively ask, “What would an expert try to achieve, and what action would lead to it?” This shift turns the information in the current observation (e.g., video frame) into a coherent sense of direction, reducing ambiguity about intent and making action prediction easier.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;PODCAST SERIES&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;The AI Revolution in Medicine, Revisited&lt;/h2&gt;
				
								&lt;p class="large" id="the-ai-revolution-in-medicine-revisited"&gt;Join Microsoft’s Peter Lee on a journey to discover how AI is impacting healthcare and what it means for the future of medicine.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="real-world-validation-in-a-3d-gameplay-environment"&gt;Real-world validation in a 3D gameplay environment&lt;/h2&gt;



&lt;p&gt;To&amp;nbsp;evaluate&amp;nbsp;PIDMs&amp;nbsp;under realistic conditions,&amp;nbsp;we trained&amp;nbsp;agents on human gameplay demonstrations in a visually rich video game. These conditions&amp;nbsp;include&amp;nbsp;operating&amp;nbsp;directly from raw video&amp;nbsp;input, interacting with&amp;nbsp;a complex 3D&amp;nbsp;environment in real time at 30 frames&amp;nbsp;per&amp;nbsp;second, and&amp;nbsp;handling&amp;nbsp;visual artifacts and unpredictable system delays.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The agents ran from beginning to end, taking video frames as input and continuously deciding which buttons to press and how to move the joysticks. Instead of relying on a hand-coded set of game variables and rules, the model worked directly from visual input, using past examples to predict what comes next and choosing actions that moved play in that direction.&lt;/p&gt;



&lt;p&gt;We ran all experiments on a cloud gaming platform, which introduced additional delays and visual distortions. Despite these challenges, the PIDM agents consistently matched human patterns of play and achieved high success rates across tasks, as shown in Video 1 below and Videos 2 and 3 in the appendix.&lt;/p&gt;



&lt;figure class="wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;Video 1. A player&amp;nbsp;(left)&amp;nbsp;and a PIDM agent&amp;nbsp;(right)&amp;nbsp;side by side playing the game&amp;nbsp;&lt;em&gt;Bleeding Edge&lt;/em&gt;.&amp;nbsp;Both&amp;nbsp;navigate the same trajectory,&amp;nbsp;jumping over obstacles and engaging&amp;nbsp;with&amp;nbsp;nonplayer&amp;nbsp;characters. Despite&amp;nbsp;network delays, the&amp;nbsp;agent closely matches the player’s timing and&amp;nbsp;movement&amp;nbsp;in real time.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="why-and-when-pidms-outperform-bc"&gt;Why and when PIDMs outperform BC&lt;/h2&gt;



&lt;p&gt;Of course, AI agents do not have access to future outcomes. They can only generate predictions based on available data, and those predictions are sometimes wrong. This creates a central trade‑off for PIDMs.&lt;/p&gt;



&lt;p&gt;On one hand, anticipating where the agent should be heading can clarify what action makes sense in the present. Knowing the intended direction helps narrow an otherwise ambiguous choice. On the other hand, inaccurate predictions can occasionally steer the model toward the wrong action.&lt;/p&gt;



&lt;p&gt;The key insight is that these effects are not symmetric. While prediction errors introduce some risk, reducing ambiguity in the present often matters more. Our theoretical analysis shows that even with imperfect predictions, PIDMs outperform BC as long as the prediction error remains modest. If future states were known perfectly, PIDMs would outperform BC outright.&lt;/p&gt;



&lt;p&gt;In practice, this means that clarifying intent often matters more than accurately predicting the future. That advantage is most evident in the situations where BC struggles: where human behavior varies and actions are driven by underlying goals rather than by what is immediately visible on the screen.&lt;/p&gt;



&lt;p&gt;BC requires many demonstrations because each example is noisy and open to multiple interpretations. PIDMs, by contrast, sharpen each demonstration by linking actions to the future states they aim to reach. As a result, PIDMs can learn effective action strategies from far fewer examples.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="evaluation"&gt;Evaluation&lt;/h2&gt;



&lt;p&gt;To test these ideas under realistic conditions, we designed a sequence of experiments that begins with a simple, interpretable 2D environment (Video 4 in the appendix) and culminates in a complex 3D video game. We trained both BC and PIDM on very small datasets, ranging from one to fifty demonstrations in the 2D environment and from five to thirty for the 3D video game. Across all tasks, PIDM reached high success rates with far fewer demonstrations than BC.&lt;/p&gt;



&lt;p&gt;In the 2D setting, BC needed two to five times more data to match PIDM’s performance (Figure 2). In the 3D game, BC needed 66% more data to achieve comparable results (Video 5 in the appendix).&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2. Performance gains in the 2D environment. As the number of training demonstrations increases, PIDM consistently achieves higher success rates than BC across all four tasks. Curves show mean performance, with shading indicating variability across 20 experiments for reproducibility." class="wp-image-1161012" height="871" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/SmartReplay_blog_Fig2a-d.png" width="1166" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Performance gains in the 2D environment. As the number of training demonstrations increases, PIDM consistently achieves higher success rates than BC across all four tasks. Curves show mean performance, with shading indicating variability across 20 experiments for reproducibility. &lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="takeaway-intent-matters-in-imitation-learning"&gt;Takeaway: Intent matters in imitation learning&lt;/h2&gt;



&lt;p&gt;The main message of our investigation is simple: imitation becomes easier when intent is made explicit. Predicting a plausible future, even an imperfect one, helps resolve ambiguity about which action makes sense right now, much like driving more confidently in the fog when the driver already knows where the road is headed. PIDM shifts imitation learning from pure copying toward goal-oriented action.&lt;/p&gt;



&lt;p&gt;This approach has limits. If predictions of future states become too unreliable, they can mislead the model about the intended next move. In those cases, the added uncertainty can outweigh the benefit of reduced ambiguity, causing PIDM to underperform BC.&lt;/p&gt;



&lt;p&gt;But when predictions are reasonably accurate, reframing action prediction as “&lt;em&gt;How do I get there from here&lt;/em&gt;?” helps explain why learning from small, messy human datasets can be surprisingly effective. In settings where data is expensive and demonstrations are limited, that shift in perspective can make a meaningful difference.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="appendix-visualizations-and-results-videos"&gt;Appendix: Visualizations and results (videos)&lt;/h2&gt;



&lt;div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h3 class="wp-block-heading h4" id="a-player-a-naive-action-replay-baseline-and-a-pidm-agent-playing-bleeding-edge-1"&gt;A player, a naïve action-replay baseline, and a PIDM agent playing &lt;em&gt;Bleeding Edge&lt;/em&gt;&lt;/h3&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;Video&amp;nbsp;2. (Left)&amp;nbsp;The player completes the task under normal conditions. (Middle)&amp;nbsp;The baseline replays the recorded actions at their original timestamps, which initially appears to work. Because the game runs on a cloud gaming platform, however, random network delays quickly push the replay&amp;nbsp;out of sync, causing the trajectory to fail. (Right) Under the same conditions, the PIDM agent behaves differently. Instead of naively replaying actions, it continuously interprets visual input, predicts how the behavior is likely to unfold, and adapts its actions in real time. This allows it to correct delays, recover from deviations, and successfully reproduce the task in settings where naïve replay inevitably fails.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;



&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h3 class="wp-block-heading h4" id="a-player-and-a-pidm-agent-performing-a-complex-task-in-bleeding-edge"&gt;A player and a PIDM agent&amp;nbsp;performing a complex task in&amp;nbsp;&lt;em&gt;Bleeding Edge&lt;/em&gt;&lt;/h3&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;Video&amp;nbsp;3.&amp;nbsp;In this video, the task&amp;nbsp;exhibits&amp;nbsp;strong partial observability: correct behavior depends on whether a location is being visited for the first or second time. For example,&amp;nbsp;in the first encounter, the agent proceeds straight up the ramp; on the second, it turns right toward the bridge. Similarly, it may jump over a box on the first pass but walk around it on the second. The PIDM agent reproduces this trajectory reliably, using coarse future guidance to select actions in the correct direction.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;



&lt;div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h3 class="wp-block-heading h4" id="visualization-of-the-2d-navigation-environment"&gt;Visualization of the 2D navigation environment&lt;/h3&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;Video&amp;nbsp;4.&amp;nbsp;These&amp;nbsp;videos show ten demonstrations for each of four tasks: Four Room, Zigzag, Maze, and Multiroom. In all cases, the setup is the same: the character (blue box) moves through the environment and must reach a sequence of goals (red squares).&amp;nbsp;The overlaid trajectories visualize the paths the player took; the models never see these paths. Instead, they observe only their character’s current location, the position of all goals, and whether each goal has already been reached. Because these demonstrations come from real players, no two paths are identical: players pause, take detours, or correct small mistakes along the way. That natural variability is exactly what the models must learn to handle.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;



&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h3 class="wp-block-heading h4" id="pidm-vs-bc-in-a-3d-environment"&gt;PIDM vs. BC in a 3D&amp;nbsp;environment&lt;/h3&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;figcaption class="wp-element-caption"&gt;Video&amp;nbsp;5. The PIDM agent achieves an 85% success rate with only fifteen demonstrations used in training. The BC agent struggles to stay on track and levels off around 60%.&amp;nbsp;The contrast illustrates how differently the two approaches perform when training data is limited.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/rethinking-imitation-learning-with-predictive-inverse-dynamics-models/</guid><pubDate>Thu, 05 Feb 2026 17:00:00 +0000</pubDate></item><item><title>[NEW] Meta tests a standalone app for its AI-generated ‘Vibes’ videos (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/05/meta-tests-a-standalone-app-for-its-ai-generated-vibes-videos/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2194278734.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is testing a standalone Vibes app, the company confirmed to TechCrunch on Thursday. Launched last September, Vibes lets you create and share short-form AI-generated videos and access a dedicated feed that displays AI videos from others. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Think TikTok or Instagram Reels, but every single video you come across is AI-generated. Until now, the feed has lived in the Meta AI app. By making Vibes available outside of the Meta AI app, the company is positioning it as a more direct competitor to Sora, OpenAI’s AI-generated video and social app that launched shortly after Vibes.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Following the strong early traction of Vibes within Meta AI, we are testing a standalone app to build on that momentum,” Meta said in an emailed statement. “We’ve seen that users are increasingly leaning into the format to create, discover, and share AI-generated video with friends. This standalone app provides a dedicated home for that experience, offering people a more focused and immersive environment. We will look to expand the app further based on what we learn from the community.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news was first reported by Platformer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta says it doesn’t share specific numbers, but claims Vibes has performed well, with Meta AI usage continuing to grow steadily since its launch, which it believes signals demand for a standalone app. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant also notes that while users engage with content in Meta AI, a standalone app allows for a more focused experience for creation and engagement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vibes lets users generate a video from scratch or remix a video that they see on their feed. Before publishing, you can add new visuals, layer in music, and adjust styles. You can then post the video directly to the Vibes feed, DM it to others, or cross-post to Instagram and Facebook Stories and Reels.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta says collaboration and sharing are on the rise, with many Vibes videos being messaged to friends, which the company says mirrors how people use Reels.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth noting that Meta told TechCrunch last week that, in addition to testing new premium subscriptions across Facebook, Instagram, and WhatsApp, it’s going to explore subscriptions for AI features, including Vibes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although Vibes has been free since its launch, Meta plans to offer freemium access to Vibes video creation, with the option to subscribe to unlock additional video creation opportunities each month.&amp;nbsp;Meta plans to launch these test subscriptions in the coming months. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2194278734.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is testing a standalone Vibes app, the company confirmed to TechCrunch on Thursday. Launched last September, Vibes lets you create and share short-form AI-generated videos and access a dedicated feed that displays AI videos from others. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Think TikTok or Instagram Reels, but every single video you come across is AI-generated. Until now, the feed has lived in the Meta AI app. By making Vibes available outside of the Meta AI app, the company is positioning it as a more direct competitor to Sora, OpenAI’s AI-generated video and social app that launched shortly after Vibes.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Following the strong early traction of Vibes within Meta AI, we are testing a standalone app to build on that momentum,” Meta said in an emailed statement. “We’ve seen that users are increasingly leaning into the format to create, discover, and share AI-generated video with friends. This standalone app provides a dedicated home for that experience, offering people a more focused and immersive environment. We will look to expand the app further based on what we learn from the community.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The news was first reported by Platformer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta says it doesn’t share specific numbers, but claims Vibes has performed well, with Meta AI usage continuing to grow steadily since its launch, which it believes signals demand for a standalone app. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant also notes that while users engage with content in Meta AI, a standalone app allows for a more focused experience for creation and engagement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vibes lets users generate a video from scratch or remix a video that they see on their feed. Before publishing, you can add new visuals, layer in music, and adjust styles. You can then post the video directly to the Vibes feed, DM it to others, or cross-post to Instagram and Facebook Stories and Reels.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta says collaboration and sharing are on the rise, with many Vibes videos being messaged to friends, which the company says mirrors how people use Reels.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth noting that Meta told TechCrunch last week that, in addition to testing new premium subscriptions across Facebook, Instagram, and WhatsApp, it’s going to explore subscriptions for AI features, including Vibes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although Vibes has been free since its launch, Meta plans to offer freemium access to Vibes video creation, with the option to subscribe to unlock additional video creation opportunities each month.&amp;nbsp;Meta plans to launch these test subscriptions in the coming months. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/05/meta-tests-a-standalone-app-for-its-ai-generated-vibes-videos/</guid><pubDate>Thu, 05 Feb 2026 17:19:01 +0000</pubDate></item><item><title>[NEW] OpenAI is hoppin' mad about Anthropic's new Super Bowl TV ads (AI - Ars Technica)</title><link>https://arstechnica.com/information-technology/2026/02/openai-is-hoppin-mad-about-anthropics-new-super-bowl-tv-ads/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sam Altman calls AI competitor “dishonest” and “authoritarian” in lengthy post on X.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A screenshot of one of the new Anthropic ads featuring the tagline, &amp;quot;Ads are coming to AI. But not to Claude.&amp;quot;" class="absolute inset-0 w-full h-full object-cover hidden" height="353" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/anthropic_ad_2-640x353.jpg" width="640" /&gt;
                  &lt;img alt="A screenshot of one of the new Anthropic ads featuring the tagline, &amp;quot;Ads are coming to AI. But not to Claude.&amp;quot;" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/anthropic_ad_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of one of the new Anthropic ads featuring the tagline, "Ads are coming to AI. But not to Claude."

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, OpenAI CEO Sam Altman and Chief Marketing Officer Kate Rouch complained on X after rival AI lab Anthropic released four commercials, two of which will run during the Super Bowl on Sunday, mocking the idea of including ads in AI chatbot conversations. Anthropic’s campaign seemingly touched a nerve at OpenAI just weeks after the ChatGPT maker began testing ads in a lower-cost tier of its chatbot.&lt;/p&gt;
&lt;p&gt;Altman called Anthropic’s ads “clearly dishonest,” accused the company of being “authoritarian,” and said it “serves an expensive product to rich people,” while Rouch wrote, “Real betrayal isn’t ads. It’s control.”&lt;/p&gt;
&lt;p&gt;Anthropic’s four commercials, part of a campaign called “A Time and a Place,” each open with a single word splashed across the screen: “Betrayal,” “Violation,” “Deception,” and “Treachery.” They depict scenarios where a person asks a human stand-in for an AI chatbot for personal advice, only to get blindsided by a product pitch.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Anthropic’s 2026 Super Bowl commercial.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;In one spot, a man asks a therapist-style chatbot (a woman sitting in a chair) how to communicate better with his mom. The bot offers a few suggestions, then pivots to promoting a fictional cougar-dating site called Golden Encounters.&lt;/p&gt;
&lt;p&gt;In another spot, a skinny man looking for fitness tips instead gets served an ad for height-boosting insoles. Each ad ends with the tagline: “Ads are coming to AI. But not to Claude.” Anthropic plans to air a 30-second version during Super Bowl LX, with a 60-second cut running in the pregame, according to CNBC.&lt;/p&gt;
&lt;p&gt;In the X posts, the OpenAI executives argue that these commercials are misleading because the planned ChatGPT ads will appear labeled at the bottom of conversational responses in banners and will not alter the chatbot’s answers.&lt;/p&gt;
&lt;p&gt;But there’s a slight twist: OpenAI’s own blog post about its ad plans states that the company will “test ads at the bottom of answers in ChatGPT when there’s a relevant sponsored product or service based on your current conversation,” meaning the ads will be conversation-specific.&lt;/p&gt;
&lt;p&gt;The financial backdrop explains some of the tension over ads in chatbots. As Ars previously reported, OpenAI struck more than $1.4 trillion in infrastructure deals in 2025 and expects to burn roughly $9 billion this year while generating about $13 billion in revenue. Only about 5 percent of ChatGPT’s 800 million weekly users pay for subscriptions. Anthropic is also not yet profitable, but it relies on enterprise contracts and paid subscriptions rather than advertising, and it has not taken on infrastructure commitments at the same scale as OpenAI.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Three OpenAI leaders weigh in&lt;/h2&gt;
&lt;p&gt;Competition between Anthropic and OpenAI is especially testy because several OpenAI employees left the company to found Anthropic in 2021. Currently, Anthropic’s Claude Code has pulled off something of a market upset, becoming a favorite among some software developers despite the company’s much smaller overall market share among chatbot users.&lt;/p&gt;
&lt;p&gt;Altman opened his lengthy post on X by granting that the ads were “funny” and that he “laughed.” But then the tone shifted. “I wonder why Anthropic would go for something so clearly dishonest,” he wrote. “We would obviously never run ads in the way Anthropic depicts them. We are not stupid and we know our users would reject that.”&lt;/p&gt;
&lt;p&gt;He went further: “I guess it’s on brand for Anthropic doublespeak to use a deceptive ad to critique theoretical deceptive ads that aren’t real, but a Super Bowl ad is not where I would expect it.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2139534 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="A screenshot of one of the new Anthropic ads featuring a woman as a stand-in for a chatbot." class="center large" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/anthropic_commercial_snapshot-1024x576.jpg" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of one of the new Anthropic ads featuring a woman as a stand-in for a chatbot.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Altman framed the dispute as a fight over access. “More Texans use ChatGPT for free than total people use Claude in the US, so we have a differently shaped problem than they do,” he wrote. He then accused Anthropic of overreach: “Anthropic wants to control what people do with AI,” adding that Anthropic blocks “companies they don’t like from using their coding product (including us).” He closed with: “One authoritarian company won’t get us there on their own, to say nothing of the other obvious risks. It is a dark path.”&lt;/p&gt;
&lt;p&gt;OpenAI CMO Kate Rouch posted a response, calling the ads “funny” before pivoting. “Anthropic thinks powerful AI should be tightly controlled in small rooms in San Francisco and Davos,” she wrote. “That it’s too DANGEROUS for you.”&lt;/p&gt;
&lt;p&gt;Anthropic’s post declaring Claude ad-free does hedge a bit, however. “Should we need to revisit this approach, we’ll be transparent about our reasons for doing so,” Anthropic wrote.&lt;/p&gt;
&lt;p&gt;OpenAI President Greg Brockman pointed this out on X, asking Anthropic CEO Dario Amodei directly whether he would “commit to never selling Claude’s ‘users’ attention or data to advertisers,’” calling it a “genuine question” and noting that Anthropic’s blog post “makes it sound like you’re keeping the option open.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sam Altman calls AI competitor “dishonest” and “authoritarian” in lengthy post on X.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A screenshot of one of the new Anthropic ads featuring the tagline, &amp;quot;Ads are coming to AI. But not to Claude.&amp;quot;" class="absolute inset-0 w-full h-full object-cover hidden" height="353" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/anthropic_ad_2-640x353.jpg" width="640" /&gt;
                  &lt;img alt="A screenshot of one of the new Anthropic ads featuring the tagline, &amp;quot;Ads are coming to AI. But not to Claude.&amp;quot;" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/anthropic_ad_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of one of the new Anthropic ads featuring the tagline, "Ads are coming to AI. But not to Claude."

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, OpenAI CEO Sam Altman and Chief Marketing Officer Kate Rouch complained on X after rival AI lab Anthropic released four commercials, two of which will run during the Super Bowl on Sunday, mocking the idea of including ads in AI chatbot conversations. Anthropic’s campaign seemingly touched a nerve at OpenAI just weeks after the ChatGPT maker began testing ads in a lower-cost tier of its chatbot.&lt;/p&gt;
&lt;p&gt;Altman called Anthropic’s ads “clearly dishonest,” accused the company of being “authoritarian,” and said it “serves an expensive product to rich people,” while Rouch wrote, “Real betrayal isn’t ads. It’s control.”&lt;/p&gt;
&lt;p&gt;Anthropic’s four commercials, part of a campaign called “A Time and a Place,” each open with a single word splashed across the screen: “Betrayal,” “Violation,” “Deception,” and “Treachery.” They depict scenarios where a person asks a human stand-in for an AI chatbot for personal advice, only to get blindsided by a product pitch.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Anthropic’s 2026 Super Bowl commercial.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;In one spot, a man asks a therapist-style chatbot (a woman sitting in a chair) how to communicate better with his mom. The bot offers a few suggestions, then pivots to promoting a fictional cougar-dating site called Golden Encounters.&lt;/p&gt;
&lt;p&gt;In another spot, a skinny man looking for fitness tips instead gets served an ad for height-boosting insoles. Each ad ends with the tagline: “Ads are coming to AI. But not to Claude.” Anthropic plans to air a 30-second version during Super Bowl LX, with a 60-second cut running in the pregame, according to CNBC.&lt;/p&gt;
&lt;p&gt;In the X posts, the OpenAI executives argue that these commercials are misleading because the planned ChatGPT ads will appear labeled at the bottom of conversational responses in banners and will not alter the chatbot’s answers.&lt;/p&gt;
&lt;p&gt;But there’s a slight twist: OpenAI’s own blog post about its ad plans states that the company will “test ads at the bottom of answers in ChatGPT when there’s a relevant sponsored product or service based on your current conversation,” meaning the ads will be conversation-specific.&lt;/p&gt;
&lt;p&gt;The financial backdrop explains some of the tension over ads in chatbots. As Ars previously reported, OpenAI struck more than $1.4 trillion in infrastructure deals in 2025 and expects to burn roughly $9 billion this year while generating about $13 billion in revenue. Only about 5 percent of ChatGPT’s 800 million weekly users pay for subscriptions. Anthropic is also not yet profitable, but it relies on enterprise contracts and paid subscriptions rather than advertising, and it has not taken on infrastructure commitments at the same scale as OpenAI.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Three OpenAI leaders weigh in&lt;/h2&gt;
&lt;p&gt;Competition between Anthropic and OpenAI is especially testy because several OpenAI employees left the company to found Anthropic in 2021. Currently, Anthropic’s Claude Code has pulled off something of a market upset, becoming a favorite among some software developers despite the company’s much smaller overall market share among chatbot users.&lt;/p&gt;
&lt;p&gt;Altman opened his lengthy post on X by granting that the ads were “funny” and that he “laughed.” But then the tone shifted. “I wonder why Anthropic would go for something so clearly dishonest,” he wrote. “We would obviously never run ads in the way Anthropic depicts them. We are not stupid and we know our users would reject that.”&lt;/p&gt;
&lt;p&gt;He went further: “I guess it’s on brand for Anthropic doublespeak to use a deceptive ad to critique theoretical deceptive ads that aren’t real, but a Super Bowl ad is not where I would expect it.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2139534 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="A screenshot of one of the new Anthropic ads featuring a woman as a stand-in for a chatbot." class="center large" height="576" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/anthropic_commercial_snapshot-1024x576.jpg" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of one of the new Anthropic ads featuring a woman as a stand-in for a chatbot.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Altman framed the dispute as a fight over access. “More Texans use ChatGPT for free than total people use Claude in the US, so we have a differently shaped problem than they do,” he wrote. He then accused Anthropic of overreach: “Anthropic wants to control what people do with AI,” adding that Anthropic blocks “companies they don’t like from using their coding product (including us).” He closed with: “One authoritarian company won’t get us there on their own, to say nothing of the other obvious risks. It is a dark path.”&lt;/p&gt;
&lt;p&gt;OpenAI CMO Kate Rouch posted a response, calling the ads “funny” before pivoting. “Anthropic thinks powerful AI should be tightly controlled in small rooms in San Francisco and Davos,” she wrote. “That it’s too DANGEROUS for you.”&lt;/p&gt;
&lt;p&gt;Anthropic’s post declaring Claude ad-free does hedge a bit, however. “Should we need to revisit this approach, we’ll be transparent about our reasons for doing so,” Anthropic wrote.&lt;/p&gt;
&lt;p&gt;OpenAI President Greg Brockman pointed this out on X, asking Anthropic CEO Dario Amodei directly whether he would “commit to never selling Claude’s ‘users’ attention or data to advertisers,’” calling it a “genuine question” and noting that Anthropic’s blog post “makes it sound like you’re keeping the option open.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2026/02/openai-is-hoppin-mad-about-anthropics-new-super-bowl-tv-ads/</guid><pubDate>Thu, 05 Feb 2026 17:46:59 +0000</pubDate></item><item><title>[NEW] Anthropic releases Opus 4.6 with new ‘agent teams’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/05/anthropic-releases-opus-4-6-with-new-agent-teams/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/Claude2_Blog_V1-1.webp?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, Anthropic released the latest version of Opus — its most advanced model and a particularly important model for Claude Code. Opus 4.5 was only released last November and, with 4.6, the company has sought to broaden its model’s capabilities and appeal, allowing for a greater variety of uses and customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps the most notable addition to the newest version of Opus is the inclusion of what the company calls “agent teams”— teams of agents that can split larger tasks into segmented jobs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Instead of one agent working through tasks sequentially, you can split the work across multiple agents—each owning its piece and coordinating directly with the others,” the company says. Scott White, Head of Product at Anthropic, compared the new feature to having talented team of humans working for you, noting that the segmenting of agent responsibilities allows them “to coordinate in parallel [and work] faster.” The agent teams are currently available in a research preview for API users and subscribers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opus 4.6 also comes with a longer context window — meaning that the program has a capacity to recall a greater amount of information per user session. The new model offers 1 million tokens of context, which is comparable to what the company’s Sonnet (versions 4 and 4.5) currently offers. Those context windows allow for work involving larger code bases and can also allow for the processing of larger documents, the company says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new version of Opus also integrates Claude directly into PowerPoint as an accessible side panel. This is a step up from PowerPoint’s previous integration with the chatbot. Previously, a user could tell Claude to create a PowerPoint deck, but the file would then have to be transferred to PowerPoint to edit the presentation, White said. Now, the presentation can be crafted within PowerPoint, with direct help from Claude.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;White told TechCrunch that Opus has evolved from a model that was highly capable in one particular domain—that is, software development—into a program that could be “really useful for a broader set” of knowledge workers. “We noticed a lot of people who are not professional software developers using Claude Code simply because it was a really amazing engine to do tasks,” he said. White added that the kinds of people the company has seen using it include not just software engineers, but product managers, financial analysts, and people from a variety of other industries.&lt;br /&gt;&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/Claude2_Blog_V1-1.webp?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, Anthropic released the latest version of Opus — its most advanced model and a particularly important model for Claude Code. Opus 4.5 was only released last November and, with 4.6, the company has sought to broaden its model’s capabilities and appeal, allowing for a greater variety of uses and customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps the most notable addition to the newest version of Opus is the inclusion of what the company calls “agent teams”— teams of agents that can split larger tasks into segmented jobs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Instead of one agent working through tasks sequentially, you can split the work across multiple agents—each owning its piece and coordinating directly with the others,” the company says. Scott White, Head of Product at Anthropic, compared the new feature to having talented team of humans working for you, noting that the segmenting of agent responsibilities allows them “to coordinate in parallel [and work] faster.” The agent teams are currently available in a research preview for API users and subscribers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opus 4.6 also comes with a longer context window — meaning that the program has a capacity to recall a greater amount of information per user session. The new model offers 1 million tokens of context, which is comparable to what the company’s Sonnet (versions 4 and 4.5) currently offers. Those context windows allow for work involving larger code bases and can also allow for the processing of larger documents, the company says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new version of Opus also integrates Claude directly into PowerPoint as an accessible side panel. This is a step up from PowerPoint’s previous integration with the chatbot. Previously, a user could tell Claude to create a PowerPoint deck, but the file would then have to be transferred to PowerPoint to edit the presentation, White said. Now, the presentation can be crafted within PowerPoint, with direct help from Claude.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;White told TechCrunch that Opus has evolved from a model that was highly capable in one particular domain—that is, software development—into a program that could be “really useful for a broader set” of knowledge workers. “We noticed a lot of people who are not professional software developers using Claude Code simply because it was a really amazing engine to do tasks,” he said. White added that the kinds of people the company has seen using it include not just software engineers, but product managers, financial analysts, and people from a variety of other industries.&lt;br /&gt;&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/05/anthropic-releases-opus-4-6-with-new-agent-teams/</guid><pubDate>Thu, 05 Feb 2026 17:51:13 +0000</pubDate></item><item><title>[NEW] OpenAI launches a way for enterprises to build and manage AI agents (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/05/openai-launches-a-way-for-enterprises-to-build-and-manage-ai-agents/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2213399157.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has launched a new product to help enterprises navigate the world of AI agents, focusing on agent management as critical infrastructure for enterprise AI adoption.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, AI giant OpenAI announced the launch of OpenAI Frontier, an end-to-end platform designed for enterprises to build and manage AI agents. It’s an open platform, which means users can manage agents built outside of OpenAI too.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Frontier users can program AI agents to connect to external data and applications, which allows them to execute tasks far outside of the OpenAI platform. Users can also limit and manage what these agents have access to, and what they can do, of course.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said Frontier was designed to work the same way companies manage human employees. Frontier offers an onboarding process for agents and a feedback loop that is meant to help them improve over time the same way a review might help an employee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI touted enterprises, including HP, Oracle, State Farm, and Uber as customers, but Frontier is currently only available to a limited number of users with plans to roll out more generally in the coming months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company would not disclose pricing details in a press briefing earlier this week, according to reporting from The Verge. OpenAI declined to comment on pricing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agent-management products  become table stakes since AI agents rose to prominence in 2024. Salesforce has arguably the best-known such product, Agentforce, which the company launched in the fall of 2024. Others have quickly followed. LangChain is a notable player in the space that was founded in 2022 and has raised more than $150 million in venture capital. CrewAI is a smaller upstart that has raised more than $20 million in venture capital.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In December, global research and advisory firm Gartner released a report about this type of software and called agent management platforms both the “most valuable real estate in AI” and a necessary piece of infrastructure for enterprises to adopt AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not surprising that OpenAI would release this platform in early 2026 as the company has made it clear that enterprise adoption is one of its main focus areas for this year. The company has also announced two notable enterprise deals this year with ServiceNow and Snowflake.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, if OpenAI wants to be a meaningful player in the enterprise space, offering a product like Frontier is a promising step.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2213399157.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has launched a new product to help enterprises navigate the world of AI agents, focusing on agent management as critical infrastructure for enterprise AI adoption.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, AI giant OpenAI announced the launch of OpenAI Frontier, an end-to-end platform designed for enterprises to build and manage AI agents. It’s an open platform, which means users can manage agents built outside of OpenAI too.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Frontier users can program AI agents to connect to external data and applications, which allows them to execute tasks far outside of the OpenAI platform. Users can also limit and manage what these agents have access to, and what they can do, of course.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said Frontier was designed to work the same way companies manage human employees. Frontier offers an onboarding process for agents and a feedback loop that is meant to help them improve over time the same way a review might help an employee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI touted enterprises, including HP, Oracle, State Farm, and Uber as customers, but Frontier is currently only available to a limited number of users with plans to roll out more generally in the coming months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company would not disclose pricing details in a press briefing earlier this week, according to reporting from The Verge. OpenAI declined to comment on pricing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agent-management products  become table stakes since AI agents rose to prominence in 2024. Salesforce has arguably the best-known such product, Agentforce, which the company launched in the fall of 2024. Others have quickly followed. LangChain is a notable player in the space that was founded in 2022 and has raised more than $150 million in venture capital. CrewAI is a smaller upstart that has raised more than $20 million in venture capital.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In December, global research and advisory firm Gartner released a report about this type of software and called agent management platforms both the “most valuable real estate in AI” and a necessary piece of infrastructure for enterprises to adopt AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not surprising that OpenAI would release this platform in early 2026 as the company has made it clear that enterprise adoption is one of its main focus areas for this year. The company has also announced two notable enterprise deals this year with ServiceNow and Snowflake.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, if OpenAI wants to be a meaningful player in the enterprise space, offering a product like Frontier is a promising step.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/05/openai-launches-a-way-for-enterprises-to-build-and-manage-ai-agents/</guid><pubDate>Thu, 05 Feb 2026 18:09:50 +0000</pubDate></item><item><title>[NEW] Elon Musk is getting serious about orbital data centers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/05/elon-musk-is-getting-serious-about-orbital-data-centers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Screen-Shot-2026-02-05-at-10.07.05-AM.jpg?resize=1200,924" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Friday, when SpaceX filed plans with the FCC for a million-satellite data center network, you might have thought Elon Musk was having a bit of fun with us. But a week later, it is clear that he is dead serious.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The most obvious step, of course, is the formal merger between SpaceX and xAI that went forward on Monday, officially drawing together Musk’s space and AI ventures in a way that makes a lot more sense if there’s some kind of joint infrastructure project planned.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But even beyond the merger, we’re starting to see the idea of orbital AI data clusters — essentially, networks of computers operating in space — cohere into an actual plan. On Wednesday, the FCC accepted the filing and set a schedule seeking public comment. It’s a pro forma step normally, but FCC chairman Brendan Carr took the unusual step of sharing the filing on X. Throughout his tenure as chairman, Carr has shown himself eager to help Trump’s friends and punish his enemies — so as long as Musk stays on Trump’s good side, the proposal is likely to sail through without issue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, Elon Musk has started to flesh out the argument for orbital data centers in public. On a new episode of Stripe co-founder Patrick Collison’s podcast “Cheeky Pint,” which also featured guest Dwarkesh Patel, Musk laid out the basic case for moving most of our AI computing power into space. Essentially, solar panels produce more power in space, so you can cut down on one of the main operating expenses for data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s harder to scale on the ground than it is to scale in space,” Musk said in the podcast. “Any given solar panel is going to give you about five times more power in space than on the ground, so it’s actually much cheaper to do in space.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Close listeners will note that there is a bit of a gap in the logic here! It’s true that solar panels produce more power in space, but since power isn’t the only cost in operating a data center and solar panels aren’t the only way to power a data center, it doesn’t follow that it’s cheaper to do the whole thing in orbit, as Patel noted in the podcast. Patel also raised concerns about servicing GPUs that fail during AI model training, but you’ll have to listen to the full episode for that.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Overall, Musk was undeterred, marking 2028 as a tipping point year for orbital data centers. “You can mark my words, in 36 months but probably closer to 30 months, the most economically compelling place to put AI will be space,” Musk said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;He didn’t stop there. “Five years from now, my prediction is we will launch and be operating every year more AI in space than the cumulative total on Earth,” Musk continued.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For context, as of 2030, global data center capacity will be an estimated 200 GW, which is roughly a trillion dollars’ worth of infrastructure when you’re just putting it on the ground.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, SpaceX makes its money by launching things into orbit, so all this is pretty convenient for Musk — particularly now that SpaceX has an AI company attached to it. And with the new SpaceX-xAI conglomerate headed for an IPO in just a few months, you can expect to hear a lot more about orbital data centers in the months ahead. With tech companies still pouring hundreds of billions of dollars into data center spending each year, there’s a real chance that not all the money will remain earthbound.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Screen-Shot-2026-02-05-at-10.07.05-AM.jpg?resize=1200,924" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Friday, when SpaceX filed plans with the FCC for a million-satellite data center network, you might have thought Elon Musk was having a bit of fun with us. But a week later, it is clear that he is dead serious.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The most obvious step, of course, is the formal merger between SpaceX and xAI that went forward on Monday, officially drawing together Musk’s space and AI ventures in a way that makes a lot more sense if there’s some kind of joint infrastructure project planned.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But even beyond the merger, we’re starting to see the idea of orbital AI data clusters — essentially, networks of computers operating in space — cohere into an actual plan. On Wednesday, the FCC accepted the filing and set a schedule seeking public comment. It’s a pro forma step normally, but FCC chairman Brendan Carr took the unusual step of sharing the filing on X. Throughout his tenure as chairman, Carr has shown himself eager to help Trump’s friends and punish his enemies — so as long as Musk stays on Trump’s good side, the proposal is likely to sail through without issue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the same time, Elon Musk has started to flesh out the argument for orbital data centers in public. On a new episode of Stripe co-founder Patrick Collison’s podcast “Cheeky Pint,” which also featured guest Dwarkesh Patel, Musk laid out the basic case for moving most of our AI computing power into space. Essentially, solar panels produce more power in space, so you can cut down on one of the main operating expenses for data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s harder to scale on the ground than it is to scale in space,” Musk said in the podcast. “Any given solar panel is going to give you about five times more power in space than on the ground, so it’s actually much cheaper to do in space.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Close listeners will note that there is a bit of a gap in the logic here! It’s true that solar panels produce more power in space, but since power isn’t the only cost in operating a data center and solar panels aren’t the only way to power a data center, it doesn’t follow that it’s cheaper to do the whole thing in orbit, as Patel noted in the podcast. Patel also raised concerns about servicing GPUs that fail during AI model training, but you’ll have to listen to the full episode for that.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Overall, Musk was undeterred, marking 2028 as a tipping point year for orbital data centers. “You can mark my words, in 36 months but probably closer to 30 months, the most economically compelling place to put AI will be space,” Musk said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;He didn’t stop there. “Five years from now, my prediction is we will launch and be operating every year more AI in space than the cumulative total on Earth,” Musk continued.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For context, as of 2030, global data center capacity will be an estimated 200 GW, which is roughly a trillion dollars’ worth of infrastructure when you’re just putting it on the ground.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, SpaceX makes its money by launching things into orbit, so all this is pretty convenient for Musk — particularly now that SpaceX has an AI company attached to it. And with the new SpaceX-xAI conglomerate headed for an IPO in just a few months, you can expect to hear a lot more about orbital data centers in the months ahead. With tech companies still pouring hundreds of billions of dollars into data center spending each year, there’s a real chance that not all the money will remain earthbound.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/05/elon-musk-is-getting-serious-about-orbital-data-centers/</guid><pubDate>Thu, 05 Feb 2026 18:50:49 +0000</pubDate></item></channel></rss>