<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 18 Feb 2026 18:59:01 +0000</lastBuildDate><item><title>Welcome to the dark side of crypto’s permissionless dream (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/18/1132587/jean-paul-thorbjornsen-dark-side-crypto-permissionless-dream/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;“We’re out of airspace now. We can do whatever we want,” Jean-Paul Thorbjornsen tells me from the pilot’s seat of his Aston Martin helicopter. As we fly over suburbs outside Melbourne, Australia, it’s becoming clear that doing whatever he wants is Thorbjornsen’s MO.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Upper-middle-class homes give way to vineyards, and Thorbjornsen points out our landing spot outside a winery. People visiting for lunch walk outside. “They’re going to ask for a shot now,” he says, used to the attention drawn by his luxury helicopter, emblazoned with the tail letters “BTC” for bitcoin (the price tag of $5 million in Australian dollars—$3.5 million in US dollars today—was perhaps reasonable for someone who claims a previous crypto project made more than AU$400 million, although he also says those funds were tied up in the company).&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Thorbjornsen is a founder of THORChain, a blockchain through which users can swap one cryptocurrency for another and earn fees from making those swaps. THORChain is permissionless, so anyone can use it without getting prior approval from a centralized authority. As a decentralized network, the blockchain is built and run by operators located across the globe, most of whom use pseudonyms.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;During its early days, Thorbjornsen himself hid behind the pseudonym “leena” and used an AI-generated female image as his avatar. But around March 2024, he revealed that he, an Australian man in his mid-30s, with a rural Catholic upbringing, was the mind behind the blockchain. More or less.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;If there is a central question around THORChain, it is this: Exactly who is responsible for its operations? Blockchains as decentralized as THORChain are supposed to offer systems that operate outside the centralized leadership of corruptible governments and financial institutions. If a few people have outsize sway over this decentralized network—one of a handful that operate at such a large scale—it’s one more blemish on the legacy of bitcoin’s promise, which has already been tarnished by capitalistic political frenzy.&amp;nbsp; &amp;nbsp;&lt;/p&gt;  &lt;p&gt;Who’s responsible for THORChain matters because in January last year, its users lost more than $200 million worth of their cryptocurrency in US dollars after THORChain transactions and accounts were frozen by a singular admin override, which users believed was not supposed to be possible given the decentralized structure. When the freeze was lifted, some users raced to pull their money out. The following month, a team of North Korean hackers known as the Lazarus Group used THORChain to move roughly $1.2 billion of stolen ethereum taken in the infamous hack of the Dubai-based crypto exchange Bybit.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Thorbjornsen explains away THORChain’s inability to stop the movement of stolen funds, or prevent a bank run, as a function of its decentralized and permissionless nature. The lack of executive powers means that anyone can use the network for any reason, and arguably there’s no one to hold accountable when even the worst goes down.&lt;/p&gt;  &lt;p&gt;But when the worst did go down, nearly everyone in the THORChain community, and those paying attention to it in channels like X, pointed their fingers at Thorbjornsen. A lawsuit filed by the THORChain creditors who lost millions in January 2025 names him. A former FBI analyst and North Korea specialist, reflecting on the potential repercussions for helping move stolen funds, told me he wouldn’t want to be in Thorbjornsen’s shoes.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;THORChain was designed to make decisions based on votes by node operators, where two-thirds majority rules.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;That’s why I traveled to Australia—to see if I could get a handle on where he sees himself and his role in relation to the network he says he founded.&lt;/p&gt;  &lt;p&gt;According to Thorbjornsen, he should not be held responsible for either event. THORChain was designed to make decisions based on votes by node operators—people with the computer power, and crypto stake, to run a cluster of servers that process the network’s transactions. In those votes, a two-thirds majority rules.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Then there’s the permissionless part. &lt;em&gt;Anyone&lt;/em&gt; can use THORChain to make swaps, which is why it’s been a popular way for widely sanctioned entities such as the government of North Korea to move stolen money. This principle goes back to the cypherpunk roots of bitcoin, a currency that operates outside of nation-states’ rules. THORChain is designed to avoid geopolitical entanglements; that’s what its users like about it.&lt;/p&gt;  &lt;p&gt;But there are distinct financial motivations for moving crypto, stolen or not: Node operators earn fees from the funds running through the network. In theory, this incentivizes them to act in the network’s best interests—and, arguably, Thorbjornsen’s interests too, as many assume his wealth is tied to the network’s profits. (Thorbjornsen says it is not, and that it comes instead from “many sources,” including “buying bitcoin back in 2013.”)&lt;/p&gt;  &lt;p&gt;Now recent events have raised critical questions, not just about Thorbjornsen’s outsize role in THORChain’s operations, but also about the blockchain’s underlying nature.&lt;/p&gt;  &lt;p&gt;If THORChain is decentralized, how was a single operator able to freeze its funds a month before the Bybit hack? Could someone have unilaterally decided to stop the stolen Bybit funds from coming through the network, and chosen not to?&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Thorbjornsen insists THORChain is helping realize bitcoin’s original purpose of enabling anyone to transact freely outside the reach of purportedly corrupt governments. Yet the network’s problems suggest that an alternative financial system might not be much better.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Decentralized?&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;On February 21, 2025, Bybit CEO Ben Zhou got an alarming call from the company’s chief financial officer. About $1.5 billion US of the exchange’s ethereum token, ETH, had been stolen.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The FBI attributed the theft to the Lazarus Group. Typically, criminals will want to convert ETH to bitcoin, which is much easier to convert in turn to cash. Knowing this, the FBI issued a public service announcement on February 26 to “exchanges, bridges … and other virtual asset service providers,” encouraging them to block transactions from accounts related to the hack.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Someone posted that announcement in THORChain’s private, invite-only developer channel on Discord, a chat app used widely by software engineers and gamers. While other crypto exchanges and bridges (which facilitate transactions across different blockchains) heeded the warning, THORChain’s node operators, developers, and invested insiders debated about whether or not to close the trading gates, a decision requiring a majority vote.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;“Civil war is a very strong term, but there was a strong rift in the community,” says Boone Wheeler, a US-based crypto enthusiast. In 2021, Wheeler purchased some rune, THORChain’s Norse-mythology-themed native token, and he has been paid to write articles about the network to help advertise it. The rift formed “between people who wanted to stay permissionless,” he says, “and others who wanted to blacklist the funds.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;Wheeler, who says he doesn’t run a node or code for THORChain, fell on the side of remaining permissionless. However, others spoke up for blocking the transfers. THORChain, they argued, wasn’t decentralized enough to keep those running the network safe from law enforcement—especially when those operators were identifiable by their IP addresses, some based in the US.&lt;/p&gt;  &lt;p&gt;“We are not the morality police,” someone with the username @Swing_Pop wrote on February 27 in the developer Discord.&lt;/p&gt;  &lt;p&gt;THORChain’s design includes up to 120 nodes whose operators manage transactions on the network through a voting process. Anyone with hosting hardware can become an operator by funding nodes with rune as collateral, which provides the network with liquidity. Nodes can respond to a transaction by validating it or doing nothing. While individual transactions can’t be blocked, trading can be halted by a two-thirds majority vote.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="contentList__wrap content-right"&gt;&lt;h2 class="contentList__header" id="2851-val-contentList"&gt;A team of North Korean hackers used THORChain to move roughly $1.2 billion of ethereum stolen from the crypto exchange Bybit.&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;Nodes are also penalized for not participating in voting, which the system labels as “bad behavior.” Every 2.5 days, THORChain automatically “churns” nodes out to ensure that no one node gains too much control. The nodes that chose not to validate transactions from the Bybit hack were automatically “churned” out of the system. Thorbjornsen says about 20 or 30 nodes were booted from the network in this way. (Node operators can run multiple nodes, and 120 are rarely running simultaneously; at the time of writing, 55 unique IDs operated 103 nodes.)&lt;/p&gt;  &lt;p&gt;By February 27, some node operators were prepared to leave the network altogether. “It’s personally getting beyond my risk tolerance,” wrote @Runetard in the dev Discord. “Sorry to those of the community that feel otherwise. There are a bunch of us holding all the risk and some are getting ready to walk away.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="contentList__wrap content-right"&gt;&lt;h2 class="contentList__header" id="2852-val-contentList"&gt;According to one estimate, THORChain earned between $5 million and $10 million from the heist.&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;Even so, the financial incentive for the network operators who remained was significant. As one member of the dev Discord put it earlier that day, $3 million had been “extracted as commission” from the theft by those operating THORChain. “This is wrong!” they wrote.&lt;/p&gt;  &lt;p&gt;Thorbjornsen weighed in on this back-and-forth, during which nodes paused and unpaused the network. He now says there was a right and wrong way for node operators to have behaved. “The correct way of doing things,” he says, was for node operators who opposed processing stolen funds to “go offline and … get [themselves] kicked out” rather than try to police who could use THORChain. He also says that while operators could discuss stopping transactions, “there was simply no design in the code that allowed [them] to do that.” However, a since-deleted post from his personal X account on March 3, 2025, stated: “I pushed for all my nodes to unhalt trading [keep trading]. Threatened to yank bond if they didn’t comply. Every single one.” (Thorbjornsen says his social media team ran this account in 2025.)&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;In an Australian 7 News Spotlight documentary last June, Thorbjornsen estimated that THORChain earned between $5 million and $10 million from the heist.&lt;/p&gt;  &lt;p&gt;When asked in that same documentary if he received any of those fees, he replied, “Not directly.” When we spoke, I asked him to elaborate. He said he’s “not a recipient” of any funds THORChain sets aside for developers or marketers, nor does he operate any nodes. He was merely speaking generally, he told me: “All crypto holders profit indirectly off economic activity on any chain.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a character in a hooded sweatshirt at a computer station" class="wp-image-1132689" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Crypto-2-c.jpg?w=1536" width="1536" /&gt;&lt;div class="image-credit"&gt;KAGAN MCLEOD&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Most important to Thorbjornsen was that, despite “huge pressure to shut the protocol down and stop servicing these swaps,” THORChain chugged along. He also notes that the hackers’ tactics, moving fast and splitting funds across multiple addresses, made it difficult to identify “bad swaps.”&lt;/p&gt;  &lt;p&gt;Blockchain experts like Nick Carlsen, a former FBI analyst at the blockchain intelligence company TRM Labs, don’t buy this assessment. Other services similar to THORChain were identifying and rejecting these transactions. Had THORChain done the same, Carlsen adds, the stolen funds could have been contained on the Ethereum network, which “would have basically denied North Korea the ability to kick off this laundering process.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;And while THORChain touts its decentralization, in “practical applications” like the Lazarus Group’s theft, “most de-fi [decentralized finance] protocols are centralized,” says Daren Firestone, an attorney who represents crypto industry whistleblowers, citing a 2023 US Treasury Department risk assessment on illicit finance.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;With centralization comes culpability, and in these cases, Firestone adds, that comes down to “who profits from [the protocol], so who creates it? But most importantly, who controls it?” Is there someone who can “hit an emergency off switch? … Direct nodes?”&lt;/p&gt;  &lt;p&gt;Many answer these questions with Thorbjornsen’s name. “Everyone likes to pass the blame,” he says, even though he wasn’t alone in building THORChain. “​​In the end, it all comes back to me anyway.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;THORChain origins&lt;/h3&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;According to Thorbjornsen, his story goes like this.&lt;/p&gt;    &lt;p&gt;The third of 10 homeschooled children in a “traditional” Catholic household in rural Australia, he spent his days learning math, reading, writing, and studying the Bible. As he got older, he was also responsible for instructing his younger siblings. Wednesday was his day to move the solar panels that powered their home. His parents “installed” a mango and citrus orchard, more to keep nine boys busy than to reap the produce, he says.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;“We lived close to a local airfield,” Thorbjornsen says, “and I was always mesmerized by these planes.” He joined the Australian air force and studied engineering, but he says the military left him feeling like “a square peg in a round hole.” He adds that doing things his own way got him frequently “pulled aside” by superiors.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;“That’s when I started looking elsewhere,” he says, and in 2013, he found bitcoin. It appealed because it existed “outside the system.”&lt;/p&gt;  &lt;p&gt;During the 2017 crypto bull run, Thorbjornsen raised AU$12 million in an initial coin offering for CanYa, a decentralized marketplace he cofounded. CanYa ultimately “died” in 2018, and Thorbjornsen pivoted to a “decentralized liquidity” project that would become THORChain.&lt;/p&gt;  &lt;p&gt;He worked with a couple of different developer teams, and then, in 2019, he clicked with an American developer, Chad Barraford, at a hackathon in Germany. Barraford (who declined to be interviewed for this story) was an early public face of THORChain.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Around this time, Thorbjornsen says, “a couple of us helped manage the payroll and early investment funds.” In a 2020 interview, Kai Ansaari, identified as a THORChain “project lead,” wrote, “We’re all contributors … There’s no real ‘lead,’ ‘CEO,’ ‘founder,’ etc.”&lt;/p&gt;  &lt;p&gt;In interviews conducted since he came out from behind the “leena” account in 2024, Thorbjornsen has positioned himself as a key lead. He now says his plan had always been to hand over the account, along with command powers and control of THORChain social media accounts, once the blockchain had matured enough to realize its promise of decentralization.&lt;/p&gt;  &lt;p&gt;In 2021, he says, he started this process, first by ceasing to use his own rune to back node operators who didn’t have enough to supply their own funding (this can be a way to influence node votes without operating a node yourself). That year, the protocol suffered multiple hacks that resulted in millions of dollars in losses. Nine Realms, a US-incorporated coding company, was brought on to take over THORChain’s development. Thorbjornsen says he passed “leena” over to “other community members” and “left crypto” in 2021, selling “a bunch of bitcoin” and buying the helicopter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Despite this crypto departure, he came back onto the scene with gusto in 2024 when he revealed himself as the operator of the “leena” account. “​​For many years, I stayed private because I didn’t want the attention,” he says now.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By early 2024 Thorbjornsen considered the network to be sufficiently decentralized and began advertising it publicly. He started regularly posting videos on his TikTok and YouTube channels (“Two sick videos every week,” in the words of one caption) that showed him piloting his helicopter wearing shirts that read “Thor.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_19"&gt; &lt;p&gt;By November 2024, Thorbjornsen, who describes himself as “a bit flamboyant,” was calling himself THORChain’s CEO (“chief energy officer”) and the “master of the memes” in a video from Binance Blockchain Week, an industry conference in Dubai. You need “strong memetic energy,” he says in the video, “to create the community, to create the cult.” Cults imply centralized leadership, and since outing himself as “leena,” Thorbjornsen has publicly appeared to helm the project, with one interviewer deeming him the “THORChain Satoshi” (an allusion to the pseudonymous creator of bitcoin).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One consequence of going public as a face of the protocol: He’s received death threats. “I stirred it up. Do I regret it? Who knows?” he said when we met in Australia. “It’s caused a lot of chaos.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But, he added, “this is the bed that I’ve laid.” When we spoke again, months later, he backtracked, saying he “got sucked into” defending THORChain in 2024 and 2025 because he was involved from 2018 to 2021 and has “a perspective on how the protocol operates.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Centralized?&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Ryan Treat, a retired US Army veteran, woke up one morning in January 2025 to some disturbing activity on X. “My heart sank,” he says. THORFi, the THORChain program he’d used to earn interest on the bitcoin he’d planned to save for his retirement, had frozen all accounts—but that didn’t make sense.&lt;/p&gt;  &lt;p&gt;THORFi featured a lending and saving program said to give users “complete control” and self-custody of their crypto, meaning they could withdraw it at any time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Treat was no crypto amateur. He bought his first bitcoin at around “$5 apiece,” he says, and had always kept it off centralized exchanges that would maintain custody of his wallets. He liked THORChain because it claimed to be decentralized and permissionless. “I got into bitcoin because I wanted to have government-less money,” he says.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;We were told it was decentralized. Then you wake up one morning and read this guy had an admin mimir.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;Many who’d used THORFi lending and saving programs felt similarly. Users I interviewed differentiated THORChain from centralized lending platforms like BlockFi and Celsius, both of which offered extraordinarily high yields before filing for bankruptcy in 2022. “I viewed THORChain as a decentralized system where it was safer,” says Halsey Richartz, a Florida-based THORFi creditor, with “vanilla, 1% passive yield.” Indeed, users I spoke with hadn’t felt the need to monitor their THORFi deposits. “Only your key can be used to withdraw your funds,” the product’s marketing materials insisted. “Savers can withdraw their position to native assets at any time.”&lt;/p&gt;  &lt;p&gt;So on January 9, when the “leena” account announced that an admin key had been used to pause withdrawals, it took THORFi users by surprise—and seemed to contradict the marketing messaging around decentralization. “We were told that it was decentralized, and you wake up one morning and read an article that says ‘This guy, JP, had an admin mimir,’” says Treat, referring to Thorbjornsen, “and I’m like, ‘What the fuck is an admin mimir?’”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_21"&gt; &lt;p&gt;The admin mimir was one of “a bunch of hard-coded admin keys built into the base code of the system,” says Jonathan Reiter, CEO of the blockchain intelligence company ChainArgos. Those with access to the keys had the ability to make executive decisions on the blockchain—a function many THORChain users didn’t realize could supersede the more democratic decisions made by node votes. These keys had been in THORChain’s code for years and “let you control just about anything,” Reiter adds, including the decision to pause the network during the hacks in 2021 that resulted in a loss of more than $16 million in assets.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Thorbjornsen says that one key was given to Nine Realms, while another was “shared around the original team.” He told me at least three people had them, adding, “I can neither confirm nor deny having access to that mimir key, because there’s no on-chain registry of the keys.”&lt;/p&gt;  &lt;p&gt;Regardless of who had access, Thorbjornsen maintains that the admin mimir mechanism was “widely known within the community, and heavily used throughout THORChain’s history” and that any action taken using the keys “could be largely overruled by the nodes.” Indeed, nodes voted to open withdrawals back up shortly after the admin key was used to pause them. By then, those burned by THORFi argue, the damage had already been done. The executive pause to withdrawals, for some, signaled that something was amiss with THORFi. This led to a bank run after the pause was lifted, until the nodes voted to freeze withdrawals permanently (which Thorbjornsen had suggested in a since-deleted post on X), separating users from crypto worth around $200 million in US dollars on January 23. THORFi users were then offered a token called TCY (THORChain Yield), which they could claim with the idea that, when its price rose to $1, they would be made whole. (The price, as of writing, sits at $0.16.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_23"&gt; &lt;p&gt;Who used the key? Thorbjornsen maintains he didn’t do it, but he claims he knows who did and won’t say. He says he’d handed over the “leena” account and doesn’t “have access to any of the core components of the system,” nor has he for “at least three years.” He implies that whoever controlled “leena” at the time used the admin key to pause network withdrawals.&lt;/p&gt;  &lt;p&gt;A video released by Nine Realms on February 20, 2025, names Thorbjornsen as the activator of the key, stating, “JP ended up pausing lenders and savers, preventing withdrawals so that we can work out … [a] payback plan on them.” Thorbjornsen told me the video was “not factual.”&lt;/p&gt;  &lt;p&gt;Multiple blockchain analysts told me it would be extremely difficult to determine who used the admin mimir key. A month after it was used to pause the network, THORChain said the key had been “removed from the network.” At least you can’t find the words “admin mimir” in THORChain’s base code; I’ve looked.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Culpability&lt;/h3&gt;  &lt;p&gt;After the debacle of the THORFi withdrawal freeze, Richartz says, he tried to file reports with the Miami-Dade Police Department, the Florida Department of Law Enforcement, the FBI, the Securities and Exchange Commission, the Commodity Futures Trading Commission, the Federal Trade Commission, and Interpol. When we spoke in November, he still hadn’t been able to file with the city of Miami. They told him to try small claims court.&lt;/p&gt;  &lt;p&gt;“I was like, no, you don’t understand … a post office box in Switzerland is the company address,” he says. “It underscored to me how little law enforcement even knows about these crimes.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_25"&gt; &lt;p&gt;As for the Bybit hack, at least one government has retaliated against those who facilitate blockchain projects. Last April German authorities shut down eXch, an exchange suspected of using THORChain to process funds Lazarus stole from Bybit, says Julia Gottesman, cofounder and head of investigations at the cybersecurity group zeroShadow. Australia, she adds, where Thorbjornsen was based, has been “slow to try to engage with the crypto community, or any regulations.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a character with his pockets turned out shrugs next to his helicopter while wearing meme sunglasses" class="wp-image-1132690" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Crypto-3-c.jpg?w=1534" width="1534" /&gt;&lt;div class="image-credit"&gt;KAGAN MCLEOD&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;In response to requests for comment, Australia’s Department of Home Affairs wrote that at the end of March 2026, the country’s regulatory powers will expand to include “exchanges between the same type of cryptocurrency and transfers between different types.” They did not comment on specific investigations.&lt;/p&gt;  &lt;p&gt;Crypto and finance experts disagree about whether THORChain engaged in money laundering, defined by the UN as “the processing of criminal proceeds to disguise their illegal origin.” But some think it fits the definition.&lt;/p&gt;  &lt;p&gt;Shlomit Wagman, a Harvard fellow and former head of Israel’s anti-money-laundering agency and its delegation to the Financial Action Task Force (FATF), thinks the Bybit activity was money laundering because THORChain helped the hackers “transfer the funds in an unsupervised manner, completely outside of the scope of regulated or supervised activity.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And by helping with conversions, Carlsen says, THORChain enabled bad actors to turn stolen crypto into usable currency. “People like [Thorbjornsen] have a personal degree of culpability in sustaining the North Korean government,” he says. Thorbjornsen counters that THORChain is “open-source infrastructure.”&lt;/p&gt;  &lt;p&gt;Meanwhile, just days after the hack, Bybit issued a 10% bounty on any funds recovered. As of mid-January this year, between $100 million and $500 million worth of those funds in US dollars remain unaccounted for, according to Gottesman of zeroShadow, which was hired by Bybit to recover funds following the hack.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Thorbjornsen hacked&lt;/h3&gt;  &lt;p&gt;For Thorbjornsen, it’s just another day at the casino. That’s the comparison he made during his regrettable 7&amp;nbsp;News Spotlight interview about the Bybit heist, and he repeated it when we met. “You go to a casino, you play a few games, you expect to lose,” he told me. “When you do actually go to zero, don’t cry.”&lt;/p&gt;  &lt;p&gt;Thorbjornsen, it should be noted, has lost at the casino himself.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_27"&gt; &lt;p&gt;In September, he says, he got a Telegram message from a friend, inviting him to a Zoom meeting. He accepted and participated in a call with people who had “American voices.”&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;Ultimately, Thorbjornsen describes himself as a guy who’s had a bad year, fending off “threat vectors” left and right.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;After the meeting, Thorbjornsen learned that his friend’s Telegram had been hacked. Whoever was responsible had used the Zoom link to remotely install software on Thorbjornsen’s computer, which “got access to everything”—his email, his crypto wallets, a bitcoin-based retirement fund. It cost him at least $1.2 million. The blockchain sleuth known as ZachXBT traced the funds and attributed the hack to North Korea.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;ZachXBT called it “poetic.”&lt;/p&gt;  &lt;p&gt;Ultimately, Thorbjornsen describes himself as a guy who’s had a bad year. He says he had to liquidate his crypto assets because he’s dealing with the fallout of a recent divorce. He also feels he is fending off “threat vectors” left and right. More than once, he asked if I was a private investigator masquerading as a journalist.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_29"&gt;&lt;p&gt;Still, his many contradictions don’t inspire confidence. He doesn’t have any more crypto assets, he says. However, the crypto wallet he shared with me so I could pay him back for lunch showed that it contained assets worth more than $143,000 in US dollars. He now says it wasn’t his wallet. He says he doesn’t control THORChain’s social media, but he’d also told me that he runs the @THORChain X account (later backtracking and saying the account is “delegated” to him for trickier questions).&lt;/p&gt;  &lt;p&gt;He insists that he does not care about money. He says that in the robot future, the AI-powered hive mind will become our benevolent overlord, rendering money obsolete, so why give it much thought? Yet as we flew back from the vineyard, he pointed out his new house from the helicopter. It resembles a compound. He says he lives there with his new wife.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Multiple people I spoke with about Thorbjornsen before I met him warned me he wasn’t trustworthy, and he’s undeniably made fishy statements. For instance, the presence of a North Korean flag in a row of decals on the tail of his helicopter suggested an affinity with the country for which THORChain has processed so much crypto. Thorbjornsen insists he had requested the flag of Australia’s Norfolk Island, calling the mix-up “a complete coincidence.” The flags were gone by the time of our flight, apparently removed during a recent repair.&lt;/p&gt;  &lt;p&gt;“Money is a meme,” he says. “Money does not exist.” Meme or not, it’s had real repercussions for those who have interacted with THORChain, and those who wound up losing have been looking for someone to blame.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When I spoke with Thorbjornsen again in January, he appeared increasingly concerned that he is that someone. He’s spending more time in Singapore, he told me. Singapore happens to have historically denied extraditions to the US for money-laundering prosecutions.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Jessica Klein is a Philadelphia-based freelance journalist covering intimate partner violence, cryptocurrency, and other topics.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;“We’re out of airspace now. We can do whatever we want,” Jean-Paul Thorbjornsen tells me from the pilot’s seat of his Aston Martin helicopter. As we fly over suburbs outside Melbourne, Australia, it’s becoming clear that doing whatever he wants is Thorbjornsen’s MO.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Upper-middle-class homes give way to vineyards, and Thorbjornsen points out our landing spot outside a winery. People visiting for lunch walk outside. “They’re going to ask for a shot now,” he says, used to the attention drawn by his luxury helicopter, emblazoned with the tail letters “BTC” for bitcoin (the price tag of $5 million in Australian dollars—$3.5 million in US dollars today—was perhaps reasonable for someone who claims a previous crypto project made more than AU$400 million, although he also says those funds were tied up in the company).&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Thorbjornsen is a founder of THORChain, a blockchain through which users can swap one cryptocurrency for another and earn fees from making those swaps. THORChain is permissionless, so anyone can use it without getting prior approval from a centralized authority. As a decentralized network, the blockchain is built and run by operators located across the globe, most of whom use pseudonyms.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;During its early days, Thorbjornsen himself hid behind the pseudonym “leena” and used an AI-generated female image as his avatar. But around March 2024, he revealed that he, an Australian man in his mid-30s, with a rural Catholic upbringing, was the mind behind the blockchain. More or less.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;If there is a central question around THORChain, it is this: Exactly who is responsible for its operations? Blockchains as decentralized as THORChain are supposed to offer systems that operate outside the centralized leadership of corruptible governments and financial institutions. If a few people have outsize sway over this decentralized network—one of a handful that operate at such a large scale—it’s one more blemish on the legacy of bitcoin’s promise, which has already been tarnished by capitalistic political frenzy.&amp;nbsp; &amp;nbsp;&lt;/p&gt;  &lt;p&gt;Who’s responsible for THORChain matters because in January last year, its users lost more than $200 million worth of their cryptocurrency in US dollars after THORChain transactions and accounts were frozen by a singular admin override, which users believed was not supposed to be possible given the decentralized structure. When the freeze was lifted, some users raced to pull their money out. The following month, a team of North Korean hackers known as the Lazarus Group used THORChain to move roughly $1.2 billion of stolen ethereum taken in the infamous hack of the Dubai-based crypto exchange Bybit.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Thorbjornsen explains away THORChain’s inability to stop the movement of stolen funds, or prevent a bank run, as a function of its decentralized and permissionless nature. The lack of executive powers means that anyone can use the network for any reason, and arguably there’s no one to hold accountable when even the worst goes down.&lt;/p&gt;  &lt;p&gt;But when the worst did go down, nearly everyone in the THORChain community, and those paying attention to it in channels like X, pointed their fingers at Thorbjornsen. A lawsuit filed by the THORChain creditors who lost millions in January 2025 names him. A former FBI analyst and North Korea specialist, reflecting on the potential repercussions for helping move stolen funds, told me he wouldn’t want to be in Thorbjornsen’s shoes.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;THORChain was designed to make decisions based on votes by node operators, where two-thirds majority rules.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;That’s why I traveled to Australia—to see if I could get a handle on where he sees himself and his role in relation to the network he says he founded.&lt;/p&gt;  &lt;p&gt;According to Thorbjornsen, he should not be held responsible for either event. THORChain was designed to make decisions based on votes by node operators—people with the computer power, and crypto stake, to run a cluster of servers that process the network’s transactions. In those votes, a two-thirds majority rules.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Then there’s the permissionless part. &lt;em&gt;Anyone&lt;/em&gt; can use THORChain to make swaps, which is why it’s been a popular way for widely sanctioned entities such as the government of North Korea to move stolen money. This principle goes back to the cypherpunk roots of bitcoin, a currency that operates outside of nation-states’ rules. THORChain is designed to avoid geopolitical entanglements; that’s what its users like about it.&lt;/p&gt;  &lt;p&gt;But there are distinct financial motivations for moving crypto, stolen or not: Node operators earn fees from the funds running through the network. In theory, this incentivizes them to act in the network’s best interests—and, arguably, Thorbjornsen’s interests too, as many assume his wealth is tied to the network’s profits. (Thorbjornsen says it is not, and that it comes instead from “many sources,” including “buying bitcoin back in 2013.”)&lt;/p&gt;  &lt;p&gt;Now recent events have raised critical questions, not just about Thorbjornsen’s outsize role in THORChain’s operations, but also about the blockchain’s underlying nature.&lt;/p&gt;  &lt;p&gt;If THORChain is decentralized, how was a single operator able to freeze its funds a month before the Bybit hack? Could someone have unilaterally decided to stop the stolen Bybit funds from coming through the network, and chosen not to?&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Thorbjornsen insists THORChain is helping realize bitcoin’s original purpose of enabling anyone to transact freely outside the reach of purportedly corrupt governments. Yet the network’s problems suggest that an alternative financial system might not be much better.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Decentralized?&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;On February 21, 2025, Bybit CEO Ben Zhou got an alarming call from the company’s chief financial officer. About $1.5 billion US of the exchange’s ethereum token, ETH, had been stolen.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The FBI attributed the theft to the Lazarus Group. Typically, criminals will want to convert ETH to bitcoin, which is much easier to convert in turn to cash. Knowing this, the FBI issued a public service announcement on February 26 to “exchanges, bridges … and other virtual asset service providers,” encouraging them to block transactions from accounts related to the hack.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Someone posted that announcement in THORChain’s private, invite-only developer channel on Discord, a chat app used widely by software engineers and gamers. While other crypto exchanges and bridges (which facilitate transactions across different blockchains) heeded the warning, THORChain’s node operators, developers, and invested insiders debated about whether or not to close the trading gates, a decision requiring a majority vote.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;“Civil war is a very strong term, but there was a strong rift in the community,” says Boone Wheeler, a US-based crypto enthusiast. In 2021, Wheeler purchased some rune, THORChain’s Norse-mythology-themed native token, and he has been paid to write articles about the network to help advertise it. The rift formed “between people who wanted to stay permissionless,” he says, “and others who wanted to blacklist the funds.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;Wheeler, who says he doesn’t run a node or code for THORChain, fell on the side of remaining permissionless. However, others spoke up for blocking the transfers. THORChain, they argued, wasn’t decentralized enough to keep those running the network safe from law enforcement—especially when those operators were identifiable by their IP addresses, some based in the US.&lt;/p&gt;  &lt;p&gt;“We are not the morality police,” someone with the username @Swing_Pop wrote on February 27 in the developer Discord.&lt;/p&gt;  &lt;p&gt;THORChain’s design includes up to 120 nodes whose operators manage transactions on the network through a voting process. Anyone with hosting hardware can become an operator by funding nodes with rune as collateral, which provides the network with liquidity. Nodes can respond to a transaction by validating it or doing nothing. While individual transactions can’t be blocked, trading can be halted by a two-thirds majority vote.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="contentList__wrap content-right"&gt;&lt;h2 class="contentList__header" id="2851-val-contentList"&gt;A team of North Korean hackers used THORChain to move roughly $1.2 billion of ethereum stolen from the crypto exchange Bybit.&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;Nodes are also penalized for not participating in voting, which the system labels as “bad behavior.” Every 2.5 days, THORChain automatically “churns” nodes out to ensure that no one node gains too much control. The nodes that chose not to validate transactions from the Bybit hack were automatically “churned” out of the system. Thorbjornsen says about 20 or 30 nodes were booted from the network in this way. (Node operators can run multiple nodes, and 120 are rarely running simultaneously; at the time of writing, 55 unique IDs operated 103 nodes.)&lt;/p&gt;  &lt;p&gt;By February 27, some node operators were prepared to leave the network altogether. “It’s personally getting beyond my risk tolerance,” wrote @Runetard in the dev Discord. “Sorry to those of the community that feel otherwise. There are a bunch of us holding all the risk and some are getting ready to walk away.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="contentList__wrap content-right"&gt;&lt;h2 class="contentList__header" id="2852-val-contentList"&gt;According to one estimate, THORChain earned between $5 million and $10 million from the heist.&lt;/h2&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;Even so, the financial incentive for the network operators who remained was significant. As one member of the dev Discord put it earlier that day, $3 million had been “extracted as commission” from the theft by those operating THORChain. “This is wrong!” they wrote.&lt;/p&gt;  &lt;p&gt;Thorbjornsen weighed in on this back-and-forth, during which nodes paused and unpaused the network. He now says there was a right and wrong way for node operators to have behaved. “The correct way of doing things,” he says, was for node operators who opposed processing stolen funds to “go offline and … get [themselves] kicked out” rather than try to police who could use THORChain. He also says that while operators could discuss stopping transactions, “there was simply no design in the code that allowed [them] to do that.” However, a since-deleted post from his personal X account on March 3, 2025, stated: “I pushed for all my nodes to unhalt trading [keep trading]. Threatened to yank bond if they didn’t comply. Every single one.” (Thorbjornsen says his social media team ran this account in 2025.)&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;In an Australian 7 News Spotlight documentary last June, Thorbjornsen estimated that THORChain earned between $5 million and $10 million from the heist.&lt;/p&gt;  &lt;p&gt;When asked in that same documentary if he received any of those fees, he replied, “Not directly.” When we spoke, I asked him to elaborate. He said he’s “not a recipient” of any funds THORChain sets aside for developers or marketers, nor does he operate any nodes. He was merely speaking generally, he told me: “All crypto holders profit indirectly off economic activity on any chain.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a character in a hooded sweatshirt at a computer station" class="wp-image-1132689" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Crypto-2-c.jpg?w=1536" width="1536" /&gt;&lt;div class="image-credit"&gt;KAGAN MCLEOD&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Most important to Thorbjornsen was that, despite “huge pressure to shut the protocol down and stop servicing these swaps,” THORChain chugged along. He also notes that the hackers’ tactics, moving fast and splitting funds across multiple addresses, made it difficult to identify “bad swaps.”&lt;/p&gt;  &lt;p&gt;Blockchain experts like Nick Carlsen, a former FBI analyst at the blockchain intelligence company TRM Labs, don’t buy this assessment. Other services similar to THORChain were identifying and rejecting these transactions. Had THORChain done the same, Carlsen adds, the stolen funds could have been contained on the Ethereum network, which “would have basically denied North Korea the ability to kick off this laundering process.”&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;And while THORChain touts its decentralization, in “practical applications” like the Lazarus Group’s theft, “most de-fi [decentralized finance] protocols are centralized,” says Daren Firestone, an attorney who represents crypto industry whistleblowers, citing a 2023 US Treasury Department risk assessment on illicit finance.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;With centralization comes culpability, and in these cases, Firestone adds, that comes down to “who profits from [the protocol], so who creates it? But most importantly, who controls it?” Is there someone who can “hit an emergency off switch? … Direct nodes?”&lt;/p&gt;  &lt;p&gt;Many answer these questions with Thorbjornsen’s name. “Everyone likes to pass the blame,” he says, even though he wasn’t alone in building THORChain. “​​In the end, it all comes back to me anyway.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;THORChain origins&lt;/h3&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;According to Thorbjornsen, his story goes like this.&lt;/p&gt;    &lt;p&gt;The third of 10 homeschooled children in a “traditional” Catholic household in rural Australia, he spent his days learning math, reading, writing, and studying the Bible. As he got older, he was also responsible for instructing his younger siblings. Wednesday was his day to move the solar panels that powered their home. His parents “installed” a mango and citrus orchard, more to keep nine boys busy than to reap the produce, he says.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;“We lived close to a local airfield,” Thorbjornsen says, “and I was always mesmerized by these planes.” He joined the Australian air force and studied engineering, but he says the military left him feeling like “a square peg in a round hole.” He adds that doing things his own way got him frequently “pulled aside” by superiors.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;“That’s when I started looking elsewhere,” he says, and in 2013, he found bitcoin. It appealed because it existed “outside the system.”&lt;/p&gt;  &lt;p&gt;During the 2017 crypto bull run, Thorbjornsen raised AU$12 million in an initial coin offering for CanYa, a decentralized marketplace he cofounded. CanYa ultimately “died” in 2018, and Thorbjornsen pivoted to a “decentralized liquidity” project that would become THORChain.&lt;/p&gt;  &lt;p&gt;He worked with a couple of different developer teams, and then, in 2019, he clicked with an American developer, Chad Barraford, at a hackathon in Germany. Barraford (who declined to be interviewed for this story) was an early public face of THORChain.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Around this time, Thorbjornsen says, “a couple of us helped manage the payroll and early investment funds.” In a 2020 interview, Kai Ansaari, identified as a THORChain “project lead,” wrote, “We’re all contributors … There’s no real ‘lead,’ ‘CEO,’ ‘founder,’ etc.”&lt;/p&gt;  &lt;p&gt;In interviews conducted since he came out from behind the “leena” account in 2024, Thorbjornsen has positioned himself as a key lead. He now says his plan had always been to hand over the account, along with command powers and control of THORChain social media accounts, once the blockchain had matured enough to realize its promise of decentralization.&lt;/p&gt;  &lt;p&gt;In 2021, he says, he started this process, first by ceasing to use his own rune to back node operators who didn’t have enough to supply their own funding (this can be a way to influence node votes without operating a node yourself). That year, the protocol suffered multiple hacks that resulted in millions of dollars in losses. Nine Realms, a US-incorporated coding company, was brought on to take over THORChain’s development. Thorbjornsen says he passed “leena” over to “other community members” and “left crypto” in 2021, selling “a bunch of bitcoin” and buying the helicopter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Despite this crypto departure, he came back onto the scene with gusto in 2024 when he revealed himself as the operator of the “leena” account. “​​For many years, I stayed private because I didn’t want the attention,” he says now.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By early 2024 Thorbjornsen considered the network to be sufficiently decentralized and began advertising it publicly. He started regularly posting videos on his TikTok and YouTube channels (“Two sick videos every week,” in the words of one caption) that showed him piloting his helicopter wearing shirts that read “Thor.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_19"&gt; &lt;p&gt;By November 2024, Thorbjornsen, who describes himself as “a bit flamboyant,” was calling himself THORChain’s CEO (“chief energy officer”) and the “master of the memes” in a video from Binance Blockchain Week, an industry conference in Dubai. You need “strong memetic energy,” he says in the video, “to create the community, to create the cult.” Cults imply centralized leadership, and since outing himself as “leena,” Thorbjornsen has publicly appeared to helm the project, with one interviewer deeming him the “THORChain Satoshi” (an allusion to the pseudonymous creator of bitcoin).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One consequence of going public as a face of the protocol: He’s received death threats. “I stirred it up. Do I regret it? Who knows?” he said when we met in Australia. “It’s caused a lot of chaos.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But, he added, “this is the bed that I’ve laid.” When we spoke again, months later, he backtracked, saying he “got sucked into” defending THORChain in 2024 and 2025 because he was involved from 2018 to 2021 and has “a perspective on how the protocol operates.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Centralized?&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Ryan Treat, a retired US Army veteran, woke up one morning in January 2025 to some disturbing activity on X. “My heart sank,” he says. THORFi, the THORChain program he’d used to earn interest on the bitcoin he’d planned to save for his retirement, had frozen all accounts—but that didn’t make sense.&lt;/p&gt;  &lt;p&gt;THORFi featured a lending and saving program said to give users “complete control” and self-custody of their crypto, meaning they could withdraw it at any time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Treat was no crypto amateur. He bought his first bitcoin at around “$5 apiece,” he says, and had always kept it off centralized exchanges that would maintain custody of his wallets. He liked THORChain because it claimed to be decentralized and permissionless. “I got into bitcoin because I wanted to have government-less money,” he says.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;We were told it was decentralized. Then you wake up one morning and read this guy had an admin mimir.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;Many who’d used THORFi lending and saving programs felt similarly. Users I interviewed differentiated THORChain from centralized lending platforms like BlockFi and Celsius, both of which offered extraordinarily high yields before filing for bankruptcy in 2022. “I viewed THORChain as a decentralized system where it was safer,” says Halsey Richartz, a Florida-based THORFi creditor, with “vanilla, 1% passive yield.” Indeed, users I spoke with hadn’t felt the need to monitor their THORFi deposits. “Only your key can be used to withdraw your funds,” the product’s marketing materials insisted. “Savers can withdraw their position to native assets at any time.”&lt;/p&gt;  &lt;p&gt;So on January 9, when the “leena” account announced that an admin key had been used to pause withdrawals, it took THORFi users by surprise—and seemed to contradict the marketing messaging around decentralization. “We were told that it was decentralized, and you wake up one morning and read an article that says ‘This guy, JP, had an admin mimir,’” says Treat, referring to Thorbjornsen, “and I’m like, ‘What the fuck is an admin mimir?’”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_21"&gt; &lt;p&gt;The admin mimir was one of “a bunch of hard-coded admin keys built into the base code of the system,” says Jonathan Reiter, CEO of the blockchain intelligence company ChainArgos. Those with access to the keys had the ability to make executive decisions on the blockchain—a function many THORChain users didn’t realize could supersede the more democratic decisions made by node votes. These keys had been in THORChain’s code for years and “let you control just about anything,” Reiter adds, including the decision to pause the network during the hacks in 2021 that resulted in a loss of more than $16 million in assets.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Thorbjornsen says that one key was given to Nine Realms, while another was “shared around the original team.” He told me at least three people had them, adding, “I can neither confirm nor deny having access to that mimir key, because there’s no on-chain registry of the keys.”&lt;/p&gt;  &lt;p&gt;Regardless of who had access, Thorbjornsen maintains that the admin mimir mechanism was “widely known within the community, and heavily used throughout THORChain’s history” and that any action taken using the keys “could be largely overruled by the nodes.” Indeed, nodes voted to open withdrawals back up shortly after the admin key was used to pause them. By then, those burned by THORFi argue, the damage had already been done. The executive pause to withdrawals, for some, signaled that something was amiss with THORFi. This led to a bank run after the pause was lifted, until the nodes voted to freeze withdrawals permanently (which Thorbjornsen had suggested in a since-deleted post on X), separating users from crypto worth around $200 million in US dollars on January 23. THORFi users were then offered a token called TCY (THORChain Yield), which they could claim with the idea that, when its price rose to $1, they would be made whole. (The price, as of writing, sits at $0.16.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_23"&gt; &lt;p&gt;Who used the key? Thorbjornsen maintains he didn’t do it, but he claims he knows who did and won’t say. He says he’d handed over the “leena” account and doesn’t “have access to any of the core components of the system,” nor has he for “at least three years.” He implies that whoever controlled “leena” at the time used the admin key to pause network withdrawals.&lt;/p&gt;  &lt;p&gt;A video released by Nine Realms on February 20, 2025, names Thorbjornsen as the activator of the key, stating, “JP ended up pausing lenders and savers, preventing withdrawals so that we can work out … [a] payback plan on them.” Thorbjornsen told me the video was “not factual.”&lt;/p&gt;  &lt;p&gt;Multiple blockchain analysts told me it would be extremely difficult to determine who used the admin mimir key. A month after it was used to pause the network, THORChain said the key had been “removed from the network.” At least you can’t find the words “admin mimir” in THORChain’s base code; I’ve looked.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Culpability&lt;/h3&gt;  &lt;p&gt;After the debacle of the THORFi withdrawal freeze, Richartz says, he tried to file reports with the Miami-Dade Police Department, the Florida Department of Law Enforcement, the FBI, the Securities and Exchange Commission, the Commodity Futures Trading Commission, the Federal Trade Commission, and Interpol. When we spoke in November, he still hadn’t been able to file with the city of Miami. They told him to try small claims court.&lt;/p&gt;  &lt;p&gt;“I was like, no, you don’t understand … a post office box in Switzerland is the company address,” he says. “It underscored to me how little law enforcement even knows about these crimes.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_25"&gt; &lt;p&gt;As for the Bybit hack, at least one government has retaliated against those who facilitate blockchain projects. Last April German authorities shut down eXch, an exchange suspected of using THORChain to process funds Lazarus stole from Bybit, says Julia Gottesman, cofounder and head of investigations at the cybersecurity group zeroShadow. Australia, she adds, where Thorbjornsen was based, has been “slow to try to engage with the crypto community, or any regulations.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a character with his pockets turned out shrugs next to his helicopter while wearing meme sunglasses" class="wp-image-1132690" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Crypto-3-c.jpg?w=1534" width="1534" /&gt;&lt;div class="image-credit"&gt;KAGAN MCLEOD&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;In response to requests for comment, Australia’s Department of Home Affairs wrote that at the end of March 2026, the country’s regulatory powers will expand to include “exchanges between the same type of cryptocurrency and transfers between different types.” They did not comment on specific investigations.&lt;/p&gt;  &lt;p&gt;Crypto and finance experts disagree about whether THORChain engaged in money laundering, defined by the UN as “the processing of criminal proceeds to disguise their illegal origin.” But some think it fits the definition.&lt;/p&gt;  &lt;p&gt;Shlomit Wagman, a Harvard fellow and former head of Israel’s anti-money-laundering agency and its delegation to the Financial Action Task Force (FATF), thinks the Bybit activity was money laundering because THORChain helped the hackers “transfer the funds in an unsupervised manner, completely outside of the scope of regulated or supervised activity.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;And by helping with conversions, Carlsen says, THORChain enabled bad actors to turn stolen crypto into usable currency. “People like [Thorbjornsen] have a personal degree of culpability in sustaining the North Korean government,” he says. Thorbjornsen counters that THORChain is “open-source infrastructure.”&lt;/p&gt;  &lt;p&gt;Meanwhile, just days after the hack, Bybit issued a 10% bounty on any funds recovered. As of mid-January this year, between $100 million and $500 million worth of those funds in US dollars remain unaccounted for, according to Gottesman of zeroShadow, which was hired by Bybit to recover funds following the hack.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Thorbjornsen hacked&lt;/h3&gt;  &lt;p&gt;For Thorbjornsen, it’s just another day at the casino. That’s the comparison he made during his regrettable 7&amp;nbsp;News Spotlight interview about the Bybit heist, and he repeated it when we met. “You go to a casino, you play a few games, you expect to lose,” he told me. “When you do actually go to zero, don’t cry.”&lt;/p&gt;  &lt;p&gt;Thorbjornsen, it should be noted, has lost at the casino himself.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_27"&gt; &lt;p&gt;In September, he says, he got a Telegram message from a friend, inviting him to a Zoom meeting. He accepted and participated in a call with people who had “American voices.”&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;Ultimately, Thorbjornsen describes himself as a guy who’s had a bad year, fending off “threat vectors” left and right.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;After the meeting, Thorbjornsen learned that his friend’s Telegram had been hacked. Whoever was responsible had used the Zoom link to remotely install software on Thorbjornsen’s computer, which “got access to everything”—his email, his crypto wallets, a bitcoin-based retirement fund. It cost him at least $1.2 million. The blockchain sleuth known as ZachXBT traced the funds and attributed the hack to North Korea.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;ZachXBT called it “poetic.”&lt;/p&gt;  &lt;p&gt;Ultimately, Thorbjornsen describes himself as a guy who’s had a bad year. He says he had to liquidate his crypto assets because he’s dealing with the fallout of a recent divorce. He also feels he is fending off “threat vectors” left and right. More than once, he asked if I was a private investigator masquerading as a journalist.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_29"&gt;&lt;p&gt;Still, his many contradictions don’t inspire confidence. He doesn’t have any more crypto assets, he says. However, the crypto wallet he shared with me so I could pay him back for lunch showed that it contained assets worth more than $143,000 in US dollars. He now says it wasn’t his wallet. He says he doesn’t control THORChain’s social media, but he’d also told me that he runs the @THORChain X account (later backtracking and saying the account is “delegated” to him for trickier questions).&lt;/p&gt;  &lt;p&gt;He insists that he does not care about money. He says that in the robot future, the AI-powered hive mind will become our benevolent overlord, rendering money obsolete, so why give it much thought? Yet as we flew back from the vineyard, he pointed out his new house from the helicopter. It resembles a compound. He says he lives there with his new wife.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Multiple people I spoke with about Thorbjornsen before I met him warned me he wasn’t trustworthy, and he’s undeniably made fishy statements. For instance, the presence of a North Korean flag in a row of decals on the tail of his helicopter suggested an affinity with the country for which THORChain has processed so much crypto. Thorbjornsen insists he had requested the flag of Australia’s Norfolk Island, calling the mix-up “a complete coincidence.” The flags were gone by the time of our flight, apparently removed during a recent repair.&lt;/p&gt;  &lt;p&gt;“Money is a meme,” he says. “Money does not exist.” Meme or not, it’s had real repercussions for those who have interacted with THORChain, and those who wound up losing have been looking for someone to blame.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When I spoke with Thorbjornsen again in January, he appeared increasingly concerned that he is that someone. He’s spending more time in Singapore, he told me. Singapore happens to have historically denied extraditions to the US for money-laundering prosecutions.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Jessica Klein is a Philadelphia-based freelance journalist covering intimate partner violence, cryptocurrency, and other topics.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/18/1132587/jean-paul-thorbjornsen-dark-side-crypto-permissionless-dream/</guid><pubDate>Wed, 18 Feb 2026 11:00:00 +0000</pubDate></item><item><title>The robots who predict the future (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/18/1132579/robots-predict-future-book-review/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;To be human is, fundamentally, to be a forecaster. Occasionally a pretty good one. Trying to see the future, whether through the lens of past experience or the logic of cause and effect, has helped us hunt, avoid &lt;em&gt;being&lt;/em&gt; hunted, plant crops, forge social bonds, and in general survive in a world that does not prioritize our survival. Indeed, as the tools of divination have changed over the centuries, from tea leaves to data sets, our conviction that the future can be known (and therefore controlled) has only grown stronger.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Today, we are awash in a sea of predictions so vast and unrelenting that most of us barely even register them. As I write this sentence, algorithms on some remote server are busy trying to guess my next word based on those I have already typed. If you’re reading this online, a separate set of algorithms has likely already served you an ad deemed to be one you are most likely to click. (To the die-hards reading this story on paper, congratulations! You have escaped the algorithms … for now.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;If the thought of a ubiquitous, mostly invisible predictive layer secretly grafted onto your life by a bunch of profit-hungry corporations makes you uneasy … well, same here.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;So how did all this happen? People’s desire for reliable forecasting is understandable. Still, nobody signed up for an omnipresent, algorithmic oracle mediating every aspect of their life. A trio of new books tries to make sense of our future-­focused world—how we got here, and what this change means. Each has its own prescriptions for navigating this new reality, but they all agree on one thing: Predictions are ultimately about power and control.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="cover of The Means of Prediction" class="wp-image-1132681" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/book.kasey_.jpg?w=666" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;The Means of Prediction: How AI Really Works (and Who Benefits)&lt;/strong&gt;&lt;br /&gt;Maximilian Kasy&lt;br /&gt;&lt;/figcaption&gt;&lt;div class="image-credit"&gt;UNIVERSITY OF CHICAGO PRESS, 2025&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;In &lt;em&gt;The Means of Prediction: How AI Really Works (and Who Benefits)&lt;/em&gt;, the Oxford economist Maximilian Kasy explains how most predictions in our lives are based on the statistical analysis of patterns in large, labeled data sets—what’s known in AI circles as supervised learning. Once “trained” on such data sets, algorithms for supervised learning can be presented with all kinds of new information and then deliver their best guess as to some specific future outcome. Will you violate your parole, pay off your mortgage, get promoted if hired, perform well on your college exams, be in your home when it gets bombed? More and more, our lives are shaped (and, yes, occasionally shortened) by a machine’s answer to these questions.&lt;/p&gt; 
 &lt;p&gt;If the thought of a ubiquitous, mostly invisible predictive layer secretly grafted onto your life by a bunch of profit-hungry corporations makes you uneasy … well, same here. This arrangement is leading to a crueler, blander, more instrumentalized world, one where life’s possibilities are foreclosed, age-old prejudices are entrenched, and everyone’s brain seems to be actively turning into goo. It’s an outcome, according to Kasy, that was entirely predictable.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;AI adherents might frame those consequences as “unintended,” or mere problems of optimization and alignment. Kasy, on the other hand, argues that they represent the system working as intended. “If an algorithm selecting what you see on social media promotes outrage, thereby maximizing engagement and ad clicks,” he writes, “that’s because promoting outrage is good for profits from ad sales.” The same holds true for an algorithm that nixes job candidates “who are likely to have family-care responsibilities outside the workplace,” and the ones that “screen out people who are likely to develop chronic health problems or disabilities.” What’s good for a company’s bottom line may not be good for your job-hunting prospects or life expectancy.&lt;/p&gt; 
 &lt;p&gt;Where Kasy differs from other critics is that he doesn’t think working to create less biased, more equitable algorithms will fix any of this. Trying to rebalance the scales can’t change the fact that predictive algorithms rely on past data that’s often racist, sexist, and flawed in countless other ways. And, he says, the incentives for profit will always trump attempts to eliminate harm. The only way to counter this is with broad democratic control over what Kasy calls “the means of prediction”: data, computational infrastructure, technical expertise, and energy. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;A little more than half of &lt;em&gt;The Means of Prediction&lt;/em&gt; is devoted to explaining how this might be accomplished—through mechanisms including “data trusts” (collective public bodies that make decisions about how to process and use data on behalf of their contributors) and corporate taxing schemes that try to account for the social harm AI inflicts. There’s a lot of economist talk along the way, about how “agents of change” might help achieve “value alignment” in order to “maximize social welfare.” Reasonable, I guess, though a skeptic might point out that Kasy’s rigorous, systematic approach to building new public-serving institutions comes at a time when public trust in institutions has never been lower. Also, there’s the brain goo problem.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To his credit, Kasy is a realist here. He doesn’t presume that any of these proposals will be easy to implement. Or that it will happen overnight, or even in the near future. The troubling question at the end his book is: Do we have that kind of time?&lt;/p&gt;  &lt;p&gt;Reading Kasy’s blueprint for seizing control of the means of prediction raises another pressing question. How on earth did we reach a point where machine-mediated prediction is more or less inescapable? &lt;em&gt;Capitalism&lt;/em&gt;, might be Marx’s pithy response. Fine, as far as it goes, but that doesn’t explain why the same kinds of algorithms that currently model climate change are for some reason also deciding whether you get a new kidney or I get a car loan.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1132682" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/book.recht_.jpg?w=1314" width="1314" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;The Irrational Decision: How We Gave Computers the Power to Choose for Us&lt;/strong&gt;&lt;br /&gt;Benjamin Recht&lt;br /&gt;&lt;/figcaption&gt;&lt;div class="image-credit"&gt;PRINCETON UNIVERSITY PRESS, 2026&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;If you ask Benjamin Recht, author of &lt;em&gt;The Irrational Decision: How We Gave Computers the Power to Choose for Us&lt;/em&gt;, he’d likely tell you our current predicament has a lot to do with the idea and ideology of decision theory—or what economists call rational choice theory. Recht, a polymathic professor in UC Berkeley’s Department of Electrical Engineering and Computer Science, prefers the term “mathematical rationality” to describe the narrow, statistical conception that stoked the desire to build computers, informed how they would eventually work, and influenced the kinds of problems they would be good at solving.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This belief system goes all the way back to the Enlightenment, but in Recht’s telling, it truly took hold at the tail end of World War II. Nothing focuses the mind on risk and quick decision-making like war, and the mathematical models that proved especially useful in the fight against the Axis powers convinced a select group of scientists and statisticians that they might also be a logical basis for designing the first computers. Thus was born the idea of a computer as an ideal rational agent, a machine capable of making optimal decisions by quantifying uncertainty and maximizing utility.&lt;/p&gt;  &lt;p&gt;Intuition, experience, and judgment gave way, says Recht, to optimization, game theory, and statistical prediction. “The core algorithms developed in this period drive the automated decisions of our modern world, whether it be in managing supply chains, scheduling flight times, or placing advertisements on your social media feeds,” he writes. In this optimization-­driven reality, “every life decision is posed as if it were a round at an imaginary casino, and every argument can be reduced to costs and benefits, means and ends.”&lt;/p&gt;  &lt;p&gt;Today, mathematical rationality (wearing its human skin) is best represented by the likes of the pollster Nate Silver, the Harvard psychologist Steven Pinker, and an assortment of Silicon Valley oligarchs, says Recht. These are people who fundamentally believe the world would be a better place if more of us adopted their analytic mindset and learned to weigh costs and benefits, estimate risks, and plan optimally. In other words, these are people who believe we should all make decisions like computers.&amp;nbsp;&lt;/p&gt; 

 &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;How might we demonstrate that (unquantifiable) human intuition, morality, and judgment are better ways of addressing some of the world’s most important and vexing problems?&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;It’s a ridiculous idea for multiple reasons, he says. To name just one, it’s not as if humans couldn’t make evidence-based decisions before automation. “Advances in clean water, antibiotics, and public health brought life expectancy from under 40 in the 1850s to 70 by 1950,” Recht writes. “From the late 1800s to the early 1900s, we had world-changing scientific breakthroughs in physics, including new theories of thermodynamics, quantum mechanics, and relativity.” We also managed to build cars and airplanes without a formal system of rationality and somehow came up with societal innovations like modern democracy without optimal decision theory.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So how might we convince the Pinkers and Silvers of the world that most decisions we face in life are not in fact grist for the unrelenting mill of mathematical rationality? Moreover, how might we demonstrate that (unquantifiable) human intuition, morality, and judgment might be better ways of addressing some of the world’s most important and vexing problems?&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="cover of Prophecy" class="wp-image-1132683" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/book.velez_.jpg?w=987" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Prophecy: Prediction, Power, and the Fight for the Future, from Ancient Oracles to AI&lt;/strong&gt;&lt;br /&gt;Carissa Véliz&lt;br /&gt;&lt;/figcaption&gt;&lt;div class="image-credit"&gt;DOUBLEDAY, 2026&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;One might start by reminding the rationalists that any prediction, computational or otherwise, is really just a &lt;em&gt;wish&lt;/em&gt;—but one with a powerful tendency to self-fulfill. This idea animates Carissa Véliz’s wonderfully wide-ranging polemic &lt;em&gt;Prophecy: Prediction, Power, and the Fight for the Future, from Ancient Oracles to AI&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A philosopher at the University of Oxford, Véliz sees a prediction as “a magnet that bends reality toward itself.” She writes, “When the force of the magnet is strong enough, the prediction becomes the cause of its becoming true.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Take Gordon Moore. While he doesn’t come up in &lt;em&gt;Prophecy&lt;/em&gt;, he does figure somewhat prominently in Recht’s history of mathematical rationality. A cofounder of the tech giant Intel, Moore is famous for his 1965 prediction that the density of transistors in integrated circuits would double every two years. “Moore’s Law” turned out to be true, and remains true today, although it does seem to be running out of steam thanks to the physical size limits of the silicon atom.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;One story you can tell yourself about Moore’s Law is that Gordon was just a prescient guy. His now-classic 1965 opinion piece “Cramming More Components onto Integrated Circuits,” for &lt;em&gt;Electronics&lt;/em&gt; magazine, simply extrapolated what computing trends might mean for the future of the semiconductor industry.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Another story—the one I’m guessing Véliz might tell—is that Moore put an informed prediction out into the world, and an entire industry had a collective interest in making it come true. As Recht makes clear, there were and remain obvious financial incentives for companies to make faster and smaller computer chips. And while the industry has likely spent billions of dollars trying to keep Moore’s Law alive, it’s undoubtedly profited even more from it. Moore’s Law was a helluva strong magnet.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Predictions don’t just have a habit of making themselves come true, says Véliz. They can also distract us from the challenges of the here and now. When an AI boomer promises that artificial general intelligence will be the last problem humanity needs to solve, it not only shapes how we think about AI’s role in our lives; it also shifts our attention away from the very real and very pressing problems of the present day—problems that in many cases AI is causing.&lt;/p&gt; 
 &lt;p&gt;In this sense, the questions around predictions (Who’s making them? Who has the right to make them?) are also fundamentally about power. It’s no accident, Véliz says, that the societies that rely most heavily on prediction are also the ones that tend toward oppression and authoritarianism. Predictions are “veiled prescriptive assertions—they tell us how to act,” she writes. “They are what philosophers call speech &lt;em&gt;acts&lt;/em&gt;. When we believe a prediction and act in accordance with it, it’s akin to obeying an order.”&lt;/p&gt;  &lt;p&gt;As much as tech companies would like us to believe otherwise, technology is not destiny. Humans make it and choose how to use it … or not use it. Maybe the most appropriate (and human) thing we can do in the face of all the uninvited daily predictions in our lives is to simply defy them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Bryan Gardiner is a writer based in Oakland, California.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;To be human is, fundamentally, to be a forecaster. Occasionally a pretty good one. Trying to see the future, whether through the lens of past experience or the logic of cause and effect, has helped us hunt, avoid &lt;em&gt;being&lt;/em&gt; hunted, plant crops, forge social bonds, and in general survive in a world that does not prioritize our survival. Indeed, as the tools of divination have changed over the centuries, from tea leaves to data sets, our conviction that the future can be known (and therefore controlled) has only grown stronger.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Today, we are awash in a sea of predictions so vast and unrelenting that most of us barely even register them. As I write this sentence, algorithms on some remote server are busy trying to guess my next word based on those I have already typed. If you’re reading this online, a separate set of algorithms has likely already served you an ad deemed to be one you are most likely to click. (To the die-hards reading this story on paper, congratulations! You have escaped the algorithms … for now.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;If the thought of a ubiquitous, mostly invisible predictive layer secretly grafted onto your life by a bunch of profit-hungry corporations makes you uneasy … well, same here.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;So how did all this happen? People’s desire for reliable forecasting is understandable. Still, nobody signed up for an omnipresent, algorithmic oracle mediating every aspect of their life. A trio of new books tries to make sense of our future-­focused world—how we got here, and what this change means. Each has its own prescriptions for navigating this new reality, but they all agree on one thing: Predictions are ultimately about power and control.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="cover of The Means of Prediction" class="wp-image-1132681" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/book.kasey_.jpg?w=666" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;The Means of Prediction: How AI Really Works (and Who Benefits)&lt;/strong&gt;&lt;br /&gt;Maximilian Kasy&lt;br /&gt;&lt;/figcaption&gt;&lt;div class="image-credit"&gt;UNIVERSITY OF CHICAGO PRESS, 2025&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;In &lt;em&gt;The Means of Prediction: How AI Really Works (and Who Benefits)&lt;/em&gt;, the Oxford economist Maximilian Kasy explains how most predictions in our lives are based on the statistical analysis of patterns in large, labeled data sets—what’s known in AI circles as supervised learning. Once “trained” on such data sets, algorithms for supervised learning can be presented with all kinds of new information and then deliver their best guess as to some specific future outcome. Will you violate your parole, pay off your mortgage, get promoted if hired, perform well on your college exams, be in your home when it gets bombed? More and more, our lives are shaped (and, yes, occasionally shortened) by a machine’s answer to these questions.&lt;/p&gt; 
 &lt;p&gt;If the thought of a ubiquitous, mostly invisible predictive layer secretly grafted onto your life by a bunch of profit-hungry corporations makes you uneasy … well, same here. This arrangement is leading to a crueler, blander, more instrumentalized world, one where life’s possibilities are foreclosed, age-old prejudices are entrenched, and everyone’s brain seems to be actively turning into goo. It’s an outcome, according to Kasy, that was entirely predictable.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;AI adherents might frame those consequences as “unintended,” or mere problems of optimization and alignment. Kasy, on the other hand, argues that they represent the system working as intended. “If an algorithm selecting what you see on social media promotes outrage, thereby maximizing engagement and ad clicks,” he writes, “that’s because promoting outrage is good for profits from ad sales.” The same holds true for an algorithm that nixes job candidates “who are likely to have family-care responsibilities outside the workplace,” and the ones that “screen out people who are likely to develop chronic health problems or disabilities.” What’s good for a company’s bottom line may not be good for your job-hunting prospects or life expectancy.&lt;/p&gt; 
 &lt;p&gt;Where Kasy differs from other critics is that he doesn’t think working to create less biased, more equitable algorithms will fix any of this. Trying to rebalance the scales can’t change the fact that predictive algorithms rely on past data that’s often racist, sexist, and flawed in countless other ways. And, he says, the incentives for profit will always trump attempts to eliminate harm. The only way to counter this is with broad democratic control over what Kasy calls “the means of prediction”: data, computational infrastructure, technical expertise, and energy. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;A little more than half of &lt;em&gt;The Means of Prediction&lt;/em&gt; is devoted to explaining how this might be accomplished—through mechanisms including “data trusts” (collective public bodies that make decisions about how to process and use data on behalf of their contributors) and corporate taxing schemes that try to account for the social harm AI inflicts. There’s a lot of economist talk along the way, about how “agents of change” might help achieve “value alignment” in order to “maximize social welfare.” Reasonable, I guess, though a skeptic might point out that Kasy’s rigorous, systematic approach to building new public-serving institutions comes at a time when public trust in institutions has never been lower. Also, there’s the brain goo problem.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To his credit, Kasy is a realist here. He doesn’t presume that any of these proposals will be easy to implement. Or that it will happen overnight, or even in the near future. The troubling question at the end his book is: Do we have that kind of time?&lt;/p&gt;  &lt;p&gt;Reading Kasy’s blueprint for seizing control of the means of prediction raises another pressing question. How on earth did we reach a point where machine-mediated prediction is more or less inescapable? &lt;em&gt;Capitalism&lt;/em&gt;, might be Marx’s pithy response. Fine, as far as it goes, but that doesn’t explain why the same kinds of algorithms that currently model climate change are for some reason also deciding whether you get a new kidney or I get a car loan.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1132682" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/book.recht_.jpg?w=1314" width="1314" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;The Irrational Decision: How We Gave Computers the Power to Choose for Us&lt;/strong&gt;&lt;br /&gt;Benjamin Recht&lt;br /&gt;&lt;/figcaption&gt;&lt;div class="image-credit"&gt;PRINCETON UNIVERSITY PRESS, 2026&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;If you ask Benjamin Recht, author of &lt;em&gt;The Irrational Decision: How We Gave Computers the Power to Choose for Us&lt;/em&gt;, he’d likely tell you our current predicament has a lot to do with the idea and ideology of decision theory—or what economists call rational choice theory. Recht, a polymathic professor in UC Berkeley’s Department of Electrical Engineering and Computer Science, prefers the term “mathematical rationality” to describe the narrow, statistical conception that stoked the desire to build computers, informed how they would eventually work, and influenced the kinds of problems they would be good at solving.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This belief system goes all the way back to the Enlightenment, but in Recht’s telling, it truly took hold at the tail end of World War II. Nothing focuses the mind on risk and quick decision-making like war, and the mathematical models that proved especially useful in the fight against the Axis powers convinced a select group of scientists and statisticians that they might also be a logical basis for designing the first computers. Thus was born the idea of a computer as an ideal rational agent, a machine capable of making optimal decisions by quantifying uncertainty and maximizing utility.&lt;/p&gt;  &lt;p&gt;Intuition, experience, and judgment gave way, says Recht, to optimization, game theory, and statistical prediction. “The core algorithms developed in this period drive the automated decisions of our modern world, whether it be in managing supply chains, scheduling flight times, or placing advertisements on your social media feeds,” he writes. In this optimization-­driven reality, “every life decision is posed as if it were a round at an imaginary casino, and every argument can be reduced to costs and benefits, means and ends.”&lt;/p&gt;  &lt;p&gt;Today, mathematical rationality (wearing its human skin) is best represented by the likes of the pollster Nate Silver, the Harvard psychologist Steven Pinker, and an assortment of Silicon Valley oligarchs, says Recht. These are people who fundamentally believe the world would be a better place if more of us adopted their analytic mindset and learned to weigh costs and benefits, estimate risks, and plan optimally. In other words, these are people who believe we should all make decisions like computers.&amp;nbsp;&lt;/p&gt; 

 &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;How might we demonstrate that (unquantifiable) human intuition, morality, and judgment are better ways of addressing some of the world’s most important and vexing problems?&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;It’s a ridiculous idea for multiple reasons, he says. To name just one, it’s not as if humans couldn’t make evidence-based decisions before automation. “Advances in clean water, antibiotics, and public health brought life expectancy from under 40 in the 1850s to 70 by 1950,” Recht writes. “From the late 1800s to the early 1900s, we had world-changing scientific breakthroughs in physics, including new theories of thermodynamics, quantum mechanics, and relativity.” We also managed to build cars and airplanes without a formal system of rationality and somehow came up with societal innovations like modern democracy without optimal decision theory.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So how might we convince the Pinkers and Silvers of the world that most decisions we face in life are not in fact grist for the unrelenting mill of mathematical rationality? Moreover, how might we demonstrate that (unquantifiable) human intuition, morality, and judgment might be better ways of addressing some of the world’s most important and vexing problems?&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="cover of Prophecy" class="wp-image-1132683" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/book.velez_.jpg?w=987" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;strong&gt;Prophecy: Prediction, Power, and the Fight for the Future, from Ancient Oracles to AI&lt;/strong&gt;&lt;br /&gt;Carissa Véliz&lt;br /&gt;&lt;/figcaption&gt;&lt;div class="image-credit"&gt;DOUBLEDAY, 2026&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;One might start by reminding the rationalists that any prediction, computational or otherwise, is really just a &lt;em&gt;wish&lt;/em&gt;—but one with a powerful tendency to self-fulfill. This idea animates Carissa Véliz’s wonderfully wide-ranging polemic &lt;em&gt;Prophecy: Prediction, Power, and the Fight for the Future, from Ancient Oracles to AI&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A philosopher at the University of Oxford, Véliz sees a prediction as “a magnet that bends reality toward itself.” She writes, “When the force of the magnet is strong enough, the prediction becomes the cause of its becoming true.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Take Gordon Moore. While he doesn’t come up in &lt;em&gt;Prophecy&lt;/em&gt;, he does figure somewhat prominently in Recht’s history of mathematical rationality. A cofounder of the tech giant Intel, Moore is famous for his 1965 prediction that the density of transistors in integrated circuits would double every two years. “Moore’s Law” turned out to be true, and remains true today, although it does seem to be running out of steam thanks to the physical size limits of the silicon atom.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;One story you can tell yourself about Moore’s Law is that Gordon was just a prescient guy. His now-classic 1965 opinion piece “Cramming More Components onto Integrated Circuits,” for &lt;em&gt;Electronics&lt;/em&gt; magazine, simply extrapolated what computing trends might mean for the future of the semiconductor industry.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Another story—the one I’m guessing Véliz might tell—is that Moore put an informed prediction out into the world, and an entire industry had a collective interest in making it come true. As Recht makes clear, there were and remain obvious financial incentives for companies to make faster and smaller computer chips. And while the industry has likely spent billions of dollars trying to keep Moore’s Law alive, it’s undoubtedly profited even more from it. Moore’s Law was a helluva strong magnet.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Predictions don’t just have a habit of making themselves come true, says Véliz. They can also distract us from the challenges of the here and now. When an AI boomer promises that artificial general intelligence will be the last problem humanity needs to solve, it not only shapes how we think about AI’s role in our lives; it also shifts our attention away from the very real and very pressing problems of the present day—problems that in many cases AI is causing.&lt;/p&gt; 
 &lt;p&gt;In this sense, the questions around predictions (Who’s making them? Who has the right to make them?) are also fundamentally about power. It’s no accident, Véliz says, that the societies that rely most heavily on prediction are also the ones that tend toward oppression and authoritarianism. Predictions are “veiled prescriptive assertions—they tell us how to act,” she writes. “They are what philosophers call speech &lt;em&gt;acts&lt;/em&gt;. When we believe a prediction and act in accordance with it, it’s akin to obeying an order.”&lt;/p&gt;  &lt;p&gt;As much as tech companies would like us to believe otherwise, technology is not destiny. Humans make it and choose how to use it … or not use it. Maybe the most appropriate (and human) thing we can do in the face of all the uninvited daily predictions in our lives is to simply defy them.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Bryan Gardiner is a writer based in Oakland, California.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/18/1132579/robots-predict-future-book-review/</guid><pubDate>Wed, 18 Feb 2026 11:00:00 +0000</pubDate></item><item><title>Infosys AI implementation framework offers business leaders guidance (AI News)</title><link>https://www.artificialintelligence-news.com/news/infosys-ai-implementation-framework-offers-business-leaders-guidance/</link><description>&lt;p&gt;Although business leaders may be already in partnership with alternative service providers other than Infosys, the company’s strategy of demarcating the necessary action areas for AI implementations offers significant value. The six areas described provide practical reference points that can be used in any organisation to plan projects or perhaps monitor and assess ongoing implementation efforts.&lt;/p&gt;&lt;p&gt;Among these, data preparation is central. AI systems depend on data quality and consistency, so investment in data platforms, data governance, and engineering practices that support models is central tenet on which AI initiatives are built.&lt;/p&gt;&lt;p&gt;Embedding AI into workflows means it’s sometimes necessary to redesign the way employees work. Leaders should be aware of how AI agents and employees interact, and measure performance improvements. Changes can be made both to the technologies deployed and the working methods that have existed to date. If the latter, retraining and educating affected employees will be necessary, with accompanying costs.&lt;/p&gt;&lt;p&gt;The issue of legacy systems requires careful attention as many organisations operate complex estates that limit the agility necessary for AI to improve operations. AI tools themselves can help to analyse existing dependencies and even plan modernisation, implemented, ideally, over several stages or in separate sprints.&lt;/p&gt;&lt;p&gt;Physical operations intersect increasingly with digital systems. For companies with physical products, such as in manufacturing or logistics, embedding AI into devices and equipment can improve monitoring and devices’ responsiveness. This will require coordination between IT, OT, engineering, and operational teams, and line-of-business leaders should be consulted in particular.&lt;/p&gt;&lt;p&gt;Governance should accompany any scale of AI implementation. Risk assessment, security testing, security policy formulation, and the design of AI-specific guardrails should be established early on. Regulatory scrutiny of AI is increasing, particularly in sectors handling sensitive data, and statutory penalties apply for data loss or mismanagement, regardless of its source – AI or otherwise – in the enterprise. Clear accountability structures and documentation reduce these risks to operations and reputation.&lt;/p&gt;&lt;p&gt;Taken together, these areas indicate that AI implementation is organisational rather than purely technical. Success depends on leadership alignment, sustained investment, and realistic assessment of any capability gaps. Claims of rapid transformation should be treated cautiously, and durable results are more likely when strategy, data, process design, modernisation, operational integration, and governance are addressed in parallel.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Infosys, Bangalore, India” by theqspeaks is licensed under CC BY-NC-SA 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Although business leaders may be already in partnership with alternative service providers other than Infosys, the company’s strategy of demarcating the necessary action areas for AI implementations offers significant value. The six areas described provide practical reference points that can be used in any organisation to plan projects or perhaps monitor and assess ongoing implementation efforts.&lt;/p&gt;&lt;p&gt;Among these, data preparation is central. AI systems depend on data quality and consistency, so investment in data platforms, data governance, and engineering practices that support models is central tenet on which AI initiatives are built.&lt;/p&gt;&lt;p&gt;Embedding AI into workflows means it’s sometimes necessary to redesign the way employees work. Leaders should be aware of how AI agents and employees interact, and measure performance improvements. Changes can be made both to the technologies deployed and the working methods that have existed to date. If the latter, retraining and educating affected employees will be necessary, with accompanying costs.&lt;/p&gt;&lt;p&gt;The issue of legacy systems requires careful attention as many organisations operate complex estates that limit the agility necessary for AI to improve operations. AI tools themselves can help to analyse existing dependencies and even plan modernisation, implemented, ideally, over several stages or in separate sprints.&lt;/p&gt;&lt;p&gt;Physical operations intersect increasingly with digital systems. For companies with physical products, such as in manufacturing or logistics, embedding AI into devices and equipment can improve monitoring and devices’ responsiveness. This will require coordination between IT, OT, engineering, and operational teams, and line-of-business leaders should be consulted in particular.&lt;/p&gt;&lt;p&gt;Governance should accompany any scale of AI implementation. Risk assessment, security testing, security policy formulation, and the design of AI-specific guardrails should be established early on. Regulatory scrutiny of AI is increasing, particularly in sectors handling sensitive data, and statutory penalties apply for data loss or mismanagement, regardless of its source – AI or otherwise – in the enterprise. Clear accountability structures and documentation reduce these risks to operations and reputation.&lt;/p&gt;&lt;p&gt;Taken together, these areas indicate that AI implementation is organisational rather than purely technical. Success depends on leadership alignment, sustained investment, and realistic assessment of any capability gaps. Claims of rapid transformation should be treated cautiously, and durable results are more likely when strategy, data, process design, modernisation, operational integration, and governance are addressed in parallel.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Infosys, Bangalore, India” by theqspeaks is licensed under CC BY-NC-SA 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/infosys-ai-implementation-framework-offers-business-leaders-guidance/</guid><pubDate>Wed, 18 Feb 2026 11:08:00 +0000</pubDate></item><item><title>Indian AI lab Sarvam’s new models are a major bet on the viability of open source AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Indian AI lab Sarvam on Tuesday unveiled a new generation of large language models, as it bets that smaller, efficient open source AI models will be able to grab some market share away from more expensive systems offered by its much larger U.S. and Chinese rivals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch, announced at the India AI Impact Summit in New Delhi, aligns with New Delhi’s push to reduce reliance on foreign AI platforms and tailor models to local languages and use cases.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sarvam said the new lineup includes 30-billion- and 105-billion-parameter models; a text-to-speech model; a speech-to-text model; and a vision model to parse documents. These mark a sharp upgrade from the company’s 2-billion-parameter Sarvam 1 model that it released in October 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The 30-billion- and 105-billion-parameter models use a mixture-of-experts architecture, which activates only a fraction of their total parameters at a time, significantly reducing computing costs, Sarvam said. The 30B model supports a 32,000-token context window aimed at real-time conversational use, while the larger model offers a 128,000-token window for more complex, multi-step reasoning tasks.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093891" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/sarvam-30b.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sarvam’s 30B model is placed against Google’s Gemma 27B and OpenAI’s GPT-OSS-20B, among other models.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sarvam&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Sarvam said the new AI models were trained from scratch rather than fine-tuned on existing open source systems. The 30B model was pre-trained on about 16 trillion tokens of text, while the 105B model was trained on trillions of tokens spanning multiple Indian languages, it said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The models are designed to support real-time applications, the startup said, including voice-based assistants and chat systems in Indian languages. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093892" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/sarvam-105b.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sarvam’s 105B is touted to compete against OpenAI’s GPT-OSS-120B and Alibaba’s Qwen-3-Next-80B.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sarvam&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The startup said the models were trained using computing resources provided under India’s government-backed IndiaAI Mission, with infrastructure support from data center operator Yotta and technical support from Nvidia.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Sarvam executives said the company plans to take a measured approach to scaling its models, focusing on real-world applications rather than raw size.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to be mindful in how we do the scaling,” Sarvam co-founder Pratyush Kumar said at the launch. “We don’t want to do the scaling mindlessly. We want to understand the tasks which really matter at scale and go and build for them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sarvam said it plans to open source the 30B and 105B models, though it did not specify whether the training data or full training code would also be made public.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also outlined plans to build specialized AI systems, including coding-focused models and enterprise tools under a product it calls Sarvam for Work, and a conversational AI agent platform called Samvaad. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2023, Sarvam has raised more than $50 million in funding and counts Lightspeed Venture Partners, Khosla Ventures, and Peak XV Partners (formerly Sequoia Capital India) among its investors.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Indian AI lab Sarvam on Tuesday unveiled a new generation of large language models, as it bets that smaller, efficient open source AI models will be able to grab some market share away from more expensive systems offered by its much larger U.S. and Chinese rivals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch, announced at the India AI Impact Summit in New Delhi, aligns with New Delhi’s push to reduce reliance on foreign AI platforms and tailor models to local languages and use cases.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sarvam said the new lineup includes 30-billion- and 105-billion-parameter models; a text-to-speech model; a speech-to-text model; and a vision model to parse documents. These mark a sharp upgrade from the company’s 2-billion-parameter Sarvam 1 model that it released in October 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The 30-billion- and 105-billion-parameter models use a mixture-of-experts architecture, which activates only a fraction of their total parameters at a time, significantly reducing computing costs, Sarvam said. The 30B model supports a 32,000-token context window aimed at real-time conversational use, while the larger model offers a 128,000-token window for more complex, multi-step reasoning tasks.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093891" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/sarvam-30b.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sarvam’s 30B model is placed against Google’s Gemma 27B and OpenAI’s GPT-OSS-20B, among other models.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sarvam&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Sarvam said the new AI models were trained from scratch rather than fine-tuned on existing open source systems. The 30B model was pre-trained on about 16 trillion tokens of text, while the 105B model was trained on trillions of tokens spanning multiple Indian languages, it said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The models are designed to support real-time applications, the startup said, including voice-based assistants and chat systems in Indian languages. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093892" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/sarvam-105b.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sarvam’s 105B is touted to compete against OpenAI’s GPT-OSS-120B and Alibaba’s Qwen-3-Next-80B.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sarvam&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The startup said the models were trained using computing resources provided under India’s government-backed IndiaAI Mission, with infrastructure support from data center operator Yotta and technical support from Nvidia.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Sarvam executives said the company plans to take a measured approach to scaling its models, focusing on real-world applications rather than raw size.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want to be mindful in how we do the scaling,” Sarvam co-founder Pratyush Kumar said at the launch. “We don’t want to do the scaling mindlessly. We want to understand the tasks which really matter at scale and go and build for them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sarvam said it plans to open source the 30B and 105B models, though it did not specify whether the training data or full training code would also be made public.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also outlined plans to build specialized AI systems, including coding-focused models and enterprise tools under a product it calls Sarvam for Work, and a conversational AI agent platform called Samvaad. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2023, Sarvam has raised more than $50 million in funding and counts Lightspeed Venture Partners, Khosla Ventures, and Peak XV Partners (formerly Sequoia Capital India) among its investors.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/18/indian-ai-lab-sarvams-new-models-are-a-major-bet-on-the-viability-of-open-source-ai/</guid><pubDate>Wed, 18 Feb 2026 12:55:20 +0000</pubDate></item><item><title>India’s Sarvam wants to bring its AI models to feature phones, cars, and smart glasses (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/sarvam-launch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Indian AI company Sarvam plans to bring its newly released AI models to users by deploying them on Nokia feature phones, cars, and its own smart glasses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company, backed by the likes of Lightspeed, Peak XV, and Khosla Ventures, said at the ongoing India AI Impact Summit in New Delhi that it is using edge models that take up only megabytes of space, can run on most phones with existing processors, and can work offline.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is teaming up with HMD to bring a conversational AI assistant to Nokia and HMD phones. A video demo showed a user clicking a dedicated AI button on a feature phone to converse with an AI assistant in a local language to get guidance on government schemes or local markets. It is not clear if all the AI features showcased at the event will work offline.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Through edge AI, we want to bring intelligence to every phone, laptop, car, and even a new generation of devices,” Tushar Goswamy, head of Edge AI at Sarvam, said during a presentation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said that the company has worked with Qualcomm to tune its models for the latter’s chipsets. Sarvam didn’t provide details on which devices the models will be deployed to. Qualcomm said that it is developing a “Sovereign AI Experience Suite” that would work across a range of devices, including phones, PCs, laptops, cars, and IoT devices. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our collaboration with Qualcomm Technologies can accelerate how we take sovereign AI from research to deployment,” Sarvam co-founder and CEO Vivek Raghavan said in a statement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This will allow Sarvam to design models and applications that run closer to the edge, safeguard data, and are ready for adoption, at scale.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Sarvam also said it is working with German engineering giant Bosch to bring AI assistants to cars, though it didn’t disclose many other details.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup also showed off a pair of AI smart-glasses, dubbed Sarvam Kaze, designed and manufactured in India. The company’s co-founder, Pratyush Kumar, said the glasses are a “builders’ device” and will be available in May.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sarvam has so far operated largely in the enterprise market, offering its voice-focused models for use cases like customer support. The new models and partnerships indicate the company is shifting its focus towards consumer use cases.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/sarvam-launch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Indian AI company Sarvam plans to bring its newly released AI models to users by deploying them on Nokia feature phones, cars, and its own smart glasses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company, backed by the likes of Lightspeed, Peak XV, and Khosla Ventures, said at the ongoing India AI Impact Summit in New Delhi that it is using edge models that take up only megabytes of space, can run on most phones with existing processors, and can work offline.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is teaming up with HMD to bring a conversational AI assistant to Nokia and HMD phones. A video demo showed a user clicking a dedicated AI button on a feature phone to converse with an AI assistant in a local language to get guidance on government schemes or local markets. It is not clear if all the AI features showcased at the event will work offline.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Through edge AI, we want to bring intelligence to every phone, laptop, car, and even a new generation of devices,” Tushar Goswamy, head of Edge AI at Sarvam, said during a presentation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said that the company has worked with Qualcomm to tune its models for the latter’s chipsets. Sarvam didn’t provide details on which devices the models will be deployed to. Qualcomm said that it is developing a “Sovereign AI Experience Suite” that would work across a range of devices, including phones, PCs, laptops, cars, and IoT devices. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our collaboration with Qualcomm Technologies can accelerate how we take sovereign AI from research to deployment,” Sarvam co-founder and CEO Vivek Raghavan said in a statement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This will allow Sarvam to design models and applications that run closer to the edge, safeguard data, and are ready for adoption, at scale.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Sarvam also said it is working with German engineering giant Bosch to bring AI assistants to cars, though it didn’t disclose many other details.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup also showed off a pair of AI smart-glasses, dubbed Sarvam Kaze, designed and manufactured in India. The company’s co-founder, Pratyush Kumar, said the glasses are a “builders’ device” and will be available in May.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sarvam has so far operated largely in the enterprise market, offering its voice-focused models for use cases like customer support. The new models and partnerships indicate the company is shifting its focus towards consumer use cases.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/18/indias-sarvam-wants-to-bring-its-ai-models-to-feature-phones-cars-and-smart-glasses/</guid><pubDate>Wed, 18 Feb 2026 13:01:04 +0000</pubDate></item><item><title>[NEW] The Download: a blockchain enigma, and the algorithms governing our lives (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/18/1133291/the-download-a-blockchain-enigma-and-the-algorithms-governing-our-lives/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Welcome to the dark side of crypto’s permissionless dream&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Jean-Paul Thorbjornsen, an Australian man in his mid-30s, with a rural Catholic upbringing, is a founder of THORChain, a blockchain through which users can swap one cryptocurrency for another and earn fees from making those swaps.&lt;/p&gt;&lt;p&gt;THORChain is permissionless, so anyone can use it without getting prior approval from a centralized authority. As a decentralized network, the blockchain is built and run by operators located across the globe. During its early days, Thorbjornsen himself hid behind the pseudonym “leena” and used an AI-generated female image as his avatar. But around March 2024, he revealed his true identity as the mind behind the blockchain. More or less.&lt;/p&gt;  &lt;p&gt;If there is a central question around THORChain, it is this: Exactly who is responsible for its operations? It matters because in January last year, its users lost more than $200 million worth of their cryptocurrency in US dollars after THORChain transactions and accounts were frozen by a singular admin override, which users believed was not supposed to be possible given the decentralized structure.&lt;/p&gt;&lt;p&gt;Thorbjornsen insists THORChain is helping realize bitcoin’s original purpose of enabling anyone to transact freely outside the reach of purportedly corrupt governments. Yet the network’s problems suggest that an alternative financial system might not be much better.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jessica Klein&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The robots who predict the future&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;To be human is, fundamentally, to be a forecaster. Occasionally a pretty good one. Trying to see the future, whether through the lens of past experience or the logic of cause and effect, has helped us hunt, avoid &lt;em&gt;being&lt;/em&gt; hunted, plant crops, forge social bonds, and in general survive in a world that does not prioritize our survival.&lt;/p&gt;  &lt;p&gt;Today, we are awash in a sea of predictions so vast and unrelenting that most of us barely even register them. People’s desire for reliable forecasting is understandable. Still, nobody signed up for an omnipresent, algorithmic oracle mediating every aspect of their life. A trio of new books tries to make sense of our future-­focused world—how we got here, and what this change means. Each has its own prescriptions for navigating this new reality, but they all agree on one thing: Predictions are ultimately about power and control. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Bryan Gardiner&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;These stories are both from the next print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazine, which is all about crime. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: Stratospheric internet could finally start taking off this year&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Today, an estimated 2.2 billion people still have either limited or no access to the internet, largely because they live in remote places. But that number could drop this year, thanks to tests of stratospheric airships, uncrewed aircraft, and other high-altitude platforms for internet delivery.&lt;/p&gt;&lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt; 

   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Mark Zuckerberg is due to give evidence in a major social media addiction trial&lt;/strong&gt;&lt;br /&gt;He’ll face questioning over whether Meta does enough to protect young users. (CNN)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Perplexity has abandoned ads inside its chatbot responses&lt;br /&gt;&lt;/strong&gt;Because advertising can erode trust in AI, it reasons. (FT $)&lt;br /&gt;+ &lt;em&gt;It’s a pretty big U-turn considering its previous stance. &lt;/em&gt;(The Verge)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 The US is being battered by a range of wild weather&lt;/strong&gt;&lt;br /&gt;From critical wildfire risks in some states, to winter storms in others. (WP $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 Microsoft plans to spend $50 billion bringing AI to the Global South by 2030&lt;br /&gt;India is one of the fastest growing markets for the technology. (Reuters)&lt;br /&gt;+ &lt;em&gt;One native startup has announced a new AI model for 22 Indian languages. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Inside India’s scramble for AI independence. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;5 AI-powered private schools are failing students&lt;br /&gt;&lt;/strong&gt;Models are being used to generate faulty lesson plans. (404 Media)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Land owners are selling out to data center builders&lt;br /&gt;&lt;/strong&gt;Land previously earmarked for housing is being sold off to the highest bidder. (WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Tesla has agreed to stop using the term “autopilot” in California&lt;/strong&gt;&lt;br /&gt;The DMV had previously also questioned its use of “Full Self-Driving.” (SF Chronicle $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 A new weight-loss drug may work a little &lt;em&gt;too &lt;/em&gt;well&lt;br /&gt;&lt;/strong&gt;Participants in a trial are dropping out at a much higher rate than normal. (NYT $)&lt;br /&gt;+ &lt;em&gt;Intermittent fasting may not help us to shed the pounds after all. &lt;/em&gt;(New Scientist $)&lt;br /&gt;+ &lt;em&gt;What we still don’t know about weight-loss drugs. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;9 Is anyone still using Grindr?&lt;/strong&gt;&lt;br /&gt;Bots and AI have rendered it virtually unusable for some people. (Vox)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 How to hack your dreams&lt;/strong&gt;&lt;br /&gt;Neuroscientists are figuring out new ways to influence what we dream about. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;I taught myself to lucid dream. You can too. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I voted for this administration and didn’t really think about [AI] until it started to affect me.”&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;—Lisa Garrett, a grandmother living in the city of Independence, Missouri, reflects on the Trump administration’s decision to embrace AI, the Financial Times reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133293" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_a87ef6.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Hydrogen trains could revolutionize how Americans get around&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Like a mirage speeding across the dusty desert outside Pueblo, Colorado, the first hydrogen-fuel-cell passenger train in the United States is getting warmed up on its test track. It will soon be shipped to Southern California, where it is slated to carry riders on San Bernardino County’s Arrow commuter rail service before the end of the year.&lt;/p&gt;&lt;p&gt;The best way to decarbonize railroads is the subject of growing debate among regulators, industry, and activists. The debate is partly technological, revolving around whether hydrogen fuel cells, batteries, or overhead electric wires offer the best performance for different railroad situations. But it’s also political: a question of the extent to which decarbonization can, or should, usher in a broader transformation of rail transportation.&lt;/p&gt;&lt;p&gt;In the insular world of railroading, this hydrogen-powered train is a Rorschach test. To some, it represents the future of rail transportation. To others, it looks like a big, shiny distraction. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Benjamin Schneider&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ How to quickly declutter your home by being brutally honest with yourself.&lt;br /&gt;+ The filming locations for &lt;em&gt;A Knight of the Seven Kingdoms &lt;/em&gt;are pretty breathtaking.&lt;br /&gt;+ Why a unicyclist decided to start juggling flaming torches in the middle of a Colorado pedestrian crossing is anyone guess, but good luck to him.&lt;br /&gt;+ How pepper took over the world (deservedly)&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Welcome to the dark side of crypto’s permissionless dream&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Jean-Paul Thorbjornsen, an Australian man in his mid-30s, with a rural Catholic upbringing, is a founder of THORChain, a blockchain through which users can swap one cryptocurrency for another and earn fees from making those swaps.&lt;/p&gt;&lt;p&gt;THORChain is permissionless, so anyone can use it without getting prior approval from a centralized authority. As a decentralized network, the blockchain is built and run by operators located across the globe. During its early days, Thorbjornsen himself hid behind the pseudonym “leena” and used an AI-generated female image as his avatar. But around March 2024, he revealed his true identity as the mind behind the blockchain. More or less.&lt;/p&gt;  &lt;p&gt;If there is a central question around THORChain, it is this: Exactly who is responsible for its operations? It matters because in January last year, its users lost more than $200 million worth of their cryptocurrency in US dollars after THORChain transactions and accounts were frozen by a singular admin override, which users believed was not supposed to be possible given the decentralized structure.&lt;/p&gt;&lt;p&gt;Thorbjornsen insists THORChain is helping realize bitcoin’s original purpose of enabling anyone to transact freely outside the reach of purportedly corrupt governments. Yet the network’s problems suggest that an alternative financial system might not be much better.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jessica Klein&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The robots who predict the future&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;To be human is, fundamentally, to be a forecaster. Occasionally a pretty good one. Trying to see the future, whether through the lens of past experience or the logic of cause and effect, has helped us hunt, avoid &lt;em&gt;being&lt;/em&gt; hunted, plant crops, forge social bonds, and in general survive in a world that does not prioritize our survival.&lt;/p&gt;  &lt;p&gt;Today, we are awash in a sea of predictions so vast and unrelenting that most of us barely even register them. People’s desire for reliable forecasting is understandable. Still, nobody signed up for an omnipresent, algorithmic oracle mediating every aspect of their life. A trio of new books tries to make sense of our future-­focused world—how we got here, and what this change means. Each has its own prescriptions for navigating this new reality, but they all agree on one thing: Predictions are ultimately about power and control. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Bryan Gardiner&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;These stories are both from the next print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazine, which is all about crime. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: Stratospheric internet could finally start taking off this year&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Today, an estimated 2.2 billion people still have either limited or no access to the internet, largely because they live in remote places. But that number could drop this year, thanks to tests of stratospheric airships, uncrewed aircraft, and other high-altitude platforms for internet delivery.&lt;/p&gt;&lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt; 

   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Mark Zuckerberg is due to give evidence in a major social media addiction trial&lt;/strong&gt;&lt;br /&gt;He’ll face questioning over whether Meta does enough to protect young users. (CNN)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Perplexity has abandoned ads inside its chatbot responses&lt;br /&gt;&lt;/strong&gt;Because advertising can erode trust in AI, it reasons. (FT $)&lt;br /&gt;+ &lt;em&gt;It’s a pretty big U-turn considering its previous stance. &lt;/em&gt;(The Verge)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 The US is being battered by a range of wild weather&lt;/strong&gt;&lt;br /&gt;From critical wildfire risks in some states, to winter storms in others. (WP $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 Microsoft plans to spend $50 billion bringing AI to the Global South by 2030&lt;br /&gt;India is one of the fastest growing markets for the technology. (Reuters)&lt;br /&gt;+ &lt;em&gt;One native startup has announced a new AI model for 22 Indian languages. &lt;/em&gt;(Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Inside India’s scramble for AI independence. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;5 AI-powered private schools are failing students&lt;br /&gt;&lt;/strong&gt;Models are being used to generate faulty lesson plans. (404 Media)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Land owners are selling out to data center builders&lt;br /&gt;&lt;/strong&gt;Land previously earmarked for housing is being sold off to the highest bidder. (WSJ $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Tesla has agreed to stop using the term “autopilot” in California&lt;/strong&gt;&lt;br /&gt;The DMV had previously also questioned its use of “Full Self-Driving.” (SF Chronicle $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 A new weight-loss drug may work a little &lt;em&gt;too &lt;/em&gt;well&lt;br /&gt;&lt;/strong&gt;Participants in a trial are dropping out at a much higher rate than normal. (NYT $)&lt;br /&gt;+ &lt;em&gt;Intermittent fasting may not help us to shed the pounds after all. &lt;/em&gt;(New Scientist $)&lt;br /&gt;+ &lt;em&gt;What we still don’t know about weight-loss drugs. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;9 Is anyone still using Grindr?&lt;/strong&gt;&lt;br /&gt;Bots and AI have rendered it virtually unusable for some people. (Vox)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 How to hack your dreams&lt;/strong&gt;&lt;br /&gt;Neuroscientists are figuring out new ways to influence what we dream about. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;I taught myself to lucid dream. You can too. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I voted for this administration and didn’t really think about [AI] until it started to affect me.”&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;—Lisa Garrett, a grandmother living in the city of Independence, Missouri, reflects on the Trump administration’s decision to embrace AI, the Financial Times reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1133293" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/image_a87ef6.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Hydrogen trains could revolutionize how Americans get around&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Like a mirage speeding across the dusty desert outside Pueblo, Colorado, the first hydrogen-fuel-cell passenger train in the United States is getting warmed up on its test track. It will soon be shipped to Southern California, where it is slated to carry riders on San Bernardino County’s Arrow commuter rail service before the end of the year.&lt;/p&gt;&lt;p&gt;The best way to decarbonize railroads is the subject of growing debate among regulators, industry, and activists. The debate is partly technological, revolving around whether hydrogen fuel cells, batteries, or overhead electric wires offer the best performance for different railroad situations. But it’s also political: a question of the extent to which decarbonization can, or should, usher in a broader transformation of rail transportation.&lt;/p&gt;&lt;p&gt;In the insular world of railroading, this hydrogen-powered train is a Rorschach test. To some, it represents the future of rail transportation. To others, it looks like a big, shiny distraction. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Benjamin Schneider&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ How to quickly declutter your home by being brutally honest with yourself.&lt;br /&gt;+ The filming locations for &lt;em&gt;A Knight of the Seven Kingdoms &lt;/em&gt;are pretty breathtaking.&lt;br /&gt;+ Why a unicyclist decided to start juggling flaming torches in the middle of a Colorado pedestrian crossing is anyone guess, but good luck to him.&lt;br /&gt;+ How pepper took over the world (deservedly)&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/18/1133291/the-download-a-blockchain-enigma-and-the-algorithms-governing-our-lives/</guid><pubDate>Wed, 18 Feb 2026 13:10:00 +0000</pubDate></item><item><title>[NEW] OpenAI pushes into higher education as India seeks to scale AI skills (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/18/openai-pushes-into-higher-education-as-india-seeks-to-scale-ai-skills/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/openai-india.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is expanding its footprint in India and moving into the country’s higher-education system through partnerships with leading academic institutions. The move comes as the South Asian nation seeks to scale AI skills and build domestic capacity in one of the world’s largest talent markets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Wednesday, OpenAI said it was partnering with six public and private higher-education institutions in India, including top engineering, management, medical, and design-focused institutes, with the aim of reaching more than 100,000 students, faculty, and staff over the next year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Rather than focusing on consumer use, the initiative centers on integrating AI into core academic functions, signaling OpenAI’s interest in influencing how AI is taught, governed, and normalized within one of the world’s largest higher-education systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has already built a large consumer audience for its ChatGPT chatbot, which has over 100 million monthly active users in India, according to CEO Sam Altman, and India has emerged as the company’s second-largest user base after the U.S. The announcement also coincides with a broader push by leading AI firms to deepen their presence in India, which is hosting an AI Impact Summit in New Delhi this week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The first cohort of partners includes some of India’s most influential academic institutions, such as the Indian Institute of Technology Delhi, the Indian Institute of Management Ahmedabad, and the All India Institute of Medical Sciences New Delhi, alongside private universities and specialized design schools. The ChatGPT maker said the partnerships would span disciplines ranging from engineering and management to healthcare and creative fields.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India has already emerged as a key testing ground for AI use in education. Last month, Google said India accounts for the highest global usage of its Gemini tools for learning. Microsoft, similarly, said this week it would expand its Elevate skilling program in India to train teachers across schools, vocational institutes, and higher-education settings, working with government agencies as part of a broader push to build AI skills at scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said the partnerships would involve campus-wide access to its ChatGPT Edu tools, faculty training, and responsible-use frameworks. The focus, the company said, is on embedding AI into core academic workflows such as coding, research, analytics, and case analysis, rather than offering standalone access to tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two of the partner institutions, the Indian Institute of Management Ahmedabad and Manipal Academy of Higher Education, will also introduce OpenAI-backed certifications. Additionally, OpenAI said it would work with Indian ed-tech platforms, including Physics Wallah, upGrad, and HCL GUVI, to extend AI training beyond campuses. These platforms will launch structured courses on AI fundamentals and ChatGPT use cases, aimed at students and early-career professionals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Raghav Gupta, head of education at OpenAI India, said educational institutions were a “critical route” to closing the gap between rapidly advancing AI tools and how people are actually using them, as skills demands shift across the economy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, OpenAI hired Gupta, a former Coursera Asia-Pacific managing director, as its India and Asia-Pacific head of education, alongside the launch of a Learning Accelerator program focused on expanding AI skills.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The flurry of moves into education underscores how AI companies are increasingly looking beyond consumer tools and corporate clients toward institutions that shape skills, norms, and long-term adoption. For countries like India, the contest is not just around access to AI, but also about who helps define how it is taught, governed, and embedded at scale.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/openai-india.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is expanding its footprint in India and moving into the country’s higher-education system through partnerships with leading academic institutions. The move comes as the South Asian nation seeks to scale AI skills and build domestic capacity in one of the world’s largest talent markets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Wednesday, OpenAI said it was partnering with six public and private higher-education institutions in India, including top engineering, management, medical, and design-focused institutes, with the aim of reaching more than 100,000 students, faculty, and staff over the next year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Rather than focusing on consumer use, the initiative centers on integrating AI into core academic functions, signaling OpenAI’s interest in influencing how AI is taught, governed, and normalized within one of the world’s largest higher-education systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has already built a large consumer audience for its ChatGPT chatbot, which has over 100 million monthly active users in India, according to CEO Sam Altman, and India has emerged as the company’s second-largest user base after the U.S. The announcement also coincides with a broader push by leading AI firms to deepen their presence in India, which is hosting an AI Impact Summit in New Delhi this week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The first cohort of partners includes some of India’s most influential academic institutions, such as the Indian Institute of Technology Delhi, the Indian Institute of Management Ahmedabad, and the All India Institute of Medical Sciences New Delhi, alongside private universities and specialized design schools. The ChatGPT maker said the partnerships would span disciplines ranging from engineering and management to healthcare and creative fields.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India has already emerged as a key testing ground for AI use in education. Last month, Google said India accounts for the highest global usage of its Gemini tools for learning. Microsoft, similarly, said this week it would expand its Elevate skilling program in India to train teachers across schools, vocational institutes, and higher-education settings, working with government agencies as part of a broader push to build AI skills at scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said the partnerships would involve campus-wide access to its ChatGPT Edu tools, faculty training, and responsible-use frameworks. The focus, the company said, is on embedding AI into core academic workflows such as coding, research, analytics, and case analysis, rather than offering standalone access to tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Two of the partner institutions, the Indian Institute of Management Ahmedabad and Manipal Academy of Higher Education, will also introduce OpenAI-backed certifications. Additionally, OpenAI said it would work with Indian ed-tech platforms, including Physics Wallah, upGrad, and HCL GUVI, to extend AI training beyond campuses. These platforms will launch structured courses on AI fundamentals and ChatGPT use cases, aimed at students and early-career professionals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Raghav Gupta, head of education at OpenAI India, said educational institutions were a “critical route” to closing the gap between rapidly advancing AI tools and how people are actually using them, as skills demands shift across the economy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, OpenAI hired Gupta, a former Coursera Asia-Pacific managing director, as its India and Asia-Pacific head of education, alongside the launch of a Learning Accelerator program focused on expanding AI skills.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The flurry of moves into education underscores how AI companies are increasingly looking beyond consumer tools and corporate clients toward institutions that shape skills, norms, and long-term adoption. For countries like India, the contest is not just around access to AI, but also about who helps define how it is taught, governed, and embedded at scale.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/18/openai-pushes-into-higher-education-as-india-seeks-to-scale-ai-skills/</guid><pubDate>Wed, 18 Feb 2026 14:32:42 +0000</pubDate></item><item><title>[NEW] Microsoft says Office bug exposed customers’ confidential emails to Copilot AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/18/microsoft-says-office-bug-exposed-customers-confidential-emails-to-copilot-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/04/GettyImages-2041281128-e1712563728365.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft has confirmed that a bug allowed its Copilot AI to summarize customers’ confidential emails for weeks without permission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bug, first reported by Bleeping Computer, allowed Copilot Chat to read and outline the contents of emails since January, even if customers had data loss prevention policies to prevent ingesting their sensitive information into Microsoft’s large language model.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Copilot Chat allows paying Microsoft 365 customers to use the AI-powered chat feature in its Office software products, including Word, Excel, and PowerPoint.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft said the bug, trackable by admins as CW1226324, means that draft and sent email messages “with a confidential label applied are being incorrectly processed by Microsoft 365 Copilot chat.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant said it began rolling out a fix for the bug earlier in February. A spokesperson for Microsoft did not respond to a request for comment, including a question about how many customers are affected by the bug.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this week, the European Parliament’s IT department told lawmakers that it blocked the built-in AI features on their work-issued devices, citing concerns that the AI tools could upload potentially confidential correspondence to the cloud.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/04/GettyImages-2041281128-e1712563728365.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft has confirmed that a bug allowed its Copilot AI to summarize customers’ confidential emails for weeks without permission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bug, first reported by Bleeping Computer, allowed Copilot Chat to read and outline the contents of emails since January, even if customers had data loss prevention policies to prevent ingesting their sensitive information into Microsoft’s large language model.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Copilot Chat allows paying Microsoft 365 customers to use the AI-powered chat feature in its Office software products, including Word, Excel, and PowerPoint.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft said the bug, trackable by admins as CW1226324, means that draft and sent email messages “with a confidential label applied are being incorrectly processed by Microsoft 365 Copilot chat.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant said it began rolling out a fix for the bug earlier in February. A spokesperson for Microsoft did not respond to a request for comment, including a question about how many customers are affected by the bug.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this week, the European Parliament’s IT department told lawmakers that it blocked the built-in AI features on their work-issued devices, citing concerns that the AI tools could upload potentially confidential correspondence to the cloud.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/18/microsoft-says-office-bug-exposed-customers-confidential-emails-to-copilot-ai/</guid><pubDate>Wed, 18 Feb 2026 14:44:28 +0000</pubDate></item><item><title>[NEW] How financial institutions are embedding AI decision-making (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-financial-institutions-embedding-ai-decision-making/</link><description>&lt;p&gt;For leaders in the financial sector, the experimental phase of generative AI has concluded and the focus for 2026 is operational integration.&lt;/p&gt;&lt;p&gt;While early adoption centred on content generation and efficiency in isolated workflows, the current requirement is to industrialise these capabilities. The objective is to create systems where AI agents do not merely assist human operators, but actively run processes within strict governance frameworks.&lt;/p&gt;&lt;p&gt;This transition presents specific architectural and cultural challenges. It requires a move from disparate tools to joined-up systems that manage data signals, decision logic, and execution layers simultaneously.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-financial-institutions-integrate-agentic-ai-workflows"&gt;Financial institutions integrate agentic AI workflows&lt;/h3&gt;&lt;p&gt;The primary bottleneck in scaling AI within financial services is no longer the availability of models or creative application, it is coordination. Marketing and customer experience teams often struggle to convert decisions into action due to friction between legacy systems, compliance approvals, and data silos.&lt;/p&gt;&lt;p&gt;Saachin Bhatt, Co-Founder and COO at Brdge, notes the distinction between current tools and future requirements: “An assistant helps you write faster. A copilot helps teams move faster. Agents run processes.”&lt;/p&gt;&lt;p&gt;For enterprise architects, this means building what Bhatt terms a ‘Moments Engine’. This operating model functions through five distinct stages:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Signals:&lt;/strong&gt; Detecting real-time events in the customer journey.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Decisions:&lt;/strong&gt; Determining the appropriate algorithmic response.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Message:&lt;/strong&gt; Generating communication aligned with brand parameters.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Routing:&lt;/strong&gt; Automated triage to determine if human approval is required.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Action and learning:&lt;/strong&gt; Deployment and feedback loop integration.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Most organisations possess components of this architecture but lack the integration to make it function as a unified system. The technical goal is to reduce the friction that slows down customer interactions. This involves creating pipelines where data flows seamlessly from signal detection to execution, minimising latency while maintaining security.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-governance-as-infrastructure"&gt;Governance as infrastructure&lt;/h3&gt;&lt;p&gt;In high-stakes environments like banking and insurance, speed cannot come at the cost of control. Trust remains the primary commercial asset. Consequently, governance must be treated as a technical feature rather than a bureaucratic hurdle.&lt;/p&gt;&lt;p&gt;The integration of AI into financial decision-making requires “guardrails” that are hard-coded into the system. This ensures that while AI agents can execute tasks autonomously, they operate within pre-defined risk parameters.&lt;/p&gt;&lt;p&gt;Farhad Divecha, Group CEO at Accuracast, suggests that creative optimisation must become a continuous loop where data-led insights feed innovation. However, this loop requires rigorous quality assurance workflows to ensure output never compromises brand integrity.&lt;/p&gt;&lt;p&gt;For technical teams, this implies a shift in how compliance is handled. Rather than a final check, regulatory requirements must be embedded into the prompt engineering and model fine-tuning stages.&lt;/p&gt;&lt;p&gt;“Legitimate interest is interesting, but it’s also where a lot of companies could trip up,” observes Jonathan Bowyer, former Marketing Director at Lloyds Banking Group. He argues that regulations like Consumer Duty help by forcing an outcome-based approach.&lt;/p&gt;&lt;p&gt;Technical leaders must work with risk teams to ensure AI-driven activity attests to brand values. This includes transparency protocols. Customers should know when they are interacting with an AI, and systems must provide a clear escalation path to human operators.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-architecture-for-restraint"&gt;Data architecture for restraint&lt;/h3&gt;&lt;p&gt;A common failure mode in personalisation engines is over-engagement. The technical capability to message a customer exists, but the logic to determine restraint is often missing. Effective personalisation relies on anticipation (i.e. knowing when to remain silent is as important as knowing when to speak.)&lt;/p&gt;&lt;p&gt;Jonathan Bowyer points out that personalisation has moved to anticipation. “Customers now expect brands to know when not to speak to them as opposed to when to speak to them.”&lt;/p&gt;&lt;p&gt;This requires a data architecture capable of cross-referencing customer context across multiple channels – including branches, apps, and contact centres – in real-time. If a customer is in financial distress, a marketing algorithm pushing a loan product creates a disconnect that erodes trust. The system must be capable of detecting negative signals and suppressing standard promotional workflows.&lt;/p&gt;&lt;p&gt;“The thing that kills trust is when you go to one channel and then move to another and have to answer the same questions all over again,” says Bowyer. Solving this requires unifying data stores so that the “memory” of the institution is accessible to every agent (whether digital or human) at the point of interaction.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-rise-of-generative-search-and-seo"&gt;The rise of generative search and SEO&lt;/h3&gt;&lt;p&gt;In the age of AI, the discovery layer for financial products is changing. Traditional search engine optimisation (SEO) focused on driving traffic to owned properties. The emergence of AI-generated answers means that brand visibility now occurs off-site, within the interface of an LLM or AI search tool.&lt;/p&gt;&lt;p&gt;“Digital PR and off-site SEO is returning to focus because generative AI answers are not confined to content pulled directly from a company’s website,” notes Divecha.&lt;/p&gt;&lt;p&gt;For CIOs and CDOs, this changes how information is structured and published. Technical SEO must evolve to ensure that the data fed into large language models is accurate and compliant.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Organisations that can confidently distribute high-quality information across the wider ecosystem gain reach without sacrificing control. This area, often termed ‘Generative Engine Optimisation’ (GEO), requires a technical strategy to ensure the brand is recommended and cited correctly by third-party AI agents.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-structured-agility"&gt;Structured agility&lt;/h3&gt;&lt;p&gt;There is a misconception that agility equates to a lack of structure. In regulated industries, the opposite is true.&lt;/p&gt;&lt;p&gt;Agile methodologies require strict frameworks to function safely. Ingrid Sierra, Brand and Marketing Director at Zego, explains: “There’s often confusion between agility and chaos. Calling something ‘agile’ doesn’t make it okay for everything to be improvised and unstructured.”&lt;/p&gt;&lt;p&gt;For technical leadership, this means systemising predictable work to create capacity for experimentation. It involves creating safe sandboxes where teams can test new AI agents or data models without risking production stability.&lt;/p&gt;&lt;p&gt;Agility starts with mindset, requiring staff who are willing to experiment. However, this experimentation must be deliberate. It requires collaboration between technical, marketing, and legal teams from the outset.&lt;/p&gt;&lt;p&gt;This “compliance-by-design” approach allows for faster iteration because the parameters of safety are established before the code is written.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-s-next-for-ai-in-the-financial-sector"&gt;What’s next for AI in the financial sector?&lt;/h3&gt;&lt;p&gt;Looking further ahead, the financial ecosystem will likely see direct interaction between AI agents acting on behalf of consumers and agents acting for institutions.&lt;/p&gt;&lt;p&gt;Melanie Lazarus, Ecosystem Engagement Director at Open Banking, warns: “We are entering a world where AI agents interact with each other, and that changes the foundations of consent, authentication, and authorisation.”&lt;/p&gt;&lt;p&gt;Tech leaders must begin architecting frameworks that protect customers in this agent-to-agent reality. This involves new protocols for identity verification and API security to ensure that an automated financial advisor acting for a client can securely interact with a bank’s infrastructure.&lt;/p&gt;&lt;p&gt;The mandate for 2026 is to turn the potential of AI into a reliable P&amp;amp;L driver. This requires a focus on infrastructure over hype and leaders must prioritise:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Unifying data streams:&lt;/strong&gt; Ensure signals from all channels feed into a central decision engine to enable context-aware actions.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Hard-coding governance:&lt;/strong&gt; Embed compliance rules into the AI workflow to allow for safe automation.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Agentic orchestration:&lt;/strong&gt; Move beyond chatbots to agents that can execute end-to-end processes.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Generative optimisation:&lt;/strong&gt; Structure public data to be readable and prioritised by external AI search engines.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Success will depend on how well these technical elements are integrated with human oversight. The winning organisations will be those that use AI automation to enhance, rather than replace, the judgment that is especially required in sectors like financial services.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Goldman Sachs deploys Anthropic systems with success&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111908" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;For leaders in the financial sector, the experimental phase of generative AI has concluded and the focus for 2026 is operational integration.&lt;/p&gt;&lt;p&gt;While early adoption centred on content generation and efficiency in isolated workflows, the current requirement is to industrialise these capabilities. The objective is to create systems where AI agents do not merely assist human operators, but actively run processes within strict governance frameworks.&lt;/p&gt;&lt;p&gt;This transition presents specific architectural and cultural challenges. It requires a move from disparate tools to joined-up systems that manage data signals, decision logic, and execution layers simultaneously.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-financial-institutions-integrate-agentic-ai-workflows"&gt;Financial institutions integrate agentic AI workflows&lt;/h3&gt;&lt;p&gt;The primary bottleneck in scaling AI within financial services is no longer the availability of models or creative application, it is coordination. Marketing and customer experience teams often struggle to convert decisions into action due to friction between legacy systems, compliance approvals, and data silos.&lt;/p&gt;&lt;p&gt;Saachin Bhatt, Co-Founder and COO at Brdge, notes the distinction between current tools and future requirements: “An assistant helps you write faster. A copilot helps teams move faster. Agents run processes.”&lt;/p&gt;&lt;p&gt;For enterprise architects, this means building what Bhatt terms a ‘Moments Engine’. This operating model functions through five distinct stages:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Signals:&lt;/strong&gt; Detecting real-time events in the customer journey.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Decisions:&lt;/strong&gt; Determining the appropriate algorithmic response.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Message:&lt;/strong&gt; Generating communication aligned with brand parameters.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Routing:&lt;/strong&gt; Automated triage to determine if human approval is required.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Action and learning:&lt;/strong&gt; Deployment and feedback loop integration.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Most organisations possess components of this architecture but lack the integration to make it function as a unified system. The technical goal is to reduce the friction that slows down customer interactions. This involves creating pipelines where data flows seamlessly from signal detection to execution, minimising latency while maintaining security.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-governance-as-infrastructure"&gt;Governance as infrastructure&lt;/h3&gt;&lt;p&gt;In high-stakes environments like banking and insurance, speed cannot come at the cost of control. Trust remains the primary commercial asset. Consequently, governance must be treated as a technical feature rather than a bureaucratic hurdle.&lt;/p&gt;&lt;p&gt;The integration of AI into financial decision-making requires “guardrails” that are hard-coded into the system. This ensures that while AI agents can execute tasks autonomously, they operate within pre-defined risk parameters.&lt;/p&gt;&lt;p&gt;Farhad Divecha, Group CEO at Accuracast, suggests that creative optimisation must become a continuous loop where data-led insights feed innovation. However, this loop requires rigorous quality assurance workflows to ensure output never compromises brand integrity.&lt;/p&gt;&lt;p&gt;For technical teams, this implies a shift in how compliance is handled. Rather than a final check, regulatory requirements must be embedded into the prompt engineering and model fine-tuning stages.&lt;/p&gt;&lt;p&gt;“Legitimate interest is interesting, but it’s also where a lot of companies could trip up,” observes Jonathan Bowyer, former Marketing Director at Lloyds Banking Group. He argues that regulations like Consumer Duty help by forcing an outcome-based approach.&lt;/p&gt;&lt;p&gt;Technical leaders must work with risk teams to ensure AI-driven activity attests to brand values. This includes transparency protocols. Customers should know when they are interacting with an AI, and systems must provide a clear escalation path to human operators.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-data-architecture-for-restraint"&gt;Data architecture for restraint&lt;/h3&gt;&lt;p&gt;A common failure mode in personalisation engines is over-engagement. The technical capability to message a customer exists, but the logic to determine restraint is often missing. Effective personalisation relies on anticipation (i.e. knowing when to remain silent is as important as knowing when to speak.)&lt;/p&gt;&lt;p&gt;Jonathan Bowyer points out that personalisation has moved to anticipation. “Customers now expect brands to know when not to speak to them as opposed to when to speak to them.”&lt;/p&gt;&lt;p&gt;This requires a data architecture capable of cross-referencing customer context across multiple channels – including branches, apps, and contact centres – in real-time. If a customer is in financial distress, a marketing algorithm pushing a loan product creates a disconnect that erodes trust. The system must be capable of detecting negative signals and suppressing standard promotional workflows.&lt;/p&gt;&lt;p&gt;“The thing that kills trust is when you go to one channel and then move to another and have to answer the same questions all over again,” says Bowyer. Solving this requires unifying data stores so that the “memory” of the institution is accessible to every agent (whether digital or human) at the point of interaction.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-rise-of-generative-search-and-seo"&gt;The rise of generative search and SEO&lt;/h3&gt;&lt;p&gt;In the age of AI, the discovery layer for financial products is changing. Traditional search engine optimisation (SEO) focused on driving traffic to owned properties. The emergence of AI-generated answers means that brand visibility now occurs off-site, within the interface of an LLM or AI search tool.&lt;/p&gt;&lt;p&gt;“Digital PR and off-site SEO is returning to focus because generative AI answers are not confined to content pulled directly from a company’s website,” notes Divecha.&lt;/p&gt;&lt;p&gt;For CIOs and CDOs, this changes how information is structured and published. Technical SEO must evolve to ensure that the data fed into large language models is accurate and compliant.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Organisations that can confidently distribute high-quality information across the wider ecosystem gain reach without sacrificing control. This area, often termed ‘Generative Engine Optimisation’ (GEO), requires a technical strategy to ensure the brand is recommended and cited correctly by third-party AI agents.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-structured-agility"&gt;Structured agility&lt;/h3&gt;&lt;p&gt;There is a misconception that agility equates to a lack of structure. In regulated industries, the opposite is true.&lt;/p&gt;&lt;p&gt;Agile methodologies require strict frameworks to function safely. Ingrid Sierra, Brand and Marketing Director at Zego, explains: “There’s often confusion between agility and chaos. Calling something ‘agile’ doesn’t make it okay for everything to be improvised and unstructured.”&lt;/p&gt;&lt;p&gt;For technical leadership, this means systemising predictable work to create capacity for experimentation. It involves creating safe sandboxes where teams can test new AI agents or data models without risking production stability.&lt;/p&gt;&lt;p&gt;Agility starts with mindset, requiring staff who are willing to experiment. However, this experimentation must be deliberate. It requires collaboration between technical, marketing, and legal teams from the outset.&lt;/p&gt;&lt;p&gt;This “compliance-by-design” approach allows for faster iteration because the parameters of safety are established before the code is written.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-s-next-for-ai-in-the-financial-sector"&gt;What’s next for AI in the financial sector?&lt;/h3&gt;&lt;p&gt;Looking further ahead, the financial ecosystem will likely see direct interaction between AI agents acting on behalf of consumers and agents acting for institutions.&lt;/p&gt;&lt;p&gt;Melanie Lazarus, Ecosystem Engagement Director at Open Banking, warns: “We are entering a world where AI agents interact with each other, and that changes the foundations of consent, authentication, and authorisation.”&lt;/p&gt;&lt;p&gt;Tech leaders must begin architecting frameworks that protect customers in this agent-to-agent reality. This involves new protocols for identity verification and API security to ensure that an automated financial advisor acting for a client can securely interact with a bank’s infrastructure.&lt;/p&gt;&lt;p&gt;The mandate for 2026 is to turn the potential of AI into a reliable P&amp;amp;L driver. This requires a focus on infrastructure over hype and leaders must prioritise:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Unifying data streams:&lt;/strong&gt; Ensure signals from all channels feed into a central decision engine to enable context-aware actions.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Hard-coding governance:&lt;/strong&gt; Embed compliance rules into the AI workflow to allow for safe automation.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Agentic orchestration:&lt;/strong&gt; Move beyond chatbots to agents that can execute end-to-end processes.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Generative optimisation:&lt;/strong&gt; Structure public data to be readable and prioritised by external AI search engines.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Success will depend on how well these technical elements are integrated with human oversight. The winning organisations will be those that use AI automation to enhance, rather than replace, the judgment that is especially required in sectors like financial services.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Goldman Sachs deploys Anthropic systems with success&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111908" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-financial-institutions-embedding-ai-decision-making/</guid><pubDate>Wed, 18 Feb 2026 15:02:14 +0000</pubDate></item><item><title>[NEW] Kana emerges from stealth with $15M to build flexible AI agents for marketers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/18/kana-emerges-from-stealth-with-15m-to-build-flexible-ai-agents-for-marketers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Copy-of-Tom-Chavez-and-Vivek-Vaidya-Group-Shot.jpg?resize=1200,901" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Marketing is one of the few operations no industry can afford to ignore, which is why we have a veritable host of AI-powered marketing tools being shoved into marketers’ faces today. All the social platforms, from Facebook and Instagram to TikTok, and major incumbents like Microsoft and Google, to content-generation startups like Jasper and Copy.ai, offer AI tools that claim to make marketers’ lives easier in uncountable ways.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That was partly why I was confused to see yet another marketing AI startup entering the fray: San Francisco-based Kana just came out of stealth with a suite of AI agents that can do data analysis, audience targeting, campaign management, customer engagement, media planning, and optimizing for AI chatbots. The startup has raised $15 million in a seed funding round led by Mayfield. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But Kana has something going for it that most marketing startups today don’t: Its co-founders, Tom Chavez (CEO; pictured above on the right) and Vivek Vaidya (CTO; pictured above on the left), have been building marketing tech for more than 25 years. Kana’s actually their fourth venture after Rapt (acquired by Microsoft in 2008), Krux (bought by Salesforce in 2016), and startup studio super{set}, which they incubated Kana in for nine months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Calling this a “wondrous” time to be building, Chavez said there was a clear opportunity to bring their experience and today’s AI tech to bear on this class of problems. “We see a market that’s crying out for solutions that meet this moment […] We understand the space deeply, having wallowed in it arguably a little too long; having really stood in our customers’ pain,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The solution, as Kana pitches it, involves “loosely coupled” AI agents that can be tailored “on the fly,” integrated into legacy marketing software, and can simultaneously work on different operations. So a marketer could, for example, upload a media brief that Kana’s agents would analyze to figure out the campaign goals, search for the audience to target, and pull in data from inventory and market research to further tweak the plan. The platform bakes in autonomous campaign tracking, optimization, and reporting.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside agents, Kana offers synthetic data generation to augment third-party data sources for activities like market research and audience targeting. This, Chavez argued, could help companies reduce the costs of using third-party data, fill in gaps in the data, and help marketers run tests on various platforms faster and narrow down strategies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kana says this is all done while keeping humans in the loop so that marketers can approve the AI agents’ actions, give feedback, and customize what the agents do as their needs change.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chavez and Vaidya emphasized the importance of the platform’s flexibility, arguing that the ability to deploy, tailor, and build new agents in real time would let marketers see results on their campaigns faster than they would with legacy systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Going forward, the startup sees that very flexibility to customize its platform for customers, doubling as its moat against incumbents and other startups building similar products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have the opportunity not to create bespoke solutions, but to highly tailor and configure these solutions to meet customers where they are. Larger companies just are never going to get there,” Chavez said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We live in a world which allows us to explore a third option [with customers]: not build, not buy, but build with — build with in a way which is supported,” Vaidya added. “We can move with insane speed that these big companies just cannot. And that’s our advantage.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kana will use the fresh cash to expand hiring across engineering, product, and go-to-market. Mayfield managing partner Navin Chaddha is joining the company’s board. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Copy-of-Tom-Chavez-and-Vivek-Vaidya-Group-Shot.jpg?resize=1200,901" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Marketing is one of the few operations no industry can afford to ignore, which is why we have a veritable host of AI-powered marketing tools being shoved into marketers’ faces today. All the social platforms, from Facebook and Instagram to TikTok, and major incumbents like Microsoft and Google, to content-generation startups like Jasper and Copy.ai, offer AI tools that claim to make marketers’ lives easier in uncountable ways.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That was partly why I was confused to see yet another marketing AI startup entering the fray: San Francisco-based Kana just came out of stealth with a suite of AI agents that can do data analysis, audience targeting, campaign management, customer engagement, media planning, and optimizing for AI chatbots. The startup has raised $15 million in a seed funding round led by Mayfield. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But Kana has something going for it that most marketing startups today don’t: Its co-founders, Tom Chavez (CEO; pictured above on the right) and Vivek Vaidya (CTO; pictured above on the left), have been building marketing tech for more than 25 years. Kana’s actually their fourth venture after Rapt (acquired by Microsoft in 2008), Krux (bought by Salesforce in 2016), and startup studio super{set}, which they incubated Kana in for nine months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Calling this a “wondrous” time to be building, Chavez said there was a clear opportunity to bring their experience and today’s AI tech to bear on this class of problems. “We see a market that’s crying out for solutions that meet this moment […] We understand the space deeply, having wallowed in it arguably a little too long; having really stood in our customers’ pain,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The solution, as Kana pitches it, involves “loosely coupled” AI agents that can be tailored “on the fly,” integrated into legacy marketing software, and can simultaneously work on different operations. So a marketer could, for example, upload a media brief that Kana’s agents would analyze to figure out the campaign goals, search for the audience to target, and pull in data from inventory and market research to further tweak the plan. The platform bakes in autonomous campaign tracking, optimization, and reporting.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside agents, Kana offers synthetic data generation to augment third-party data sources for activities like market research and audience targeting. This, Chavez argued, could help companies reduce the costs of using third-party data, fill in gaps in the data, and help marketers run tests on various platforms faster and narrow down strategies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kana says this is all done while keeping humans in the loop so that marketers can approve the AI agents’ actions, give feedback, and customize what the agents do as their needs change.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chavez and Vaidya emphasized the importance of the platform’s flexibility, arguing that the ability to deploy, tailor, and build new agents in real time would let marketers see results on their campaigns faster than they would with legacy systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Going forward, the startup sees that very flexibility to customize its platform for customers, doubling as its moat against incumbents and other startups building similar products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have the opportunity not to create bespoke solutions, but to highly tailor and configure these solutions to meet customers where they are. Larger companies just are never going to get there,” Chavez said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We live in a world which allows us to explore a third option [with customers]: not build, not buy, but build with — build with in a way which is supported,” Vaidya added. “We can move with insane speed that these big companies just cannot. And that’s our advantage.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kana will use the fresh cash to expand hiring across engineering, product, and go-to-market. Mayfield managing partner Navin Chaddha is joining the company’s board. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/18/kana-emerges-from-stealth-with-15m-to-build-flexible-ai-agents-for-marketers/</guid><pubDate>Wed, 18 Feb 2026 15:08:40 +0000</pubDate></item><item><title>[NEW] Google adds music-generation capabilities to the Gemini app (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Lyria-feature.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google announced on Wednesday that it’s adding a music-generation feature to the Gemini app. The company is using DeepMind’s Lyria 3 music-generation model to power the feature, which is still in beta.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To use the feature, you’ll describe the song you want to create, and the app will generate a track along with lyrics. For instance, you could ask Gemini to create a “comical R&amp;amp;B slow jam about a sock finding its match,” and the app will generate a 30-second track along with cover art made by Nano Banana.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google said that you can even upload a photo or a video, and the AI-powered tool will create a song to match the mood of the media file.&lt;/p&gt;

&lt;div class="jwppp-video-box" id="jwppp-video-box-30938721"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that Lyria 3 improves on the previous generation of models, creating more realistic and complex music tracks. Users can also change and control other elements like style, vocals, and tempo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Along with rolling out Lyria 3 to the Gemini app, Google is making the model available to YouTube creators through the Dream Track feature on YouTube, a tool that helps creators make AI-generated tracks. The option was only available to YouTube creators in the U.S. until now. But with this release, Google is expanding Dream Track availability globally.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google said that you can’t mimic an artist outright, but if you add an artist’s name to your prompt, Gemini will create a track in a similar style or a mood. (It’s not clear if generation will make it easier for others to decode the music style of a particular artist.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Music generation with Lyria 3 is designed for original expression, not for mimicking existing artists. If your prompt names a specific artist, Gemini will take this as broad creative inspiration and create a track that shares a similar style or mood. We also have filters in place to check outputs against existing content,” the company said in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google noted that all songs created with the Lyria 3 model will have a SynthID watermark to identify AI-generated content. The company said that it’s also adding capabilities to identify AI-generated music with SynthID within Gemini. Users will be able to upload tracks and ask Gemini if it is AI-generated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Music generation is rolling out to all 18+ Gemini users across the world with support for English, German, Spanish, French, Hindi, Japanese, Korean, and Portuguese.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI-generated music has created mixed sentiments among artists and listeners. On one hand, companies like YouTube and Spotify are adopting AI and signing contracts with music labels to monetize AI-generated music. On the other hand, AI model and tooling companies are facing lawsuits from the music industry over copyrights of the training material. Platforms like Deezer have published tools to mark AI-generated music to curb fraudulent streams of this kind of music.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Lyria-feature.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google announced on Wednesday that it’s adding a music-generation feature to the Gemini app. The company is using DeepMind’s Lyria 3 music-generation model to power the feature, which is still in beta.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To use the feature, you’ll describe the song you want to create, and the app will generate a track along with lyrics. For instance, you could ask Gemini to create a “comical R&amp;amp;B slow jam about a sock finding its match,” and the app will generate a 30-second track along with cover art made by Nano Banana.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google said that you can even upload a photo or a video, and the AI-powered tool will create a song to match the mood of the media file.&lt;/p&gt;

&lt;div class="jwppp-video-box" id="jwppp-video-box-30938721"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that Lyria 3 improves on the previous generation of models, creating more realistic and complex music tracks. Users can also change and control other elements like style, vocals, and tempo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Along with rolling out Lyria 3 to the Gemini app, Google is making the model available to YouTube creators through the Dream Track feature on YouTube, a tool that helps creators make AI-generated tracks. The option was only available to YouTube creators in the U.S. until now. But with this release, Google is expanding Dream Track availability globally.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google said that you can’t mimic an artist outright, but if you add an artist’s name to your prompt, Gemini will create a track in a similar style or a mood. (It’s not clear if generation will make it easier for others to decode the music style of a particular artist.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Music generation with Lyria 3 is designed for original expression, not for mimicking existing artists. If your prompt names a specific artist, Gemini will take this as broad creative inspiration and create a track that shares a similar style or mood. We also have filters in place to check outputs against existing content,” the company said in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google noted that all songs created with the Lyria 3 model will have a SynthID watermark to identify AI-generated content. The company said that it’s also adding capabilities to identify AI-generated music with SynthID within Gemini. Users will be able to upload tracks and ask Gemini if it is AI-generated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Music generation is rolling out to all 18+ Gemini users across the world with support for English, German, Spanish, French, Hindi, Japanese, Korean, and Portuguese.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI-generated music has created mixed sentiments among artists and listeners. On one hand, companies like YouTube and Spotify are adopting AI and signing contracts with music labels to monetize AI-generated music. On the other hand, AI model and tooling companies are facing lawsuits from the music industry over copyrights of the training material. Platforms like Deezer have published tools to mark AI-generated music to curb fraudulent streams of this kind of music.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/18/google-adds-music-generation-capabilities-to-the-gemini-app/</guid><pubDate>Wed, 18 Feb 2026 16:00:00 +0000</pubDate></item><item><title>[NEW] Record scratch—Google's Lyria 3 AI music model is coming to Gemini today (AI - Ars Technica)</title><link>https://arstechnica.com/google/2026/02/gemini-can-now-generate-ai-music-for-you-no-lyrics-required/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        With a simple prompt, you can generate 30 seconds of something like music.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Lyria AI album covers" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Lyria_Hero-Image-640x360.png" width="640" /&gt;
                  &lt;img alt="Lyria AI album covers" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Lyria_Hero-Image-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The American poet Henry Wadsworth Longfellow called music “the universal language of mankind.” Is that still true when the so-called music is being generated by a probabilistic robot instead of a human? We’re about to find out. Google has announced its latest Lyria 3 AI model is being deployed in the Gemini app, vastly expanding access to AI music generation.&lt;/p&gt;
&lt;p&gt;Google DeepMind has been tinkering with Lyria for a while now, offering limited access in developer-oriented products like Vertex AI. Lyria 3 is more capable than previous versions, and it’s also quicker to use. Just select the new “Create music” option in the Gemini app or web UI to get started. You can describe what you want and even upload an image to help the robot get the right vibe. And in a few seconds, you get music (or something like it).&lt;/p&gt;
&lt;p&gt;In case there was any uncertainty about whether Lyria tracks still counted as a human artistic endeavor, worry not! Unlike past versions of the model, you don’t even have to provide lyrics in your prompt. You can be vague with your request, and the model will create suitable lyrics for the 30-second song. Although with that limit, “jingle” might be more accurate.&lt;/p&gt;
&lt;p&gt;In addition to the track, each music creation job will come with an album cover-style image created by the Nano Banana model. Gemini will also have a pre-loaded set of AI tracks that you can choose to remix to your heart’s content. The Lyria 3 tools are also coming to Google’s Dream Track toolkit for YouTube Shorts, which will pair nicely with the Veo AI video options.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;So what kind of tracks can you expect Gemini to spit out? Google has provided some examples:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“&lt;/em&gt;Sweet Like Plantain&lt;em&gt;“&lt;/em&gt;&lt;/p&gt;
&lt;audio class="wp-audio-shortcode" controls="controls" id="audio-2141467-1" preload="none" style="width: 100%;"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Sweet-Like-Plantain-included-in-blog.mp3?_=1" type="audio/mpeg" /&gt;&lt;/audio&gt;
&lt;p&gt;Prompt: I’m feeling nostalgic. Create a track for my mother about the great times we had as kids and the memories of her home-cooked plantains. Make it a fun afrobeat track with a true African vibe.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“&lt;/em&gt;Motown Parody&lt;em&gt;“&lt;/em&gt;&lt;/p&gt;
&lt;audio class="wp-audio-shortcode" controls="controls" id="audio-2141467-2" preload="none" style="width: 100%;"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Motown-Parody.wav?_=2" type="audio/wav" /&gt;&lt;/audio&gt;
&lt;p&gt;Prompt: Quintessential 1970s Motown soul. Lush, orchestral R&amp;amp;B production. Warm bassline with melodic fills, locked into a steady drum groove with crisp snare and tambourine. Vintage organ harmonic bed. Three-piece brass section. Gritty, gospel-tinged male tenor lead.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“&lt;/em&gt;Pop Flutter&lt;em&gt;“&lt;/em&gt;&lt;/p&gt;
&lt;audio class="wp-audio-shortcode" controls="controls" id="audio-2141467-3" preload="none" style="width: 100%;"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Pop-Flutter.wav?_=3" type="audio/wav" /&gt;&lt;/audio&gt;
&lt;p&gt;Prompt: Wistful and airy. Soft, breathy female vocals with intimacy. Rapid-fire drum and bass rhythm, low-passed and softened. Deep, warm bass swells. Dreamy electric piano chords and subtle chime textures. Rainy city vibes.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“&lt;/em&gt;Sea Shanty&lt;em&gt;“&lt;/em&gt;&lt;/p&gt;
&lt;audio class="wp-audio-shortcode" controls="controls" id="audio-2141467-4" preload="none" style="width: 100%;"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Sea-Shanty-Acapella.wav?_=4" type="audio/wav" /&gt;&lt;/audio&gt;
&lt;p&gt;Prompt: An authentic A capella Sea Shanty featuring a robust male choir singing in a traditional call-and-response format. The piece is entirely vocal, relying on synchronized foot-stomps on a wooden deck and sharp handclaps to provide the rhythmic pulse. The lead is a weathered male baritone with a gravelly timbre who sings the narrative ‘chant’ lines. He is immediately answered by a powerful male choir singing in rich, rugged harmony on the ‘response’ lines. The voices are recorded with a natural room reverb that simulates the acoustic environment of a wooden ship’s deck, giving the vocals a resonant, atmospheric quality. The performance is energetic and driving, with the choir leaning into the rhythm of the stomps to create a sense of focused, communal effort. There are no instruments, only the layered textures of collective male voices spanning tenor, baritone, and bass ranges, all contributing to a confident, monolithic sound.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Sour notes&lt;/h2&gt;
&lt;p&gt;AI-generated music is not a new phenomenon. Several companies offer models that ingest and homogenize human-created music, and the resulting tracks can sound remarkably “real,” if a bit overproduced. Streaming services have already been inundated with phony AI artists, some of which have gathered thousands of listeners who may not even realize they’re grooving to the musical equivalent of a blender set to purée.&lt;/p&gt;
&lt;p&gt;Still, you have to seek out tools like that, and Google is bringing similar capabilities to the Gemini app. As one of the most popular AI platforms, we’re probably about to see a lot more AI music on the Internet. Google says tracks generated with Lyria 3 will have an audio version of Google’s SynthID embedded within. That means you’ll always be able to check if a piece of audio was created with Google’s AI by uploading it to Gemini, similar to the way you can check images and videos for SynthID tags.&lt;/p&gt;
&lt;p&gt;Google also says it has sought to create a music AI that respects copyright and partner agreements. If you name a specific artist in your prompt, Gemini won’t attempt to copy that artist’s sound. Instead, it’s trained to take that as “broad creative inspiration.” Although it also notes this process is not foolproof, and some of that original expression might imitate an artist too much. In those cases, Google invites users to report such shared content.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2141467-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Gemini-App-UI.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Lyria 3 is going live in the Gemini web interface today and should be available in the mobile app within a few days. It works in English, German, Spanish, French, Hindi, Japanese, Korean, and Portuguese, but Google plans to add more languages soon. While all users will have some access to music generation, those with AI Pro and AI Ultra subscriptions will have higher usage limits, but the specifics are unclear.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        With a simple prompt, you can generate 30 seconds of something like music.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Lyria AI album covers" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Lyria_Hero-Image-640x360.png" width="640" /&gt;
                  &lt;img alt="Lyria AI album covers" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Lyria_Hero-Image-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The American poet Henry Wadsworth Longfellow called music “the universal language of mankind.” Is that still true when the so-called music is being generated by a probabilistic robot instead of a human? We’re about to find out. Google has announced its latest Lyria 3 AI model is being deployed in the Gemini app, vastly expanding access to AI music generation.&lt;/p&gt;
&lt;p&gt;Google DeepMind has been tinkering with Lyria for a while now, offering limited access in developer-oriented products like Vertex AI. Lyria 3 is more capable than previous versions, and it’s also quicker to use. Just select the new “Create music” option in the Gemini app or web UI to get started. You can describe what you want and even upload an image to help the robot get the right vibe. And in a few seconds, you get music (or something like it).&lt;/p&gt;
&lt;p&gt;In case there was any uncertainty about whether Lyria tracks still counted as a human artistic endeavor, worry not! Unlike past versions of the model, you don’t even have to provide lyrics in your prompt. You can be vague with your request, and the model will create suitable lyrics for the 30-second song. Although with that limit, “jingle” might be more accurate.&lt;/p&gt;
&lt;p&gt;In addition to the track, each music creation job will come with an album cover-style image created by the Nano Banana model. Gemini will also have a pre-loaded set of AI tracks that you can choose to remix to your heart’s content. The Lyria 3 tools are also coming to Google’s Dream Track toolkit for YouTube Shorts, which will pair nicely with the Veo AI video options.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;So what kind of tracks can you expect Gemini to spit out? Google has provided some examples:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“&lt;/em&gt;Sweet Like Plantain&lt;em&gt;“&lt;/em&gt;&lt;/p&gt;
&lt;audio class="wp-audio-shortcode" controls="controls" id="audio-2141467-1" preload="none" style="width: 100%;"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Sweet-Like-Plantain-included-in-blog.mp3?_=1" type="audio/mpeg" /&gt;&lt;/audio&gt;
&lt;p&gt;Prompt: I’m feeling nostalgic. Create a track for my mother about the great times we had as kids and the memories of her home-cooked plantains. Make it a fun afrobeat track with a true African vibe.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“&lt;/em&gt;Motown Parody&lt;em&gt;“&lt;/em&gt;&lt;/p&gt;
&lt;audio class="wp-audio-shortcode" controls="controls" id="audio-2141467-2" preload="none" style="width: 100%;"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Motown-Parody.wav?_=2" type="audio/wav" /&gt;&lt;/audio&gt;
&lt;p&gt;Prompt: Quintessential 1970s Motown soul. Lush, orchestral R&amp;amp;B production. Warm bassline with melodic fills, locked into a steady drum groove with crisp snare and tambourine. Vintage organ harmonic bed. Three-piece brass section. Gritty, gospel-tinged male tenor lead.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“&lt;/em&gt;Pop Flutter&lt;em&gt;“&lt;/em&gt;&lt;/p&gt;
&lt;audio class="wp-audio-shortcode" controls="controls" id="audio-2141467-3" preload="none" style="width: 100%;"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Pop-Flutter.wav?_=3" type="audio/wav" /&gt;&lt;/audio&gt;
&lt;p&gt;Prompt: Wistful and airy. Soft, breathy female vocals with intimacy. Rapid-fire drum and bass rhythm, low-passed and softened. Deep, warm bass swells. Dreamy electric piano chords and subtle chime textures. Rainy city vibes.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;“&lt;/em&gt;Sea Shanty&lt;em&gt;“&lt;/em&gt;&lt;/p&gt;
&lt;audio class="wp-audio-shortcode" controls="controls" id="audio-2141467-4" preload="none" style="width: 100%;"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Sea-Shanty-Acapella.wav?_=4" type="audio/wav" /&gt;&lt;/audio&gt;
&lt;p&gt;Prompt: An authentic A capella Sea Shanty featuring a robust male choir singing in a traditional call-and-response format. The piece is entirely vocal, relying on synchronized foot-stomps on a wooden deck and sharp handclaps to provide the rhythmic pulse. The lead is a weathered male baritone with a gravelly timbre who sings the narrative ‘chant’ lines. He is immediately answered by a powerful male choir singing in rich, rugged harmony on the ‘response’ lines. The voices are recorded with a natural room reverb that simulates the acoustic environment of a wooden ship’s deck, giving the vocals a resonant, atmospheric quality. The performance is energetic and driving, with the choir leaning into the rhythm of the stomps to create a sense of focused, communal effort. There are no instruments, only the layered textures of collective male voices spanning tenor, baritone, and bass ranges, all contributing to a confident, monolithic sound.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Sour notes&lt;/h2&gt;
&lt;p&gt;AI-generated music is not a new phenomenon. Several companies offer models that ingest and homogenize human-created music, and the resulting tracks can sound remarkably “real,” if a bit overproduced. Streaming services have already been inundated with phony AI artists, some of which have gathered thousands of listeners who may not even realize they’re grooving to the musical equivalent of a blender set to purée.&lt;/p&gt;
&lt;p&gt;Still, you have to seek out tools like that, and Google is bringing similar capabilities to the Gemini app. As one of the most popular AI platforms, we’re probably about to see a lot more AI music on the Internet. Google says tracks generated with Lyria 3 will have an audio version of Google’s SynthID embedded within. That means you’ll always be able to check if a piece of audio was created with Google’s AI by uploading it to Gemini, similar to the way you can check images and videos for SynthID tags.&lt;/p&gt;
&lt;p&gt;Google also says it has sought to create a music AI that respects copyright and partner agreements. If you name a specific artist in your prompt, Gemini won’t attempt to copy that artist’s sound. Instead, it’s trained to take that as “broad creative inspiration.” Although it also notes this process is not foolproof, and some of that original expression might imitate an artist too much. In those cases, Google invites users to report such shared content.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2141467-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/Gemini-App-UI.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Lyria 3 is going live in the Gemini web interface today and should be available in the mobile app within a few days. It works in English, German, Spanish, French, Hindi, Japanese, Korean, and Portuguese, but Google plans to add more languages soon. While all users will have some access to music generation, those with AI Pro and AI Ultra subscriptions will have higher usage limits, but the specifics are unclear.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2026/02/gemini-can-now-generate-ai-music-for-you-no-lyrics-required/</guid><pubDate>Wed, 18 Feb 2026 16:00:11 +0000</pubDate></item><item><title>[NEW] Google DeepMind wants to know if chatbots are just virtue signaling (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/18/1133299/google-deepmind-wants-to-know-if-chatbots-are-just-virtue-signaling/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/decision-tree2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;Google DeepMind is calling for the moral behavior of large language models—such as what they do when called on to act as companions, therapists, medical advisors, and so on—to be scrutinized with the same kind of rigor as their ability to code or do math.&lt;/p&gt;  &lt;p&gt;As LLMs improve, people are asking them to play more and more sensitive roles in their lives. Agents are starting to take actions on people’s behalf. LLMs may be able to influence human decision-making. And yet nobody knows how trustworthy this technology really is at such tasks.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;With coding and math, you have clear-cut, correct answers that you can check, William Isaac, a research scientist at Google DeepMind, told me when I met him and Julia Haas, a fellow research scientist at the firm, for an exclusive preview of their work, which is published in &lt;em&gt;Nature&lt;/em&gt; today. That’s not the case for moral questions, which typically have a range of acceptable answers: “Morality is an important capability but hard to evaluate,” says Isaac.&lt;/p&gt;  &lt;p&gt;“In the moral domain, there’s no right and wrong,” adds Haas. “But it’s not by any means a free-for-all. There are better answers and there are worse answers.”&lt;/p&gt; 
 &lt;p&gt;The researchers have identified several key challenges and suggested ways to address them. But it is more a wish list than a set of ready-made solutions. “They do a nice job of bringing together different perspectives,” says Vera Demberg, who studies LLMs at Saarland University in Germany.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Better than "The Ethicist"&lt;/h3&gt;  &lt;p&gt;A number of studies have shown that LLMs can show remarkable moral competence. One study published last year found that people in the US scored ethical advice from OpenAI’s GPT-4o as being more moral, trustworthy, thoughtful, and correct than advice given by the (human) writer of “The Ethicist,” a popular &lt;em&gt;New York Times&lt;/em&gt; advice column.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The problem is that it is hard to unpick whether such behaviors are a performance—mimicking a memorized response, say—or evidence that there is in fact some kind of moral reasoning taking place inside the model. In other words, is it virtue or virtue signaling?&lt;/p&gt;  &lt;p&gt;This question matters because multiple studies also show just how untrustworthy LLMs can be. For a start, models can be too eager to please. They have been found to flip their answer to a moral question and say the exact opposite when a person disagrees or pushes back on their first response. Worse, the answers an LLM gives to a question can change in response to how it is presented or formatted. For example, researchers have found that models quizzed about political values can give different—sometimes opposite—answers depending on whether the questions offer multiple-choice answers or instruct the model to respond in its own words.&lt;/p&gt;  &lt;p&gt;In an even more striking case, Demberg and her colleagues presented several LLMs, including versions of Meta’s Llama 3 and Mistral, with a series of moral dilemmas and asked them to pick which of two options was the better outcome. The researchers found that the models often reversed their choice when the labels for those two options were changed from “Case 1” and “Case 2” to “(A)” and “(B).”&lt;/p&gt;  &lt;p&gt;They also showed that models changed their answers in response to other tiny formatting tweaks, including swapping the order of the options and ending the question with a colon instead of a question mark.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;In short, the appearance of moral behavior in LLMs should not be taken at face value. Models must be probed to see how robust that moral behavior really is. “For people to trust the answers, you need to know how you got there,” says Haas.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;More rigorous tests&lt;/h3&gt;  &lt;p&gt;What Haas, Isaac, and their colleagues at Google DeepMind propose is a new line of research to develop more rigorous techniques for evaluating moral competence in LLMs. This would include tests designed to push models to change their responses to moral questions. If a model flipped its moral position, it would show that it hadn’t engaged in robust moral reasoning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Another type of test would present models with variations of common moral problems to check whether they produce a rote response or one that’s more nuanced and relevant to the actual problem that was posed. For example, asking a model to talk through the moral implications of a complex scenario in which a man donates sperm to his son so that his son can have a child of his own might produce concerns about the social impact of allowing a man to be both biological father and biological grandfather to a child. But it should not produce concerns about incest, even though the scenario has superficial parallels with that taboo.&lt;/p&gt;  &lt;p&gt;Haas also says that getting models to provide a trace of the steps they took to produce an answer would give some insight into whether that answer was a fluke or grounded in actual evidence. Techniques such as chain-of-thought monitoring, in which researchers listen in on a kind of internal monologue that some LLMs produce as they work, could help here too.&lt;/p&gt; 

 &lt;p&gt;Another approach researchers could use to determine why a model gave a particular answer is mechanistic interpretability, which can provide small glimpses inside a model as it carries out a task. Neither chain-of-thought monitoring nor mechanistic interpretability provides perfect snapshots of a model’s workings. But the Google DeepMind team believes that combining such techniques with a wide range of rigorous tests will go a long way to figuring out exactly how far to trust LLMs with certain critical or sensitive tasks.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Different values&lt;/h3&gt;  &lt;p&gt;And yet there’s a wider problem too. Models from major companies such as Google DeepMind are used across the world by people with different values and belief systems. The answer to a simple question like “Should I order pork chops?” should differ depending on whether or not the person asking is vegetarian or Jewish, for example.&lt;/p&gt;  &lt;p&gt;There’s no solution to this challenge, Haas and Isaac admit. But they think that models may need to be designed either to produce a range of acceptable answers, aiming to please everyone, or to have a kind of switch that turns different moral codes on and off depending on the user.&lt;/p&gt;  &lt;p&gt;“It’s a complex world out there,” says Haas. “We will probably need some combination of those things, because even if you’re taking just one population, there’s going to be a range of views represented.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;“It’s a fascinating paper,” says Danica Dillion at Ohio State University, who studies how large language models handle different belief systems and was not involved in the work. “Pluralism in AI is really important, and it’s one of the biggest limitations of LLMs and moral reasoning right now,” she says. “Even though they were trained on a ginormous amount of data, that data still leans heavily Western. When you probe LLMs, they do a lot better at representing Westerners’ morality than non-Westerners’.”&lt;/p&gt;  &lt;p&gt;But it is not yet clear how we can build models that are guaranteed to have moral competence across global cultures, says Demberg. “There are these two independent questions. One is: How should it work? And, secondly, how can it technically be achieved? And I think that both of those questions are pretty open at the moment.”&lt;/p&gt;  &lt;p&gt;For Isaac, that makes morality a new frontier for LLMs. “I think this is equally as fascinating as math and code in terms of what it means for AI progress,” he says. “You know, advancing moral competency could also mean that we’re going to see better AI systems overall that actually align with society.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/decision-tree2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;Google DeepMind is calling for the moral behavior of large language models—such as what they do when called on to act as companions, therapists, medical advisors, and so on—to be scrutinized with the same kind of rigor as their ability to code or do math.&lt;/p&gt;  &lt;p&gt;As LLMs improve, people are asking them to play more and more sensitive roles in their lives. Agents are starting to take actions on people’s behalf. LLMs may be able to influence human decision-making. And yet nobody knows how trustworthy this technology really is at such tasks.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;With coding and math, you have clear-cut, correct answers that you can check, William Isaac, a research scientist at Google DeepMind, told me when I met him and Julia Haas, a fellow research scientist at the firm, for an exclusive preview of their work, which is published in &lt;em&gt;Nature&lt;/em&gt; today. That’s not the case for moral questions, which typically have a range of acceptable answers: “Morality is an important capability but hard to evaluate,” says Isaac.&lt;/p&gt;  &lt;p&gt;“In the moral domain, there’s no right and wrong,” adds Haas. “But it’s not by any means a free-for-all. There are better answers and there are worse answers.”&lt;/p&gt; 
 &lt;p&gt;The researchers have identified several key challenges and suggested ways to address them. But it is more a wish list than a set of ready-made solutions. “They do a nice job of bringing together different perspectives,” says Vera Demberg, who studies LLMs at Saarland University in Germany.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Better than "The Ethicist"&lt;/h3&gt;  &lt;p&gt;A number of studies have shown that LLMs can show remarkable moral competence. One study published last year found that people in the US scored ethical advice from OpenAI’s GPT-4o as being more moral, trustworthy, thoughtful, and correct than advice given by the (human) writer of “The Ethicist,” a popular &lt;em&gt;New York Times&lt;/em&gt; advice column.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The problem is that it is hard to unpick whether such behaviors are a performance—mimicking a memorized response, say—or evidence that there is in fact some kind of moral reasoning taking place inside the model. In other words, is it virtue or virtue signaling?&lt;/p&gt;  &lt;p&gt;This question matters because multiple studies also show just how untrustworthy LLMs can be. For a start, models can be too eager to please. They have been found to flip their answer to a moral question and say the exact opposite when a person disagrees or pushes back on their first response. Worse, the answers an LLM gives to a question can change in response to how it is presented or formatted. For example, researchers have found that models quizzed about political values can give different—sometimes opposite—answers depending on whether the questions offer multiple-choice answers or instruct the model to respond in its own words.&lt;/p&gt;  &lt;p&gt;In an even more striking case, Demberg and her colleagues presented several LLMs, including versions of Meta’s Llama 3 and Mistral, with a series of moral dilemmas and asked them to pick which of two options was the better outcome. The researchers found that the models often reversed their choice when the labels for those two options were changed from “Case 1” and “Case 2” to “(A)” and “(B).”&lt;/p&gt;  &lt;p&gt;They also showed that models changed their answers in response to other tiny formatting tweaks, including swapping the order of the options and ending the question with a colon instead of a question mark.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;In short, the appearance of moral behavior in LLMs should not be taken at face value. Models must be probed to see how robust that moral behavior really is. “For people to trust the answers, you need to know how you got there,” says Haas.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;More rigorous tests&lt;/h3&gt;  &lt;p&gt;What Haas, Isaac, and their colleagues at Google DeepMind propose is a new line of research to develop more rigorous techniques for evaluating moral competence in LLMs. This would include tests designed to push models to change their responses to moral questions. If a model flipped its moral position, it would show that it hadn’t engaged in robust moral reasoning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Another type of test would present models with variations of common moral problems to check whether they produce a rote response or one that’s more nuanced and relevant to the actual problem that was posed. For example, asking a model to talk through the moral implications of a complex scenario in which a man donates sperm to his son so that his son can have a child of his own might produce concerns about the social impact of allowing a man to be both biological father and biological grandfather to a child. But it should not produce concerns about incest, even though the scenario has superficial parallels with that taboo.&lt;/p&gt;  &lt;p&gt;Haas also says that getting models to provide a trace of the steps they took to produce an answer would give some insight into whether that answer was a fluke or grounded in actual evidence. Techniques such as chain-of-thought monitoring, in which researchers listen in on a kind of internal monologue that some LLMs produce as they work, could help here too.&lt;/p&gt; 

 &lt;p&gt;Another approach researchers could use to determine why a model gave a particular answer is mechanistic interpretability, which can provide small glimpses inside a model as it carries out a task. Neither chain-of-thought monitoring nor mechanistic interpretability provides perfect snapshots of a model’s workings. But the Google DeepMind team believes that combining such techniques with a wide range of rigorous tests will go a long way to figuring out exactly how far to trust LLMs with certain critical or sensitive tasks.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Different values&lt;/h3&gt;  &lt;p&gt;And yet there’s a wider problem too. Models from major companies such as Google DeepMind are used across the world by people with different values and belief systems. The answer to a simple question like “Should I order pork chops?” should differ depending on whether or not the person asking is vegetarian or Jewish, for example.&lt;/p&gt;  &lt;p&gt;There’s no solution to this challenge, Haas and Isaac admit. But they think that models may need to be designed either to produce a range of acceptable answers, aiming to please everyone, or to have a kind of switch that turns different moral codes on and off depending on the user.&lt;/p&gt;  &lt;p&gt;“It’s a complex world out there,” says Haas. “We will probably need some combination of those things, because even if you’re taking just one population, there’s going to be a range of views represented.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;“It’s a fascinating paper,” says Danica Dillion at Ohio State University, who studies how large language models handle different belief systems and was not involved in the work. “Pluralism in AI is really important, and it’s one of the biggest limitations of LLMs and moral reasoning right now,” she says. “Even though they were trained on a ginormous amount of data, that data still leans heavily Western. When you probe LLMs, they do a lot better at representing Westerners’ morality than non-Westerners’.”&lt;/p&gt;  &lt;p&gt;But it is not yet clear how we can build models that are guaranteed to have moral competence across global cultures, says Demberg. “There are these two independent questions. One is: How should it work? And, secondly, how can it technically be achieved? And I think that both of those questions are pretty open at the moment.”&lt;/p&gt;  &lt;p&gt;For Isaac, that makes morality a new frontier for LLMs. “I think this is equally as fascinating as math and code in terms of what it means for AI progress,” he says. “You know, advancing moral competency could also mean that we’re going to see better AI systems overall that actually align with society.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/18/1133299/google-deepmind-wants-to-know-if-chatbots-are-just-virtue-signaling/</guid><pubDate>Wed, 18 Feb 2026 16:00:22 +0000</pubDate></item><item><title>[NEW] A new way to express yourself: Gemini can now create music (Google DeepMind News)</title><link>https://deepmind.google/blog/a-new-way-to-express-yourself-gemini-can-now-create-music/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/0217_KeywordHeaderFinalc.width-1300.png" /&gt;&lt;/div&gt;
  





            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Since launching the Gemini app, we've built tools to encourage creative expression through images and video. Today, we're taking the next step: custom music generation. Lyria 3, Google DeepMind’s latest generative music model, is rolling out today in beta in the Gemini app. Just describe an idea or upload a photo, like “a comical R&amp;amp;B slow jam about a sock finding their match" and in a matter of seconds, Gemini will translate it into a high-quality, catchy track. To push the creative envelope further, you can even ask Gemini to take inspiration from something you upload.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Lyria 3 improves on audio generation from our Lyria models in three important ways:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;No need to provide your own lyrics! They'll be generated for you based on your prompt.&lt;/li&gt;&lt;li&gt;You have more creative control over elements like the style, vocals and tempo you want.&lt;/li&gt;&lt;li&gt;You can create more realistic and musically complex tracks.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Here’s how you can use it:&lt;br /&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Text to track:&lt;/b&gt; Describe a specific genre, mood, inside joke, or memory to create unique tracks with lyrics or instrumental audio that fits your vibe. &lt;i&gt;“I’m feeling nostalgic. Create a track for my mother about the great times we had as kids and the memories of her home cooked plantains. Make it a fun afrobeat track with a true African vibe.”&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;From photos and videos to track:&lt;/b&gt; Upload a photo or video and watch Gemini use the content to compose a track with lyrics that fit the mood perfectly. &lt;i&gt;“Use these photos to create a track about my dog Duncan on a hike in the woods.”&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The Gemini app creates 30-second tracks with custom cover art generated by Nano Banana. This makes it easy to quickly share with friends by downloading or simply clicking the share link. The goal of these tracks isn't to create a musical masterpiece, but rather to give you a fun, unique way to express yourself.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    











&lt;div class="audio-player"&gt;
  &lt;audio class="audio-player__player" title="Sweet Like Plantain"&gt;
    &lt;audio controls="controls"&gt;
&lt;source src="https://storage.googleapis.com/gweb-uniblog-publish-prod/media/Sweet_Like_Plantain_1.mp3" type="audio/mpeg" /&gt;
&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
&lt;/audio&gt;
  &lt;/audio&gt;
  &lt;div class="audio-player__container"&gt;
    &lt;div class="audio-player__text-content"&gt;
      &lt;div class="audio-player__content"&gt;
        &lt;span class="audio-player__content--title"&gt;Sweet Like Plantain&lt;/span&gt;
        
      &lt;/div&gt;
      &lt;button class="audio-player__preview-play"&gt;
        &lt;svg class="icon audio-player__play-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;span class="audio-player__duration"&gt;&lt;/span&gt;
      &lt;/button&gt;
      &lt;span class="audio-player__duration--large-viewport"&gt;&lt;/span&gt;
    &lt;/div&gt;
    &lt;div class="audio-player__console"&gt;
      &lt;div class="audio-player__start"&gt;
        &lt;button class="audio-player__replay"&gt;
          &lt;svg class="icon h-c-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;button class="audio-player__pause"&gt;
          &lt;svg class="icon audio-player__icon-play" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;svg class="icon audio-player__icon-pause audio-player__icon-pause--hidden" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;button class="audio-player__forward"&gt;
          &lt;svg class="icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
      &lt;/div&gt;
      &lt;div class="audio-player__time-bar"&gt;
        &lt;span class="audio-player__current-time"&gt;&lt;/span&gt;
        &lt;div class="audio-player__timeline-slider-container"&gt;
          &lt;input class="timeline__slider" max="100" step="5" tabindex="0" type="range" value="0" /&gt;
        &lt;/div&gt;
        &lt;span class="audio-player__duration-time"&gt;&lt;/span&gt;
        &lt;div class="audio-player__volume-content"&gt;
          &lt;button class="audio-player__volume"&gt;
            &lt;svg class="icon audio-player__volume-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

            &lt;svg class="icon audio-player__mute-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;/button&gt;
          &lt;div class="audio-player__volume-slider-container"&gt;
            &lt;input class="volume__slider" max="100" tabindex="0" type="range" value="100" /&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Creators can also explore Lyria 3 on YouTube’s Dream Track. Available in the U.S. and now rolling out to YouTube creators in other countries, Lyria 3 will enhance the quality of each unique Shorts soundtrack. Whether it's creating a lyrical verse or a vibey backing track, being able to better customize the soundtrack will take creators’ Shorts to the next level.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;New audio verification capabilities&lt;/h2&gt;&lt;p&gt;All tracks generated in the Gemini app are embedded with SynthID, our imperceptible watermark for identifying Google AI-generated content. We are also giving you more tools to help identify AI content, broadening our verification capabilities in the Gemini app to include audio, along with image and video. Simply upload a file and ask if it was generated using Google AI, and Gemini will check for SynthID and use its own reasoning to return a response.&lt;/p&gt;&lt;h2&gt;Our commitment to developing generative AI responsibly&lt;/h2&gt;&lt;p&gt;Since we first launched Lyria in 2023, we've sought to develop this technology responsibly in collaboration with the music community. We've learned a lot through these collaborations and our experiments, like Music AI Sandbox, and have been very mindful of copyright and partner agreements as we've trained Lyria 3.&lt;/p&gt;&lt;p&gt;Music generation with Lyria 3 is designed for original expression, not for mimicking existing artists. If your prompt names a specific artist, Gemini will take this as broad creative inspiration and create a track that shares a similar style or mood. We also have filters in place to check outputs against existing content. We recognize that our approach might not be foolproof, so you can report content that may violate your rights or the rights of others. Additionally, in order to use our products, users must adhere to our Terms of Service and Gen AI prohibited use policies, which prohibit violations of others’ intellectual property and privacy rights.&lt;/p&gt;&lt;p&gt;Lyria 3 is available in the Gemini app for all users 18+ in English, German, Spanish, French, Hindi, Japanese, Korean and Portuguese, with plans to expand quality and coverage of more languages, rolling out on desktop today and to the mobile app over the next several days. And Google AI Plus, Pro and Ultra subscribers will enjoy higher limits.&lt;/p&gt;&lt;p&gt;Our goal with music generation in the Gemini app is to help you add a fun, custom soundtrack to your daily life. Try it out today at gemini.google.com.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Gemini App


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/0217_KeywordHeaderFinalc.width-1300.png" /&gt;&lt;/div&gt;
  





            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Since launching the Gemini app, we've built tools to encourage creative expression through images and video. Today, we're taking the next step: custom music generation. Lyria 3, Google DeepMind’s latest generative music model, is rolling out today in beta in the Gemini app. Just describe an idea or upload a photo, like “a comical R&amp;amp;B slow jam about a sock finding their match" and in a matter of seconds, Gemini will translate it into a high-quality, catchy track. To push the creative envelope further, you can even ask Gemini to take inspiration from something you upload.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Lyria 3 improves on audio generation from our Lyria models in three important ways:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;No need to provide your own lyrics! They'll be generated for you based on your prompt.&lt;/li&gt;&lt;li&gt;You have more creative control over elements like the style, vocals and tempo you want.&lt;/li&gt;&lt;li&gt;You can create more realistic and musically complex tracks.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Here’s how you can use it:&lt;br /&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Text to track:&lt;/b&gt; Describe a specific genre, mood, inside joke, or memory to create unique tracks with lyrics or instrumental audio that fits your vibe. &lt;i&gt;“I’m feeling nostalgic. Create a track for my mother about the great times we had as kids and the memories of her home cooked plantains. Make it a fun afrobeat track with a true African vibe.”&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;From photos and videos to track:&lt;/b&gt; Upload a photo or video and watch Gemini use the content to compose a track with lyrics that fit the mood perfectly. &lt;i&gt;“Use these photos to create a track about my dog Duncan on a hike in the woods.”&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The Gemini app creates 30-second tracks with custom cover art generated by Nano Banana. This makes it easy to quickly share with friends by downloading or simply clicking the share link. The goal of these tracks isn't to create a musical masterpiece, but rather to give you a fun, unique way to express yourself.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    











&lt;div class="audio-player"&gt;
  &lt;audio class="audio-player__player" title="Sweet Like Plantain"&gt;
    &lt;audio controls="controls"&gt;
&lt;source src="https://storage.googleapis.com/gweb-uniblog-publish-prod/media/Sweet_Like_Plantain_1.mp3" type="audio/mpeg" /&gt;
&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;
&lt;/audio&gt;
  &lt;/audio&gt;
  &lt;div class="audio-player__container"&gt;
    &lt;div class="audio-player__text-content"&gt;
      &lt;div class="audio-player__content"&gt;
        &lt;span class="audio-player__content--title"&gt;Sweet Like Plantain&lt;/span&gt;
        
      &lt;/div&gt;
      &lt;button class="audio-player__preview-play"&gt;
        &lt;svg class="icon audio-player__play-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;span class="audio-player__duration"&gt;&lt;/span&gt;
      &lt;/button&gt;
      &lt;span class="audio-player__duration--large-viewport"&gt;&lt;/span&gt;
    &lt;/div&gt;
    &lt;div class="audio-player__console"&gt;
      &lt;div class="audio-player__start"&gt;
        &lt;button class="audio-player__replay"&gt;
          &lt;svg class="icon h-c-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;button class="audio-player__pause"&gt;
          &lt;svg class="icon audio-player__icon-play" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;svg class="icon audio-player__icon-pause audio-player__icon-pause--hidden" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
        &lt;button class="audio-player__forward"&gt;
          &lt;svg class="icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

        &lt;/button&gt;
      &lt;/div&gt;
      &lt;div class="audio-player__time-bar"&gt;
        &lt;span class="audio-player__current-time"&gt;&lt;/span&gt;
        &lt;div class="audio-player__timeline-slider-container"&gt;
          &lt;input class="timeline__slider" max="100" step="5" tabindex="0" type="range" value="0" /&gt;
        &lt;/div&gt;
        &lt;span class="audio-player__duration-time"&gt;&lt;/span&gt;
        &lt;div class="audio-player__volume-content"&gt;
          &lt;button class="audio-player__volume"&gt;
            &lt;svg class="icon audio-player__volume-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

            &lt;svg class="icon audio-player__mute-icon" xmlns="http://www.w3.org/2000/svg"&gt;
  &lt;use xmlns:xlink="http://www.w3.org/1999/xlink"&gt;
&lt;/svg&gt;

          &lt;/button&gt;
          &lt;div class="audio-player__volume-slider-container"&gt;
            &lt;input class="volume__slider" max="100" tabindex="0" type="range" value="100" /&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Creators can also explore Lyria 3 on YouTube’s Dream Track. Available in the U.S. and now rolling out to YouTube creators in other countries, Lyria 3 will enhance the quality of each unique Shorts soundtrack. Whether it's creating a lyrical verse or a vibey backing track, being able to better customize the soundtrack will take creators’ Shorts to the next level.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;New audio verification capabilities&lt;/h2&gt;&lt;p&gt;All tracks generated in the Gemini app are embedded with SynthID, our imperceptible watermark for identifying Google AI-generated content. We are also giving you more tools to help identify AI content, broadening our verification capabilities in the Gemini app to include audio, along with image and video. Simply upload a file and ask if it was generated using Google AI, and Gemini will check for SynthID and use its own reasoning to return a response.&lt;/p&gt;&lt;h2&gt;Our commitment to developing generative AI responsibly&lt;/h2&gt;&lt;p&gt;Since we first launched Lyria in 2023, we've sought to develop this technology responsibly in collaboration with the music community. We've learned a lot through these collaborations and our experiments, like Music AI Sandbox, and have been very mindful of copyright and partner agreements as we've trained Lyria 3.&lt;/p&gt;&lt;p&gt;Music generation with Lyria 3 is designed for original expression, not for mimicking existing artists. If your prompt names a specific artist, Gemini will take this as broad creative inspiration and create a track that shares a similar style or mood. We also have filters in place to check outputs against existing content. We recognize that our approach might not be foolproof, so you can report content that may violate your rights or the rights of others. Additionally, in order to use our products, users must adhere to our Terms of Service and Gen AI prohibited use policies, which prohibit violations of others’ intellectual property and privacy rights.&lt;/p&gt;&lt;p&gt;Lyria 3 is available in the Gemini app for all users 18+ in English, German, Spanish, French, Hindi, Japanese, Korean and Portuguese, with plans to expand quality and coverage of more languages, rolling out on desktop today and to the mobile app over the next several days. And Google AI Plus, Pro and Ultra subscribers will enjoy higher limits.&lt;/p&gt;&lt;p&gt;Our goal with music generation in the Gemini app is to help you add a fun, custom soundtrack to your daily life. Try it out today at gemini.google.com.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


Gemini App


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/blog/a-new-way-to-express-yourself-gemini-can-now-create-music/</guid><pubDate>Wed, 18 Feb 2026 16:01:38 +0000</pubDate></item><item><title>[NEW] Project Silica’s advances in glass storage technology (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/project-silicas-advances-in-glass-storage-technology/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="A blue-to-green gradient background featuring three white icons: a networked globe on the left, a cloud in the center, and a stacked database on the right." class="wp-image-1162006" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/NatureSilica-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns mb-10 pb-1 pr-1 is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Microsoft Research publishes&amp;nbsp;breakthrough&amp;nbsp;in&amp;nbsp;&lt;em&gt;Nature&lt;/em&gt;&amp;nbsp;on glass-based data storage that could preserve information for 10,000 years.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;New&amp;nbsp;technique extends technology from expensive fused silica to ordinary borosilicate glass found in kitchen cookware.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Innovations enable faster parallel writing, simplified readers (one camera instead of three), and easier manufacturing.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Phase voxel method requires only a single laser pulse, significantly reducing complexity and cost.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;Long-term preservation of digital information has long challenged archivists and datacenters, as magnetic tapes and hard drives degrade within decades. Existing archival storage solutions have limited media lifespans that make them less than ideal for preserving information for future generations.&lt;/p&gt;



&lt;p&gt;Now, we are excited to report significant progress on Project Silica&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, our effort to encode data in glass using femtosecond lasers, a technology that could preserve information for 10,000 years. Glass is a permanent data storage material that is resistant to water, heat, and dust.&lt;/p&gt;



&lt;p&gt;In findings published in &lt;em&gt;Nature&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&lt;/em&gt;, we describe a breakthrough that extends the technology beyond expensive fused silica to ordinary borosilicate glass. A readily available and lower-cost medium, this is the same material found in kitchen cookware and oven doors. This advance addresses key barriers to commercialization: cost and availability of storage media. We have unlocked the science for parallel high-speed writing and developed a technique to permit accelerated aging tests on the written glass, suggesting that the data should remain intact for at least 10,000 years.&lt;/p&gt;



&lt;p&gt;Storing data inside glass with femtosecond&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; laser pulses is one of the few technologies on the horizon with the potential for durable, immutable, and long-lived storage. Although we have been leading innovation in this type of storage for years, prior to this research the technique only worked with pure fused silica glass, a type of glass that is relatively difficult to manufacture and available from only a few sources.&lt;/p&gt;



&lt;p&gt;In the paper, we show how data can be stored in borosilicate glass. The new technique stores hundreds of layers of data in glass only 2mm thin, as with previous methods, but with important improvements. The reader for the glass now needs only one camera, not three or four, reducing cost and size. In addition, the writing devices require fewer parts, making them easier to manufacture and calibrate, and enabling them to encode data more quickly.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;PODCAST SERIES&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/h2&gt;
				
								&lt;p class="large" id="ai-testing-and-evaluation-learnings-from-science-and-industry"&gt;Discover how Microsoft is learning from other domains to advance evaluation and testing as a pillar of AI governance.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="key-scientific-discoveries"&gt;Key scientific discoveries&lt;/h2&gt;



&lt;p&gt;The &lt;em&gt;Nature&lt;/em&gt; paper details several key new scientific discoveries:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Advances in birefringent voxel&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; writing&lt;/strong&gt;: For the previous type of data storage in fused silica glass using birefringent (i.e., polarization) voxels, we developed a technique to reduce the number of pulses used to form the voxel from many to only two, critically showing that the polarization of the first pulse is not important to the polarization of the voxel formed. We further developed this to enable pseudo-single-pulse writing, in which a single pulse can be split after its polarization is set to simultaneously form the first pulse for one voxel (where the polarization doesn’t matter) and the second pulse of another (where the set polarization is essential). We demonstrated how to use this pseudo-single-pulse writing to enable fast writing with beam scanning across the media.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Phase voxels, a new storage method&lt;/strong&gt;: We invented a new type of data storage in glass called phase voxels, in which the phase change of the glass is modified instead of its polarization, showing that only a single pulse is necessary to make a phase voxel. We demonstrated that these phase voxels can also be formed in borosilicate glass and devised a technique to read the phase information from phase voxels encoded in this material. We showed that the much higher levels of three-dimensional inter-symbol interference in phase voxels can be mitigated with a machine learning classification model.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Parallel writing capabilities&lt;/strong&gt;: By combining a mathematical model of pre-heating and post-heating within the glass with the invention of a multi-beam delivery system, we showed that many data voxels can be written in proximity in the glass at the same time, significantly increasing writing speed. We explained a method for using light emissions (a side effect of voxel formation) for both static calibration and dynamic control to fully support automatic writing operations.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Optimization and longevity testing&lt;/strong&gt;: We developed a new way to optimize symbol encodings using machine learning and a better way to understand the tradeoff between error rates, error protection, and error recovery when evaluating new digital storage systems. We also created a new nondestructive optical method&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to identify the aging of data storage voxels within the glass, using this and standard accelerated aging techniques to support data lasting 10,000 years. We extended the industry standard Gray codes to apply to nonpower-of-two numbers of symbols.&lt;/p&gt;


&lt;div class="wp-block-msr-cards msr-cards msr-cards--carousel mt-4 has-text-align-left has-cards"&gt;
	&lt;div class="msr-cards__inner"&gt;
		
					&lt;div class="mt-4"&gt;
				&lt;div class="row"&gt;
	&lt;div class="col-12 px-0 px-md-g"&gt;
		&lt;section&gt;
			
			&lt;div class="carousel slide carousel-content-cards carousel-sneak-peek"&gt;
				
					Skip slideshow for: 				
				&lt;div&gt;
					&lt;div class="carousel-controls"&gt;
						&lt;button class="carousel-control-prev " type="button"&gt;
							&lt;span class="sr-only"&gt;Previous slide&lt;/span&gt;
						&lt;/button&gt;

						&lt;ol class="carousel-indicators"&gt;
															&lt;li class="active"&gt;&lt;/li&gt;
															&lt;li class="class"&gt;&lt;/li&gt;
															&lt;li class="class"&gt;&lt;/li&gt;
															&lt;li class="class"&gt;&lt;/li&gt;
													&lt;/ol&gt;

						&lt;button class="carousel-control-next " type="button"&gt;
							&lt;span class="sr-only"&gt;Previous slide&lt;/span&gt;
						&lt;/button&gt;
					&lt;/div&gt;

					&lt;div class="carousel-inner"&gt;
													&lt;section class="carousel-item msr-cards__card msr-cards__card--carousel active"&gt;

	&lt;div class="card material-card h-100 p-0"&gt;

					&lt;div class="embed-responsive embed-responsive-16by9"&gt;
				&lt;img alt="Project Silica | Nature | Microsoft Azure - vertical color bars in varying shades of blue" class="card-img embed-responsive-item img-object-cover" height="683" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/Nature_Silica_1_1200x800-1024x683.jpg" width="1024" /&gt;			&lt;/div&gt;
		
		&lt;div class="card-body px-4 px-lg-5 pt-4"&gt;
										&lt;div class="card__description mb-3"&gt;
					&lt;p&gt;A piece of Project Silica media written with data.&lt;/p&gt;				&lt;/div&gt;
					&lt;/div&gt;

			&lt;/div&gt;
&lt;/section&gt;
													&lt;section class="carousel-item msr-cards__card msr-cards__card--carousel"&gt;

	&lt;div class="card material-card h-100 p-0"&gt;

					&lt;div class="embed-responsive embed-responsive-16by9"&gt;
				&lt;img alt="Project Silica | Nature | photo of lab testing set up" class="card-img embed-responsive-item img-object-cover" height="683" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/Nature_Silica_2_1200x800-1024x683.jpg" width="1024" /&gt;			&lt;/div&gt;
		
		&lt;div class="card-body px-4 px-lg-5 pt-4"&gt;
										&lt;div class="card__description mb-3"&gt;
					&lt;p&gt;A research-grade Writer used to set the record for high speed data writing into glass.&lt;/p&gt;				&lt;/div&gt;
					&lt;/div&gt;

			&lt;/div&gt;
&lt;/section&gt;
													&lt;section class="carousel-item msr-cards__card msr-cards__card--carousel"&gt;

	&lt;div class="card material-card h-100 p-0"&gt;

					&lt;div class="embed-responsive embed-responsive-16by9"&gt;
				&lt;img alt="Project Silica | Nature | photo of lab testing set up" class="card-img embed-responsive-item img-object-cover" height="683" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/Nature_Silica_3_1200x800-1024x683.jpg" width="1024" /&gt;			&lt;/div&gt;
		
		&lt;div class="card-body px-4 px-lg-5 pt-4"&gt;
										&lt;div class="card__description mb-3"&gt;
					&lt;p&gt;A research-grade Reader for retrieving data from glass.&lt;/p&gt;				&lt;/div&gt;
					&lt;/div&gt;

			&lt;/div&gt;
&lt;/section&gt;
													&lt;section class="carousel-item msr-cards__card msr-cards__card--carousel"&gt;

	&lt;div class="card material-card h-100 p-0"&gt;

					&lt;div class="embed-responsive embed-responsive-16by9"&gt;
				&lt;img alt="Project Silica | Nature | photo of lab testing set up" class="card-img embed-responsive-item img-object-cover" height="683" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/Nature_Silica_4_1200x800-1024x683.jpg" width="1024" /&gt;			&lt;/div&gt;
		
		&lt;div class="card-body px-4 px-lg-5 pt-4"&gt;
										&lt;div class="card__description mb-3"&gt;
					&lt;p&gt;Close up of Writer showing high-speed multi-beam data encoding on laser pulses.&lt;/p&gt;				&lt;/div&gt;
					&lt;/div&gt;

			&lt;/div&gt;
&lt;/section&gt;
											&lt;/div&gt;
				&lt;/div&gt;
			&lt;/div&gt;
		&lt;/section&gt;
		
			End of slideshow for: 		
	&lt;/div&gt;
&lt;/div&gt;
			&lt;/div&gt;
		
			&lt;/div&gt;
&lt;/div&gt;



&lt;h2 class="wp-block-heading" id="demonstrating-the-technology"&gt;Demonstrating the technology&lt;/h2&gt;



&lt;p&gt;As a research initiative, Project Silica has demonstrated these advances through several proofs of concept, including storing Warner Bros.’ “Superman” movie on quartz glass&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, partnering with Global Music Vault&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to preserve music under ice for 10,000 years&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and working with students on a “Golden Record 2.0” project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a digitally curated archive of images, sounds, music, and spoken language, crowdsourced to represent and preserve humanity’s diversity for millennia.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="looking-ahead"&gt;Looking ahead&lt;/h2&gt;



&lt;p&gt;The research phase is now complete, and we are continuing to consider learnings from Project Silica as we explore the ongoing need for sustainable, long-term preservation of digital information. We have added this paper to our published works so that others can build on them.&lt;/p&gt;







&lt;p&gt;Project Silica has made scientific advances across multiple areas beyond laser direct writing (LDW) in glass, including archival storage systems design, archival workload analysis, datacenter robotics, erasure coding, free-space optical components, and machine learning-based methods for symbol decoding in storage systems. Many of these innovations were described in our ACM Transactions on Storage publication&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; in 2025.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="A blue-to-green gradient background featuring three white icons: a networked globe on the left, a cloud in the center, and a stacked database on the right." class="wp-image-1162006" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/NatureSilica-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns mb-10 pb-1 pr-1 is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Microsoft Research publishes&amp;nbsp;breakthrough&amp;nbsp;in&amp;nbsp;&lt;em&gt;Nature&lt;/em&gt;&amp;nbsp;on glass-based data storage that could preserve information for 10,000 years.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;New&amp;nbsp;technique extends technology from expensive fused silica to ordinary borosilicate glass found in kitchen cookware.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Innovations enable faster parallel writing, simplified readers (one camera instead of three), and easier manufacturing.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Phase voxel method requires only a single laser pulse, significantly reducing complexity and cost.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;Long-term preservation of digital information has long challenged archivists and datacenters, as magnetic tapes and hard drives degrade within decades. Existing archival storage solutions have limited media lifespans that make them less than ideal for preserving information for future generations.&lt;/p&gt;



&lt;p&gt;Now, we are excited to report significant progress on Project Silica&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, our effort to encode data in glass using femtosecond lasers, a technology that could preserve information for 10,000 years. Glass is a permanent data storage material that is resistant to water, heat, and dust.&lt;/p&gt;



&lt;p&gt;In findings published in &lt;em&gt;Nature&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&lt;/em&gt;, we describe a breakthrough that extends the technology beyond expensive fused silica to ordinary borosilicate glass. A readily available and lower-cost medium, this is the same material found in kitchen cookware and oven doors. This advance addresses key barriers to commercialization: cost and availability of storage media. We have unlocked the science for parallel high-speed writing and developed a technique to permit accelerated aging tests on the written glass, suggesting that the data should remain intact for at least 10,000 years.&lt;/p&gt;



&lt;p&gt;Storing data inside glass with femtosecond&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; laser pulses is one of the few technologies on the horizon with the potential for durable, immutable, and long-lived storage. Although we have been leading innovation in this type of storage for years, prior to this research the technique only worked with pure fused silica glass, a type of glass that is relatively difficult to manufacture and available from only a few sources.&lt;/p&gt;



&lt;p&gt;In the paper, we show how data can be stored in borosilicate glass. The new technique stores hundreds of layers of data in glass only 2mm thin, as with previous methods, but with important improvements. The reader for the glass now needs only one camera, not three or four, reducing cost and size. In addition, the writing devices require fewer parts, making them easier to manufacture and calibrate, and enabling them to encode data more quickly.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;PODCAST SERIES&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/h2&gt;
				
								&lt;p class="large" id="ai-testing-and-evaluation-learnings-from-science-and-industry"&gt;Discover how Microsoft is learning from other domains to advance evaluation and testing as a pillar of AI governance.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="key-scientific-discoveries"&gt;Key scientific discoveries&lt;/h2&gt;



&lt;p&gt;The &lt;em&gt;Nature&lt;/em&gt; paper details several key new scientific discoveries:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Advances in birefringent voxel&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; writing&lt;/strong&gt;: For the previous type of data storage in fused silica glass using birefringent (i.e., polarization) voxels, we developed a technique to reduce the number of pulses used to form the voxel from many to only two, critically showing that the polarization of the first pulse is not important to the polarization of the voxel formed. We further developed this to enable pseudo-single-pulse writing, in which a single pulse can be split after its polarization is set to simultaneously form the first pulse for one voxel (where the polarization doesn’t matter) and the second pulse of another (where the set polarization is essential). We demonstrated how to use this pseudo-single-pulse writing to enable fast writing with beam scanning across the media.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Phase voxels, a new storage method&lt;/strong&gt;: We invented a new type of data storage in glass called phase voxels, in which the phase change of the glass is modified instead of its polarization, showing that only a single pulse is necessary to make a phase voxel. We demonstrated that these phase voxels can also be formed in borosilicate glass and devised a technique to read the phase information from phase voxels encoded in this material. We showed that the much higher levels of three-dimensional inter-symbol interference in phase voxels can be mitigated with a machine learning classification model.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Parallel writing capabilities&lt;/strong&gt;: By combining a mathematical model of pre-heating and post-heating within the glass with the invention of a multi-beam delivery system, we showed that many data voxels can be written in proximity in the glass at the same time, significantly increasing writing speed. We explained a method for using light emissions (a side effect of voxel formation) for both static calibration and dynamic control to fully support automatic writing operations.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Optimization and longevity testing&lt;/strong&gt;: We developed a new way to optimize symbol encodings using machine learning and a better way to understand the tradeoff between error rates, error protection, and error recovery when evaluating new digital storage systems. We also created a new nondestructive optical method&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to identify the aging of data storage voxels within the glass, using this and standard accelerated aging techniques to support data lasting 10,000 years. We extended the industry standard Gray codes to apply to nonpower-of-two numbers of symbols.&lt;/p&gt;


&lt;div class="wp-block-msr-cards msr-cards msr-cards--carousel mt-4 has-text-align-left has-cards"&gt;
	&lt;div class="msr-cards__inner"&gt;
		
					&lt;div class="mt-4"&gt;
				&lt;div class="row"&gt;
	&lt;div class="col-12 px-0 px-md-g"&gt;
		&lt;section&gt;
			
			&lt;div class="carousel slide carousel-content-cards carousel-sneak-peek"&gt;
				
					Skip slideshow for: 				
				&lt;div&gt;
					&lt;div class="carousel-controls"&gt;
						&lt;button class="carousel-control-prev " type="button"&gt;
							&lt;span class="sr-only"&gt;Previous slide&lt;/span&gt;
						&lt;/button&gt;

						&lt;ol class="carousel-indicators"&gt;
															&lt;li class="active"&gt;&lt;/li&gt;
															&lt;li class="class"&gt;&lt;/li&gt;
															&lt;li class="class"&gt;&lt;/li&gt;
															&lt;li class="class"&gt;&lt;/li&gt;
													&lt;/ol&gt;

						&lt;button class="carousel-control-next " type="button"&gt;
							&lt;span class="sr-only"&gt;Previous slide&lt;/span&gt;
						&lt;/button&gt;
					&lt;/div&gt;

					&lt;div class="carousel-inner"&gt;
													&lt;section class="carousel-item msr-cards__card msr-cards__card--carousel active"&gt;

	&lt;div class="card material-card h-100 p-0"&gt;

					&lt;div class="embed-responsive embed-responsive-16by9"&gt;
				&lt;img alt="Project Silica | Nature | Microsoft Azure - vertical color bars in varying shades of blue" class="card-img embed-responsive-item img-object-cover" height="683" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/Nature_Silica_1_1200x800-1024x683.jpg" width="1024" /&gt;			&lt;/div&gt;
		
		&lt;div class="card-body px-4 px-lg-5 pt-4"&gt;
										&lt;div class="card__description mb-3"&gt;
					&lt;p&gt;A piece of Project Silica media written with data.&lt;/p&gt;				&lt;/div&gt;
					&lt;/div&gt;

			&lt;/div&gt;
&lt;/section&gt;
													&lt;section class="carousel-item msr-cards__card msr-cards__card--carousel"&gt;

	&lt;div class="card material-card h-100 p-0"&gt;

					&lt;div class="embed-responsive embed-responsive-16by9"&gt;
				&lt;img alt="Project Silica | Nature | photo of lab testing set up" class="card-img embed-responsive-item img-object-cover" height="683" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/Nature_Silica_2_1200x800-1024x683.jpg" width="1024" /&gt;			&lt;/div&gt;
		
		&lt;div class="card-body px-4 px-lg-5 pt-4"&gt;
										&lt;div class="card__description mb-3"&gt;
					&lt;p&gt;A research-grade Writer used to set the record for high speed data writing into glass.&lt;/p&gt;				&lt;/div&gt;
					&lt;/div&gt;

			&lt;/div&gt;
&lt;/section&gt;
													&lt;section class="carousel-item msr-cards__card msr-cards__card--carousel"&gt;

	&lt;div class="card material-card h-100 p-0"&gt;

					&lt;div class="embed-responsive embed-responsive-16by9"&gt;
				&lt;img alt="Project Silica | Nature | photo of lab testing set up" class="card-img embed-responsive-item img-object-cover" height="683" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/Nature_Silica_3_1200x800-1024x683.jpg" width="1024" /&gt;			&lt;/div&gt;
		
		&lt;div class="card-body px-4 px-lg-5 pt-4"&gt;
										&lt;div class="card__description mb-3"&gt;
					&lt;p&gt;A research-grade Reader for retrieving data from glass.&lt;/p&gt;				&lt;/div&gt;
					&lt;/div&gt;

			&lt;/div&gt;
&lt;/section&gt;
													&lt;section class="carousel-item msr-cards__card msr-cards__card--carousel"&gt;

	&lt;div class="card material-card h-100 p-0"&gt;

					&lt;div class="embed-responsive embed-responsive-16by9"&gt;
				&lt;img alt="Project Silica | Nature | photo of lab testing set up" class="card-img embed-responsive-item img-object-cover" height="683" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/02/Nature_Silica_4_1200x800-1024x683.jpg" width="1024" /&gt;			&lt;/div&gt;
		
		&lt;div class="card-body px-4 px-lg-5 pt-4"&gt;
										&lt;div class="card__description mb-3"&gt;
					&lt;p&gt;Close up of Writer showing high-speed multi-beam data encoding on laser pulses.&lt;/p&gt;				&lt;/div&gt;
					&lt;/div&gt;

			&lt;/div&gt;
&lt;/section&gt;
											&lt;/div&gt;
				&lt;/div&gt;
			&lt;/div&gt;
		&lt;/section&gt;
		
			End of slideshow for: 		
	&lt;/div&gt;
&lt;/div&gt;
			&lt;/div&gt;
		
			&lt;/div&gt;
&lt;/div&gt;



&lt;h2 class="wp-block-heading" id="demonstrating-the-technology"&gt;Demonstrating the technology&lt;/h2&gt;



&lt;p&gt;As a research initiative, Project Silica has demonstrated these advances through several proofs of concept, including storing Warner Bros.’ “Superman” movie on quartz glass&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, partnering with Global Music Vault&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to preserve music under ice for 10,000 years&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and working with students on a “Golden Record 2.0” project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a digitally curated archive of images, sounds, music, and spoken language, crowdsourced to represent and preserve humanity’s diversity for millennia.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="looking-ahead"&gt;Looking ahead&lt;/h2&gt;



&lt;p&gt;The research phase is now complete, and we are continuing to consider learnings from Project Silica as we explore the ongoing need for sustainable, long-term preservation of digital information. We have added this paper to our published works so that others can build on them.&lt;/p&gt;







&lt;p&gt;Project Silica has made scientific advances across multiple areas beyond laser direct writing (LDW) in glass, including archival storage systems design, archival workload analysis, datacenter robotics, erasure coding, free-space optical components, and machine learning-based methods for symbol decoding in storage systems. Many of these innovations were described in our ACM Transactions on Storage publication&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; in 2025.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/project-silicas-advances-in-glass-storage-technology/</guid><pubDate>Wed, 18 Feb 2026 16:11:45 +0000</pubDate></item><item><title>[NEW] IBM and UC Berkeley Diagnose Why Enterprise Agents Fail Using IT-Bench and MAST (Hugging Face - Blog)</title><link>https://huggingface.co/blog/ibm-research/itbenchandmast</link><description>&lt;!-- HTML_TAG_START --&gt;
Ayhan Sebin
Saurabh Jha
Rohan Arora
Daby Sow
Mert Cemri
Melissa Pan
Ion Stoica
&lt;p&gt;ITBench HF Space
ITBench HF Dataset
MAST HF Dataset
ITBench Github
MAST Github&lt;/p&gt;
&lt;p&gt;IBM Research and UC Berkeley collaborated to study how agentic LLM systems break in real-world IT automation, for tasks involving incident triage, logs/metrics queries, and Kubernetes actions in long-horizon tool loops.&lt;/p&gt;
&lt;p&gt;Benchmarks typically reduce performance to a single number, telling you whether an agent failed but never why. To solve this black-box problem, we applied MAST (Multi-Agent System Failure Taxonomy), an emerging practice for diagnosing agentic reliability ). By leveraging MAST to analyze ITBench—the industry benchmark for SRE, Security, and FinOps automation—we turned raw execution traces into structured failure signatures, revealing exactly what broke and how to fix it. We annotated 310 ITBench SRE traces across three distinct model classes: Gemini-3-Flash, Kimi-K2, and GPT-OSS-120B.&lt;/p&gt;
&lt;p&gt;Key Findings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Frontier models like Gemini-3-Flash fail cleanly (2.6 failure modes/trace), typically hitting isolated bottlenecks like verification. Large open models like GPT-OSS-120B suffer from cascading failure modes (5.3 failure modes/trace). -A single reasoning mismatch early in the run poisons the context, leading to compounding hallucinations.&lt;/li&gt;
&lt;li&gt;Across all models, the strongest predictor of failure is FM-3.3 (Incorrect Verification). Agents consistently "declare victory" without checking ground truth. &lt;/li&gt;
&lt;li&gt;Kimi-K2 struggles to recognize when a task is done. It exhibits a massive spike in Premature Termination (+46%) and Unaware of Termination Conditions (+43%), often quitting just before solving the problem or looping indefinitely.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Takeaways from our analysis when building agents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For Frontier Models like Gemini: Externalize Verification. Never let the LLM grade its own homework. Require hard tool evidence before exit.&lt;/li&gt;
&lt;li&gt;Put termination + loop control outside the model: Termination issues are common killers (FM-1.5). Add explicit stop conditions + loop detectors for repeated tool calls/actions or implement Finite State Machines.&lt;/li&gt;
&lt;li&gt;Force clarify-or-read-only when inputs are ambiguous: Clarification failures (FM-2.2) are a major failure driver for smaller models. Make ambiguity a first-class branch in your agent graph.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you’re building agents for enterprise IT workflows, this is the kind of evaluation you want: not just “did it pass?”, but “what broke, where, and what intervention is most leverageable?”&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		The "Black Box" Problem of Agent Benchmarks
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Benchmarks like &lt;strong&gt;ITBench&lt;/strong&gt; are becoming the standard for measuring agentic performance in high-stakes IT automation tasks. In ITBench, agents act as Site Reliability Engineers (SREs) or Security Analysts tasked with diagnosing Kubernetes outages, patching vulnerabilities, or managing cloud costs in production environments.&lt;/p&gt;
&lt;p&gt;This benchmarks use success rate as a main metric to evaluate agents. However, this metric is insufficient for engineering robust systems. Knowing that an agentic system achieves a 14% success rate on ITBench tells us &lt;em&gt;that&lt;/em&gt; it failed, but not why: &lt;strong&gt;Did it fail because it forgot the context? Because it hallucinated a command? Or because it simply did not terminate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Without a comprehensive approach to diagnose these failures, developers are left guessing, often resorting to blind prompting tweaks that solve one problem only to create another.&lt;/p&gt;
&lt;p&gt;As a new standard to analyze the failure modes of complex agentic systems, we developed &lt;strong&gt;MAST (Multi-Agent System Failure Taxonomy)&lt;/strong&gt;. MAST brings more insights and open up the opaque evaluation of these benchmarks. Derived from a rigorous analysis of over 1,600 traces across seven different frameworks, MAST provides a standardized taxonomy for agent failures.&lt;/p&gt;
&lt;p&gt;MAST converts unstructured execution logs into structured "&lt;em&gt;failure vectors&lt;/em&gt;" based on 14 distinct patterns across three key categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FC1: System Design Issues&lt;/strong&gt; (The "Skeleton")&lt;ul&gt;
&lt;li&gt;Failures here stem from the agent's architecture and role definition.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Examples:&lt;/em&gt; &lt;strong&gt;FM-1.3 Step Repetition&lt;/strong&gt; (looping), &lt;strong&gt;FM-1.4 Loss of Conversation History&lt;/strong&gt; (memory leaks), &lt;strong&gt;FM-1.5 Unaware of Termination&lt;/strong&gt; (failing to stop).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FC2: Inter-Agent Misalignment&lt;/strong&gt; (The "Communication")&lt;ul&gt;
&lt;li&gt;Failures arising during runtime from how agents talk to each other or the environment.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Examples:&lt;/em&gt; &lt;strong&gt;FM-2.2 Fail to Ask for Clarification&lt;/strong&gt; (assuming instead of asking), &lt;strong&gt;FM-2.3 Task Derailment&lt;/strong&gt; (going off-topic).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FC3: Task Verification&lt;/strong&gt; (The "Quality Control")&lt;ul&gt;
&lt;li&gt;Failures in quality assurance of the agents' output.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Examples:&lt;/em&gt; &lt;strong&gt;FM-3.1 Premature Termination&lt;/strong&gt; (giving up too soon), &lt;strong&gt;FM-3.3 Incorrect Verification&lt;/strong&gt; (hallucinating success).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="MAST ANALYSIS" src="https://cdn-uploads.huggingface.co/production/uploads/64e8143f6de557454220921e/e4z2uA2pkASgWJdqdGJZl.webp" /&gt;&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		The Experiment: Diagnosing ITBench Agents
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;We stress-test the idea of using MAST to make agent evaluations actionable and gain insights on the failure modes by applying it to ITBench, a popular evaluation suite for IT automation tasks across &lt;strong&gt;SRE&lt;/strong&gt;, &lt;strong&gt;Security/Compliance&lt;/strong&gt;, and &lt;strong&gt;FinOps&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We annotated 310 ITBench SRE execution traces produced by an SRE agent built with Codex in realistic environments. These traces capture natural language interactions between agents and their tools across three models representing different capability tiers: Gemini-3-Flash, Kimi-K2, and GPT-OSS-120B. This lets us look past simple success metrics and investigate the distinct failure signatures driving these results. For this we use the recall scores, as the models by design only output a maximum of 3-5 outputs and SREs prefer the recall scores over F-1 score.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Gemini-3-Flash:&lt;/strong&gt; 100 traces (75.5% Mean Recall)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kimi-K2:&lt;/strong&gt; 105 traces (28.6% Mean Recall)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPT-OSS-120B:&lt;/strong&gt; 105 traces (12.4% Mean Recall)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below, we detail the findings from this diagnostic analysis.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Finding 1: Stronger models like Gemini-3-Flash shows surgical (isolated failure modes) per trace whereas open sourced Kimi-K2 and GPT-oss-120b show compounding failure patterns
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;When we examine the failed traces, a clear hierarchy of complexity becomes apparent across the three models. This is measured by the number of distinct failure modes observed per failed run.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Gemini-3-Flash:&lt;/strong&gt;&amp;nbsp;2.6 failure modes per failed trace&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kimi-K2:&lt;/strong&gt;&amp;nbsp;4.7 failure modes per failed trace&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPT-OSS-120B:&lt;/strong&gt;&amp;nbsp;5.3 failure modes per failed trace&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This disparity in failure mode density reveals a fundamental difference in how these systems break down. Gemini-3-Flash exhibits a surgical failure profile. Even in unsuccessful runs, it maintains high internal coherence&amp;nbsp;and typically fails due to a single isolated failure, such as an incorrect verification step. These failures are precise and far easier to diagnose.&lt;/p&gt;
&lt;p&gt;On the opposite end of the spectrum, GPT-OSS-120B suffers from cascading collapse. In these&amp;nbsp;traces, we observe that errors tend to compound over time. A small reasoning mismatch&amp;nbsp;early in the process often leads to a deviation from the task specification, which in turn&amp;nbsp;triggers a total derailment of the agent. Kimi-K2 represents the&amp;nbsp;middle ground, where failures are more frequent and complex than the frontier model but do&amp;nbsp;not reach the systemic instability seen in the 120B open weights model.&lt;/p&gt;
&lt;p&gt;The significance of this finding is that a higher success rate is often accompanied&amp;nbsp;by isolated failure. Systems that fail with fewer simultaneous problems are far more predictable and&amp;nbsp;simpler to improve through targeted engineering interventions.&lt;/p&gt;
&lt;p&gt;&lt;img alt="failure mode" src="https://cdn-uploads.huggingface.co/production/uploads/64e8143f6de557454220921e/7OtWv_RJ1BZj8n3ChhgUz.webp" /&gt;&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Finding 2: "Non-Fatal" vs. "Fatal" Failures
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Perhaps the most critical insight from MAST is distinguishing between failures that the system can &lt;em&gt;tolerate&lt;/em&gt; versus those that are fatal to success of the downstream task. By comparing the distribution of failure modes in &lt;strong&gt;Successful Traces&lt;/strong&gt; vs. &lt;strong&gt;Failed Traces&lt;/strong&gt;, we can classify them into three categories.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		The "Non-Fatal" (Benign) Flaws
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Across all three models, certain failure modes appear frequently even in runs that ultimately succeed. These are often structural frictions rather than terminal bugs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FM-1.3 Step Repetition:&lt;/strong&gt;&amp;nbsp;This mode is present in over 90 percent of successful Kimi-K2 runs. In the SRE domain, iteration is often a necessity. An agent might query the&amp;nbsp;same metric multiple times to verify if a service is stabilizing or if a fix has taken&amp;nbsp;effect. Gemini-3-Flash actually shows less repetition in its failed traces, suggesting&amp;nbsp;that it sometimes fails because it does not iterate enough.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-1.1 Disobey Task Specification:&lt;/strong&gt;&amp;nbsp;Agents frequently deviate from strict tool formatting or sequential&amp;nbsp;instructions yet still manage to identify the correct root cause.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This separation is where MAST proves&amp;nbsp;its value. It allows us to ignore the bening failures like repetition that often occurs in troubleshooting, and focus instead on fatal failures that killed a run.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		The "Fatal" Flaws
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Certain behaviors strongly separate success from failure. When these modes appear, the probability of a successful outcome drops precipitously. The most&amp;nbsp;prominent example is&amp;nbsp;&lt;strong&gt;FM-3.3 (Incorrect Verification)&lt;/strong&gt;. This mode&amp;nbsp;shows a 52 percent increase in failed Gemini-3-Flash traces compared to its&amp;nbsp;successful ones. Other prominent failure modes are 1.5 (Unaware of Termination Conditions) and 2.6 (Reasoning Action Mismatch).&lt;/p&gt;
&lt;p&gt;If these happen, the run is likely dead; guiding practitioners to develop robust context management strategies across agents in the system and multiple turns of interactions.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;Case Study: Gemini-3-Flash&amp;nbsp;(Decisive but Overconfident)&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Gemini-3-Flash is highly efficient, but its primary bottleneck is its tendency to assume success without rigorous proof. Its failure signature is dominated by a massive delta in verification errors. It often identifies the correct signals but terminates before cross-referencing them against the ground truth. To fix this, developers should implement an external verification gate. By requiring tool-based evidence like a cleared alert or a healthy metric threshold before allowing the agent to exit, we can mitigate this model’s inherent overconfidence.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Fix:&lt;/strong&gt; To improve Gemini-3-Flash on ITBench, prompt engineering won't help much. In particular, the experiments we shown in our NeurIPS 2025 paper shows that with manual interventions like prompt engineering for memory related failures, we can get only up to around 15.6% performance improvements, whereas in a previous blogpost on MAST, we showed that by introducing new agents such as a &lt;strong&gt;Summarizer Agent&lt;/strong&gt; to remind the other agents of what is going on and continuously augment their state (fixing FM-1.4) or by introducing context management mechanisms (such as a stricter &lt;strong&gt;State Machine&lt;/strong&gt; to enforce termination to fix FM-1.5), we can get up to 53% performance improvement as these tackle more fundamental issues with the system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="gemini 3" src="https://cdn-uploads.huggingface.co/production/uploads/64e8143f6de557454220921e/TIC3M-6ZyIJhRuWdv-Zvr.webp" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;Case Study: Kimi-K2 (The Termination Crisis)&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h3&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While termination confusion&amp;nbsp;(FM-3.1 and FM-1.5) is the prevalent failure mode&amp;nbsp;for Kimi-K2, its failed trajectories are defined by a pervasive&amp;nbsp;&lt;strong&gt;Action-Reasoning Mismatch (FM-2.6)&lt;/strong&gt;, which is present in a&amp;nbsp;staggering&amp;nbsp;&lt;strong&gt;92% of its failures&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The Execution Gap:&lt;/strong&gt;&amp;nbsp;While parts of its internal reasoning are often accurate, it suffers from a 92 percent failure prevalence of&amp;nbsp;&lt;strong&gt;FM-2.6 (Action-Reasoning Mismatch)&lt;/strong&gt;. It frequently identifies the correct next step but then executes a redundant or irrelevant command.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Meta-Loop Trap:&lt;/strong&gt;&amp;nbsp;Roughly 25 percent of failed traces involve&amp;nbsp;&lt;strong&gt;FM-2.3 (Task Derailment)&lt;/strong&gt;. When a tool call returns a minor error, the agent often abandons the primary incident to enter a cycle of debugging its own investigation scripts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kimi-K2 is a good example of an overthinking model, its reasoning chains are often too long but can fail at execution.&lt;/p&gt;
&lt;p&gt;&lt;img alt="kimi2" src="https://cdn-uploads.huggingface.co/production/uploads/64e8143f6de557454220921e/oiqI0JpzhJIzT8WU8YPRM.webp" /&gt;&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Case Study: &lt;strong&gt;GPT-OSS-120B&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;GPT-OSS-120B exhibits the most unstable failure signature of the cohort. This model exhibits an average of 5.3 distinct failure modes per failed trace, indicating a fundamental inability to maintain internal state.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Loss of Conversation History (FM-1.4):&lt;/strong&gt;&amp;nbsp;This is a unique fatal flaw for the 120B&amp;nbsp;model. It loses conversation history in&amp;nbsp;&lt;strong&gt;24%&lt;/strong&gt;&amp;nbsp;of traces, whereas Gemini-3-Flash exhibited zero memory loss and Kimi-K2 only 7%. As&amp;nbsp;SRE traces grow in length, GPT-OSS-120B effectively&amp;nbsp;"forgets" the alerts it was originally triaging, leading to total task&amp;nbsp;derailment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reasoning Disconnect (FM-2.6):&lt;/strong&gt;&amp;nbsp;A staggering&amp;nbsp;&lt;strong&gt;94%&lt;/strong&gt;&amp;nbsp;of traces show a decoupling of reasoning and&amp;nbsp;action. It is nearly 3x more likely than Gemini (31%) to&amp;nbsp;describe a correct plan but then execute a completely unrelated or redundant tool call.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="OSS" src="https://cdn-uploads.huggingface.co/production/uploads/64e8143f6de557454220921e/i179ZOT-r6et7kC23J0oy.webp" /&gt;&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		A different (and more useful) way to read the plots: “fatal” vs “non-fatal”
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;In summary, MAST lets you split failure modes into two buckets:&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Recoverable / structural (show up even in successful traces)
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;These are failures which are not fatal and from which the system can recover to successfully complete the task.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FM-1.3 Step repetition&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-3.3 Incorrect verification&lt;/strong&gt; (important nuance: the system &lt;em&gt;does&lt;/em&gt; verify; it just verifies poorly)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-2.6 Reasoning–action mismatch&lt;/strong&gt; (often present, but not always decisive)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Fatal / decisive (strongly associated with failed traces)
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;These are failures from which the system typically cannot recover.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FM-1.5 Unaware of termination conditions&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-3.1 Premature termination&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-1.4 Loss of conversation history&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-2.3 Task derailment&lt;/strong&gt; (rare but extremely diagnostic when it appears)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-2.2 Fail to ask for clarification&lt;/strong&gt; (especially for Granite/Llama regimes)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is the “richer understanding” piece: &lt;strong&gt;two models can have the same success rate on a small slice, yet fail for entirely different reasons—requiring different fixes.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Conclusion
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;MAST is a tool that inspects the agentic system traces to identify fine-grain failure types that support system development and debugging. In this blog, we show that by applying MAST to ITBench, we move from generic observations ("Open models struggle") to a concrete engineering roadmap that help improving the performance of agentic systems relying on thse models, e.g.:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;For Gemini-3-Flash:&lt;/strong&gt; &amp;nbsp;Verification failure (&lt;strong&gt;FM-3.3&lt;/strong&gt;) is the most common fatal failure for surgical models. Never allow an agent to self-terminate; require hard, tool-mediated evidence (e.g., AlertManager clearance or K8s state changes) before a run is considered successful.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;For Kimi-K2:&lt;/strong&gt; Use a deterministic state machine to fix the model's frequent struggle with recognizing task completion. This model’s reasoning chains can be too long and struggle to terminate, so it might benefit significantly from a tighter control on when to end.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;For GPT-oss-120b:&lt;/strong&gt; Systemic collapse occurs when minor reasoning mismatches (&lt;strong&gt;FM-2.6&lt;/strong&gt;) poison the task history. Implement aggressive context hygiene and early error detection to ensure that small misalignment's do not compound into total derailment.&lt;/li&gt;
&lt;/ol&gt;

&lt;!-- HTML_TAG_END --&gt;</description><content:encoded>&lt;!-- HTML_TAG_START --&gt;
Ayhan Sebin
Saurabh Jha
Rohan Arora
Daby Sow
Mert Cemri
Melissa Pan
Ion Stoica
&lt;p&gt;ITBench HF Space
ITBench HF Dataset
MAST HF Dataset
ITBench Github
MAST Github&lt;/p&gt;
&lt;p&gt;IBM Research and UC Berkeley collaborated to study how agentic LLM systems break in real-world IT automation, for tasks involving incident triage, logs/metrics queries, and Kubernetes actions in long-horizon tool loops.&lt;/p&gt;
&lt;p&gt;Benchmarks typically reduce performance to a single number, telling you whether an agent failed but never why. To solve this black-box problem, we applied MAST (Multi-Agent System Failure Taxonomy), an emerging practice for diagnosing agentic reliability ). By leveraging MAST to analyze ITBench—the industry benchmark for SRE, Security, and FinOps automation—we turned raw execution traces into structured failure signatures, revealing exactly what broke and how to fix it. We annotated 310 ITBench SRE traces across three distinct model classes: Gemini-3-Flash, Kimi-K2, and GPT-OSS-120B.&lt;/p&gt;
&lt;p&gt;Key Findings:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Frontier models like Gemini-3-Flash fail cleanly (2.6 failure modes/trace), typically hitting isolated bottlenecks like verification. Large open models like GPT-OSS-120B suffer from cascading failure modes (5.3 failure modes/trace). -A single reasoning mismatch early in the run poisons the context, leading to compounding hallucinations.&lt;/li&gt;
&lt;li&gt;Across all models, the strongest predictor of failure is FM-3.3 (Incorrect Verification). Agents consistently "declare victory" without checking ground truth. &lt;/li&gt;
&lt;li&gt;Kimi-K2 struggles to recognize when a task is done. It exhibits a massive spike in Premature Termination (+46%) and Unaware of Termination Conditions (+43%), often quitting just before solving the problem or looping indefinitely.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Takeaways from our analysis when building agents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;For Frontier Models like Gemini: Externalize Verification. Never let the LLM grade its own homework. Require hard tool evidence before exit.&lt;/li&gt;
&lt;li&gt;Put termination + loop control outside the model: Termination issues are common killers (FM-1.5). Add explicit stop conditions + loop detectors for repeated tool calls/actions or implement Finite State Machines.&lt;/li&gt;
&lt;li&gt;Force clarify-or-read-only when inputs are ambiguous: Clarification failures (FM-2.2) are a major failure driver for smaller models. Make ambiguity a first-class branch in your agent graph.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you’re building agents for enterprise IT workflows, this is the kind of evaluation you want: not just “did it pass?”, but “what broke, where, and what intervention is most leverageable?”&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		The "Black Box" Problem of Agent Benchmarks
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Benchmarks like &lt;strong&gt;ITBench&lt;/strong&gt; are becoming the standard for measuring agentic performance in high-stakes IT automation tasks. In ITBench, agents act as Site Reliability Engineers (SREs) or Security Analysts tasked with diagnosing Kubernetes outages, patching vulnerabilities, or managing cloud costs in production environments.&lt;/p&gt;
&lt;p&gt;This benchmarks use success rate as a main metric to evaluate agents. However, this metric is insufficient for engineering robust systems. Knowing that an agentic system achieves a 14% success rate on ITBench tells us &lt;em&gt;that&lt;/em&gt; it failed, but not why: &lt;strong&gt;Did it fail because it forgot the context? Because it hallucinated a command? Or because it simply did not terminate?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Without a comprehensive approach to diagnose these failures, developers are left guessing, often resorting to blind prompting tweaks that solve one problem only to create another.&lt;/p&gt;
&lt;p&gt;As a new standard to analyze the failure modes of complex agentic systems, we developed &lt;strong&gt;MAST (Multi-Agent System Failure Taxonomy)&lt;/strong&gt;. MAST brings more insights and open up the opaque evaluation of these benchmarks. Derived from a rigorous analysis of over 1,600 traces across seven different frameworks, MAST provides a standardized taxonomy for agent failures.&lt;/p&gt;
&lt;p&gt;MAST converts unstructured execution logs into structured "&lt;em&gt;failure vectors&lt;/em&gt;" based on 14 distinct patterns across three key categories:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FC1: System Design Issues&lt;/strong&gt; (The "Skeleton")&lt;ul&gt;
&lt;li&gt;Failures here stem from the agent's architecture and role definition.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Examples:&lt;/em&gt; &lt;strong&gt;FM-1.3 Step Repetition&lt;/strong&gt; (looping), &lt;strong&gt;FM-1.4 Loss of Conversation History&lt;/strong&gt; (memory leaks), &lt;strong&gt;FM-1.5 Unaware of Termination&lt;/strong&gt; (failing to stop).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FC2: Inter-Agent Misalignment&lt;/strong&gt; (The "Communication")&lt;ul&gt;
&lt;li&gt;Failures arising during runtime from how agents talk to each other or the environment.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Examples:&lt;/em&gt; &lt;strong&gt;FM-2.2 Fail to Ask for Clarification&lt;/strong&gt; (assuming instead of asking), &lt;strong&gt;FM-2.3 Task Derailment&lt;/strong&gt; (going off-topic).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FC3: Task Verification&lt;/strong&gt; (The "Quality Control")&lt;ul&gt;
&lt;li&gt;Failures in quality assurance of the agents' output.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Examples:&lt;/em&gt; &lt;strong&gt;FM-3.1 Premature Termination&lt;/strong&gt; (giving up too soon), &lt;strong&gt;FM-3.3 Incorrect Verification&lt;/strong&gt; (hallucinating success).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="MAST ANALYSIS" src="https://cdn-uploads.huggingface.co/production/uploads/64e8143f6de557454220921e/e4z2uA2pkASgWJdqdGJZl.webp" /&gt;&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		The Experiment: Diagnosing ITBench Agents
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;We stress-test the idea of using MAST to make agent evaluations actionable and gain insights on the failure modes by applying it to ITBench, a popular evaluation suite for IT automation tasks across &lt;strong&gt;SRE&lt;/strong&gt;, &lt;strong&gt;Security/Compliance&lt;/strong&gt;, and &lt;strong&gt;FinOps&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We annotated 310 ITBench SRE execution traces produced by an SRE agent built with Codex in realistic environments. These traces capture natural language interactions between agents and their tools across three models representing different capability tiers: Gemini-3-Flash, Kimi-K2, and GPT-OSS-120B. This lets us look past simple success metrics and investigate the distinct failure signatures driving these results. For this we use the recall scores, as the models by design only output a maximum of 3-5 outputs and SREs prefer the recall scores over F-1 score.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Gemini-3-Flash:&lt;/strong&gt; 100 traces (75.5% Mean Recall)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kimi-K2:&lt;/strong&gt; 105 traces (28.6% Mean Recall)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPT-OSS-120B:&lt;/strong&gt; 105 traces (12.4% Mean Recall)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Below, we detail the findings from this diagnostic analysis.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Finding 1: Stronger models like Gemini-3-Flash shows surgical (isolated failure modes) per trace whereas open sourced Kimi-K2 and GPT-oss-120b show compounding failure patterns
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;When we examine the failed traces, a clear hierarchy of complexity becomes apparent across the three models. This is measured by the number of distinct failure modes observed per failed run.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Gemini-3-Flash:&lt;/strong&gt;&amp;nbsp;2.6 failure modes per failed trace&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kimi-K2:&lt;/strong&gt;&amp;nbsp;4.7 failure modes per failed trace&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPT-OSS-120B:&lt;/strong&gt;&amp;nbsp;5.3 failure modes per failed trace&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This disparity in failure mode density reveals a fundamental difference in how these systems break down. Gemini-3-Flash exhibits a surgical failure profile. Even in unsuccessful runs, it maintains high internal coherence&amp;nbsp;and typically fails due to a single isolated failure, such as an incorrect verification step. These failures are precise and far easier to diagnose.&lt;/p&gt;
&lt;p&gt;On the opposite end of the spectrum, GPT-OSS-120B suffers from cascading collapse. In these&amp;nbsp;traces, we observe that errors tend to compound over time. A small reasoning mismatch&amp;nbsp;early in the process often leads to a deviation from the task specification, which in turn&amp;nbsp;triggers a total derailment of the agent. Kimi-K2 represents the&amp;nbsp;middle ground, where failures are more frequent and complex than the frontier model but do&amp;nbsp;not reach the systemic instability seen in the 120B open weights model.&lt;/p&gt;
&lt;p&gt;The significance of this finding is that a higher success rate is often accompanied&amp;nbsp;by isolated failure. Systems that fail with fewer simultaneous problems are far more predictable and&amp;nbsp;simpler to improve through targeted engineering interventions.&lt;/p&gt;
&lt;p&gt;&lt;img alt="failure mode" src="https://cdn-uploads.huggingface.co/production/uploads/64e8143f6de557454220921e/7OtWv_RJ1BZj8n3ChhgUz.webp" /&gt;&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Finding 2: "Non-Fatal" vs. "Fatal" Failures
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Perhaps the most critical insight from MAST is distinguishing between failures that the system can &lt;em&gt;tolerate&lt;/em&gt; versus those that are fatal to success of the downstream task. By comparing the distribution of failure modes in &lt;strong&gt;Successful Traces&lt;/strong&gt; vs. &lt;strong&gt;Failed Traces&lt;/strong&gt;, we can classify them into three categories.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		The "Non-Fatal" (Benign) Flaws
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Across all three models, certain failure modes appear frequently even in runs that ultimately succeed. These are often structural frictions rather than terminal bugs.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FM-1.3 Step Repetition:&lt;/strong&gt;&amp;nbsp;This mode is present in over 90 percent of successful Kimi-K2 runs. In the SRE domain, iteration is often a necessity. An agent might query the&amp;nbsp;same metric multiple times to verify if a service is stabilizing or if a fix has taken&amp;nbsp;effect. Gemini-3-Flash actually shows less repetition in its failed traces, suggesting&amp;nbsp;that it sometimes fails because it does not iterate enough.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-1.1 Disobey Task Specification:&lt;/strong&gt;&amp;nbsp;Agents frequently deviate from strict tool formatting or sequential&amp;nbsp;instructions yet still manage to identify the correct root cause.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This separation is where MAST proves&amp;nbsp;its value. It allows us to ignore the bening failures like repetition that often occurs in troubleshooting, and focus instead on fatal failures that killed a run.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		The "Fatal" Flaws
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Certain behaviors strongly separate success from failure. When these modes appear, the probability of a successful outcome drops precipitously. The most&amp;nbsp;prominent example is&amp;nbsp;&lt;strong&gt;FM-3.3 (Incorrect Verification)&lt;/strong&gt;. This mode&amp;nbsp;shows a 52 percent increase in failed Gemini-3-Flash traces compared to its&amp;nbsp;successful ones. Other prominent failure modes are 1.5 (Unaware of Termination Conditions) and 2.6 (Reasoning Action Mismatch).&lt;/p&gt;
&lt;p&gt;If these happen, the run is likely dead; guiding practitioners to develop robust context management strategies across agents in the system and multiple turns of interactions.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;Case Study: Gemini-3-Flash&amp;nbsp;(Decisive but Overconfident)&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Gemini-3-Flash is highly efficient, but its primary bottleneck is its tendency to assume success without rigorous proof. Its failure signature is dominated by a massive delta in verification errors. It often identifies the correct signals but terminates before cross-referencing them against the ground truth. To fix this, developers should implement an external verification gate. By requiring tool-based evidence like a cleared alert or a healthy metric threshold before allowing the agent to exit, we can mitigate this model’s inherent overconfidence.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Fix:&lt;/strong&gt; To improve Gemini-3-Flash on ITBench, prompt engineering won't help much. In particular, the experiments we shown in our NeurIPS 2025 paper shows that with manual interventions like prompt engineering for memory related failures, we can get only up to around 15.6% performance improvements, whereas in a previous blogpost on MAST, we showed that by introducing new agents such as a &lt;strong&gt;Summarizer Agent&lt;/strong&gt; to remind the other agents of what is going on and continuously augment their state (fixing FM-1.4) or by introducing context management mechanisms (such as a stricter &lt;strong&gt;State Machine&lt;/strong&gt; to enforce termination to fix FM-1.5), we can get up to 53% performance improvement as these tackle more fundamental issues with the system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="gemini 3" src="https://cdn-uploads.huggingface.co/production/uploads/64e8143f6de557454220921e/TIC3M-6ZyIJhRuWdv-Zvr.webp" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		&lt;strong&gt;Case Study: Kimi-K2 (The Termination Crisis)&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h3&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While termination confusion&amp;nbsp;(FM-3.1 and FM-1.5) is the prevalent failure mode&amp;nbsp;for Kimi-K2, its failed trajectories are defined by a pervasive&amp;nbsp;&lt;strong&gt;Action-Reasoning Mismatch (FM-2.6)&lt;/strong&gt;, which is present in a&amp;nbsp;staggering&amp;nbsp;&lt;strong&gt;92% of its failures&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The Execution Gap:&lt;/strong&gt;&amp;nbsp;While parts of its internal reasoning are often accurate, it suffers from a 92 percent failure prevalence of&amp;nbsp;&lt;strong&gt;FM-2.6 (Action-Reasoning Mismatch)&lt;/strong&gt;. It frequently identifies the correct next step but then executes a redundant or irrelevant command.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Meta-Loop Trap:&lt;/strong&gt;&amp;nbsp;Roughly 25 percent of failed traces involve&amp;nbsp;&lt;strong&gt;FM-2.3 (Task Derailment)&lt;/strong&gt;. When a tool call returns a minor error, the agent often abandons the primary incident to enter a cycle of debugging its own investigation scripts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kimi-K2 is a good example of an overthinking model, its reasoning chains are often too long but can fail at execution.&lt;/p&gt;
&lt;p&gt;&lt;img alt="kimi2" src="https://cdn-uploads.huggingface.co/production/uploads/64e8143f6de557454220921e/oiqI0JpzhJIzT8WU8YPRM.webp" /&gt;&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Case Study: &lt;strong&gt;GPT-OSS-120B&lt;/strong&gt;
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;GPT-OSS-120B exhibits the most unstable failure signature of the cohort. This model exhibits an average of 5.3 distinct failure modes per failed trace, indicating a fundamental inability to maintain internal state.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Loss of Conversation History (FM-1.4):&lt;/strong&gt;&amp;nbsp;This is a unique fatal flaw for the 120B&amp;nbsp;model. It loses conversation history in&amp;nbsp;&lt;strong&gt;24%&lt;/strong&gt;&amp;nbsp;of traces, whereas Gemini-3-Flash exhibited zero memory loss and Kimi-K2 only 7%. As&amp;nbsp;SRE traces grow in length, GPT-OSS-120B effectively&amp;nbsp;"forgets" the alerts it was originally triaging, leading to total task&amp;nbsp;derailment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reasoning Disconnect (FM-2.6):&lt;/strong&gt;&amp;nbsp;A staggering&amp;nbsp;&lt;strong&gt;94%&lt;/strong&gt;&amp;nbsp;of traces show a decoupling of reasoning and&amp;nbsp;action. It is nearly 3x more likely than Gemini (31%) to&amp;nbsp;describe a correct plan but then execute a completely unrelated or redundant tool call.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="OSS" src="https://cdn-uploads.huggingface.co/production/uploads/64e8143f6de557454220921e/i179ZOT-r6et7kC23J0oy.webp" /&gt;&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		A different (and more useful) way to read the plots: “fatal” vs “non-fatal”
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;In summary, MAST lets you split failure modes into two buckets:&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Recoverable / structural (show up even in successful traces)
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;These are failures which are not fatal and from which the system can recover to successfully complete the task.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FM-1.3 Step repetition&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-3.3 Incorrect verification&lt;/strong&gt; (important nuance: the system &lt;em&gt;does&lt;/em&gt; verify; it just verifies poorly)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-2.6 Reasoning–action mismatch&lt;/strong&gt; (often present, but not always decisive)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Fatal / decisive (strongly associated with failed traces)
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;These are failures from which the system typically cannot recover.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FM-1.5 Unaware of termination conditions&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-3.1 Premature termination&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-1.4 Loss of conversation history&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-2.3 Task derailment&lt;/strong&gt; (rare but extremely diagnostic when it appears)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FM-2.2 Fail to ask for clarification&lt;/strong&gt; (especially for Granite/Llama regimes)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is the “richer understanding” piece: &lt;strong&gt;two models can have the same success rate on a small slice, yet fail for entirely different reasons—requiring different fixes.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Conclusion
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;MAST is a tool that inspects the agentic system traces to identify fine-grain failure types that support system development and debugging. In this blog, we show that by applying MAST to ITBench, we move from generic observations ("Open models struggle") to a concrete engineering roadmap that help improving the performance of agentic systems relying on thse models, e.g.:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;For Gemini-3-Flash:&lt;/strong&gt; &amp;nbsp;Verification failure (&lt;strong&gt;FM-3.3&lt;/strong&gt;) is the most common fatal failure for surgical models. Never allow an agent to self-terminate; require hard, tool-mediated evidence (e.g., AlertManager clearance or K8s state changes) before a run is considered successful.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;For Kimi-K2:&lt;/strong&gt; Use a deterministic state machine to fix the model's frequent struggle with recognizing task completion. This model’s reasoning chains can be too long and struggle to terminate, so it might benefit significantly from a tighter control on when to end.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;For GPT-oss-120b:&lt;/strong&gt; Systemic collapse occurs when minor reasoning mismatches (&lt;strong&gt;FM-2.6&lt;/strong&gt;) poison the task history. Implement aggressive context hygiene and early error detection to ensure that small misalignment's do not compound into total derailment.&lt;/li&gt;
&lt;/ol&gt;

&lt;!-- HTML_TAG_END --&gt;</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/ibm-research/itbenchandmast</guid><pubDate>Wed, 18 Feb 2026 16:15:45 +0000</pubDate></item><item><title>[NEW] World Labs lands $1B, with $200M from Autodesk, to bring world models into 3D workflows (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/18/world-labs-lands-200m-from-autodesk-to-bring-world-models-into-3d-workflows/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Untitled-design.png?resize=1200,764" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Fei-Fei Li’s World Labs has secured a $200 million investment from software design giant Autodesk as part of a larger $1 billion round from backers including AMD, Emerson Collective, Fidelity, Nvidia, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;World Labs, which emerged from stealth in 2024 with $230 million at a $1 billion valuation, declined to say whether the latest round boosted its valuation. However, reports a month ago suggested it was aiming to raise at a $5 billion valuation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The partnership between World Labs and Autodesk will see the two companies collaborating to explore how World Labs’ models — AI systems that can generate and reason about immersive 3D environments — can work alongside Autodesk’s tools, and vice versa, starting with a focus on entertainment use cases.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For World Labs, Autodesk’s investment is a signal that its product has commercial appeal. The startup’s first world model product, Marble, released last November, lets users create editable, downloadable 3D environments.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Autodesk is one of the biggest developers of 3D CAD (computer-aided design) software. Its platform underpins architectural, engineering, construction, manufacturing, and entertainment workflows. That focus on the built world makes investment in advanced spatial AI a natural extension of its core business.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Or as Li put it in a statement: “Autodesk has long helped people think spatially and solve real-world problems and, together, we share a clear purpose: building physical AI that augments human creativity and puts more powerful tools in the hands of designers, builders, and creators.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the deal, Autodesk will serve as an advisor to World Labs, and the two will collaborate at the “research and model level.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Daron Green, Autodesk’s chief scientist, told TechCrunch the partnership is still in its early days, so the precise form it’s going to take hasn’t been determined yet.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You could anticipate us consuming their models or them consuming our models in different settings,” Green said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He mused that customers might like to start with a world-model-based sketch in World Labs (say, of an office layout) and then drill down on certain design aspects (like the design of the desk), which is where Autodesk’s tech might come in. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Similarly, you might want to take an object that you’ve designed in our [platform], and put it in a context that you create through one of [World Labs’] prompts,” Green said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Green added that data sharing is not part of the agreement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Green said the two companies plan to start with media and entertainment use cases. Most companies building world models — including Google DeepMind and Runway — see gaming and interactive entertainment as an initial go-to-market strategy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Autodesk already works with most major media production companies and has been training models for character animation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These are close to world models,” Green said. “They’re a characterization of an animal in the world that’s responding to physical constraints like time, maybe a terrain it needs to traverse. So there’s a physical understanding in the model, and you can see how that might be combined [with World Labs’ tech]. You’re not just animating the dog, but you’re giving it a world within which it can now interact.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership with World Labs supports Autodesk’s broader push to integrate more AI features across its software portfolio. The company is developing “neural CAD,” a new kind of generative AI model trained on geometric data that can reason about components and entire systems. Put simply, it can generate working 3D models, not just images, with an understanding of how those designs would function in the real world.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Autodesk’s neural CAD models are already being integrated into the firm’s product design and architecture products as a step toward more advanced spatial intelligence. But World Labs’ models could help extend that capability beyond individual design files toward more holistic digital representations of the physical world.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Green thinks different AI systems, including large language models, world models, and neural CAD will be combined in the future to improve designs for Autodesk’s customers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“If AI is to be truly useful, it must understand worlds, not just words,” Li said in the statement. “Worlds are governed by geometry, physics, and dynamics, and reconciling the semantic, spatial, and physical is the next great frontier of AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was originally published February 18, 2026 at 6 a.m. PST. It has been updated to include more details on World Labs’ raise.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Untitled-design.png?resize=1200,764" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Fei-Fei Li’s World Labs has secured a $200 million investment from software design giant Autodesk as part of a larger $1 billion round from backers including AMD, Emerson Collective, Fidelity, Nvidia, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;World Labs, which emerged from stealth in 2024 with $230 million at a $1 billion valuation, declined to say whether the latest round boosted its valuation. However, reports a month ago suggested it was aiming to raise at a $5 billion valuation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The partnership between World Labs and Autodesk will see the two companies collaborating to explore how World Labs’ models — AI systems that can generate and reason about immersive 3D environments — can work alongside Autodesk’s tools, and vice versa, starting with a focus on entertainment use cases.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For World Labs, Autodesk’s investment is a signal that its product has commercial appeal. The startup’s first world model product, Marble, released last November, lets users create editable, downloadable 3D environments.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Autodesk is one of the biggest developers of 3D CAD (computer-aided design) software. Its platform underpins architectural, engineering, construction, manufacturing, and entertainment workflows. That focus on the built world makes investment in advanced spatial AI a natural extension of its core business.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Or as Li put it in a statement: “Autodesk has long helped people think spatially and solve real-world problems and, together, we share a clear purpose: building physical AI that augments human creativity and puts more powerful tools in the hands of designers, builders, and creators.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the deal, Autodesk will serve as an advisor to World Labs, and the two will collaborate at the “research and model level.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Daron Green, Autodesk’s chief scientist, told TechCrunch the partnership is still in its early days, so the precise form it’s going to take hasn’t been determined yet.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You could anticipate us consuming their models or them consuming our models in different settings,” Green said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He mused that customers might like to start with a world-model-based sketch in World Labs (say, of an office layout) and then drill down on certain design aspects (like the design of the desk), which is where Autodesk’s tech might come in. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Similarly, you might want to take an object that you’ve designed in our [platform], and put it in a context that you create through one of [World Labs’] prompts,” Green said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Green added that data sharing is not part of the agreement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Green said the two companies plan to start with media and entertainment use cases. Most companies building world models — including Google DeepMind and Runway — see gaming and interactive entertainment as an initial go-to-market strategy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Autodesk already works with most major media production companies and has been training models for character animation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These are close to world models,” Green said. “They’re a characterization of an animal in the world that’s responding to physical constraints like time, maybe a terrain it needs to traverse. So there’s a physical understanding in the model, and you can see how that might be combined [with World Labs’ tech]. You’re not just animating the dog, but you’re giving it a world within which it can now interact.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The partnership with World Labs supports Autodesk’s broader push to integrate more AI features across its software portfolio. The company is developing “neural CAD,” a new kind of generative AI model trained on geometric data that can reason about components and entire systems. Put simply, it can generate working 3D models, not just images, with an understanding of how those designs would function in the real world.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Autodesk’s neural CAD models are already being integrated into the firm’s product design and architecture products as a step toward more advanced spatial intelligence. But World Labs’ models could help extend that capability beyond individual design files toward more holistic digital representations of the physical world.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Green thinks different AI systems, including large language models, world models, and neural CAD will be combined in the future to improve designs for Autodesk’s customers.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“If AI is to be truly useful, it must understand worlds, not just words,” Li said in the statement. “Worlds are governed by geometry, physics, and dynamics, and reconciling the semantic, spatial, and physical is the next great frontier of AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was originally published February 18, 2026 at 6 a.m. PST. It has been updated to include more details on World Labs’ raise.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/18/world-labs-lands-200m-from-autodesk-to-bring-world-models-into-3d-workflows/</guid><pubDate>Wed, 18 Feb 2026 18:07:16 +0000</pubDate></item><item><title>[NEW] Amazon halts Blue Jay robotics project after less than six months (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/18/amazon-halts-blue-jay-robotics-project-after-less-than-six-months/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/about-amazon-hero-20230227-amazon-288.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon has hundreds of thousands of robots in its warehouses, but that doesn’t mean all of its robotic initiatives are a success story.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ecommerce giant has halted its Blue Jay warehouse robotics project just months after unveiling the tech, as originally reported by Business Insider and confirmed by TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Blue Jay, a multi-armed robot designed to sort and move packages, was unveiled in October for use in the company’s same-day delivery facilities. At the time, the company was testing the robots at a facility in South Carolina and said it took Amazon significantly less time to develop Blue Jay — only about a year— than it did to develop its other warehouse robots, a speed the company credited to advancements in AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon spokesperson Terrance Clark told TechCrunch that Blue Jay was launched as a prototype — although that was not made clear in the company’s original press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company plans to use Blue Jay’s core technology for other robotics “manipulation programs” with employees who worked on Blue Jay being moved to other projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re always experimenting with new ways to improve the customer experience and make work safer, more efficient, and more engaging for our employees,” Clark told TechCrunch over email. “In this case, we’re actually accelerating the use of the underlying technology developed for Blue Jay, and nearly all of the technologies are being carried over and will continue to support employees across our network.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon also unveiled the Vulcan robot last year, which is used in the storage compartments of the company’s warehouses. Vulcan is a two-armed robot, with one arm meant to rearrange and move items in a compartment while the other is equipped with a camera and suction cups to grab goods. The Vulcan can allegedly “feel” the objects that it touches and was trained on data gathered from real-world interactions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon has been developing its internal robotics program since 2012 when it purchased Kiva Systems, a robotics company whose warehouse automation technology formed the foundation of Amazon’s fulfillment operations. It surpassed 1 million robots in its warehouses last July.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/about-amazon-hero-20230227-amazon-288.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon has hundreds of thousands of robots in its warehouses, but that doesn’t mean all of its robotic initiatives are a success story.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ecommerce giant has halted its Blue Jay warehouse robotics project just months after unveiling the tech, as originally reported by Business Insider and confirmed by TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Blue Jay, a multi-armed robot designed to sort and move packages, was unveiled in October for use in the company’s same-day delivery facilities. At the time, the company was testing the robots at a facility in South Carolina and said it took Amazon significantly less time to develop Blue Jay — only about a year— than it did to develop its other warehouse robots, a speed the company credited to advancements in AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon spokesperson Terrance Clark told TechCrunch that Blue Jay was launched as a prototype — although that was not made clear in the company’s original press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company plans to use Blue Jay’s core technology for other robotics “manipulation programs” with employees who worked on Blue Jay being moved to other projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re always experimenting with new ways to improve the customer experience and make work safer, more efficient, and more engaging for our employees,” Clark told TechCrunch over email. “In this case, we’re actually accelerating the use of the underlying technology developed for Blue Jay, and nearly all of the technologies are being carried over and will continue to support employees across our network.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon also unveiled the Vulcan robot last year, which is used in the storage compartments of the company’s warehouses. Vulcan is a two-armed robot, with one arm meant to rearrange and move items in a compartment while the other is equipped with a camera and suction cups to grab goods. The Vulcan can allegedly “feel” the objects that it touches and was trained on data gathered from real-world interactions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon has been developing its internal robotics program since 2012 when it purchased Kiva Systems, a robotics company whose warehouse automation technology formed the foundation of Amazon’s fulfillment operations. It surpassed 1 million robots in its warehouses last July.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/18/amazon-halts-blue-jay-robotics-project-after-less-than-six-months/</guid><pubDate>Wed, 18 Feb 2026 18:27:10 +0000</pubDate></item></channel></rss>